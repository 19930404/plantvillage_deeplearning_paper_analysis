I0403 04:58:46.435801 31448 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 04:58:46.436228 31448 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 04:58:46.436262 31448 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 04:58:50.480046 31448 caffe.cpp:185] Using GPUs 0, 1
I0403 04:58:50.480531 31448 caffe.cpp:190] GPU 0: Tesla K40m
I0403 04:58:50.480922 31448 caffe.cpp:190] GPU 1: Tesla K40m
I0403 04:58:50.685693 31448 solver.cpp:48] Initializing solver from parameters: 
test_iter: 437
test_interval: 105
base_lr: 0.005
display: 5
max_iter: 3172
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1057
snapshot: 105
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 04:58:50.707592 31448 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 04:58:50.723690 31448 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 04:58:50.723742 31448 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 04:58:50.724397 31448 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 04:58:50.724876 31448 layer_factory.hpp:77] Creating layer data
I0403 04:58:50.725587 31448 net.cpp:91] Creating Layer data
I0403 04:58:50.725626 31448 net.cpp:399] data -> data
I0403 04:58:50.725678 31448 net.cpp:399] data -> label
I0403 04:58:50.725715 31448 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto
I0403 04:58:50.772070 31450 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/train_db
I0403 04:58:50.810116 31448 data_layer.cpp:41] output data size: 100,3,227,227
I0403 04:58:50.932087 31448 net.cpp:141] Setting up data
I0403 04:58:50.932199 31448 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 04:58:50.932224 31448 net.cpp:148] Top shape: 100 (100)
I0403 04:58:50.932241 31448 net.cpp:156] Memory required for data: 61835200
I0403 04:58:50.932274 31448 layer_factory.hpp:77] Creating layer conv1
I0403 04:58:50.932328 31448 net.cpp:91] Creating Layer conv1
I0403 04:58:50.932353 31448 net.cpp:425] conv1 <- data
I0403 04:58:50.932387 31448 net.cpp:399] conv1 -> conv1
I0403 04:58:50.935078 31448 net.cpp:141] Setting up conv1
I0403 04:58:50.935111 31448 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 04:58:50.935130 31448 net.cpp:156] Memory required for data: 177995200
I0403 04:58:50.935168 31448 layer_factory.hpp:77] Creating layer relu1
I0403 04:58:50.935196 31448 net.cpp:91] Creating Layer relu1
I0403 04:58:50.935217 31448 net.cpp:425] relu1 <- conv1
I0403 04:58:50.935236 31448 net.cpp:386] relu1 -> conv1 (in-place)
I0403 04:58:50.935262 31448 net.cpp:141] Setting up relu1
I0403 04:58:50.935283 31448 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 04:58:50.935308 31448 net.cpp:156] Memory required for data: 294155200
I0403 04:58:50.935327 31448 layer_factory.hpp:77] Creating layer norm1
I0403 04:58:50.935382 31448 net.cpp:91] Creating Layer norm1
I0403 04:58:50.935401 31448 net.cpp:425] norm1 <- conv1
I0403 04:58:50.935423 31448 net.cpp:399] norm1 -> norm1
I0403 04:58:50.941033 31448 net.cpp:141] Setting up norm1
I0403 04:58:50.941071 31448 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 04:58:50.941089 31448 net.cpp:156] Memory required for data: 410315200
I0403 04:58:50.941105 31448 layer_factory.hpp:77] Creating layer pool1
I0403 04:58:50.941128 31448 net.cpp:91] Creating Layer pool1
I0403 04:58:50.941148 31448 net.cpp:425] pool1 <- norm1
I0403 04:58:50.941169 31448 net.cpp:399] pool1 -> pool1
I0403 04:58:50.941231 31448 net.cpp:141] Setting up pool1
I0403 04:58:50.941259 31448 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 04:58:50.941277 31448 net.cpp:156] Memory required for data: 438308800
I0403 04:58:50.941301 31448 layer_factory.hpp:77] Creating layer conv2
I0403 04:58:50.941329 31448 net.cpp:91] Creating Layer conv2
I0403 04:58:50.941349 31448 net.cpp:425] conv2 <- pool1
I0403 04:58:50.941371 31448 net.cpp:399] conv2 -> conv2
I0403 04:58:50.942762 31452 blocking_queue.cpp:50] Waiting for data
I0403 04:58:50.958396 31448 net.cpp:141] Setting up conv2
I0403 04:58:50.958427 31448 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 04:58:50.958446 31448 net.cpp:156] Memory required for data: 512958400
I0403 04:58:50.958468 31448 layer_factory.hpp:77] Creating layer relu2
I0403 04:58:50.958492 31448 net.cpp:91] Creating Layer relu2
I0403 04:58:50.958511 31448 net.cpp:425] relu2 <- conv2
I0403 04:58:50.958530 31448 net.cpp:386] relu2 -> conv2 (in-place)
I0403 04:58:50.958551 31448 net.cpp:141] Setting up relu2
I0403 04:58:50.958570 31448 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 04:58:50.958587 31448 net.cpp:156] Memory required for data: 587608000
I0403 04:58:50.958606 31448 layer_factory.hpp:77] Creating layer norm2
I0403 04:58:50.958624 31448 net.cpp:91] Creating Layer norm2
I0403 04:58:50.958641 31448 net.cpp:425] norm2 <- conv2
I0403 04:58:50.958660 31448 net.cpp:399] norm2 -> norm2
I0403 04:58:50.958705 31448 net.cpp:141] Setting up norm2
I0403 04:58:50.958730 31448 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 04:58:50.958746 31448 net.cpp:156] Memory required for data: 662257600
I0403 04:58:50.958763 31448 layer_factory.hpp:77] Creating layer pool2
I0403 04:58:50.958784 31448 net.cpp:91] Creating Layer pool2
I0403 04:58:50.958802 31448 net.cpp:425] pool2 <- norm2
I0403 04:58:50.958820 31448 net.cpp:399] pool2 -> pool2
I0403 04:58:50.958866 31448 net.cpp:141] Setting up pool2
I0403 04:58:50.958890 31448 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 04:58:50.958906 31448 net.cpp:156] Memory required for data: 679563200
I0403 04:58:50.958921 31448 layer_factory.hpp:77] Creating layer conv3
I0403 04:58:50.958943 31448 net.cpp:91] Creating Layer conv3
I0403 04:58:50.958961 31448 net.cpp:425] conv3 <- pool2
I0403 04:58:50.958982 31448 net.cpp:399] conv3 -> conv3
I0403 04:58:50.993111 31448 net.cpp:141] Setting up conv3
I0403 04:58:50.993144 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:50.993162 31448 net.cpp:156] Memory required for data: 705521600
I0403 04:58:50.993185 31448 layer_factory.hpp:77] Creating layer relu3
I0403 04:58:50.993206 31448 net.cpp:91] Creating Layer relu3
I0403 04:58:50.993224 31448 net.cpp:425] relu3 <- conv3
I0403 04:58:50.993244 31448 net.cpp:386] relu3 -> conv3 (in-place)
I0403 04:58:50.993265 31448 net.cpp:141] Setting up relu3
I0403 04:58:50.993284 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:50.993305 31448 net.cpp:156] Memory required for data: 731480000
I0403 04:58:50.993322 31448 layer_factory.hpp:77] Creating layer conv4
I0403 04:58:50.993345 31448 net.cpp:91] Creating Layer conv4
I0403 04:58:50.993366 31448 net.cpp:425] conv4 <- conv3
I0403 04:58:50.993388 31448 net.cpp:399] conv4 -> conv4
I0403 04:58:51.018940 31448 net.cpp:141] Setting up conv4
I0403 04:58:51.018975 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:51.018992 31448 net.cpp:156] Memory required for data: 757438400
I0403 04:58:51.019031 31448 layer_factory.hpp:77] Creating layer relu4
I0403 04:58:51.019053 31448 net.cpp:91] Creating Layer relu4
I0403 04:58:51.019073 31448 net.cpp:425] relu4 <- conv4
I0403 04:58:51.019093 31448 net.cpp:386] relu4 -> conv4 (in-place)
I0403 04:58:51.019114 31448 net.cpp:141] Setting up relu4
I0403 04:58:51.019134 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:51.019151 31448 net.cpp:156] Memory required for data: 783396800
I0403 04:58:51.019166 31448 layer_factory.hpp:77] Creating layer conv5
I0403 04:58:51.019189 31448 net.cpp:91] Creating Layer conv5
I0403 04:58:51.019208 31448 net.cpp:425] conv5 <- conv4
I0403 04:58:51.019229 31448 net.cpp:399] conv5 -> conv5
I0403 04:58:51.036451 31448 net.cpp:141] Setting up conv5
I0403 04:58:51.036487 31448 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 04:58:51.036505 31448 net.cpp:156] Memory required for data: 800702400
I0403 04:58:51.036528 31448 layer_factory.hpp:77] Creating layer relu5
I0403 04:58:51.036552 31448 net.cpp:91] Creating Layer relu5
I0403 04:58:51.036571 31448 net.cpp:425] relu5 <- conv5
I0403 04:58:51.036592 31448 net.cpp:386] relu5 -> conv5 (in-place)
I0403 04:58:51.036615 31448 net.cpp:141] Setting up relu5
I0403 04:58:51.036636 31448 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 04:58:51.036653 31448 net.cpp:156] Memory required for data: 818008000
I0403 04:58:51.036669 31448 layer_factory.hpp:77] Creating layer pool5
I0403 04:58:51.036690 31448 net.cpp:91] Creating Layer pool5
I0403 04:58:51.036706 31448 net.cpp:425] pool5 <- conv5
I0403 04:58:51.036727 31448 net.cpp:399] pool5 -> pool5
I0403 04:58:51.036777 31448 net.cpp:141] Setting up pool5
I0403 04:58:51.036803 31448 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 04:58:51.036820 31448 net.cpp:156] Memory required for data: 821694400
I0403 04:58:51.036837 31448 layer_factory.hpp:77] Creating layer fc6
I0403 04:58:51.036870 31448 net.cpp:91] Creating Layer fc6
I0403 04:58:51.036890 31448 net.cpp:425] fc6 <- pool5
I0403 04:58:51.036912 31448 net.cpp:399] fc6 -> fc6
I0403 04:58:52.424613 31448 net.cpp:141] Setting up fc6
I0403 04:58:52.424710 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:52.424727 31448 net.cpp:156] Memory required for data: 823332800
I0403 04:58:52.424751 31448 layer_factory.hpp:77] Creating layer relu6
I0403 04:58:52.424778 31448 net.cpp:91] Creating Layer relu6
I0403 04:58:52.424798 31448 net.cpp:425] relu6 <- fc6
I0403 04:58:52.424818 31448 net.cpp:386] relu6 -> fc6 (in-place)
I0403 04:58:52.424840 31448 net.cpp:141] Setting up relu6
I0403 04:58:52.424859 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:52.424873 31448 net.cpp:156] Memory required for data: 824971200
I0403 04:58:52.424886 31448 layer_factory.hpp:77] Creating layer drop6
I0403 04:58:52.424916 31448 net.cpp:91] Creating Layer drop6
I0403 04:58:52.424932 31448 net.cpp:425] drop6 <- fc6
I0403 04:58:52.424950 31448 net.cpp:386] drop6 -> fc6 (in-place)
I0403 04:58:52.424998 31448 net.cpp:141] Setting up drop6
I0403 04:58:52.425024 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:52.425040 31448 net.cpp:156] Memory required for data: 826609600
I0403 04:58:52.425055 31448 layer_factory.hpp:77] Creating layer fc7
I0403 04:58:52.425076 31448 net.cpp:91] Creating Layer fc7
I0403 04:58:52.425091 31448 net.cpp:425] fc7 <- fc6
I0403 04:58:52.425110 31448 net.cpp:399] fc7 -> fc7
I0403 04:58:53.036368 31448 net.cpp:141] Setting up fc7
I0403 04:58:53.036470 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:53.036489 31448 net.cpp:156] Memory required for data: 828248000
I0403 04:58:53.036511 31448 layer_factory.hpp:77] Creating layer relu7
I0403 04:58:53.036537 31448 net.cpp:91] Creating Layer relu7
I0403 04:58:53.036566 31448 net.cpp:425] relu7 <- fc7
I0403 04:58:53.036587 31448 net.cpp:386] relu7 -> fc7 (in-place)
I0403 04:58:53.036622 31448 net.cpp:141] Setting up relu7
I0403 04:58:53.036640 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:53.036655 31448 net.cpp:156] Memory required for data: 829886400
I0403 04:58:53.036705 31448 layer_factory.hpp:77] Creating layer drop7
I0403 04:58:53.036731 31448 net.cpp:91] Creating Layer drop7
I0403 04:58:53.036749 31448 net.cpp:425] drop7 <- fc7
I0403 04:58:53.036767 31448 net.cpp:386] drop7 -> fc7 (in-place)
I0403 04:58:53.036808 31448 net.cpp:141] Setting up drop7
I0403 04:58:53.036831 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:53.036851 31448 net.cpp:156] Memory required for data: 831524800
I0403 04:58:53.036866 31448 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 04:58:53.036890 31448 net.cpp:91] Creating Layer fc8_plantvillage
I0403 04:58:53.036918 31448 net.cpp:425] fc8_plantvillage <- fc7
I0403 04:58:53.036938 31448 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 04:58:53.042914 31448 net.cpp:141] Setting up fc8_plantvillage
I0403 04:58:53.042945 31448 net.cpp:148] Top shape: 100 38 (3800)
I0403 04:58:53.042963 31448 net.cpp:156] Memory required for data: 831540000
I0403 04:58:53.042982 31448 layer_factory.hpp:77] Creating layer loss
I0403 04:58:53.043007 31448 net.cpp:91] Creating Layer loss
I0403 04:58:53.043025 31448 net.cpp:425] loss <- fc8_plantvillage
I0403 04:58:53.043041 31448 net.cpp:425] loss <- label
I0403 04:58:53.043062 31448 net.cpp:399] loss -> loss
I0403 04:58:53.043089 31448 layer_factory.hpp:77] Creating layer loss
I0403 04:58:53.043187 31448 net.cpp:141] Setting up loss
I0403 04:58:53.043211 31448 net.cpp:148] Top shape: (1)
I0403 04:58:53.043227 31448 net.cpp:151]     with loss weight 1
I0403 04:58:53.043290 31448 net.cpp:156] Memory required for data: 831540004
I0403 04:58:53.043308 31448 net.cpp:217] loss needs backward computation.
I0403 04:58:53.043324 31448 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 04:58:53.043339 31448 net.cpp:217] drop7 needs backward computation.
I0403 04:58:53.043354 31448 net.cpp:217] relu7 needs backward computation.
I0403 04:58:53.043368 31448 net.cpp:217] fc7 needs backward computation.
I0403 04:58:53.043383 31448 net.cpp:217] drop6 needs backward computation.
I0403 04:58:53.043397 31448 net.cpp:217] relu6 needs backward computation.
I0403 04:58:53.043411 31448 net.cpp:217] fc6 needs backward computation.
I0403 04:58:53.043426 31448 net.cpp:217] pool5 needs backward computation.
I0403 04:58:53.043440 31448 net.cpp:217] relu5 needs backward computation.
I0403 04:58:53.043455 31448 net.cpp:217] conv5 needs backward computation.
I0403 04:58:53.043470 31448 net.cpp:217] relu4 needs backward computation.
I0403 04:58:53.043485 31448 net.cpp:217] conv4 needs backward computation.
I0403 04:58:53.043500 31448 net.cpp:217] relu3 needs backward computation.
I0403 04:58:53.043515 31448 net.cpp:217] conv3 needs backward computation.
I0403 04:58:53.043530 31448 net.cpp:217] pool2 needs backward computation.
I0403 04:58:53.043545 31448 net.cpp:217] norm2 needs backward computation.
I0403 04:58:53.043560 31448 net.cpp:217] relu2 needs backward computation.
I0403 04:58:53.043576 31448 net.cpp:217] conv2 needs backward computation.
I0403 04:58:53.043589 31448 net.cpp:217] pool1 needs backward computation.
I0403 04:58:53.043603 31448 net.cpp:217] norm1 needs backward computation.
I0403 04:58:53.043618 31448 net.cpp:217] relu1 needs backward computation.
I0403 04:58:53.043632 31448 net.cpp:217] conv1 needs backward computation.
I0403 04:58:53.043648 31448 net.cpp:219] data does not need backward computation.
I0403 04:58:53.043661 31448 net.cpp:261] This network produces output loss
I0403 04:58:53.043687 31448 net.cpp:274] Network initialization done.
I0403 04:58:53.044706 31448 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 04:58:53.044764 31448 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 04:58:53.045379 31448 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 04:58:53.045532 31448 layer_factory.hpp:77] Creating layer data
I0403 04:58:53.045697 31448 net.cpp:91] Creating Layer data
I0403 04:58:53.045727 31448 net.cpp:399] data -> data
I0403 04:58:53.045753 31448 net.cpp:399] data -> label
I0403 04:58:53.045776 31448 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto
I0403 04:58:53.092578 31453 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/test_db
I0403 04:58:53.151515 31448 data_layer.cpp:41] output data size: 100,3,227,227
I0403 04:58:53.341711 31448 net.cpp:141] Setting up data
I0403 04:58:53.341789 31448 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 04:58:53.341809 31448 net.cpp:148] Top shape: 100 (100)
I0403 04:58:53.341826 31448 net.cpp:156] Memory required for data: 61835200
I0403 04:58:53.341845 31448 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 04:58:53.341874 31448 net.cpp:91] Creating Layer label_data_1_split
I0403 04:58:53.341894 31448 net.cpp:425] label_data_1_split <- label
I0403 04:58:53.341917 31448 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 04:58:53.341944 31448 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 04:58:53.342006 31448 net.cpp:141] Setting up label_data_1_split
I0403 04:58:53.342031 31448 net.cpp:148] Top shape: 100 (100)
I0403 04:58:53.342048 31448 net.cpp:148] Top shape: 100 (100)
I0403 04:58:53.342066 31448 net.cpp:156] Memory required for data: 61836000
I0403 04:58:53.342082 31448 layer_factory.hpp:77] Creating layer conv1
I0403 04:58:53.342113 31448 net.cpp:91] Creating Layer conv1
I0403 04:58:53.342133 31448 net.cpp:425] conv1 <- data
I0403 04:58:53.342154 31448 net.cpp:399] conv1 -> conv1
I0403 04:58:53.343755 31448 net.cpp:141] Setting up conv1
I0403 04:58:53.343783 31448 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 04:58:53.343801 31448 net.cpp:156] Memory required for data: 177996000
I0403 04:58:53.343825 31448 layer_factory.hpp:77] Creating layer relu1
I0403 04:58:53.343847 31448 net.cpp:91] Creating Layer relu1
I0403 04:58:53.343865 31448 net.cpp:425] relu1 <- conv1
I0403 04:58:53.343885 31448 net.cpp:386] relu1 -> conv1 (in-place)
I0403 04:58:53.343906 31448 net.cpp:141] Setting up relu1
I0403 04:58:53.343925 31448 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 04:58:53.343941 31448 net.cpp:156] Memory required for data: 294156000
I0403 04:58:53.343958 31448 layer_factory.hpp:77] Creating layer norm1
I0403 04:58:53.343981 31448 net.cpp:91] Creating Layer norm1
I0403 04:58:53.343998 31448 net.cpp:425] norm1 <- conv1
I0403 04:58:53.344018 31448 net.cpp:399] norm1 -> norm1
I0403 04:58:53.349903 31448 net.cpp:141] Setting up norm1
I0403 04:58:53.349944 31448 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 04:58:53.349962 31448 net.cpp:156] Memory required for data: 410316000
I0403 04:58:53.349979 31448 layer_factory.hpp:77] Creating layer pool1
I0403 04:58:53.350003 31448 net.cpp:91] Creating Layer pool1
I0403 04:58:53.350019 31448 net.cpp:425] pool1 <- norm1
I0403 04:58:53.350040 31448 net.cpp:399] pool1 -> pool1
I0403 04:58:53.350092 31448 net.cpp:141] Setting up pool1
I0403 04:58:53.350117 31448 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 04:58:53.350133 31448 net.cpp:156] Memory required for data: 438309600
I0403 04:58:53.350175 31448 layer_factory.hpp:77] Creating layer conv2
I0403 04:58:53.350201 31448 net.cpp:91] Creating Layer conv2
I0403 04:58:53.350221 31448 net.cpp:425] conv2 <- pool1
I0403 04:58:53.350242 31448 net.cpp:399] conv2 -> conv2
I0403 04:58:53.362669 31448 net.cpp:141] Setting up conv2
I0403 04:58:53.364748 31448 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 04:58:53.364778 31448 net.cpp:156] Memory required for data: 512959200
I0403 04:58:53.364809 31448 layer_factory.hpp:77] Creating layer relu2
I0403 04:58:53.364838 31448 net.cpp:91] Creating Layer relu2
I0403 04:58:53.364863 31448 net.cpp:425] relu2 <- conv2
I0403 04:58:53.364889 31448 net.cpp:386] relu2 -> conv2 (in-place)
I0403 04:58:53.364910 31448 net.cpp:141] Setting up relu2
I0403 04:58:53.364938 31448 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 04:58:53.364974 31448 net.cpp:156] Memory required for data: 587608800
I0403 04:58:53.364997 31448 layer_factory.hpp:77] Creating layer norm2
I0403 04:58:53.365020 31448 net.cpp:91] Creating Layer norm2
I0403 04:58:53.365037 31448 net.cpp:425] norm2 <- conv2
I0403 04:58:53.365057 31448 net.cpp:399] norm2 -> norm2
I0403 04:58:53.365116 31448 net.cpp:141] Setting up norm2
I0403 04:58:53.365142 31448 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 04:58:53.365159 31448 net.cpp:156] Memory required for data: 662258400
I0403 04:58:53.365175 31448 layer_factory.hpp:77] Creating layer pool2
I0403 04:58:53.365195 31448 net.cpp:91] Creating Layer pool2
I0403 04:58:53.365211 31448 net.cpp:425] pool2 <- norm2
I0403 04:58:53.365231 31448 net.cpp:399] pool2 -> pool2
I0403 04:58:53.365304 31448 net.cpp:141] Setting up pool2
I0403 04:58:53.365330 31448 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 04:58:53.365346 31448 net.cpp:156] Memory required for data: 679564000
I0403 04:58:53.365361 31448 layer_factory.hpp:77] Creating layer conv3
I0403 04:58:53.365386 31448 net.cpp:91] Creating Layer conv3
I0403 04:58:53.365406 31448 net.cpp:425] conv3 <- pool2
I0403 04:58:53.365427 31448 net.cpp:399] conv3 -> conv3
I0403 04:58:53.399910 31448 net.cpp:141] Setting up conv3
I0403 04:58:53.399966 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:53.399984 31448 net.cpp:156] Memory required for data: 705522400
I0403 04:58:53.400010 31448 layer_factory.hpp:77] Creating layer relu3
I0403 04:58:53.400035 31448 net.cpp:91] Creating Layer relu3
I0403 04:58:53.400054 31448 net.cpp:425] relu3 <- conv3
I0403 04:58:53.400075 31448 net.cpp:386] relu3 -> conv3 (in-place)
I0403 04:58:53.400097 31448 net.cpp:141] Setting up relu3
I0403 04:58:53.400116 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:53.400131 31448 net.cpp:156] Memory required for data: 731480800
I0403 04:58:53.400147 31448 layer_factory.hpp:77] Creating layer conv4
I0403 04:58:53.400171 31448 net.cpp:91] Creating Layer conv4
I0403 04:58:53.400190 31448 net.cpp:425] conv4 <- conv3
I0403 04:58:53.400213 31448 net.cpp:399] conv4 -> conv4
I0403 04:58:53.425918 31448 net.cpp:141] Setting up conv4
I0403 04:58:53.425958 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:53.425974 31448 net.cpp:156] Memory required for data: 757439200
I0403 04:58:53.425994 31448 layer_factory.hpp:77] Creating layer relu4
I0403 04:58:53.426015 31448 net.cpp:91] Creating Layer relu4
I0403 04:58:53.426033 31448 net.cpp:425] relu4 <- conv4
I0403 04:58:53.426053 31448 net.cpp:386] relu4 -> conv4 (in-place)
I0403 04:58:53.426072 31448 net.cpp:141] Setting up relu4
I0403 04:58:53.426090 31448 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 04:58:53.426105 31448 net.cpp:156] Memory required for data: 783397600
I0403 04:58:53.426121 31448 layer_factory.hpp:77] Creating layer conv5
I0403 04:58:53.426144 31448 net.cpp:91] Creating Layer conv5
I0403 04:58:53.426162 31448 net.cpp:425] conv5 <- conv4
I0403 04:58:53.426182 31448 net.cpp:399] conv5 -> conv5
I0403 04:58:53.443522 31448 net.cpp:141] Setting up conv5
I0403 04:58:53.443554 31448 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 04:58:53.443599 31448 net.cpp:156] Memory required for data: 800703200
I0403 04:58:53.443626 31448 layer_factory.hpp:77] Creating layer relu5
I0403 04:58:53.443648 31448 net.cpp:91] Creating Layer relu5
I0403 04:58:53.443675 31448 net.cpp:425] relu5 <- conv5
I0403 04:58:53.443701 31448 net.cpp:386] relu5 -> conv5 (in-place)
I0403 04:58:53.443729 31448 net.cpp:141] Setting up relu5
I0403 04:58:53.443758 31448 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 04:58:53.443774 31448 net.cpp:156] Memory required for data: 818008800
I0403 04:58:53.443789 31448 layer_factory.hpp:77] Creating layer pool5
I0403 04:58:53.443815 31448 net.cpp:91] Creating Layer pool5
I0403 04:58:53.443835 31448 net.cpp:425] pool5 <- conv5
I0403 04:58:53.443856 31448 net.cpp:399] pool5 -> pool5
I0403 04:58:53.443910 31448 net.cpp:141] Setting up pool5
I0403 04:58:53.443934 31448 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 04:58:53.443950 31448 net.cpp:156] Memory required for data: 821695200
I0403 04:58:53.443965 31448 layer_factory.hpp:77] Creating layer fc6
I0403 04:58:53.443989 31448 net.cpp:91] Creating Layer fc6
I0403 04:58:53.444010 31448 net.cpp:425] fc6 <- pool5
I0403 04:58:53.444030 31448 net.cpp:399] fc6 -> fc6
I0403 04:58:54.836196 31448 net.cpp:141] Setting up fc6
I0403 04:58:54.836297 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:54.836315 31448 net.cpp:156] Memory required for data: 823333600
I0403 04:58:54.836338 31448 layer_factory.hpp:77] Creating layer relu6
I0403 04:58:54.836366 31448 net.cpp:91] Creating Layer relu6
I0403 04:58:54.836385 31448 net.cpp:425] relu6 <- fc6
I0403 04:58:54.836405 31448 net.cpp:386] relu6 -> fc6 (in-place)
I0403 04:58:54.836427 31448 net.cpp:141] Setting up relu6
I0403 04:58:54.836447 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:54.836459 31448 net.cpp:156] Memory required for data: 824972000
I0403 04:58:54.836473 31448 layer_factory.hpp:77] Creating layer drop6
I0403 04:58:54.836494 31448 net.cpp:91] Creating Layer drop6
I0403 04:58:54.836513 31448 net.cpp:425] drop6 <- fc6
I0403 04:58:54.836529 31448 net.cpp:386] drop6 -> fc6 (in-place)
I0403 04:58:54.836567 31448 net.cpp:141] Setting up drop6
I0403 04:58:54.836596 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:54.836613 31448 net.cpp:156] Memory required for data: 826610400
I0403 04:58:54.836627 31448 layer_factory.hpp:77] Creating layer fc7
I0403 04:58:54.836649 31448 net.cpp:91] Creating Layer fc7
I0403 04:58:54.836666 31448 net.cpp:425] fc7 <- fc6
I0403 04:58:54.836685 31448 net.cpp:399] fc7 -> fc7
I0403 04:58:55.440155 31448 net.cpp:141] Setting up fc7
I0403 04:58:55.440248 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:55.440266 31448 net.cpp:156] Memory required for data: 828248800
I0403 04:58:55.440294 31448 layer_factory.hpp:77] Creating layer relu7
I0403 04:58:55.440321 31448 net.cpp:91] Creating Layer relu7
I0403 04:58:55.440340 31448 net.cpp:425] relu7 <- fc7
I0403 04:58:55.440359 31448 net.cpp:386] relu7 -> fc7 (in-place)
I0403 04:58:55.440382 31448 net.cpp:141] Setting up relu7
I0403 04:58:55.440398 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:55.440413 31448 net.cpp:156] Memory required for data: 829887200
I0403 04:58:55.440428 31448 layer_factory.hpp:77] Creating layer drop7
I0403 04:58:55.440450 31448 net.cpp:91] Creating Layer drop7
I0403 04:58:55.440467 31448 net.cpp:425] drop7 <- fc7
I0403 04:58:55.440485 31448 net.cpp:386] drop7 -> fc7 (in-place)
I0403 04:58:55.440526 31448 net.cpp:141] Setting up drop7
I0403 04:58:55.440547 31448 net.cpp:148] Top shape: 100 4096 (409600)
I0403 04:58:55.440562 31448 net.cpp:156] Memory required for data: 831525600
I0403 04:58:55.440577 31448 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 04:58:55.440598 31448 net.cpp:91] Creating Layer fc8_plantvillage
I0403 04:58:55.440615 31448 net.cpp:425] fc8_plantvillage <- fc7
I0403 04:58:55.440635 31448 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 04:58:55.446622 31448 net.cpp:141] Setting up fc8_plantvillage
I0403 04:58:55.446655 31448 net.cpp:148] Top shape: 100 38 (3800)
I0403 04:58:55.446704 31448 net.cpp:156] Memory required for data: 831540800
I0403 04:58:55.446723 31448 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 04:58:55.446744 31448 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 04:58:55.446760 31448 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 04:58:55.446779 31448 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 04:58:55.446799 31448 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 04:58:55.446856 31448 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 04:58:55.446879 31448 net.cpp:148] Top shape: 100 38 (3800)
I0403 04:58:55.446895 31448 net.cpp:148] Top shape: 100 38 (3800)
I0403 04:58:55.446909 31448 net.cpp:156] Memory required for data: 831571200
I0403 04:58:55.446925 31448 layer_factory.hpp:77] Creating layer loss
I0403 04:58:55.446943 31448 net.cpp:91] Creating Layer loss
I0403 04:58:55.446959 31448 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 04:58:55.446976 31448 net.cpp:425] loss <- label_data_1_split_0
I0403 04:58:55.446995 31448 net.cpp:399] loss -> loss
I0403 04:58:55.447018 31448 layer_factory.hpp:77] Creating layer loss
I0403 04:58:55.447108 31448 net.cpp:141] Setting up loss
I0403 04:58:55.447130 31448 net.cpp:148] Top shape: (1)
I0403 04:58:55.447144 31448 net.cpp:151]     with loss weight 1
I0403 04:58:55.447172 31448 net.cpp:156] Memory required for data: 831571204
I0403 04:58:55.447187 31448 layer_factory.hpp:77] Creating layer accuracy
I0403 04:58:55.447209 31448 net.cpp:91] Creating Layer accuracy
I0403 04:58:55.447227 31448 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 04:58:55.447243 31448 net.cpp:425] accuracy <- label_data_1_split_1
I0403 04:58:55.447260 31448 net.cpp:399] accuracy -> accuracy
I0403 04:58:55.447298 31448 net.cpp:141] Setting up accuracy
I0403 04:58:55.447319 31448 net.cpp:148] Top shape: (1)
I0403 04:58:55.447335 31448 net.cpp:156] Memory required for data: 831571208
I0403 04:58:55.447348 31448 net.cpp:219] accuracy does not need backward computation.
I0403 04:58:55.447363 31448 net.cpp:217] loss needs backward computation.
I0403 04:58:55.447378 31448 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 04:58:55.447393 31448 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 04:58:55.447408 31448 net.cpp:217] drop7 needs backward computation.
I0403 04:58:55.447422 31448 net.cpp:217] relu7 needs backward computation.
I0403 04:58:55.447435 31448 net.cpp:217] fc7 needs backward computation.
I0403 04:58:55.447449 31448 net.cpp:217] drop6 needs backward computation.
I0403 04:58:55.447463 31448 net.cpp:217] relu6 needs backward computation.
I0403 04:58:55.447477 31448 net.cpp:217] fc6 needs backward computation.
I0403 04:58:55.447492 31448 net.cpp:217] pool5 needs backward computation.
I0403 04:58:55.447507 31448 net.cpp:217] relu5 needs backward computation.
I0403 04:58:55.447521 31448 net.cpp:217] conv5 needs backward computation.
I0403 04:58:55.447535 31448 net.cpp:217] relu4 needs backward computation.
I0403 04:58:55.447551 31448 net.cpp:217] conv4 needs backward computation.
I0403 04:58:55.447564 31448 net.cpp:217] relu3 needs backward computation.
I0403 04:58:55.447578 31448 net.cpp:217] conv3 needs backward computation.
I0403 04:58:55.447593 31448 net.cpp:217] pool2 needs backward computation.
I0403 04:58:55.447608 31448 net.cpp:217] norm2 needs backward computation.
I0403 04:58:55.447623 31448 net.cpp:217] relu2 needs backward computation.
I0403 04:58:55.447635 31448 net.cpp:217] conv2 needs backward computation.
I0403 04:58:55.447650 31448 net.cpp:217] pool1 needs backward computation.
I0403 04:58:55.447665 31448 net.cpp:217] norm1 needs backward computation.
I0403 04:58:55.447679 31448 net.cpp:217] relu1 needs backward computation.
I0403 04:58:55.447692 31448 net.cpp:217] conv1 needs backward computation.
I0403 04:58:55.447720 31448 net.cpp:219] label_data_1_split does not need backward computation.
I0403 04:58:55.447736 31448 net.cpp:219] data does not need backward computation.
I0403 04:58:55.447752 31448 net.cpp:261] This network produces output accuracy
I0403 04:58:55.447767 31448 net.cpp:261] This network produces output loss
I0403 04:58:55.447798 31448 net.cpp:274] Network initialization done.
I0403 04:58:55.447902 31448 solver.cpp:60] Solver scaffolding done.
I0403 04:58:55.471468 31448 parallel.cpp:392] GPUs pairs 0:1
I0403 04:58:55.694667 31448 data_layer.cpp:41] output data size: 100,3,227,227
I0403 04:58:58.094064 31448 parallel.cpp:425] Starting Optimization
I0403 04:58:58.094605 31448 solver.cpp:279] Solving 
I0403 04:58:58.094630 31448 solver.cpp:280] Learning Rate Policy: step
I0403 04:58:58.095631 31448 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 05:00:38.441799 31448 solver.cpp:404]     Test net output #0: accuracy = 0.0184669
I0403 05:00:38.443210 31448 solver.cpp:404]     Test net output #1: loss = 3.64262 (* 1 = 3.64262 loss)
I0403 05:00:39.080734 31448 solver.cpp:228] Iteration 0, loss = 3.66274
I0403 05:00:39.080808 31448 solver.cpp:244]     Train net output #0: loss = 3.66274 (* 1 = 3.66274 loss)
I0403 05:00:39.181318 31448 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 05:00:42.756664 31448 solver.cpp:228] Iteration 5, loss = 3.55322
I0403 05:00:42.756737 31448 solver.cpp:244]     Train net output #0: loss = 3.55322 (* 1 = 3.55322 loss)
I0403 05:00:42.932497 31448 sgd_solver.cpp:106] Iteration 5, lr = 0.005
I0403 05:00:46.401144 31448 solver.cpp:228] Iteration 10, loss = 3.39917
I0403 05:00:46.401219 31448 solver.cpp:244]     Train net output #0: loss = 3.39917 (* 1 = 3.39917 loss)
I0403 05:00:46.578627 31448 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 05:00:50.053617 31448 solver.cpp:228] Iteration 15, loss = 3.32669
I0403 05:00:50.053691 31448 solver.cpp:244]     Train net output #0: loss = 3.32669 (* 1 = 3.32669 loss)
I0403 05:00:50.198794 31448 sgd_solver.cpp:106] Iteration 15, lr = 0.005
I0403 05:00:53.710454 31448 solver.cpp:228] Iteration 20, loss = 3.3764
I0403 05:00:53.710539 31448 solver.cpp:244]     Train net output #0: loss = 3.3764 (* 1 = 3.3764 loss)
I0403 05:00:53.897054 31448 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 05:00:57.374004 31448 solver.cpp:228] Iteration 25, loss = 3.41412
I0403 05:00:57.374089 31448 solver.cpp:244]     Train net output #0: loss = 3.41412 (* 1 = 3.41412 loss)
I0403 05:00:57.586165 31448 sgd_solver.cpp:106] Iteration 25, lr = 0.005
I0403 05:01:01.116971 31448 solver.cpp:228] Iteration 30, loss = 3.39029
I0403 05:01:01.117044 31448 solver.cpp:244]     Train net output #0: loss = 3.39029 (* 1 = 3.39029 loss)
I0403 05:01:01.293077 31448 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 05:01:04.755638 31448 solver.cpp:228] Iteration 35, loss = 3.24863
I0403 05:01:04.755717 31448 solver.cpp:244]     Train net output #0: loss = 3.24863 (* 1 = 3.24863 loss)
I0403 05:01:04.959066 31448 sgd_solver.cpp:106] Iteration 35, lr = 0.005
I0403 05:01:08.354640 31448 solver.cpp:228] Iteration 40, loss = 3.42842
I0403 05:01:08.354724 31448 solver.cpp:244]     Train net output #0: loss = 3.42842 (* 1 = 3.42842 loss)
I0403 05:01:08.576345 31448 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 05:01:12.047473 31448 solver.cpp:228] Iteration 45, loss = 3.19947
I0403 05:01:12.047552 31448 solver.cpp:244]     Train net output #0: loss = 3.19947 (* 1 = 3.19947 loss)
I0403 05:01:12.212357 31448 sgd_solver.cpp:106] Iteration 45, lr = 0.005
I0403 05:01:15.679831 31448 solver.cpp:228] Iteration 50, loss = 3.17078
I0403 05:01:15.679935 31448 solver.cpp:244]     Train net output #0: loss = 3.17078 (* 1 = 3.17078 loss)
I0403 05:01:15.857377 31448 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 05:01:19.344066 31448 solver.cpp:228] Iteration 55, loss = 2.95072
I0403 05:01:19.345012 31448 solver.cpp:244]     Train net output #0: loss = 2.95072 (* 1 = 2.95072 loss)
I0403 05:01:19.534998 31448 sgd_solver.cpp:106] Iteration 55, lr = 0.005
I0403 05:01:22.934751 31448 solver.cpp:228] Iteration 60, loss = 3.10959
I0403 05:01:22.934864 31448 solver.cpp:244]     Train net output #0: loss = 3.10959 (* 1 = 3.10959 loss)
I0403 05:01:23.171737 31448 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 05:01:26.613106 31448 solver.cpp:228] Iteration 65, loss = 3.14071
I0403 05:01:26.613204 31448 solver.cpp:244]     Train net output #0: loss = 3.14071 (* 1 = 3.14071 loss)
I0403 05:01:26.780009 31448 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 05:01:30.286478 31448 solver.cpp:228] Iteration 70, loss = 3.1425
I0403 05:01:30.286587 31448 solver.cpp:244]     Train net output #0: loss = 3.1425 (* 1 = 3.1425 loss)
I0403 05:01:30.494361 31448 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 05:01:33.942942 31448 solver.cpp:228] Iteration 75, loss = 2.94132
I0403 05:01:33.943045 31448 solver.cpp:244]     Train net output #0: loss = 2.94132 (* 1 = 2.94132 loss)
I0403 05:01:34.135218 31448 sgd_solver.cpp:106] Iteration 75, lr = 0.005
I0403 05:01:37.572027 31448 solver.cpp:228] Iteration 80, loss = 2.69808
I0403 05:01:37.572126 31448 solver.cpp:244]     Train net output #0: loss = 2.69808 (* 1 = 2.69808 loss)
I0403 05:01:37.750921 31448 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 05:01:41.237211 31448 solver.cpp:228] Iteration 85, loss = 2.86907
I0403 05:01:41.237547 31448 solver.cpp:244]     Train net output #0: loss = 2.86907 (* 1 = 2.86907 loss)
I0403 05:01:41.378803 31448 sgd_solver.cpp:106] Iteration 85, lr = 0.005
I0403 05:01:45.033233 31448 solver.cpp:228] Iteration 90, loss = 2.9255
I0403 05:01:45.033335 31448 solver.cpp:244]     Train net output #0: loss = 2.9255 (* 1 = 2.9255 loss)
I0403 05:01:45.192466 31448 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 05:01:48.808533 31448 solver.cpp:228] Iteration 95, loss = 2.60081
I0403 05:01:48.808641 31448 solver.cpp:244]     Train net output #0: loss = 2.60081 (* 1 = 2.60081 loss)
I0403 05:01:48.991905 31448 sgd_solver.cpp:106] Iteration 95, lr = 0.005
I0403 05:01:52.526082 31448 solver.cpp:228] Iteration 100, loss = 2.84275
I0403 05:01:52.526181 31448 solver.cpp:244]     Train net output #0: loss = 2.84275 (* 1 = 2.84275 loss)
I0403 05:01:52.693912 31448 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 05:01:55.812124 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_105.caffemodel
I0403 05:01:58.692975 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_105.solverstate
I0403 05:02:00.579233 31448 solver.cpp:337] Iteration 105, Testing net (#0)
I0403 05:03:40.618646 31448 solver.cpp:404]     Test net output #0: accuracy = 0.265881
I0403 05:03:40.618960 31448 solver.cpp:404]     Test net output #1: loss = 2.69884 (* 1 = 2.69884 loss)
I0403 05:03:41.145952 31448 solver.cpp:228] Iteration 105, loss = 2.56764
I0403 05:03:41.146046 31448 solver.cpp:244]     Train net output #0: loss = 2.56764 (* 1 = 2.56764 loss)
I0403 05:03:41.299393 31448 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 05:03:44.804540 31448 solver.cpp:228] Iteration 110, loss = 2.6079
I0403 05:03:44.804648 31448 solver.cpp:244]     Train net output #0: loss = 2.6079 (* 1 = 2.6079 loss)
I0403 05:03:44.990970 31448 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 05:03:48.442109 31448 solver.cpp:228] Iteration 115, loss = 2.82873
I0403 05:03:48.442217 31448 solver.cpp:244]     Train net output #0: loss = 2.82873 (* 1 = 2.82873 loss)
I0403 05:03:48.642629 31448 sgd_solver.cpp:106] Iteration 115, lr = 0.005
I0403 05:03:52.075484 31448 solver.cpp:228] Iteration 120, loss = 2.33534
I0403 05:03:52.075595 31448 solver.cpp:244]     Train net output #0: loss = 2.33534 (* 1 = 2.33534 loss)
I0403 05:03:52.281328 31448 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 05:03:55.703234 31448 solver.cpp:228] Iteration 125, loss = 2.46248
I0403 05:03:55.703337 31448 solver.cpp:244]     Train net output #0: loss = 2.46248 (* 1 = 2.46248 loss)
I0403 05:03:55.881582 31448 sgd_solver.cpp:106] Iteration 125, lr = 0.005
I0403 05:03:59.395372 31448 solver.cpp:228] Iteration 130, loss = 2.48402
I0403 05:03:59.395478 31448 solver.cpp:244]     Train net output #0: loss = 2.48402 (* 1 = 2.48402 loss)
I0403 05:03:59.596197 31448 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 05:04:03.082200 31448 solver.cpp:228] Iteration 135, loss = 2.51401
I0403 05:04:03.082304 31448 solver.cpp:244]     Train net output #0: loss = 2.51401 (* 1 = 2.51401 loss)
I0403 05:04:03.262483 31448 sgd_solver.cpp:106] Iteration 135, lr = 0.005
I0403 05:04:06.686390 31448 solver.cpp:228] Iteration 140, loss = 2.17859
I0403 05:04:06.686501 31448 solver.cpp:244]     Train net output #0: loss = 2.17859 (* 1 = 2.17859 loss)
I0403 05:04:06.865226 31448 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 05:04:10.354722 31448 solver.cpp:228] Iteration 145, loss = 3.69667
I0403 05:04:10.354820 31448 solver.cpp:244]     Train net output #0: loss = 3.69667 (* 1 = 3.69667 loss)
I0403 05:04:10.507792 31448 sgd_solver.cpp:106] Iteration 145, lr = 0.005
I0403 05:04:14.045912 31448 solver.cpp:228] Iteration 150, loss = 3.08878
I0403 05:04:14.046231 31448 solver.cpp:244]     Train net output #0: loss = 3.08878 (* 1 = 3.08878 loss)
I0403 05:04:14.211275 31448 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 05:04:17.705545 31448 solver.cpp:228] Iteration 155, loss = 2.70321
I0403 05:04:17.705642 31448 solver.cpp:244]     Train net output #0: loss = 2.70321 (* 1 = 2.70321 loss)
I0403 05:04:17.884894 31448 sgd_solver.cpp:106] Iteration 155, lr = 0.005
I0403 05:04:21.353730 31448 solver.cpp:228] Iteration 160, loss = 2.46516
I0403 05:04:21.353827 31448 solver.cpp:244]     Train net output #0: loss = 2.46516 (* 1 = 2.46516 loss)
I0403 05:04:21.514917 31448 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 05:04:25.031750 31448 solver.cpp:228] Iteration 165, loss = 2.22922
I0403 05:04:25.031860 31448 solver.cpp:244]     Train net output #0: loss = 2.22922 (* 1 = 2.22922 loss)
I0403 05:04:25.260675 31448 sgd_solver.cpp:106] Iteration 165, lr = 0.005
I0403 05:04:28.813153 31448 solver.cpp:228] Iteration 170, loss = 2.36811
I0403 05:04:28.813253 31448 solver.cpp:244]     Train net output #0: loss = 2.36811 (* 1 = 2.36811 loss)
I0403 05:04:28.986377 31448 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 05:04:32.456887 31448 solver.cpp:228] Iteration 175, loss = 2.01545
I0403 05:04:32.456995 31448 solver.cpp:244]     Train net output #0: loss = 2.01545 (* 1 = 2.01545 loss)
I0403 05:04:32.658607 31448 sgd_solver.cpp:106] Iteration 175, lr = 0.005
I0403 05:04:36.182814 31448 solver.cpp:228] Iteration 180, loss = 2.1225
I0403 05:04:36.182912 31448 solver.cpp:244]     Train net output #0: loss = 2.1225 (* 1 = 2.1225 loss)
I0403 05:04:36.330932 31448 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 05:04:39.951428 31448 solver.cpp:228] Iteration 185, loss = 2.29932
I0403 05:04:39.951530 31448 solver.cpp:244]     Train net output #0: loss = 2.29932 (* 1 = 2.29932 loss)
I0403 05:04:40.115679 31448 sgd_solver.cpp:106] Iteration 185, lr = 0.005
I0403 05:04:43.618633 31448 solver.cpp:228] Iteration 190, loss = 2.14587
I0403 05:04:43.618741 31448 solver.cpp:244]     Train net output #0: loss = 2.14587 (* 1 = 2.14587 loss)
I0403 05:04:43.847430 31448 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 05:04:47.371340 31448 solver.cpp:228] Iteration 195, loss = 2.40984
I0403 05:04:47.371654 31448 solver.cpp:244]     Train net output #0: loss = 2.40984 (* 1 = 2.40984 loss)
I0403 05:04:47.598033 31448 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 05:04:51.177960 31448 solver.cpp:228] Iteration 200, loss = 1.99673
I0403 05:04:51.178058 31448 solver.cpp:244]     Train net output #0: loss = 1.99673 (* 1 = 1.99673 loss)
I0403 05:04:51.341372 31448 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 05:04:54.914775 31448 solver.cpp:228] Iteration 205, loss = 2.1804
I0403 05:04:54.915630 31448 solver.cpp:244]     Train net output #0: loss = 2.1804 (* 1 = 2.1804 loss)
I0403 05:04:55.093432 31448 sgd_solver.cpp:106] Iteration 205, lr = 0.005
I0403 05:04:58.001469 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_210.caffemodel
I0403 05:05:00.741642 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_210.solverstate
I0403 05:05:02.629016 31448 solver.cpp:337] Iteration 210, Testing net (#0)
I0403 05:06:42.678791 31448 solver.cpp:404]     Test net output #0: accuracy = 0.436201
I0403 05:06:42.679098 31448 solver.cpp:404]     Test net output #1: loss = 2.00672 (* 1 = 2.00672 loss)
I0403 05:06:43.193018 31448 solver.cpp:228] Iteration 210, loss = 2.04615
I0403 05:06:43.193114 31448 solver.cpp:244]     Train net output #0: loss = 2.04615 (* 1 = 2.04615 loss)
I0403 05:06:43.370087 31448 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 05:06:46.835686 31448 solver.cpp:228] Iteration 215, loss = 2.11727
I0403 05:06:46.835795 31448 solver.cpp:244]     Train net output #0: loss = 2.11727 (* 1 = 2.11727 loss)
I0403 05:06:47.054538 31448 sgd_solver.cpp:106] Iteration 215, lr = 0.005
I0403 05:06:50.491477 31448 solver.cpp:228] Iteration 220, loss = 2.09875
I0403 05:06:50.491575 31448 solver.cpp:244]     Train net output #0: loss = 2.09875 (* 1 = 2.09875 loss)
I0403 05:06:50.668689 31448 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 05:06:54.127746 31448 solver.cpp:228] Iteration 225, loss = 1.84345
I0403 05:06:54.127840 31448 solver.cpp:244]     Train net output #0: loss = 1.84345 (* 1 = 1.84345 loss)
I0403 05:06:54.302287 31448 sgd_solver.cpp:106] Iteration 225, lr = 0.005
I0403 05:06:57.757556 31448 solver.cpp:228] Iteration 230, loss = 1.84522
I0403 05:06:57.757648 31448 solver.cpp:244]     Train net output #0: loss = 1.84522 (* 1 = 1.84522 loss)
I0403 05:06:57.936585 31448 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 05:07:01.403398 31448 solver.cpp:228] Iteration 235, loss = 1.84531
I0403 05:07:01.403506 31448 solver.cpp:244]     Train net output #0: loss = 1.84531 (* 1 = 1.84531 loss)
I0403 05:07:01.597352 31448 sgd_solver.cpp:106] Iteration 235, lr = 0.005
I0403 05:07:05.106503 31448 solver.cpp:228] Iteration 240, loss = 1.92403
I0403 05:07:05.106600 31448 solver.cpp:244]     Train net output #0: loss = 1.92403 (* 1 = 1.92403 loss)
I0403 05:07:05.271517 31448 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 05:07:08.986151 31448 solver.cpp:228] Iteration 245, loss = 1.78385
I0403 05:07:08.986254 31448 solver.cpp:244]     Train net output #0: loss = 1.78385 (* 1 = 1.78385 loss)
I0403 05:07:09.134035 31448 sgd_solver.cpp:106] Iteration 245, lr = 0.005
I0403 05:07:12.681001 31448 solver.cpp:228] Iteration 250, loss = 1.82896
I0403 05:07:12.681277 31448 solver.cpp:244]     Train net output #0: loss = 1.82896 (* 1 = 1.82896 loss)
I0403 05:07:12.881741 31448 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 05:07:16.348422 31448 solver.cpp:228] Iteration 255, loss = 1.6785
I0403 05:07:16.348529 31448 solver.cpp:244]     Train net output #0: loss = 1.6785 (* 1 = 1.6785 loss)
I0403 05:07:16.532073 31448 sgd_solver.cpp:106] Iteration 255, lr = 0.005
I0403 05:07:19.970930 31448 solver.cpp:228] Iteration 260, loss = 1.76601
I0403 05:07:19.971040 31448 solver.cpp:244]     Train net output #0: loss = 1.76601 (* 1 = 1.76601 loss)
I0403 05:07:20.177592 31448 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 05:07:23.626240 31448 solver.cpp:228] Iteration 265, loss = 1.59475
I0403 05:07:23.626338 31448 solver.cpp:244]     Train net output #0: loss = 1.59475 (* 1 = 1.59475 loss)
I0403 05:07:23.803932 31448 sgd_solver.cpp:106] Iteration 265, lr = 0.005
I0403 05:07:27.332409 31448 solver.cpp:228] Iteration 270, loss = 1.71207
I0403 05:07:27.332517 31448 solver.cpp:244]     Train net output #0: loss = 1.71207 (* 1 = 1.71207 loss)
I0403 05:07:27.525065 31448 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 05:07:31.089458 31448 solver.cpp:228] Iteration 275, loss = 1.62853
I0403 05:07:31.089570 31448 solver.cpp:244]     Train net output #0: loss = 1.62853 (* 1 = 1.62853 loss)
I0403 05:07:31.272740 31448 sgd_solver.cpp:106] Iteration 275, lr = 0.005
I0403 05:07:34.732327 31448 solver.cpp:228] Iteration 280, loss = 1.65676
I0403 05:07:34.732435 31448 solver.cpp:244]     Train net output #0: loss = 1.65676 (* 1 = 1.65676 loss)
I0403 05:07:34.916879 31448 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 05:07:38.392251 31448 solver.cpp:228] Iteration 285, loss = 1.48065
I0403 05:07:38.392352 31448 solver.cpp:244]     Train net output #0: loss = 1.48065 (* 1 = 1.48065 loss)
I0403 05:07:38.563457 31448 sgd_solver.cpp:106] Iteration 285, lr = 0.005
I0403 05:07:42.086223 31448 solver.cpp:228] Iteration 290, loss = 1.83295
I0403 05:07:42.086328 31448 solver.cpp:244]     Train net output #0: loss = 1.83295 (* 1 = 1.83295 loss)
I0403 05:07:42.265059 31448 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 05:07:45.709964 31448 solver.cpp:228] Iteration 295, loss = 1.50815
I0403 05:07:45.710299 31448 solver.cpp:244]     Train net output #0: loss = 1.50815 (* 1 = 1.50815 loss)
I0403 05:07:45.895551 31448 sgd_solver.cpp:106] Iteration 295, lr = 0.005
I0403 05:07:49.342207 31448 solver.cpp:228] Iteration 300, loss = 1.88876
I0403 05:07:49.342319 31448 solver.cpp:244]     Train net output #0: loss = 1.88876 (* 1 = 1.88876 loss)
I0403 05:07:49.525776 31448 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 05:07:52.957059 31448 solver.cpp:228] Iteration 305, loss = 1.75821
I0403 05:07:52.957170 31448 solver.cpp:244]     Train net output #0: loss = 1.75821 (* 1 = 1.75821 loss)
I0403 05:07:53.148753 31448 sgd_solver.cpp:106] Iteration 305, lr = 0.005
I0403 05:07:56.567564 31448 solver.cpp:228] Iteration 310, loss = 1.49998
I0403 05:07:56.567673 31448 solver.cpp:244]     Train net output #0: loss = 1.49998 (* 1 = 1.49998 loss)
I0403 05:07:56.807034 31448 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 05:07:59.708515 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_315.caffemodel
I0403 05:08:02.426054 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_315.solverstate
I0403 05:08:04.321213 31448 solver.cpp:337] Iteration 315, Testing net (#0)
I0403 05:09:44.349269 31448 solver.cpp:404]     Test net output #0: accuracy = 0.543204
I0403 05:09:44.349587 31448 solver.cpp:404]     Test net output #1: loss = 1.5864 (* 1 = 1.5864 loss)
I0403 05:09:44.869472 31448 solver.cpp:228] Iteration 315, loss = 1.64585
I0403 05:09:44.869565 31448 solver.cpp:244]     Train net output #0: loss = 1.64585 (* 1 = 1.64585 loss)
I0403 05:09:45.042525 31448 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 05:09:48.465407 31448 solver.cpp:228] Iteration 320, loss = 1.56619
I0403 05:09:48.465507 31448 solver.cpp:244]     Train net output #0: loss = 1.56619 (* 1 = 1.56619 loss)
I0403 05:09:48.640705 31448 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 05:09:52.122787 31448 solver.cpp:228] Iteration 325, loss = 1.52898
I0403 05:09:52.122889 31448 solver.cpp:244]     Train net output #0: loss = 1.52898 (* 1 = 1.52898 loss)
I0403 05:09:52.291326 31448 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 05:09:55.849900 31448 solver.cpp:228] Iteration 330, loss = 1.46393
I0403 05:09:55.850006 31448 solver.cpp:244]     Train net output #0: loss = 1.46393 (* 1 = 1.46393 loss)
I0403 05:09:56.035140 31448 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 05:09:59.461119 31448 solver.cpp:228] Iteration 335, loss = 1.47875
I0403 05:09:59.461230 31448 solver.cpp:244]     Train net output #0: loss = 1.47875 (* 1 = 1.47875 loss)
I0403 05:09:59.678114 31448 sgd_solver.cpp:106] Iteration 335, lr = 0.005
I0403 05:10:03.110210 31448 solver.cpp:228] Iteration 340, loss = 1.09453
I0403 05:10:03.111212 31448 solver.cpp:244]     Train net output #0: loss = 1.09453 (* 1 = 1.09453 loss)
I0403 05:10:03.293720 31448 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 05:10:06.770025 31448 solver.cpp:228] Iteration 345, loss = 1.34897
I0403 05:10:06.770123 31448 solver.cpp:244]     Train net output #0: loss = 1.34897 (* 1 = 1.34897 loss)
I0403 05:10:06.935111 31448 sgd_solver.cpp:106] Iteration 345, lr = 0.005
I0403 05:10:10.479568 31448 solver.cpp:228] Iteration 350, loss = 1.28125
I0403 05:10:10.479665 31448 solver.cpp:244]     Train net output #0: loss = 1.28125 (* 1 = 1.28125 loss)
I0403 05:10:10.650637 31448 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 05:10:14.132644 31448 solver.cpp:228] Iteration 355, loss = 1.19641
I0403 05:10:14.132745 31448 solver.cpp:244]     Train net output #0: loss = 1.19641 (* 1 = 1.19641 loss)
I0403 05:10:14.313840 31448 sgd_solver.cpp:106] Iteration 355, lr = 0.005
I0403 05:10:17.752630 31448 solver.cpp:228] Iteration 360, loss = 1.27614
I0403 05:10:17.752954 31448 solver.cpp:244]     Train net output #0: loss = 1.27614 (* 1 = 1.27614 loss)
I0403 05:10:17.942824 31448 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 05:10:21.384541 31448 solver.cpp:228] Iteration 365, loss = 1.03414
I0403 05:10:21.384649 31448 solver.cpp:244]     Train net output #0: loss = 1.03414 (* 1 = 1.03414 loss)
I0403 05:10:21.582200 31448 sgd_solver.cpp:106] Iteration 365, lr = 0.005
I0403 05:10:24.997079 31448 solver.cpp:228] Iteration 370, loss = 1.44689
I0403 05:10:24.997187 31448 solver.cpp:244]     Train net output #0: loss = 1.44689 (* 1 = 1.44689 loss)
I0403 05:10:25.201751 31448 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 05:10:28.694629 31448 solver.cpp:228] Iteration 375, loss = 1.44393
I0403 05:10:28.694730 31448 solver.cpp:244]     Train net output #0: loss = 1.44393 (* 1 = 1.44393 loss)
I0403 05:10:28.865183 31448 sgd_solver.cpp:106] Iteration 375, lr = 0.005
I0403 05:10:32.417999 31448 solver.cpp:228] Iteration 380, loss = 1.60235
I0403 05:10:32.418107 31448 solver.cpp:244]     Train net output #0: loss = 1.60235 (* 1 = 1.60235 loss)
I0403 05:10:32.636235 31448 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 05:10:36.088340 31448 solver.cpp:228] Iteration 385, loss = 1.20862
I0403 05:10:36.088452 31448 solver.cpp:244]     Train net output #0: loss = 1.20862 (* 1 = 1.20862 loss)
I0403 05:10:36.311942 31448 sgd_solver.cpp:106] Iteration 385, lr = 0.005
I0403 05:10:39.726140 31448 solver.cpp:228] Iteration 390, loss = 1.03565
I0403 05:10:39.726233 31448 solver.cpp:244]     Train net output #0: loss = 1.03565 (* 1 = 1.03565 loss)
I0403 05:10:39.901516 31448 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 05:10:43.454824 31448 solver.cpp:228] Iteration 395, loss = 1.4099
I0403 05:10:43.454929 31448 solver.cpp:244]     Train net output #0: loss = 1.4099 (* 1 = 1.4099 loss)
I0403 05:10:43.614056 31448 sgd_solver.cpp:106] Iteration 395, lr = 0.005
I0403 05:10:47.272945 31448 solver.cpp:228] Iteration 400, loss = 1.41641
I0403 05:10:47.273043 31448 solver.cpp:244]     Train net output #0: loss = 1.41641 (* 1 = 1.41641 loss)
I0403 05:10:47.452231 31448 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 05:10:50.951527 31448 solver.cpp:228] Iteration 405, loss = 0.976329
I0403 05:10:50.951844 31448 solver.cpp:244]     Train net output #0: loss = 0.976329 (* 1 = 0.976329 loss)
I0403 05:10:51.140161 31448 sgd_solver.cpp:106] Iteration 405, lr = 0.005
I0403 05:10:54.577388 31448 solver.cpp:228] Iteration 410, loss = 1.3027
I0403 05:10:54.577500 31448 solver.cpp:244]     Train net output #0: loss = 1.3027 (* 1 = 1.3027 loss)
I0403 05:10:54.751539 31448 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 05:10:58.205351 31448 solver.cpp:228] Iteration 415, loss = 1.10787
I0403 05:10:58.205448 31448 solver.cpp:244]     Train net output #0: loss = 1.10787 (* 1 = 1.10787 loss)
I0403 05:10:58.357717 31448 sgd_solver.cpp:106] Iteration 415, lr = 0.005
I0403 05:11:01.256805 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_420.caffemodel
I0403 05:11:04.054829 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_420.solverstate
I0403 05:11:05.942459 31448 solver.cpp:337] Iteration 420, Testing net (#0)
I0403 05:12:45.949394 31448 solver.cpp:404]     Test net output #0: accuracy = 0.655858
I0403 05:12:45.949743 31448 solver.cpp:404]     Test net output #1: loss = 1.14863 (* 1 = 1.14863 loss)
I0403 05:12:46.465785 31448 solver.cpp:228] Iteration 420, loss = 0.952969
I0403 05:12:46.465885 31448 solver.cpp:244]     Train net output #0: loss = 0.952969 (* 1 = 0.952969 loss)
I0403 05:12:46.653578 31448 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 05:12:50.088887 31448 solver.cpp:228] Iteration 425, loss = 1.13821
I0403 05:12:50.088997 31448 solver.cpp:244]     Train net output #0: loss = 1.13821 (* 1 = 1.13821 loss)
I0403 05:12:50.301494 31448 sgd_solver.cpp:106] Iteration 425, lr = 0.005
I0403 05:12:53.758309 31448 solver.cpp:228] Iteration 430, loss = 1.06918
I0403 05:12:53.758420 31448 solver.cpp:244]     Train net output #0: loss = 1.06918 (* 1 = 1.06918 loss)
I0403 05:12:53.946563 31448 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 05:12:57.410894 31448 solver.cpp:228] Iteration 435, loss = 1.37004
I0403 05:12:57.410994 31448 solver.cpp:244]     Train net output #0: loss = 1.37004 (* 1 = 1.37004 loss)
I0403 05:12:57.591668 31448 sgd_solver.cpp:106] Iteration 435, lr = 0.005
I0403 05:13:01.001199 31448 solver.cpp:228] Iteration 440, loss = 1.26715
I0403 05:13:01.001304 31448 solver.cpp:244]     Train net output #0: loss = 1.26715 (* 1 = 1.26715 loss)
I0403 05:13:01.165493 31448 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 05:13:04.658293 31448 solver.cpp:228] Iteration 445, loss = 1.01561
I0403 05:13:04.658392 31448 solver.cpp:244]     Train net output #0: loss = 1.01561 (* 1 = 1.01561 loss)
I0403 05:13:04.836390 31448 sgd_solver.cpp:106] Iteration 445, lr = 0.005
I0403 05:13:08.277858 31448 solver.cpp:228] Iteration 450, loss = 1.10236
I0403 05:13:08.277967 31448 solver.cpp:244]     Train net output #0: loss = 1.10236 (* 1 = 1.10236 loss)
I0403 05:13:08.510926 31448 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 05:13:11.936255 31448 solver.cpp:228] Iteration 455, loss = 0.872478
I0403 05:13:11.936369 31448 solver.cpp:244]     Train net output #0: loss = 0.872478 (* 1 = 0.872478 loss)
I0403 05:13:12.143476 31448 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 05:13:15.617223 31448 solver.cpp:228] Iteration 460, loss = 1.37523
I0403 05:13:15.617323 31448 solver.cpp:244]     Train net output #0: loss = 1.37523 (* 1 = 1.37523 loss)
I0403 05:13:15.793427 31448 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 05:13:19.242697 31448 solver.cpp:228] Iteration 465, loss = 0.886232
I0403 05:13:19.242990 31448 solver.cpp:244]     Train net output #0: loss = 0.886232 (* 1 = 0.886232 loss)
I0403 05:13:19.421774 31448 sgd_solver.cpp:106] Iteration 465, lr = 0.005
I0403 05:13:22.954972 31448 solver.cpp:228] Iteration 470, loss = 0.992709
I0403 05:13:22.955070 31448 solver.cpp:244]     Train net output #0: loss = 0.992709 (* 1 = 0.992709 loss)
I0403 05:13:23.133080 31448 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 05:13:26.611788 31448 solver.cpp:228] Iteration 475, loss = 1.02487
I0403 05:13:26.611898 31448 solver.cpp:244]     Train net output #0: loss = 1.02487 (* 1 = 1.02487 loss)
I0403 05:13:26.801638 31448 sgd_solver.cpp:106] Iteration 475, lr = 0.005
I0403 05:13:30.318275 31448 solver.cpp:228] Iteration 480, loss = 1.16051
I0403 05:13:30.318372 31448 solver.cpp:244]     Train net output #0: loss = 1.16051 (* 1 = 1.16051 loss)
I0403 05:13:30.496500 31448 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 05:13:33.995401 31448 solver.cpp:228] Iteration 485, loss = 1.05863
I0403 05:13:33.995508 31448 solver.cpp:244]     Train net output #0: loss = 1.05863 (* 1 = 1.05863 loss)
I0403 05:13:34.184288 31448 sgd_solver.cpp:106] Iteration 485, lr = 0.005
I0403 05:13:37.695442 31448 solver.cpp:228] Iteration 490, loss = 0.791076
I0403 05:13:37.695540 31448 solver.cpp:244]     Train net output #0: loss = 0.791076 (* 1 = 0.791076 loss)
I0403 05:13:37.874280 31448 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 05:13:41.342782 31448 solver.cpp:228] Iteration 495, loss = 0.971346
I0403 05:13:41.342876 31448 solver.cpp:244]     Train net output #0: loss = 0.971346 (* 1 = 0.971346 loss)
I0403 05:13:41.504559 31448 sgd_solver.cpp:106] Iteration 495, lr = 0.005
I0403 05:13:45.064383 31448 solver.cpp:228] Iteration 500, loss = 0.804427
I0403 05:13:45.064491 31448 solver.cpp:244]     Train net output #0: loss = 0.804427 (* 1 = 0.804427 loss)
I0403 05:13:45.280345 31448 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 05:13:48.724484 31448 solver.cpp:228] Iteration 505, loss = 0.940637
I0403 05:13:48.724597 31448 solver.cpp:244]     Train net output #0: loss = 0.940637 (* 1 = 0.940637 loss)
I0403 05:13:48.960600 31448 sgd_solver.cpp:106] Iteration 505, lr = 0.005
I0403 05:13:52.373723 31448 solver.cpp:228] Iteration 510, loss = 1.02709
I0403 05:13:52.374060 31448 solver.cpp:244]     Train net output #0: loss = 1.02709 (* 1 = 1.02709 loss)
I0403 05:13:52.560281 31448 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 05:13:56.038874 31448 solver.cpp:228] Iteration 515, loss = 0.946224
I0403 05:13:56.038983 31448 solver.cpp:244]     Train net output #0: loss = 0.946224 (* 1 = 0.946224 loss)
I0403 05:13:56.286622 31448 sgd_solver.cpp:106] Iteration 515, lr = 0.005
I0403 05:13:59.753384 31448 solver.cpp:228] Iteration 520, loss = 1.07435
I0403 05:13:59.753482 31448 solver.cpp:244]     Train net output #0: loss = 1.07435 (* 1 = 1.07435 loss)
I0403 05:13:59.923173 31448 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 05:14:02.887431 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_525.caffemodel
I0403 05:14:05.648049 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_525.solverstate
I0403 05:14:07.529443 31448 solver.cpp:337] Iteration 525, Testing net (#0)
I0403 05:15:47.535989 31448 solver.cpp:404]     Test net output #0: accuracy = 0.663135
I0403 05:15:47.536303 31448 solver.cpp:404]     Test net output #1: loss = 1.10818 (* 1 = 1.10818 loss)
I0403 05:15:48.057955 31448 solver.cpp:228] Iteration 525, loss = 1.00007
I0403 05:15:48.058051 31448 solver.cpp:244]     Train net output #0: loss = 1.00007 (* 1 = 1.00007 loss)
I0403 05:15:48.234706 31448 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 05:15:51.777379 31448 solver.cpp:228] Iteration 530, loss = 1.00589
I0403 05:15:51.777484 31448 solver.cpp:244]     Train net output #0: loss = 1.00589 (* 1 = 1.00589 loss)
I0403 05:15:51.966918 31448 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 05:15:55.440356 31448 solver.cpp:228] Iteration 535, loss = 0.815822
I0403 05:15:55.440454 31448 solver.cpp:244]     Train net output #0: loss = 0.815822 (* 1 = 0.815822 loss)
I0403 05:15:55.623425 31448 sgd_solver.cpp:106] Iteration 535, lr = 0.005
I0403 05:15:59.043228 31448 solver.cpp:228] Iteration 540, loss = 1.13921
I0403 05:15:59.043332 31448 solver.cpp:244]     Train net output #0: loss = 1.13921 (* 1 = 1.13921 loss)
I0403 05:15:59.216009 31448 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 05:16:02.719177 31448 solver.cpp:228] Iteration 545, loss = 0.799537
I0403 05:16:02.719288 31448 solver.cpp:244]     Train net output #0: loss = 0.799537 (* 1 = 0.799537 loss)
I0403 05:16:02.916930 31448 sgd_solver.cpp:106] Iteration 545, lr = 0.005
I0403 05:16:06.397323 31448 solver.cpp:228] Iteration 550, loss = 0.774984
I0403 05:16:06.397426 31448 solver.cpp:244]     Train net output #0: loss = 0.774984 (* 1 = 0.774984 loss)
I0403 05:16:06.587491 31448 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 05:16:10.218719 31448 solver.cpp:228] Iteration 555, loss = 1.02445
I0403 05:16:10.219535 31448 solver.cpp:244]     Train net output #0: loss = 1.02445 (* 1 = 1.02445 loss)
I0403 05:16:10.334870 31448 sgd_solver.cpp:106] Iteration 555, lr = 0.005
I0403 05:16:13.952796 31448 solver.cpp:228] Iteration 560, loss = 1.00083
I0403 05:16:13.952893 31448 solver.cpp:244]     Train net output #0: loss = 1.00083 (* 1 = 1.00083 loss)
I0403 05:16:14.131310 31448 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 05:16:17.667557 31448 solver.cpp:228] Iteration 565, loss = 0.986781
I0403 05:16:17.667882 31448 solver.cpp:244]     Train net output #0: loss = 0.986781 (* 1 = 0.986781 loss)
I0403 05:16:17.831166 31448 sgd_solver.cpp:106] Iteration 565, lr = 0.005
I0403 05:16:21.319239 31448 solver.cpp:228] Iteration 570, loss = 0.743761
I0403 05:16:21.319353 31448 solver.cpp:244]     Train net output #0: loss = 0.743761 (* 1 = 0.743761 loss)
I0403 05:16:21.529463 31448 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 05:16:24.986516 31448 solver.cpp:228] Iteration 575, loss = 0.739488
I0403 05:16:24.986616 31448 solver.cpp:244]     Train net output #0: loss = 0.739488 (* 1 = 0.739488 loss)
I0403 05:16:25.141439 31448 sgd_solver.cpp:106] Iteration 575, lr = 0.005
I0403 05:16:28.615830 31448 solver.cpp:228] Iteration 580, loss = 0.720435
I0403 05:16:28.615939 31448 solver.cpp:244]     Train net output #0: loss = 0.720435 (* 1 = 0.720435 loss)
I0403 05:16:28.800456 31448 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 05:16:32.286109 31448 solver.cpp:228] Iteration 585, loss = 0.848413
I0403 05:16:32.286206 31448 solver.cpp:244]     Train net output #0: loss = 0.848413 (* 1 = 0.848413 loss)
I0403 05:16:32.445904 31448 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 05:16:35.975400 31448 solver.cpp:228] Iteration 590, loss = 0.987968
I0403 05:16:35.975512 31448 solver.cpp:244]     Train net output #0: loss = 0.987968 (* 1 = 0.987968 loss)
I0403 05:16:36.158752 31448 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 05:16:39.594871 31448 solver.cpp:228] Iteration 595, loss = 0.942578
I0403 05:16:39.594977 31448 solver.cpp:244]     Train net output #0: loss = 0.942578 (* 1 = 0.942578 loss)
I0403 05:16:39.780782 31448 sgd_solver.cpp:106] Iteration 595, lr = 0.005
I0403 05:16:43.309629 31448 solver.cpp:228] Iteration 600, loss = 0.856591
I0403 05:16:43.309736 31448 solver.cpp:244]     Train net output #0: loss = 0.856591 (* 1 = 0.856591 loss)
I0403 05:16:43.498857 31448 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 05:16:46.948860 31448 solver.cpp:228] Iteration 605, loss = 0.748731
I0403 05:16:46.948961 31448 solver.cpp:244]     Train net output #0: loss = 0.748731 (* 1 = 0.748731 loss)
I0403 05:16:47.117518 31448 sgd_solver.cpp:106] Iteration 605, lr = 0.005
I0403 05:16:50.666167 31448 solver.cpp:228] Iteration 610, loss = 0.840542
I0403 05:16:50.666514 31448 solver.cpp:244]     Train net output #0: loss = 0.840542 (* 1 = 0.840542 loss)
I0403 05:16:50.855655 31448 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 05:16:54.291761 31448 solver.cpp:228] Iteration 615, loss = 0.729034
I0403 05:16:54.291864 31448 solver.cpp:244]     Train net output #0: loss = 0.729034 (* 1 = 0.729034 loss)
I0403 05:16:54.471667 31448 sgd_solver.cpp:106] Iteration 615, lr = 0.005
I0403 05:16:57.943121 31448 solver.cpp:228] Iteration 620, loss = 0.850052
I0403 05:16:57.943233 31448 solver.cpp:244]     Train net output #0: loss = 0.850052 (* 1 = 0.850052 loss)
I0403 05:16:58.131597 31448 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 05:17:01.582176 31448 solver.cpp:228] Iteration 625, loss = 0.733315
I0403 05:17:01.582283 31448 solver.cpp:244]     Train net output #0: loss = 0.733315 (* 1 = 0.733315 loss)
I0403 05:17:01.765388 31448 sgd_solver.cpp:106] Iteration 625, lr = 0.005
I0403 05:17:04.691884 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_630.caffemodel
I0403 05:17:07.430618 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_630.solverstate
I0403 05:17:09.333261 31448 solver.cpp:337] Iteration 630, Testing net (#0)
I0403 05:18:49.334209 31448 solver.cpp:404]     Test net output #0: accuracy = 0.716041
I0403 05:18:49.334600 31448 solver.cpp:404]     Test net output #1: loss = 0.921163 (* 1 = 0.921163 loss)
I0403 05:18:49.854558 31448 solver.cpp:228] Iteration 630, loss = 0.756228
I0403 05:18:49.854653 31448 solver.cpp:244]     Train net output #0: loss = 0.756228 (* 1 = 0.756228 loss)
I0403 05:18:50.017364 31448 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 05:18:53.775431 31448 solver.cpp:228] Iteration 635, loss = 0.72726
I0403 05:18:53.775529 31448 solver.cpp:244]     Train net output #0: loss = 0.72726 (* 1 = 0.72726 loss)
I0403 05:18:53.926368 31448 sgd_solver.cpp:106] Iteration 635, lr = 0.005
I0403 05:18:57.433153 31448 solver.cpp:228] Iteration 640, loss = 0.711009
I0403 05:18:57.433264 31448 solver.cpp:244]     Train net output #0: loss = 0.711009 (* 1 = 0.711009 loss)
I0403 05:18:57.651355 31448 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 05:19:01.221670 31448 solver.cpp:228] Iteration 645, loss = 0.701289
I0403 05:19:01.221778 31448 solver.cpp:244]     Train net output #0: loss = 0.701289 (* 1 = 0.701289 loss)
I0403 05:19:01.420704 31448 sgd_solver.cpp:106] Iteration 645, lr = 0.005
I0403 05:19:04.895308 31448 solver.cpp:228] Iteration 650, loss = 0.848482
I0403 05:19:04.895406 31448 solver.cpp:244]     Train net output #0: loss = 0.848482 (* 1 = 0.848482 loss)
I0403 05:19:05.074405 31448 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 05:19:08.570284 31448 solver.cpp:228] Iteration 655, loss = 0.537014
I0403 05:19:08.570399 31448 solver.cpp:244]     Train net output #0: loss = 0.537014 (* 1 = 0.537014 loss)
I0403 05:19:08.804944 31448 sgd_solver.cpp:106] Iteration 655, lr = 0.005
I0403 05:19:12.284195 31448 solver.cpp:228] Iteration 660, loss = 0.535404
I0403 05:19:12.284306 31448 solver.cpp:244]     Train net output #0: loss = 0.535404 (* 1 = 0.535404 loss)
I0403 05:19:12.451220 31448 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 05:19:15.917778 31448 solver.cpp:228] Iteration 665, loss = 0.630831
I0403 05:19:15.917876 31448 solver.cpp:244]     Train net output #0: loss = 0.630831 (* 1 = 0.630831 loss)
I0403 05:19:16.098747 31448 sgd_solver.cpp:106] Iteration 665, lr = 0.005
I0403 05:19:19.557843 31448 solver.cpp:228] Iteration 670, loss = 0.889716
I0403 05:19:19.558151 31448 solver.cpp:244]     Train net output #0: loss = 0.889716 (* 1 = 0.889716 loss)
I0403 05:19:19.752435 31448 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 05:19:23.184059 31448 solver.cpp:228] Iteration 675, loss = 0.809209
I0403 05:19:23.184171 31448 solver.cpp:244]     Train net output #0: loss = 0.809209 (* 1 = 0.809209 loss)
I0403 05:19:23.412153 31448 sgd_solver.cpp:106] Iteration 675, lr = 0.005
I0403 05:19:26.862937 31448 solver.cpp:228] Iteration 680, loss = 0.866209
I0403 05:19:26.863045 31448 solver.cpp:244]     Train net output #0: loss = 0.866209 (* 1 = 0.866209 loss)
I0403 05:19:27.046628 31448 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 05:19:30.517899 31448 solver.cpp:228] Iteration 685, loss = 0.789804
I0403 05:19:30.518007 31448 solver.cpp:244]     Train net output #0: loss = 0.789804 (* 1 = 0.789804 loss)
I0403 05:19:30.704701 31448 sgd_solver.cpp:106] Iteration 685, lr = 0.005
I0403 05:19:34.166396 31448 solver.cpp:228] Iteration 690, loss = 0.931785
I0403 05:19:34.166507 31448 solver.cpp:244]     Train net output #0: loss = 0.931785 (* 1 = 0.931785 loss)
I0403 05:19:34.351512 31448 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 05:19:37.992161 31448 solver.cpp:228] Iteration 695, loss = 0.637101
I0403 05:19:37.992275 31448 solver.cpp:244]     Train net output #0: loss = 0.637101 (* 1 = 0.637101 loss)
I0403 05:19:38.203480 31448 sgd_solver.cpp:106] Iteration 695, lr = 0.005
I0403 05:19:41.703701 31448 solver.cpp:228] Iteration 700, loss = 0.681338
I0403 05:19:41.703811 31448 solver.cpp:244]     Train net output #0: loss = 0.681338 (* 1 = 0.681338 loss)
I0403 05:19:41.890671 31448 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 05:19:45.382388 31448 solver.cpp:228] Iteration 705, loss = 0.828446
I0403 05:19:45.382486 31448 solver.cpp:244]     Train net output #0: loss = 0.828446 (* 1 = 0.828446 loss)
I0403 05:19:45.568845 31448 sgd_solver.cpp:106] Iteration 705, lr = 0.005
I0403 05:19:49.259152 31448 solver.cpp:228] Iteration 710, loss = 0.418992
I0403 05:19:49.259253 31448 solver.cpp:244]     Train net output #0: loss = 0.418992 (* 1 = 0.418992 loss)
I0403 05:19:49.418087 31448 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 05:19:52.874308 31448 solver.cpp:228] Iteration 715, loss = 0.609232
I0403 05:19:52.874630 31448 solver.cpp:244]     Train net output #0: loss = 0.609232 (* 1 = 0.609232 loss)
I0403 05:19:53.047205 31448 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 05:19:56.518453 31448 solver.cpp:228] Iteration 720, loss = 0.521901
I0403 05:19:56.518558 31448 solver.cpp:244]     Train net output #0: loss = 0.521901 (* 1 = 0.521901 loss)
I0403 05:19:56.702857 31448 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 05:20:00.117696 31448 solver.cpp:228] Iteration 725, loss = 0.62504
I0403 05:20:00.117796 31448 solver.cpp:244]     Train net output #0: loss = 0.62504 (* 1 = 0.62504 loss)
I0403 05:20:00.298404 31448 sgd_solver.cpp:106] Iteration 725, lr = 0.005
I0403 05:20:03.775043 31448 solver.cpp:228] Iteration 730, loss = 0.623771
I0403 05:20:03.775143 31448 solver.cpp:244]     Train net output #0: loss = 0.623771 (* 1 = 0.623771 loss)
I0403 05:20:03.958755 31448 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 05:20:06.841620 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_735.caffemodel
I0403 05:20:09.590638 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_735.solverstate
I0403 05:20:11.477036 31448 solver.cpp:337] Iteration 735, Testing net (#0)
I0403 05:21:51.487792 31448 solver.cpp:404]     Test net output #0: accuracy = 0.742929
I0403 05:21:51.488103 31448 solver.cpp:404]     Test net output #1: loss = 0.826672 (* 1 = 0.826672 loss)
I0403 05:21:52.022876 31448 solver.cpp:228] Iteration 735, loss = 0.677874
I0403 05:21:52.022974 31448 solver.cpp:244]     Train net output #0: loss = 0.677874 (* 1 = 0.677874 loss)
I0403 05:21:52.174330 31448 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 05:21:55.862994 31448 solver.cpp:228] Iteration 740, loss = 0.71984
I0403 05:21:55.863093 31448 solver.cpp:244]     Train net output #0: loss = 0.71984 (* 1 = 0.71984 loss)
I0403 05:21:56.020092 31448 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 05:21:59.716837 31448 solver.cpp:228] Iteration 745, loss = 0.517814
I0403 05:21:59.716948 31448 solver.cpp:244]     Train net output #0: loss = 0.517814 (* 1 = 0.517814 loss)
I0403 05:21:59.918650 31448 sgd_solver.cpp:106] Iteration 745, lr = 0.005
I0403 05:22:03.401324 31448 solver.cpp:228] Iteration 750, loss = 0.692785
I0403 05:22:03.401422 31448 solver.cpp:244]     Train net output #0: loss = 0.692785 (* 1 = 0.692785 loss)
I0403 05:22:03.580276 31448 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 05:22:07.029814 31448 solver.cpp:228] Iteration 755, loss = 0.727335
I0403 05:22:07.029912 31448 solver.cpp:244]     Train net output #0: loss = 0.727335 (* 1 = 0.727335 loss)
I0403 05:22:07.195729 31448 sgd_solver.cpp:106] Iteration 755, lr = 0.005
I0403 05:22:10.661229 31448 solver.cpp:228] Iteration 760, loss = 0.357051
I0403 05:22:10.661331 31448 solver.cpp:244]     Train net output #0: loss = 0.357051 (* 1 = 0.357051 loss)
I0403 05:22:10.835592 31448 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 05:22:14.343982 31448 solver.cpp:228] Iteration 765, loss = 0.69949
I0403 05:22:14.344080 31448 solver.cpp:244]     Train net output #0: loss = 0.69949 (* 1 = 0.69949 loss)
I0403 05:22:14.514818 31448 sgd_solver.cpp:106] Iteration 765, lr = 0.005
I0403 05:22:17.989091 31448 solver.cpp:228] Iteration 770, loss = 0.628288
I0403 05:22:17.989189 31448 solver.cpp:244]     Train net output #0: loss = 0.628288 (* 1 = 0.628288 loss)
I0403 05:22:18.165874 31448 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 05:22:21.585768 31448 solver.cpp:228] Iteration 775, loss = 0.576101
I0403 05:22:21.586079 31448 solver.cpp:244]     Train net output #0: loss = 0.576101 (* 1 = 0.576101 loss)
I0403 05:22:21.761704 31448 sgd_solver.cpp:106] Iteration 775, lr = 0.005
I0403 05:22:25.246234 31448 solver.cpp:228] Iteration 780, loss = 0.560521
I0403 05:22:25.246335 31448 solver.cpp:244]     Train net output #0: loss = 0.560521 (* 1 = 0.560521 loss)
I0403 05:22:25.424808 31448 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 05:22:28.898360 31448 solver.cpp:228] Iteration 785, loss = 0.664071
I0403 05:22:28.898473 31448 solver.cpp:244]     Train net output #0: loss = 0.664071 (* 1 = 0.664071 loss)
I0403 05:22:29.081850 31448 sgd_solver.cpp:106] Iteration 785, lr = 0.005
I0403 05:22:32.570550 31448 solver.cpp:228] Iteration 790, loss = 0.555347
I0403 05:22:32.570647 31448 solver.cpp:244]     Train net output #0: loss = 0.555347 (* 1 = 0.555347 loss)
I0403 05:22:32.724299 31448 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 05:22:36.255071 31448 solver.cpp:228] Iteration 795, loss = 0.559515
I0403 05:22:36.255173 31448 solver.cpp:244]     Train net output #0: loss = 0.559515 (* 1 = 0.559515 loss)
I0403 05:22:36.434170 31448 sgd_solver.cpp:106] Iteration 795, lr = 0.005
I0403 05:22:39.855396 31448 solver.cpp:228] Iteration 800, loss = 0.459737
I0403 05:22:39.855501 31448 solver.cpp:244]     Train net output #0: loss = 0.459737 (* 1 = 0.459737 loss)
I0403 05:22:40.053711 31448 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 05:22:43.497603 31448 solver.cpp:228] Iteration 805, loss = 0.736019
I0403 05:22:43.497712 31448 solver.cpp:244]     Train net output #0: loss = 0.736019 (* 1 = 0.736019 loss)
I0403 05:22:43.682431 31448 sgd_solver.cpp:106] Iteration 805, lr = 0.005
I0403 05:22:47.137601 31448 solver.cpp:228] Iteration 810, loss = 0.663064
I0403 05:22:47.137712 31448 solver.cpp:244]     Train net output #0: loss = 0.663064 (* 1 = 0.663064 loss)
I0403 05:22:47.320982 31448 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 05:22:50.744302 31448 solver.cpp:228] Iteration 815, loss = 0.615303
I0403 05:22:50.744415 31448 solver.cpp:244]     Train net output #0: loss = 0.615303 (* 1 = 0.615303 loss)
I0403 05:22:50.963979 31448 sgd_solver.cpp:106] Iteration 815, lr = 0.005
I0403 05:22:54.435905 31448 solver.cpp:228] Iteration 820, loss = 0.630945
I0403 05:22:54.436228 31448 solver.cpp:244]     Train net output #0: loss = 0.630945 (* 1 = 0.630945 loss)
I0403 05:22:54.678027 31448 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 05:22:58.111791 31448 solver.cpp:228] Iteration 825, loss = 0.395404
I0403 05:22:58.111894 31448 solver.cpp:244]     Train net output #0: loss = 0.395404 (* 1 = 0.395404 loss)
I0403 05:22:58.288787 31448 sgd_solver.cpp:106] Iteration 825, lr = 0.005
I0403 05:23:01.732955 31448 solver.cpp:228] Iteration 830, loss = 0.609415
I0403 05:23:01.733064 31448 solver.cpp:244]     Train net output #0: loss = 0.609415 (* 1 = 0.609415 loss)
I0403 05:23:01.937125 31448 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 05:23:05.468586 31448 solver.cpp:228] Iteration 835, loss = 0.55287
I0403 05:23:05.468688 31448 solver.cpp:244]     Train net output #0: loss = 0.55287 (* 1 = 0.55287 loss)
I0403 05:23:05.645602 31448 sgd_solver.cpp:106] Iteration 835, lr = 0.005
I0403 05:23:08.577482 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_840.caffemodel
I0403 05:23:11.308197 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_840.solverstate
I0403 05:23:13.083183 31448 solver.cpp:337] Iteration 840, Testing net (#0)
I0403 05:24:53.103534 31448 solver.cpp:404]     Test net output #0: accuracy = 0.762837
I0403 05:24:53.103912 31448 solver.cpp:404]     Test net output #1: loss = 0.804804 (* 1 = 0.804804 loss)
I0403 05:24:53.628226 31448 solver.cpp:228] Iteration 840, loss = 0.67758
I0403 05:24:53.628329 31448 solver.cpp:244]     Train net output #0: loss = 0.67758 (* 1 = 0.67758 loss)
I0403 05:24:53.792629 31448 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 05:24:57.257261 31448 solver.cpp:228] Iteration 845, loss = 0.409805
I0403 05:24:57.257365 31448 solver.cpp:244]     Train net output #0: loss = 0.409805 (* 1 = 0.409805 loss)
I0403 05:24:57.436000 31448 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 05:25:00.846922 31448 solver.cpp:228] Iteration 850, loss = 0.669966
I0403 05:25:00.847029 31448 solver.cpp:244]     Train net output #0: loss = 0.669966 (* 1 = 0.669966 loss)
I0403 05:25:01.045022 31448 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 05:25:04.483144 31448 solver.cpp:228] Iteration 855, loss = 0.704913
I0403 05:25:04.483242 31448 solver.cpp:244]     Train net output #0: loss = 0.704913 (* 1 = 0.704913 loss)
I0403 05:25:04.654525 31448 sgd_solver.cpp:106] Iteration 855, lr = 0.005
I0403 05:25:08.216266 31448 solver.cpp:228] Iteration 860, loss = 0.568362
I0403 05:25:08.216366 31448 solver.cpp:244]     Train net output #0: loss = 0.568362 (* 1 = 0.568362 loss)
I0403 05:25:08.392664 31448 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 05:25:11.866540 31448 solver.cpp:228] Iteration 865, loss = 0.699411
I0403 05:25:11.866649 31448 solver.cpp:244]     Train net output #0: loss = 0.699411 (* 1 = 0.699411 loss)
I0403 05:25:12.032783 31448 sgd_solver.cpp:106] Iteration 865, lr = 0.005
I0403 05:25:15.508455 31448 solver.cpp:228] Iteration 870, loss = 0.431457
I0403 05:25:15.508566 31448 solver.cpp:244]     Train net output #0: loss = 0.431457 (* 1 = 0.431457 loss)
I0403 05:25:15.691902 31448 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 05:25:19.162946 31448 solver.cpp:228] Iteration 875, loss = 0.524159
I0403 05:25:19.163044 31448 solver.cpp:244]     Train net output #0: loss = 0.524159 (* 1 = 0.524159 loss)
I0403 05:25:19.335590 31448 sgd_solver.cpp:106] Iteration 875, lr = 0.005
I0403 05:25:22.757911 31448 solver.cpp:228] Iteration 880, loss = 0.42364
I0403 05:25:22.758020 31448 solver.cpp:244]     Train net output #0: loss = 0.42364 (* 1 = 0.42364 loss)
I0403 05:25:22.952927 31448 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 05:25:26.503494 31448 solver.cpp:228] Iteration 885, loss = 0.385266
I0403 05:25:26.503804 31448 solver.cpp:244]     Train net output #0: loss = 0.385266 (* 1 = 0.385266 loss)
I0403 05:25:26.691437 31448 sgd_solver.cpp:106] Iteration 885, lr = 0.005
I0403 05:25:30.147986 31448 solver.cpp:228] Iteration 890, loss = 0.495595
I0403 05:25:30.148087 31448 solver.cpp:244]     Train net output #0: loss = 0.495595 (* 1 = 0.495595 loss)
I0403 05:25:30.323266 31448 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 05:25:33.761265 31448 solver.cpp:228] Iteration 895, loss = 0.543652
I0403 05:25:33.761369 31448 solver.cpp:244]     Train net output #0: loss = 0.543652 (* 1 = 0.543652 loss)
I0403 05:25:33.978950 31448 sgd_solver.cpp:106] Iteration 895, lr = 0.005
I0403 05:25:37.455577 31448 solver.cpp:228] Iteration 900, loss = 0.633053
I0403 05:25:37.455685 31448 solver.cpp:244]     Train net output #0: loss = 0.633053 (* 1 = 0.633053 loss)
I0403 05:25:37.645316 31448 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 05:25:41.081960 31448 solver.cpp:228] Iteration 905, loss = 0.433668
I0403 05:25:41.082058 31448 solver.cpp:244]     Train net output #0: loss = 0.433668 (* 1 = 0.433668 loss)
I0403 05:25:41.260099 31448 sgd_solver.cpp:106] Iteration 905, lr = 0.005
I0403 05:25:44.691004 31448 solver.cpp:228] Iteration 910, loss = 0.313405
I0403 05:25:44.691098 31448 solver.cpp:244]     Train net output #0: loss = 0.313405 (* 1 = 0.313405 loss)
I0403 05:25:44.865758 31448 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 05:25:48.328132 31448 solver.cpp:228] Iteration 915, loss = 0.574689
I0403 05:25:48.329197 31448 solver.cpp:244]     Train net output #0: loss = 0.574689 (* 1 = 0.574689 loss)
I0403 05:25:48.506994 31448 sgd_solver.cpp:106] Iteration 915, lr = 0.005
I0403 05:25:52.007895 31448 solver.cpp:228] Iteration 920, loss = 0.413293
I0403 05:25:52.007998 31448 solver.cpp:244]     Train net output #0: loss = 0.413293 (* 1 = 0.413293 loss)
I0403 05:25:52.185101 31448 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 05:25:55.638260 31448 solver.cpp:228] Iteration 925, loss = 0.403417
I0403 05:25:55.638360 31448 solver.cpp:244]     Train net output #0: loss = 0.403417 (* 1 = 0.403417 loss)
I0403 05:25:55.814877 31448 sgd_solver.cpp:106] Iteration 925, lr = 0.005
I0403 05:25:59.242975 31448 solver.cpp:228] Iteration 930, loss = 0.595376
I0403 05:25:59.243316 31448 solver.cpp:244]     Train net output #0: loss = 0.595376 (* 1 = 0.595376 loss)
I0403 05:25:59.417593 31448 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 05:26:02.915102 31448 solver.cpp:228] Iteration 935, loss = 0.614081
I0403 05:26:02.915199 31448 solver.cpp:244]     Train net output #0: loss = 0.614081 (* 1 = 0.614081 loss)
I0403 05:26:03.091008 31448 sgd_solver.cpp:106] Iteration 935, lr = 0.005
I0403 05:26:06.564631 31448 solver.cpp:228] Iteration 940, loss = 0.580084
I0403 05:26:06.564728 31448 solver.cpp:244]     Train net output #0: loss = 0.580084 (* 1 = 0.580084 loss)
I0403 05:26:06.745115 31448 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 05:26:09.656047 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_945.caffemodel
I0403 05:26:12.459520 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_945.solverstate
I0403 05:26:14.338531 31448 solver.cpp:337] Iteration 945, Testing net (#0)
I0403 05:27:54.358747 31448 solver.cpp:404]     Test net output #0: accuracy = 0.787849
I0403 05:27:54.359045 31448 solver.cpp:404]     Test net output #1: loss = 0.716086 (* 1 = 0.716086 loss)
I0403 05:27:54.868878 31448 solver.cpp:228] Iteration 945, loss = 0.431333
I0403 05:27:54.868973 31448 solver.cpp:244]     Train net output #0: loss = 0.431333 (* 1 = 0.431333 loss)
I0403 05:27:55.045070 31448 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 05:27:58.533821 31448 solver.cpp:228] Iteration 950, loss = 0.44312
I0403 05:27:58.533921 31448 solver.cpp:244]     Train net output #0: loss = 0.44312 (* 1 = 0.44312 loss)
I0403 05:27:58.716220 31448 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 05:28:02.182014 31448 solver.cpp:228] Iteration 955, loss = 0.552269
I0403 05:28:02.182111 31448 solver.cpp:244]     Train net output #0: loss = 0.552269 (* 1 = 0.552269 loss)
I0403 05:28:02.363173 31448 sgd_solver.cpp:106] Iteration 955, lr = 0.005
I0403 05:28:05.816323 31448 solver.cpp:228] Iteration 960, loss = 0.484553
I0403 05:28:05.816421 31448 solver.cpp:244]     Train net output #0: loss = 0.484553 (* 1 = 0.484553 loss)
I0403 05:28:05.992816 31448 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 05:28:09.446959 31448 solver.cpp:228] Iteration 965, loss = 0.637185
I0403 05:28:09.447067 31448 solver.cpp:244]     Train net output #0: loss = 0.637185 (* 1 = 0.637185 loss)
I0403 05:28:09.644327 31448 sgd_solver.cpp:106] Iteration 965, lr = 0.005
I0403 05:28:13.182299 31448 solver.cpp:228] Iteration 970, loss = 0.591029
I0403 05:28:13.182410 31448 solver.cpp:244]     Train net output #0: loss = 0.591029 (* 1 = 0.591029 loss)
I0403 05:28:13.375054 31448 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 05:28:16.850531 31448 solver.cpp:228] Iteration 975, loss = 0.353255
I0403 05:28:16.850638 31448 solver.cpp:244]     Train net output #0: loss = 0.353255 (* 1 = 0.353255 loss)
I0403 05:28:17.033922 31448 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 05:28:20.522675 31448 solver.cpp:228] Iteration 980, loss = 0.650415
I0403 05:28:20.522773 31448 solver.cpp:244]     Train net output #0: loss = 0.650415 (* 1 = 0.650415 loss)
I0403 05:28:20.700031 31448 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 05:28:24.191918 31448 solver.cpp:228] Iteration 985, loss = 0.477276
I0403 05:28:24.192013 31448 solver.cpp:244]     Train net output #0: loss = 0.477276 (* 1 = 0.477276 loss)
I0403 05:28:24.369562 31448 sgd_solver.cpp:106] Iteration 985, lr = 0.005
I0403 05:28:27.809650 31448 solver.cpp:228] Iteration 990, loss = 0.456571
I0403 05:28:27.809753 31448 solver.cpp:244]     Train net output #0: loss = 0.456571 (* 1 = 0.456571 loss)
I0403 05:28:27.999776 31448 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 05:28:31.406424 31448 solver.cpp:228] Iteration 995, loss = 0.496184
I0403 05:28:31.406523 31448 solver.cpp:244]     Train net output #0: loss = 0.496184 (* 1 = 0.496184 loss)
I0403 05:28:31.582221 31448 sgd_solver.cpp:106] Iteration 995, lr = 0.005
I0403 05:28:35.098745 31448 solver.cpp:228] Iteration 1000, loss = 0.421747
I0403 05:28:35.098855 31448 solver.cpp:244]     Train net output #0: loss = 0.421747 (* 1 = 0.421747 loss)
I0403 05:28:35.337501 31448 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 05:28:38.868803 31448 solver.cpp:228] Iteration 1005, loss = 0.442337
I0403 05:28:38.868896 31448 solver.cpp:244]     Train net output #0: loss = 0.442337 (* 1 = 0.442337 loss)
I0403 05:28:39.036931 31448 sgd_solver.cpp:106] Iteration 1005, lr = 0.005
I0403 05:28:42.554210 31448 solver.cpp:228] Iteration 1010, loss = 0.48659
I0403 05:28:42.554328 31448 solver.cpp:244]     Train net output #0: loss = 0.48659 (* 1 = 0.48659 loss)
I0403 05:28:42.784756 31448 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 05:28:46.262193 31448 solver.cpp:228] Iteration 1015, loss = 0.430814
I0403 05:28:46.262306 31448 solver.cpp:244]     Train net output #0: loss = 0.430814 (* 1 = 0.430814 loss)
I0403 05:28:46.455863 31448 sgd_solver.cpp:106] Iteration 1015, lr = 0.005
I0403 05:28:49.938074 31448 solver.cpp:228] Iteration 1020, loss = 0.483691
I0403 05:28:49.938172 31448 solver.cpp:244]     Train net output #0: loss = 0.483691 (* 1 = 0.483691 loss)
I0403 05:28:50.117319 31448 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 05:28:53.568161 31448 solver.cpp:228] Iteration 1025, loss = 0.455055
I0403 05:28:53.568265 31448 solver.cpp:244]     Train net output #0: loss = 0.455055 (* 1 = 0.455055 loss)
I0403 05:28:53.742321 31448 sgd_solver.cpp:106] Iteration 1025, lr = 0.005
I0403 05:28:57.183882 31448 solver.cpp:228] Iteration 1030, loss = 0.291316
I0403 05:28:57.184216 31448 solver.cpp:244]     Train net output #0: loss = 0.291316 (* 1 = 0.291316 loss)
I0403 05:28:57.390347 31448 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 05:29:00.921592 31448 solver.cpp:228] Iteration 1035, loss = 0.518894
I0403 05:29:00.921715 31448 solver.cpp:244]     Train net output #0: loss = 0.518894 (* 1 = 0.518894 loss)
I0403 05:29:01.108780 31448 sgd_solver.cpp:106] Iteration 1035, lr = 0.005
I0403 05:29:04.577013 31448 solver.cpp:228] Iteration 1040, loss = 0.459263
I0403 05:29:04.577122 31448 solver.cpp:244]     Train net output #0: loss = 0.459263 (* 1 = 0.459263 loss)
I0403 05:29:04.763211 31448 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 05:29:08.247244 31448 solver.cpp:228] Iteration 1045, loss = 0.408659
I0403 05:29:08.247361 31448 solver.cpp:244]     Train net output #0: loss = 0.408659 (* 1 = 0.408659 loss)
I0403 05:29:08.457855 31448 sgd_solver.cpp:106] Iteration 1045, lr = 0.005
I0403 05:29:11.388061 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1050.caffemodel
I0403 05:29:14.132920 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1050.solverstate
I0403 05:29:16.006489 31448 solver.cpp:337] Iteration 1050, Testing net (#0)
I0403 05:30:56.026679 31448 solver.cpp:404]     Test net output #0: accuracy = 0.782906
I0403 05:30:56.027025 31448 solver.cpp:404]     Test net output #1: loss = 0.741892 (* 1 = 0.741892 loss)
I0403 05:30:56.549865 31448 solver.cpp:228] Iteration 1050, loss = 0.49582
I0403 05:30:56.549958 31448 solver.cpp:244]     Train net output #0: loss = 0.49582 (* 1 = 0.49582 loss)
I0403 05:30:56.722133 31448 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 05:31:00.216728 31448 solver.cpp:228] Iteration 1055, loss = 0.498173
I0403 05:31:00.216864 31448 solver.cpp:244]     Train net output #0: loss = 0.498173 (* 1 = 0.498173 loss)
I0403 05:31:00.407260 31448 sgd_solver.cpp:106] Iteration 1055, lr = 0.005
I0403 05:31:03.930193 31448 solver.cpp:228] Iteration 1060, loss = 0.360791
I0403 05:31:03.930290 31448 solver.cpp:244]     Train net output #0: loss = 0.360791 (* 1 = 0.360791 loss)
I0403 05:31:04.113314 31448 sgd_solver.cpp:106] Iteration 1060, lr = 0.0005
I0403 05:31:07.540750 31448 solver.cpp:228] Iteration 1065, loss = 0.333202
I0403 05:31:07.540859 31448 solver.cpp:244]     Train net output #0: loss = 0.333202 (* 1 = 0.333202 loss)
I0403 05:31:07.745782 31448 sgd_solver.cpp:106] Iteration 1065, lr = 0.0005
I0403 05:31:11.286273 31448 solver.cpp:228] Iteration 1070, loss = 0.395672
I0403 05:31:11.286373 31448 solver.cpp:244]     Train net output #0: loss = 0.395672 (* 1 = 0.395672 loss)
I0403 05:31:11.451364 31448 sgd_solver.cpp:106] Iteration 1070, lr = 0.0005
I0403 05:31:14.953160 31448 solver.cpp:228] Iteration 1075, loss = 0.534979
I0403 05:31:14.953258 31448 solver.cpp:244]     Train net output #0: loss = 0.534979 (* 1 = 0.534979 loss)
I0403 05:31:15.113240 31448 sgd_solver.cpp:106] Iteration 1075, lr = 0.0005
I0403 05:31:18.596170 31448 solver.cpp:228] Iteration 1080, loss = 0.253398
I0403 05:31:18.596282 31448 solver.cpp:244]     Train net output #0: loss = 0.253398 (* 1 = 0.253398 loss)
I0403 05:31:18.845636 31448 sgd_solver.cpp:106] Iteration 1080, lr = 0.0005
I0403 05:31:22.316066 31448 solver.cpp:228] Iteration 1085, loss = 0.305282
I0403 05:31:22.316171 31448 solver.cpp:244]     Train net output #0: loss = 0.305282 (* 1 = 0.305282 loss)
I0403 05:31:22.501544 31448 sgd_solver.cpp:106] Iteration 1085, lr = 0.0005
I0403 05:31:26.009533 31448 solver.cpp:228] Iteration 1090, loss = 0.313016
I0403 05:31:26.009645 31448 solver.cpp:244]     Train net output #0: loss = 0.313016 (* 1 = 0.313016 loss)
I0403 05:31:26.205420 31448 sgd_solver.cpp:106] Iteration 1090, lr = 0.0005
I0403 05:31:29.689851 31448 solver.cpp:228] Iteration 1095, loss = 0.322982
I0403 05:31:29.689949 31448 solver.cpp:244]     Train net output #0: loss = 0.322982 (* 1 = 0.322982 loss)
I0403 05:31:29.841310 31448 sgd_solver.cpp:106] Iteration 1095, lr = 0.0005
I0403 05:31:33.365895 31448 solver.cpp:228] Iteration 1100, loss = 0.272405
I0403 05:31:33.365990 31448 solver.cpp:244]     Train net output #0: loss = 0.272405 (* 1 = 0.272405 loss)
I0403 05:31:33.543561 31448 sgd_solver.cpp:106] Iteration 1100, lr = 0.0005
I0403 05:31:37.133581 31448 solver.cpp:228] Iteration 1105, loss = 0.298894
I0403 05:31:37.133682 31448 solver.cpp:244]     Train net output #0: loss = 0.298894 (* 1 = 0.298894 loss)
I0403 05:31:37.313608 31448 sgd_solver.cpp:106] Iteration 1105, lr = 0.0005
I0403 05:31:40.748106 31448 solver.cpp:228] Iteration 1110, loss = 0.315203
I0403 05:31:40.748219 31448 solver.cpp:244]     Train net output #0: loss = 0.315203 (* 1 = 0.315203 loss)
I0403 05:31:40.951329 31448 sgd_solver.cpp:106] Iteration 1110, lr = 0.0005
I0403 05:31:44.409605 31448 solver.cpp:228] Iteration 1115, loss = 0.476956
I0403 05:31:44.409703 31448 solver.cpp:244]     Train net output #0: loss = 0.476956 (* 1 = 0.476956 loss)
I0403 05:31:44.563329 31448 sgd_solver.cpp:106] Iteration 1115, lr = 0.0005
I0403 05:31:48.120834 31448 solver.cpp:228] Iteration 1120, loss = 0.219998
I0403 05:31:48.120934 31448 solver.cpp:244]     Train net output #0: loss = 0.219998 (* 1 = 0.219998 loss)
I0403 05:31:48.302163 31448 sgd_solver.cpp:106] Iteration 1120, lr = 0.0005
I0403 05:31:51.806299 31448 solver.cpp:228] Iteration 1125, loss = 0.202743
I0403 05:31:51.806401 31448 solver.cpp:244]     Train net output #0: loss = 0.202743 (* 1 = 0.202743 loss)
I0403 05:31:51.989593 31448 sgd_solver.cpp:106] Iteration 1125, lr = 0.0005
I0403 05:31:55.464861 31448 solver.cpp:228] Iteration 1130, loss = 0.180059
I0403 05:31:55.464961 31448 solver.cpp:244]     Train net output #0: loss = 0.180059 (* 1 = 0.180059 loss)
I0403 05:31:55.642355 31448 sgd_solver.cpp:106] Iteration 1130, lr = 0.0005
I0403 05:31:59.195643 31448 solver.cpp:228] Iteration 1135, loss = 0.313162
I0403 05:31:59.195912 31448 solver.cpp:244]     Train net output #0: loss = 0.313162 (* 1 = 0.313162 loss)
I0403 05:31:59.362691 31448 sgd_solver.cpp:106] Iteration 1135, lr = 0.0005
I0403 05:32:02.828009 31448 solver.cpp:228] Iteration 1140, loss = 0.390611
I0403 05:32:02.828116 31448 solver.cpp:244]     Train net output #0: loss = 0.390611 (* 1 = 0.390611 loss)
I0403 05:32:03.012941 31448 sgd_solver.cpp:106] Iteration 1140, lr = 0.0005
I0403 05:32:06.522002 31448 solver.cpp:228] Iteration 1145, loss = 0.234135
I0403 05:32:06.522099 31448 solver.cpp:244]     Train net output #0: loss = 0.234135 (* 1 = 0.234135 loss)
I0403 05:32:06.694783 31448 sgd_solver.cpp:106] Iteration 1145, lr = 0.0005
I0403 05:32:10.185703 31448 solver.cpp:228] Iteration 1150, loss = 0.188544
I0403 05:32:10.185799 31448 solver.cpp:244]     Train net output #0: loss = 0.188544 (* 1 = 0.188544 loss)
I0403 05:32:10.362925 31448 sgd_solver.cpp:106] Iteration 1150, lr = 0.0005
I0403 05:32:13.305706 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1155.caffemodel
I0403 05:32:16.103247 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1155.solverstate
I0403 05:32:17.892261 31448 solver.cpp:337] Iteration 1155, Testing net (#0)
I0403 05:33:57.927387 31448 solver.cpp:404]     Test net output #0: accuracy = 0.832906
I0403 05:33:57.927654 31448 solver.cpp:404]     Test net output #1: loss = 0.562273 (* 1 = 0.562273 loss)
I0403 05:33:58.452844 31448 solver.cpp:228] Iteration 1155, loss = 0.336243
I0403 05:33:58.452941 31448 solver.cpp:244]     Train net output #0: loss = 0.336243 (* 1 = 0.336243 loss)
I0403 05:33:58.615309 31448 sgd_solver.cpp:106] Iteration 1155, lr = 0.0005
I0403 05:34:02.239941 31448 solver.cpp:228] Iteration 1160, loss = 0.247331
I0403 05:34:02.240041 31448 solver.cpp:244]     Train net output #0: loss = 0.247331 (* 1 = 0.247331 loss)
I0403 05:34:02.364261 31448 sgd_solver.cpp:106] Iteration 1160, lr = 0.0005
I0403 05:34:05.937089 31448 solver.cpp:228] Iteration 1165, loss = 0.252701
I0403 05:34:05.937201 31448 solver.cpp:244]     Train net output #0: loss = 0.252701 (* 1 = 0.252701 loss)
I0403 05:34:06.122367 31448 sgd_solver.cpp:106] Iteration 1165, lr = 0.0005
I0403 05:34:09.592797 31448 solver.cpp:228] Iteration 1170, loss = 0.18138
I0403 05:34:09.592896 31448 solver.cpp:244]     Train net output #0: loss = 0.18138 (* 1 = 0.18138 loss)
I0403 05:34:09.750046 31448 sgd_solver.cpp:106] Iteration 1170, lr = 0.0005
I0403 05:34:13.326836 31448 solver.cpp:228] Iteration 1175, loss = 0.24684
I0403 05:34:13.326932 31448 solver.cpp:244]     Train net output #0: loss = 0.24684 (* 1 = 0.24684 loss)
I0403 05:34:13.506273 31448 sgd_solver.cpp:106] Iteration 1175, lr = 0.0005
I0403 05:34:16.974930 31448 solver.cpp:228] Iteration 1180, loss = 0.275657
I0403 05:34:16.975028 31448 solver.cpp:244]     Train net output #0: loss = 0.275657 (* 1 = 0.275657 loss)
I0403 05:34:17.152844 31448 sgd_solver.cpp:106] Iteration 1180, lr = 0.0005
I0403 05:34:20.626463 31448 solver.cpp:228] Iteration 1185, loss = 0.157268
I0403 05:34:20.626574 31448 solver.cpp:244]     Train net output #0: loss = 0.157268 (* 1 = 0.157268 loss)
I0403 05:34:20.832754 31448 sgd_solver.cpp:106] Iteration 1185, lr = 0.0005
I0403 05:34:24.282135 31448 solver.cpp:228] Iteration 1190, loss = 0.217529
I0403 05:34:24.282233 31448 solver.cpp:244]     Train net output #0: loss = 0.217529 (* 1 = 0.217529 loss)
I0403 05:34:24.454061 31448 sgd_solver.cpp:106] Iteration 1190, lr = 0.0005
I0403 05:34:27.949867 31448 solver.cpp:228] Iteration 1195, loss = 0.179104
I0403 05:34:27.950199 31448 solver.cpp:244]     Train net output #0: loss = 0.179104 (* 1 = 0.179104 loss)
I0403 05:34:28.093539 31448 sgd_solver.cpp:106] Iteration 1195, lr = 0.0005
I0403 05:34:31.664201 31448 solver.cpp:228] Iteration 1200, loss = 0.287889
I0403 05:34:31.664309 31448 solver.cpp:244]     Train net output #0: loss = 0.287889 (* 1 = 0.287889 loss)
I0403 05:34:31.840405 31448 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0403 05:34:35.420409 31448 solver.cpp:228] Iteration 1205, loss = 0.316933
I0403 05:34:35.420518 31448 solver.cpp:244]     Train net output #0: loss = 0.316933 (* 1 = 0.316933 loss)
I0403 05:34:35.613833 31448 sgd_solver.cpp:106] Iteration 1205, lr = 0.0005
I0403 05:34:39.022415 31448 solver.cpp:228] Iteration 1210, loss = 0.280868
I0403 05:34:39.022526 31448 solver.cpp:244]     Train net output #0: loss = 0.280868 (* 1 = 0.280868 loss)
I0403 05:34:39.216521 31448 sgd_solver.cpp:106] Iteration 1210, lr = 0.0005
I0403 05:34:42.651439 31448 solver.cpp:228] Iteration 1215, loss = 0.203544
I0403 05:34:42.651535 31448 solver.cpp:244]     Train net output #0: loss = 0.203544 (* 1 = 0.203544 loss)
I0403 05:34:42.822859 31448 sgd_solver.cpp:106] Iteration 1215, lr = 0.0005
I0403 05:34:46.343067 31448 solver.cpp:228] Iteration 1220, loss = 0.37752
I0403 05:34:46.343173 31448 solver.cpp:244]     Train net output #0: loss = 0.37752 (* 1 = 0.37752 loss)
I0403 05:34:46.598476 31448 sgd_solver.cpp:106] Iteration 1220, lr = 0.0005
I0403 05:34:50.030766 31448 solver.cpp:228] Iteration 1225, loss = 0.308997
I0403 05:34:50.030860 31448 solver.cpp:244]     Train net output #0: loss = 0.308997 (* 1 = 0.308997 loss)
I0403 05:34:50.203843 31448 sgd_solver.cpp:106] Iteration 1225, lr = 0.0005
I0403 05:34:53.680184 31448 solver.cpp:228] Iteration 1230, loss = 0.249159
I0403 05:34:53.680281 31448 solver.cpp:244]     Train net output #0: loss = 0.249159 (* 1 = 0.249159 loss)
I0403 05:34:53.841967 31448 sgd_solver.cpp:106] Iteration 1230, lr = 0.0005
I0403 05:34:57.472703 31448 solver.cpp:228] Iteration 1235, loss = 0.195972
I0403 05:34:57.472802 31448 solver.cpp:244]     Train net output #0: loss = 0.195972 (* 1 = 0.195972 loss)
I0403 05:34:57.635643 31448 sgd_solver.cpp:106] Iteration 1235, lr = 0.0005
I0403 05:35:01.135988 31448 solver.cpp:228] Iteration 1240, loss = 0.205389
I0403 05:35:01.136283 31448 solver.cpp:244]     Train net output #0: loss = 0.205389 (* 1 = 0.205389 loss)
I0403 05:35:01.294255 31448 sgd_solver.cpp:106] Iteration 1240, lr = 0.0005
I0403 05:35:04.769193 31448 solver.cpp:228] Iteration 1245, loss = 0.14668
I0403 05:35:04.769290 31448 solver.cpp:244]     Train net output #0: loss = 0.14668 (* 1 = 0.14668 loss)
I0403 05:35:04.942889 31448 sgd_solver.cpp:106] Iteration 1245, lr = 0.0005
I0403 05:35:08.409795 31448 solver.cpp:228] Iteration 1250, loss = 0.128976
I0403 05:35:08.409904 31448 solver.cpp:244]     Train net output #0: loss = 0.128976 (* 1 = 0.128976 loss)
I0403 05:35:08.596324 31448 sgd_solver.cpp:106] Iteration 1250, lr = 0.0005
I0403 05:35:12.067612 31448 solver.cpp:228] Iteration 1255, loss = 0.272487
I0403 05:35:12.067713 31448 solver.cpp:244]     Train net output #0: loss = 0.272487 (* 1 = 0.272487 loss)
I0403 05:35:12.245515 31448 sgd_solver.cpp:106] Iteration 1255, lr = 0.0005
I0403 05:35:15.179348 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1260.caffemodel
I0403 05:35:18.023175 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1260.solverstate
I0403 05:35:19.918015 31448 solver.cpp:337] Iteration 1260, Testing net (#0)
I0403 05:36:59.930941 31448 solver.cpp:404]     Test net output #0: accuracy = 0.840457
I0403 05:36:59.931335 31448 solver.cpp:404]     Test net output #1: loss = 0.546153 (* 1 = 0.546153 loss)
I0403 05:37:00.459102 31448 solver.cpp:228] Iteration 1260, loss = 0.175032
I0403 05:37:00.459208 31448 solver.cpp:244]     Train net output #0: loss = 0.175032 (* 1 = 0.175032 loss)
I0403 05:37:00.642356 31448 sgd_solver.cpp:106] Iteration 1260, lr = 0.0005
I0403 05:37:04.080199 31448 solver.cpp:228] Iteration 1265, loss = 0.228026
I0403 05:37:04.080312 31448 solver.cpp:244]     Train net output #0: loss = 0.228026 (* 1 = 0.228026 loss)
I0403 05:37:04.276631 31448 sgd_solver.cpp:106] Iteration 1265, lr = 0.0005
I0403 05:37:07.705886 31448 solver.cpp:228] Iteration 1270, loss = 0.186719
I0403 05:37:07.706006 31448 solver.cpp:244]     Train net output #0: loss = 0.186719 (* 1 = 0.186719 loss)
I0403 05:37:07.909453 31448 sgd_solver.cpp:106] Iteration 1270, lr = 0.0005
I0403 05:37:11.374428 31448 solver.cpp:228] Iteration 1275, loss = 0.290924
I0403 05:37:11.374541 31448 solver.cpp:244]     Train net output #0: loss = 0.290924 (* 1 = 0.290924 loss)
I0403 05:37:11.549532 31448 sgd_solver.cpp:106] Iteration 1275, lr = 0.0005
I0403 05:37:15.045498 31448 solver.cpp:228] Iteration 1280, loss = 0.269425
I0403 05:37:15.045619 31448 solver.cpp:244]     Train net output #0: loss = 0.269425 (* 1 = 0.269425 loss)
I0403 05:37:15.231133 31448 sgd_solver.cpp:106] Iteration 1280, lr = 0.0005
I0403 05:37:18.678015 31448 solver.cpp:228] Iteration 1285, loss = 0.22856
I0403 05:37:18.678109 31448 solver.cpp:244]     Train net output #0: loss = 0.22856 (* 1 = 0.22856 loss)
I0403 05:37:18.856087 31448 sgd_solver.cpp:106] Iteration 1285, lr = 0.0005
I0403 05:37:22.346175 31448 solver.cpp:228] Iteration 1290, loss = 0.184326
I0403 05:37:22.346274 31448 solver.cpp:244]     Train net output #0: loss = 0.184325 (* 1 = 0.184325 loss)
I0403 05:37:22.523634 31448 sgd_solver.cpp:106] Iteration 1290, lr = 0.0005
I0403 05:37:26.097671 31448 solver.cpp:228] Iteration 1295, loss = 0.237207
I0403 05:37:26.097769 31448 solver.cpp:244]     Train net output #0: loss = 0.237207 (* 1 = 0.237207 loss)
I0403 05:37:26.260643 31448 sgd_solver.cpp:106] Iteration 1295, lr = 0.0005
I0403 05:37:29.893586 31448 solver.cpp:228] Iteration 1300, loss = 0.175827
I0403 05:37:29.893697 31448 solver.cpp:244]     Train net output #0: loss = 0.175827 (* 1 = 0.175827 loss)
I0403 05:37:30.090397 31448 sgd_solver.cpp:106] Iteration 1300, lr = 0.0005
I0403 05:37:33.506995 31448 solver.cpp:228] Iteration 1305, loss = 0.361927
I0403 05:37:33.507096 31448 solver.cpp:244]     Train net output #0: loss = 0.361927 (* 1 = 0.361927 loss)
I0403 05:37:33.681707 31448 sgd_solver.cpp:106] Iteration 1305, lr = 0.0005
I0403 05:37:37.164836 31448 solver.cpp:228] Iteration 1310, loss = 0.172992
I0403 05:37:37.164949 31448 solver.cpp:244]     Train net output #0: loss = 0.172992 (* 1 = 0.172992 loss)
I0403 05:37:37.415606 31448 sgd_solver.cpp:106] Iteration 1310, lr = 0.0005
I0403 05:37:40.856703 31448 solver.cpp:228] Iteration 1315, loss = 0.275623
I0403 05:37:40.856812 31448 solver.cpp:244]     Train net output #0: loss = 0.275623 (* 1 = 0.275623 loss)
I0403 05:37:41.041363 31448 sgd_solver.cpp:106] Iteration 1315, lr = 0.0005
I0403 05:37:44.467730 31448 solver.cpp:228] Iteration 1320, loss = 0.19251
I0403 05:37:44.467860 31448 solver.cpp:244]     Train net output #0: loss = 0.19251 (* 1 = 0.19251 loss)
I0403 05:37:44.727530 31448 sgd_solver.cpp:106] Iteration 1320, lr = 0.0005
I0403 05:37:48.255626 31448 solver.cpp:228] Iteration 1325, loss = 0.273124
I0403 05:37:48.255735 31448 solver.cpp:244]     Train net output #0: loss = 0.273124 (* 1 = 0.273124 loss)
I0403 05:37:48.441345 31448 sgd_solver.cpp:106] Iteration 1325, lr = 0.0005
I0403 05:37:51.878079 31448 solver.cpp:228] Iteration 1330, loss = 0.142457
I0403 05:37:51.878176 31448 solver.cpp:244]     Train net output #0: loss = 0.142457 (* 1 = 0.142457 loss)
I0403 05:37:52.053525 31448 sgd_solver.cpp:106] Iteration 1330, lr = 0.0005
I0403 05:37:55.534765 31448 solver.cpp:228] Iteration 1335, loss = 0.253572
I0403 05:37:55.534860 31448 solver.cpp:244]     Train net output #0: loss = 0.253572 (* 1 = 0.253572 loss)
I0403 05:37:55.713248 31448 sgd_solver.cpp:106] Iteration 1335, lr = 0.0005
I0403 05:37:59.157239 31448 solver.cpp:228] Iteration 1340, loss = 0.210302
I0403 05:37:59.157341 31448 solver.cpp:244]     Train net output #0: loss = 0.210302 (* 1 = 0.210302 loss)
I0403 05:37:59.334527 31448 sgd_solver.cpp:106] Iteration 1340, lr = 0.0005
I0403 05:38:02.797227 31448 solver.cpp:228] Iteration 1345, loss = 0.21237
I0403 05:38:02.797551 31448 solver.cpp:244]     Train net output #0: loss = 0.21237 (* 1 = 0.21237 loss)
I0403 05:38:02.974804 31448 sgd_solver.cpp:106] Iteration 1345, lr = 0.0005
I0403 05:38:06.499222 31448 solver.cpp:228] Iteration 1350, loss = 0.124154
I0403 05:38:06.499327 31448 solver.cpp:244]     Train net output #0: loss = 0.124154 (* 1 = 0.124154 loss)
I0403 05:38:06.608675 31448 sgd_solver.cpp:106] Iteration 1350, lr = 0.0005
I0403 05:38:10.149853 31448 solver.cpp:228] Iteration 1355, loss = 0.206166
I0403 05:38:10.149966 31448 solver.cpp:244]     Train net output #0: loss = 0.206166 (* 1 = 0.206166 loss)
I0403 05:38:10.353579 31448 sgd_solver.cpp:106] Iteration 1355, lr = 0.0005
I0403 05:38:13.789000 31448 solver.cpp:228] Iteration 1360, loss = 0.0716042
I0403 05:38:13.789099 31448 solver.cpp:244]     Train net output #0: loss = 0.0716042 (* 1 = 0.0716042 loss)
I0403 05:38:13.955101 31448 sgd_solver.cpp:106] Iteration 1360, lr = 0.0005
I0403 05:38:17.000819 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1365.caffemodel
I0403 05:38:19.776830 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1365.solverstate
I0403 05:38:21.657582 31448 solver.cpp:337] Iteration 1365, Testing net (#0)
I0403 05:40:01.673576 31448 solver.cpp:404]     Test net output #0: accuracy = 0.843272
I0403 05:40:01.673872 31448 solver.cpp:404]     Test net output #1: loss = 0.547927 (* 1 = 0.547927 loss)
I0403 05:40:02.194787 31448 solver.cpp:228] Iteration 1365, loss = 0.151446
I0403 05:40:02.194885 31448 solver.cpp:244]     Train net output #0: loss = 0.151446 (* 1 = 0.151446 loss)
I0403 05:40:02.372803 31448 sgd_solver.cpp:106] Iteration 1365, lr = 0.0005
I0403 05:40:05.809176 31448 solver.cpp:228] Iteration 1370, loss = 0.203349
I0403 05:40:05.809285 31448 solver.cpp:244]     Train net output #0: loss = 0.203349 (* 1 = 0.203349 loss)
I0403 05:40:06.004607 31448 sgd_solver.cpp:106] Iteration 1370, lr = 0.0005
I0403 05:40:09.493737 31448 solver.cpp:228] Iteration 1375, loss = 0.198642
I0403 05:40:09.493834 31448 solver.cpp:244]     Train net output #0: loss = 0.198642 (* 1 = 0.198642 loss)
I0403 05:40:09.670661 31448 sgd_solver.cpp:106] Iteration 1375, lr = 0.0005
I0403 05:40:13.119581 31448 solver.cpp:228] Iteration 1380, loss = 0.203622
I0403 05:40:13.119691 31448 solver.cpp:244]     Train net output #0: loss = 0.203622 (* 1 = 0.203622 loss)
I0403 05:40:13.304939 31448 sgd_solver.cpp:106] Iteration 1380, lr = 0.0005
I0403 05:40:16.737586 31448 solver.cpp:228] Iteration 1385, loss = 0.256886
I0403 05:40:16.737684 31448 solver.cpp:244]     Train net output #0: loss = 0.256886 (* 1 = 0.256886 loss)
I0403 05:40:16.913202 31448 sgd_solver.cpp:106] Iteration 1385, lr = 0.0005
I0403 05:40:20.378657 31448 solver.cpp:228] Iteration 1390, loss = 0.198884
I0403 05:40:20.378756 31448 solver.cpp:244]     Train net output #0: loss = 0.198884 (* 1 = 0.198884 loss)
I0403 05:40:20.528506 31448 sgd_solver.cpp:106] Iteration 1390, lr = 0.0005
I0403 05:40:24.040966 31448 solver.cpp:228] Iteration 1395, loss = 0.0672164
I0403 05:40:24.041074 31448 solver.cpp:244]     Train net output #0: loss = 0.0672164 (* 1 = 0.0672164 loss)
I0403 05:40:24.230597 31448 sgd_solver.cpp:106] Iteration 1395, lr = 0.0005
I0403 05:40:27.697474 31448 solver.cpp:228] Iteration 1400, loss = 0.213509
I0403 05:40:27.697569 31448 solver.cpp:244]     Train net output #0: loss = 0.213509 (* 1 = 0.213509 loss)
I0403 05:40:27.874202 31448 sgd_solver.cpp:106] Iteration 1400, lr = 0.0005
I0403 05:40:31.377375 31448 solver.cpp:228] Iteration 1405, loss = 0.184442
I0403 05:40:31.377487 31448 solver.cpp:244]     Train net output #0: loss = 0.184442 (* 1 = 0.184442 loss)
I0403 05:40:31.542927 31448 sgd_solver.cpp:106] Iteration 1405, lr = 0.0005
I0403 05:40:35.034745 31448 solver.cpp:228] Iteration 1410, loss = 0.203312
I0403 05:40:35.035071 31448 solver.cpp:244]     Train net output #0: loss = 0.203312 (* 1 = 0.203312 loss)
I0403 05:40:35.221278 31448 sgd_solver.cpp:106] Iteration 1410, lr = 0.0005
I0403 05:40:38.712827 31448 solver.cpp:228] Iteration 1415, loss = 0.212081
I0403 05:40:38.712939 31448 solver.cpp:244]     Train net output #0: loss = 0.212081 (* 1 = 0.212081 loss)
I0403 05:40:38.957074 31448 sgd_solver.cpp:106] Iteration 1415, lr = 0.0005
I0403 05:40:42.387970 31448 solver.cpp:228] Iteration 1420, loss = 0.174647
I0403 05:40:42.388067 31448 solver.cpp:244]     Train net output #0: loss = 0.174647 (* 1 = 0.174647 loss)
I0403 05:40:42.567631 31448 sgd_solver.cpp:106] Iteration 1420, lr = 0.0005
I0403 05:40:46.028872 31448 solver.cpp:228] Iteration 1425, loss = 0.201933
I0403 05:40:46.028970 31448 solver.cpp:244]     Train net output #0: loss = 0.201933 (* 1 = 0.201933 loss)
I0403 05:40:46.198318 31448 sgd_solver.cpp:106] Iteration 1425, lr = 0.0005
I0403 05:40:49.693411 31448 solver.cpp:228] Iteration 1430, loss = 0.229327
I0403 05:40:49.693523 31448 solver.cpp:244]     Train net output #0: loss = 0.229327 (* 1 = 0.229327 loss)
I0403 05:40:49.917490 31448 sgd_solver.cpp:106] Iteration 1430, lr = 0.0005
I0403 05:40:53.392294 31448 solver.cpp:228] Iteration 1435, loss = 0.173248
I0403 05:40:53.392395 31448 solver.cpp:244]     Train net output #0: loss = 0.173248 (* 1 = 0.173248 loss)
I0403 05:40:53.570631 31448 sgd_solver.cpp:106] Iteration 1435, lr = 0.0005
I0403 05:40:57.016836 31448 solver.cpp:228] Iteration 1440, loss = 0.200454
I0403 05:40:57.016945 31448 solver.cpp:244]     Train net output #0: loss = 0.200453 (* 1 = 0.200453 loss)
I0403 05:40:57.203682 31448 sgd_solver.cpp:106] Iteration 1440, lr = 0.0005
I0403 05:41:00.668244 31448 solver.cpp:228] Iteration 1445, loss = 0.177116
I0403 05:41:00.668372 31448 solver.cpp:244]     Train net output #0: loss = 0.177116 (* 1 = 0.177116 loss)
I0403 05:41:00.881567 31448 sgd_solver.cpp:106] Iteration 1445, lr = 0.0005
I0403 05:41:04.371522 31448 solver.cpp:228] Iteration 1450, loss = 0.0821696
I0403 05:41:04.371620 31448 solver.cpp:244]     Train net output #0: loss = 0.0821695 (* 1 = 0.0821695 loss)
I0403 05:41:04.548490 31448 sgd_solver.cpp:106] Iteration 1450, lr = 0.0005
I0403 05:41:07.958981 31448 solver.cpp:228] Iteration 1455, loss = 0.17285
I0403 05:41:07.959239 31448 solver.cpp:244]     Train net output #0: loss = 0.17285 (* 1 = 0.17285 loss)
I0403 05:41:08.143846 31448 sgd_solver.cpp:106] Iteration 1455, lr = 0.0005
I0403 05:41:11.572674 31448 solver.cpp:228] Iteration 1460, loss = 0.085187
I0403 05:41:11.572764 31448 solver.cpp:244]     Train net output #0: loss = 0.0851869 (* 1 = 0.0851869 loss)
I0403 05:41:11.765409 31448 sgd_solver.cpp:106] Iteration 1460, lr = 0.0005
I0403 05:41:15.171761 31448 solver.cpp:228] Iteration 1465, loss = 0.176157
I0403 05:41:15.171861 31448 solver.cpp:244]     Train net output #0: loss = 0.176157 (* 1 = 0.176157 loss)
I0403 05:41:15.354384 31448 sgd_solver.cpp:106] Iteration 1465, lr = 0.0005
I0403 05:41:18.254529 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1470.caffemodel
I0403 05:41:21.035212 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1470.solverstate
I0403 05:41:22.925528 31448 solver.cpp:337] Iteration 1470, Testing net (#0)
I0403 05:43:02.924319 31448 solver.cpp:404]     Test net output #0: accuracy = 0.845446
I0403 05:43:02.924710 31448 solver.cpp:404]     Test net output #1: loss = 0.549565 (* 1 = 0.549565 loss)
I0403 05:43:03.458889 31448 solver.cpp:228] Iteration 1470, loss = 0.2759
I0403 05:43:03.459868 31448 solver.cpp:244]     Train net output #0: loss = 0.2759 (* 1 = 0.2759 loss)
I0403 05:43:03.599891 31448 sgd_solver.cpp:106] Iteration 1470, lr = 0.0005
I0403 05:43:07.165199 31448 solver.cpp:228] Iteration 1475, loss = 0.14492
I0403 05:43:07.165314 31448 solver.cpp:244]     Train net output #0: loss = 0.14492 (* 1 = 0.14492 loss)
I0403 05:43:07.330325 31448 sgd_solver.cpp:106] Iteration 1475, lr = 0.0005
I0403 05:43:10.798913 31448 solver.cpp:228] Iteration 1480, loss = 0.188416
I0403 05:43:10.799026 31448 solver.cpp:244]     Train net output #0: loss = 0.188416 (* 1 = 0.188416 loss)
I0403 05:43:11.057759 31448 sgd_solver.cpp:106] Iteration 1480, lr = 0.0005
I0403 05:43:14.551758 31448 solver.cpp:228] Iteration 1485, loss = 0.214385
I0403 05:43:14.551854 31448 solver.cpp:244]     Train net output #0: loss = 0.214384 (* 1 = 0.214384 loss)
I0403 05:43:14.723127 31448 sgd_solver.cpp:106] Iteration 1485, lr = 0.0005
I0403 05:43:18.285257 31448 solver.cpp:228] Iteration 1490, loss = 0.266324
I0403 05:43:18.285359 31448 solver.cpp:244]     Train net output #0: loss = 0.266324 (* 1 = 0.266324 loss)
I0403 05:43:18.434448 31448 sgd_solver.cpp:106] Iteration 1490, lr = 0.0005
I0403 05:43:21.996785 31448 solver.cpp:228] Iteration 1495, loss = 0.118042
I0403 05:43:21.996898 31448 solver.cpp:244]     Train net output #0: loss = 0.118042 (* 1 = 0.118042 loss)
I0403 05:43:22.181223 31448 sgd_solver.cpp:106] Iteration 1495, lr = 0.0005
I0403 05:43:25.624562 31448 solver.cpp:228] Iteration 1500, loss = 0.132407
I0403 05:43:25.624660 31448 solver.cpp:244]     Train net output #0: loss = 0.132407 (* 1 = 0.132407 loss)
I0403 05:43:25.788404 31448 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0403 05:43:29.275267 31448 solver.cpp:228] Iteration 1505, loss = 0.160545
I0403 05:43:29.275383 31448 solver.cpp:244]     Train net output #0: loss = 0.160545 (* 1 = 0.160545 loss)
I0403 05:43:29.498615 31448 sgd_solver.cpp:106] Iteration 1505, lr = 0.0005
I0403 05:43:32.994459 31448 solver.cpp:228] Iteration 1510, loss = 0.243757
I0403 05:43:32.994788 31448 solver.cpp:244]     Train net output #0: loss = 0.243757 (* 1 = 0.243757 loss)
I0403 05:43:33.172008 31448 sgd_solver.cpp:106] Iteration 1510, lr = 0.0005
I0403 05:43:36.630484 31448 solver.cpp:228] Iteration 1515, loss = 0.126081
I0403 05:43:36.630584 31448 solver.cpp:244]     Train net output #0: loss = 0.126081 (* 1 = 0.126081 loss)
I0403 05:43:36.791445 31448 sgd_solver.cpp:106] Iteration 1515, lr = 0.0005
I0403 05:43:40.372149 31448 solver.cpp:228] Iteration 1520, loss = 0.131559
I0403 05:43:40.372247 31448 solver.cpp:244]     Train net output #0: loss = 0.131559 (* 1 = 0.131559 loss)
I0403 05:43:40.550451 31448 sgd_solver.cpp:106] Iteration 1520, lr = 0.0005
I0403 05:43:43.994500 31448 solver.cpp:228] Iteration 1525, loss = 0.188733
I0403 05:43:43.994611 31448 solver.cpp:244]     Train net output #0: loss = 0.188733 (* 1 = 0.188733 loss)
I0403 05:43:44.201951 31448 sgd_solver.cpp:106] Iteration 1525, lr = 0.0005
I0403 05:43:47.614063 31448 solver.cpp:228] Iteration 1530, loss = 0.146967
I0403 05:43:47.614159 31448 solver.cpp:244]     Train net output #0: loss = 0.146967 (* 1 = 0.146967 loss)
I0403 05:43:47.786069 31448 sgd_solver.cpp:106] Iteration 1530, lr = 0.0005
I0403 05:43:51.316521 31448 solver.cpp:228] Iteration 1535, loss = 0.107021
I0403 05:43:51.316630 31448 solver.cpp:244]     Train net output #0: loss = 0.107021 (* 1 = 0.107021 loss)
I0403 05:43:51.512542 31448 sgd_solver.cpp:106] Iteration 1535, lr = 0.0005
I0403 05:43:54.950642 31448 solver.cpp:228] Iteration 1540, loss = 0.125671
I0403 05:43:54.950749 31448 solver.cpp:244]     Train net output #0: loss = 0.125671 (* 1 = 0.125671 loss)
I0403 05:43:55.138591 31448 sgd_solver.cpp:106] Iteration 1540, lr = 0.0005
I0403 05:43:58.592900 31448 solver.cpp:228] Iteration 1545, loss = 0.249727
I0403 05:43:58.592996 31448 solver.cpp:244]     Train net output #0: loss = 0.249727 (* 1 = 0.249727 loss)
I0403 05:43:58.763352 31448 sgd_solver.cpp:106] Iteration 1545, lr = 0.0005
I0403 05:44:02.262356 31448 solver.cpp:228] Iteration 1550, loss = 0.23164
I0403 05:44:02.262457 31448 solver.cpp:244]     Train net output #0: loss = 0.23164 (* 1 = 0.23164 loss)
I0403 05:44:02.432991 31448 sgd_solver.cpp:106] Iteration 1550, lr = 0.0005
I0403 05:44:05.942853 31448 solver.cpp:228] Iteration 1555, loss = 0.149655
I0403 05:44:05.943186 31448 solver.cpp:244]     Train net output #0: loss = 0.149655 (* 1 = 0.149655 loss)
I0403 05:44:06.105415 31448 sgd_solver.cpp:106] Iteration 1555, lr = 0.0005
I0403 05:44:09.894937 31448 solver.cpp:228] Iteration 1560, loss = 0.190732
I0403 05:44:09.895035 31448 solver.cpp:244]     Train net output #0: loss = 0.190732 (* 1 = 0.190732 loss)
I0403 05:44:10.035418 31448 sgd_solver.cpp:106] Iteration 1560, lr = 0.0005
I0403 05:44:13.582676 31448 solver.cpp:228] Iteration 1565, loss = 0.0743932
I0403 05:44:13.582774 31448 solver.cpp:244]     Train net output #0: loss = 0.0743931 (* 1 = 0.0743931 loss)
I0403 05:44:13.757534 31448 sgd_solver.cpp:106] Iteration 1565, lr = 0.0005
I0403 05:44:17.440665 31448 solver.cpp:228] Iteration 1570, loss = 0.27052
I0403 05:44:17.440774 31448 solver.cpp:244]     Train net output #0: loss = 0.27052 (* 1 = 0.27052 loss)
I0403 05:44:17.624138 31448 sgd_solver.cpp:106] Iteration 1570, lr = 0.0005
I0403 05:44:20.534831 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1575.caffemodel
I0403 05:44:23.288990 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1575.solverstate
I0403 05:44:25.152740 31448 solver.cpp:337] Iteration 1575, Testing net (#0)
I0403 05:46:05.167531 31448 solver.cpp:404]     Test net output #0: accuracy = 0.847826
I0403 05:46:05.167856 31448 solver.cpp:404]     Test net output #1: loss = 0.541583 (* 1 = 0.541583 loss)
I0403 05:46:05.700958 31448 solver.cpp:228] Iteration 1575, loss = 0.162932
I0403 05:46:05.701050 31448 solver.cpp:244]     Train net output #0: loss = 0.162932 (* 1 = 0.162932 loss)
I0403 05:46:05.868034 31448 sgd_solver.cpp:106] Iteration 1575, lr = 0.0005
I0403 05:46:09.451828 31448 solver.cpp:228] Iteration 1580, loss = 0.291164
I0403 05:46:09.451928 31448 solver.cpp:244]     Train net output #0: loss = 0.291163 (* 1 = 0.291163 loss)
I0403 05:46:09.625120 31448 sgd_solver.cpp:106] Iteration 1580, lr = 0.0005
I0403 05:46:13.083503 31448 solver.cpp:228] Iteration 1585, loss = 0.102827
I0403 05:46:13.083614 31448 solver.cpp:244]     Train net output #0: loss = 0.102827 (* 1 = 0.102827 loss)
I0403 05:46:13.277217 31448 sgd_solver.cpp:106] Iteration 1585, lr = 0.0005
I0403 05:46:16.770324 31448 solver.cpp:228] Iteration 1590, loss = 0.259556
I0403 05:46:16.770423 31448 solver.cpp:244]     Train net output #0: loss = 0.259556 (* 1 = 0.259556 loss)
I0403 05:46:16.950687 31448 sgd_solver.cpp:106] Iteration 1590, lr = 0.0005
I0403 05:46:20.538591 31448 solver.cpp:228] Iteration 1595, loss = 0.159716
I0403 05:46:20.538689 31448 solver.cpp:244]     Train net output #0: loss = 0.159716 (* 1 = 0.159716 loss)
I0403 05:46:20.713351 31448 sgd_solver.cpp:106] Iteration 1595, lr = 0.0005
I0403 05:46:24.191710 31448 solver.cpp:228] Iteration 1600, loss = 0.273221
I0403 05:46:24.191820 31448 solver.cpp:244]     Train net output #0: loss = 0.273221 (* 1 = 0.273221 loss)
I0403 05:46:24.424535 31448 sgd_solver.cpp:106] Iteration 1600, lr = 0.0005
I0403 05:46:27.867499 31448 solver.cpp:228] Iteration 1605, loss = 0.221005
I0403 05:46:27.867594 31448 solver.cpp:244]     Train net output #0: loss = 0.221005 (* 1 = 0.221005 loss)
I0403 05:46:28.045696 31448 sgd_solver.cpp:106] Iteration 1605, lr = 0.0005
I0403 05:46:31.497547 31448 solver.cpp:228] Iteration 1610, loss = 0.102623
I0403 05:46:31.497643 31448 solver.cpp:244]     Train net output #0: loss = 0.102623 (* 1 = 0.102623 loss)
I0403 05:46:31.681104 31448 sgd_solver.cpp:106] Iteration 1610, lr = 0.0005
I0403 05:46:35.207135 31448 solver.cpp:228] Iteration 1615, loss = 0.209009
I0403 05:46:35.208389 31448 solver.cpp:244]     Train net output #0: loss = 0.209009 (* 1 = 0.209009 loss)
I0403 05:46:35.400408 31448 sgd_solver.cpp:106] Iteration 1615, lr = 0.0005
I0403 05:46:38.825866 31448 solver.cpp:228] Iteration 1620, loss = 0.220776
I0403 05:46:38.825978 31448 solver.cpp:244]     Train net output #0: loss = 0.220776 (* 1 = 0.220776 loss)
I0403 05:46:39.023597 31448 sgd_solver.cpp:106] Iteration 1620, lr = 0.0005
I0403 05:46:42.585762 31448 solver.cpp:228] Iteration 1625, loss = 0.22216
I0403 05:46:42.585860 31448 solver.cpp:244]     Train net output #0: loss = 0.22216 (* 1 = 0.22216 loss)
I0403 05:46:42.768530 31448 sgd_solver.cpp:106] Iteration 1625, lr = 0.0005
I0403 05:46:46.160717 31448 solver.cpp:228] Iteration 1630, loss = 0.176695
I0403 05:46:46.160825 31448 solver.cpp:244]     Train net output #0: loss = 0.176695 (* 1 = 0.176695 loss)
I0403 05:46:46.346381 31448 sgd_solver.cpp:106] Iteration 1630, lr = 0.0005
I0403 05:46:49.816123 31448 solver.cpp:228] Iteration 1635, loss = 0.132117
I0403 05:46:49.816234 31448 solver.cpp:244]     Train net output #0: loss = 0.132117 (* 1 = 0.132117 loss)
I0403 05:46:50.057078 31448 sgd_solver.cpp:106] Iteration 1635, lr = 0.0005
I0403 05:46:53.506146 31448 solver.cpp:228] Iteration 1640, loss = 0.103428
I0403 05:46:53.506263 31448 solver.cpp:244]     Train net output #0: loss = 0.103428 (* 1 = 0.103428 loss)
I0403 05:46:53.737598 31448 sgd_solver.cpp:106] Iteration 1640, lr = 0.0005
I0403 05:46:57.346112 31448 solver.cpp:228] Iteration 1645, loss = 0.323481
I0403 05:46:57.346225 31448 solver.cpp:244]     Train net output #0: loss = 0.323481 (* 1 = 0.323481 loss)
I0403 05:46:57.597417 31448 sgd_solver.cpp:106] Iteration 1645, lr = 0.0005
I0403 05:47:00.986745 31448 solver.cpp:228] Iteration 1650, loss = 0.177946
I0403 05:47:00.986855 31448 solver.cpp:244]     Train net output #0: loss = 0.177946 (* 1 = 0.177946 loss)
I0403 05:47:01.176336 31448 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I0403 05:47:04.619220 31448 solver.cpp:228] Iteration 1655, loss = 0.236077
I0403 05:47:04.619333 31448 solver.cpp:244]     Train net output #0: loss = 0.236077 (* 1 = 0.236077 loss)
I0403 05:47:04.830190 31448 sgd_solver.cpp:106] Iteration 1655, lr = 0.0005
I0403 05:47:08.246134 31448 solver.cpp:228] Iteration 1660, loss = 0.212645
I0403 05:47:08.246438 31448 solver.cpp:244]     Train net output #0: loss = 0.212645 (* 1 = 0.212645 loss)
I0403 05:47:08.434556 31448 sgd_solver.cpp:106] Iteration 1660, lr = 0.0005
I0403 05:47:11.876765 31448 solver.cpp:228] Iteration 1665, loss = 0.181201
I0403 05:47:11.876878 31448 solver.cpp:244]     Train net output #0: loss = 0.181201 (* 1 = 0.181201 loss)
I0403 05:47:12.069659 31448 sgd_solver.cpp:106] Iteration 1665, lr = 0.0005
I0403 05:47:15.535972 31448 solver.cpp:228] Iteration 1670, loss = 0.0807152
I0403 05:47:15.536079 31448 solver.cpp:244]     Train net output #0: loss = 0.0807152 (* 1 = 0.0807152 loss)
I0403 05:47:15.737613 31448 sgd_solver.cpp:106] Iteration 1670, lr = 0.0005
I0403 05:47:19.216611 31448 solver.cpp:228] Iteration 1675, loss = 0.178173
I0403 05:47:19.216722 31448 solver.cpp:244]     Train net output #0: loss = 0.178173 (* 1 = 0.178173 loss)
I0403 05:47:19.400578 31448 sgd_solver.cpp:106] Iteration 1675, lr = 0.0005
I0403 05:47:22.284739 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1680.caffemodel
I0403 05:47:25.051415 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1680.solverstate
I0403 05:47:26.913525 31448 solver.cpp:337] Iteration 1680, Testing net (#0)
I0403 05:49:06.913183 31448 solver.cpp:404]     Test net output #0: accuracy = 0.848512
I0403 05:49:06.913496 31448 solver.cpp:404]     Test net output #1: loss = 0.546451 (* 1 = 0.546451 loss)
I0403 05:49:07.435958 31448 solver.cpp:228] Iteration 1680, loss = 0.0985977
I0403 05:49:07.436903 31448 solver.cpp:244]     Train net output #0: loss = 0.0985977 (* 1 = 0.0985977 loss)
I0403 05:49:07.611430 31448 sgd_solver.cpp:106] Iteration 1680, lr = 0.0005
I0403 05:49:11.118541 31448 solver.cpp:228] Iteration 1685, loss = 0.285396
I0403 05:49:11.118654 31448 solver.cpp:244]     Train net output #0: loss = 0.285396 (* 1 = 0.285396 loss)
I0403 05:49:11.260607 31448 sgd_solver.cpp:106] Iteration 1685, lr = 0.0005
I0403 05:49:14.856406 31448 solver.cpp:228] Iteration 1690, loss = 0.152564
I0403 05:49:14.856530 31448 solver.cpp:244]     Train net output #0: loss = 0.152564 (* 1 = 0.152564 loss)
I0403 05:49:15.098439 31448 sgd_solver.cpp:106] Iteration 1690, lr = 0.0005
I0403 05:49:18.558320 31448 solver.cpp:228] Iteration 1695, loss = 0.136435
I0403 05:49:18.558423 31448 solver.cpp:244]     Train net output #0: loss = 0.136435 (* 1 = 0.136435 loss)
I0403 05:49:18.733702 31448 sgd_solver.cpp:106] Iteration 1695, lr = 0.0005
I0403 05:49:22.191478 31448 solver.cpp:228] Iteration 1700, loss = 0.147993
I0403 05:49:22.191601 31448 solver.cpp:244]     Train net output #0: loss = 0.147993 (* 1 = 0.147993 loss)
I0403 05:49:22.378362 31448 sgd_solver.cpp:106] Iteration 1700, lr = 0.0005
I0403 05:49:25.901741 31448 solver.cpp:228] Iteration 1705, loss = 0.198896
I0403 05:49:25.901841 31448 solver.cpp:244]     Train net output #0: loss = 0.198896 (* 1 = 0.198896 loss)
I0403 05:49:26.035573 31448 sgd_solver.cpp:106] Iteration 1705, lr = 0.0005
I0403 05:49:29.593950 31448 solver.cpp:228] Iteration 1710, loss = 0.208315
I0403 05:49:29.594084 31448 solver.cpp:244]     Train net output #0: loss = 0.208315 (* 1 = 0.208315 loss)
I0403 05:49:29.790707 31448 sgd_solver.cpp:106] Iteration 1710, lr = 0.0005
I0403 05:49:33.310135 31448 solver.cpp:228] Iteration 1715, loss = 0.119767
I0403 05:49:33.310247 31448 solver.cpp:244]     Train net output #0: loss = 0.119767 (* 1 = 0.119767 loss)
I0403 05:49:33.534386 31448 sgd_solver.cpp:106] Iteration 1715, lr = 0.0005
I0403 05:49:36.956858 31448 solver.cpp:228] Iteration 1720, loss = 0.166724
I0403 05:49:36.957197 31448 solver.cpp:244]     Train net output #0: loss = 0.166724 (* 1 = 0.166724 loss)
I0403 05:49:37.151934 31448 sgd_solver.cpp:106] Iteration 1720, lr = 0.0005
I0403 05:49:40.702286 31448 solver.cpp:228] Iteration 1725, loss = 0.134338
I0403 05:49:40.702392 31448 solver.cpp:244]     Train net output #0: loss = 0.134338 (* 1 = 0.134338 loss)
I0403 05:49:40.869330 31448 sgd_solver.cpp:106] Iteration 1725, lr = 0.0005
I0403 05:49:44.398486 31448 solver.cpp:228] Iteration 1730, loss = 0.130349
I0403 05:49:44.398586 31448 solver.cpp:244]     Train net output #0: loss = 0.130349 (* 1 = 0.130349 loss)
I0403 05:49:44.525537 31448 sgd_solver.cpp:106] Iteration 1730, lr = 0.0005
I0403 05:49:48.165012 31448 solver.cpp:228] Iteration 1735, loss = 0.102666
I0403 05:49:48.165120 31448 solver.cpp:244]     Train net output #0: loss = 0.102666 (* 1 = 0.102666 loss)
I0403 05:49:48.359166 31448 sgd_solver.cpp:106] Iteration 1735, lr = 0.0005
I0403 05:49:51.786289 31448 solver.cpp:228] Iteration 1740, loss = 0.110829
I0403 05:49:51.786391 31448 solver.cpp:244]     Train net output #0: loss = 0.110829 (* 1 = 0.110829 loss)
I0403 05:49:51.972695 31448 sgd_solver.cpp:106] Iteration 1740, lr = 0.0005
I0403 05:49:55.564429 31448 solver.cpp:228] Iteration 1745, loss = 0.153196
I0403 05:49:55.564530 31448 solver.cpp:244]     Train net output #0: loss = 0.153196 (* 1 = 0.153196 loss)
I0403 05:49:55.725556 31448 sgd_solver.cpp:106] Iteration 1745, lr = 0.0005
I0403 05:49:59.225137 31448 solver.cpp:228] Iteration 1750, loss = 0.190912
I0403 05:49:59.225250 31448 solver.cpp:244]     Train net output #0: loss = 0.190912 (* 1 = 0.190912 loss)
I0403 05:49:59.417697 31448 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I0403 05:50:02.869650 31448 solver.cpp:228] Iteration 1755, loss = 0.157211
I0403 05:50:02.869748 31448 solver.cpp:244]     Train net output #0: loss = 0.157211 (* 1 = 0.157211 loss)
I0403 05:50:03.043704 31448 sgd_solver.cpp:106] Iteration 1755, lr = 0.0005
I0403 05:50:06.586041 31448 solver.cpp:228] Iteration 1760, loss = 0.181876
I0403 05:50:06.587069 31448 solver.cpp:244]     Train net output #0: loss = 0.181876 (* 1 = 0.181876 loss)
I0403 05:50:06.742732 31448 sgd_solver.cpp:106] Iteration 1760, lr = 0.0005
I0403 05:50:10.271114 31448 solver.cpp:228] Iteration 1765, loss = 0.0749925
I0403 05:50:10.271466 31448 solver.cpp:244]     Train net output #0: loss = 0.0749925 (* 1 = 0.0749925 loss)
I0403 05:50:10.455096 31448 sgd_solver.cpp:106] Iteration 1765, lr = 0.0005
I0403 05:50:13.901654 31448 solver.cpp:228] Iteration 1770, loss = 0.221195
I0403 05:50:13.901762 31448 solver.cpp:244]     Train net output #0: loss = 0.221195 (* 1 = 0.221195 loss)
I0403 05:50:14.091526 31448 sgd_solver.cpp:106] Iteration 1770, lr = 0.0005
I0403 05:50:17.696729 31448 solver.cpp:228] Iteration 1775, loss = 0.243836
I0403 05:50:17.696830 31448 solver.cpp:244]     Train net output #0: loss = 0.243836 (* 1 = 0.243836 loss)
I0403 05:50:17.876694 31448 sgd_solver.cpp:106] Iteration 1775, lr = 0.0005
I0403 05:50:21.385324 31448 solver.cpp:228] Iteration 1780, loss = 0.130831
I0403 05:50:21.385421 31448 solver.cpp:244]     Train net output #0: loss = 0.130831 (* 1 = 0.130831 loss)
I0403 05:50:21.566123 31448 sgd_solver.cpp:106] Iteration 1780, lr = 0.0005
I0403 05:50:24.519088 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1785.caffemodel
I0403 05:50:27.283172 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1785.solverstate
I0403 05:50:29.176147 31448 solver.cpp:337] Iteration 1785, Testing net (#0)
I0403 05:52:09.172268 31448 solver.cpp:404]     Test net output #0: accuracy = 0.849405
I0403 05:52:09.172607 31448 solver.cpp:404]     Test net output #1: loss = 0.547781 (* 1 = 0.547781 loss)
I0403 05:52:09.692606 31448 solver.cpp:228] Iteration 1785, loss = 0.182927
I0403 05:52:09.692695 31448 solver.cpp:244]     Train net output #0: loss = 0.182927 (* 1 = 0.182927 loss)
I0403 05:52:09.870371 31448 sgd_solver.cpp:106] Iteration 1785, lr = 0.0005
I0403 05:52:13.339784 31448 solver.cpp:228] Iteration 1790, loss = 0.117551
I0403 05:52:13.339896 31448 solver.cpp:244]     Train net output #0: loss = 0.117551 (* 1 = 0.117551 loss)
I0403 05:52:13.523053 31448 sgd_solver.cpp:106] Iteration 1790, lr = 0.0005
I0403 05:52:17.003784 31448 solver.cpp:228] Iteration 1795, loss = 0.0989313
I0403 05:52:17.003907 31448 solver.cpp:244]     Train net output #0: loss = 0.0989313 (* 1 = 0.0989313 loss)
I0403 05:52:17.198529 31448 sgd_solver.cpp:106] Iteration 1795, lr = 0.0005
I0403 05:52:20.608899 31448 solver.cpp:228] Iteration 1800, loss = 0.248431
I0403 05:52:20.609009 31448 solver.cpp:244]     Train net output #0: loss = 0.248431 (* 1 = 0.248431 loss)
I0403 05:52:20.800457 31448 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0403 05:52:24.238390 31448 solver.cpp:228] Iteration 1805, loss = 0.133173
I0403 05:52:24.238503 31448 solver.cpp:244]     Train net output #0: loss = 0.133173 (* 1 = 0.133173 loss)
I0403 05:52:24.434320 31448 sgd_solver.cpp:106] Iteration 1805, lr = 0.0005
I0403 05:52:27.896524 31448 solver.cpp:228] Iteration 1810, loss = 0.203219
I0403 05:52:27.896631 31448 solver.cpp:244]     Train net output #0: loss = 0.203219 (* 1 = 0.203219 loss)
I0403 05:52:28.098955 31448 sgd_solver.cpp:106] Iteration 1810, lr = 0.0005
I0403 05:52:31.547907 31448 solver.cpp:228] Iteration 1815, loss = 0.176193
I0403 05:52:31.548012 31448 solver.cpp:244]     Train net output #0: loss = 0.176193 (* 1 = 0.176193 loss)
I0403 05:52:31.734614 31448 sgd_solver.cpp:106] Iteration 1815, lr = 0.0005
I0403 05:52:35.187981 31448 solver.cpp:228] Iteration 1820, loss = 0.0311935
I0403 05:52:35.188079 31448 solver.cpp:244]     Train net output #0: loss = 0.0311935 (* 1 = 0.0311935 loss)
I0403 05:52:35.369367 31448 sgd_solver.cpp:106] Iteration 1820, lr = 0.0005
I0403 05:52:38.785048 31448 solver.cpp:228] Iteration 1825, loss = 0.0664083
I0403 05:52:38.786252 31448 solver.cpp:244]     Train net output #0: loss = 0.0664082 (* 1 = 0.0664082 loss)
I0403 05:52:39.004581 31448 sgd_solver.cpp:106] Iteration 1825, lr = 0.0005
I0403 05:52:42.496000 31448 solver.cpp:228] Iteration 1830, loss = 0.0558487
I0403 05:52:42.496331 31448 solver.cpp:244]     Train net output #0: loss = 0.0558488 (* 1 = 0.0558488 loss)
I0403 05:52:42.674463 31448 sgd_solver.cpp:106] Iteration 1830, lr = 0.0005
I0403 05:52:46.131508 31448 solver.cpp:228] Iteration 1835, loss = 0.110822
I0403 05:52:46.131604 31448 solver.cpp:244]     Train net output #0: loss = 0.110822 (* 1 = 0.110822 loss)
I0403 05:52:46.300782 31448 sgd_solver.cpp:106] Iteration 1835, lr = 0.0005
I0403 05:52:49.775552 31448 solver.cpp:228] Iteration 1840, loss = 0.219887
I0403 05:52:49.775642 31448 solver.cpp:244]     Train net output #0: loss = 0.219887 (* 1 = 0.219887 loss)
I0403 05:52:50.030752 31448 sgd_solver.cpp:106] Iteration 1840, lr = 0.0005
I0403 05:52:53.528954 31448 solver.cpp:228] Iteration 1845, loss = 0.161129
I0403 05:52:53.529052 31448 solver.cpp:244]     Train net output #0: loss = 0.161129 (* 1 = 0.161129 loss)
I0403 05:52:53.706317 31448 sgd_solver.cpp:106] Iteration 1845, lr = 0.0005
I0403 05:52:57.197415 31448 solver.cpp:228] Iteration 1850, loss = 0.135304
I0403 05:52:57.197516 31448 solver.cpp:244]     Train net output #0: loss = 0.135304 (* 1 = 0.135304 loss)
I0403 05:52:57.376286 31448 sgd_solver.cpp:106] Iteration 1850, lr = 0.0005
I0403 05:53:00.884848 31448 solver.cpp:228] Iteration 1855, loss = 0.30856
I0403 05:53:00.884958 31448 solver.cpp:244]     Train net output #0: loss = 0.30856 (* 1 = 0.30856 loss)
I0403 05:53:01.068290 31448 sgd_solver.cpp:106] Iteration 1855, lr = 0.0005
I0403 05:53:04.588771 31448 solver.cpp:228] Iteration 1860, loss = 0.314662
I0403 05:53:04.588878 31448 solver.cpp:244]     Train net output #0: loss = 0.314662 (* 1 = 0.314662 loss)
I0403 05:53:04.772018 31448 sgd_solver.cpp:106] Iteration 1860, lr = 0.0005
I0403 05:53:08.588414 31448 solver.cpp:228] Iteration 1865, loss = 0.148304
I0403 05:53:08.588513 31448 solver.cpp:244]     Train net output #0: loss = 0.148304 (* 1 = 0.148304 loss)
I0403 05:53:08.721520 31448 sgd_solver.cpp:106] Iteration 1865, lr = 0.0005
I0403 05:53:12.246454 31448 solver.cpp:228] Iteration 1870, loss = 0.171402
I0403 05:53:12.246565 31448 solver.cpp:244]     Train net output #0: loss = 0.171402 (* 1 = 0.171402 loss)
I0403 05:53:12.449316 31448 sgd_solver.cpp:106] Iteration 1870, lr = 0.0005
I0403 05:53:15.941246 31448 solver.cpp:228] Iteration 1875, loss = 0.14422
I0403 05:53:15.941545 31448 solver.cpp:244]     Train net output #0: loss = 0.14422 (* 1 = 0.14422 loss)
I0403 05:53:16.105165 31448 sgd_solver.cpp:106] Iteration 1875, lr = 0.0005
I0403 05:53:19.665663 31448 solver.cpp:228] Iteration 1880, loss = 0.186957
I0403 05:53:19.665774 31448 solver.cpp:244]     Train net output #0: loss = 0.186957 (* 1 = 0.186957 loss)
I0403 05:53:19.851035 31448 sgd_solver.cpp:106] Iteration 1880, lr = 0.0005
I0403 05:53:23.344188 31448 solver.cpp:228] Iteration 1885, loss = 0.203318
I0403 05:53:23.344306 31448 solver.cpp:244]     Train net output #0: loss = 0.203318 (* 1 = 0.203318 loss)
I0403 05:53:23.556907 31448 sgd_solver.cpp:106] Iteration 1885, lr = 0.0005
I0403 05:53:26.466032 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1890.caffemodel
I0403 05:53:29.141047 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1890.solverstate
I0403 05:53:30.913594 31448 solver.cpp:337] Iteration 1890, Testing net (#0)
I0403 05:55:10.944332 31448 solver.cpp:404]     Test net output #0: accuracy = 0.851418
I0403 05:55:10.944646 31448 solver.cpp:404]     Test net output #1: loss = 0.541512 (* 1 = 0.541512 loss)
I0403 05:55:11.475703 31448 solver.cpp:228] Iteration 1890, loss = 0.0738146
I0403 05:55:11.476620 31448 solver.cpp:244]     Train net output #0: loss = 0.0738146 (* 1 = 0.0738146 loss)
I0403 05:55:11.640312 31448 sgd_solver.cpp:106] Iteration 1890, lr = 0.0005
I0403 05:55:15.194264 31448 solver.cpp:228] Iteration 1895, loss = 0.165736
I0403 05:55:15.194378 31448 solver.cpp:244]     Train net output #0: loss = 0.165736 (* 1 = 0.165736 loss)
I0403 05:55:15.344053 31448 sgd_solver.cpp:106] Iteration 1895, lr = 0.0005
I0403 05:55:18.933205 31448 solver.cpp:228] Iteration 1900, loss = 0.162704
I0403 05:55:18.933310 31448 solver.cpp:244]     Train net output #0: loss = 0.162704 (* 1 = 0.162704 loss)
I0403 05:55:19.083956 31448 sgd_solver.cpp:106] Iteration 1900, lr = 0.0005
I0403 05:55:22.582233 31448 solver.cpp:228] Iteration 1905, loss = 0.103177
I0403 05:55:22.582336 31448 solver.cpp:244]     Train net output #0: loss = 0.103177 (* 1 = 0.103177 loss)
I0403 05:55:22.762356 31448 sgd_solver.cpp:106] Iteration 1905, lr = 0.0005
I0403 05:55:26.208530 31448 solver.cpp:228] Iteration 1910, loss = 0.159125
I0403 05:55:26.208644 31448 solver.cpp:244]     Train net output #0: loss = 0.159125 (* 1 = 0.159125 loss)
I0403 05:55:26.424191 31448 sgd_solver.cpp:106] Iteration 1910, lr = 0.0005
I0403 05:55:29.926312 31448 solver.cpp:228] Iteration 1915, loss = 0.257553
I0403 05:55:29.926422 31448 solver.cpp:244]     Train net output #0: loss = 0.257553 (* 1 = 0.257553 loss)
I0403 05:55:30.109757 31448 sgd_solver.cpp:106] Iteration 1915, lr = 0.0005
I0403 05:55:33.598001 31448 solver.cpp:228] Iteration 1920, loss = 0.229978
I0403 05:55:33.598109 31448 solver.cpp:244]     Train net output #0: loss = 0.229978 (* 1 = 0.229978 loss)
I0403 05:55:33.787811 31448 sgd_solver.cpp:106] Iteration 1920, lr = 0.0005
I0403 05:55:37.265090 31448 solver.cpp:228] Iteration 1925, loss = 0.157768
I0403 05:55:37.265198 31448 solver.cpp:244]     Train net output #0: loss = 0.157768 (* 1 = 0.157768 loss)
I0403 05:55:37.448575 31448 sgd_solver.cpp:106] Iteration 1925, lr = 0.0005
I0403 05:55:40.916417 31448 solver.cpp:228] Iteration 1930, loss = 0.224757
I0403 05:55:40.916528 31448 solver.cpp:244]     Train net output #0: loss = 0.224757 (* 1 = 0.224757 loss)
I0403 05:55:41.104755 31448 sgd_solver.cpp:106] Iteration 1930, lr = 0.0005
I0403 05:55:44.526384 31448 solver.cpp:228] Iteration 1935, loss = 0.147309
I0403 05:55:44.526494 31448 solver.cpp:244]     Train net output #0: loss = 0.147309 (* 1 = 0.147309 loss)
I0403 05:55:44.744477 31448 sgd_solver.cpp:106] Iteration 1935, lr = 0.0005
I0403 05:55:48.242810 31448 solver.cpp:228] Iteration 1940, loss = 0.25237
I0403 05:55:48.242908 31448 solver.cpp:244]     Train net output #0: loss = 0.25237 (* 1 = 0.25237 loss)
I0403 05:55:48.421972 31448 sgd_solver.cpp:106] Iteration 1940, lr = 0.0005
I0403 05:55:51.876191 31448 solver.cpp:228] Iteration 1945, loss = 0.201993
I0403 05:55:51.876308 31448 solver.cpp:244]     Train net output #0: loss = 0.201993 (* 1 = 0.201993 loss)
I0403 05:55:52.059494 31448 sgd_solver.cpp:106] Iteration 1945, lr = 0.0005
I0403 05:55:55.660419 31448 solver.cpp:228] Iteration 1950, loss = 0.141594
I0403 05:55:55.660516 31448 solver.cpp:244]     Train net output #0: loss = 0.141594 (* 1 = 0.141594 loss)
I0403 05:55:55.840739 31448 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I0403 05:55:59.346525 31448 solver.cpp:228] Iteration 1955, loss = 0.0915956
I0403 05:55:59.346619 31448 solver.cpp:244]     Train net output #0: loss = 0.0915956 (* 1 = 0.0915956 loss)
I0403 05:55:59.519575 31448 sgd_solver.cpp:106] Iteration 1955, lr = 0.0005
I0403 05:56:02.988710 31448 solver.cpp:228] Iteration 1960, loss = 0.193764
I0403 05:56:02.988811 31448 solver.cpp:244]     Train net output #0: loss = 0.193764 (* 1 = 0.193764 loss)
I0403 05:56:03.164324 31448 sgd_solver.cpp:106] Iteration 1960, lr = 0.0005
I0403 05:56:06.779055 31448 solver.cpp:228] Iteration 1965, loss = 0.164965
I0403 05:56:06.779153 31448 solver.cpp:244]     Train net output #0: loss = 0.164965 (* 1 = 0.164965 loss)
I0403 05:56:06.954376 31448 sgd_solver.cpp:106] Iteration 1965, lr = 0.0005
I0403 05:56:10.412556 31448 solver.cpp:228] Iteration 1970, loss = 0.133295
I0403 05:56:10.413460 31448 solver.cpp:244]     Train net output #0: loss = 0.133295 (* 1 = 0.133295 loss)
I0403 05:56:10.579020 31448 sgd_solver.cpp:106] Iteration 1970, lr = 0.0005
I0403 05:56:14.069443 31448 solver.cpp:228] Iteration 1975, loss = 0.177436
I0403 05:56:14.069775 31448 solver.cpp:244]     Train net output #0: loss = 0.177436 (* 1 = 0.177436 loss)
I0403 05:56:14.253070 31448 sgd_solver.cpp:106] Iteration 1975, lr = 0.0005
I0403 05:56:17.732723 31448 solver.cpp:228] Iteration 1980, loss = 0.134661
I0403 05:56:17.732836 31448 solver.cpp:244]     Train net output #0: loss = 0.134661 (* 1 = 0.134661 loss)
I0403 05:56:17.915936 31448 sgd_solver.cpp:106] Iteration 1980, lr = 0.0005
I0403 05:56:21.449501 31448 solver.cpp:228] Iteration 1985, loss = 0.150377
I0403 05:56:21.449601 31448 solver.cpp:244]     Train net output #0: loss = 0.150377 (* 1 = 0.150377 loss)
I0403 05:56:21.601109 31448 sgd_solver.cpp:106] Iteration 1985, lr = 0.0005
I0403 05:56:25.164435 31448 solver.cpp:228] Iteration 1990, loss = 0.176222
I0403 05:56:25.164537 31448 solver.cpp:244]     Train net output #0: loss = 0.176222 (* 1 = 0.176222 loss)
I0403 05:56:25.341207 31448 sgd_solver.cpp:106] Iteration 1990, lr = 0.0005
I0403 05:56:28.284536 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1995.caffemodel
I0403 05:56:31.021075 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_1995.solverstate
I0403 05:56:32.802644 31448 solver.cpp:337] Iteration 1995, Testing net (#0)
I0403 05:58:12.828706 31448 solver.cpp:404]     Test net output #0: accuracy = 0.85199
I0403 05:58:12.829020 31448 solver.cpp:404]     Test net output #1: loss = 0.550177 (* 1 = 0.550177 loss)
I0403 05:58:13.355965 31448 solver.cpp:228] Iteration 1995, loss = 0.223514
I0403 05:58:13.356061 31448 solver.cpp:244]     Train net output #0: loss = 0.223514 (* 1 = 0.223514 loss)
I0403 05:58:13.514318 31448 sgd_solver.cpp:106] Iteration 1995, lr = 0.0005
I0403 05:58:17.005242 31448 solver.cpp:228] Iteration 2000, loss = 0.0999378
I0403 05:58:17.005345 31448 solver.cpp:244]     Train net output #0: loss = 0.0999378 (* 1 = 0.0999378 loss)
I0403 05:58:17.181304 31448 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I0403 05:58:20.634724 31448 solver.cpp:228] Iteration 2005, loss = 0.164515
I0403 05:58:20.634830 31448 solver.cpp:244]     Train net output #0: loss = 0.164515 (* 1 = 0.164515 loss)
I0403 05:58:20.818001 31448 sgd_solver.cpp:106] Iteration 2005, lr = 0.0005
I0403 05:58:24.244504 31448 solver.cpp:228] Iteration 2010, loss = 0.182118
I0403 05:58:24.244616 31448 solver.cpp:244]     Train net output #0: loss = 0.182118 (* 1 = 0.182118 loss)
I0403 05:58:24.457229 31448 sgd_solver.cpp:106] Iteration 2010, lr = 0.0005
I0403 05:58:27.918149 31448 solver.cpp:228] Iteration 2015, loss = 0.124765
I0403 05:58:27.918262 31448 solver.cpp:244]     Train net output #0: loss = 0.124765 (* 1 = 0.124765 loss)
I0403 05:58:28.105993 31448 sgd_solver.cpp:106] Iteration 2015, lr = 0.0005
I0403 05:58:31.588454 31448 solver.cpp:228] Iteration 2020, loss = 0.161901
I0403 05:58:31.588559 31448 solver.cpp:244]     Train net output #0: loss = 0.161901 (* 1 = 0.161901 loss)
I0403 05:58:31.773589 31448 sgd_solver.cpp:106] Iteration 2020, lr = 0.0005
I0403 05:58:35.243285 31448 solver.cpp:228] Iteration 2025, loss = 0.188138
I0403 05:58:35.243399 31448 solver.cpp:244]     Train net output #0: loss = 0.188138 (* 1 = 0.188138 loss)
I0403 05:58:35.471325 31448 sgd_solver.cpp:106] Iteration 2025, lr = 0.0005
I0403 05:58:38.936693 31448 solver.cpp:228] Iteration 2030, loss = 0.0629235
I0403 05:58:38.936803 31448 solver.cpp:244]     Train net output #0: loss = 0.0629235 (* 1 = 0.0629235 loss)
I0403 05:58:39.123888 31448 sgd_solver.cpp:106] Iteration 2030, lr = 0.0005
I0403 05:58:42.547668 31448 solver.cpp:228] Iteration 2035, loss = 0.104401
I0403 05:58:42.548763 31448 solver.cpp:244]     Train net output #0: loss = 0.104401 (* 1 = 0.104401 loss)
I0403 05:58:42.767853 31448 sgd_solver.cpp:106] Iteration 2035, lr = 0.0005
I0403 05:58:46.175815 31448 solver.cpp:228] Iteration 2040, loss = 0.0455709
I0403 05:58:46.176141 31448 solver.cpp:244]     Train net output #0: loss = 0.0455709 (* 1 = 0.0455709 loss)
I0403 05:58:46.354161 31448 sgd_solver.cpp:106] Iteration 2040, lr = 0.0005
I0403 05:58:49.830392 31448 solver.cpp:228] Iteration 2045, loss = 0.192719
I0403 05:58:49.830500 31448 solver.cpp:244]     Train net output #0: loss = 0.192719 (* 1 = 0.192719 loss)
I0403 05:58:50.040699 31448 sgd_solver.cpp:106] Iteration 2045, lr = 0.0005
I0403 05:58:53.520824 31448 solver.cpp:228] Iteration 2050, loss = 0.117138
I0403 05:58:53.520923 31448 solver.cpp:244]     Train net output #0: loss = 0.117138 (* 1 = 0.117138 loss)
I0403 05:58:53.687458 31448 sgd_solver.cpp:106] Iteration 2050, lr = 0.0005
I0403 05:58:57.195478 31448 solver.cpp:228] Iteration 2055, loss = 0.138421
I0403 05:58:57.195579 31448 solver.cpp:244]     Train net output #0: loss = 0.138421 (* 1 = 0.138421 loss)
I0403 05:58:57.366281 31448 sgd_solver.cpp:106] Iteration 2055, lr = 0.0005
I0403 05:59:01.033670 31448 solver.cpp:228] Iteration 2060, loss = 0.133103
I0403 05:59:01.033769 31448 solver.cpp:244]     Train net output #0: loss = 0.133103 (* 1 = 0.133103 loss)
I0403 05:59:01.211375 31448 sgd_solver.cpp:106] Iteration 2060, lr = 0.0005
I0403 05:59:04.735271 31448 solver.cpp:228] Iteration 2065, loss = 0.114817
I0403 05:59:04.735376 31448 solver.cpp:244]     Train net output #0: loss = 0.114817 (* 1 = 0.114817 loss)
I0403 05:59:04.905550 31448 sgd_solver.cpp:106] Iteration 2065, lr = 0.0005
I0403 05:59:08.384368 31448 solver.cpp:228] Iteration 2070, loss = 0.0616832
I0403 05:59:08.384479 31448 solver.cpp:244]     Train net output #0: loss = 0.0616832 (* 1 = 0.0616832 loss)
I0403 05:59:08.567628 31448 sgd_solver.cpp:106] Iteration 2070, lr = 0.0005
I0403 05:59:12.017011 31448 solver.cpp:228] Iteration 2075, loss = 0.157025
I0403 05:59:12.017119 31448 solver.cpp:244]     Train net output #0: loss = 0.157025 (* 1 = 0.157025 loss)
I0403 05:59:12.205656 31448 sgd_solver.cpp:106] Iteration 2075, lr = 0.0005
I0403 05:59:15.661201 31448 solver.cpp:228] Iteration 2080, loss = 0.119557
I0403 05:59:15.661303 31448 solver.cpp:244]     Train net output #0: loss = 0.119557 (* 1 = 0.119557 loss)
I0403 05:59:15.840029 31448 sgd_solver.cpp:106] Iteration 2080, lr = 0.0005
I0403 05:59:19.294996 31448 solver.cpp:228] Iteration 2085, loss = 0.0914576
I0403 05:59:19.295251 31448 solver.cpp:244]     Train net output #0: loss = 0.0914576 (* 1 = 0.0914576 loss)
I0403 05:59:19.487490 31448 sgd_solver.cpp:106] Iteration 2085, lr = 0.0005
I0403 05:59:22.896066 31448 solver.cpp:228] Iteration 2090, loss = 0.0865673
I0403 05:59:22.896167 31448 solver.cpp:244]     Train net output #0: loss = 0.0865673 (* 1 = 0.0865673 loss)
I0403 05:59:23.074558 31448 sgd_solver.cpp:106] Iteration 2090, lr = 0.0005
I0403 05:59:26.591734 31448 solver.cpp:228] Iteration 2095, loss = 0.120702
I0403 05:59:26.591833 31448 solver.cpp:244]     Train net output #0: loss = 0.120702 (* 1 = 0.120702 loss)
I0403 05:59:26.768965 31448 sgd_solver.cpp:106] Iteration 2095, lr = 0.0005
I0403 05:59:29.687980 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2100.caffemodel
I0403 05:59:32.433408 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2100.solverstate
I0403 05:59:34.257454 31448 solver.cpp:337] Iteration 2100, Testing net (#0)
I0403 06:01:14.271809 31448 solver.cpp:404]     Test net output #0: accuracy = 0.850824
I0403 06:01:14.272143 31448 solver.cpp:404]     Test net output #1: loss = 0.558609 (* 1 = 0.558609 loss)
I0403 06:01:14.818502 31448 solver.cpp:228] Iteration 2100, loss = 0.172684
I0403 06:01:14.818598 31448 solver.cpp:244]     Train net output #0: loss = 0.172684 (* 1 = 0.172684 loss)
I0403 06:01:14.958745 31448 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0403 06:01:18.586383 31448 solver.cpp:228] Iteration 2105, loss = 0.116437
I0403 06:01:18.586483 31448 solver.cpp:244]     Train net output #0: loss = 0.116437 (* 1 = 0.116437 loss)
I0403 06:01:18.764500 31448 sgd_solver.cpp:106] Iteration 2105, lr = 0.0005
I0403 06:01:22.225239 31448 solver.cpp:228] Iteration 2110, loss = 0.0672473
I0403 06:01:22.225355 31448 solver.cpp:244]     Train net output #0: loss = 0.0672474 (* 1 = 0.0672474 loss)
I0403 06:01:22.424154 31448 sgd_solver.cpp:106] Iteration 2110, lr = 0.0005
I0403 06:01:25.919278 31448 solver.cpp:228] Iteration 2115, loss = 0.181344
I0403 06:01:25.919387 31448 solver.cpp:244]     Train net output #0: loss = 0.181344 (* 1 = 0.181344 loss)
I0403 06:01:26.150634 31448 sgd_solver.cpp:106] Iteration 2115, lr = 5e-05
I0403 06:01:29.834617 31448 solver.cpp:228] Iteration 2120, loss = 0.148958
I0403 06:01:29.834714 31448 solver.cpp:244]     Train net output #0: loss = 0.148958 (* 1 = 0.148958 loss)
I0403 06:01:30.006204 31448 sgd_solver.cpp:106] Iteration 2120, lr = 5e-05
I0403 06:01:33.486883 31448 solver.cpp:228] Iteration 2125, loss = 0.190623
I0403 06:01:33.486982 31448 solver.cpp:244]     Train net output #0: loss = 0.190623 (* 1 = 0.190623 loss)
I0403 06:01:33.650943 31448 sgd_solver.cpp:106] Iteration 2125, lr = 5e-05
I0403 06:01:37.114976 31448 solver.cpp:228] Iteration 2130, loss = 0.199436
I0403 06:01:37.115089 31448 solver.cpp:244]     Train net output #0: loss = 0.199436 (* 1 = 0.199436 loss)
I0403 06:01:37.301091 31448 sgd_solver.cpp:106] Iteration 2130, lr = 5e-05
I0403 06:01:40.728282 31448 solver.cpp:228] Iteration 2135, loss = 0.103968
I0403 06:01:40.728391 31448 solver.cpp:244]     Train net output #0: loss = 0.103968 (* 1 = 0.103968 loss)
I0403 06:01:40.914806 31448 sgd_solver.cpp:106] Iteration 2135, lr = 5e-05
I0403 06:01:44.347159 31448 solver.cpp:228] Iteration 2140, loss = 0.0924436
I0403 06:01:44.347445 31448 solver.cpp:244]     Train net output #0: loss = 0.0924436 (* 1 = 0.0924436 loss)
I0403 06:01:44.540912 31448 sgd_solver.cpp:106] Iteration 2140, lr = 5e-05
I0403 06:01:47.970151 31448 solver.cpp:228] Iteration 2145, loss = 0.146925
I0403 06:01:47.970265 31448 solver.cpp:244]     Train net output #0: loss = 0.146925 (* 1 = 0.146925 loss)
I0403 06:01:48.175060 31448 sgd_solver.cpp:106] Iteration 2145, lr = 5e-05
I0403 06:01:51.664685 31448 solver.cpp:228] Iteration 2150, loss = 0.0878668
I0403 06:01:51.664783 31448 solver.cpp:244]     Train net output #0: loss = 0.0878668 (* 1 = 0.0878668 loss)
I0403 06:01:51.832913 31448 sgd_solver.cpp:106] Iteration 2150, lr = 5e-05
I0403 06:01:55.366052 31448 solver.cpp:228] Iteration 2155, loss = 0.138335
I0403 06:01:55.366152 31448 solver.cpp:244]     Train net output #0: loss = 0.138335 (* 1 = 0.138335 loss)
I0403 06:01:55.540141 31448 sgd_solver.cpp:106] Iteration 2155, lr = 5e-05
I0403 06:01:59.058828 31448 solver.cpp:228] Iteration 2160, loss = 0.139633
I0403 06:01:59.058930 31448 solver.cpp:244]     Train net output #0: loss = 0.139633 (* 1 = 0.139633 loss)
I0403 06:01:59.236276 31448 sgd_solver.cpp:106] Iteration 2160, lr = 5e-05
I0403 06:02:02.735265 31448 solver.cpp:228] Iteration 2165, loss = 0.124269
I0403 06:02:02.735379 31448 solver.cpp:244]     Train net output #0: loss = 0.124269 (* 1 = 0.124269 loss)
I0403 06:02:02.918709 31448 sgd_solver.cpp:106] Iteration 2165, lr = 5e-05
I0403 06:02:06.402669 31448 solver.cpp:228] Iteration 2170, loss = 0.189335
I0403 06:02:06.402765 31448 solver.cpp:244]     Train net output #0: loss = 0.189335 (* 1 = 0.189335 loss)
I0403 06:02:06.580613 31448 sgd_solver.cpp:106] Iteration 2170, lr = 5e-05
I0403 06:02:10.043762 31448 solver.cpp:228] Iteration 2175, loss = 0.121217
I0403 06:02:10.043867 31448 solver.cpp:244]     Train net output #0: loss = 0.121217 (* 1 = 0.121217 loss)
I0403 06:02:10.238127 31448 sgd_solver.cpp:106] Iteration 2175, lr = 5e-05
I0403 06:02:13.705502 31448 solver.cpp:228] Iteration 2180, loss = 0.171577
I0403 06:02:13.706423 31448 solver.cpp:244]     Train net output #0: loss = 0.171577 (* 1 = 0.171577 loss)
I0403 06:02:13.883669 31448 sgd_solver.cpp:106] Iteration 2180, lr = 5e-05
I0403 06:02:17.372149 31448 solver.cpp:228] Iteration 2185, loss = 0.266212
I0403 06:02:17.372478 31448 solver.cpp:244]     Train net output #0: loss = 0.266212 (* 1 = 0.266212 loss)
I0403 06:02:17.551694 31448 sgd_solver.cpp:106] Iteration 2185, lr = 5e-05
I0403 06:02:21.007683 31448 solver.cpp:228] Iteration 2190, loss = 0.0818014
I0403 06:02:21.007781 31448 solver.cpp:244]     Train net output #0: loss = 0.0818014 (* 1 = 0.0818014 loss)
I0403 06:02:21.184160 31448 sgd_solver.cpp:106] Iteration 2190, lr = 5e-05
I0403 06:02:24.642592 31448 solver.cpp:228] Iteration 2195, loss = 0.0776184
I0403 06:02:24.642702 31448 solver.cpp:244]     Train net output #0: loss = 0.0776184 (* 1 = 0.0776184 loss)
I0403 06:02:24.826190 31448 sgd_solver.cpp:106] Iteration 2195, lr = 5e-05
I0403 06:02:28.237844 31448 solver.cpp:228] Iteration 2200, loss = 0.149768
I0403 06:02:28.237954 31448 solver.cpp:244]     Train net output #0: loss = 0.149768 (* 1 = 0.149768 loss)
I0403 06:02:28.433754 31448 sgd_solver.cpp:106] Iteration 2200, lr = 5e-05
I0403 06:02:31.308168 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2205.caffemodel
I0403 06:02:33.993579 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2205.solverstate
I0403 06:02:35.812455 31448 solver.cpp:337] Iteration 2205, Testing net (#0)
I0403 06:04:15.854290 31448 solver.cpp:404]     Test net output #0: accuracy = 0.852746
I0403 06:04:15.854578 31448 solver.cpp:404]     Test net output #1: loss = 0.554883 (* 1 = 0.554883 loss)
I0403 06:04:16.368355 31448 solver.cpp:228] Iteration 2205, loss = 0.177565
I0403 06:04:16.368451 31448 solver.cpp:244]     Train net output #0: loss = 0.177565 (* 1 = 0.177565 loss)
I0403 06:04:16.544862 31448 sgd_solver.cpp:106] Iteration 2205, lr = 5e-05
I0403 06:04:19.982241 31448 solver.cpp:228] Iteration 2210, loss = 0.142506
I0403 06:04:19.982347 31448 solver.cpp:244]     Train net output #0: loss = 0.142506 (* 1 = 0.142506 loss)
I0403 06:04:20.150743 31448 sgd_solver.cpp:106] Iteration 2210, lr = 5e-05
I0403 06:04:23.635660 31448 solver.cpp:228] Iteration 2215, loss = 0.102885
I0403 06:04:23.635769 31448 solver.cpp:244]     Train net output #0: loss = 0.102885 (* 1 = 0.102885 loss)
I0403 06:04:23.828264 31448 sgd_solver.cpp:106] Iteration 2215, lr = 5e-05
I0403 06:04:27.253880 31448 solver.cpp:228] Iteration 2220, loss = 0.107136
I0403 06:04:27.253990 31448 solver.cpp:244]     Train net output #0: loss = 0.107136 (* 1 = 0.107136 loss)
I0403 06:04:27.437124 31448 sgd_solver.cpp:106] Iteration 2220, lr = 5e-05
I0403 06:04:30.860188 31448 solver.cpp:228] Iteration 2225, loss = 0.193644
I0403 06:04:30.860290 31448 solver.cpp:244]     Train net output #0: loss = 0.193644 (* 1 = 0.193644 loss)
I0403 06:04:31.021673 31448 sgd_solver.cpp:106] Iteration 2225, lr = 5e-05
I0403 06:04:34.527837 31448 solver.cpp:228] Iteration 2230, loss = 0.131144
I0403 06:04:34.527935 31448 solver.cpp:244]     Train net output #0: loss = 0.131144 (* 1 = 0.131144 loss)
I0403 06:04:34.709663 31448 sgd_solver.cpp:106] Iteration 2230, lr = 5e-05
I0403 06:04:38.197468 31448 solver.cpp:228] Iteration 2235, loss = 0.15116
I0403 06:04:38.197577 31448 solver.cpp:244]     Train net output #0: loss = 0.15116 (* 1 = 0.15116 loss)
I0403 06:04:38.381878 31448 sgd_solver.cpp:106] Iteration 2235, lr = 5e-05
I0403 06:04:41.836575 31448 solver.cpp:228] Iteration 2240, loss = 0.0990537
I0403 06:04:41.836673 31448 solver.cpp:244]     Train net output #0: loss = 0.0990537 (* 1 = 0.0990537 loss)
I0403 06:04:42.012343 31448 sgd_solver.cpp:106] Iteration 2240, lr = 5e-05
I0403 06:04:45.484697 31448 solver.cpp:228] Iteration 2245, loss = 0.142075
I0403 06:04:45.484792 31448 solver.cpp:244]     Train net output #0: loss = 0.142075 (* 1 = 0.142075 loss)
I0403 06:04:45.662053 31448 sgd_solver.cpp:106] Iteration 2245, lr = 5e-05
I0403 06:04:49.237313 31448 solver.cpp:228] Iteration 2250, loss = 0.0998729
I0403 06:04:49.237663 31448 solver.cpp:244]     Train net output #0: loss = 0.0998729 (* 1 = 0.0998729 loss)
I0403 06:04:49.448055 31448 sgd_solver.cpp:106] Iteration 2250, lr = 5e-05
I0403 06:04:53.011909 31448 solver.cpp:228] Iteration 2255, loss = 0.0758377
I0403 06:04:53.012024 31448 solver.cpp:244]     Train net output #0: loss = 0.0758377 (* 1 = 0.0758377 loss)
I0403 06:04:53.199892 31448 sgd_solver.cpp:106] Iteration 2255, lr = 5e-05
I0403 06:04:56.643056 31448 solver.cpp:228] Iteration 2260, loss = 0.0962857
I0403 06:04:56.643168 31448 solver.cpp:244]     Train net output #0: loss = 0.0962857 (* 1 = 0.0962857 loss)
I0403 06:04:56.830281 31448 sgd_solver.cpp:106] Iteration 2260, lr = 5e-05
I0403 06:05:00.300559 31448 solver.cpp:228] Iteration 2265, loss = 0.149919
I0403 06:05:00.300658 31448 solver.cpp:244]     Train net output #0: loss = 0.149919 (* 1 = 0.149919 loss)
I0403 06:05:00.474470 31448 sgd_solver.cpp:106] Iteration 2265, lr = 5e-05
I0403 06:05:03.937404 31448 solver.cpp:228] Iteration 2270, loss = 0.043596
I0403 06:05:03.937505 31448 solver.cpp:244]     Train net output #0: loss = 0.043596 (* 1 = 0.043596 loss)
I0403 06:05:04.110036 31448 sgd_solver.cpp:106] Iteration 2270, lr = 5e-05
I0403 06:05:07.702040 31448 solver.cpp:228] Iteration 2275, loss = 0.130911
I0403 06:05:07.702148 31448 solver.cpp:244]     Train net output #0: loss = 0.130911 (* 1 = 0.130911 loss)
I0403 06:05:07.887349 31448 sgd_solver.cpp:106] Iteration 2275, lr = 5e-05
I0403 06:05:11.327935 31448 solver.cpp:228] Iteration 2280, loss = 0.0945733
I0403 06:05:11.328045 31448 solver.cpp:244]     Train net output #0: loss = 0.0945733 (* 1 = 0.0945733 loss)
I0403 06:05:11.521740 31448 sgd_solver.cpp:106] Iteration 2280, lr = 5e-05
I0403 06:05:15.029577 31448 solver.cpp:228] Iteration 2285, loss = 0.12993
I0403 06:05:15.029675 31448 solver.cpp:244]     Train net output #0: loss = 0.12993 (* 1 = 0.12993 loss)
I0403 06:05:15.204653 31448 sgd_solver.cpp:106] Iteration 2285, lr = 5e-05
I0403 06:05:18.736858 31448 solver.cpp:228] Iteration 2290, loss = 0.237024
I0403 06:05:18.736958 31448 solver.cpp:244]     Train net output #0: loss = 0.237024 (* 1 = 0.237024 loss)
I0403 06:05:18.919881 31448 sgd_solver.cpp:106] Iteration 2290, lr = 5e-05
I0403 06:05:22.340672 31448 solver.cpp:228] Iteration 2295, loss = 0.0696817
I0403 06:05:22.340991 31448 solver.cpp:244]     Train net output #0: loss = 0.0696817 (* 1 = 0.0696817 loss)
I0403 06:05:22.525774 31448 sgd_solver.cpp:106] Iteration 2295, lr = 5e-05
I0403 06:05:26.076089 31448 solver.cpp:228] Iteration 2300, loss = 0.0955844
I0403 06:05:26.076189 31448 solver.cpp:244]     Train net output #0: loss = 0.0955844 (* 1 = 0.0955844 loss)
I0403 06:05:26.238929 31448 sgd_solver.cpp:106] Iteration 2300, lr = 5e-05
I0403 06:05:29.802536 31448 solver.cpp:228] Iteration 2305, loss = 0.115625
I0403 06:05:29.802647 31448 solver.cpp:244]     Train net output #0: loss = 0.115625 (* 1 = 0.115625 loss)
I0403 06:05:29.989354 31448 sgd_solver.cpp:106] Iteration 2305, lr = 5e-05
I0403 06:05:32.876787 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2310.caffemodel
I0403 06:05:35.649178 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2310.solverstate
I0403 06:05:37.526377 31448 solver.cpp:337] Iteration 2310, Testing net (#0)
I0403 06:07:17.541581 31448 solver.cpp:404]     Test net output #0: accuracy = 0.853799
I0403 06:07:17.541880 31448 solver.cpp:404]     Test net output #1: loss = 0.550808 (* 1 = 0.550808 loss)
I0403 06:07:18.064687 31448 solver.cpp:228] Iteration 2310, loss = 0.0973715
I0403 06:07:18.064782 31448 solver.cpp:244]     Train net output #0: loss = 0.0973715 (* 1 = 0.0973715 loss)
I0403 06:07:18.234875 31448 sgd_solver.cpp:106] Iteration 2310, lr = 5e-05
I0403 06:07:21.716167 31448 solver.cpp:228] Iteration 2315, loss = 0.110943
I0403 06:07:21.716260 31448 solver.cpp:244]     Train net output #0: loss = 0.110943 (* 1 = 0.110943 loss)
I0403 06:07:21.892935 31448 sgd_solver.cpp:106] Iteration 2315, lr = 5e-05
I0403 06:07:25.412911 31448 solver.cpp:228] Iteration 2320, loss = 0.141089
I0403 06:07:25.413008 31448 solver.cpp:244]     Train net output #0: loss = 0.141089 (* 1 = 0.141089 loss)
I0403 06:07:25.592149 31448 sgd_solver.cpp:106] Iteration 2320, lr = 5e-05
I0403 06:07:29.047796 31448 solver.cpp:228] Iteration 2325, loss = 0.0896567
I0403 06:07:29.047909 31448 solver.cpp:244]     Train net output #0: loss = 0.0896567 (* 1 = 0.0896567 loss)
I0403 06:07:29.256850 31448 sgd_solver.cpp:106] Iteration 2325, lr = 5e-05
I0403 06:07:32.748684 31448 solver.cpp:228] Iteration 2330, loss = 0.17939
I0403 06:07:32.748782 31448 solver.cpp:244]     Train net output #0: loss = 0.17939 (* 1 = 0.17939 loss)
I0403 06:07:32.920172 31448 sgd_solver.cpp:106] Iteration 2330, lr = 5e-05
I0403 06:07:36.533022 31448 solver.cpp:228] Iteration 2335, loss = 0.104437
I0403 06:07:36.533130 31448 solver.cpp:244]     Train net output #0: loss = 0.104437 (* 1 = 0.104437 loss)
I0403 06:07:36.716536 31448 sgd_solver.cpp:106] Iteration 2335, lr = 5e-05
I0403 06:07:40.115576 31448 solver.cpp:228] Iteration 2340, loss = 0.208884
I0403 06:07:40.115687 31448 solver.cpp:244]     Train net output #0: loss = 0.208884 (* 1 = 0.208884 loss)
I0403 06:07:40.294721 31448 sgd_solver.cpp:106] Iteration 2340, lr = 5e-05
I0403 06:07:43.736232 31448 solver.cpp:228] Iteration 2345, loss = 0.144711
I0403 06:07:43.736333 31448 solver.cpp:244]     Train net output #0: loss = 0.144711 (* 1 = 0.144711 loss)
I0403 06:07:43.911579 31448 sgd_solver.cpp:106] Iteration 2345, lr = 5e-05
I0403 06:07:47.440726 31448 solver.cpp:228] Iteration 2350, loss = 0.110159
I0403 06:07:47.440839 31448 solver.cpp:244]     Train net output #0: loss = 0.110159 (* 1 = 0.110159 loss)
I0403 06:07:47.638797 31448 sgd_solver.cpp:106] Iteration 2350, lr = 5e-05
I0403 06:07:51.036967 31448 solver.cpp:228] Iteration 2355, loss = 0.103994
I0403 06:07:51.037077 31448 solver.cpp:244]     Train net output #0: loss = 0.103994 (* 1 = 0.103994 loss)
I0403 06:07:51.232439 31448 sgd_solver.cpp:106] Iteration 2355, lr = 5e-05
I0403 06:07:54.639669 31448 solver.cpp:228] Iteration 2360, loss = 0.077832
I0403 06:07:54.639770 31448 solver.cpp:244]     Train net output #0: loss = 0.077832 (* 1 = 0.077832 loss)
I0403 06:07:54.820788 31448 sgd_solver.cpp:106] Iteration 2360, lr = 5e-05
I0403 06:07:58.247916 31448 solver.cpp:228] Iteration 2365, loss = 0.195153
I0403 06:07:58.248025 31448 solver.cpp:244]     Train net output #0: loss = 0.195153 (* 1 = 0.195153 loss)
I0403 06:07:58.439425 31448 sgd_solver.cpp:106] Iteration 2365, lr = 5e-05
I0403 06:08:01.916887 31448 solver.cpp:228] Iteration 2370, loss = 0.107683
I0403 06:08:01.916986 31448 solver.cpp:244]     Train net output #0: loss = 0.107683 (* 1 = 0.107683 loss)
I0403 06:08:02.095049 31448 sgd_solver.cpp:106] Iteration 2370, lr = 5e-05
I0403 06:08:05.587898 31448 solver.cpp:228] Iteration 2375, loss = 0.128925
I0403 06:08:05.587998 31448 solver.cpp:244]     Train net output #0: loss = 0.128925 (* 1 = 0.128925 loss)
I0403 06:08:05.746109 31448 sgd_solver.cpp:106] Iteration 2375, lr = 5e-05
I0403 06:08:09.273262 31448 solver.cpp:228] Iteration 2380, loss = 0.0767248
I0403 06:08:09.273375 31448 solver.cpp:244]     Train net output #0: loss = 0.0767248 (* 1 = 0.0767248 loss)
I0403 06:08:09.453188 31448 sgd_solver.cpp:106] Iteration 2380, lr = 5e-05
I0403 06:08:12.930421 31448 solver.cpp:228] Iteration 2385, loss = 0.144264
I0403 06:08:12.930519 31448 solver.cpp:244]     Train net output #0: loss = 0.144264 (* 1 = 0.144264 loss)
I0403 06:08:13.076668 31448 sgd_solver.cpp:106] Iteration 2385, lr = 5e-05
I0403 06:08:16.590733 31448 solver.cpp:228] Iteration 2390, loss = 0.202622
I0403 06:08:16.590838 31448 solver.cpp:244]     Train net output #0: loss = 0.202622 (* 1 = 0.202622 loss)
I0403 06:08:16.784037 31448 sgd_solver.cpp:106] Iteration 2390, lr = 5e-05
I0403 06:08:20.204879 31448 solver.cpp:228] Iteration 2395, loss = 0.297208
I0403 06:08:20.205224 31448 solver.cpp:244]     Train net output #0: loss = 0.297208 (* 1 = 0.297208 loss)
I0403 06:08:20.397150 31448 sgd_solver.cpp:106] Iteration 2395, lr = 5e-05
I0403 06:08:23.970552 31448 solver.cpp:228] Iteration 2400, loss = 0.0973539
I0403 06:08:23.970654 31448 solver.cpp:244]     Train net output #0: loss = 0.0973539 (* 1 = 0.0973539 loss)
I0403 06:08:24.137109 31448 sgd_solver.cpp:106] Iteration 2400, lr = 5e-05
I0403 06:08:27.647799 31448 solver.cpp:228] Iteration 2405, loss = 0.0770139
I0403 06:08:27.647896 31448 solver.cpp:244]     Train net output #0: loss = 0.0770139 (* 1 = 0.0770139 loss)
I0403 06:08:27.827042 31448 sgd_solver.cpp:106] Iteration 2405, lr = 5e-05
I0403 06:08:31.331331 31448 solver.cpp:228] Iteration 2410, loss = 0.121255
I0403 06:08:31.331429 31448 solver.cpp:244]     Train net output #0: loss = 0.121255 (* 1 = 0.121255 loss)
I0403 06:08:31.509963 31448 sgd_solver.cpp:106] Iteration 2410, lr = 5e-05
I0403 06:08:34.453951 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2415.caffemodel
I0403 06:08:37.216764 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2415.solverstate
I0403 06:08:39.084813 31448 solver.cpp:337] Iteration 2415, Testing net (#0)
I0403 06:10:19.105347 31448 solver.cpp:404]     Test net output #0: accuracy = 0.854553
I0403 06:10:19.105661 31448 solver.cpp:404]     Test net output #1: loss = 0.548507 (* 1 = 0.548507 loss)
I0403 06:10:19.631994 31448 solver.cpp:228] Iteration 2415, loss = 0.104329
I0403 06:10:19.632092 31448 solver.cpp:244]     Train net output #0: loss = 0.104329 (* 1 = 0.104329 loss)
I0403 06:10:19.792754 31448 sgd_solver.cpp:106] Iteration 2415, lr = 5e-05
I0403 06:10:23.266384 31448 solver.cpp:228] Iteration 2420, loss = 0.110599
I0403 06:10:23.266495 31448 solver.cpp:244]     Train net output #0: loss = 0.110599 (* 1 = 0.110599 loss)
I0403 06:10:23.452797 31448 sgd_solver.cpp:106] Iteration 2420, lr = 5e-05
I0403 06:10:27.025849 31448 solver.cpp:228] Iteration 2425, loss = 0.235082
I0403 06:10:27.025948 31448 solver.cpp:244]     Train net output #0: loss = 0.235082 (* 1 = 0.235082 loss)
I0403 06:10:27.193900 31448 sgd_solver.cpp:106] Iteration 2425, lr = 5e-05
I0403 06:10:30.855645 31448 solver.cpp:228] Iteration 2430, loss = 0.134282
I0403 06:10:30.855747 31448 solver.cpp:244]     Train net output #0: loss = 0.134282 (* 1 = 0.134282 loss)
I0403 06:10:30.990581 31448 sgd_solver.cpp:106] Iteration 2430, lr = 5e-05
I0403 06:10:34.546669 31448 solver.cpp:228] Iteration 2435, loss = 0.231051
I0403 06:10:34.546768 31448 solver.cpp:244]     Train net output #0: loss = 0.231051 (* 1 = 0.231051 loss)
I0403 06:10:34.711570 31448 sgd_solver.cpp:106] Iteration 2435, lr = 5e-05
I0403 06:10:38.208009 31448 solver.cpp:228] Iteration 2440, loss = 0.0938661
I0403 06:10:38.208108 31448 solver.cpp:244]     Train net output #0: loss = 0.0938661 (* 1 = 0.0938661 loss)
I0403 06:10:38.364328 31448 sgd_solver.cpp:106] Iteration 2440, lr = 5e-05
I0403 06:10:41.910437 31448 solver.cpp:228] Iteration 2445, loss = 0.13295
I0403 06:10:41.910538 31448 solver.cpp:244]     Train net output #0: loss = 0.13295 (* 1 = 0.13295 loss)
I0403 06:10:42.089396 31448 sgd_solver.cpp:106] Iteration 2445, lr = 5e-05
I0403 06:10:45.609141 31448 solver.cpp:228] Iteration 2450, loss = 0.184183
I0403 06:10:45.609239 31448 solver.cpp:244]     Train net output #0: loss = 0.184183 (* 1 = 0.184183 loss)
I0403 06:10:45.786478 31448 sgd_solver.cpp:106] Iteration 2450, lr = 5e-05
I0403 06:10:49.378355 31448 solver.cpp:228] Iteration 2455, loss = 0.066955
I0403 06:10:49.378686 31448 solver.cpp:244]     Train net output #0: loss = 0.0669549 (* 1 = 0.0669549 loss)
I0403 06:10:49.550182 31448 sgd_solver.cpp:106] Iteration 2455, lr = 5e-05
I0403 06:10:53.029564 31448 solver.cpp:228] Iteration 2460, loss = 0.138159
I0403 06:10:53.029664 31448 solver.cpp:244]     Train net output #0: loss = 0.138159 (* 1 = 0.138159 loss)
I0403 06:10:53.208237 31448 sgd_solver.cpp:106] Iteration 2460, lr = 5e-05
I0403 06:10:56.684519 31448 solver.cpp:228] Iteration 2465, loss = 0.0993622
I0403 06:10:56.684617 31448 solver.cpp:244]     Train net output #0: loss = 0.0993622 (* 1 = 0.0993622 loss)
I0403 06:10:56.856215 31448 sgd_solver.cpp:106] Iteration 2465, lr = 5e-05
I0403 06:11:00.328755 31448 solver.cpp:228] Iteration 2470, loss = 0.109055
I0403 06:11:00.328868 31448 solver.cpp:244]     Train net output #0: loss = 0.109055 (* 1 = 0.109055 loss)
I0403 06:11:00.538024 31448 sgd_solver.cpp:106] Iteration 2470, lr = 5e-05
I0403 06:11:03.957787 31448 solver.cpp:228] Iteration 2475, loss = 0.0861885
I0403 06:11:03.957901 31448 solver.cpp:244]     Train net output #0: loss = 0.0861885 (* 1 = 0.0861885 loss)
I0403 06:11:04.152259 31448 sgd_solver.cpp:106] Iteration 2475, lr = 5e-05
I0403 06:11:07.610081 31448 solver.cpp:228] Iteration 2480, loss = 0.0967861
I0403 06:11:07.610180 31448 solver.cpp:244]     Train net output #0: loss = 0.0967861 (* 1 = 0.0967861 loss)
I0403 06:11:07.791086 31448 sgd_solver.cpp:106] Iteration 2480, lr = 5e-05
I0403 06:11:11.232290 31448 solver.cpp:228] Iteration 2485, loss = 0.192177
I0403 06:11:11.232401 31448 solver.cpp:244]     Train net output #0: loss = 0.192177 (* 1 = 0.192177 loss)
I0403 06:11:11.437484 31448 sgd_solver.cpp:106] Iteration 2485, lr = 5e-05
I0403 06:11:14.853976 31448 solver.cpp:228] Iteration 2490, loss = 0.192087
I0403 06:11:14.854087 31448 solver.cpp:244]     Train net output #0: loss = 0.192087 (* 1 = 0.192087 loss)
I0403 06:11:15.051007 31448 sgd_solver.cpp:106] Iteration 2490, lr = 5e-05
I0403 06:11:18.557947 31448 solver.cpp:228] Iteration 2495, loss = 0.101614
I0403 06:11:18.558051 31448 solver.cpp:244]     Train net output #0: loss = 0.101614 (* 1 = 0.101614 loss)
I0403 06:11:18.741739 31448 sgd_solver.cpp:106] Iteration 2495, lr = 5e-05
I0403 06:11:22.245980 31448 solver.cpp:228] Iteration 2500, loss = 0.127767
I0403 06:11:22.246299 31448 solver.cpp:244]     Train net output #0: loss = 0.127767 (* 1 = 0.127767 loss)
I0403 06:11:22.431325 31448 sgd_solver.cpp:106] Iteration 2500, lr = 5e-05
I0403 06:11:25.873316 31448 solver.cpp:228] Iteration 2505, loss = 0.134654
I0403 06:11:25.873422 31448 solver.cpp:244]     Train net output #0: loss = 0.134654 (* 1 = 0.134654 loss)
I0403 06:11:26.068159 31448 sgd_solver.cpp:106] Iteration 2505, lr = 5e-05
I0403 06:11:29.506743 31448 solver.cpp:228] Iteration 2510, loss = 0.123495
I0403 06:11:29.506855 31448 solver.cpp:244]     Train net output #0: loss = 0.123495 (* 1 = 0.123495 loss)
I0403 06:11:29.714918 31448 sgd_solver.cpp:106] Iteration 2510, lr = 5e-05
I0403 06:11:33.179770 31448 solver.cpp:228] Iteration 2515, loss = 0.121794
I0403 06:11:33.179868 31448 solver.cpp:244]     Train net output #0: loss = 0.121794 (* 1 = 0.121794 loss)
I0403 06:11:33.342608 31448 sgd_solver.cpp:106] Iteration 2515, lr = 5e-05
I0403 06:11:36.334909 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2520.caffemodel
I0403 06:11:39.093749 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2520.solverstate
I0403 06:11:40.994572 31448 solver.cpp:337] Iteration 2520, Testing net (#0)
I0403 06:13:21.024484 31448 solver.cpp:404]     Test net output #0: accuracy = 0.85437
I0403 06:13:21.024785 31448 solver.cpp:404]     Test net output #1: loss = 0.547352 (* 1 = 0.547352 loss)
I0403 06:13:21.578793 31448 solver.cpp:228] Iteration 2520, loss = 0.120024
I0403 06:13:21.578886 31448 solver.cpp:244]     Train net output #0: loss = 0.120024 (* 1 = 0.120024 loss)
I0403 06:13:21.704546 31448 sgd_solver.cpp:106] Iteration 2520, lr = 5e-05
I0403 06:13:25.316965 31448 solver.cpp:228] Iteration 2525, loss = 0.0712329
I0403 06:13:25.317065 31448 solver.cpp:244]     Train net output #0: loss = 0.0712329 (* 1 = 0.0712329 loss)
I0403 06:13:25.494830 31448 sgd_solver.cpp:106] Iteration 2525, lr = 5e-05
I0403 06:13:28.983572 31448 solver.cpp:228] Iteration 2530, loss = 0.0931881
I0403 06:13:28.983669 31448 solver.cpp:244]     Train net output #0: loss = 0.0931881 (* 1 = 0.0931881 loss)
I0403 06:13:29.145187 31448 sgd_solver.cpp:106] Iteration 2530, lr = 5e-05
I0403 06:13:32.645579 31448 solver.cpp:228] Iteration 2535, loss = 0.0968302
I0403 06:13:32.645678 31448 solver.cpp:244]     Train net output #0: loss = 0.0968302 (* 1 = 0.0968302 loss)
I0403 06:13:32.823320 31448 sgd_solver.cpp:106] Iteration 2535, lr = 5e-05
I0403 06:13:36.235178 31448 solver.cpp:228] Iteration 2540, loss = 0.128171
I0403 06:13:36.235296 31448 solver.cpp:244]     Train net output #0: loss = 0.128171 (* 1 = 0.128171 loss)
I0403 06:13:36.421128 31448 sgd_solver.cpp:106] Iteration 2540, lr = 5e-05
I0403 06:13:39.799557 31448 solver.cpp:228] Iteration 2545, loss = 0.0983192
I0403 06:13:39.799656 31448 solver.cpp:244]     Train net output #0: loss = 0.0983192 (* 1 = 0.0983192 loss)
I0403 06:13:40.001327 31448 sgd_solver.cpp:106] Iteration 2545, lr = 5e-05
I0403 06:13:43.405488 31448 solver.cpp:228] Iteration 2550, loss = 0.157249
I0403 06:13:43.405587 31448 solver.cpp:244]     Train net output #0: loss = 0.157249 (* 1 = 0.157249 loss)
I0403 06:13:43.583768 31448 sgd_solver.cpp:106] Iteration 2550, lr = 5e-05
I0403 06:13:47.035724 31448 solver.cpp:228] Iteration 2555, loss = 0.207316
I0403 06:13:47.035835 31448 solver.cpp:244]     Train net output #0: loss = 0.207316 (* 1 = 0.207316 loss)
I0403 06:13:47.219202 31448 sgd_solver.cpp:106] Iteration 2555, lr = 5e-05
I0403 06:13:50.677989 31448 solver.cpp:228] Iteration 2560, loss = 0.0722707
I0403 06:13:50.678087 31448 solver.cpp:244]     Train net output #0: loss = 0.0722707 (* 1 = 0.0722707 loss)
I0403 06:13:50.847280 31448 sgd_solver.cpp:106] Iteration 2560, lr = 5e-05
I0403 06:13:54.344483 31448 solver.cpp:228] Iteration 2565, loss = 0.100984
I0403 06:13:54.344811 31448 solver.cpp:244]     Train net output #0: loss = 0.100984 (* 1 = 0.100984 loss)
I0403 06:13:54.496177 31448 sgd_solver.cpp:106] Iteration 2565, lr = 5e-05
I0403 06:13:57.987345 31448 solver.cpp:228] Iteration 2570, loss = 0.12152
I0403 06:13:57.987457 31448 solver.cpp:244]     Train net output #0: loss = 0.12152 (* 1 = 0.12152 loss)
I0403 06:13:58.170681 31448 sgd_solver.cpp:106] Iteration 2570, lr = 5e-05
I0403 06:14:01.587517 31448 solver.cpp:228] Iteration 2575, loss = 0.179082
I0403 06:14:01.587623 31448 solver.cpp:244]     Train net output #0: loss = 0.179082 (* 1 = 0.179082 loss)
I0403 06:14:01.787288 31448 sgd_solver.cpp:106] Iteration 2575, lr = 5e-05
I0403 06:14:05.367617 31448 solver.cpp:228] Iteration 2580, loss = 0.108168
I0403 06:14:05.367733 31448 solver.cpp:244]     Train net output #0: loss = 0.108168 (* 1 = 0.108168 loss)
I0403 06:14:05.551313 31448 sgd_solver.cpp:106] Iteration 2580, lr = 5e-05
I0403 06:14:09.031679 31448 solver.cpp:228] Iteration 2585, loss = 0.108282
I0403 06:14:09.031777 31448 solver.cpp:244]     Train net output #0: loss = 0.108282 (* 1 = 0.108282 loss)
I0403 06:14:09.211828 31448 sgd_solver.cpp:106] Iteration 2585, lr = 5e-05
I0403 06:14:12.670249 31448 solver.cpp:228] Iteration 2590, loss = 0.140226
I0403 06:14:12.670351 31448 solver.cpp:244]     Train net output #0: loss = 0.140226 (* 1 = 0.140226 loss)
I0403 06:14:12.841588 31448 sgd_solver.cpp:106] Iteration 2590, lr = 5e-05
I0403 06:14:16.433260 31448 solver.cpp:228] Iteration 2595, loss = 0.244377
I0403 06:14:16.433364 31448 solver.cpp:244]     Train net output #0: loss = 0.244377 (* 1 = 0.244377 loss)
I0403 06:14:16.608530 31448 sgd_solver.cpp:106] Iteration 2595, lr = 5e-05
I0403 06:14:20.055601 31448 solver.cpp:228] Iteration 2600, loss = 0.134429
I0403 06:14:20.055713 31448 solver.cpp:244]     Train net output #0: loss = 0.134429 (* 1 = 0.134429 loss)
I0403 06:14:20.241564 31448 sgd_solver.cpp:106] Iteration 2600, lr = 5e-05
I0403 06:14:23.721750 31448 solver.cpp:228] Iteration 2605, loss = 0.183744
I0403 06:14:23.721848 31448 solver.cpp:244]     Train net output #0: loss = 0.183744 (* 1 = 0.183744 loss)
I0403 06:14:23.899682 31448 sgd_solver.cpp:106] Iteration 2605, lr = 5e-05
I0403 06:14:27.401746 31448 solver.cpp:228] Iteration 2610, loss = 0.189481
I0403 06:14:27.402096 31448 solver.cpp:244]     Train net output #0: loss = 0.189481 (* 1 = 0.189481 loss)
I0403 06:14:27.601794 31448 sgd_solver.cpp:106] Iteration 2610, lr = 5e-05
I0403 06:14:31.046372 31448 solver.cpp:228] Iteration 2615, loss = 0.0868072
I0403 06:14:31.046486 31448 solver.cpp:244]     Train net output #0: loss = 0.0868073 (* 1 = 0.0868073 loss)
I0403 06:14:31.237985 31448 sgd_solver.cpp:106] Iteration 2615, lr = 5e-05
I0403 06:14:34.684742 31448 solver.cpp:228] Iteration 2620, loss = 0.113634
I0403 06:14:34.684865 31448 solver.cpp:244]     Train net output #0: loss = 0.113634 (* 1 = 0.113634 loss)
I0403 06:14:34.871744 31448 sgd_solver.cpp:106] Iteration 2620, lr = 5e-05
I0403 06:14:37.773811 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2625.caffemodel
I0403 06:14:40.529892 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2625.solverstate
I0403 06:14:42.417207 31448 solver.cpp:337] Iteration 2625, Testing net (#0)
I0403 06:16:22.450773 31448 solver.cpp:404]     Test net output #0: accuracy = 0.854737
I0403 06:16:22.451077 31448 solver.cpp:404]     Test net output #1: loss = 0.548905 (* 1 = 0.548905 loss)
I0403 06:16:22.980370 31448 solver.cpp:228] Iteration 2625, loss = 0.151926
I0403 06:16:22.980466 31448 solver.cpp:244]     Train net output #0: loss = 0.151926 (* 1 = 0.151926 loss)
I0403 06:16:23.145895 31448 sgd_solver.cpp:106] Iteration 2625, lr = 5e-05
I0403 06:16:26.772359 31448 solver.cpp:228] Iteration 2630, loss = 0.104801
I0403 06:16:26.772469 31448 solver.cpp:244]     Train net output #0: loss = 0.104801 (* 1 = 0.104801 loss)
I0403 06:16:26.984545 31448 sgd_solver.cpp:106] Iteration 2630, lr = 5e-05
I0403 06:16:30.416189 31448 solver.cpp:228] Iteration 2635, loss = 0.0960009
I0403 06:16:30.416295 31448 solver.cpp:244]     Train net output #0: loss = 0.0960009 (* 1 = 0.0960009 loss)
I0403 06:16:30.581903 31448 sgd_solver.cpp:106] Iteration 2635, lr = 5e-05
I0403 06:16:34.080835 31448 solver.cpp:228] Iteration 2640, loss = 0.0915725
I0403 06:16:34.080947 31448 solver.cpp:244]     Train net output #0: loss = 0.0915725 (* 1 = 0.0915725 loss)
I0403 06:16:34.317766 31448 sgd_solver.cpp:106] Iteration 2640, lr = 5e-05
I0403 06:16:37.992166 31448 solver.cpp:228] Iteration 2645, loss = 0.128903
I0403 06:16:37.992277 31448 solver.cpp:244]     Train net output #0: loss = 0.128903 (* 1 = 0.128903 loss)
I0403 06:16:38.197922 31448 sgd_solver.cpp:106] Iteration 2645, lr = 5e-05
I0403 06:16:41.802330 31448 solver.cpp:228] Iteration 2650, loss = 0.131443
I0403 06:16:41.802434 31448 solver.cpp:244]     Train net output #0: loss = 0.131443 (* 1 = 0.131443 loss)
I0403 06:16:41.962200 31448 sgd_solver.cpp:106] Iteration 2650, lr = 5e-05
I0403 06:16:45.480083 31448 solver.cpp:228] Iteration 2655, loss = 0.163951
I0403 06:16:45.480192 31448 solver.cpp:244]     Train net output #0: loss = 0.163951 (* 1 = 0.163951 loss)
I0403 06:16:45.676445 31448 sgd_solver.cpp:106] Iteration 2655, lr = 5e-05
I0403 06:16:49.121388 31448 solver.cpp:228] Iteration 2660, loss = 0.155503
I0403 06:16:49.121501 31448 solver.cpp:244]     Train net output #0: loss = 0.155503 (* 1 = 0.155503 loss)
I0403 06:16:49.319664 31448 sgd_solver.cpp:106] Iteration 2660, lr = 5e-05
I0403 06:16:52.832238 31448 solver.cpp:228] Iteration 2665, loss = 0.078478
I0403 06:16:52.832564 31448 solver.cpp:244]     Train net output #0: loss = 0.0784781 (* 1 = 0.0784781 loss)
I0403 06:16:53.011152 31448 sgd_solver.cpp:106] Iteration 2665, lr = 5e-05
I0403 06:16:56.483598 31448 solver.cpp:228] Iteration 2670, loss = 0.12508
I0403 06:16:56.483711 31448 solver.cpp:244]     Train net output #0: loss = 0.12508 (* 1 = 0.12508 loss)
I0403 06:16:56.677115 31448 sgd_solver.cpp:106] Iteration 2670, lr = 5e-05
I0403 06:17:00.100204 31448 solver.cpp:228] Iteration 2675, loss = 0.105082
I0403 06:17:00.100320 31448 solver.cpp:244]     Train net output #0: loss = 0.105082 (* 1 = 0.105082 loss)
I0403 06:17:00.330428 31448 sgd_solver.cpp:106] Iteration 2675, lr = 5e-05
I0403 06:17:03.801053 31448 solver.cpp:228] Iteration 2680, loss = 0.201399
I0403 06:17:03.801147 31448 solver.cpp:244]     Train net output #0: loss = 0.201399 (* 1 = 0.201399 loss)
I0403 06:17:03.982070 31448 sgd_solver.cpp:106] Iteration 2680, lr = 5e-05
I0403 06:17:07.433290 31448 solver.cpp:228] Iteration 2685, loss = 0.119383
I0403 06:17:07.433403 31448 solver.cpp:244]     Train net output #0: loss = 0.119383 (* 1 = 0.119383 loss)
I0403 06:17:07.605065 31448 sgd_solver.cpp:106] Iteration 2685, lr = 5e-05
I0403 06:17:11.066241 31448 solver.cpp:228] Iteration 2690, loss = 0.121449
I0403 06:17:11.066355 31448 solver.cpp:244]     Train net output #0: loss = 0.12145 (* 1 = 0.12145 loss)
I0403 06:17:11.250406 31448 sgd_solver.cpp:106] Iteration 2690, lr = 5e-05
I0403 06:17:14.720444 31448 solver.cpp:228] Iteration 2695, loss = 0.0996462
I0403 06:17:14.720566 31448 solver.cpp:244]     Train net output #0: loss = 0.0996462 (* 1 = 0.0996462 loss)
I0403 06:17:14.975847 31448 sgd_solver.cpp:106] Iteration 2695, lr = 5e-05
I0403 06:17:18.466022 31448 solver.cpp:228] Iteration 2700, loss = 0.202172
I0403 06:17:18.466119 31448 solver.cpp:244]     Train net output #0: loss = 0.202172 (* 1 = 0.202172 loss)
I0403 06:17:18.617121 31448 sgd_solver.cpp:106] Iteration 2700, lr = 5e-05
I0403 06:17:22.166201 31448 solver.cpp:228] Iteration 2705, loss = 0.102273
I0403 06:17:22.166317 31448 solver.cpp:244]     Train net output #0: loss = 0.102273 (* 1 = 0.102273 loss)
I0403 06:17:22.387325 31448 sgd_solver.cpp:106] Iteration 2705, lr = 5e-05
I0403 06:17:25.801333 31448 solver.cpp:228] Iteration 2710, loss = 0.0930889
I0403 06:17:25.801645 31448 solver.cpp:244]     Train net output #0: loss = 0.0930889 (* 1 = 0.0930889 loss)
I0403 06:17:25.994734 31448 sgd_solver.cpp:106] Iteration 2710, lr = 5e-05
I0403 06:17:29.395936 31448 solver.cpp:228] Iteration 2715, loss = 0.135817
I0403 06:17:29.396046 31448 solver.cpp:244]     Train net output #0: loss = 0.135817 (* 1 = 0.135817 loss)
I0403 06:17:29.582895 31448 sgd_solver.cpp:106] Iteration 2715, lr = 5e-05
I0403 06:17:33.097301 31448 solver.cpp:228] Iteration 2720, loss = 0.0897986
I0403 06:17:33.097404 31448 solver.cpp:244]     Train net output #0: loss = 0.0897986 (* 1 = 0.0897986 loss)
I0403 06:17:33.256438 31448 sgd_solver.cpp:106] Iteration 2720, lr = 5e-05
I0403 06:17:36.803252 31448 solver.cpp:228] Iteration 2725, loss = 0.0721341
I0403 06:17:36.803356 31448 solver.cpp:244]     Train net output #0: loss = 0.0721341 (* 1 = 0.0721341 loss)
I0403 06:17:36.981066 31448 sgd_solver.cpp:106] Iteration 2725, lr = 5e-05
I0403 06:17:39.910851 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2730.caffemodel
I0403 06:17:42.635112 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2730.solverstate
I0403 06:17:44.473278 31448 solver.cpp:337] Iteration 2730, Testing net (#0)
I0403 06:19:24.502596 31448 solver.cpp:404]     Test net output #0: accuracy = 0.854828
I0403 06:19:24.502907 31448 solver.cpp:404]     Test net output #1: loss = 0.550891 (* 1 = 0.550891 loss)
I0403 06:19:25.066535 31448 solver.cpp:228] Iteration 2730, loss = 0.0585115
I0403 06:19:25.066629 31448 solver.cpp:244]     Train net output #0: loss = 0.0585115 (* 1 = 0.0585115 loss)
I0403 06:19:25.187975 31448 sgd_solver.cpp:106] Iteration 2730, lr = 5e-05
I0403 06:19:28.745923 31448 solver.cpp:228] Iteration 2735, loss = 0.142527
I0403 06:19:28.746037 31448 solver.cpp:244]     Train net output #0: loss = 0.142527 (* 1 = 0.142527 loss)
I0403 06:19:28.933706 31448 sgd_solver.cpp:106] Iteration 2735, lr = 5e-05
I0403 06:19:32.362818 31448 solver.cpp:228] Iteration 2740, loss = 0.0882759
I0403 06:19:32.362931 31448 solver.cpp:244]     Train net output #0: loss = 0.0882759 (* 1 = 0.0882759 loss)
I0403 06:19:32.559908 31448 sgd_solver.cpp:106] Iteration 2740, lr = 5e-05
I0403 06:19:35.989622 31448 solver.cpp:228] Iteration 2745, loss = 0.208938
I0403 06:19:35.989733 31448 solver.cpp:244]     Train net output #0: loss = 0.208938 (* 1 = 0.208938 loss)
I0403 06:19:36.218142 31448 sgd_solver.cpp:106] Iteration 2745, lr = 5e-05
I0403 06:19:39.800025 31448 solver.cpp:228] Iteration 2750, loss = 0.145676
I0403 06:19:39.800122 31448 solver.cpp:244]     Train net output #0: loss = 0.145676 (* 1 = 0.145676 loss)
I0403 06:19:39.976788 31448 sgd_solver.cpp:106] Iteration 2750, lr = 5e-05
I0403 06:19:43.414759 31448 solver.cpp:228] Iteration 2755, loss = 0.164209
I0403 06:19:43.414872 31448 solver.cpp:244]     Train net output #0: loss = 0.164209 (* 1 = 0.164209 loss)
I0403 06:19:43.622054 31448 sgd_solver.cpp:106] Iteration 2755, lr = 5e-05
I0403 06:19:47.184749 31448 solver.cpp:228] Iteration 2760, loss = 0.102782
I0403 06:19:47.184851 31448 solver.cpp:244]     Train net output #0: loss = 0.102782 (* 1 = 0.102782 loss)
I0403 06:19:47.352141 31448 sgd_solver.cpp:106] Iteration 2760, lr = 5e-05
I0403 06:19:50.895139 31448 solver.cpp:228] Iteration 2765, loss = 0.117103
I0403 06:19:50.895239 31448 solver.cpp:244]     Train net output #0: loss = 0.117103 (* 1 = 0.117103 loss)
I0403 06:19:51.048449 31448 sgd_solver.cpp:106] Iteration 2765, lr = 5e-05
I0403 06:19:54.554054 31448 solver.cpp:228] Iteration 2770, loss = 0.0589393
I0403 06:19:54.554373 31448 solver.cpp:244]     Train net output #0: loss = 0.0589393 (* 1 = 0.0589393 loss)
I0403 06:19:54.756683 31448 sgd_solver.cpp:106] Iteration 2770, lr = 5e-05
I0403 06:19:58.286980 31448 solver.cpp:228] Iteration 2775, loss = 0.094054
I0403 06:19:58.287091 31448 solver.cpp:244]     Train net output #0: loss = 0.094054 (* 1 = 0.094054 loss)
I0403 06:19:58.471817 31448 sgd_solver.cpp:106] Iteration 2775, lr = 5e-05
I0403 06:20:01.993142 31448 solver.cpp:228] Iteration 2780, loss = 0.123372
I0403 06:20:01.993240 31448 solver.cpp:244]     Train net output #0: loss = 0.123372 (* 1 = 0.123372 loss)
I0403 06:20:02.168221 31448 sgd_solver.cpp:106] Iteration 2780, lr = 5e-05
I0403 06:20:05.780598 31448 solver.cpp:228] Iteration 2785, loss = 0.129287
I0403 06:20:05.780697 31448 solver.cpp:244]     Train net output #0: loss = 0.129287 (* 1 = 0.129287 loss)
I0403 06:20:05.942137 31448 sgd_solver.cpp:106] Iteration 2785, lr = 5e-05
I0403 06:20:09.503021 31448 solver.cpp:228] Iteration 2790, loss = 0.149895
I0403 06:20:09.503120 31448 solver.cpp:244]     Train net output #0: loss = 0.149895 (* 1 = 0.149895 loss)
I0403 06:20:09.680675 31448 sgd_solver.cpp:106] Iteration 2790, lr = 5e-05
I0403 06:20:13.120163 31448 solver.cpp:228] Iteration 2795, loss = 0.0723269
I0403 06:20:13.120261 31448 solver.cpp:244]     Train net output #0: loss = 0.0723269 (* 1 = 0.0723269 loss)
I0403 06:20:13.299654 31448 sgd_solver.cpp:106] Iteration 2795, lr = 5e-05
I0403 06:20:16.731537 31448 solver.cpp:228] Iteration 2800, loss = 0.149543
I0403 06:20:16.731645 31448 solver.cpp:244]     Train net output #0: loss = 0.149543 (* 1 = 0.149543 loss)
I0403 06:20:16.915000 31448 sgd_solver.cpp:106] Iteration 2800, lr = 5e-05
I0403 06:20:20.422674 31448 solver.cpp:228] Iteration 2805, loss = 0.149354
I0403 06:20:20.422775 31448 solver.cpp:244]     Train net output #0: loss = 0.149354 (* 1 = 0.149354 loss)
I0403 06:20:20.573299 31448 sgd_solver.cpp:106] Iteration 2805, lr = 5e-05
I0403 06:20:24.080278 31448 solver.cpp:228] Iteration 2810, loss = 0.0464568
I0403 06:20:24.080376 31448 solver.cpp:244]     Train net output #0: loss = 0.0464568 (* 1 = 0.0464568 loss)
I0403 06:20:24.257582 31448 sgd_solver.cpp:106] Iteration 2810, lr = 5e-05
I0403 06:20:27.740595 31448 solver.cpp:228] Iteration 2815, loss = 0.123628
I0403 06:20:27.740926 31448 solver.cpp:244]     Train net output #0: loss = 0.123628 (* 1 = 0.123628 loss)
I0403 06:20:27.931624 31448 sgd_solver.cpp:106] Iteration 2815, lr = 5e-05
I0403 06:20:31.392366 31448 solver.cpp:228] Iteration 2820, loss = 0.155217
I0403 06:20:31.392463 31448 solver.cpp:244]     Train net output #0: loss = 0.155217 (* 1 = 0.155217 loss)
I0403 06:20:31.555691 31448 sgd_solver.cpp:106] Iteration 2820, lr = 5e-05
I0403 06:20:35.015849 31448 solver.cpp:228] Iteration 2825, loss = 0.0369483
I0403 06:20:35.015959 31448 solver.cpp:244]     Train net output #0: loss = 0.0369483 (* 1 = 0.0369483 loss)
I0403 06:20:35.242393 31448 sgd_solver.cpp:106] Iteration 2825, lr = 5e-05
I0403 06:20:38.679805 31448 solver.cpp:228] Iteration 2830, loss = 0.071336
I0403 06:20:38.679918 31448 solver.cpp:244]     Train net output #0: loss = 0.071336 (* 1 = 0.071336 loss)
I0403 06:20:38.864636 31448 sgd_solver.cpp:106] Iteration 2830, lr = 5e-05
I0403 06:20:41.762418 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2835.caffemodel
I0403 06:20:44.493101 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2835.solverstate
I0403 06:20:46.370838 31448 solver.cpp:337] Iteration 2835, Testing net (#0)
I0403 06:22:26.386119 31448 solver.cpp:404]     Test net output #0: accuracy = 0.854942
I0403 06:22:26.386435 31448 solver.cpp:404]     Test net output #1: loss = 0.550098 (* 1 = 0.550098 loss)
I0403 06:22:26.913089 31448 solver.cpp:228] Iteration 2835, loss = 0.101137
I0403 06:22:26.913187 31448 solver.cpp:244]     Train net output #0: loss = 0.101137 (* 1 = 0.101137 loss)
I0403 06:22:27.084566 31448 sgd_solver.cpp:106] Iteration 2835, lr = 5e-05
I0403 06:22:30.536242 31448 solver.cpp:228] Iteration 2840, loss = 0.0487377
I0403 06:22:30.536344 31448 solver.cpp:244]     Train net output #0: loss = 0.0487377 (* 1 = 0.0487377 loss)
I0403 06:22:30.714092 31448 sgd_solver.cpp:106] Iteration 2840, lr = 5e-05
I0403 06:22:34.247033 31448 solver.cpp:228] Iteration 2845, loss = 0.0648472
I0403 06:22:34.247120 31448 solver.cpp:244]     Train net output #0: loss = 0.0648473 (* 1 = 0.0648473 loss)
I0403 06:22:34.425417 31448 sgd_solver.cpp:106] Iteration 2845, lr = 5e-05
I0403 06:22:37.857959 31448 solver.cpp:228] Iteration 2850, loss = 0.194472
I0403 06:22:37.858055 31448 solver.cpp:244]     Train net output #0: loss = 0.194472 (* 1 = 0.194472 loss)
I0403 06:22:38.038707 31448 sgd_solver.cpp:106] Iteration 2850, lr = 5e-05
I0403 06:22:41.473526 31448 solver.cpp:228] Iteration 2855, loss = 0.12734
I0403 06:22:41.473623 31448 solver.cpp:244]     Train net output #0: loss = 0.12734 (* 1 = 0.12734 loss)
I0403 06:22:41.651975 31448 sgd_solver.cpp:106] Iteration 2855, lr = 5e-05
I0403 06:22:45.081895 31448 solver.cpp:228] Iteration 2860, loss = 0.199716
I0403 06:22:45.082006 31448 solver.cpp:244]     Train net output #0: loss = 0.199716 (* 1 = 0.199716 loss)
I0403 06:22:45.281865 31448 sgd_solver.cpp:106] Iteration 2860, lr = 5e-05
I0403 06:22:48.709254 31448 solver.cpp:228] Iteration 2865, loss = 0.181402
I0403 06:22:48.709369 31448 solver.cpp:244]     Train net output #0: loss = 0.181402 (* 1 = 0.181402 loss)
I0403 06:22:48.895073 31448 sgd_solver.cpp:106] Iteration 2865, lr = 5e-05
I0403 06:22:52.352738 31448 solver.cpp:228] Iteration 2870, loss = 0.131054
I0403 06:22:52.352849 31448 solver.cpp:244]     Train net output #0: loss = 0.131054 (* 1 = 0.131054 loss)
I0403 06:22:52.529950 31448 sgd_solver.cpp:106] Iteration 2870, lr = 5e-05
I0403 06:22:55.955775 31448 solver.cpp:228] Iteration 2875, loss = 0.101505
I0403 06:22:55.955884 31448 solver.cpp:244]     Train net output #0: loss = 0.101505 (* 1 = 0.101505 loss)
I0403 06:22:56.167212 31448 sgd_solver.cpp:106] Iteration 2875, lr = 5e-05
I0403 06:22:59.711496 31448 solver.cpp:228] Iteration 2880, loss = 0.0692953
I0403 06:22:59.711808 31448 solver.cpp:244]     Train net output #0: loss = 0.0692954 (* 1 = 0.0692954 loss)
I0403 06:22:59.881405 31448 sgd_solver.cpp:106] Iteration 2880, lr = 5e-05
I0403 06:23:03.361306 31448 solver.cpp:228] Iteration 2885, loss = 0.19564
I0403 06:23:03.361412 31448 solver.cpp:244]     Train net output #0: loss = 0.19564 (* 1 = 0.19564 loss)
I0403 06:23:03.540397 31448 sgd_solver.cpp:106] Iteration 2885, lr = 5e-05
I0403 06:23:07.053206 31448 solver.cpp:228] Iteration 2890, loss = 0.10717
I0403 06:23:07.053324 31448 solver.cpp:244]     Train net output #0: loss = 0.10717 (* 1 = 0.10717 loss)
I0403 06:23:07.255918 31448 sgd_solver.cpp:106] Iteration 2890, lr = 5e-05
I0403 06:23:10.707756 31448 solver.cpp:228] Iteration 2895, loss = 0.11271
I0403 06:23:10.707854 31448 solver.cpp:244]     Train net output #0: loss = 0.11271 (* 1 = 0.11271 loss)
I0403 06:23:10.884990 31448 sgd_solver.cpp:106] Iteration 2895, lr = 5e-05
I0403 06:23:14.348212 31448 solver.cpp:228] Iteration 2900, loss = 0.116489
I0403 06:23:14.348316 31448 solver.cpp:244]     Train net output #0: loss = 0.116489 (* 1 = 0.116489 loss)
I0403 06:23:14.508882 31448 sgd_solver.cpp:106] Iteration 2900, lr = 5e-05
I0403 06:23:18.167073 31448 solver.cpp:228] Iteration 2905, loss = 0.139467
I0403 06:23:18.167171 31448 solver.cpp:244]     Train net output #0: loss = 0.139467 (* 1 = 0.139467 loss)
I0403 06:23:18.342829 31448 sgd_solver.cpp:106] Iteration 2905, lr = 5e-05
I0403 06:23:21.838156 31448 solver.cpp:228] Iteration 2910, loss = 0.12376
I0403 06:23:21.838249 31448 solver.cpp:244]     Train net output #0: loss = 0.12376 (* 1 = 0.12376 loss)
I0403 06:23:22.006446 31448 sgd_solver.cpp:106] Iteration 2910, lr = 5e-05
I0403 06:23:25.586978 31448 solver.cpp:228] Iteration 2915, loss = 0.148917
I0403 06:23:25.587077 31448 solver.cpp:244]     Train net output #0: loss = 0.148917 (* 1 = 0.148917 loss)
I0403 06:23:25.764889 31448 sgd_solver.cpp:106] Iteration 2915, lr = 5e-05
I0403 06:23:29.231443 31448 solver.cpp:228] Iteration 2920, loss = 0.129951
I0403 06:23:29.231542 31448 solver.cpp:244]     Train net output #0: loss = 0.129951 (* 1 = 0.129951 loss)
I0403 06:23:29.414419 31448 sgd_solver.cpp:106] Iteration 2920, lr = 5e-05
I0403 06:23:32.854604 31448 solver.cpp:228] Iteration 2925, loss = 0.122879
I0403 06:23:32.854910 31448 solver.cpp:244]     Train net output #0: loss = 0.122879 (* 1 = 0.122879 loss)
I0403 06:23:33.046607 31448 sgd_solver.cpp:106] Iteration 2925, lr = 5e-05
I0403 06:23:36.462985 31448 solver.cpp:228] Iteration 2930, loss = 0.0647883
I0403 06:23:36.463099 31448 solver.cpp:244]     Train net output #0: loss = 0.0647883 (* 1 = 0.0647883 loss)
I0403 06:23:36.661240 31448 sgd_solver.cpp:106] Iteration 2930, lr = 5e-05
I0403 06:23:40.085253 31448 solver.cpp:228] Iteration 2935, loss = 0.0902621
I0403 06:23:40.085372 31448 solver.cpp:244]     Train net output #0: loss = 0.0902621 (* 1 = 0.0902621 loss)
I0403 06:23:40.280963 31448 sgd_solver.cpp:106] Iteration 2935, lr = 5e-05
I0403 06:23:43.174252 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2940.caffemodel
I0403 06:23:45.942361 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_2940.solverstate
I0403 06:23:47.818765 31448 solver.cpp:337] Iteration 2940, Testing net (#0)
I0403 06:25:27.838244 31448 solver.cpp:404]     Test net output #0: accuracy = 0.854896
I0403 06:25:27.838575 31448 solver.cpp:404]     Test net output #1: loss = 0.552124 (* 1 = 0.552124 loss)
I0403 06:25:28.349563 31448 solver.cpp:228] Iteration 2940, loss = 0.0477537
I0403 06:25:28.349673 31448 solver.cpp:244]     Train net output #0: loss = 0.0477538 (* 1 = 0.0477538 loss)
I0403 06:25:28.532949 31448 sgd_solver.cpp:106] Iteration 2940, lr = 5e-05
I0403 06:25:32.019206 31448 solver.cpp:228] Iteration 2945, loss = 0.0839112
I0403 06:25:32.020205 31448 solver.cpp:244]     Train net output #0: loss = 0.0839112 (* 1 = 0.0839112 loss)
I0403 06:25:32.224454 31448 sgd_solver.cpp:106] Iteration 2945, lr = 5e-05
I0403 06:25:35.709823 31448 solver.cpp:228] Iteration 2950, loss = 0.177598
I0403 06:25:35.709923 31448 solver.cpp:244]     Train net output #0: loss = 0.177598 (* 1 = 0.177598 loss)
I0403 06:25:35.883330 31448 sgd_solver.cpp:106] Iteration 2950, lr = 5e-05
I0403 06:25:39.382192 31448 solver.cpp:228] Iteration 2955, loss = 0.144673
I0403 06:25:39.382298 31448 solver.cpp:244]     Train net output #0: loss = 0.144673 (* 1 = 0.144673 loss)
I0403 06:25:39.550881 31448 sgd_solver.cpp:106] Iteration 2955, lr = 5e-05
I0403 06:25:43.021070 31448 solver.cpp:228] Iteration 2960, loss = 0.110918
I0403 06:25:43.021168 31448 solver.cpp:244]     Train net output #0: loss = 0.110918 (* 1 = 0.110918 loss)
I0403 06:25:43.184610 31448 sgd_solver.cpp:106] Iteration 2960, lr = 5e-05
I0403 06:25:46.668578 31448 solver.cpp:228] Iteration 2965, loss = 0.213342
I0403 06:25:46.668684 31448 solver.cpp:244]     Train net output #0: loss = 0.213342 (* 1 = 0.213342 loss)
I0403 06:25:46.837787 31448 sgd_solver.cpp:106] Iteration 2965, lr = 5e-05
I0403 06:25:50.333222 31448 solver.cpp:228] Iteration 2970, loss = 0.124274
I0403 06:25:50.333320 31448 solver.cpp:244]     Train net output #0: loss = 0.124274 (* 1 = 0.124274 loss)
I0403 06:25:50.487383 31448 sgd_solver.cpp:106] Iteration 2970, lr = 5e-05
I0403 06:25:54.006561 31448 solver.cpp:228] Iteration 2975, loss = 0.114369
I0403 06:25:54.006681 31448 solver.cpp:244]     Train net output #0: loss = 0.114369 (* 1 = 0.114369 loss)
I0403 06:25:54.207041 31448 sgd_solver.cpp:106] Iteration 2975, lr = 5e-05
I0403 06:25:57.657524 31448 solver.cpp:228] Iteration 2980, loss = 0.0887875
I0403 06:25:57.657634 31448 solver.cpp:244]     Train net output #0: loss = 0.0887875 (* 1 = 0.0887875 loss)
I0403 06:25:57.852404 31448 sgd_solver.cpp:106] Iteration 2980, lr = 5e-05
I0403 06:26:01.285430 31448 solver.cpp:228] Iteration 2985, loss = 0.126367
I0403 06:26:01.285540 31448 solver.cpp:244]     Train net output #0: loss = 0.126367 (* 1 = 0.126367 loss)
I0403 06:26:01.480876 31448 sgd_solver.cpp:106] Iteration 2985, lr = 5e-05
I0403 06:26:04.951143 31448 solver.cpp:228] Iteration 2990, loss = 0.167631
I0403 06:26:04.951243 31448 solver.cpp:244]     Train net output #0: loss = 0.167631 (* 1 = 0.167631 loss)
I0403 06:26:05.120443 31448 sgd_solver.cpp:106] Iteration 2990, lr = 5e-05
I0403 06:26:08.623395 31448 solver.cpp:228] Iteration 2995, loss = 0.0837746
I0403 06:26:08.623507 31448 solver.cpp:244]     Train net output #0: loss = 0.0837747 (* 1 = 0.0837747 loss)
I0403 06:26:08.819355 31448 sgd_solver.cpp:106] Iteration 2995, lr = 5e-05
I0403 06:26:12.264780 31448 solver.cpp:228] Iteration 3000, loss = 0.139736
I0403 06:26:12.264914 31448 solver.cpp:244]     Train net output #0: loss = 0.139736 (* 1 = 0.139736 loss)
I0403 06:26:12.466771 31448 sgd_solver.cpp:106] Iteration 3000, lr = 5e-05
I0403 06:26:15.923296 31448 solver.cpp:228] Iteration 3005, loss = 0.0683987
I0403 06:26:15.923410 31448 solver.cpp:244]     Train net output #0: loss = 0.0683987 (* 1 = 0.0683987 loss)
I0403 06:26:16.110919 31448 sgd_solver.cpp:106] Iteration 3005, lr = 5e-05
I0403 06:26:19.576347 31448 solver.cpp:228] Iteration 3010, loss = 0.103695
I0403 06:26:19.576459 31448 solver.cpp:244]     Train net output #0: loss = 0.103695 (* 1 = 0.103695 loss)
I0403 06:26:19.776926 31448 sgd_solver.cpp:106] Iteration 3010, lr = 5e-05
I0403 06:26:23.307096 31448 solver.cpp:228] Iteration 3015, loss = 0.13353
I0403 06:26:23.307206 31448 solver.cpp:244]     Train net output #0: loss = 0.13353 (* 1 = 0.13353 loss)
I0403 06:26:23.502141 31448 sgd_solver.cpp:106] Iteration 3015, lr = 5e-05
I0403 06:26:26.991542 31448 solver.cpp:228] Iteration 3020, loss = 0.0596703
I0403 06:26:26.991653 31448 solver.cpp:244]     Train net output #0: loss = 0.0596703 (* 1 = 0.0596703 loss)
I0403 06:26:27.175439 31448 sgd_solver.cpp:106] Iteration 3020, lr = 5e-05
I0403 06:26:30.661824 31448 solver.cpp:228] Iteration 3025, loss = 0.105362
I0403 06:26:30.662163 31448 solver.cpp:244]     Train net output #0: loss = 0.105362 (* 1 = 0.105362 loss)
I0403 06:26:30.840657 31448 sgd_solver.cpp:106] Iteration 3025, lr = 5e-05
I0403 06:26:34.412138 31448 solver.cpp:228] Iteration 3030, loss = 0.153174
I0403 06:26:34.412240 31448 solver.cpp:244]     Train net output #0: loss = 0.153174 (* 1 = 0.153174 loss)
I0403 06:26:34.574110 31448 sgd_solver.cpp:106] Iteration 3030, lr = 5e-05
I0403 06:26:38.055940 31448 solver.cpp:228] Iteration 3035, loss = 0.0612547
I0403 06:26:38.056041 31448 solver.cpp:244]     Train net output #0: loss = 0.0612547 (* 1 = 0.0612547 loss)
I0403 06:26:38.233961 31448 sgd_solver.cpp:106] Iteration 3035, lr = 5e-05
I0403 06:26:41.709350 31448 solver.cpp:228] Iteration 3040, loss = 0.0689143
I0403 06:26:41.709450 31448 solver.cpp:244]     Train net output #0: loss = 0.0689143 (* 1 = 0.0689143 loss)
I0403 06:26:41.838064 31448 sgd_solver.cpp:106] Iteration 3040, lr = 5e-05
I0403 06:26:44.862854 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_3045.caffemodel
I0403 06:26:47.620259 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_3045.solverstate
I0403 06:26:49.473125 31448 solver.cpp:337] Iteration 3045, Testing net (#0)
I0403 06:28:29.464426 31448 solver.cpp:404]     Test net output #0: accuracy = 0.854966
I0403 06:28:29.464715 31448 solver.cpp:404]     Test net output #1: loss = 0.551243 (* 1 = 0.551243 loss)
I0403 06:28:29.988545 31448 solver.cpp:228] Iteration 3045, loss = 0.12232
I0403 06:28:29.988646 31448 solver.cpp:244]     Train net output #0: loss = 0.12232 (* 1 = 0.12232 loss)
I0403 06:28:30.151324 31448 sgd_solver.cpp:106] Iteration 3045, lr = 5e-05
I0403 06:28:33.796205 31448 solver.cpp:228] Iteration 3050, loss = 0.166363
I0403 06:28:33.796311 31448 solver.cpp:244]     Train net output #0: loss = 0.166363 (* 1 = 0.166363 loss)
I0403 06:28:33.983233 31448 sgd_solver.cpp:106] Iteration 3050, lr = 5e-05
I0403 06:28:37.445487 31448 solver.cpp:228] Iteration 3055, loss = 0.0904769
I0403 06:28:37.445585 31448 solver.cpp:244]     Train net output #0: loss = 0.0904769 (* 1 = 0.0904769 loss)
I0403 06:28:37.617204 31448 sgd_solver.cpp:106] Iteration 3055, lr = 5e-05
I0403 06:28:41.046964 31448 solver.cpp:228] Iteration 3060, loss = 0.188413
I0403 06:28:41.047075 31448 solver.cpp:244]     Train net output #0: loss = 0.188413 (* 1 = 0.188413 loss)
I0403 06:28:41.259055 31448 sgd_solver.cpp:106] Iteration 3060, lr = 5e-05
I0403 06:28:44.738364 31448 solver.cpp:228] Iteration 3065, loss = 0.0950758
I0403 06:28:44.738474 31448 solver.cpp:244]     Train net output #0: loss = 0.0950758 (* 1 = 0.0950758 loss)
I0403 06:28:44.922003 31448 sgd_solver.cpp:106] Iteration 3065, lr = 5e-05
I0403 06:28:48.358392 31448 solver.cpp:228] Iteration 3070, loss = 0.0962688
I0403 06:28:48.358503 31448 solver.cpp:244]     Train net output #0: loss = 0.0962688 (* 1 = 0.0962688 loss)
I0403 06:28:48.541699 31448 sgd_solver.cpp:106] Iteration 3070, lr = 5e-05
I0403 06:28:51.968754 31448 solver.cpp:228] Iteration 3075, loss = 0.0898827
I0403 06:28:51.968866 31448 solver.cpp:244]     Train net output #0: loss = 0.0898827 (* 1 = 0.0898827 loss)
I0403 06:28:52.173725 31448 sgd_solver.cpp:106] Iteration 3075, lr = 5e-05
I0403 06:28:55.666743 31448 solver.cpp:228] Iteration 3080, loss = 0.132656
I0403 06:28:55.666839 31448 solver.cpp:244]     Train net output #0: loss = 0.132656 (* 1 = 0.132656 loss)
I0403 06:28:55.841675 31448 sgd_solver.cpp:106] Iteration 3080, lr = 5e-05
I0403 06:28:59.411202 31448 solver.cpp:228] Iteration 3085, loss = 0.159756
I0403 06:28:59.411310 31448 solver.cpp:244]     Train net output #0: loss = 0.159756 (* 1 = 0.159756 loss)
I0403 06:28:59.559420 31448 sgd_solver.cpp:106] Iteration 3085, lr = 5e-05
I0403 06:29:03.235986 31448 solver.cpp:228] Iteration 3090, loss = 0.110059
I0403 06:29:03.236945 31448 solver.cpp:244]     Train net output #0: loss = 0.110059 (* 1 = 0.110059 loss)
I0403 06:29:03.373764 31448 sgd_solver.cpp:106] Iteration 3090, lr = 5e-05
I0403 06:29:06.943315 31448 solver.cpp:228] Iteration 3095, loss = 0.0949863
I0403 06:29:06.943430 31448 solver.cpp:244]     Train net output #0: loss = 0.0949863 (* 1 = 0.0949863 loss)
I0403 06:29:07.113241 31448 sgd_solver.cpp:106] Iteration 3095, lr = 5e-05
I0403 06:29:10.584875 31448 solver.cpp:228] Iteration 3100, loss = 0.0763321
I0403 06:29:10.584972 31448 solver.cpp:244]     Train net output #0: loss = 0.0763321 (* 1 = 0.0763321 loss)
I0403 06:29:10.767669 31448 sgd_solver.cpp:106] Iteration 3100, lr = 5e-05
I0403 06:29:14.208750 31448 solver.cpp:228] Iteration 3105, loss = 0.0862
I0403 06:29:14.208847 31448 solver.cpp:244]     Train net output #0: loss = 0.0862 (* 1 = 0.0862 loss)
I0403 06:29:14.375448 31448 sgd_solver.cpp:106] Iteration 3105, lr = 5e-05
I0403 06:29:17.875622 31448 solver.cpp:228] Iteration 3110, loss = 0.102188
I0403 06:29:17.875735 31448 solver.cpp:244]     Train net output #0: loss = 0.102188 (* 1 = 0.102188 loss)
I0403 06:29:18.062391 31448 sgd_solver.cpp:106] Iteration 3110, lr = 5e-05
I0403 06:29:21.544286 31448 solver.cpp:228] Iteration 3115, loss = 0.0803925
I0403 06:29:21.544383 31448 solver.cpp:244]     Train net output #0: loss = 0.0803925 (* 1 = 0.0803925 loss)
I0403 06:29:21.727283 31448 sgd_solver.cpp:106] Iteration 3115, lr = 5e-05
I0403 06:29:25.367221 31448 solver.cpp:228] Iteration 3120, loss = 0.129711
I0403 06:29:25.367341 31448 solver.cpp:244]     Train net output #0: loss = 0.129711 (* 1 = 0.129711 loss)
I0403 06:29:25.576239 31448 sgd_solver.cpp:106] Iteration 3120, lr = 5e-05
I0403 06:29:29.014891 31448 solver.cpp:228] Iteration 3125, loss = 0.121368
I0403 06:29:29.014991 31448 solver.cpp:244]     Train net output #0: loss = 0.121368 (* 1 = 0.121368 loss)
I0403 06:29:29.197962 31448 sgd_solver.cpp:106] Iteration 3125, lr = 5e-05
I0403 06:29:32.712616 31448 solver.cpp:228] Iteration 3130, loss = 0.0922083
I0403 06:29:32.712857 31448 solver.cpp:244]     Train net output #0: loss = 0.0922083 (* 1 = 0.0922083 loss)
I0403 06:29:32.883882 31448 sgd_solver.cpp:106] Iteration 3130, lr = 5e-05
I0403 06:29:36.365888 31448 solver.cpp:228] Iteration 3135, loss = 0.0966558
I0403 06:29:36.365989 31448 solver.cpp:244]     Train net output #0: loss = 0.0966558 (* 1 = 0.0966558 loss)
I0403 06:29:36.548955 31448 sgd_solver.cpp:106] Iteration 3135, lr = 5e-05
I0403 06:29:39.998343 31448 solver.cpp:228] Iteration 3140, loss = 0.0382414
I0403 06:29:39.998443 31448 solver.cpp:244]     Train net output #0: loss = 0.0382414 (* 1 = 0.0382414 loss)
I0403 06:29:40.170536 31448 sgd_solver.cpp:106] Iteration 3140, lr = 5e-05
I0403 06:29:43.729885 31448 solver.cpp:228] Iteration 3145, loss = 0.0614209
I0403 06:29:43.729985 31448 solver.cpp:244]     Train net output #0: loss = 0.0614209 (* 1 = 0.0614209 loss)
I0403 06:29:43.902832 31448 sgd_solver.cpp:106] Iteration 3145, lr = 5e-05
I0403 06:29:46.877567 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_3150.caffemodel
I0403 06:29:49.623152 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_3150.solverstate
I0403 06:29:51.456153 31448 solver.cpp:337] Iteration 3150, Testing net (#0)
I0403 06:31:31.466639 31448 solver.cpp:404]     Test net output #0: accuracy = 0.855332
I0403 06:31:31.466970 31448 solver.cpp:404]     Test net output #1: loss = 0.552795 (* 1 = 0.552795 loss)
I0403 06:31:31.998597 31448 solver.cpp:228] Iteration 3150, loss = 0.137929
I0403 06:31:31.998694 31448 solver.cpp:244]     Train net output #0: loss = 0.137929 (* 1 = 0.137929 loss)
I0403 06:31:32.156580 31448 sgd_solver.cpp:106] Iteration 3150, lr = 5e-05
I0403 06:31:35.648416 31448 solver.cpp:228] Iteration 3155, loss = 0.105542
I0403 06:31:35.649629 31448 solver.cpp:244]     Train net output #0: loss = 0.105542 (* 1 = 0.105542 loss)
I0403 06:31:35.828011 31448 sgd_solver.cpp:106] Iteration 3155, lr = 5e-05
I0403 06:31:39.279105 31448 solver.cpp:228] Iteration 3160, loss = 0.13447
I0403 06:31:39.279203 31448 solver.cpp:244]     Train net output #0: loss = 0.13447 (* 1 = 0.13447 loss)
I0403 06:31:39.454840 31448 sgd_solver.cpp:106] Iteration 3160, lr = 5e-05
I0403 06:31:42.862820 31448 solver.cpp:228] Iteration 3165, loss = 0.0861531
I0403 06:31:42.862931 31448 solver.cpp:244]     Train net output #0: loss = 0.0861531 (* 1 = 0.0861531 loss)
I0403 06:31:43.064406 31448 sgd_solver.cpp:106] Iteration 3165, lr = 5e-05
I0403 06:31:46.470284 31448 solver.cpp:228] Iteration 3170, loss = 0.118865
I0403 06:31:46.470399 31448 solver.cpp:244]     Train net output #0: loss = 0.118865 (* 1 = 0.118865 loss)
I0403 06:31:46.653647 31448 sgd_solver.cpp:106] Iteration 3170, lr = 5e-05
I0403 06:31:47.375753 31448 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_3172.caffemodel
I0403 06:31:50.084131 31448 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_train_from_scratch/snapshots__iter_3172.solverstate
I0403 06:31:51.941761 31448 solver.cpp:322] Optimization Done.
I0403 06:31:52.023994 31448 caffe.cpp:222] Optimization Done.
