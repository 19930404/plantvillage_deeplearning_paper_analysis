I0403 02:30:28.145629 19293 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.146116 19293 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.146143 19293 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.204547 19293 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.206113 19293 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.207562 19293 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:36.790292 19293 solver.cpp:48] Initializing solver from parameters: 
test_iter: 437
test_interval: 105
base_lr: 0.005
display: 5
max_iter: 3172
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1057
snapshot: 105
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:36.857640 19293 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:36.868898 19293 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:36.869079 19293 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:36.870965 19293 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:36.873487 19293 layer_factory.hpp:77] Creating layer data
I0403 02:30:36.876132 19293 net.cpp:91] Creating Layer data
I0403 02:30:36.876346 19293 net.cpp:399] data -> data
I0403 02:30:36.876803 19293 net.cpp:399] data -> label
I0403 02:30:36.877063 19293 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto
I0403 02:30:36.892213 19300 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/train_db
I0403 02:30:36.951231 19293 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.090081 19293 net.cpp:141] Setting up data
I0403 02:30:37.090198 19293 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.090227 19293 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.090247 19293 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.090286 19293 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.090344 19293 net.cpp:91] Creating Layer conv1
I0403 02:30:37.090374 19293 net.cpp:425] conv1 <- data
I0403 02:30:37.090415 19293 net.cpp:399] conv1 -> conv1
I0403 02:30:37.094269 19293 net.cpp:141] Setting up conv1
I0403 02:30:37.094331 19293 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.094354 19293 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.094416 19293 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.094471 19293 net.cpp:91] Creating Layer relu1
I0403 02:30:37.094499 19293 net.cpp:425] relu1 <- conv1
I0403 02:30:37.094522 19293 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.094568 19293 net.cpp:141] Setting up relu1
I0403 02:30:37.094596 19293 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.094616 19293 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.094636 19293 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.094661 19293 net.cpp:91] Creating Layer norm1
I0403 02:30:37.094724 19293 net.cpp:425] norm1 <- conv1
I0403 02:30:37.094749 19293 net.cpp:399] norm1 -> norm1
I0403 02:30:37.100214 19293 net.cpp:141] Setting up norm1
I0403 02:30:37.100263 19293 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.100291 19293 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.100313 19293 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.100343 19293 net.cpp:91] Creating Layer pool1
I0403 02:30:37.100365 19293 net.cpp:425] pool1 <- norm1
I0403 02:30:37.100389 19293 net.cpp:399] pool1 -> pool1
I0403 02:30:37.100497 19293 net.cpp:141] Setting up pool1
I0403 02:30:37.100533 19293 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.100553 19293 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.100574 19293 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.100602 19293 net.cpp:91] Creating Layer conv2
I0403 02:30:37.100625 19293 net.cpp:425] conv2 <- pool1
I0403 02:30:37.100651 19293 net.cpp:399] conv2 -> conv2
I0403 02:30:37.102339 19301 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.120645 19293 net.cpp:141] Setting up conv2
I0403 02:30:37.120685 19293 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.120708 19293 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.120738 19293 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.120765 19293 net.cpp:91] Creating Layer relu2
I0403 02:30:37.120789 19293 net.cpp:425] relu2 <- conv2
I0403 02:30:37.120823 19293 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.120849 19293 net.cpp:141] Setting up relu2
I0403 02:30:37.120872 19293 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.120892 19293 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.120913 19293 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.120937 19293 net.cpp:91] Creating Layer norm2
I0403 02:30:37.120960 19293 net.cpp:425] norm2 <- conv2
I0403 02:30:37.120985 19293 net.cpp:399] norm2 -> norm2
I0403 02:30:37.121043 19293 net.cpp:141] Setting up norm2
I0403 02:30:37.121073 19293 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.121093 19293 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.121115 19293 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.121142 19293 net.cpp:91] Creating Layer pool2
I0403 02:30:37.121165 19293 net.cpp:425] pool2 <- norm2
I0403 02:30:37.121189 19293 net.cpp:399] pool2 -> pool2
I0403 02:30:37.121248 19293 net.cpp:141] Setting up pool2
I0403 02:30:37.121278 19293 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.121299 19293 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.121320 19293 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.121348 19293 net.cpp:91] Creating Layer conv3
I0403 02:30:37.121371 19293 net.cpp:425] conv3 <- pool2
I0403 02:30:37.121398 19293 net.cpp:399] conv3 -> conv3
I0403 02:30:37.163244 19293 net.cpp:141] Setting up conv3
I0403 02:30:37.163287 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.163310 19293 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.163338 19293 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.163363 19293 net.cpp:91] Creating Layer relu3
I0403 02:30:37.163385 19293 net.cpp:425] relu3 <- conv3
I0403 02:30:37.163409 19293 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.163434 19293 net.cpp:141] Setting up relu3
I0403 02:30:37.163456 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.163481 19293 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.163501 19293 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.163530 19293 net.cpp:91] Creating Layer conv4
I0403 02:30:37.163553 19293 net.cpp:425] conv4 <- conv3
I0403 02:30:37.163580 19293 net.cpp:399] conv4 -> conv4
I0403 02:30:37.196333 19293 net.cpp:141] Setting up conv4
I0403 02:30:37.196375 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.196395 19293 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.196444 19293 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.196476 19293 net.cpp:91] Creating Layer relu4
I0403 02:30:37.196501 19293 net.cpp:425] relu4 <- conv4
I0403 02:30:37.196523 19293 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.196549 19293 net.cpp:141] Setting up relu4
I0403 02:30:37.196573 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.196593 19293 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.196612 19293 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.196641 19293 net.cpp:91] Creating Layer conv5
I0403 02:30:37.196662 19293 net.cpp:425] conv5 <- conv4
I0403 02:30:37.196688 19293 net.cpp:399] conv5 -> conv5
I0403 02:30:37.217813 19293 net.cpp:141] Setting up conv5
I0403 02:30:37.217852 19293 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.217874 19293 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.217901 19293 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.217926 19293 net.cpp:91] Creating Layer relu5
I0403 02:30:37.217948 19293 net.cpp:425] relu5 <- conv5
I0403 02:30:37.217973 19293 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.217999 19293 net.cpp:141] Setting up relu5
I0403 02:30:37.218022 19293 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.218040 19293 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.218060 19293 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.218082 19293 net.cpp:91] Creating Layer pool5
I0403 02:30:37.218104 19293 net.cpp:425] pool5 <- conv5
I0403 02:30:37.218132 19293 net.cpp:399] pool5 -> pool5
I0403 02:30:37.218190 19293 net.cpp:141] Setting up pool5
I0403 02:30:37.218220 19293 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.218240 19293 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.218260 19293 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.218319 19293 net.cpp:91] Creating Layer fc6
I0403 02:30:37.218346 19293 net.cpp:425] fc6 <- pool5
I0403 02:30:37.218372 19293 net.cpp:399] fc6 -> fc6
I0403 02:30:38.789791 19293 net.cpp:141] Setting up fc6
I0403 02:30:38.789875 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.789893 19293 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.789916 19293 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.789942 19293 net.cpp:91] Creating Layer relu6
I0403 02:30:38.789961 19293 net.cpp:425] relu6 <- fc6
I0403 02:30:38.789986 19293 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.790011 19293 net.cpp:141] Setting up relu6
I0403 02:30:38.790030 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.790046 19293 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.790061 19293 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.790112 19293 net.cpp:91] Creating Layer drop6
I0403 02:30:38.790132 19293 net.cpp:425] drop6 <- fc6
I0403 02:30:38.790153 19293 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.790215 19293 net.cpp:141] Setting up drop6
I0403 02:30:38.790237 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.790253 19293 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.790268 19293 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.790292 19293 net.cpp:91] Creating Layer fc7
I0403 02:30:38.790312 19293 net.cpp:425] fc7 <- fc6
I0403 02:30:38.790343 19293 net.cpp:399] fc7 -> fc7
I0403 02:30:39.417300 19293 net.cpp:141] Setting up fc7
I0403 02:30:39.417389 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.417407 19293 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.417430 19293 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.417456 19293 net.cpp:91] Creating Layer relu7
I0403 02:30:39.417492 19293 net.cpp:425] relu7 <- fc7
I0403 02:30:39.417515 19293 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.417539 19293 net.cpp:141] Setting up relu7
I0403 02:30:39.417557 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.417573 19293 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.417589 19293 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.417655 19293 net.cpp:91] Creating Layer drop7
I0403 02:30:39.417675 19293 net.cpp:425] drop7 <- fc7
I0403 02:30:39.417695 19293 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.417733 19293 net.cpp:141] Setting up drop7
I0403 02:30:39.417770 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.417786 19293 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.417803 19293 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.417824 19293 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.417841 19293 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.417862 19293 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.423977 19293 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.424005 19293 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.424022 19293 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.424042 19293 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.424088 19293 net.cpp:91] Creating Layer loss
I0403 02:30:39.424108 19293 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.424135 19293 net.cpp:425] loss <- label
I0403 02:30:39.424165 19293 net.cpp:399] loss -> loss
I0403 02:30:39.424206 19293 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.424335 19293 net.cpp:141] Setting up loss
I0403 02:30:39.424360 19293 net.cpp:148] Top shape: (1)
I0403 02:30:39.424376 19293 net.cpp:151]     with loss weight 1
I0403 02:30:39.424434 19293 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.424451 19293 net.cpp:217] loss needs backward computation.
I0403 02:30:39.424473 19293 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.424489 19293 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.424504 19293 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.424520 19293 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.424533 19293 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.424547 19293 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.424561 19293 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.424576 19293 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.424592 19293 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.424607 19293 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.424623 19293 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.424638 19293 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.424654 19293 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.424667 19293 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.424684 19293 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.424700 19293 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.424715 19293 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.424731 19293 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.424744 19293 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.424760 19293 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.424775 19293 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.424789 19293 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.424804 19293 net.cpp:219] data does not need backward computation.
I0403 02:30:39.424819 19293 net.cpp:261] This network produces output loss
I0403 02:30:39.424846 19293 net.cpp:274] Network initialization done.
I0403 02:30:39.425997 19293 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.426057 19293 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.426712 19293 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-20-80/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.426882 19293 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.427408 19293 net.cpp:91] Creating Layer data
I0403 02:30:39.427435 19293 net.cpp:399] data -> data
I0403 02:30:39.427467 19293 net.cpp:399] data -> label
I0403 02:30:39.427495 19293 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/mean.binaryproto
I0403 02:30:39.449884 19306 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-20-80/test_db
I0403 02:30:39.456312 19293 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.599959 19293 net.cpp:141] Setting up data
I0403 02:30:39.600090 19293 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.600168 19293 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.600242 19293 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.600347 19293 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.600399 19293 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.600495 19293 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.600625 19293 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.600752 19293 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.600970 19293 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.601099 19293 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.601229 19293 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.601374 19293 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.601510 19293 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.601624 19293 net.cpp:91] Creating Layer conv1
I0403 02:30:39.601749 19293 net.cpp:425] conv1 <- data
I0403 02:30:39.601886 19293 net.cpp:399] conv1 -> conv1
I0403 02:30:39.603770 19293 net.cpp:141] Setting up conv1
I0403 02:30:39.603804 19293 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.603828 19293 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.603859 19293 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.603884 19293 net.cpp:91] Creating Layer relu1
I0403 02:30:39.603909 19293 net.cpp:425] relu1 <- conv1
I0403 02:30:39.603935 19293 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.603962 19293 net.cpp:141] Setting up relu1
I0403 02:30:39.603983 19293 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.604007 19293 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.604030 19293 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.604058 19293 net.cpp:91] Creating Layer norm1
I0403 02:30:39.604077 19293 net.cpp:425] norm1 <- conv1
I0403 02:30:39.604105 19293 net.cpp:399] norm1 -> norm1
I0403 02:30:39.604162 19293 net.cpp:141] Setting up norm1
I0403 02:30:39.604192 19293 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.604209 19293 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.604231 19293 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.604259 19293 net.cpp:91] Creating Layer pool1
I0403 02:30:39.604280 19293 net.cpp:425] pool1 <- norm1
I0403 02:30:39.604305 19293 net.cpp:399] pool1 -> pool1
I0403 02:30:39.604362 19293 net.cpp:141] Setting up pool1
I0403 02:30:39.604390 19293 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.604408 19293 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.604452 19293 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.604497 19293 net.cpp:91] Creating Layer conv2
I0403 02:30:39.604522 19293 net.cpp:425] conv2 <- pool1
I0403 02:30:39.604550 19293 net.cpp:399] conv2 -> conv2
I0403 02:30:39.616658 19293 net.cpp:141] Setting up conv2
I0403 02:30:39.616693 19293 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.616711 19293 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.616734 19293 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.616755 19293 net.cpp:91] Creating Layer relu2
I0403 02:30:39.616775 19293 net.cpp:425] relu2 <- conv2
I0403 02:30:39.616794 19293 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.616816 19293 net.cpp:141] Setting up relu2
I0403 02:30:39.616834 19293 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.616850 19293 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.616866 19293 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.616888 19293 net.cpp:91] Creating Layer norm2
I0403 02:30:39.616907 19293 net.cpp:425] norm2 <- conv2
I0403 02:30:39.616927 19293 net.cpp:399] norm2 -> norm2
I0403 02:30:39.616977 19293 net.cpp:141] Setting up norm2
I0403 02:30:39.617002 19293 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.617017 19293 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.617034 19293 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.617054 19293 net.cpp:91] Creating Layer pool2
I0403 02:30:39.617072 19293 net.cpp:425] pool2 <- norm2
I0403 02:30:39.617091 19293 net.cpp:399] pool2 -> pool2
I0403 02:30:39.617137 19293 net.cpp:141] Setting up pool2
I0403 02:30:39.617161 19293 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.617178 19293 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.617195 19293 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.617218 19293 net.cpp:91] Creating Layer conv3
I0403 02:30:39.617238 19293 net.cpp:425] conv3 <- pool2
I0403 02:30:39.617259 19293 net.cpp:399] conv3 -> conv3
I0403 02:30:39.651548 19293 net.cpp:141] Setting up conv3
I0403 02:30:39.663841 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.663916 19293 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.663956 19293 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.664037 19293 net.cpp:91] Creating Layer relu3
I0403 02:30:39.664124 19293 net.cpp:425] relu3 <- conv3
I0403 02:30:39.664227 19293 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.664320 19293 net.cpp:141] Setting up relu3
I0403 02:30:39.664356 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.664414 19293 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.664530 19293 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.664628 19293 net.cpp:91] Creating Layer conv4
I0403 02:30:39.664702 19293 net.cpp:425] conv4 <- conv3
I0403 02:30:39.664800 19293 net.cpp:399] conv4 -> conv4
I0403 02:30:39.697613 19293 net.cpp:141] Setting up conv4
I0403 02:30:39.707551 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.707588 19293 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.707626 19293 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.707675 19293 net.cpp:91] Creating Layer relu4
I0403 02:30:39.707720 19293 net.cpp:425] relu4 <- conv4
I0403 02:30:39.707746 19293 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.707784 19293 net.cpp:141] Setting up relu4
I0403 02:30:39.707828 19293 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.708034 19293 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.708217 19293 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.708271 19293 net.cpp:91] Creating Layer conv5
I0403 02:30:39.708309 19293 net.cpp:425] conv5 <- conv4
I0403 02:30:39.708353 19293 net.cpp:399] conv5 -> conv5
I0403 02:30:39.730650 19293 net.cpp:141] Setting up conv5
I0403 02:30:39.750921 19293 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.753460 19293 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.753512 19293 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.753550 19293 net.cpp:91] Creating Layer relu5
I0403 02:30:39.753585 19293 net.cpp:425] relu5 <- conv5
I0403 02:30:39.753631 19293 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.753654 19293 net.cpp:141] Setting up relu5
I0403 02:30:39.753693 19293 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.753734 19293 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.753772 19293 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.753815 19293 net.cpp:91] Creating Layer pool5
I0403 02:30:39.753859 19293 net.cpp:425] pool5 <- conv5
I0403 02:30:39.753918 19293 net.cpp:399] pool5 -> pool5
I0403 02:30:39.754045 19293 net.cpp:141] Setting up pool5
I0403 02:30:39.754073 19293 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.754114 19293 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.754149 19293 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.754194 19293 net.cpp:91] Creating Layer fc6
I0403 02:30:39.754211 19293 net.cpp:425] fc6 <- pool5
I0403 02:30:39.754245 19293 net.cpp:399] fc6 -> fc6
I0403 02:30:41.145566 19293 net.cpp:141] Setting up fc6
I0403 02:30:41.145650 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.145668 19293 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.145691 19293 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.145717 19293 net.cpp:91] Creating Layer relu6
I0403 02:30:41.145737 19293 net.cpp:425] relu6 <- fc6
I0403 02:30:41.145761 19293 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.145787 19293 net.cpp:141] Setting up relu6
I0403 02:30:41.145804 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.145818 19293 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.145833 19293 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.145854 19293 net.cpp:91] Creating Layer drop6
I0403 02:30:41.145872 19293 net.cpp:425] drop6 <- fc6
I0403 02:30:41.145892 19293 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.145932 19293 net.cpp:141] Setting up drop6
I0403 02:30:41.145954 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.145969 19293 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.145984 19293 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.146006 19293 net.cpp:91] Creating Layer fc7
I0403 02:30:41.146024 19293 net.cpp:425] fc7 <- fc6
I0403 02:30:41.146044 19293 net.cpp:399] fc7 -> fc7
I0403 02:30:41.749228 19293 net.cpp:141] Setting up fc7
I0403 02:30:41.749315 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.749335 19293 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.749357 19293 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.749382 19293 net.cpp:91] Creating Layer relu7
I0403 02:30:41.749402 19293 net.cpp:425] relu7 <- fc7
I0403 02:30:41.749423 19293 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.749452 19293 net.cpp:141] Setting up relu7
I0403 02:30:41.749470 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.749486 19293 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.749500 19293 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.749519 19293 net.cpp:91] Creating Layer drop7
I0403 02:30:41.749536 19293 net.cpp:425] drop7 <- fc7
I0403 02:30:41.749557 19293 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.749596 19293 net.cpp:141] Setting up drop7
I0403 02:30:41.749621 19293 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.749637 19293 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.749652 19293 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.749675 19293 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.749691 19293 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.749713 19293 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.755692 19293 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.755722 19293 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.755784 19293 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.755802 19293 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.755825 19293 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.755843 19293 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.755862 19293 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.755883 19293 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.755934 19293 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.755956 19293 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.755973 19293 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.755988 19293 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.756005 19293 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.756022 19293 net.cpp:91] Creating Layer loss
I0403 02:30:41.756037 19293 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.756054 19293 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.756075 19293 net.cpp:399] loss -> loss
I0403 02:30:41.756100 19293 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.756192 19293 net.cpp:141] Setting up loss
I0403 02:30:41.756217 19293 net.cpp:148] Top shape: (1)
I0403 02:30:41.756232 19293 net.cpp:151]     with loss weight 1
I0403 02:30:41.756260 19293 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.756275 19293 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.756296 19293 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.756314 19293 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.756330 19293 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.756350 19293 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.756403 19293 net.cpp:141] Setting up accuracy
I0403 02:30:41.756425 19293 net.cpp:148] Top shape: (1)
I0403 02:30:41.756446 19293 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.756461 19293 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.756479 19293 net.cpp:217] loss needs backward computation.
I0403 02:30:41.756494 19293 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.756510 19293 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.756525 19293 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.756541 19293 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.756556 19293 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.756569 19293 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.756583 19293 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.756598 19293 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.756613 19293 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.756628 19293 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.756642 19293 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.756657 19293 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.756672 19293 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.756687 19293 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.756701 19293 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.756717 19293 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.756732 19293 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.756747 19293 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.756762 19293 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.756777 19293 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.756790 19293 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.756806 19293 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.756821 19293 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.756850 19293 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.756865 19293 net.cpp:219] data does not need backward computation.
I0403 02:30:41.756880 19293 net.cpp:261] This network produces output accuracy
I0403 02:30:41.756896 19293 net.cpp:261] This network produces output loss
I0403 02:30:41.756930 19293 net.cpp:274] Network initialization done.
I0403 02:30:41.757040 19293 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.757513 19293 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.287729 19293 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.287796 19293 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.287817 19293 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.287863 19293 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.723680 19293 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.765832 19293 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.609328 19293 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.609439 19293 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.609477 19293 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.609546 19293 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.998574 19293 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.049080 19293 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.081512 19293 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.375304 19293 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.002575 19293 parallel.cpp:425] Starting Optimization
I0403 02:30:48.002732 19293 solver.cpp:279] Solving 
I0403 02:30:48.002756 19293 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.002902 19293 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:32:26.653687 19293 solver.cpp:404]     Test net output #0: accuracy = 0.0279177
I0403 02:32:26.661669 19293 solver.cpp:404]     Test net output #1: loss = 3.84908 (* 1 = 3.84908 loss)
I0403 02:32:27.243994 19293 solver.cpp:228] Iteration 0, loss = 4.03687
I0403 02:32:27.247869 19293 solver.cpp:244]     Train net output #0: loss = 4.03687 (* 1 = 4.03687 loss)
I0403 02:32:27.398344 19293 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:30.908885 19293 solver.cpp:228] Iteration 5, loss = 2.7809
I0403 02:32:30.914928 19293 solver.cpp:244]     Train net output #0: loss = 2.7809 (* 1 = 2.7809 loss)
I0403 02:32:31.135078 19293 sgd_solver.cpp:106] Iteration 5, lr = 0.005
I0403 02:32:34.573261 19293 solver.cpp:228] Iteration 10, loss = 2.0095
I0403 02:32:34.579589 19293 solver.cpp:244]     Train net output #0: loss = 2.0095 (* 1 = 2.0095 loss)
I0403 02:32:34.769491 19293 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 02:32:38.211308 19293 solver.cpp:228] Iteration 15, loss = 1.31582
I0403 02:32:38.217726 19293 solver.cpp:244]     Train net output #0: loss = 1.31582 (* 1 = 1.31582 loss)
I0403 02:32:38.435398 19293 sgd_solver.cpp:106] Iteration 15, lr = 0.005
I0403 02:32:41.869580 19293 solver.cpp:228] Iteration 20, loss = 1.13714
I0403 02:32:41.873960 19293 solver.cpp:244]     Train net output #0: loss = 1.13714 (* 1 = 1.13714 loss)
I0403 02:32:42.050463 19293 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 02:32:45.589535 19293 solver.cpp:228] Iteration 25, loss = 1.56188
I0403 02:32:45.595758 19293 solver.cpp:244]     Train net output #0: loss = 1.56188 (* 1 = 1.56188 loss)
I0403 02:32:45.755553 19293 sgd_solver.cpp:106] Iteration 25, lr = 0.005
I0403 02:32:49.235280 19293 solver.cpp:228] Iteration 30, loss = 1.20153
I0403 02:32:49.239369 19293 solver.cpp:244]     Train net output #0: loss = 1.20153 (* 1 = 1.20153 loss)
I0403 02:32:49.441417 19293 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 02:32:52.900038 19293 solver.cpp:228] Iteration 35, loss = 0.989182
I0403 02:32:52.905732 19293 solver.cpp:244]     Train net output #0: loss = 0.989182 (* 1 = 0.989182 loss)
I0403 02:32:53.091588 19293 sgd_solver.cpp:106] Iteration 35, lr = 0.005
I0403 02:32:56.509757 19293 solver.cpp:228] Iteration 40, loss = 0.962778
I0403 02:32:56.515418 19293 solver.cpp:244]     Train net output #0: loss = 0.962778 (* 1 = 0.962778 loss)
I0403 02:32:56.700691 19293 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 02:33:00.122380 19293 solver.cpp:228] Iteration 45, loss = 0.833158
I0403 02:33:00.129644 19293 solver.cpp:244]     Train net output #0: loss = 0.833158 (* 1 = 0.833158 loss)
I0403 02:33:00.306675 19293 sgd_solver.cpp:106] Iteration 45, lr = 0.005
I0403 02:33:03.768252 19293 solver.cpp:228] Iteration 50, loss = 0.825389
I0403 02:33:03.773855 19293 solver.cpp:244]     Train net output #0: loss = 0.825389 (* 1 = 0.825389 loss)
I0403 02:33:03.976739 19293 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 02:33:07.466051 19293 solver.cpp:228] Iteration 55, loss = 0.699437
I0403 02:33:07.472554 19293 solver.cpp:244]     Train net output #0: loss = 0.699437 (* 1 = 0.699437 loss)
I0403 02:33:07.629185 19293 sgd_solver.cpp:106] Iteration 55, lr = 0.005
I0403 02:33:11.263907 19293 solver.cpp:228] Iteration 60, loss = 0.609455
I0403 02:33:11.268517 19293 solver.cpp:244]     Train net output #0: loss = 0.609455 (* 1 = 0.609455 loss)
I0403 02:33:11.454617 19293 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 02:33:14.915546 19293 solver.cpp:228] Iteration 65, loss = 0.691935
I0403 02:33:14.921489 19293 solver.cpp:244]     Train net output #0: loss = 0.691935 (* 1 = 0.691935 loss)
I0403 02:33:15.091003 19293 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 02:33:18.577579 19293 solver.cpp:228] Iteration 70, loss = 0.576878
I0403 02:33:18.583783 19293 solver.cpp:244]     Train net output #0: loss = 0.576878 (* 1 = 0.576878 loss)
I0403 02:33:18.743028 19293 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 02:33:22.258432 19293 solver.cpp:228] Iteration 75, loss = 0.413278
I0403 02:33:22.264734 19293 solver.cpp:244]     Train net output #0: loss = 0.413278 (* 1 = 0.413278 loss)
I0403 02:33:22.471611 19293 sgd_solver.cpp:106] Iteration 75, lr = 0.005
I0403 02:33:25.883481 19293 solver.cpp:228] Iteration 80, loss = 0.559797
I0403 02:33:25.883579 19293 solver.cpp:244]     Train net output #0: loss = 0.559797 (* 1 = 0.559797 loss)
I0403 02:33:26.088822 19293 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:33:29.547051 19293 solver.cpp:228] Iteration 85, loss = 0.344453
I0403 02:33:29.547374 19293 solver.cpp:244]     Train net output #0: loss = 0.344453 (* 1 = 0.344453 loss)
I0403 02:33:29.757082 19293 sgd_solver.cpp:106] Iteration 85, lr = 0.005
I0403 02:33:33.235822 19293 solver.cpp:228] Iteration 90, loss = 0.48195
I0403 02:33:33.241957 19293 solver.cpp:244]     Train net output #0: loss = 0.48195 (* 1 = 0.48195 loss)
I0403 02:33:33.414542 19293 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 02:33:36.880352 19293 solver.cpp:228] Iteration 95, loss = 0.662769
I0403 02:33:36.887012 19293 solver.cpp:244]     Train net output #0: loss = 0.662769 (* 1 = 0.662769 loss)
I0403 02:33:37.060792 19293 sgd_solver.cpp:106] Iteration 95, lr = 0.005
I0403 02:33:40.507982 19293 solver.cpp:228] Iteration 100, loss = 0.537109
I0403 02:33:40.513845 19293 solver.cpp:244]     Train net output #0: loss = 0.537109 (* 1 = 0.537109 loss)
I0403 02:33:40.742516 19293 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 02:33:43.703018 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_105.caffemodel
I0403 02:33:46.572448 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_105.solverstate
I0403 02:33:48.486711 19293 solver.cpp:337] Iteration 105, Testing net (#0)
I0403 02:35:26.977880 19293 solver.cpp:404]     Test net output #0: accuracy = 0.840595
I0403 02:35:26.991751 19293 solver.cpp:404]     Test net output #1: loss = 0.508537 (* 1 = 0.508537 loss)
I0403 02:35:27.514736 19293 solver.cpp:228] Iteration 105, loss = 0.40513
I0403 02:35:27.542531 19293 solver.cpp:244]     Train net output #0: loss = 0.40513 (* 1 = 0.40513 loss)
I0403 02:35:27.695652 19293 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 02:35:31.171761 19293 solver.cpp:228] Iteration 110, loss = 0.502897
I0403 02:35:31.182930 19293 solver.cpp:244]     Train net output #0: loss = 0.502897 (* 1 = 0.502897 loss)
I0403 02:35:31.431247 19293 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 02:35:34.855068 19293 solver.cpp:228] Iteration 115, loss = 0.402255
I0403 02:35:34.861701 19293 solver.cpp:244]     Train net output #0: loss = 0.402255 (* 1 = 0.402255 loss)
I0403 02:35:35.041254 19293 sgd_solver.cpp:106] Iteration 115, lr = 0.005
I0403 02:35:38.476954 19293 solver.cpp:228] Iteration 120, loss = 0.2088
I0403 02:35:38.483005 19293 solver.cpp:244]     Train net output #0: loss = 0.2088 (* 1 = 0.2088 loss)
I0403 02:35:38.663600 19293 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 02:35:42.085496 19293 solver.cpp:228] Iteration 125, loss = 0.513848
I0403 02:35:42.094481 19293 solver.cpp:244]     Train net output #0: loss = 0.513848 (* 1 = 0.513848 loss)
I0403 02:35:42.332557 19293 sgd_solver.cpp:106] Iteration 125, lr = 0.005
I0403 02:35:45.839941 19293 solver.cpp:228] Iteration 130, loss = 0.513885
I0403 02:35:45.845597 19293 solver.cpp:244]     Train net output #0: loss = 0.513885 (* 1 = 0.513885 loss)
I0403 02:35:46.026588 19293 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:35:49.490891 19293 solver.cpp:228] Iteration 135, loss = 0.421113
I0403 02:35:49.497612 19293 solver.cpp:244]     Train net output #0: loss = 0.421113 (* 1 = 0.421113 loss)
I0403 02:35:49.664067 19293 sgd_solver.cpp:106] Iteration 135, lr = 0.005
I0403 02:35:53.180255 19293 solver.cpp:228] Iteration 140, loss = 0.268295
I0403 02:35:53.188545 19293 solver.cpp:244]     Train net output #0: loss = 0.268295 (* 1 = 0.268295 loss)
I0403 02:35:53.384482 19293 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 02:35:56.790009 19293 solver.cpp:228] Iteration 145, loss = 0.327259
I0403 02:35:56.795671 19293 solver.cpp:244]     Train net output #0: loss = 0.327259 (* 1 = 0.327259 loss)
I0403 02:35:57.011750 19293 sgd_solver.cpp:106] Iteration 145, lr = 0.005
I0403 02:36:00.478078 19293 solver.cpp:228] Iteration 150, loss = 0.350607
I0403 02:36:00.484639 19293 solver.cpp:244]     Train net output #0: loss = 0.350607 (* 1 = 0.350607 loss)
I0403 02:36:00.669992 19293 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 02:36:04.102351 19293 solver.cpp:228] Iteration 155, loss = 0.441366
I0403 02:36:04.108747 19293 solver.cpp:244]     Train net output #0: loss = 0.441366 (* 1 = 0.441366 loss)
I0403 02:36:04.294049 19293 sgd_solver.cpp:106] Iteration 155, lr = 0.005
I0403 02:36:07.728909 19293 solver.cpp:228] Iteration 160, loss = 0.2924
I0403 02:36:07.735045 19293 solver.cpp:244]     Train net output #0: loss = 0.2924 (* 1 = 0.2924 loss)
I0403 02:36:07.920368 19293 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:36:11.421303 19293 solver.cpp:228] Iteration 165, loss = 0.325911
I0403 02:36:11.427757 19293 solver.cpp:244]     Train net output #0: loss = 0.325911 (* 1 = 0.325911 loss)
I0403 02:36:11.621090 19293 sgd_solver.cpp:106] Iteration 165, lr = 0.005
I0403 02:36:15.083909 19293 solver.cpp:228] Iteration 170, loss = 0.417174
I0403 02:36:15.089993 19293 solver.cpp:244]     Train net output #0: loss = 0.417174 (* 1 = 0.417174 loss)
I0403 02:36:15.275787 19293 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 02:36:18.710316 19293 solver.cpp:228] Iteration 175, loss = 0.416917
I0403 02:36:18.716122 19293 solver.cpp:244]     Train net output #0: loss = 0.416917 (* 1 = 0.416917 loss)
I0403 02:36:18.907470 19293 sgd_solver.cpp:106] Iteration 175, lr = 0.005
I0403 02:36:22.437768 19293 solver.cpp:228] Iteration 180, loss = 0.27835
I0403 02:36:22.444268 19293 solver.cpp:244]     Train net output #0: loss = 0.27835 (* 1 = 0.27835 loss)
I0403 02:36:22.628298 19293 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 02:36:26.119285 19293 solver.cpp:228] Iteration 185, loss = 0.308399
I0403 02:36:26.125079 19293 solver.cpp:244]     Train net output #0: loss = 0.308399 (* 1 = 0.308399 loss)
I0403 02:36:26.314651 19293 sgd_solver.cpp:106] Iteration 185, lr = 0.005
I0403 02:36:29.721947 19293 solver.cpp:228] Iteration 190, loss = 0.266593
I0403 02:36:29.727857 19293 solver.cpp:244]     Train net output #0: loss = 0.266593 (* 1 = 0.266593 loss)
I0403 02:36:29.949123 19293 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 02:36:33.449690 19293 solver.cpp:228] Iteration 195, loss = 0.411029
I0403 02:36:33.455534 19293 solver.cpp:244]     Train net output #0: loss = 0.411029 (* 1 = 0.411029 loss)
I0403 02:36:33.652303 19293 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 02:36:37.142771 19293 solver.cpp:228] Iteration 200, loss = 0.441365
I0403 02:36:37.148798 19293 solver.cpp:244]     Train net output #0: loss = 0.441365 (* 1 = 0.441365 loss)
I0403 02:36:37.341449 19293 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 02:36:40.828058 19293 solver.cpp:228] Iteration 205, loss = 0.491897
I0403 02:36:40.833675 19293 solver.cpp:244]     Train net output #0: loss = 0.491897 (* 1 = 0.491897 loss)
I0403 02:36:41.034018 19293 sgd_solver.cpp:106] Iteration 205, lr = 0.005
I0403 02:36:43.924810 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_210.caffemodel
I0403 02:36:46.674365 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_210.solverstate
I0403 02:36:48.583185 19293 solver.cpp:337] Iteration 210, Testing net (#0)
I0403 02:38:27.074111 19293 solver.cpp:404]     Test net output #0: accuracy = 0.880366
I0403 02:38:27.080066 19293 solver.cpp:404]     Test net output #1: loss = 0.373261 (* 1 = 0.373261 loss)
I0403 02:38:27.602783 19293 solver.cpp:228] Iteration 210, loss = 0.4025
I0403 02:38:27.607972 19293 solver.cpp:244]     Train net output #0: loss = 0.4025 (* 1 = 0.4025 loss)
I0403 02:38:27.784412 19293 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:38:31.263027 19293 solver.cpp:228] Iteration 215, loss = 0.402673
I0403 02:38:31.269646 19293 solver.cpp:244]     Train net output #0: loss = 0.402673 (* 1 = 0.402673 loss)
I0403 02:38:31.442083 19293 sgd_solver.cpp:106] Iteration 215, lr = 0.005
I0403 02:38:34.904150 19293 solver.cpp:228] Iteration 220, loss = 0.294859
I0403 02:38:34.904250 19293 solver.cpp:244]     Train net output #0: loss = 0.294859 (* 1 = 0.294859 loss)
I0403 02:38:35.095188 19293 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 02:38:38.513444 19293 solver.cpp:228] Iteration 225, loss = 0.414144
I0403 02:38:38.520748 19293 solver.cpp:244]     Train net output #0: loss = 0.414144 (* 1 = 0.414144 loss)
I0403 02:38:38.714395 19293 sgd_solver.cpp:106] Iteration 225, lr = 0.005
I0403 02:38:42.158674 19293 solver.cpp:228] Iteration 230, loss = 0.377763
I0403 02:38:42.169878 19293 solver.cpp:244]     Train net output #0: loss = 0.377763 (* 1 = 0.377763 loss)
I0403 02:38:42.365566 19293 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 02:38:45.763902 19293 solver.cpp:228] Iteration 235, loss = 0.276994
I0403 02:38:45.764003 19293 solver.cpp:244]     Train net output #0: loss = 0.276994 (* 1 = 0.276994 loss)
I0403 02:38:46.012533 19293 sgd_solver.cpp:106] Iteration 235, lr = 0.005
I0403 02:38:49.472646 19293 solver.cpp:228] Iteration 240, loss = 0.302606
I0403 02:38:49.472743 19293 solver.cpp:244]     Train net output #0: loss = 0.302606 (* 1 = 0.302606 loss)
I0403 02:38:49.664739 19293 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:38:53.168597 19293 solver.cpp:228] Iteration 245, loss = 0.188171
I0403 02:38:53.168696 19293 solver.cpp:244]     Train net output #0: loss = 0.188171 (* 1 = 0.188171 loss)
I0403 02:38:53.368353 19293 sgd_solver.cpp:106] Iteration 245, lr = 0.005
I0403 02:38:56.770615 19293 solver.cpp:228] Iteration 250, loss = 0.392766
I0403 02:38:56.770714 19293 solver.cpp:244]     Train net output #0: loss = 0.392766 (* 1 = 0.392766 loss)
I0403 02:38:56.974144 19293 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 02:39:00.441161 19293 solver.cpp:228] Iteration 255, loss = 0.233247
I0403 02:39:00.441522 19293 solver.cpp:244]     Train net output #0: loss = 0.233247 (* 1 = 0.233247 loss)
I0403 02:39:00.625541 19293 sgd_solver.cpp:106] Iteration 255, lr = 0.005
I0403 02:39:04.083281 19293 solver.cpp:228] Iteration 260, loss = 0.17716
I0403 02:39:04.083374 19293 solver.cpp:244]     Train net output #0: loss = 0.17716 (* 1 = 0.17716 loss)
I0403 02:39:04.276754 19293 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:39:07.735604 19293 solver.cpp:228] Iteration 265, loss = 0.230825
I0403 02:39:07.735703 19293 solver.cpp:244]     Train net output #0: loss = 0.230825 (* 1 = 0.230825 loss)
I0403 02:39:07.951691 19293 sgd_solver.cpp:106] Iteration 265, lr = 0.005
I0403 02:39:11.384546 19293 solver.cpp:228] Iteration 270, loss = 0.241432
I0403 02:39:11.384642 19293 solver.cpp:244]     Train net output #0: loss = 0.241432 (* 1 = 0.241432 loss)
I0403 02:39:11.576128 19293 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 02:39:15.040401 19293 solver.cpp:228] Iteration 275, loss = 0.27991
I0403 02:39:15.040505 19293 solver.cpp:244]     Train net output #0: loss = 0.27991 (* 1 = 0.27991 loss)
I0403 02:39:15.226558 19293 sgd_solver.cpp:106] Iteration 275, lr = 0.005
I0403 02:39:18.707056 19293 solver.cpp:228] Iteration 280, loss = 0.402609
I0403 02:39:18.707151 19293 solver.cpp:244]     Train net output #0: loss = 0.402609 (* 1 = 0.402609 loss)
I0403 02:39:18.905040 19293 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 02:39:22.334792 19293 solver.cpp:228] Iteration 285, loss = 0.274451
I0403 02:39:22.334889 19293 solver.cpp:244]     Train net output #0: loss = 0.274451 (* 1 = 0.274451 loss)
I0403 02:39:22.542153 19293 sgd_solver.cpp:106] Iteration 285, lr = 0.005
I0403 02:39:26.089526 19293 solver.cpp:228] Iteration 290, loss = 0.13078
I0403 02:39:26.089627 19293 solver.cpp:244]     Train net output #0: loss = 0.13078 (* 1 = 0.13078 loss)
I0403 02:39:26.275074 19293 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 02:39:29.837271 19293 solver.cpp:228] Iteration 295, loss = 0.169608
I0403 02:39:29.837376 19293 solver.cpp:244]     Train net output #0: loss = 0.169608 (* 1 = 0.169608 loss)
I0403 02:39:30.131757 19293 sgd_solver.cpp:106] Iteration 295, lr = 0.005
I0403 02:39:33.647867 19293 solver.cpp:228] Iteration 300, loss = 0.259045
I0403 02:39:33.648178 19293 solver.cpp:244]     Train net output #0: loss = 0.259045 (* 1 = 0.259045 loss)
I0403 02:39:33.831202 19293 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 02:39:37.271512 19293 solver.cpp:228] Iteration 305, loss = 0.10462
I0403 02:39:37.271607 19293 solver.cpp:244]     Train net output #0: loss = 0.10462 (* 1 = 0.10462 loss)
I0403 02:39:37.499052 19293 sgd_solver.cpp:106] Iteration 305, lr = 0.005
I0403 02:39:41.032860 19293 solver.cpp:228] Iteration 310, loss = 0.309347
I0403 02:39:41.032958 19293 solver.cpp:244]     Train net output #0: loss = 0.309347 (* 1 = 0.309347 loss)
I0403 02:39:41.230376 19293 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 02:39:44.158890 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_315.caffemodel
I0403 02:39:46.787737 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_315.solverstate
I0403 02:39:48.545114 19293 solver.cpp:337] Iteration 315, Testing net (#0)
I0403 02:41:27.031865 19293 solver.cpp:404]     Test net output #0: accuracy = 0.885561
I0403 02:41:27.038890 19293 solver.cpp:404]     Test net output #1: loss = 0.358235 (* 1 = 0.358235 loss)
I0403 02:41:27.550707 19293 solver.cpp:228] Iteration 315, loss = 0.306541
I0403 02:41:27.556648 19293 solver.cpp:244]     Train net output #0: loss = 0.306541 (* 1 = 0.306541 loss)
I0403 02:41:27.740144 19293 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 02:41:31.192291 19293 solver.cpp:228] Iteration 320, loss = 0.225356
I0403 02:41:31.199165 19293 solver.cpp:244]     Train net output #0: loss = 0.225356 (* 1 = 0.225356 loss)
I0403 02:41:31.422019 19293 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:41:34.874963 19293 solver.cpp:228] Iteration 325, loss = 0.158646
I0403 02:41:34.881469 19293 solver.cpp:244]     Train net output #0: loss = 0.158646 (* 1 = 0.158646 loss)
I0403 02:41:35.079294 19293 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 02:41:38.494604 19293 solver.cpp:228] Iteration 330, loss = 0.228589
I0403 02:41:38.501447 19293 solver.cpp:244]     Train net output #0: loss = 0.228589 (* 1 = 0.228589 loss)
I0403 02:41:38.724925 19293 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 02:41:42.193321 19293 solver.cpp:228] Iteration 335, loss = 0.169259
I0403 02:41:42.199831 19293 solver.cpp:244]     Train net output #0: loss = 0.169259 (* 1 = 0.169259 loss)
I0403 02:41:42.391384 19293 sgd_solver.cpp:106] Iteration 335, lr = 0.005
I0403 02:41:45.806816 19293 solver.cpp:228] Iteration 340, loss = 0.280449
I0403 02:41:45.813830 19293 solver.cpp:244]     Train net output #0: loss = 0.280449 (* 1 = 0.280449 loss)
I0403 02:41:46.006305 19293 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 02:41:49.421478 19293 solver.cpp:228] Iteration 345, loss = 0.139101
I0403 02:41:49.427788 19293 solver.cpp:244]     Train net output #0: loss = 0.139101 (* 1 = 0.139101 loss)
I0403 02:41:49.642066 19293 sgd_solver.cpp:106] Iteration 345, lr = 0.005
I0403 02:41:53.113559 19293 solver.cpp:228] Iteration 350, loss = 0.107867
I0403 02:41:53.120412 19293 solver.cpp:244]     Train net output #0: loss = 0.107867 (* 1 = 0.107867 loss)
I0403 02:41:53.304908 19293 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 02:41:56.778589 19293 solver.cpp:228] Iteration 355, loss = 0.241282
I0403 02:41:56.784709 19293 solver.cpp:244]     Train net output #0: loss = 0.241282 (* 1 = 0.241282 loss)
I0403 02:41:56.900976 19293 sgd_solver.cpp:106] Iteration 355, lr = 0.005
I0403 02:42:00.482779 19293 solver.cpp:228] Iteration 360, loss = 0.158187
I0403 02:42:00.489631 19293 solver.cpp:244]     Train net output #0: loss = 0.158187 (* 1 = 0.158187 loss)
I0403 02:42:00.706590 19293 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 02:42:04.190456 19293 solver.cpp:228] Iteration 365, loss = 0.224001
I0403 02:42:04.196902 19293 solver.cpp:244]     Train net output #0: loss = 0.224001 (* 1 = 0.224001 loss)
I0403 02:42:04.450978 19293 sgd_solver.cpp:106] Iteration 365, lr = 0.005
I0403 02:42:07.895190 19293 solver.cpp:228] Iteration 370, loss = 0.309257
I0403 02:42:07.901499 19293 solver.cpp:244]     Train net output #0: loss = 0.309257 (* 1 = 0.309257 loss)
I0403 02:42:08.080551 19293 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 02:42:11.483275 19293 solver.cpp:228] Iteration 375, loss = 0.158182
I0403 02:42:11.489615 19293 solver.cpp:244]     Train net output #0: loss = 0.158182 (* 1 = 0.158182 loss)
I0403 02:42:11.744282 19293 sgd_solver.cpp:106] Iteration 375, lr = 0.005
I0403 02:42:15.199180 19293 solver.cpp:228] Iteration 380, loss = 0.130074
I0403 02:42:15.205739 19293 solver.cpp:244]     Train net output #0: loss = 0.130074 (* 1 = 0.130074 loss)
I0403 02:42:15.420878 19293 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 02:42:18.897114 19293 solver.cpp:228] Iteration 385, loss = 0.114893
I0403 02:42:18.903718 19293 solver.cpp:244]     Train net output #0: loss = 0.114893 (* 1 = 0.114893 loss)
I0403 02:42:19.094120 19293 sgd_solver.cpp:106] Iteration 385, lr = 0.005
I0403 02:42:22.571765 19293 solver.cpp:228] Iteration 390, loss = 0.1017
I0403 02:42:22.578166 19293 solver.cpp:244]     Train net output #0: loss = 0.1017 (* 1 = 0.1017 loss)
I0403 02:42:22.756212 19293 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:42:26.179924 19293 solver.cpp:228] Iteration 395, loss = 0.258175
I0403 02:42:26.185542 19293 solver.cpp:244]     Train net output #0: loss = 0.258175 (* 1 = 0.258175 loss)
I0403 02:42:26.376996 19293 sgd_solver.cpp:106] Iteration 395, lr = 0.005
I0403 02:42:29.871302 19293 solver.cpp:228] Iteration 400, loss = 0.18113
I0403 02:42:29.876878 19293 solver.cpp:244]     Train net output #0: loss = 0.18113 (* 1 = 0.18113 loss)
I0403 02:42:30.060605 19293 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:42:33.472915 19293 solver.cpp:228] Iteration 405, loss = 0.143576
I0403 02:42:33.479326 19293 solver.cpp:244]     Train net output #0: loss = 0.143576 (* 1 = 0.143576 loss)
I0403 02:42:33.669773 19293 sgd_solver.cpp:106] Iteration 405, lr = 0.005
I0403 02:42:37.086753 19293 solver.cpp:228] Iteration 410, loss = 0.150169
I0403 02:42:37.113620 19293 solver.cpp:244]     Train net output #0: loss = 0.150169 (* 1 = 0.150169 loss)
I0403 02:42:37.302753 19293 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 02:42:40.772472 19293 solver.cpp:228] Iteration 415, loss = 0.192166
I0403 02:42:40.779373 19293 solver.cpp:244]     Train net output #0: loss = 0.192166 (* 1 = 0.192166 loss)
I0403 02:42:40.950335 19293 sgd_solver.cpp:106] Iteration 415, lr = 0.005
I0403 02:42:43.884687 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_420.caffemodel
I0403 02:42:46.740699 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_420.solverstate
I0403 02:42:48.651321 19293 solver.cpp:337] Iteration 420, Testing net (#0)
I0403 02:44:27.179697 19293 solver.cpp:404]     Test net output #0: accuracy = 0.888924
I0403 02:44:27.187196 19293 solver.cpp:404]     Test net output #1: loss = 0.363868 (* 1 = 0.363868 loss)
I0403 02:44:27.705006 19293 solver.cpp:228] Iteration 420, loss = 0.146007
I0403 02:44:27.711143 19293 solver.cpp:244]     Train net output #0: loss = 0.146007 (* 1 = 0.146007 loss)
I0403 02:44:27.897380 19293 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:44:31.340574 19293 solver.cpp:228] Iteration 425, loss = 0.166915
I0403 02:44:31.351008 19293 solver.cpp:244]     Train net output #0: loss = 0.166915 (* 1 = 0.166915 loss)
I0403 02:44:31.581493 19293 sgd_solver.cpp:106] Iteration 425, lr = 0.005
I0403 02:44:35.012562 19293 solver.cpp:228] Iteration 430, loss = 0.140237
I0403 02:44:35.018510 19293 solver.cpp:244]     Train net output #0: loss = 0.140237 (* 1 = 0.140237 loss)
I0403 02:44:35.210947 19293 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 02:44:38.676796 19293 solver.cpp:228] Iteration 435, loss = 0.27179
I0403 02:44:38.683075 19293 solver.cpp:244]     Train net output #0: loss = 0.27179 (* 1 = 0.27179 loss)
I0403 02:44:38.860818 19293 sgd_solver.cpp:106] Iteration 435, lr = 0.005
I0403 02:44:42.323915 19293 solver.cpp:228] Iteration 440, loss = 0.132841
I0403 02:44:42.330255 19293 solver.cpp:244]     Train net output #0: loss = 0.132841 (* 1 = 0.132841 loss)
I0403 02:44:42.520098 19293 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 02:44:46.027829 19293 solver.cpp:228] Iteration 445, loss = 0.060897
I0403 02:44:46.034591 19293 solver.cpp:244]     Train net output #0: loss = 0.060897 (* 1 = 0.060897 loss)
I0403 02:44:46.234704 19293 sgd_solver.cpp:106] Iteration 445, lr = 0.005
I0403 02:44:49.714022 19293 solver.cpp:228] Iteration 450, loss = 0.147989
I0403 02:44:49.720638 19293 solver.cpp:244]     Train net output #0: loss = 0.147989 (* 1 = 0.147989 loss)
I0403 02:44:49.915000 19293 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 02:44:53.327782 19293 solver.cpp:228] Iteration 455, loss = 0.0792725
I0403 02:44:53.334466 19293 solver.cpp:244]     Train net output #0: loss = 0.0792725 (* 1 = 0.0792725 loss)
I0403 02:44:53.572896 19293 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 02:44:57.057626 19293 solver.cpp:228] Iteration 460, loss = 0.14458
I0403 02:44:57.063277 19293 solver.cpp:244]     Train net output #0: loss = 0.14458 (* 1 = 0.14458 loss)
I0403 02:44:57.249661 19293 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 02:45:00.681530 19293 solver.cpp:228] Iteration 465, loss = 0.14456
I0403 02:45:00.686794 19293 solver.cpp:244]     Train net output #0: loss = 0.14456 (* 1 = 0.14456 loss)
I0403 02:45:00.880528 19293 sgd_solver.cpp:106] Iteration 465, lr = 0.005
I0403 02:45:04.381328 19293 solver.cpp:228] Iteration 470, loss = 0.144347
I0403 02:45:04.387971 19293 solver.cpp:244]     Train net output #0: loss = 0.144347 (* 1 = 0.144347 loss)
I0403 02:45:04.577496 19293 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 02:45:08.087450 19293 solver.cpp:228] Iteration 475, loss = 0.0880424
I0403 02:45:08.094239 19293 solver.cpp:244]     Train net output #0: loss = 0.0880424 (* 1 = 0.0880424 loss)
I0403 02:45:08.261106 19293 sgd_solver.cpp:106] Iteration 475, lr = 0.005
I0403 02:45:11.779203 19293 solver.cpp:228] Iteration 480, loss = 0.171569
I0403 02:45:11.785532 19293 solver.cpp:244]     Train net output #0: loss = 0.171569 (* 1 = 0.171569 loss)
I0403 02:45:12.021738 19293 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:45:15.482173 19293 solver.cpp:228] Iteration 485, loss = 0.149863
I0403 02:45:15.487380 19293 solver.cpp:244]     Train net output #0: loss = 0.149863 (* 1 = 0.149863 loss)
I0403 02:45:15.675494 19293 sgd_solver.cpp:106] Iteration 485, lr = 0.005
I0403 02:45:19.122663 19293 solver.cpp:228] Iteration 490, loss = 0.101617
I0403 02:45:19.127790 19293 solver.cpp:244]     Train net output #0: loss = 0.101617 (* 1 = 0.101617 loss)
I0403 02:45:19.342483 19293 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 02:45:22.775665 19293 solver.cpp:228] Iteration 495, loss = 0.190086
I0403 02:45:22.785934 19293 solver.cpp:244]     Train net output #0: loss = 0.190086 (* 1 = 0.190086 loss)
I0403 02:45:23.011034 19293 sgd_solver.cpp:106] Iteration 495, lr = 0.005
I0403 02:45:26.564780 19293 solver.cpp:228] Iteration 500, loss = 0.0810715
I0403 02:45:26.571198 19293 solver.cpp:244]     Train net output #0: loss = 0.0810715 (* 1 = 0.0810715 loss)
I0403 02:45:26.744899 19293 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 02:45:30.270298 19293 solver.cpp:228] Iteration 505, loss = 0.146987
I0403 02:45:30.276726 19293 solver.cpp:244]     Train net output #0: loss = 0.146987 (* 1 = 0.146987 loss)
I0403 02:45:30.461578 19293 sgd_solver.cpp:106] Iteration 505, lr = 0.005
I0403 02:45:33.948637 19293 solver.cpp:228] Iteration 510, loss = 0.0975484
I0403 02:45:33.954532 19293 solver.cpp:244]     Train net output #0: loss = 0.0975484 (* 1 = 0.0975484 loss)
I0403 02:45:34.124933 19293 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 02:45:37.581969 19293 solver.cpp:228] Iteration 515, loss = 0.0708646
I0403 02:45:37.587987 19293 solver.cpp:244]     Train net output #0: loss = 0.0708646 (* 1 = 0.0708646 loss)
I0403 02:45:37.783576 19293 sgd_solver.cpp:106] Iteration 515, lr = 0.005
I0403 02:45:41.254997 19293 solver.cpp:228] Iteration 520, loss = 0.0771907
I0403 02:45:41.261608 19293 solver.cpp:244]     Train net output #0: loss = 0.0771907 (* 1 = 0.0771907 loss)
I0403 02:45:41.455184 19293 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:45:44.424975 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_525.caffemodel
I0403 02:45:47.075644 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_525.solverstate
I0403 02:45:48.866075 19293 solver.cpp:337] Iteration 525, Testing net (#0)
I0403 02:47:27.363543 19293 solver.cpp:404]     Test net output #0: accuracy = 0.908788
I0403 02:47:27.369885 19293 solver.cpp:404]     Test net output #1: loss = 0.319861 (* 1 = 0.319861 loss)
I0403 02:47:27.899472 19293 solver.cpp:228] Iteration 525, loss = 0.0321015
I0403 02:47:27.905376 19293 solver.cpp:244]     Train net output #0: loss = 0.0321015 (* 1 = 0.0321015 loss)
I0403 02:47:28.077971 19293 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 02:47:31.619105 19293 solver.cpp:228] Iteration 530, loss = 0.0820928
I0403 02:47:31.625815 19293 solver.cpp:244]     Train net output #0: loss = 0.0820928 (* 1 = 0.0820928 loss)
I0403 02:47:31.815893 19293 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 02:47:35.281767 19293 solver.cpp:228] Iteration 535, loss = 0.101468
I0403 02:47:35.288630 19293 solver.cpp:244]     Train net output #0: loss = 0.101468 (* 1 = 0.101468 loss)
I0403 02:47:35.499469 19293 sgd_solver.cpp:106] Iteration 535, lr = 0.005
I0403 02:47:38.992838 19293 solver.cpp:228] Iteration 540, loss = 0.0837497
I0403 02:47:38.998147 19293 solver.cpp:244]     Train net output #0: loss = 0.0837497 (* 1 = 0.0837497 loss)
I0403 02:47:39.178820 19293 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 02:47:42.632086 19293 solver.cpp:228] Iteration 545, loss = 0.125118
I0403 02:47:42.638056 19293 solver.cpp:244]     Train net output #0: loss = 0.125118 (* 1 = 0.125118 loss)
I0403 02:47:42.836835 19293 sgd_solver.cpp:106] Iteration 545, lr = 0.005
I0403 02:47:46.247372 19293 solver.cpp:228] Iteration 550, loss = 0.221581
I0403 02:47:46.253720 19293 solver.cpp:244]     Train net output #0: loss = 0.221581 (* 1 = 0.221581 loss)
I0403 02:47:46.512037 19293 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 02:47:50.033154 19293 solver.cpp:228] Iteration 555, loss = 0.193227
I0403 02:47:50.039093 19293 solver.cpp:244]     Train net output #0: loss = 0.193227 (* 1 = 0.193227 loss)
I0403 02:47:50.251056 19293 sgd_solver.cpp:106] Iteration 555, lr = 0.005
I0403 02:47:53.762320 19293 solver.cpp:228] Iteration 560, loss = 0.23199
I0403 02:47:53.768771 19293 solver.cpp:244]     Train net output #0: loss = 0.23199 (* 1 = 0.23199 loss)
I0403 02:47:53.960064 19293 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:47:57.367305 19293 solver.cpp:228] Iteration 565, loss = 0.231544
I0403 02:47:57.373911 19293 solver.cpp:244]     Train net output #0: loss = 0.231544 (* 1 = 0.231544 loss)
I0403 02:47:57.574635 19293 sgd_solver.cpp:106] Iteration 565, lr = 0.005
I0403 02:48:01.035574 19293 solver.cpp:228] Iteration 570, loss = 0.131157
I0403 02:48:01.040992 19293 solver.cpp:244]     Train net output #0: loss = 0.131157 (* 1 = 0.131157 loss)
I0403 02:48:01.217602 19293 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 02:48:04.676960 19293 solver.cpp:228] Iteration 575, loss = 0.197512
I0403 02:48:04.683185 19293 solver.cpp:244]     Train net output #0: loss = 0.197512 (* 1 = 0.197512 loss)
I0403 02:48:04.864053 19293 sgd_solver.cpp:106] Iteration 575, lr = 0.005
I0403 02:48:08.292479 19293 solver.cpp:228] Iteration 580, loss = 0.133756
I0403 02:48:08.298868 19293 solver.cpp:244]     Train net output #0: loss = 0.133756 (* 1 = 0.133756 loss)
I0403 02:48:08.531481 19293 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 02:48:12.060436 19293 solver.cpp:228] Iteration 585, loss = 0.056039
I0403 02:48:12.066839 19293 solver.cpp:244]     Train net output #0: loss = 0.056039 (* 1 = 0.056039 loss)
I0403 02:48:12.249107 19293 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 02:48:15.675500 19293 solver.cpp:228] Iteration 590, loss = 0.144512
I0403 02:48:15.680968 19293 solver.cpp:244]     Train net output #0: loss = 0.144512 (* 1 = 0.144512 loss)
I0403 02:48:15.883473 19293 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 02:48:19.329346 19293 solver.cpp:228] Iteration 595, loss = 0.16471
I0403 02:48:19.335767 19293 solver.cpp:244]     Train net output #0: loss = 0.16471 (* 1 = 0.16471 loss)
I0403 02:48:19.531798 19293 sgd_solver.cpp:106] Iteration 595, lr = 0.005
I0403 02:48:22.970724 19293 solver.cpp:228] Iteration 600, loss = 0.195666
I0403 02:48:22.977752 19293 solver.cpp:244]     Train net output #0: loss = 0.195666 (* 1 = 0.195666 loss)
I0403 02:48:23.158715 19293 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 02:48:26.573038 19293 solver.cpp:228] Iteration 605, loss = 0.168124
I0403 02:48:26.580247 19293 solver.cpp:244]     Train net output #0: loss = 0.168124 (* 1 = 0.168124 loss)
I0403 02:48:26.793728 19293 sgd_solver.cpp:106] Iteration 605, lr = 0.005
I0403 02:48:30.274263 19293 solver.cpp:228] Iteration 610, loss = 0.110009
I0403 02:48:30.280002 19293 solver.cpp:244]     Train net output #0: loss = 0.110009 (* 1 = 0.110009 loss)
I0403 02:48:30.456069 19293 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 02:48:33.924190 19293 solver.cpp:228] Iteration 615, loss = 0.066965
I0403 02:48:33.930068 19293 solver.cpp:244]     Train net output #0: loss = 0.066965 (* 1 = 0.066965 loss)
I0403 02:48:34.126129 19293 sgd_solver.cpp:106] Iteration 615, lr = 0.005
I0403 02:48:37.628231 19293 solver.cpp:228] Iteration 620, loss = 0.121385
I0403 02:48:37.634148 19293 solver.cpp:244]     Train net output #0: loss = 0.121385 (* 1 = 0.121385 loss)
I0403 02:48:37.826491 19293 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 02:48:41.298751 19293 solver.cpp:228] Iteration 625, loss = 0.0768875
I0403 02:48:41.305074 19293 solver.cpp:244]     Train net output #0: loss = 0.0768875 (* 1 = 0.0768875 loss)
I0403 02:48:41.480659 19293 sgd_solver.cpp:106] Iteration 625, lr = 0.005
I0403 02:48:44.449321 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_630.caffemodel
I0403 02:48:47.172035 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_630.solverstate
I0403 02:48:48.976080 19293 solver.cpp:337] Iteration 630, Testing net (#0)
I0403 02:50:27.481700 19293 solver.cpp:404]     Test net output #0: accuracy = 0.909406
I0403 02:50:27.488535 19293 solver.cpp:404]     Test net output #1: loss = 0.302248 (* 1 = 0.302248 loss)
I0403 02:50:28.035678 19293 solver.cpp:228] Iteration 630, loss = 0.0974259
I0403 02:50:28.042244 19293 solver.cpp:244]     Train net output #0: loss = 0.0974259 (* 1 = 0.0974259 loss)
I0403 02:50:28.174854 19293 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:50:31.880928 19293 solver.cpp:228] Iteration 635, loss = 0.111834
I0403 02:50:31.887269 19293 solver.cpp:244]     Train net output #0: loss = 0.111834 (* 1 = 0.111834 loss)
I0403 02:50:32.095278 19293 sgd_solver.cpp:106] Iteration 635, lr = 0.005
I0403 02:50:35.538485 19293 solver.cpp:228] Iteration 640, loss = 0.151048
I0403 02:50:35.544044 19293 solver.cpp:244]     Train net output #0: loss = 0.151048 (* 1 = 0.151048 loss)
I0403 02:50:35.718161 19293 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:50:39.128495 19293 solver.cpp:228] Iteration 645, loss = 0.137311
I0403 02:50:39.134233 19293 solver.cpp:244]     Train net output #0: loss = 0.137311 (* 1 = 0.137311 loss)
I0403 02:50:39.327103 19293 sgd_solver.cpp:106] Iteration 645, lr = 0.005
I0403 02:50:42.731400 19293 solver.cpp:228] Iteration 650, loss = 0.103735
I0403 02:50:42.736609 19293 solver.cpp:244]     Train net output #0: loss = 0.103735 (* 1 = 0.103735 loss)
I0403 02:50:42.938062 19293 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:50:46.402775 19293 solver.cpp:228] Iteration 655, loss = 0.0858494
I0403 02:50:46.408969 19293 solver.cpp:244]     Train net output #0: loss = 0.0858494 (* 1 = 0.0858494 loss)
I0403 02:50:46.605420 19293 sgd_solver.cpp:106] Iteration 655, lr = 0.005
I0403 02:50:50.091260 19293 solver.cpp:228] Iteration 660, loss = 0.028921
I0403 02:50:50.098112 19293 solver.cpp:244]     Train net output #0: loss = 0.028921 (* 1 = 0.028921 loss)
I0403 02:50:50.372262 19293 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 02:50:53.841199 19293 solver.cpp:228] Iteration 665, loss = 0.0928367
I0403 02:50:53.846563 19293 solver.cpp:244]     Train net output #0: loss = 0.0928367 (* 1 = 0.0928367 loss)
I0403 02:50:54.045193 19293 sgd_solver.cpp:106] Iteration 665, lr = 0.005
I0403 02:50:57.675104 19293 solver.cpp:228] Iteration 670, loss = 0.0782962
I0403 02:50:57.680516 19293 solver.cpp:244]     Train net output #0: loss = 0.0782962 (* 1 = 0.0782962 loss)
I0403 02:50:57.804050 19293 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 02:51:01.320425 19293 solver.cpp:228] Iteration 675, loss = 0.034951
I0403 02:51:01.326513 19293 solver.cpp:244]     Train net output #0: loss = 0.034951 (* 1 = 0.034951 loss)
I0403 02:51:01.514009 19293 sgd_solver.cpp:106] Iteration 675, lr = 0.005
I0403 02:51:04.942769 19293 solver.cpp:228] Iteration 680, loss = 0.181839
I0403 02:51:04.964395 19293 solver.cpp:244]     Train net output #0: loss = 0.181839 (* 1 = 0.181839 loss)
I0403 02:51:05.135601 19293 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 02:51:08.670440 19293 solver.cpp:228] Iteration 685, loss = 0.152299
I0403 02:51:08.677343 19293 solver.cpp:244]     Train net output #0: loss = 0.152299 (* 1 = 0.152299 loss)
I0403 02:51:08.887560 19293 sgd_solver.cpp:106] Iteration 685, lr = 0.005
I0403 02:51:12.353329 19293 solver.cpp:228] Iteration 690, loss = 0.199224
I0403 02:51:12.359567 19293 solver.cpp:244]     Train net output #0: loss = 0.199224 (* 1 = 0.199224 loss)
I0403 02:51:12.540596 19293 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 02:51:15.999629 19293 solver.cpp:228] Iteration 695, loss = 0.0311142
I0403 02:51:16.004886 19293 solver.cpp:244]     Train net output #0: loss = 0.0311141 (* 1 = 0.0311141 loss)
I0403 02:51:16.189586 19293 sgd_solver.cpp:106] Iteration 695, lr = 0.005
I0403 02:51:19.617776 19293 solver.cpp:228] Iteration 700, loss = 0.128723
I0403 02:51:19.624080 19293 solver.cpp:244]     Train net output #0: loss = 0.128723 (* 1 = 0.128723 loss)
I0403 02:51:19.828124 19293 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 02:51:23.228291 19293 solver.cpp:228] Iteration 705, loss = 0.108273
I0403 02:51:23.233759 19293 solver.cpp:244]     Train net output #0: loss = 0.108273 (* 1 = 0.108273 loss)
I0403 02:51:23.470767 19293 sgd_solver.cpp:106] Iteration 705, lr = 0.005
I0403 02:51:26.960065 19293 solver.cpp:228] Iteration 710, loss = 0.048902
I0403 02:51:26.965315 19293 solver.cpp:244]     Train net output #0: loss = 0.0489019 (* 1 = 0.0489019 loss)
I0403 02:51:27.161517 19293 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 02:51:30.614452 19293 solver.cpp:228] Iteration 715, loss = 0.073457
I0403 02:51:30.620965 19293 solver.cpp:244]     Train net output #0: loss = 0.0734569 (* 1 = 0.0734569 loss)
I0403 02:51:30.811141 19293 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 02:51:34.292273 19293 solver.cpp:228] Iteration 720, loss = 0.0467323
I0403 02:51:34.298177 19293 solver.cpp:244]     Train net output #0: loss = 0.0467322 (* 1 = 0.0467322 loss)
I0403 02:51:34.470903 19293 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:51:37.944432 19293 solver.cpp:228] Iteration 725, loss = 0.0268924
I0403 02:51:37.950649 19293 solver.cpp:244]     Train net output #0: loss = 0.0268924 (* 1 = 0.0268924 loss)
I0403 02:51:38.152246 19293 sgd_solver.cpp:106] Iteration 725, lr = 0.005
I0403 02:51:41.569238 19293 solver.cpp:228] Iteration 730, loss = 0.0174638
I0403 02:51:41.575733 19293 solver.cpp:244]     Train net output #0: loss = 0.0174638 (* 1 = 0.0174638 loss)
I0403 02:51:41.760308 19293 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 02:51:44.651470 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_735.caffemodel
I0403 02:51:47.312405 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_735.solverstate
I0403 02:51:49.145848 19293 solver.cpp:337] Iteration 735, Testing net (#0)
I0403 02:53:27.639509 19293 solver.cpp:404]     Test net output #0: accuracy = 0.90595
I0403 02:53:27.646745 19293 solver.cpp:404]     Test net output #1: loss = 0.33781 (* 1 = 0.33781 loss)
I0403 02:53:28.151545 19293 solver.cpp:228] Iteration 735, loss = 0.187308
I0403 02:53:28.157110 19293 solver.cpp:244]     Train net output #0: loss = 0.187308 (* 1 = 0.187308 loss)
I0403 02:53:28.359182 19293 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 02:53:31.832764 19293 solver.cpp:228] Iteration 740, loss = 0.106309
I0403 02:53:31.838692 19293 solver.cpp:244]     Train net output #0: loss = 0.106309 (* 1 = 0.106309 loss)
I0403 02:53:32.011008 19293 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 02:53:35.530974 19293 solver.cpp:228] Iteration 745, loss = 0.128397
I0403 02:53:35.537485 19293 solver.cpp:244]     Train net output #0: loss = 0.128397 (* 1 = 0.128397 loss)
I0403 02:53:35.724905 19293 sgd_solver.cpp:106] Iteration 745, lr = 0.005
I0403 02:53:39.202055 19293 solver.cpp:228] Iteration 750, loss = 0.124502
I0403 02:53:39.208259 19293 solver.cpp:244]     Train net output #0: loss = 0.124502 (* 1 = 0.124502 loss)
I0403 02:53:39.402060 19293 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 02:53:42.823328 19293 solver.cpp:228] Iteration 755, loss = 0.0676491
I0403 02:53:42.829653 19293 solver.cpp:244]     Train net output #0: loss = 0.0676491 (* 1 = 0.0676491 loss)
I0403 02:53:43.009975 19293 sgd_solver.cpp:106] Iteration 755, lr = 0.005
I0403 02:53:46.434093 19293 solver.cpp:228] Iteration 760, loss = 0.165101
I0403 02:53:46.440546 19293 solver.cpp:244]     Train net output #0: loss = 0.165101 (* 1 = 0.165101 loss)
I0403 02:53:46.620087 19293 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 02:53:50.047216 19293 solver.cpp:228] Iteration 765, loss = 0.0491636
I0403 02:53:50.053534 19293 solver.cpp:244]     Train net output #0: loss = 0.0491636 (* 1 = 0.0491636 loss)
I0403 02:53:50.282865 19293 sgd_solver.cpp:106] Iteration 765, lr = 0.005
I0403 02:53:53.820617 19293 solver.cpp:228] Iteration 770, loss = 0.0608039
I0403 02:53:53.826113 19293 solver.cpp:244]     Train net output #0: loss = 0.0608039 (* 1 = 0.0608039 loss)
I0403 02:53:54.007403 19293 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 02:53:57.441648 19293 solver.cpp:228] Iteration 775, loss = 0.0820169
I0403 02:53:57.446387 19293 solver.cpp:244]     Train net output #0: loss = 0.0820169 (* 1 = 0.0820169 loss)
I0403 02:53:57.658187 19293 sgd_solver.cpp:106] Iteration 775, lr = 0.005
I0403 02:54:01.127117 19293 solver.cpp:228] Iteration 780, loss = 0.0669261
I0403 02:54:01.133343 19293 solver.cpp:244]     Train net output #0: loss = 0.0669261 (* 1 = 0.0669261 loss)
I0403 02:54:01.314503 19293 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:54:04.837764 19293 solver.cpp:228] Iteration 785, loss = 0.0413848
I0403 02:54:04.844233 19293 solver.cpp:244]     Train net output #0: loss = 0.0413848 (* 1 = 0.0413848 loss)
I0403 02:54:05.071877 19293 sgd_solver.cpp:106] Iteration 785, lr = 0.005
I0403 02:54:08.607499 19293 solver.cpp:228] Iteration 790, loss = 0.0344157
I0403 02:54:08.612668 19293 solver.cpp:244]     Train net output #0: loss = 0.0344157 (* 1 = 0.0344157 loss)
I0403 02:54:08.807394 19293 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 02:54:12.310205 19293 solver.cpp:228] Iteration 795, loss = 0.0333642
I0403 02:54:12.316480 19293 solver.cpp:244]     Train net output #0: loss = 0.0333642 (* 1 = 0.0333642 loss)
I0403 02:54:12.499975 19293 sgd_solver.cpp:106] Iteration 795, lr = 0.005
I0403 02:54:15.940136 19293 solver.cpp:228] Iteration 800, loss = 0.026319
I0403 02:54:15.945947 19293 solver.cpp:244]     Train net output #0: loss = 0.026319 (* 1 = 0.026319 loss)
I0403 02:54:16.127296 19293 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:54:19.568091 19293 solver.cpp:228] Iteration 805, loss = 0.188364
I0403 02:54:19.574066 19293 solver.cpp:244]     Train net output #0: loss = 0.188364 (* 1 = 0.188364 loss)
I0403 02:54:19.763176 19293 sgd_solver.cpp:106] Iteration 805, lr = 0.005
I0403 02:54:23.222592 19293 solver.cpp:228] Iteration 810, loss = 0.0954952
I0403 02:54:23.228462 19293 solver.cpp:244]     Train net output #0: loss = 0.0954952 (* 1 = 0.0954952 loss)
I0403 02:54:23.415645 19293 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 02:54:26.970916 19293 solver.cpp:228] Iteration 815, loss = 0.0237297
I0403 02:54:26.976804 19293 solver.cpp:244]     Train net output #0: loss = 0.0237297 (* 1 = 0.0237297 loss)
I0403 02:54:27.148140 19293 sgd_solver.cpp:106] Iteration 815, lr = 0.005
I0403 02:54:30.601032 19293 solver.cpp:228] Iteration 820, loss = 0.0883363
I0403 02:54:30.609750 19293 solver.cpp:244]     Train net output #0: loss = 0.0883363 (* 1 = 0.0883363 loss)
I0403 02:54:30.861224 19293 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 02:54:34.354928 19293 solver.cpp:228] Iteration 825, loss = 0.0775111
I0403 02:54:34.361263 19293 solver.cpp:244]     Train net output #0: loss = 0.0775111 (* 1 = 0.0775111 loss)
I0403 02:54:34.534103 19293 sgd_solver.cpp:106] Iteration 825, lr = 0.005
I0403 02:54:38.002231 19293 solver.cpp:228] Iteration 830, loss = 0.0517045
I0403 02:54:38.008733 19293 solver.cpp:244]     Train net output #0: loss = 0.0517045 (* 1 = 0.0517045 loss)
I0403 02:54:38.190281 19293 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 02:54:41.591203 19293 solver.cpp:228] Iteration 835, loss = 0.0870197
I0403 02:54:41.598150 19293 solver.cpp:244]     Train net output #0: loss = 0.0870196 (* 1 = 0.0870196 loss)
I0403 02:54:41.808329 19293 sgd_solver.cpp:106] Iteration 835, lr = 0.005
I0403 02:54:44.715699 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_840.caffemodel
I0403 02:54:47.468214 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_840.solverstate
I0403 02:54:49.383528 19293 solver.cpp:337] Iteration 840, Testing net (#0)
I0403 02:56:27.887771 19293 solver.cpp:404]     Test net output #0: accuracy = 0.917071
I0403 02:56:27.895051 19293 solver.cpp:404]     Test net output #1: loss = 0.307833 (* 1 = 0.307833 loss)
I0403 02:56:28.400041 19293 solver.cpp:228] Iteration 840, loss = 0.0419516
I0403 02:56:28.405235 19293 solver.cpp:244]     Train net output #0: loss = 0.0419516 (* 1 = 0.0419516 loss)
I0403 02:56:28.596814 19293 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:56:32.119436 19293 solver.cpp:228] Iteration 845, loss = 0.0632232
I0403 02:56:32.125615 19293 solver.cpp:244]     Train net output #0: loss = 0.0632232 (* 1 = 0.0632232 loss)
I0403 02:56:32.314215 19293 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 02:56:35.828074 19293 solver.cpp:228] Iteration 850, loss = 0.0390645
I0403 02:56:35.834132 19293 solver.cpp:244]     Train net output #0: loss = 0.0390645 (* 1 = 0.0390645 loss)
I0403 02:56:36.024188 19293 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 02:56:39.479585 19293 solver.cpp:228] Iteration 855, loss = 0.0759495
I0403 02:56:39.486305 19293 solver.cpp:244]     Train net output #0: loss = 0.0759495 (* 1 = 0.0759495 loss)
I0403 02:56:39.666193 19293 sgd_solver.cpp:106] Iteration 855, lr = 0.005
I0403 02:56:43.122633 19293 solver.cpp:228] Iteration 860, loss = 0.0536133
I0403 02:56:43.129144 19293 solver.cpp:244]     Train net output #0: loss = 0.0536132 (* 1 = 0.0536132 loss)
I0403 02:56:43.313017 19293 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 02:56:46.784690 19293 solver.cpp:228] Iteration 865, loss = 0.0404248
I0403 02:56:46.791247 19293 solver.cpp:244]     Train net output #0: loss = 0.0404248 (* 1 = 0.0404248 loss)
I0403 02:56:46.975301 19293 sgd_solver.cpp:106] Iteration 865, lr = 0.005
I0403 02:56:50.460326 19293 solver.cpp:228] Iteration 870, loss = 0.078027
I0403 02:56:50.466680 19293 solver.cpp:244]     Train net output #0: loss = 0.078027 (* 1 = 0.078027 loss)
I0403 02:56:50.639891 19293 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 02:56:54.088558 19293 solver.cpp:228] Iteration 875, loss = 0.0479869
I0403 02:56:54.094394 19293 solver.cpp:244]     Train net output #0: loss = 0.0479869 (* 1 = 0.0479869 loss)
I0403 02:56:54.275696 19293 sgd_solver.cpp:106] Iteration 875, lr = 0.005
I0403 02:56:57.819702 19293 solver.cpp:228] Iteration 880, loss = 0.0707874
I0403 02:56:57.823644 19293 solver.cpp:244]     Train net output #0: loss = 0.0707874 (* 1 = 0.0707874 loss)
I0403 02:56:57.990123 19293 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:57:01.523303 19293 solver.cpp:228] Iteration 885, loss = 0.07677
I0403 02:57:01.528684 19293 solver.cpp:244]     Train net output #0: loss = 0.07677 (* 1 = 0.07677 loss)
I0403 02:57:01.688922 19293 sgd_solver.cpp:106] Iteration 885, lr = 0.005
I0403 02:57:05.180429 19293 solver.cpp:228] Iteration 890, loss = 0.0807685
I0403 02:57:05.186573 19293 solver.cpp:244]     Train net output #0: loss = 0.0807685 (* 1 = 0.0807685 loss)
I0403 02:57:05.384496 19293 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 02:57:08.864075 19293 solver.cpp:228] Iteration 895, loss = 0.0699561
I0403 02:57:08.869936 19293 solver.cpp:244]     Train net output #0: loss = 0.0699561 (* 1 = 0.0699561 loss)
I0403 02:57:09.056854 19293 sgd_solver.cpp:106] Iteration 895, lr = 0.005
I0403 02:57:12.515962 19293 solver.cpp:228] Iteration 900, loss = 0.0274558
I0403 02:57:12.521612 19293 solver.cpp:244]     Train net output #0: loss = 0.0274558 (* 1 = 0.0274558 loss)
I0403 02:57:12.721499 19293 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 02:57:16.400290 19293 solver.cpp:228] Iteration 905, loss = 0.0153452
I0403 02:57:16.406291 19293 solver.cpp:244]     Train net output #0: loss = 0.0153452 (* 1 = 0.0153452 loss)
I0403 02:57:16.595453 19293 sgd_solver.cpp:106] Iteration 905, lr = 0.005
I0403 02:57:20.049860 19293 solver.cpp:228] Iteration 910, loss = 0.0594519
I0403 02:57:20.056880 19293 solver.cpp:244]     Train net output #0: loss = 0.0594519 (* 1 = 0.0594519 loss)
I0403 02:57:20.258564 19293 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:57:23.697587 19293 solver.cpp:228] Iteration 915, loss = 0.0898416
I0403 02:57:23.703199 19293 solver.cpp:244]     Train net output #0: loss = 0.0898416 (* 1 = 0.0898416 loss)
I0403 02:57:23.917037 19293 sgd_solver.cpp:106] Iteration 915, lr = 0.005
I0403 02:57:27.352311 19293 solver.cpp:228] Iteration 920, loss = 0.0612012
I0403 02:57:27.358852 19293 solver.cpp:244]     Train net output #0: loss = 0.0612012 (* 1 = 0.0612012 loss)
I0403 02:57:27.546066 19293 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 02:57:31.128623 19293 solver.cpp:228] Iteration 925, loss = 0.0399517
I0403 02:57:31.136090 19293 solver.cpp:244]     Train net output #0: loss = 0.0399517 (* 1 = 0.0399517 loss)
I0403 02:57:31.311558 19293 sgd_solver.cpp:106] Iteration 925, lr = 0.005
I0403 02:57:34.802711 19293 solver.cpp:228] Iteration 930, loss = 0.0743534
I0403 02:57:34.809618 19293 solver.cpp:244]     Train net output #0: loss = 0.0743534 (* 1 = 0.0743534 loss)
I0403 02:57:34.997498 19293 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 02:57:38.433068 19293 solver.cpp:228] Iteration 935, loss = 0.0365697
I0403 02:57:38.439323 19293 solver.cpp:244]     Train net output #0: loss = 0.0365696 (* 1 = 0.0365696 loss)
I0403 02:57:38.627365 19293 sgd_solver.cpp:106] Iteration 935, lr = 0.005
I0403 02:57:42.168095 19293 solver.cpp:228] Iteration 940, loss = 0.066902
I0403 02:57:42.174396 19293 solver.cpp:244]     Train net output #0: loss = 0.066902 (* 1 = 0.066902 loss)
I0403 02:57:42.375587 19293 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 02:57:45.298611 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_945.caffemodel
I0403 02:57:48.068606 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_945.solverstate
I0403 02:57:49.969862 19293 solver.cpp:337] Iteration 945, Testing net (#0)
I0403 02:59:28.468813 19293 solver.cpp:404]     Test net output #0: accuracy = 0.906957
I0403 02:59:28.475400 19293 solver.cpp:404]     Test net output #1: loss = 0.340903 (* 1 = 0.340903 loss)
I0403 02:59:28.998733 19293 solver.cpp:228] Iteration 945, loss = 0.0696584
I0403 02:59:29.004611 19293 solver.cpp:244]     Train net output #0: loss = 0.0696584 (* 1 = 0.0696584 loss)
I0403 02:59:29.179986 19293 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 02:59:32.625182 19293 solver.cpp:228] Iteration 950, loss = 0.0981461
I0403 02:59:32.632213 19293 solver.cpp:244]     Train net output #0: loss = 0.0981461 (* 1 = 0.0981461 loss)
I0403 02:59:32.810513 19293 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 02:59:36.234210 19293 solver.cpp:228] Iteration 955, loss = 0.0982112
I0403 02:59:36.240339 19293 solver.cpp:244]     Train net output #0: loss = 0.0982111 (* 1 = 0.0982111 loss)
I0403 02:59:36.438341 19293 sgd_solver.cpp:106] Iteration 955, lr = 0.005
I0403 02:59:39.937944 19293 solver.cpp:228] Iteration 960, loss = 0.0383729
I0403 02:59:39.944005 19293 solver.cpp:244]     Train net output #0: loss = 0.0383729 (* 1 = 0.0383729 loss)
I0403 02:59:40.120100 19293 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:59:43.576921 19293 solver.cpp:228] Iteration 965, loss = 0.0345729
I0403 02:59:43.584537 19293 solver.cpp:244]     Train net output #0: loss = 0.0345729 (* 1 = 0.0345729 loss)
I0403 02:59:43.777192 19293 sgd_solver.cpp:106] Iteration 965, lr = 0.005
I0403 02:59:47.180819 19293 solver.cpp:228] Iteration 970, loss = 0.0624829
I0403 02:59:47.187213 19293 solver.cpp:244]     Train net output #0: loss = 0.0624829 (* 1 = 0.0624829 loss)
I0403 02:59:47.380501 19293 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 02:59:50.793198 19293 solver.cpp:228] Iteration 975, loss = 0.0476314
I0403 02:59:50.799706 19293 solver.cpp:244]     Train net output #0: loss = 0.0476314 (* 1 = 0.0476314 loss)
I0403 02:59:51.000805 19293 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 02:59:54.451799 19293 solver.cpp:228] Iteration 980, loss = 0.0808974
I0403 02:59:54.457615 19293 solver.cpp:244]     Train net output #0: loss = 0.0808974 (* 1 = 0.0808974 loss)
I0403 02:59:54.650821 19293 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 02:59:58.057708 19293 solver.cpp:228] Iteration 985, loss = 0.0482491
I0403 02:59:58.064105 19293 solver.cpp:244]     Train net output #0: loss = 0.0482491 (* 1 = 0.0482491 loss)
I0403 02:59:58.260404 19293 sgd_solver.cpp:106] Iteration 985, lr = 0.005
I0403 03:00:01.743742 19293 solver.cpp:228] Iteration 990, loss = 0.0353751
I0403 03:00:01.749179 19293 solver.cpp:244]     Train net output #0: loss = 0.0353751 (* 1 = 0.0353751 loss)
I0403 03:00:01.935267 19293 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 03:00:05.398016 19293 solver.cpp:228] Iteration 995, loss = 0.0542654
I0403 03:00:05.403683 19293 solver.cpp:244]     Train net output #0: loss = 0.0542654 (* 1 = 0.0542654 loss)
I0403 03:00:05.587272 19293 sgd_solver.cpp:106] Iteration 995, lr = 0.005
I0403 03:00:09.049666 19293 solver.cpp:228] Iteration 1000, loss = 0.021927
I0403 03:00:09.056715 19293 solver.cpp:244]     Train net output #0: loss = 0.021927 (* 1 = 0.021927 loss)
I0403 03:00:09.274992 19293 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 03:00:12.835006 19293 solver.cpp:228] Iteration 1005, loss = 0.0209472
I0403 03:00:12.841024 19293 solver.cpp:244]     Train net output #0: loss = 0.0209472 (* 1 = 0.0209472 loss)
I0403 03:00:12.990078 19293 sgd_solver.cpp:106] Iteration 1005, lr = 0.005
I0403 03:00:16.523056 19293 solver.cpp:228] Iteration 1010, loss = 0.083984
I0403 03:00:16.529500 19293 solver.cpp:244]     Train net output #0: loss = 0.083984 (* 1 = 0.083984 loss)
I0403 03:00:16.736740 19293 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 03:00:20.151558 19293 solver.cpp:228] Iteration 1015, loss = 0.0679504
I0403 03:00:20.157847 19293 solver.cpp:244]     Train net output #0: loss = 0.0679504 (* 1 = 0.0679504 loss)
I0403 03:00:20.364882 19293 sgd_solver.cpp:106] Iteration 1015, lr = 0.005
I0403 03:00:23.788688 19293 solver.cpp:228] Iteration 1020, loss = 0.0147165
I0403 03:00:23.794806 19293 solver.cpp:244]     Train net output #0: loss = 0.0147165 (* 1 = 0.0147165 loss)
I0403 03:00:23.979960 19293 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 03:00:27.431905 19293 solver.cpp:228] Iteration 1025, loss = 0.0317467
I0403 03:00:27.438308 19293 solver.cpp:244]     Train net output #0: loss = 0.0317467 (* 1 = 0.0317467 loss)
I0403 03:00:27.625355 19293 sgd_solver.cpp:106] Iteration 1025, lr = 0.005
I0403 03:00:31.063055 19293 solver.cpp:228] Iteration 1030, loss = 0.0710932
I0403 03:00:31.069196 19293 solver.cpp:244]     Train net output #0: loss = 0.0710932 (* 1 = 0.0710932 loss)
I0403 03:00:31.290328 19293 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 03:00:34.762639 19293 solver.cpp:228] Iteration 1035, loss = 0.0279168
I0403 03:00:34.768748 19293 solver.cpp:244]     Train net output #0: loss = 0.0279168 (* 1 = 0.0279168 loss)
I0403 03:00:34.951468 19293 sgd_solver.cpp:106] Iteration 1035, lr = 0.005
I0403 03:00:38.352032 19293 solver.cpp:228] Iteration 1040, loss = 0.0785687
I0403 03:00:38.358340 19293 solver.cpp:244]     Train net output #0: loss = 0.0785687 (* 1 = 0.0785687 loss)
I0403 03:00:38.622908 19293 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 03:00:42.076699 19293 solver.cpp:228] Iteration 1045, loss = 0.0250343
I0403 03:00:42.082886 19293 solver.cpp:244]     Train net output #0: loss = 0.0250343 (* 1 = 0.0250343 loss)
I0403 03:00:42.266402 19293 sgd_solver.cpp:106] Iteration 1045, lr = 0.005
I0403 03:00:45.171387 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1050.caffemodel
I0403 03:00:47.797938 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1050.solverstate
I0403 03:00:49.625902 19293 solver.cpp:337] Iteration 1050, Testing net (#0)
I0403 03:02:28.129354 19293 solver.cpp:404]     Test net output #0: accuracy = 0.915447
I0403 03:02:28.137424 19293 solver.cpp:404]     Test net output #1: loss = 0.303829 (* 1 = 0.303829 loss)
I0403 03:02:28.642493 19293 solver.cpp:228] Iteration 1050, loss = 0.0475291
I0403 03:02:28.649174 19293 solver.cpp:244]     Train net output #0: loss = 0.0475291 (* 1 = 0.0475291 loss)
I0403 03:02:28.831102 19293 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 03:02:32.246870 19293 solver.cpp:228] Iteration 1055, loss = 0.0654823
I0403 03:02:32.253185 19293 solver.cpp:244]     Train net output #0: loss = 0.0654823 (* 1 = 0.0654823 loss)
I0403 03:02:32.479037 19293 sgd_solver.cpp:106] Iteration 1055, lr = 0.005
I0403 03:02:35.949465 19293 solver.cpp:228] Iteration 1060, loss = 0.0621932
I0403 03:02:35.954572 19293 solver.cpp:244]     Train net output #0: loss = 0.0621932 (* 1 = 0.0621932 loss)
I0403 03:02:36.154729 19293 sgd_solver.cpp:106] Iteration 1060, lr = 0.0005
I0403 03:02:39.624708 19293 solver.cpp:228] Iteration 1065, loss = 0.0805064
I0403 03:02:39.630532 19293 solver.cpp:244]     Train net output #0: loss = 0.0805064 (* 1 = 0.0805064 loss)
I0403 03:02:39.815515 19293 sgd_solver.cpp:106] Iteration 1065, lr = 0.0005
I0403 03:02:43.280685 19293 solver.cpp:228] Iteration 1070, loss = 0.0925848
I0403 03:02:43.287230 19293 solver.cpp:244]     Train net output #0: loss = 0.0925848 (* 1 = 0.0925848 loss)
I0403 03:02:43.466244 19293 sgd_solver.cpp:106] Iteration 1070, lr = 0.0005
I0403 03:02:46.919767 19293 solver.cpp:228] Iteration 1075, loss = 0.0379582
I0403 03:02:46.925492 19293 solver.cpp:244]     Train net output #0: loss = 0.0379581 (* 1 = 0.0379581 loss)
I0403 03:02:47.126616 19293 sgd_solver.cpp:106] Iteration 1075, lr = 0.0005
I0403 03:02:50.617607 19293 solver.cpp:228] Iteration 1080, loss = 0.00280943
I0403 03:02:50.623350 19293 solver.cpp:244]     Train net output #0: loss = 0.00280942 (* 1 = 0.00280942 loss)
I0403 03:02:50.772472 19293 sgd_solver.cpp:106] Iteration 1080, lr = 0.0005
I0403 03:02:54.302584 19293 solver.cpp:228] Iteration 1085, loss = 0.0547123
I0403 03:02:54.309373 19293 solver.cpp:244]     Train net output #0: loss = 0.0547123 (* 1 = 0.0547123 loss)
I0403 03:02:54.496976 19293 sgd_solver.cpp:106] Iteration 1085, lr = 0.0005
I0403 03:02:57.940485 19293 solver.cpp:228] Iteration 1090, loss = 0.05608
I0403 03:02:57.947005 19293 solver.cpp:244]     Train net output #0: loss = 0.05608 (* 1 = 0.05608 loss)
I0403 03:02:58.139154 19293 sgd_solver.cpp:106] Iteration 1090, lr = 0.0005
I0403 03:03:01.571739 19293 solver.cpp:228] Iteration 1095, loss = 0.0112108
I0403 03:03:01.578385 19293 solver.cpp:244]     Train net output #0: loss = 0.0112108 (* 1 = 0.0112108 loss)
I0403 03:03:01.775466 19293 sgd_solver.cpp:106] Iteration 1095, lr = 0.0005
I0403 03:03:05.229645 19293 solver.cpp:228] Iteration 1100, loss = 0.021162
I0403 03:03:05.235584 19293 solver.cpp:244]     Train net output #0: loss = 0.021162 (* 1 = 0.021162 loss)
I0403 03:03:05.429013 19293 sgd_solver.cpp:106] Iteration 1100, lr = 0.0005
I0403 03:03:08.856834 19293 solver.cpp:228] Iteration 1105, loss = 0.00400041
I0403 03:03:08.862833 19293 solver.cpp:244]     Train net output #0: loss = 0.00400039 (* 1 = 0.00400039 loss)
I0403 03:03:09.029075 19293 sgd_solver.cpp:106] Iteration 1105, lr = 0.0005
I0403 03:03:12.633618 19293 solver.cpp:228] Iteration 1110, loss = 0.0328616
I0403 03:03:12.640238 19293 solver.cpp:244]     Train net output #0: loss = 0.0328616 (* 1 = 0.0328616 loss)
I0403 03:03:12.820632 19293 sgd_solver.cpp:106] Iteration 1110, lr = 0.0005
I0403 03:03:16.286806 19293 solver.cpp:228] Iteration 1115, loss = 0.0336792
I0403 03:03:16.292537 19293 solver.cpp:244]     Train net output #0: loss = 0.0336792 (* 1 = 0.0336792 loss)
I0403 03:03:16.488054 19293 sgd_solver.cpp:106] Iteration 1115, lr = 0.0005
I0403 03:03:19.918771 19293 solver.cpp:228] Iteration 1120, loss = 0.0300464
I0403 03:03:19.924557 19293 solver.cpp:244]     Train net output #0: loss = 0.0300464 (* 1 = 0.0300464 loss)
I0403 03:03:20.120975 19293 sgd_solver.cpp:106] Iteration 1120, lr = 0.0005
I0403 03:03:23.586513 19293 solver.cpp:228] Iteration 1125, loss = 0.00395014
I0403 03:03:23.593104 19293 solver.cpp:244]     Train net output #0: loss = 0.00395012 (* 1 = 0.00395012 loss)
I0403 03:03:23.772429 19293 sgd_solver.cpp:106] Iteration 1125, lr = 0.0005
I0403 03:03:27.361284 19293 solver.cpp:228] Iteration 1130, loss = 0.0245983
I0403 03:03:27.366933 19293 solver.cpp:244]     Train net output #0: loss = 0.0245983 (* 1 = 0.0245983 loss)
I0403 03:03:27.542973 19293 sgd_solver.cpp:106] Iteration 1130, lr = 0.0005
I0403 03:03:31.082736 19293 solver.cpp:228] Iteration 1135, loss = 0.0173304
I0403 03:03:31.089545 19293 solver.cpp:244]     Train net output #0: loss = 0.0173303 (* 1 = 0.0173303 loss)
I0403 03:03:31.263494 19293 sgd_solver.cpp:106] Iteration 1135, lr = 0.0005
I0403 03:03:34.836607 19293 solver.cpp:228] Iteration 1140, loss = 0.00637925
I0403 03:03:34.845751 19293 solver.cpp:244]     Train net output #0: loss = 0.00637922 (* 1 = 0.00637922 loss)
I0403 03:03:35.038528 19293 sgd_solver.cpp:106] Iteration 1140, lr = 0.0005
I0403 03:03:38.620463 19293 solver.cpp:228] Iteration 1145, loss = 0.00701222
I0403 03:03:38.626947 19293 solver.cpp:244]     Train net output #0: loss = 0.00701219 (* 1 = 0.00701219 loss)
I0403 03:03:38.816301 19293 sgd_solver.cpp:106] Iteration 1145, lr = 0.0005
I0403 03:03:42.261379 19293 solver.cpp:228] Iteration 1150, loss = 0.0208805
I0403 03:03:42.267228 19293 solver.cpp:244]     Train net output #0: loss = 0.0208805 (* 1 = 0.0208805 loss)
I0403 03:03:42.464918 19293 sgd_solver.cpp:106] Iteration 1150, lr = 0.0005
I0403 03:03:45.374701 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1155.caffemodel
I0403 03:03:48.137498 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1155.solverstate
I0403 03:03:50.045670 19293 solver.cpp:337] Iteration 1155, Testing net (#0)
I0403 03:05:28.539178 19293 solver.cpp:404]     Test net output #0: accuracy = 0.931945
I0403 03:05:28.545250 19293 solver.cpp:404]     Test net output #1: loss = 0.247029 (* 1 = 0.247029 loss)
I0403 03:05:29.070315 19293 solver.cpp:228] Iteration 1155, loss = 0.0375544
I0403 03:05:29.075266 19293 solver.cpp:244]     Train net output #0: loss = 0.0375544 (* 1 = 0.0375544 loss)
I0403 03:05:29.239776 19293 sgd_solver.cpp:106] Iteration 1155, lr = 0.0005
I0403 03:05:32.716210 19293 solver.cpp:228] Iteration 1160, loss = 0.017098
I0403 03:05:32.722113 19293 solver.cpp:244]     Train net output #0: loss = 0.017098 (* 1 = 0.017098 loss)
I0403 03:05:32.916079 19293 sgd_solver.cpp:106] Iteration 1160, lr = 0.0005
I0403 03:05:36.372644 19293 solver.cpp:228] Iteration 1165, loss = 0.0204951
I0403 03:05:36.378926 19293 solver.cpp:244]     Train net output #0: loss = 0.020495 (* 1 = 0.020495 loss)
I0403 03:05:36.621305 19293 sgd_solver.cpp:106] Iteration 1165, lr = 0.0005
I0403 03:05:40.066589 19293 solver.cpp:228] Iteration 1170, loss = 0.00961167
I0403 03:05:40.073202 19293 solver.cpp:244]     Train net output #0: loss = 0.00961164 (* 1 = 0.00961164 loss)
I0403 03:05:40.286942 19293 sgd_solver.cpp:106] Iteration 1170, lr = 0.0005
I0403 03:05:43.821370 19293 solver.cpp:228] Iteration 1175, loss = 0.0200093
I0403 03:05:43.827723 19293 solver.cpp:244]     Train net output #0: loss = 0.0200093 (* 1 = 0.0200093 loss)
I0403 03:05:43.952723 19293 sgd_solver.cpp:106] Iteration 1175, lr = 0.0005
I0403 03:05:47.553601 19293 solver.cpp:228] Iteration 1180, loss = 0.0410191
I0403 03:05:47.558569 19293 solver.cpp:244]     Train net output #0: loss = 0.0410191 (* 1 = 0.0410191 loss)
I0403 03:05:47.727377 19293 sgd_solver.cpp:106] Iteration 1180, lr = 0.0005
I0403 03:05:51.214368 19293 solver.cpp:228] Iteration 1185, loss = 0.00418184
I0403 03:05:51.220808 19293 solver.cpp:244]     Train net output #0: loss = 0.0041818 (* 1 = 0.0041818 loss)
I0403 03:05:51.434643 19293 sgd_solver.cpp:106] Iteration 1185, lr = 0.0005
I0403 03:05:54.885354 19293 solver.cpp:228] Iteration 1190, loss = 0.00485813
I0403 03:05:54.890604 19293 solver.cpp:244]     Train net output #0: loss = 0.0048581 (* 1 = 0.0048581 loss)
I0403 03:05:55.101501 19293 sgd_solver.cpp:106] Iteration 1190, lr = 0.0005
I0403 03:05:58.521142 19293 solver.cpp:228] Iteration 1195, loss = 0.00201766
I0403 03:05:58.527174 19293 solver.cpp:244]     Train net output #0: loss = 0.00201763 (* 1 = 0.00201763 loss)
I0403 03:05:58.734210 19293 sgd_solver.cpp:106] Iteration 1195, lr = 0.0005
I0403 03:06:02.220371 19293 solver.cpp:228] Iteration 1200, loss = 0.0468294
I0403 03:06:02.225890 19293 solver.cpp:244]     Train net output #0: loss = 0.0468294 (* 1 = 0.0468294 loss)
I0403 03:06:02.407902 19293 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0403 03:06:05.935925 19293 solver.cpp:228] Iteration 1205, loss = 0.02445
I0403 03:06:05.942852 19293 solver.cpp:244]     Train net output #0: loss = 0.02445 (* 1 = 0.02445 loss)
I0403 03:06:06.044507 19293 sgd_solver.cpp:106] Iteration 1205, lr = 0.0005
I0403 03:06:09.621239 19293 solver.cpp:228] Iteration 1210, loss = 0.0500825
I0403 03:06:09.627352 19293 solver.cpp:244]     Train net output #0: loss = 0.0500825 (* 1 = 0.0500825 loss)
I0403 03:06:09.820818 19293 sgd_solver.cpp:106] Iteration 1210, lr = 0.0005
I0403 03:06:13.317294 19293 solver.cpp:228] Iteration 1215, loss = 0.0922916
I0403 03:06:13.322902 19293 solver.cpp:244]     Train net output #0: loss = 0.0922915 (* 1 = 0.0922915 loss)
I0403 03:06:13.503857 19293 sgd_solver.cpp:106] Iteration 1215, lr = 0.0005
I0403 03:06:16.968760 19293 solver.cpp:228] Iteration 1220, loss = 0.0115951
I0403 03:06:16.974290 19293 solver.cpp:244]     Train net output #0: loss = 0.0115951 (* 1 = 0.0115951 loss)
I0403 03:06:17.211731 19293 sgd_solver.cpp:106] Iteration 1220, lr = 0.0005
I0403 03:06:20.779011 19293 solver.cpp:228] Iteration 1225, loss = 0.0387033
I0403 03:06:20.795819 19293 solver.cpp:244]     Train net output #0: loss = 0.0387033 (* 1 = 0.0387033 loss)
I0403 03:06:20.949667 19293 sgd_solver.cpp:106] Iteration 1225, lr = 0.0005
I0403 03:06:24.502390 19293 solver.cpp:228] Iteration 1230, loss = 0.0192316
I0403 03:06:24.508287 19293 solver.cpp:244]     Train net output #0: loss = 0.0192315 (* 1 = 0.0192315 loss)
I0403 03:06:24.695127 19293 sgd_solver.cpp:106] Iteration 1230, lr = 0.0005
I0403 03:06:28.146183 19293 solver.cpp:228] Iteration 1235, loss = 0.0564828
I0403 03:06:28.151687 19293 solver.cpp:244]     Train net output #0: loss = 0.0564828 (* 1 = 0.0564828 loss)
I0403 03:06:28.334599 19293 sgd_solver.cpp:106] Iteration 1235, lr = 0.0005
I0403 03:06:32.000269 19293 solver.cpp:228] Iteration 1240, loss = 0.00767476
I0403 03:06:32.006546 19293 solver.cpp:244]     Train net output #0: loss = 0.00767473 (* 1 = 0.00767473 loss)
I0403 03:06:32.185972 19293 sgd_solver.cpp:106] Iteration 1240, lr = 0.0005
I0403 03:06:35.630632 19293 solver.cpp:228] Iteration 1245, loss = 0.0269366
I0403 03:06:35.636723 19293 solver.cpp:244]     Train net output #0: loss = 0.0269365 (* 1 = 0.0269365 loss)
I0403 03:06:35.878618 19293 sgd_solver.cpp:106] Iteration 1245, lr = 0.0005
I0403 03:06:39.366942 19293 solver.cpp:228] Iteration 1250, loss = 0.0205571
I0403 03:06:39.372885 19293 solver.cpp:244]     Train net output #0: loss = 0.020557 (* 1 = 0.020557 loss)
I0403 03:06:39.632925 19293 sgd_solver.cpp:106] Iteration 1250, lr = 0.0005
I0403 03:06:43.080809 19293 solver.cpp:228] Iteration 1255, loss = 0.034528
I0403 03:06:43.086860 19293 solver.cpp:244]     Train net output #0: loss = 0.034528 (* 1 = 0.034528 loss)
I0403 03:06:43.281414 19293 sgd_solver.cpp:106] Iteration 1255, lr = 0.0005
I0403 03:06:46.188781 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1260.caffemodel
I0403 03:06:48.946730 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1260.solverstate
I0403 03:06:50.845746 19293 solver.cpp:337] Iteration 1260, Testing net (#0)
I0403 03:08:29.355329 19293 solver.cpp:404]     Test net output #0: accuracy = 0.933502
I0403 03:08:29.361204 19293 solver.cpp:404]     Test net output #1: loss = 0.250589 (* 1 = 0.250589 loss)
I0403 03:08:29.878037 19293 solver.cpp:228] Iteration 1260, loss = 0.0177529
I0403 03:08:29.881778 19293 solver.cpp:244]     Train net output #0: loss = 0.0177529 (* 1 = 0.0177529 loss)
I0403 03:08:30.066036 19293 sgd_solver.cpp:106] Iteration 1260, lr = 0.0005
I0403 03:08:33.602095 19293 solver.cpp:228] Iteration 1265, loss = 0.00229516
I0403 03:08:33.608536 19293 solver.cpp:244]     Train net output #0: loss = 0.00229513 (* 1 = 0.00229513 loss)
I0403 03:08:33.789526 19293 sgd_solver.cpp:106] Iteration 1265, lr = 0.0005
I0403 03:08:37.224437 19293 solver.cpp:228] Iteration 1270, loss = 0.00613421
I0403 03:08:37.230281 19293 solver.cpp:244]     Train net output #0: loss = 0.00613418 (* 1 = 0.00613418 loss)
I0403 03:08:37.421614 19293 sgd_solver.cpp:106] Iteration 1270, lr = 0.0005
I0403 03:08:40.911293 19293 solver.cpp:228] Iteration 1275, loss = 0.0106219
I0403 03:08:40.916393 19293 solver.cpp:244]     Train net output #0: loss = 0.0106219 (* 1 = 0.0106219 loss)
I0403 03:08:41.097507 19293 sgd_solver.cpp:106] Iteration 1275, lr = 0.0005
I0403 03:08:44.530524 19293 solver.cpp:228] Iteration 1280, loss = 0.042357
I0403 03:08:44.536422 19293 solver.cpp:244]     Train net output #0: loss = 0.042357 (* 1 = 0.042357 loss)
I0403 03:08:44.735054 19293 sgd_solver.cpp:106] Iteration 1280, lr = 0.0005
I0403 03:08:48.171371 19293 solver.cpp:228] Iteration 1285, loss = 0.0197375
I0403 03:08:48.177098 19293 solver.cpp:244]     Train net output #0: loss = 0.0197375 (* 1 = 0.0197375 loss)
I0403 03:08:48.360062 19293 sgd_solver.cpp:106] Iteration 1285, lr = 0.0005
I0403 03:08:51.849828 19293 solver.cpp:228] Iteration 1290, loss = 0.00514771
I0403 03:08:51.856165 19293 solver.cpp:244]     Train net output #0: loss = 0.00514768 (* 1 = 0.00514768 loss)
I0403 03:08:52.111704 19293 sgd_solver.cpp:106] Iteration 1290, lr = 0.0005
I0403 03:08:55.542809 19293 solver.cpp:228] Iteration 1295, loss = 0.00169128
I0403 03:08:55.548562 19293 solver.cpp:244]     Train net output #0: loss = 0.00169125 (* 1 = 0.00169125 loss)
I0403 03:08:55.764508 19293 sgd_solver.cpp:106] Iteration 1295, lr = 0.0005
I0403 03:08:59.259802 19293 solver.cpp:228] Iteration 1300, loss = 0.0302992
I0403 03:08:59.266335 19293 solver.cpp:244]     Train net output #0: loss = 0.0302992 (* 1 = 0.0302992 loss)
I0403 03:08:59.465201 19293 sgd_solver.cpp:106] Iteration 1300, lr = 0.0005
I0403 03:09:02.969723 19293 solver.cpp:228] Iteration 1305, loss = 0.00363594
I0403 03:09:02.975916 19293 solver.cpp:244]     Train net output #0: loss = 0.00363591 (* 1 = 0.00363591 loss)
I0403 03:09:03.167590 19293 sgd_solver.cpp:106] Iteration 1305, lr = 0.0005
I0403 03:09:06.572219 19293 solver.cpp:228] Iteration 1310, loss = 0.0172353
I0403 03:09:06.578842 19293 solver.cpp:244]     Train net output #0: loss = 0.0172352 (* 1 = 0.0172352 loss)
I0403 03:09:06.787488 19293 sgd_solver.cpp:106] Iteration 1310, lr = 0.0005
I0403 03:09:10.202536 19293 solver.cpp:228] Iteration 1315, loss = 0.0132654
I0403 03:09:10.208999 19293 solver.cpp:244]     Train net output #0: loss = 0.0132654 (* 1 = 0.0132654 loss)
I0403 03:09:10.426012 19293 sgd_solver.cpp:106] Iteration 1315, lr = 0.0005
I0403 03:09:13.889302 19293 solver.cpp:228] Iteration 1320, loss = 0.011646
I0403 03:09:13.895345 19293 solver.cpp:244]     Train net output #0: loss = 0.0116459 (* 1 = 0.0116459 loss)
I0403 03:09:14.107265 19293 sgd_solver.cpp:106] Iteration 1320, lr = 0.0005
I0403 03:09:17.586601 19293 solver.cpp:228] Iteration 1325, loss = 0.0368481
I0403 03:09:17.591477 19293 solver.cpp:244]     Train net output #0: loss = 0.0368481 (* 1 = 0.0368481 loss)
I0403 03:09:17.798713 19293 sgd_solver.cpp:106] Iteration 1325, lr = 0.0005
I0403 03:09:21.214376 19293 solver.cpp:228] Iteration 1330, loss = 0.0257015
I0403 03:09:21.219983 19293 solver.cpp:244]     Train net output #0: loss = 0.0257015 (* 1 = 0.0257015 loss)
I0403 03:09:21.422057 19293 sgd_solver.cpp:106] Iteration 1330, lr = 0.0005
I0403 03:09:24.892371 19293 solver.cpp:228] Iteration 1335, loss = 0.00364831
I0403 03:09:24.898046 19293 solver.cpp:244]     Train net output #0: loss = 0.00364828 (* 1 = 0.00364828 loss)
I0403 03:09:25.090615 19293 sgd_solver.cpp:106] Iteration 1335, lr = 0.0005
I0403 03:09:28.596434 19293 solver.cpp:228] Iteration 1340, loss = 0.0364922
I0403 03:09:28.602337 19293 solver.cpp:244]     Train net output #0: loss = 0.0364922 (* 1 = 0.0364922 loss)
I0403 03:09:28.823323 19293 sgd_solver.cpp:106] Iteration 1340, lr = 0.0005
I0403 03:09:32.309155 19293 solver.cpp:228] Iteration 1345, loss = 0.0259058
I0403 03:09:32.315101 19293 solver.cpp:244]     Train net output #0: loss = 0.0259058 (* 1 = 0.0259058 loss)
I0403 03:09:32.502012 19293 sgd_solver.cpp:106] Iteration 1345, lr = 0.0005
I0403 03:09:35.968770 19293 solver.cpp:228] Iteration 1350, loss = 0.00221662
I0403 03:09:35.974046 19293 solver.cpp:244]     Train net output #0: loss = 0.00221658 (* 1 = 0.00221658 loss)
I0403 03:09:36.165184 19293 sgd_solver.cpp:106] Iteration 1350, lr = 0.0005
I0403 03:09:39.603160 19293 solver.cpp:228] Iteration 1355, loss = 0.0231177
I0403 03:09:39.608696 19293 solver.cpp:244]     Train net output #0: loss = 0.0231177 (* 1 = 0.0231177 loss)
I0403 03:09:39.821264 19293 sgd_solver.cpp:106] Iteration 1355, lr = 0.0005
I0403 03:09:43.284384 19293 solver.cpp:228] Iteration 1360, loss = 0.00906685
I0403 03:09:43.290953 19293 solver.cpp:244]     Train net output #0: loss = 0.00906682 (* 1 = 0.00906682 loss)
I0403 03:09:43.533910 19293 sgd_solver.cpp:106] Iteration 1360, lr = 0.0005
I0403 03:09:46.454927 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1365.caffemodel
I0403 03:09:49.185191 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1365.solverstate
I0403 03:09:50.971302 19293 solver.cpp:337] Iteration 1365, Testing net (#0)
I0403 03:11:29.473134 19293 solver.cpp:404]     Test net output #0: accuracy = 0.934578
I0403 03:11:29.480924 19293 solver.cpp:404]     Test net output #1: loss = 0.24729 (* 1 = 0.24729 loss)
I0403 03:11:30.020328 19293 solver.cpp:228] Iteration 1365, loss = 0.000956289
I0403 03:11:30.026276 19293 solver.cpp:244]     Train net output #0: loss = 0.000956258 (* 1 = 0.000956258 loss)
I0403 03:11:30.173532 19293 sgd_solver.cpp:106] Iteration 1365, lr = 0.0005
I0403 03:11:33.871436 19293 solver.cpp:228] Iteration 1370, loss = 0.00621725
I0403 03:11:33.878268 19293 solver.cpp:244]     Train net output #0: loss = 0.00621722 (* 1 = 0.00621722 loss)
I0403 03:11:34.004329 19293 sgd_solver.cpp:106] Iteration 1370, lr = 0.0005
I0403 03:11:37.546703 19293 solver.cpp:228] Iteration 1375, loss = 0.0396107
I0403 03:11:37.552726 19293 solver.cpp:244]     Train net output #0: loss = 0.0396107 (* 1 = 0.0396107 loss)
I0403 03:11:37.701951 19293 sgd_solver.cpp:106] Iteration 1375, lr = 0.0005
I0403 03:11:41.308374 19293 solver.cpp:228] Iteration 1380, loss = 0.00710289
I0403 03:11:41.314924 19293 solver.cpp:244]     Train net output #0: loss = 0.00710286 (* 1 = 0.00710286 loss)
I0403 03:11:41.500787 19293 sgd_solver.cpp:106] Iteration 1380, lr = 0.0005
I0403 03:11:44.995008 19293 solver.cpp:228] Iteration 1385, loss = 0.0413297
I0403 03:11:45.001309 19293 solver.cpp:244]     Train net output #0: loss = 0.0413296 (* 1 = 0.0413296 loss)
I0403 03:11:45.181340 19293 sgd_solver.cpp:106] Iteration 1385, lr = 0.0005
I0403 03:11:48.667757 19293 solver.cpp:228] Iteration 1390, loss = 0.0118471
I0403 03:11:48.674016 19293 solver.cpp:244]     Train net output #0: loss = 0.0118471 (* 1 = 0.0118471 loss)
I0403 03:11:48.865000 19293 sgd_solver.cpp:106] Iteration 1390, lr = 0.0005
I0403 03:11:52.319118 19293 solver.cpp:228] Iteration 1395, loss = 0.023628
I0403 03:11:52.326138 19293 solver.cpp:244]     Train net output #0: loss = 0.023628 (* 1 = 0.023628 loss)
I0403 03:11:52.506075 19293 sgd_solver.cpp:106] Iteration 1395, lr = 0.0005
I0403 03:11:55.937304 19293 solver.cpp:228] Iteration 1400, loss = 0.00804733
I0403 03:11:55.942968 19293 solver.cpp:244]     Train net output #0: loss = 0.0080473 (* 1 = 0.0080473 loss)
I0403 03:11:56.140977 19293 sgd_solver.cpp:106] Iteration 1400, lr = 0.0005
I0403 03:11:59.636425 19293 solver.cpp:228] Iteration 1405, loss = 0.00565834
I0403 03:11:59.642948 19293 solver.cpp:244]     Train net output #0: loss = 0.0056583 (* 1 = 0.0056583 loss)
I0403 03:11:59.847724 19293 sgd_solver.cpp:106] Iteration 1405, lr = 0.0005
I0403 03:12:03.298954 19293 solver.cpp:228] Iteration 1410, loss = 0.00978061
I0403 03:12:03.304880 19293 solver.cpp:244]     Train net output #0: loss = 0.00978057 (* 1 = 0.00978057 loss)
I0403 03:12:03.506989 19293 sgd_solver.cpp:106] Iteration 1410, lr = 0.0005
I0403 03:12:06.977200 19293 solver.cpp:228] Iteration 1415, loss = 0.0156885
I0403 03:12:06.982462 19293 solver.cpp:244]     Train net output #0: loss = 0.0156884 (* 1 = 0.0156884 loss)
I0403 03:12:07.161078 19293 sgd_solver.cpp:106] Iteration 1415, lr = 0.0005
I0403 03:12:10.633265 19293 solver.cpp:228] Iteration 1420, loss = 0.0152638
I0403 03:12:10.640422 19293 solver.cpp:244]     Train net output #0: loss = 0.0152638 (* 1 = 0.0152638 loss)
I0403 03:12:10.826759 19293 sgd_solver.cpp:106] Iteration 1420, lr = 0.0005
I0403 03:12:14.256470 19293 solver.cpp:228] Iteration 1425, loss = 0.0120302
I0403 03:12:14.263478 19293 solver.cpp:244]     Train net output #0: loss = 0.0120302 (* 1 = 0.0120302 loss)
I0403 03:12:14.459414 19293 sgd_solver.cpp:106] Iteration 1425, lr = 0.0005
I0403 03:12:17.945737 19293 solver.cpp:228] Iteration 1430, loss = 0.0100653
I0403 03:12:17.952780 19293 solver.cpp:244]     Train net output #0: loss = 0.0100653 (* 1 = 0.0100653 loss)
I0403 03:12:18.126677 19293 sgd_solver.cpp:106] Iteration 1430, lr = 0.0005
I0403 03:12:21.695394 19293 solver.cpp:228] Iteration 1435, loss = 0.0101864
I0403 03:12:21.700297 19293 solver.cpp:244]     Train net output #0: loss = 0.0101864 (* 1 = 0.0101864 loss)
I0403 03:12:21.843824 19293 sgd_solver.cpp:106] Iteration 1435, lr = 0.0005
I0403 03:12:25.362917 19293 solver.cpp:228] Iteration 1440, loss = 0.0157945
I0403 03:12:25.369998 19293 solver.cpp:244]     Train net output #0: loss = 0.0157945 (* 1 = 0.0157945 loss)
I0403 03:12:25.570399 19293 sgd_solver.cpp:106] Iteration 1440, lr = 0.0005
I0403 03:12:29.061722 19293 solver.cpp:228] Iteration 1445, loss = 0.00717911
I0403 03:12:29.068513 19293 solver.cpp:244]     Train net output #0: loss = 0.00717908 (* 1 = 0.00717908 loss)
I0403 03:12:29.234722 19293 sgd_solver.cpp:106] Iteration 1445, lr = 0.0005
I0403 03:12:32.805605 19293 solver.cpp:228] Iteration 1450, loss = 0.00644074
I0403 03:12:32.812281 19293 solver.cpp:244]     Train net output #0: loss = 0.00644071 (* 1 = 0.00644071 loss)
I0403 03:12:32.960034 19293 sgd_solver.cpp:106] Iteration 1450, lr = 0.0005
I0403 03:12:36.502636 19293 solver.cpp:228] Iteration 1455, loss = 0.0263403
I0403 03:12:36.509013 19293 solver.cpp:244]     Train net output #0: loss = 0.0263403 (* 1 = 0.0263403 loss)
I0403 03:12:36.698815 19293 sgd_solver.cpp:106] Iteration 1455, lr = 0.0005
I0403 03:12:40.189820 19293 solver.cpp:228] Iteration 1460, loss = 0.00162414
I0403 03:12:40.196081 19293 solver.cpp:244]     Train net output #0: loss = 0.00162411 (* 1 = 0.00162411 loss)
I0403 03:12:40.387838 19293 sgd_solver.cpp:106] Iteration 1460, lr = 0.0005
I0403 03:12:43.846829 19293 solver.cpp:228] Iteration 1465, loss = 0.00799303
I0403 03:12:43.853997 19293 solver.cpp:244]     Train net output #0: loss = 0.007993 (* 1 = 0.007993 loss)
I0403 03:12:44.046120 19293 sgd_solver.cpp:106] Iteration 1465, lr = 0.0005
I0403 03:12:47.012617 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1470.caffemodel
I0403 03:12:49.769127 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1470.solverstate
I0403 03:12:51.681123 19293 solver.cpp:337] Iteration 1470, Testing net (#0)
I0403 03:14:30.177958 19293 solver.cpp:404]     Test net output #0: accuracy = 0.93444
I0403 03:14:30.184010 19293 solver.cpp:404]     Test net output #1: loss = 0.252021 (* 1 = 0.252021 loss)
I0403 03:14:30.697302 19293 solver.cpp:228] Iteration 1470, loss = 0.00707146
I0403 03:14:30.702642 19293 solver.cpp:244]     Train net output #0: loss = 0.00707143 (* 1 = 0.00707143 loss)
I0403 03:14:30.885316 19293 sgd_solver.cpp:106] Iteration 1470, lr = 0.0005
I0403 03:14:34.342133 19293 solver.cpp:228] Iteration 1475, loss = 0.0429414
I0403 03:14:34.368154 19293 solver.cpp:244]     Train net output #0: loss = 0.0429413 (* 1 = 0.0429413 loss)
I0403 03:14:34.518267 19293 sgd_solver.cpp:106] Iteration 1475, lr = 0.0005
I0403 03:14:37.971153 19293 solver.cpp:228] Iteration 1480, loss = 0.0359106
I0403 03:14:37.978240 19293 solver.cpp:244]     Train net output #0: loss = 0.0359105 (* 1 = 0.0359105 loss)
I0403 03:14:38.172760 19293 sgd_solver.cpp:106] Iteration 1480, lr = 0.0005
I0403 03:14:41.581746 19293 solver.cpp:228] Iteration 1485, loss = 0.010741
I0403 03:14:41.588744 19293 solver.cpp:244]     Train net output #0: loss = 0.010741 (* 1 = 0.010741 loss)
I0403 03:14:41.832083 19293 sgd_solver.cpp:106] Iteration 1485, lr = 0.0005
I0403 03:14:45.273635 19293 solver.cpp:228] Iteration 1490, loss = 0.00465066
I0403 03:14:45.280964 19293 solver.cpp:244]     Train net output #0: loss = 0.00465062 (* 1 = 0.00465062 loss)
I0403 03:14:45.468139 19293 sgd_solver.cpp:106] Iteration 1490, lr = 0.0005
I0403 03:14:48.902477 19293 solver.cpp:228] Iteration 1495, loss = 0.00218953
I0403 03:14:48.908478 19293 solver.cpp:244]     Train net output #0: loss = 0.0021895 (* 1 = 0.0021895 loss)
I0403 03:14:49.096621 19293 sgd_solver.cpp:106] Iteration 1495, lr = 0.0005
I0403 03:14:52.554337 19293 solver.cpp:228] Iteration 1500, loss = 0.0450052
I0403 03:14:52.560883 19293 solver.cpp:244]     Train net output #0: loss = 0.0450051 (* 1 = 0.0450051 loss)
I0403 03:14:52.732805 19293 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0403 03:14:56.184742 19293 solver.cpp:228] Iteration 1505, loss = 0.00428757
I0403 03:14:56.190820 19293 solver.cpp:244]     Train net output #0: loss = 0.00428754 (* 1 = 0.00428754 loss)
I0403 03:14:56.370460 19293 sgd_solver.cpp:106] Iteration 1505, lr = 0.0005
I0403 03:14:59.870551 19293 solver.cpp:228] Iteration 1510, loss = 0.0068904
I0403 03:14:59.876641 19293 solver.cpp:244]     Train net output #0: loss = 0.00689036 (* 1 = 0.00689036 loss)
I0403 03:15:00.056290 19293 sgd_solver.cpp:106] Iteration 1510, lr = 0.0005
I0403 03:15:03.453318 19293 solver.cpp:228] Iteration 1515, loss = 0.0021095
I0403 03:15:03.459352 19293 solver.cpp:244]     Train net output #0: loss = 0.00210947 (* 1 = 0.00210947 loss)
I0403 03:15:03.659773 19293 sgd_solver.cpp:106] Iteration 1515, lr = 0.0005
I0403 03:15:07.107836 19293 solver.cpp:228] Iteration 1520, loss = 0.0378011
I0403 03:15:07.115000 19293 solver.cpp:244]     Train net output #0: loss = 0.0378011 (* 1 = 0.0378011 loss)
I0403 03:15:07.314321 19293 sgd_solver.cpp:106] Iteration 1520, lr = 0.0005
I0403 03:15:10.780712 19293 solver.cpp:228] Iteration 1525, loss = 0.0409497
I0403 03:15:10.788643 19293 solver.cpp:244]     Train net output #0: loss = 0.0409496 (* 1 = 0.0409496 loss)
I0403 03:15:10.976227 19293 sgd_solver.cpp:106] Iteration 1525, lr = 0.0005
I0403 03:15:14.391604 19293 solver.cpp:228] Iteration 1530, loss = 0.00318553
I0403 03:15:14.397228 19293 solver.cpp:244]     Train net output #0: loss = 0.00318549 (* 1 = 0.00318549 loss)
I0403 03:15:14.579741 19293 sgd_solver.cpp:106] Iteration 1530, lr = 0.0005
I0403 03:15:18.024111 19293 solver.cpp:228] Iteration 1535, loss = 0.0142951
I0403 03:15:18.034268 19293 solver.cpp:244]     Train net output #0: loss = 0.014295 (* 1 = 0.014295 loss)
I0403 03:15:18.281883 19293 sgd_solver.cpp:106] Iteration 1535, lr = 0.0005
I0403 03:15:21.734503 19293 solver.cpp:228] Iteration 1540, loss = 0.0148434
I0403 03:15:21.740986 19293 solver.cpp:244]     Train net output #0: loss = 0.0148433 (* 1 = 0.0148433 loss)
I0403 03:15:21.916626 19293 sgd_solver.cpp:106] Iteration 1540, lr = 0.0005
I0403 03:15:25.406554 19293 solver.cpp:228] Iteration 1545, loss = 0.023538
I0403 03:15:25.413915 19293 solver.cpp:244]     Train net output #0: loss = 0.023538 (* 1 = 0.023538 loss)
I0403 03:15:25.605679 19293 sgd_solver.cpp:106] Iteration 1545, lr = 0.0005
I0403 03:15:29.110816 19293 solver.cpp:228] Iteration 1550, loss = 0.0138185
I0403 03:15:29.116672 19293 solver.cpp:244]     Train net output #0: loss = 0.0138184 (* 1 = 0.0138184 loss)
I0403 03:15:29.288980 19293 sgd_solver.cpp:106] Iteration 1550, lr = 0.0005
I0403 03:15:32.808270 19293 solver.cpp:228] Iteration 1555, loss = 0.00176776
I0403 03:15:32.814827 19293 solver.cpp:244]     Train net output #0: loss = 0.00176772 (* 1 = 0.00176772 loss)
I0403 03:15:33.035367 19293 sgd_solver.cpp:106] Iteration 1555, lr = 0.0005
I0403 03:15:36.547996 19293 solver.cpp:228] Iteration 1560, loss = 0.0118902
I0403 03:15:36.555019 19293 solver.cpp:244]     Train net output #0: loss = 0.0118902 (* 1 = 0.0118902 loss)
I0403 03:15:36.734530 19293 sgd_solver.cpp:106] Iteration 1560, lr = 0.0005
I0403 03:15:40.220165 19293 solver.cpp:228] Iteration 1565, loss = 0.00758121
I0403 03:15:40.226419 19293 solver.cpp:244]     Train net output #0: loss = 0.00758117 (* 1 = 0.00758117 loss)
I0403 03:15:40.418370 19293 sgd_solver.cpp:106] Iteration 1565, lr = 0.0005
I0403 03:15:43.870934 19293 solver.cpp:228] Iteration 1570, loss = 0.00453564
I0403 03:15:43.877732 19293 solver.cpp:244]     Train net output #0: loss = 0.00453561 (* 1 = 0.00453561 loss)
I0403 03:15:44.064049 19293 sgd_solver.cpp:106] Iteration 1570, lr = 0.0005
I0403 03:15:47.011153 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1575.caffemodel
I0403 03:15:49.766422 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1575.solverstate
I0403 03:15:51.687021 19293 solver.cpp:337] Iteration 1575, Testing net (#0)
I0403 03:17:30.174928 19293 solver.cpp:404]     Test net output #0: accuracy = 0.934325
I0403 03:17:30.192497 19293 solver.cpp:404]     Test net output #1: loss = 0.253988 (* 1 = 0.253988 loss)
I0403 03:17:30.726162 19293 solver.cpp:228] Iteration 1575, loss = 0.0230513
I0403 03:17:30.732982 19293 solver.cpp:244]     Train net output #0: loss = 0.0230513 (* 1 = 0.0230513 loss)
I0403 03:17:30.879309 19293 sgd_solver.cpp:106] Iteration 1575, lr = 0.0005
I0403 03:17:34.521473 19293 solver.cpp:228] Iteration 1580, loss = 0.00647195
I0403 03:17:34.528326 19293 solver.cpp:244]     Train net output #0: loss = 0.00647191 (* 1 = 0.00647191 loss)
I0403 03:17:34.707634 19293 sgd_solver.cpp:106] Iteration 1580, lr = 0.0005
I0403 03:17:38.159826 19293 solver.cpp:228] Iteration 1585, loss = 0.0144831
I0403 03:17:38.166966 19293 solver.cpp:244]     Train net output #0: loss = 0.014483 (* 1 = 0.014483 loss)
I0403 03:17:38.356487 19293 sgd_solver.cpp:106] Iteration 1585, lr = 0.0005
I0403 03:17:41.804503 19293 solver.cpp:228] Iteration 1590, loss = 0.0302915
I0403 03:17:41.811148 19293 solver.cpp:244]     Train net output #0: loss = 0.0302915 (* 1 = 0.0302915 loss)
I0403 03:17:41.991320 19293 sgd_solver.cpp:106] Iteration 1590, lr = 0.0005
I0403 03:17:45.445572 19293 solver.cpp:228] Iteration 1595, loss = 0.00421117
I0403 03:17:45.451536 19293 solver.cpp:244]     Train net output #0: loss = 0.00421113 (* 1 = 0.00421113 loss)
I0403 03:17:45.653723 19293 sgd_solver.cpp:106] Iteration 1595, lr = 0.0005
I0403 03:17:49.170758 19293 solver.cpp:228] Iteration 1600, loss = 0.00183856
I0403 03:17:49.177516 19293 solver.cpp:244]     Train net output #0: loss = 0.00183851 (* 1 = 0.00183851 loss)
I0403 03:17:49.364855 19293 sgd_solver.cpp:106] Iteration 1600, lr = 0.0005
I0403 03:17:52.827695 19293 solver.cpp:228] Iteration 1605, loss = 0.0138845
I0403 03:17:52.834758 19293 solver.cpp:244]     Train net output #0: loss = 0.0138844 (* 1 = 0.0138844 loss)
I0403 03:17:53.022595 19293 sgd_solver.cpp:106] Iteration 1605, lr = 0.0005
I0403 03:17:56.492995 19293 solver.cpp:228] Iteration 1610, loss = 0.00845791
I0403 03:17:56.499346 19293 solver.cpp:244]     Train net output #0: loss = 0.00845787 (* 1 = 0.00845787 loss)
I0403 03:17:56.672354 19293 sgd_solver.cpp:106] Iteration 1610, lr = 0.0005
I0403 03:18:00.176695 19293 solver.cpp:228] Iteration 1615, loss = 0.0322136
I0403 03:18:00.183523 19293 solver.cpp:244]     Train net output #0: loss = 0.0322136 (* 1 = 0.0322136 loss)
I0403 03:18:00.354409 19293 sgd_solver.cpp:106] Iteration 1615, lr = 0.0005
I0403 03:18:03.814251 19293 solver.cpp:228] Iteration 1620, loss = 0.00126712
I0403 03:18:03.821049 19293 solver.cpp:244]     Train net output #0: loss = 0.00126707 (* 1 = 0.00126707 loss)
I0403 03:18:04.102041 19293 sgd_solver.cpp:106] Iteration 1620, lr = 0.0005
I0403 03:18:07.519315 19293 solver.cpp:228] Iteration 1625, loss = 0.0240558
I0403 03:18:07.538789 19293 solver.cpp:244]     Train net output #0: loss = 0.0240557 (* 1 = 0.0240557 loss)
I0403 03:18:07.711653 19293 sgd_solver.cpp:106] Iteration 1625, lr = 0.0005
I0403 03:18:11.208897 19293 solver.cpp:228] Iteration 1630, loss = 0.00898843
I0403 03:18:11.215773 19293 solver.cpp:244]     Train net output #0: loss = 0.00898839 (* 1 = 0.00898839 loss)
I0403 03:18:11.424777 19293 sgd_solver.cpp:106] Iteration 1630, lr = 0.0005
I0403 03:18:14.955014 19293 solver.cpp:228] Iteration 1635, loss = 0.0144352
I0403 03:18:14.961401 19293 solver.cpp:244]     Train net output #0: loss = 0.0144352 (* 1 = 0.0144352 loss)
I0403 03:18:15.116397 19293 sgd_solver.cpp:106] Iteration 1635, lr = 0.0005
I0403 03:18:18.675947 19293 solver.cpp:228] Iteration 1640, loss = 0.00241909
I0403 03:18:18.682109 19293 solver.cpp:244]     Train net output #0: loss = 0.00241904 (* 1 = 0.00241904 loss)
I0403 03:18:18.867053 19293 sgd_solver.cpp:106] Iteration 1640, lr = 0.0005
I0403 03:18:22.373260 19293 solver.cpp:228] Iteration 1645, loss = 0.0295108
I0403 03:18:22.380079 19293 solver.cpp:244]     Train net output #0: loss = 0.0295108 (* 1 = 0.0295108 loss)
I0403 03:18:22.565488 19293 sgd_solver.cpp:106] Iteration 1645, lr = 0.0005
I0403 03:18:26.170194 19293 solver.cpp:228] Iteration 1650, loss = 0.0227717
I0403 03:18:26.176036 19293 solver.cpp:244]     Train net output #0: loss = 0.0227717 (* 1 = 0.0227717 loss)
I0403 03:18:26.378304 19293 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I0403 03:18:29.878784 19293 solver.cpp:228] Iteration 1655, loss = 0.0124346
I0403 03:18:29.885782 19293 solver.cpp:244]     Train net output #0: loss = 0.0124346 (* 1 = 0.0124346 loss)
I0403 03:18:30.050307 19293 sgd_solver.cpp:106] Iteration 1655, lr = 0.0005
I0403 03:18:33.497592 19293 solver.cpp:228] Iteration 1660, loss = 0.00633365
I0403 03:18:33.504850 19293 solver.cpp:244]     Train net output #0: loss = 0.00633361 (* 1 = 0.00633361 loss)
I0403 03:18:33.736850 19293 sgd_solver.cpp:106] Iteration 1660, lr = 0.0005
I0403 03:18:37.202183 19293 solver.cpp:228] Iteration 1665, loss = 0.00325509
I0403 03:18:37.207927 19293 solver.cpp:244]     Train net output #0: loss = 0.00325505 (* 1 = 0.00325505 loss)
I0403 03:18:37.424875 19293 sgd_solver.cpp:106] Iteration 1665, lr = 0.0005
I0403 03:18:41.048167 19293 solver.cpp:228] Iteration 1670, loss = 0.0499935
I0403 03:18:41.055129 19293 solver.cpp:244]     Train net output #0: loss = 0.0499934 (* 1 = 0.0499934 loss)
I0403 03:18:41.228586 19293 sgd_solver.cpp:106] Iteration 1670, lr = 0.0005
I0403 03:18:44.694988 19293 solver.cpp:228] Iteration 1675, loss = 0.00747335
I0403 03:18:44.701773 19293 solver.cpp:244]     Train net output #0: loss = 0.00747331 (* 1 = 0.00747331 loss)
I0403 03:18:44.849128 19293 sgd_solver.cpp:106] Iteration 1675, lr = 0.0005
I0403 03:18:47.858207 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1680.caffemodel
I0403 03:18:50.614599 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1680.solverstate
I0403 03:18:52.530365 19293 solver.cpp:337] Iteration 1680, Testing net (#0)
I0403 03:20:31.022086 19293 solver.cpp:404]     Test net output #0: accuracy = 0.934898
I0403 03:20:31.027530 19293 solver.cpp:404]     Test net output #1: loss = 0.260269 (* 1 = 0.260269 loss)
I0403 03:20:31.571818 19293 solver.cpp:228] Iteration 1680, loss = 0.00916542
I0403 03:20:31.577224 19293 solver.cpp:244]     Train net output #0: loss = 0.00916537 (* 1 = 0.00916537 loss)
I0403 03:20:31.727396 19293 sgd_solver.cpp:106] Iteration 1680, lr = 0.0005
I0403 03:20:35.293092 19293 solver.cpp:228] Iteration 1685, loss = 0.0078814
I0403 03:20:35.307728 19293 solver.cpp:244]     Train net output #0: loss = 0.00788135 (* 1 = 0.00788135 loss)
I0403 03:20:35.486693 19293 sgd_solver.cpp:106] Iteration 1685, lr = 0.0005
I0403 03:20:38.922318 19293 solver.cpp:228] Iteration 1690, loss = 0.0350085
I0403 03:20:38.928251 19293 solver.cpp:244]     Train net output #0: loss = 0.0350084 (* 1 = 0.0350084 loss)
I0403 03:20:39.129919 19293 sgd_solver.cpp:106] Iteration 1690, lr = 0.0005
I0403 03:20:42.571125 19293 solver.cpp:228] Iteration 1695, loss = 0.00522064
I0403 03:20:42.577886 19293 solver.cpp:244]     Train net output #0: loss = 0.00522059 (* 1 = 0.00522059 loss)
I0403 03:20:42.777647 19293 sgd_solver.cpp:106] Iteration 1695, lr = 0.0005
I0403 03:20:46.213598 19293 solver.cpp:228] Iteration 1700, loss = 0.00193571
I0403 03:20:46.219346 19293 solver.cpp:244]     Train net output #0: loss = 0.00193567 (* 1 = 0.00193567 loss)
I0403 03:20:46.424517 19293 sgd_solver.cpp:106] Iteration 1700, lr = 0.0005
I0403 03:20:49.877943 19293 solver.cpp:228] Iteration 1705, loss = 0.00241018
I0403 03:20:49.884395 19293 solver.cpp:244]     Train net output #0: loss = 0.00241013 (* 1 = 0.00241013 loss)
I0403 03:20:50.066898 19293 sgd_solver.cpp:106] Iteration 1705, lr = 0.0005
I0403 03:20:53.587308 19293 solver.cpp:228] Iteration 1710, loss = 0.00474558
I0403 03:20:53.593513 19293 solver.cpp:244]     Train net output #0: loss = 0.00474553 (* 1 = 0.00474553 loss)
I0403 03:20:53.754250 19293 sgd_solver.cpp:106] Iteration 1710, lr = 0.0005
I0403 03:20:57.311866 19293 solver.cpp:228] Iteration 1715, loss = 0.00437208
I0403 03:20:57.320266 19293 solver.cpp:244]     Train net output #0: loss = 0.00437204 (* 1 = 0.00437204 loss)
I0403 03:20:57.474648 19293 sgd_solver.cpp:106] Iteration 1715, lr = 0.0005
I0403 03:21:01.183723 19293 solver.cpp:228] Iteration 1720, loss = 0.00469488
I0403 03:21:01.194515 19293 solver.cpp:244]     Train net output #0: loss = 0.00469484 (* 1 = 0.00469484 loss)
I0403 03:21:01.371332 19293 sgd_solver.cpp:106] Iteration 1720, lr = 0.0005
I0403 03:21:04.852650 19293 solver.cpp:228] Iteration 1725, loss = 0.00633255
I0403 03:21:04.859951 19293 solver.cpp:244]     Train net output #0: loss = 0.00633251 (* 1 = 0.00633251 loss)
I0403 03:21:05.044687 19293 sgd_solver.cpp:106] Iteration 1725, lr = 0.0005
I0403 03:21:08.458422 19293 solver.cpp:228] Iteration 1730, loss = 0.00111953
I0403 03:21:08.465564 19293 solver.cpp:244]     Train net output #0: loss = 0.00111949 (* 1 = 0.00111949 loss)
I0403 03:21:08.646780 19293 sgd_solver.cpp:106] Iteration 1730, lr = 0.0005
I0403 03:21:12.095405 19293 solver.cpp:228] Iteration 1735, loss = 0.00224116
I0403 03:21:12.102895 19293 solver.cpp:244]     Train net output #0: loss = 0.00224111 (* 1 = 0.00224111 loss)
I0403 03:21:12.282099 19293 sgd_solver.cpp:106] Iteration 1735, lr = 0.0005
I0403 03:21:15.683594 19293 solver.cpp:228] Iteration 1740, loss = 0.00570727
I0403 03:21:15.688994 19293 solver.cpp:244]     Train net output #0: loss = 0.00570722 (* 1 = 0.00570722 loss)
I0403 03:21:15.883667 19293 sgd_solver.cpp:106] Iteration 1740, lr = 0.0005
I0403 03:21:19.326136 19293 solver.cpp:228] Iteration 1745, loss = 0.0100285
I0403 03:21:19.330996 19293 solver.cpp:244]     Train net output #0: loss = 0.0100284 (* 1 = 0.0100284 loss)
I0403 03:21:19.518324 19293 sgd_solver.cpp:106] Iteration 1745, lr = 0.0005
I0403 03:21:22.942468 19293 solver.cpp:228] Iteration 1750, loss = 0.00257571
I0403 03:21:22.949774 19293 solver.cpp:244]     Train net output #0: loss = 0.00257567 (* 1 = 0.00257567 loss)
I0403 03:21:23.139914 19293 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I0403 03:21:26.640177 19293 solver.cpp:228] Iteration 1755, loss = 0.00757932
I0403 03:21:26.646360 19293 solver.cpp:244]     Train net output #0: loss = 0.00757927 (* 1 = 0.00757927 loss)
I0403 03:21:26.827028 19293 sgd_solver.cpp:106] Iteration 1755, lr = 0.0005
I0403 03:21:30.308431 19293 solver.cpp:228] Iteration 1760, loss = 0.00229987
I0403 03:21:30.314991 19293 solver.cpp:244]     Train net output #0: loss = 0.00229982 (* 1 = 0.00229982 loss)
I0403 03:21:30.511184 19293 sgd_solver.cpp:106] Iteration 1760, lr = 0.0005
I0403 03:21:34.025192 19293 solver.cpp:228] Iteration 1765, loss = 0.00522843
I0403 03:21:34.034925 19293 solver.cpp:244]     Train net output #0: loss = 0.00522839 (* 1 = 0.00522839 loss)
I0403 03:21:34.154119 19293 sgd_solver.cpp:106] Iteration 1765, lr = 0.0005
I0403 03:21:37.713352 19293 solver.cpp:228] Iteration 1770, loss = 0.0304398
I0403 03:21:37.720986 19293 solver.cpp:244]     Train net output #0: loss = 0.0304398 (* 1 = 0.0304398 loss)
I0403 03:21:37.912171 19293 sgd_solver.cpp:106] Iteration 1770, lr = 0.0005
I0403 03:21:41.362823 19293 solver.cpp:228] Iteration 1775, loss = 0.0031794
I0403 03:21:41.369549 19293 solver.cpp:244]     Train net output #0: loss = 0.00317935 (* 1 = 0.00317935 loss)
I0403 03:21:41.547641 19293 sgd_solver.cpp:106] Iteration 1775, lr = 0.0005
I0403 03:21:44.999900 19293 solver.cpp:228] Iteration 1780, loss = 0.000463717
I0403 03:21:45.007511 19293 solver.cpp:244]     Train net output #0: loss = 0.000463675 (* 1 = 0.000463675 loss)
I0403 03:21:45.200462 19293 sgd_solver.cpp:106] Iteration 1780, lr = 0.0005
I0403 03:21:48.149657 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1785.caffemodel
I0403 03:21:50.896137 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1785.solverstate
I0403 03:21:52.803843 19293 solver.cpp:337] Iteration 1785, Testing net (#0)
I0403 03:23:31.291282 19293 solver.cpp:404]     Test net output #0: accuracy = 0.935241
I0403 03:23:31.298413 19293 solver.cpp:404]     Test net output #1: loss = 0.257437 (* 1 = 0.257437 loss)
I0403 03:23:31.808398 19293 solver.cpp:228] Iteration 1785, loss = 0.00426111
I0403 03:23:31.815145 19293 solver.cpp:244]     Train net output #0: loss = 0.00426107 (* 1 = 0.00426107 loss)
I0403 03:23:32.007194 19293 sgd_solver.cpp:106] Iteration 1785, lr = 0.0005
I0403 03:23:35.425904 19293 solver.cpp:228] Iteration 1790, loss = 0.0209842
I0403 03:23:35.432579 19293 solver.cpp:244]     Train net output #0: loss = 0.0209841 (* 1 = 0.0209841 loss)
I0403 03:23:35.612121 19293 sgd_solver.cpp:106] Iteration 1790, lr = 0.0005
I0403 03:23:39.053149 19293 solver.cpp:228] Iteration 1795, loss = 0.00535424
I0403 03:23:39.059476 19293 solver.cpp:244]     Train net output #0: loss = 0.00535419 (* 1 = 0.00535419 loss)
I0403 03:23:39.256206 19293 sgd_solver.cpp:106] Iteration 1795, lr = 0.0005
I0403 03:23:42.745000 19293 solver.cpp:228] Iteration 1800, loss = 0.0267061
I0403 03:23:42.750948 19293 solver.cpp:244]     Train net output #0: loss = 0.0267061 (* 1 = 0.0267061 loss)
I0403 03:23:42.978513 19293 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0403 03:23:46.463593 19293 solver.cpp:228] Iteration 1805, loss = 0.0343059
I0403 03:23:46.469350 19293 solver.cpp:244]     Train net output #0: loss = 0.0343059 (* 1 = 0.0343059 loss)
I0403 03:23:46.636998 19293 sgd_solver.cpp:106] Iteration 1805, lr = 0.0005
I0403 03:23:50.102942 19293 solver.cpp:228] Iteration 1810, loss = 0.0117252
I0403 03:23:50.109516 19293 solver.cpp:244]     Train net output #0: loss = 0.0117252 (* 1 = 0.0117252 loss)
I0403 03:23:50.289871 19293 sgd_solver.cpp:106] Iteration 1810, lr = 0.0005
I0403 03:23:53.771294 19293 solver.cpp:228] Iteration 1815, loss = 0.00398113
I0403 03:23:53.778244 19293 solver.cpp:244]     Train net output #0: loss = 0.00398108 (* 1 = 0.00398108 loss)
I0403 03:23:53.960156 19293 sgd_solver.cpp:106] Iteration 1815, lr = 0.0005
I0403 03:23:57.451341 19293 solver.cpp:228] Iteration 1820, loss = 0.0010413
I0403 03:23:57.457085 19293 solver.cpp:244]     Train net output #0: loss = 0.00104125 (* 1 = 0.00104125 loss)
I0403 03:23:57.638893 19293 sgd_solver.cpp:106] Iteration 1820, lr = 0.0005
I0403 03:24:01.047014 19293 solver.cpp:228] Iteration 1825, loss = 0.00423264
I0403 03:24:01.057075 19293 solver.cpp:244]     Train net output #0: loss = 0.00423259 (* 1 = 0.00423259 loss)
I0403 03:24:01.291741 19293 sgd_solver.cpp:106] Iteration 1825, lr = 0.0005
I0403 03:24:04.790205 19293 solver.cpp:228] Iteration 1830, loss = 0.0065891
I0403 03:24:04.798005 19293 solver.cpp:244]     Train net output #0: loss = 0.00658905 (* 1 = 0.00658905 loss)
I0403 03:24:04.980198 19293 sgd_solver.cpp:106] Iteration 1830, lr = 0.0005
I0403 03:24:08.409703 19293 solver.cpp:228] Iteration 1835, loss = 0.00964717
I0403 03:24:08.416420 19293 solver.cpp:244]     Train net output #0: loss = 0.00964712 (* 1 = 0.00964712 loss)
I0403 03:24:08.591445 19293 sgd_solver.cpp:106] Iteration 1835, lr = 0.0005
I0403 03:24:12.117652 19293 solver.cpp:228] Iteration 1840, loss = 0.0121187
I0403 03:24:12.124328 19293 solver.cpp:244]     Train net output #0: loss = 0.0121187 (* 1 = 0.0121187 loss)
I0403 03:24:12.323685 19293 sgd_solver.cpp:106] Iteration 1840, lr = 0.0005
I0403 03:24:15.829851 19293 solver.cpp:228] Iteration 1845, loss = 0.0108603
I0403 03:24:15.837276 19293 solver.cpp:244]     Train net output #0: loss = 0.0108602 (* 1 = 0.0108602 loss)
I0403 03:24:16.026584 19293 sgd_solver.cpp:106] Iteration 1845, lr = 0.0005
I0403 03:24:19.490964 19293 solver.cpp:228] Iteration 1850, loss = 0.0759801
I0403 03:24:19.497277 19293 solver.cpp:244]     Train net output #0: loss = 0.0759801 (* 1 = 0.0759801 loss)
I0403 03:24:19.693677 19293 sgd_solver.cpp:106] Iteration 1850, lr = 0.0005
I0403 03:24:23.137493 19293 solver.cpp:228] Iteration 1855, loss = 0.0217793
I0403 03:24:23.144204 19293 solver.cpp:244]     Train net output #0: loss = 0.0217793 (* 1 = 0.0217793 loss)
I0403 03:24:23.341536 19293 sgd_solver.cpp:106] Iteration 1855, lr = 0.0005
I0403 03:24:26.862381 19293 solver.cpp:228] Iteration 1860, loss = 0.00337854
I0403 03:24:26.868460 19293 solver.cpp:244]     Train net output #0: loss = 0.00337849 (* 1 = 0.00337849 loss)
I0403 03:24:27.060482 19293 sgd_solver.cpp:106] Iteration 1860, lr = 0.0005
I0403 03:24:30.532462 19293 solver.cpp:228] Iteration 1865, loss = 0.00104167
I0403 03:24:30.539204 19293 solver.cpp:244]     Train net output #0: loss = 0.00104162 (* 1 = 0.00104162 loss)
I0403 03:24:30.720324 19293 sgd_solver.cpp:106] Iteration 1865, lr = 0.0005
I0403 03:24:34.200104 19293 solver.cpp:228] Iteration 1870, loss = 0.0379874
I0403 03:24:34.206420 19293 solver.cpp:244]     Train net output #0: loss = 0.0379874 (* 1 = 0.0379874 loss)
I0403 03:24:34.395331 19293 sgd_solver.cpp:106] Iteration 1870, lr = 0.0005
I0403 03:24:37.828285 19293 solver.cpp:228] Iteration 1875, loss = 0.0178742
I0403 03:24:37.834604 19293 solver.cpp:244]     Train net output #0: loss = 0.0178741 (* 1 = 0.0178741 loss)
I0403 03:24:38.018193 19293 sgd_solver.cpp:106] Iteration 1875, lr = 0.0005
I0403 03:24:41.530843 19293 solver.cpp:228] Iteration 1880, loss = 0.0036615
I0403 03:24:41.537518 19293 solver.cpp:244]     Train net output #0: loss = 0.00366145 (* 1 = 0.00366145 loss)
I0403 03:24:41.708598 19293 sgd_solver.cpp:106] Iteration 1880, lr = 0.0005
I0403 03:24:45.192715 19293 solver.cpp:228] Iteration 1885, loss = 0.000856073
I0403 03:24:45.199615 19293 solver.cpp:244]     Train net output #0: loss = 0.00085602 (* 1 = 0.00085602 loss)
I0403 03:24:45.421293 19293 sgd_solver.cpp:106] Iteration 1885, lr = 0.0005
I0403 03:24:48.316836 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1890.caffemodel
I0403 03:24:50.937332 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1890.solverstate
I0403 03:24:52.740769 19293 solver.cpp:337] Iteration 1890, Testing net (#0)
I0403 03:26:31.238174 19293 solver.cpp:404]     Test net output #0: accuracy = 0.934485
I0403 03:26:31.244315 19293 solver.cpp:404]     Test net output #1: loss = 0.261904 (* 1 = 0.261904 loss)
I0403 03:26:31.758926 19293 solver.cpp:228] Iteration 1890, loss = 0.00600165
I0403 03:26:31.782485 19293 solver.cpp:244]     Train net output #0: loss = 0.0060016 (* 1 = 0.0060016 loss)
I0403 03:26:31.937353 19293 sgd_solver.cpp:106] Iteration 1890, lr = 0.0005
I0403 03:26:35.411439 19293 solver.cpp:228] Iteration 1895, loss = 0.00310869
I0403 03:26:35.417490 19293 solver.cpp:244]     Train net output #0: loss = 0.00310864 (* 1 = 0.00310864 loss)
I0403 03:26:35.605262 19293 sgd_solver.cpp:106] Iteration 1895, lr = 0.0005
I0403 03:26:39.075110 19293 solver.cpp:228] Iteration 1900, loss = 0.00054857
I0403 03:26:39.081537 19293 solver.cpp:244]     Train net output #0: loss = 0.000548519 (* 1 = 0.000548519 loss)
I0403 03:26:39.271469 19293 sgd_solver.cpp:106] Iteration 1900, lr = 0.0005
I0403 03:26:42.768682 19293 solver.cpp:228] Iteration 1905, loss = 0.00286691
I0403 03:26:42.775171 19293 solver.cpp:244]     Train net output #0: loss = 0.00286686 (* 1 = 0.00286686 loss)
I0403 03:26:42.971148 19293 sgd_solver.cpp:106] Iteration 1905, lr = 0.0005
I0403 03:26:46.454514 19293 solver.cpp:228] Iteration 1910, loss = 0.00233436
I0403 03:26:46.463073 19293 solver.cpp:244]     Train net output #0: loss = 0.00233431 (* 1 = 0.00233431 loss)
I0403 03:26:46.645169 19293 sgd_solver.cpp:106] Iteration 1910, lr = 0.0005
I0403 03:26:50.156311 19293 solver.cpp:228] Iteration 1915, loss = 0.00687771
I0403 03:26:50.162358 19293 solver.cpp:244]     Train net output #0: loss = 0.00687766 (* 1 = 0.00687766 loss)
I0403 03:26:50.346879 19293 sgd_solver.cpp:106] Iteration 1915, lr = 0.0005
I0403 03:26:53.763794 19293 solver.cpp:228] Iteration 1920, loss = 0.0128048
I0403 03:26:53.772302 19293 solver.cpp:244]     Train net output #0: loss = 0.0128047 (* 1 = 0.0128047 loss)
I0403 03:26:53.950913 19293 sgd_solver.cpp:106] Iteration 1920, lr = 0.0005
I0403 03:26:57.442471 19293 solver.cpp:228] Iteration 1925, loss = 0.00271876
I0403 03:26:57.449326 19293 solver.cpp:244]     Train net output #0: loss = 0.00271871 (* 1 = 0.00271871 loss)
I0403 03:26:57.636700 19293 sgd_solver.cpp:106] Iteration 1925, lr = 0.0005
I0403 03:27:01.084687 19293 solver.cpp:228] Iteration 1930, loss = 0.00191721
I0403 03:27:01.091392 19293 solver.cpp:244]     Train net output #0: loss = 0.00191715 (* 1 = 0.00191715 loss)
I0403 03:27:01.258888 19293 sgd_solver.cpp:106] Iteration 1930, lr = 0.0005
I0403 03:27:04.715075 19293 solver.cpp:228] Iteration 1935, loss = 0.00226577
I0403 03:27:04.722069 19293 solver.cpp:244]     Train net output #0: loss = 0.00226571 (* 1 = 0.00226571 loss)
I0403 03:27:04.951128 19293 sgd_solver.cpp:106] Iteration 1935, lr = 0.0005
I0403 03:27:08.467295 19293 solver.cpp:228] Iteration 1940, loss = 0.0119841
I0403 03:27:08.472873 19293 solver.cpp:244]     Train net output #0: loss = 0.011984 (* 1 = 0.011984 loss)
I0403 03:27:08.668097 19293 sgd_solver.cpp:106] Iteration 1940, lr = 0.0005
I0403 03:27:12.117916 19293 solver.cpp:228] Iteration 1945, loss = 0.0151676
I0403 03:27:12.124539 19293 solver.cpp:244]     Train net output #0: loss = 0.0151676 (* 1 = 0.0151676 loss)
I0403 03:27:12.341444 19293 sgd_solver.cpp:106] Iteration 1945, lr = 0.0005
I0403 03:27:15.781991 19293 solver.cpp:228] Iteration 1950, loss = 0.00642259
I0403 03:27:15.788413 19293 solver.cpp:244]     Train net output #0: loss = 0.00642253 (* 1 = 0.00642253 loss)
I0403 03:27:15.967274 19293 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I0403 03:27:19.387403 19293 solver.cpp:228] Iteration 1955, loss = 0.0118811
I0403 03:27:19.393241 19293 solver.cpp:244]     Train net output #0: loss = 0.011881 (* 1 = 0.011881 loss)
I0403 03:27:19.577877 19293 sgd_solver.cpp:106] Iteration 1955, lr = 0.0005
I0403 03:27:23.047329 19293 solver.cpp:228] Iteration 1960, loss = 0.00744295
I0403 03:27:23.053421 19293 solver.cpp:244]     Train net output #0: loss = 0.0074429 (* 1 = 0.0074429 loss)
I0403 03:27:23.255089 19293 sgd_solver.cpp:106] Iteration 1960, lr = 0.0005
I0403 03:27:26.743119 19293 solver.cpp:228] Iteration 1965, loss = 0.00236129
I0403 03:27:26.750345 19293 solver.cpp:244]     Train net output #0: loss = 0.00236123 (* 1 = 0.00236123 loss)
I0403 03:27:26.898119 19293 sgd_solver.cpp:106] Iteration 1965, lr = 0.0005
I0403 03:27:30.462860 19293 solver.cpp:228] Iteration 1970, loss = 0.00112104
I0403 03:27:30.469974 19293 solver.cpp:244]     Train net output #0: loss = 0.00112098 (* 1 = 0.00112098 loss)
I0403 03:27:30.679039 19293 sgd_solver.cpp:106] Iteration 1970, lr = 0.0005
I0403 03:27:34.127521 19293 solver.cpp:228] Iteration 1975, loss = 0.0269008
I0403 03:27:34.134996 19293 solver.cpp:244]     Train net output #0: loss = 0.0269008 (* 1 = 0.0269008 loss)
I0403 03:27:34.313437 19293 sgd_solver.cpp:106] Iteration 1975, lr = 0.0005
I0403 03:27:37.877635 19293 solver.cpp:228] Iteration 1980, loss = 0.00888055
I0403 03:27:37.885485 19293 solver.cpp:244]     Train net output #0: loss = 0.0088805 (* 1 = 0.0088805 loss)
I0403 03:27:38.055135 19293 sgd_solver.cpp:106] Iteration 1980, lr = 0.0005
I0403 03:27:41.503123 19293 solver.cpp:228] Iteration 1985, loss = 0.00318582
I0403 03:27:41.509068 19293 solver.cpp:244]     Train net output #0: loss = 0.00318577 (* 1 = 0.00318577 loss)
I0403 03:27:41.739223 19293 sgd_solver.cpp:106] Iteration 1985, lr = 0.0005
I0403 03:27:45.167345 19293 solver.cpp:228] Iteration 1990, loss = 0.00141065
I0403 03:27:45.174541 19293 solver.cpp:244]     Train net output #0: loss = 0.00141059 (* 1 = 0.00141059 loss)
I0403 03:27:45.354035 19293 sgd_solver.cpp:106] Iteration 1990, lr = 0.0005
I0403 03:27:48.311697 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1995.caffemodel
I0403 03:27:50.979487 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_1995.solverstate
I0403 03:27:52.750962 19293 solver.cpp:337] Iteration 1995, Testing net (#0)
I0403 03:29:31.264397 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936775
I0403 03:29:31.270654 19293 solver.cpp:404]     Test net output #1: loss = 0.254431 (* 1 = 0.254431 loss)
I0403 03:29:31.809432 19293 solver.cpp:228] Iteration 1995, loss = 0.00832717
I0403 03:29:31.815312 19293 solver.cpp:244]     Train net output #0: loss = 0.00832712 (* 1 = 0.00832712 loss)
I0403 03:29:31.969899 19293 sgd_solver.cpp:106] Iteration 1995, lr = 0.0005
I0403 03:29:35.544168 19293 solver.cpp:228] Iteration 2000, loss = 0.026902
I0403 03:29:35.551583 19293 solver.cpp:244]     Train net output #0: loss = 0.0269019 (* 1 = 0.0269019 loss)
I0403 03:29:35.725952 19293 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I0403 03:29:39.211108 19293 solver.cpp:228] Iteration 2005, loss = 0.0086407
I0403 03:29:39.218240 19293 solver.cpp:244]     Train net output #0: loss = 0.00864065 (* 1 = 0.00864065 loss)
I0403 03:29:39.408419 19293 sgd_solver.cpp:106] Iteration 2005, lr = 0.0005
I0403 03:29:42.882256 19293 solver.cpp:228] Iteration 2010, loss = 0.00340465
I0403 03:29:42.889081 19293 solver.cpp:244]     Train net output #0: loss = 0.00340459 (* 1 = 0.00340459 loss)
I0403 03:29:43.058074 19293 sgd_solver.cpp:106] Iteration 2010, lr = 0.0005
I0403 03:29:46.609375 19293 solver.cpp:228] Iteration 2015, loss = 0.0131526
I0403 03:29:46.616312 19293 solver.cpp:244]     Train net output #0: loss = 0.0131526 (* 1 = 0.0131526 loss)
I0403 03:29:46.820183 19293 sgd_solver.cpp:106] Iteration 2015, lr = 0.0005
I0403 03:29:50.284164 19293 solver.cpp:228] Iteration 2020, loss = 0.00444508
I0403 03:29:50.290555 19293 solver.cpp:244]     Train net output #0: loss = 0.00444503 (* 1 = 0.00444503 loss)
I0403 03:29:50.477304 19293 sgd_solver.cpp:106] Iteration 2020, lr = 0.0005
I0403 03:29:53.998530 19293 solver.cpp:228] Iteration 2025, loss = 0.0111949
I0403 03:29:54.005180 19293 solver.cpp:244]     Train net output #0: loss = 0.0111949 (* 1 = 0.0111949 loss)
I0403 03:29:54.254624 19293 sgd_solver.cpp:106] Iteration 2025, lr = 0.0005
I0403 03:29:57.770809 19293 solver.cpp:228] Iteration 2030, loss = 0.0068506
I0403 03:29:57.795254 19293 solver.cpp:244]     Train net output #0: loss = 0.00685054 (* 1 = 0.00685054 loss)
I0403 03:29:57.966745 19293 sgd_solver.cpp:106] Iteration 2030, lr = 0.0005
I0403 03:30:01.454864 19293 solver.cpp:228] Iteration 2035, loss = 0.011564
I0403 03:30:01.461186 19293 solver.cpp:244]     Train net output #0: loss = 0.0115639 (* 1 = 0.0115639 loss)
I0403 03:30:01.713217 19293 sgd_solver.cpp:106] Iteration 2035, lr = 0.0005
I0403 03:30:05.194826 19293 solver.cpp:228] Iteration 2040, loss = 0.00473014
I0403 03:30:05.200220 19293 solver.cpp:244]     Train net output #0: loss = 0.00473008 (* 1 = 0.00473008 loss)
I0403 03:30:05.367645 19293 sgd_solver.cpp:106] Iteration 2040, lr = 0.0005
I0403 03:30:08.835032 19293 solver.cpp:228] Iteration 2045, loss = 0.0119204
I0403 03:30:08.840914 19293 solver.cpp:244]     Train net output #0: loss = 0.0119203 (* 1 = 0.0119203 loss)
I0403 03:30:09.036406 19293 sgd_solver.cpp:106] Iteration 2045, lr = 0.0005
I0403 03:30:12.554262 19293 solver.cpp:228] Iteration 2050, loss = 0.0109151
I0403 03:30:12.560149 19293 solver.cpp:244]     Train net output #0: loss = 0.010915 (* 1 = 0.010915 loss)
I0403 03:30:12.736076 19293 sgd_solver.cpp:106] Iteration 2050, lr = 0.0005
I0403 03:30:16.352378 19293 solver.cpp:228] Iteration 2055, loss = 0.00171032
I0403 03:30:16.358686 19293 solver.cpp:244]     Train net output #0: loss = 0.00171026 (* 1 = 0.00171026 loss)
I0403 03:30:16.603080 19293 sgd_solver.cpp:106] Iteration 2055, lr = 0.0005
I0403 03:30:20.131494 19293 solver.cpp:228] Iteration 2060, loss = 0.0115603
I0403 03:30:20.138416 19293 solver.cpp:244]     Train net output #0: loss = 0.0115602 (* 1 = 0.0115602 loss)
I0403 03:30:20.317137 19293 sgd_solver.cpp:106] Iteration 2060, lr = 0.0005
I0403 03:30:23.759740 19293 solver.cpp:228] Iteration 2065, loss = 0.00329772
I0403 03:30:23.767639 19293 solver.cpp:244]     Train net output #0: loss = 0.00329766 (* 1 = 0.00329766 loss)
I0403 03:30:23.946671 19293 sgd_solver.cpp:106] Iteration 2065, lr = 0.0005
I0403 03:30:27.397564 19293 solver.cpp:228] Iteration 2070, loss = 0.00153316
I0403 03:30:27.402832 19293 solver.cpp:244]     Train net output #0: loss = 0.0015331 (* 1 = 0.0015331 loss)
I0403 03:30:27.585588 19293 sgd_solver.cpp:106] Iteration 2070, lr = 0.0005
I0403 03:30:31.010154 19293 solver.cpp:228] Iteration 2075, loss = 0.0206108
I0403 03:30:31.016007 19293 solver.cpp:244]     Train net output #0: loss = 0.0206107 (* 1 = 0.0206107 loss)
I0403 03:30:31.195271 19293 sgd_solver.cpp:106] Iteration 2075, lr = 0.0005
I0403 03:30:34.654810 19293 solver.cpp:228] Iteration 2080, loss = 0.0040562
I0403 03:30:34.660840 19293 solver.cpp:244]     Train net output #0: loss = 0.00405614 (* 1 = 0.00405614 loss)
I0403 03:30:34.865809 19293 sgd_solver.cpp:106] Iteration 2080, lr = 0.0005
I0403 03:30:38.327955 19293 solver.cpp:228] Iteration 2085, loss = 0.00225844
I0403 03:30:38.334002 19293 solver.cpp:244]     Train net output #0: loss = 0.00225838 (* 1 = 0.00225838 loss)
I0403 03:30:38.527164 19293 sgd_solver.cpp:106] Iteration 2085, lr = 0.0005
I0403 03:30:41.951609 19293 solver.cpp:228] Iteration 2090, loss = 0.0306734
I0403 03:30:41.958063 19293 solver.cpp:244]     Train net output #0: loss = 0.0306733 (* 1 = 0.0306733 loss)
I0403 03:30:42.144379 19293 sgd_solver.cpp:106] Iteration 2090, lr = 0.0005
I0403 03:30:45.618927 19293 solver.cpp:228] Iteration 2095, loss = 0.00945895
I0403 03:30:45.624570 19293 solver.cpp:244]     Train net output #0: loss = 0.00945889 (* 1 = 0.00945889 loss)
I0403 03:30:45.805479 19293 sgd_solver.cpp:106] Iteration 2095, lr = 0.0005
I0403 03:30:48.680860 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2100.caffemodel
I0403 03:30:51.422595 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2100.solverstate
I0403 03:30:53.176038 19293 solver.cpp:337] Iteration 2100, Testing net (#0)
I0403 03:32:31.662889 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936706
I0403 03:32:31.668849 19293 solver.cpp:404]     Test net output #1: loss = 0.254167 (* 1 = 0.254167 loss)
I0403 03:32:32.193238 19293 solver.cpp:228] Iteration 2100, loss = 0.00232411
I0403 03:32:32.199437 19293 solver.cpp:244]     Train net output #0: loss = 0.00232404 (* 1 = 0.00232404 loss)
I0403 03:32:32.408933 19293 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0403 03:32:35.834789 19293 solver.cpp:228] Iteration 2105, loss = 0.00518158
I0403 03:32:35.841470 19293 solver.cpp:244]     Train net output #0: loss = 0.00518152 (* 1 = 0.00518152 loss)
I0403 03:32:36.071482 19293 sgd_solver.cpp:106] Iteration 2105, lr = 0.0005
I0403 03:32:39.546146 19293 solver.cpp:228] Iteration 2110, loss = 0.0102024
I0403 03:32:39.553635 19293 solver.cpp:244]     Train net output #0: loss = 0.0102023 (* 1 = 0.0102023 loss)
I0403 03:32:39.761286 19293 sgd_solver.cpp:106] Iteration 2110, lr = 0.0005
I0403 03:32:43.172726 19293 solver.cpp:228] Iteration 2115, loss = 0.00597303
I0403 03:32:43.178933 19293 solver.cpp:244]     Train net output #0: loss = 0.00597296 (* 1 = 0.00597296 loss)
I0403 03:32:43.381830 19293 sgd_solver.cpp:106] Iteration 2115, lr = 5e-05
I0403 03:32:46.832231 19293 solver.cpp:228] Iteration 2120, loss = 0.00242525
I0403 03:32:46.838747 19293 solver.cpp:244]     Train net output #0: loss = 0.00242519 (* 1 = 0.00242519 loss)
I0403 03:32:47.010289 19293 sgd_solver.cpp:106] Iteration 2120, lr = 5e-05
I0403 03:32:50.572516 19293 solver.cpp:228] Iteration 2125, loss = 0.0109494
I0403 03:32:50.580354 19293 solver.cpp:244]     Train net output #0: loss = 0.0109494 (* 1 = 0.0109494 loss)
I0403 03:32:50.741029 19293 sgd_solver.cpp:106] Iteration 2125, lr = 5e-05
I0403 03:32:54.233042 19293 solver.cpp:228] Iteration 2130, loss = 0.00367693
I0403 03:32:54.239367 19293 solver.cpp:244]     Train net output #0: loss = 0.00367687 (* 1 = 0.00367687 loss)
I0403 03:32:54.429008 19293 sgd_solver.cpp:106] Iteration 2130, lr = 5e-05
I0403 03:32:57.867542 19293 solver.cpp:228] Iteration 2135, loss = 0.0320073
I0403 03:32:57.873371 19293 solver.cpp:244]     Train net output #0: loss = 0.0320072 (* 1 = 0.0320072 loss)
I0403 03:32:58.074869 19293 sgd_solver.cpp:106] Iteration 2135, lr = 5e-05
I0403 03:33:01.506139 19293 solver.cpp:228] Iteration 2140, loss = 0.0124222
I0403 03:33:01.512485 19293 solver.cpp:244]     Train net output #0: loss = 0.0124221 (* 1 = 0.0124221 loss)
I0403 03:33:01.738348 19293 sgd_solver.cpp:106] Iteration 2140, lr = 5e-05
I0403 03:33:05.121971 19293 solver.cpp:228] Iteration 2145, loss = 0.0118864
I0403 03:33:05.128964 19293 solver.cpp:244]     Train net output #0: loss = 0.0118864 (* 1 = 0.0118864 loss)
I0403 03:33:05.338251 19293 sgd_solver.cpp:106] Iteration 2145, lr = 5e-05
I0403 03:33:08.803434 19293 solver.cpp:228] Iteration 2150, loss = 0.00555084
I0403 03:33:08.810437 19293 solver.cpp:244]     Train net output #0: loss = 0.00555077 (* 1 = 0.00555077 loss)
I0403 03:33:09.027685 19293 sgd_solver.cpp:106] Iteration 2150, lr = 5e-05
I0403 03:33:12.549681 19293 solver.cpp:228] Iteration 2155, loss = 0.00195824
I0403 03:33:12.556241 19293 solver.cpp:244]     Train net output #0: loss = 0.00195817 (* 1 = 0.00195817 loss)
I0403 03:33:12.737112 19293 sgd_solver.cpp:106] Iteration 2155, lr = 5e-05
I0403 03:33:16.268959 19293 solver.cpp:228] Iteration 2160, loss = 0.00653642
I0403 03:33:16.275148 19293 solver.cpp:244]     Train net output #0: loss = 0.00653635 (* 1 = 0.00653635 loss)
I0403 03:33:16.464247 19293 sgd_solver.cpp:106] Iteration 2160, lr = 5e-05
I0403 03:33:19.967840 19293 solver.cpp:228] Iteration 2165, loss = 0.0011486
I0403 03:33:19.973516 19293 solver.cpp:244]     Train net output #0: loss = 0.00114853 (* 1 = 0.00114853 loss)
I0403 03:33:20.156361 19293 sgd_solver.cpp:106] Iteration 2165, lr = 5e-05
I0403 03:33:23.667692 19293 solver.cpp:228] Iteration 2170, loss = 0.0192306
I0403 03:33:23.674250 19293 solver.cpp:244]     Train net output #0: loss = 0.0192305 (* 1 = 0.0192305 loss)
I0403 03:33:23.896365 19293 sgd_solver.cpp:106] Iteration 2170, lr = 5e-05
I0403 03:33:27.393359 19293 solver.cpp:228] Iteration 2175, loss = 0.00167793
I0403 03:33:27.399458 19293 solver.cpp:244]     Train net output #0: loss = 0.00167786 (* 1 = 0.00167786 loss)
I0403 03:33:27.578814 19293 sgd_solver.cpp:106] Iteration 2175, lr = 5e-05
I0403 03:33:31.028175 19293 solver.cpp:228] Iteration 2180, loss = 0.0031686
I0403 03:33:31.035027 19293 solver.cpp:244]     Train net output #0: loss = 0.00316853 (* 1 = 0.00316853 loss)
I0403 03:33:31.225378 19293 sgd_solver.cpp:106] Iteration 2180, lr = 5e-05
I0403 03:33:34.666203 19293 solver.cpp:228] Iteration 2185, loss = 0.00061432
I0403 03:33:34.673631 19293 solver.cpp:244]     Train net output #0: loss = 0.000614262 (* 1 = 0.000614262 loss)
I0403 03:33:34.894713 19293 sgd_solver.cpp:106] Iteration 2185, lr = 5e-05
I0403 03:33:38.335016 19293 solver.cpp:228] Iteration 2190, loss = 0.00275184
I0403 03:33:38.343510 19293 solver.cpp:244]     Train net output #0: loss = 0.00275178 (* 1 = 0.00275178 loss)
I0403 03:33:38.530503 19293 sgd_solver.cpp:106] Iteration 2190, lr = 5e-05
I0403 03:33:42.011009 19293 solver.cpp:228] Iteration 2195, loss = 0.00296764
I0403 03:33:42.017173 19293 solver.cpp:244]     Train net output #0: loss = 0.00296759 (* 1 = 0.00296759 loss)
I0403 03:33:42.204424 19293 sgd_solver.cpp:106] Iteration 2195, lr = 5e-05
I0403 03:33:45.648603 19293 solver.cpp:228] Iteration 2200, loss = 0.000398849
I0403 03:33:45.656990 19293 solver.cpp:244]     Train net output #0: loss = 0.000398791 (* 1 = 0.000398791 loss)
I0403 03:33:45.834811 19293 sgd_solver.cpp:106] Iteration 2200, lr = 5e-05
I0403 03:33:48.767969 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2205.caffemodel
I0403 03:33:51.412817 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2205.solverstate
I0403 03:33:53.673568 19293 solver.cpp:337] Iteration 2205, Testing net (#0)
I0403 03:35:32.289520 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936774
I0403 03:35:32.289865 19293 solver.cpp:404]     Test net output #1: loss = 0.255173 (* 1 = 0.255173 loss)
I0403 03:35:32.832819 19293 solver.cpp:228] Iteration 2205, loss = 0.0245834
I0403 03:35:32.832906 19293 solver.cpp:244]     Train net output #0: loss = 0.0245833 (* 1 = 0.0245833 loss)
I0403 03:35:32.999234 19293 sgd_solver.cpp:106] Iteration 2205, lr = 5e-05
I0403 03:35:36.551147 19293 solver.cpp:228] Iteration 2210, loss = 0.00283376
I0403 03:35:36.551245 19293 solver.cpp:244]     Train net output #0: loss = 0.0028337 (* 1 = 0.0028337 loss)
I0403 03:35:36.745606 19293 sgd_solver.cpp:106] Iteration 2210, lr = 5e-05
I0403 03:35:40.146215 19293 solver.cpp:228] Iteration 2215, loss = 0.0123413
I0403 03:35:40.146314 19293 solver.cpp:244]     Train net output #0: loss = 0.0123412 (* 1 = 0.0123412 loss)
I0403 03:35:40.350666 19293 sgd_solver.cpp:106] Iteration 2215, lr = 5e-05
I0403 03:35:43.797926 19293 solver.cpp:228] Iteration 2220, loss = 0.00831192
I0403 03:35:43.798022 19293 solver.cpp:244]     Train net output #0: loss = 0.00831186 (* 1 = 0.00831186 loss)
I0403 03:35:43.990190 19293 sgd_solver.cpp:106] Iteration 2220, lr = 5e-05
I0403 03:35:47.432494 19293 solver.cpp:228] Iteration 2225, loss = 0.0141496
I0403 03:35:47.432596 19293 solver.cpp:244]     Train net output #0: loss = 0.0141495 (* 1 = 0.0141495 loss)
I0403 03:35:47.648068 19293 sgd_solver.cpp:106] Iteration 2225, lr = 5e-05
I0403 03:35:51.094477 19293 solver.cpp:228] Iteration 2230, loss = 0.00842888
I0403 03:35:51.094569 19293 solver.cpp:244]     Train net output #0: loss = 0.00842882 (* 1 = 0.00842882 loss)
I0403 03:35:51.302022 19293 sgd_solver.cpp:106] Iteration 2230, lr = 5e-05
I0403 03:35:54.789438 19293 solver.cpp:228] Iteration 2235, loss = 0.00466559
I0403 03:35:54.789525 19293 solver.cpp:244]     Train net output #0: loss = 0.00466553 (* 1 = 0.00466553 loss)
I0403 03:35:54.964047 19293 sgd_solver.cpp:106] Iteration 2235, lr = 5e-05
I0403 03:35:58.470674 19293 solver.cpp:228] Iteration 2240, loss = 0.00408435
I0403 03:35:58.470775 19293 solver.cpp:244]     Train net output #0: loss = 0.0040843 (* 1 = 0.0040843 loss)
I0403 03:35:58.658306 19293 sgd_solver.cpp:106] Iteration 2240, lr = 5e-05
I0403 03:36:02.150753 19293 solver.cpp:228] Iteration 2245, loss = 0.00100204
I0403 03:36:02.150851 19293 solver.cpp:244]     Train net output #0: loss = 0.00100199 (* 1 = 0.00100199 loss)
I0403 03:36:02.369932 19293 sgd_solver.cpp:106] Iteration 2245, lr = 5e-05
I0403 03:36:05.854846 19293 solver.cpp:228] Iteration 2250, loss = 0.0077133
I0403 03:36:05.854930 19293 solver.cpp:244]     Train net output #0: loss = 0.00771325 (* 1 = 0.00771325 loss)
I0403 03:36:06.024763 19293 sgd_solver.cpp:106] Iteration 2250, lr = 5e-05
I0403 03:36:09.500622 19293 solver.cpp:228] Iteration 2255, loss = 0.00364419
I0403 03:36:09.500722 19293 solver.cpp:244]     Train net output #0: loss = 0.00364413 (* 1 = 0.00364413 loss)
I0403 03:36:09.741206 19293 sgd_solver.cpp:106] Iteration 2255, lr = 5e-05
I0403 03:36:13.208547 19293 solver.cpp:228] Iteration 2260, loss = 0.0295042
I0403 03:36:13.208645 19293 solver.cpp:244]     Train net output #0: loss = 0.0295041 (* 1 = 0.0295041 loss)
I0403 03:36:13.407050 19293 sgd_solver.cpp:106] Iteration 2260, lr = 5e-05
I0403 03:36:16.942273 19293 solver.cpp:228] Iteration 2265, loss = 0.00450133
I0403 03:36:16.942374 19293 solver.cpp:244]     Train net output #0: loss = 0.00450128 (* 1 = 0.00450128 loss)
I0403 03:36:17.130261 19293 sgd_solver.cpp:106] Iteration 2265, lr = 5e-05
I0403 03:36:20.569360 19293 solver.cpp:228] Iteration 2270, loss = 0.00667402
I0403 03:36:20.569460 19293 solver.cpp:244]     Train net output #0: loss = 0.00667397 (* 1 = 0.00667397 loss)
I0403 03:36:20.765004 19293 sgd_solver.cpp:106] Iteration 2270, lr = 5e-05
I0403 03:36:24.320583 19293 solver.cpp:228] Iteration 2275, loss = 0.0074822
I0403 03:36:24.320673 19293 solver.cpp:244]     Train net output #0: loss = 0.00748215 (* 1 = 0.00748215 loss)
I0403 03:36:24.488250 19293 sgd_solver.cpp:106] Iteration 2275, lr = 5e-05
I0403 03:36:28.047938 19293 solver.cpp:228] Iteration 2280, loss = 0.013806
I0403 03:36:28.048027 19293 solver.cpp:244]     Train net output #0: loss = 0.0138059 (* 1 = 0.0138059 loss)
I0403 03:36:28.230926 19293 sgd_solver.cpp:106] Iteration 2280, lr = 5e-05
I0403 03:36:31.669332 19293 solver.cpp:228] Iteration 2285, loss = 0.00721677
I0403 03:36:31.669435 19293 solver.cpp:244]     Train net output #0: loss = 0.00721672 (* 1 = 0.00721672 loss)
I0403 03:36:31.877199 19293 sgd_solver.cpp:106] Iteration 2285, lr = 5e-05
I0403 03:36:35.310588 19293 solver.cpp:228] Iteration 2290, loss = 0.010842
I0403 03:36:35.310950 19293 solver.cpp:244]     Train net output #0: loss = 0.010842 (* 1 = 0.010842 loss)
I0403 03:36:35.505067 19293 sgd_solver.cpp:106] Iteration 2290, lr = 5e-05
I0403 03:36:38.932324 19293 solver.cpp:228] Iteration 2295, loss = 0.00252685
I0403 03:36:38.932422 19293 solver.cpp:244]     Train net output #0: loss = 0.0025268 (* 1 = 0.0025268 loss)
I0403 03:36:39.140832 19293 sgd_solver.cpp:106] Iteration 2295, lr = 5e-05
I0403 03:36:42.600338 19293 solver.cpp:228] Iteration 2300, loss = 0.00494586
I0403 03:36:42.600437 19293 solver.cpp:244]     Train net output #0: loss = 0.00494581 (* 1 = 0.00494581 loss)
I0403 03:36:42.810248 19293 sgd_solver.cpp:106] Iteration 2300, lr = 5e-05
I0403 03:36:46.315316 19293 solver.cpp:228] Iteration 2305, loss = 0.00486254
I0403 03:36:46.315418 19293 solver.cpp:244]     Train net output #0: loss = 0.00486249 (* 1 = 0.00486249 loss)
I0403 03:36:46.511085 19293 sgd_solver.cpp:106] Iteration 2305, lr = 5e-05
I0403 03:36:49.430658 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2310.caffemodel
I0403 03:36:52.195370 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2310.solverstate
I0403 03:36:54.086601 19293 solver.cpp:337] Iteration 2310, Testing net (#0)
I0403 03:38:32.578663 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936523
I0403 03:38:32.578989 19293 solver.cpp:404]     Test net output #1: loss = 0.255933 (* 1 = 0.255933 loss)
I0403 03:38:33.097506 19293 solver.cpp:228] Iteration 2310, loss = 0.00509794
I0403 03:38:33.097590 19293 solver.cpp:244]     Train net output #0: loss = 0.00509788 (* 1 = 0.00509788 loss)
I0403 03:38:33.279463 19293 sgd_solver.cpp:106] Iteration 2310, lr = 5e-05
I0403 03:38:36.737584 19293 solver.cpp:228] Iteration 2315, loss = 0.0120874
I0403 03:38:36.737682 19293 solver.cpp:244]     Train net output #0: loss = 0.0120873 (* 1 = 0.0120873 loss)
I0403 03:38:36.924541 19293 sgd_solver.cpp:106] Iteration 2315, lr = 5e-05
I0403 03:38:40.374256 19293 solver.cpp:228] Iteration 2320, loss = 0.0514119
I0403 03:38:40.374356 19293 solver.cpp:244]     Train net output #0: loss = 0.0514119 (* 1 = 0.0514119 loss)
I0403 03:38:40.577471 19293 sgd_solver.cpp:106] Iteration 2320, lr = 5e-05
I0403 03:38:44.091356 19293 solver.cpp:228] Iteration 2325, loss = 0.00451693
I0403 03:38:44.091454 19293 solver.cpp:244]     Train net output #0: loss = 0.00451688 (* 1 = 0.00451688 loss)
I0403 03:38:44.280959 19293 sgd_solver.cpp:106] Iteration 2325, lr = 5e-05
I0403 03:38:47.753700 19293 solver.cpp:228] Iteration 2330, loss = 0.00542809
I0403 03:38:47.753798 19293 solver.cpp:244]     Train net output #0: loss = 0.00542804 (* 1 = 0.00542804 loss)
I0403 03:38:47.946324 19293 sgd_solver.cpp:106] Iteration 2330, lr = 5e-05
I0403 03:38:51.390651 19293 solver.cpp:228] Iteration 2335, loss = 0.00197463
I0403 03:38:51.390754 19293 solver.cpp:244]     Train net output #0: loss = 0.00197458 (* 1 = 0.00197458 loss)
I0403 03:38:51.580361 19293 sgd_solver.cpp:106] Iteration 2335, lr = 5e-05
I0403 03:38:55.001868 19293 solver.cpp:228] Iteration 2340, loss = 0.0285789
I0403 03:38:55.001968 19293 solver.cpp:244]     Train net output #0: loss = 0.0285789 (* 1 = 0.0285789 loss)
I0403 03:38:55.196831 19293 sgd_solver.cpp:106] Iteration 2340, lr = 5e-05
I0403 03:38:58.657295 19293 solver.cpp:228] Iteration 2345, loss = 0.00386186
I0403 03:38:58.657392 19293 solver.cpp:244]     Train net output #0: loss = 0.00386181 (* 1 = 0.00386181 loss)
I0403 03:38:58.861102 19293 sgd_solver.cpp:106] Iteration 2345, lr = 5e-05
I0403 03:39:02.329813 19293 solver.cpp:228] Iteration 2350, loss = 0.0264674
I0403 03:39:02.329900 19293 solver.cpp:244]     Train net output #0: loss = 0.0264674 (* 1 = 0.0264674 loss)
I0403 03:39:02.491396 19293 sgd_solver.cpp:106] Iteration 2350, lr = 5e-05
I0403 03:39:06.019014 19293 solver.cpp:228] Iteration 2355, loss = 0.00897175
I0403 03:39:06.019376 19293 solver.cpp:244]     Train net output #0: loss = 0.0089717 (* 1 = 0.0089717 loss)
I0403 03:39:06.206231 19293 sgd_solver.cpp:106] Iteration 2355, lr = 5e-05
I0403 03:39:09.806020 19293 solver.cpp:228] Iteration 2360, loss = 0.00531453
I0403 03:39:09.806107 19293 solver.cpp:244]     Train net output #0: loss = 0.00531448 (* 1 = 0.00531448 loss)
I0403 03:39:09.927263 19293 sgd_solver.cpp:106] Iteration 2360, lr = 5e-05
I0403 03:39:13.527721 19293 solver.cpp:228] Iteration 2365, loss = 0.00695976
I0403 03:39:13.527807 19293 solver.cpp:244]     Train net output #0: loss = 0.00695971 (* 1 = 0.00695971 loss)
I0403 03:39:13.696355 19293 sgd_solver.cpp:106] Iteration 2365, lr = 5e-05
I0403 03:39:17.171845 19293 solver.cpp:228] Iteration 2370, loss = 0.00166758
I0403 03:39:17.171948 19293 solver.cpp:244]     Train net output #0: loss = 0.00166753 (* 1 = 0.00166753 loss)
I0403 03:39:17.376320 19293 sgd_solver.cpp:106] Iteration 2370, lr = 5e-05
I0403 03:39:20.804477 19293 solver.cpp:228] Iteration 2375, loss = 0.00863647
I0403 03:39:20.804576 19293 solver.cpp:244]     Train net output #0: loss = 0.00863642 (* 1 = 0.00863642 loss)
I0403 03:39:20.989013 19293 sgd_solver.cpp:106] Iteration 2375, lr = 5e-05
I0403 03:39:24.439620 19293 solver.cpp:228] Iteration 2380, loss = 0.00488934
I0403 03:39:24.439721 19293 solver.cpp:244]     Train net output #0: loss = 0.00488929 (* 1 = 0.00488929 loss)
I0403 03:39:24.638489 19293 sgd_solver.cpp:106] Iteration 2380, lr = 5e-05
I0403 03:39:28.100697 19293 solver.cpp:228] Iteration 2385, loss = 0.0245943
I0403 03:39:28.100796 19293 solver.cpp:244]     Train net output #0: loss = 0.0245943 (* 1 = 0.0245943 loss)
I0403 03:39:28.300189 19293 sgd_solver.cpp:106] Iteration 2385, lr = 5e-05
I0403 03:39:31.753378 19293 solver.cpp:228] Iteration 2390, loss = 0.00395475
I0403 03:39:31.753479 19293 solver.cpp:244]     Train net output #0: loss = 0.0039547 (* 1 = 0.0039547 loss)
I0403 03:39:31.947763 19293 sgd_solver.cpp:106] Iteration 2390, lr = 5e-05
I0403 03:39:35.374830 19293 solver.cpp:228] Iteration 2395, loss = 0.00312096
I0403 03:39:35.374932 19293 solver.cpp:244]     Train net output #0: loss = 0.0031209 (* 1 = 0.0031209 loss)
I0403 03:39:35.576673 19293 sgd_solver.cpp:106] Iteration 2395, lr = 5e-05
I0403 03:39:39.038795 19293 solver.cpp:228] Iteration 2400, loss = 0.00125288
I0403 03:39:39.039101 19293 solver.cpp:244]     Train net output #0: loss = 0.00125283 (* 1 = 0.00125283 loss)
I0403 03:39:39.253968 19293 sgd_solver.cpp:106] Iteration 2400, lr = 5e-05
I0403 03:39:42.696491 19293 solver.cpp:228] Iteration 2405, loss = 0.00148634
I0403 03:39:42.696588 19293 solver.cpp:244]     Train net output #0: loss = 0.00148629 (* 1 = 0.00148629 loss)
I0403 03:39:42.885442 19293 sgd_solver.cpp:106] Iteration 2405, lr = 5e-05
I0403 03:39:46.332252 19293 solver.cpp:228] Iteration 2410, loss = 0.00161466
I0403 03:39:46.333206 19293 solver.cpp:244]     Train net output #0: loss = 0.00161461 (* 1 = 0.00161461 loss)
I0403 03:39:46.524991 19293 sgd_solver.cpp:106] Iteration 2410, lr = 5e-05
I0403 03:39:49.471637 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2415.caffemodel
I0403 03:39:54.844276 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2415.solverstate
I0403 03:39:56.693362 19293 solver.cpp:337] Iteration 2415, Testing net (#0)
I0403 03:41:35.206032 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936591
I0403 03:41:35.206388 19293 solver.cpp:404]     Test net output #1: loss = 0.254571 (* 1 = 0.254571 loss)
I0403 03:41:35.742383 19293 solver.cpp:228] Iteration 2415, loss = 0.00516105
I0403 03:41:35.742475 19293 solver.cpp:244]     Train net output #0: loss = 0.005161 (* 1 = 0.005161 loss)
I0403 03:41:35.899832 19293 sgd_solver.cpp:106] Iteration 2415, lr = 5e-05
I0403 03:41:39.404273 19293 solver.cpp:228] Iteration 2420, loss = 0.0127524
I0403 03:41:39.404376 19293 solver.cpp:244]     Train net output #0: loss = 0.0127523 (* 1 = 0.0127523 loss)
I0403 03:41:39.602643 19293 sgd_solver.cpp:106] Iteration 2420, lr = 5e-05
I0403 03:41:43.144160 19293 solver.cpp:228] Iteration 2425, loss = 0.00500778
I0403 03:41:43.144249 19293 solver.cpp:244]     Train net output #0: loss = 0.00500773 (* 1 = 0.00500773 loss)
I0403 03:41:43.334417 19293 sgd_solver.cpp:106] Iteration 2425, lr = 5e-05
I0403 03:41:46.800887 19293 solver.cpp:228] Iteration 2430, loss = 0.00134538
I0403 03:41:46.800987 19293 solver.cpp:244]     Train net output #0: loss = 0.00134533 (* 1 = 0.00134533 loss)
I0403 03:41:46.991379 19293 sgd_solver.cpp:106] Iteration 2430, lr = 5e-05
I0403 03:41:50.452941 19293 solver.cpp:228] Iteration 2435, loss = 0.017157
I0403 03:41:50.453028 19293 solver.cpp:244]     Train net output #0: loss = 0.0171569 (* 1 = 0.0171569 loss)
I0403 03:41:50.630411 19293 sgd_solver.cpp:106] Iteration 2435, lr = 5e-05
I0403 03:41:54.137994 19293 solver.cpp:228] Iteration 2440, loss = 0.001251
I0403 03:41:54.138092 19293 solver.cpp:244]     Train net output #0: loss = 0.00125095 (* 1 = 0.00125095 loss)
I0403 03:41:54.344741 19293 sgd_solver.cpp:106] Iteration 2440, lr = 5e-05
I0403 03:41:57.834771 19293 solver.cpp:228] Iteration 2445, loss = 0.000903696
I0403 03:41:57.834873 19293 solver.cpp:244]     Train net output #0: loss = 0.000903644 (* 1 = 0.000903644 loss)
I0403 03:41:58.038231 19293 sgd_solver.cpp:106] Iteration 2445, lr = 5e-05
I0403 03:42:01.522027 19293 solver.cpp:228] Iteration 2450, loss = 0.0011645
I0403 03:42:01.522130 19293 solver.cpp:244]     Train net output #0: loss = 0.00116445 (* 1 = 0.00116445 loss)
I0403 03:42:01.718935 19293 sgd_solver.cpp:106] Iteration 2450, lr = 5e-05
I0403 03:42:05.200829 19293 solver.cpp:228] Iteration 2455, loss = 0.00606557
I0403 03:42:05.200927 19293 solver.cpp:244]     Train net output #0: loss = 0.00606551 (* 1 = 0.00606551 loss)
I0403 03:42:05.387951 19293 sgd_solver.cpp:106] Iteration 2455, lr = 5e-05
I0403 03:42:08.854457 19293 solver.cpp:228] Iteration 2460, loss = 0.00516783
I0403 03:42:08.854553 19293 solver.cpp:244]     Train net output #0: loss = 0.00516778 (* 1 = 0.00516778 loss)
I0403 03:42:09.052852 19293 sgd_solver.cpp:106] Iteration 2460, lr = 5e-05
I0403 03:42:12.501910 19293 solver.cpp:228] Iteration 2465, loss = 0.00545564
I0403 03:42:12.502005 19293 solver.cpp:244]     Train net output #0: loss = 0.00545558 (* 1 = 0.00545558 loss)
I0403 03:42:12.690558 19293 sgd_solver.cpp:106] Iteration 2465, lr = 5e-05
I0403 03:42:16.141638 19293 solver.cpp:228] Iteration 2470, loss = 0.00174618
I0403 03:42:16.141736 19293 solver.cpp:244]     Train net output #0: loss = 0.00174613 (* 1 = 0.00174613 loss)
I0403 03:42:16.338619 19293 sgd_solver.cpp:106] Iteration 2470, lr = 5e-05
I0403 03:42:19.770452 19293 solver.cpp:228] Iteration 2475, loss = 0.00840011
I0403 03:42:19.771456 19293 solver.cpp:244]     Train net output #0: loss = 0.00840006 (* 1 = 0.00840006 loss)
I0403 03:42:19.969485 19293 sgd_solver.cpp:106] Iteration 2475, lr = 5e-05
I0403 03:42:23.389458 19293 solver.cpp:228] Iteration 2480, loss = 0.0048742
I0403 03:42:23.389559 19293 solver.cpp:244]     Train net output #0: loss = 0.00487414 (* 1 = 0.00487414 loss)
I0403 03:42:23.580570 19293 sgd_solver.cpp:106] Iteration 2480, lr = 5e-05
I0403 03:42:27.012377 19293 solver.cpp:228] Iteration 2485, loss = 0.00357875
I0403 03:42:27.012480 19293 solver.cpp:244]     Train net output #0: loss = 0.00357869 (* 1 = 0.00357869 loss)
I0403 03:42:27.281306 19293 sgd_solver.cpp:106] Iteration 2485, lr = 5e-05
I0403 03:42:30.768209 19293 solver.cpp:228] Iteration 2490, loss = 0.00643804
I0403 03:42:30.768311 19293 solver.cpp:244]     Train net output #0: loss = 0.00643798 (* 1 = 0.00643798 loss)
I0403 03:42:30.971336 19293 sgd_solver.cpp:106] Iteration 2490, lr = 5e-05
I0403 03:42:34.542490 19293 solver.cpp:228] Iteration 2495, loss = 0.00407411
I0403 03:42:34.542598 19293 solver.cpp:244]     Train net output #0: loss = 0.00407405 (* 1 = 0.00407405 loss)
I0403 03:42:34.752265 19293 sgd_solver.cpp:106] Iteration 2495, lr = 5e-05
I0403 03:42:38.188546 19293 solver.cpp:228] Iteration 2500, loss = 0.00802075
I0403 03:42:38.188894 19293 solver.cpp:244]     Train net output #0: loss = 0.00802069 (* 1 = 0.00802069 loss)
I0403 03:42:38.360544 19293 sgd_solver.cpp:106] Iteration 2500, lr = 5e-05
I0403 03:42:41.848662 19293 solver.cpp:228] Iteration 2505, loss = 0.00566287
I0403 03:42:41.848773 19293 solver.cpp:244]     Train net output #0: loss = 0.00566281 (* 1 = 0.00566281 loss)
I0403 03:42:42.078553 19293 sgd_solver.cpp:106] Iteration 2505, lr = 5e-05
I0403 03:42:45.513514 19293 solver.cpp:228] Iteration 2510, loss = 0.00280173
I0403 03:42:45.513617 19293 solver.cpp:244]     Train net output #0: loss = 0.00280167 (* 1 = 0.00280167 loss)
I0403 03:42:45.706073 19293 sgd_solver.cpp:106] Iteration 2510, lr = 5e-05
I0403 03:42:49.224635 19293 solver.cpp:228] Iteration 2515, loss = 0.00810241
I0403 03:42:49.224733 19293 solver.cpp:244]     Train net output #0: loss = 0.00810235 (* 1 = 0.00810235 loss)
I0403 03:42:49.427040 19293 sgd_solver.cpp:106] Iteration 2515, lr = 5e-05
I0403 03:42:52.322799 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2520.caffemodel
I0403 03:42:55.072937 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2520.solverstate
I0403 03:42:56.999876 19293 solver.cpp:337] Iteration 2520, Testing net (#0)
I0403 03:44:35.482874 19293 solver.cpp:404]     Test net output #0: accuracy = 0.93666
I0403 03:44:35.483199 19293 solver.cpp:404]     Test net output #1: loss = 0.25589 (* 1 = 0.25589 loss)
I0403 03:44:36.002707 19293 solver.cpp:228] Iteration 2520, loss = 0.00196777
I0403 03:44:36.002804 19293 solver.cpp:244]     Train net output #0: loss = 0.0019677 (* 1 = 0.0019677 loss)
I0403 03:44:36.198662 19293 sgd_solver.cpp:106] Iteration 2520, lr = 5e-05
I0403 03:44:39.660995 19293 solver.cpp:228] Iteration 2525, loss = 0.00278495
I0403 03:44:39.661082 19293 solver.cpp:244]     Train net output #0: loss = 0.00278489 (* 1 = 0.00278489 loss)
I0403 03:44:39.843888 19293 sgd_solver.cpp:106] Iteration 2525, lr = 5e-05
I0403 03:44:43.336237 19293 solver.cpp:228] Iteration 2530, loss = 0.0164581
I0403 03:44:43.336338 19293 solver.cpp:244]     Train net output #0: loss = 0.016458 (* 1 = 0.016458 loss)
I0403 03:44:43.544878 19293 sgd_solver.cpp:106] Iteration 2530, lr = 5e-05
I0403 03:44:47.038349 19293 solver.cpp:228] Iteration 2535, loss = 0.000641521
I0403 03:44:47.038451 19293 solver.cpp:244]     Train net output #0: loss = 0.000641461 (* 1 = 0.000641461 loss)
I0403 03:44:47.200780 19293 sgd_solver.cpp:106] Iteration 2535, lr = 5e-05
I0403 03:44:50.725123 19293 solver.cpp:228] Iteration 2540, loss = 0.00630554
I0403 03:44:50.725955 19293 solver.cpp:244]     Train net output #0: loss = 0.00630548 (* 1 = 0.00630548 loss)
I0403 03:44:50.904091 19293 sgd_solver.cpp:106] Iteration 2540, lr = 5e-05
I0403 03:44:54.359951 19293 solver.cpp:228] Iteration 2545, loss = 0.000618031
I0403 03:44:54.360049 19293 solver.cpp:244]     Train net output #0: loss = 0.000617974 (* 1 = 0.000617974 loss)
I0403 03:44:54.557665 19293 sgd_solver.cpp:106] Iteration 2545, lr = 5e-05
I0403 03:44:58.055239 19293 solver.cpp:228] Iteration 2550, loss = 0.0119845
I0403 03:44:58.055326 19293 solver.cpp:244]     Train net output #0: loss = 0.0119845 (* 1 = 0.0119845 loss)
I0403 03:44:58.245350 19293 sgd_solver.cpp:106] Iteration 2550, lr = 5e-05
I0403 03:45:01.743870 19293 solver.cpp:228] Iteration 2555, loss = 0.00289787
I0403 03:45:01.743970 19293 solver.cpp:244]     Train net output #0: loss = 0.00289781 (* 1 = 0.00289781 loss)
I0403 03:45:01.947104 19293 sgd_solver.cpp:106] Iteration 2555, lr = 5e-05
I0403 03:45:05.437984 19293 solver.cpp:228] Iteration 2560, loss = 0.00396372
I0403 03:45:05.438072 19293 solver.cpp:244]     Train net output #0: loss = 0.00396366 (* 1 = 0.00396366 loss)
I0403 03:45:05.625334 19293 sgd_solver.cpp:106] Iteration 2560, lr = 5e-05
I0403 03:45:09.163447 19293 solver.cpp:228] Iteration 2565, loss = 0.00658699
I0403 03:45:09.163552 19293 solver.cpp:244]     Train net output #0: loss = 0.00658693 (* 1 = 0.00658693 loss)
I0403 03:45:09.371045 19293 sgd_solver.cpp:106] Iteration 2565, lr = 5e-05
I0403 03:45:12.841925 19293 solver.cpp:228] Iteration 2570, loss = 0.00127426
I0403 03:45:12.842026 19293 solver.cpp:244]     Train net output #0: loss = 0.0012742 (* 1 = 0.0012742 loss)
I0403 03:45:13.027940 19293 sgd_solver.cpp:106] Iteration 2570, lr = 5e-05
I0403 03:45:16.445749 19293 solver.cpp:228] Iteration 2575, loss = 0.0017861
I0403 03:45:16.445849 19293 solver.cpp:244]     Train net output #0: loss = 0.00178604 (* 1 = 0.00178604 loss)
I0403 03:45:16.681731 19293 sgd_solver.cpp:106] Iteration 2575, lr = 5e-05
I0403 03:45:20.076205 19293 solver.cpp:228] Iteration 2580, loss = 0.00517773
I0403 03:45:20.076297 19293 solver.cpp:244]     Train net output #0: loss = 0.00517768 (* 1 = 0.00517768 loss)
I0403 03:45:20.282006 19293 sgd_solver.cpp:106] Iteration 2580, lr = 5e-05
I0403 03:45:23.882465 19293 solver.cpp:228] Iteration 2585, loss = 0.00566732
I0403 03:45:23.882566 19293 solver.cpp:244]     Train net output #0: loss = 0.00566726 (* 1 = 0.00566726 loss)
I0403 03:45:24.071741 19293 sgd_solver.cpp:106] Iteration 2585, lr = 5e-05
I0403 03:45:27.537827 19293 solver.cpp:228] Iteration 2590, loss = 0.00485412
I0403 03:45:27.537925 19293 solver.cpp:244]     Train net output #0: loss = 0.00485406 (* 1 = 0.00485406 loss)
I0403 03:45:27.722594 19293 sgd_solver.cpp:106] Iteration 2590, lr = 5e-05
I0403 03:45:31.210613 19293 solver.cpp:228] Iteration 2595, loss = 0.00221652
I0403 03:45:31.210712 19293 solver.cpp:244]     Train net output #0: loss = 0.00221646 (* 1 = 0.00221646 loss)
I0403 03:45:31.426831 19293 sgd_solver.cpp:106] Iteration 2595, lr = 5e-05
I0403 03:45:34.911785 19293 solver.cpp:228] Iteration 2600, loss = 0.0167696
I0403 03:45:34.911887 19293 solver.cpp:244]     Train net output #0: loss = 0.0167696 (* 1 = 0.0167696 loss)
I0403 03:45:35.123255 19293 sgd_solver.cpp:106] Iteration 2600, lr = 5e-05
I0403 03:45:38.738384 19293 solver.cpp:228] Iteration 2605, loss = 0.00528135
I0403 03:45:38.738648 19293 solver.cpp:244]     Train net output #0: loss = 0.0052813 (* 1 = 0.0052813 loss)
I0403 03:45:38.918942 19293 sgd_solver.cpp:106] Iteration 2605, lr = 5e-05
I0403 03:45:42.403430 19293 solver.cpp:228] Iteration 2610, loss = 0.0113114
I0403 03:45:42.403532 19293 solver.cpp:244]     Train net output #0: loss = 0.0113114 (* 1 = 0.0113114 loss)
I0403 03:45:42.598618 19293 sgd_solver.cpp:106] Iteration 2610, lr = 5e-05
I0403 03:45:46.078661 19293 solver.cpp:228] Iteration 2615, loss = 0.00100218
I0403 03:45:46.078753 19293 solver.cpp:244]     Train net output #0: loss = 0.00100213 (* 1 = 0.00100213 loss)
I0403 03:45:46.260064 19293 sgd_solver.cpp:106] Iteration 2615, lr = 5e-05
I0403 03:45:49.777600 19293 solver.cpp:228] Iteration 2620, loss = 0.0042195
I0403 03:45:49.777699 19293 solver.cpp:244]     Train net output #0: loss = 0.00421945 (* 1 = 0.00421945 loss)
I0403 03:45:49.991178 19293 sgd_solver.cpp:106] Iteration 2620, lr = 5e-05
I0403 03:45:52.901082 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2625.caffemodel
I0403 03:45:55.651221 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2625.solverstate
I0403 03:45:57.570065 19293 solver.cpp:337] Iteration 2625, Testing net (#0)
I0403 03:47:36.049794 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936774
I0403 03:47:36.050145 19293 solver.cpp:404]     Test net output #1: loss = 0.255861 (* 1 = 0.255861 loss)
I0403 03:47:36.590416 19293 solver.cpp:228] Iteration 2625, loss = 0.0049694
I0403 03:47:36.590497 19293 solver.cpp:244]     Train net output #0: loss = 0.00496934 (* 1 = 0.00496934 loss)
I0403 03:47:36.761188 19293 sgd_solver.cpp:106] Iteration 2625, lr = 5e-05
I0403 03:47:40.248540 19293 solver.cpp:228] Iteration 2630, loss = 0.00827502
I0403 03:47:40.248638 19293 solver.cpp:244]     Train net output #0: loss = 0.00827496 (* 1 = 0.00827496 loss)
I0403 03:47:40.435510 19293 sgd_solver.cpp:106] Iteration 2630, lr = 5e-05
I0403 03:47:43.861277 19293 solver.cpp:228] Iteration 2635, loss = 0.0104362
I0403 03:47:43.861367 19293 solver.cpp:244]     Train net output #0: loss = 0.0104362 (* 1 = 0.0104362 loss)
I0403 03:47:44.054323 19293 sgd_solver.cpp:106] Iteration 2635, lr = 5e-05
I0403 03:47:47.575474 19293 solver.cpp:228] Iteration 2640, loss = 0.00101233
I0403 03:47:47.575573 19293 solver.cpp:244]     Train net output #0: loss = 0.00101227 (* 1 = 0.00101227 loss)
I0403 03:47:47.765266 19293 sgd_solver.cpp:106] Iteration 2640, lr = 5e-05
I0403 03:47:51.181998 19293 solver.cpp:228] Iteration 2645, loss = 0.00200043
I0403 03:47:51.182096 19293 solver.cpp:244]     Train net output #0: loss = 0.00200037 (* 1 = 0.00200037 loss)
I0403 03:47:51.383749 19293 sgd_solver.cpp:106] Iteration 2645, lr = 5e-05
I0403 03:47:54.830796 19293 solver.cpp:228] Iteration 2650, loss = 0.0146213
I0403 03:47:54.830898 19293 solver.cpp:244]     Train net output #0: loss = 0.0146212 (* 1 = 0.0146212 loss)
I0403 03:47:55.058454 19293 sgd_solver.cpp:106] Iteration 2650, lr = 5e-05
I0403 03:47:58.513810 19293 solver.cpp:228] Iteration 2655, loss = 0.00259607
I0403 03:47:58.513906 19293 solver.cpp:244]     Train net output #0: loss = 0.00259601 (* 1 = 0.00259601 loss)
I0403 03:47:58.704783 19293 sgd_solver.cpp:106] Iteration 2655, lr = 5e-05
I0403 03:48:02.171089 19293 solver.cpp:228] Iteration 2660, loss = 0.0278127
I0403 03:48:02.171192 19293 solver.cpp:244]     Train net output #0: loss = 0.0278126 (* 1 = 0.0278126 loss)
I0403 03:48:02.381252 19293 sgd_solver.cpp:106] Iteration 2660, lr = 5e-05
I0403 03:48:05.921716 19293 solver.cpp:228] Iteration 2665, loss = 0.000731137
I0403 03:48:05.921818 19293 solver.cpp:244]     Train net output #0: loss = 0.000731076 (* 1 = 0.000731076 loss)
I0403 03:48:06.116086 19293 sgd_solver.cpp:106] Iteration 2665, lr = 5e-05
I0403 03:48:09.752310 19293 solver.cpp:228] Iteration 2670, loss = 0.00152841
I0403 03:48:09.752409 19293 solver.cpp:244]     Train net output #0: loss = 0.00152836 (* 1 = 0.00152836 loss)
I0403 03:48:09.946099 19293 sgd_solver.cpp:106] Iteration 2670, lr = 5e-05
I0403 03:48:13.360899 19293 solver.cpp:228] Iteration 2675, loss = 0.00369247
I0403 03:48:13.360999 19293 solver.cpp:244]     Train net output #0: loss = 0.00369241 (* 1 = 0.00369241 loss)
I0403 03:48:13.556077 19293 sgd_solver.cpp:106] Iteration 2675, lr = 5e-05
I0403 03:48:16.988785 19293 solver.cpp:228] Iteration 2680, loss = 0.0111132
I0403 03:48:16.988895 19293 solver.cpp:244]     Train net output #0: loss = 0.0111132 (* 1 = 0.0111132 loss)
I0403 03:48:17.183300 19293 sgd_solver.cpp:106] Iteration 2680, lr = 5e-05
I0403 03:48:20.642206 19293 solver.cpp:228] Iteration 2685, loss = 0.0122734
I0403 03:48:20.642309 19293 solver.cpp:244]     Train net output #0: loss = 0.0122734 (* 1 = 0.0122734 loss)
I0403 03:48:20.846006 19293 sgd_solver.cpp:106] Iteration 2685, lr = 5e-05
I0403 03:48:24.273241 19293 solver.cpp:228] Iteration 2690, loss = 0.00229805
I0403 03:48:24.273341 19293 solver.cpp:244]     Train net output #0: loss = 0.002298 (* 1 = 0.002298 loss)
I0403 03:48:24.460158 19293 sgd_solver.cpp:106] Iteration 2690, lr = 5e-05
I0403 03:48:27.916759 19293 solver.cpp:228] Iteration 2695, loss = 0.00284898
I0403 03:48:27.916863 19293 solver.cpp:244]     Train net output #0: loss = 0.00284892 (* 1 = 0.00284892 loss)
I0403 03:48:28.151777 19293 sgd_solver.cpp:106] Iteration 2695, lr = 5e-05
I0403 03:48:31.701082 19293 solver.cpp:228] Iteration 2700, loss = 0.00452481
I0403 03:48:31.701182 19293 solver.cpp:244]     Train net output #0: loss = 0.00452475 (* 1 = 0.00452475 loss)
I0403 03:48:31.922768 19293 sgd_solver.cpp:106] Iteration 2700, lr = 5e-05
I0403 03:48:35.462812 19293 solver.cpp:228] Iteration 2705, loss = 0.00935689
I0403 03:48:35.462913 19293 solver.cpp:244]     Train net output #0: loss = 0.00935683 (* 1 = 0.00935683 loss)
I0403 03:48:35.653774 19293 sgd_solver.cpp:106] Iteration 2705, lr = 5e-05
I0403 03:48:39.102390 19293 solver.cpp:228] Iteration 2710, loss = 0.00347762
I0403 03:48:39.102764 19293 solver.cpp:244]     Train net output #0: loss = 0.00347756 (* 1 = 0.00347756 loss)
I0403 03:48:39.296039 19293 sgd_solver.cpp:106] Iteration 2710, lr = 5e-05
I0403 03:48:42.781774 19293 solver.cpp:228] Iteration 2715, loss = 0.00454712
I0403 03:48:42.781872 19293 solver.cpp:244]     Train net output #0: loss = 0.00454707 (* 1 = 0.00454707 loss)
I0403 03:48:42.969542 19293 sgd_solver.cpp:106] Iteration 2715, lr = 5e-05
I0403 03:48:46.464937 19293 solver.cpp:228] Iteration 2720, loss = 0.00469802
I0403 03:48:46.465028 19293 solver.cpp:244]     Train net output #0: loss = 0.00469797 (* 1 = 0.00469797 loss)
I0403 03:48:46.645613 19293 sgd_solver.cpp:106] Iteration 2720, lr = 5e-05
I0403 03:48:50.081948 19293 solver.cpp:228] Iteration 2725, loss = 0.00344745
I0403 03:48:50.082048 19293 solver.cpp:244]     Train net output #0: loss = 0.00344739 (* 1 = 0.00344739 loss)
I0403 03:48:50.305551 19293 sgd_solver.cpp:106] Iteration 2725, lr = 5e-05
I0403 03:48:53.221065 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2730.caffemodel
I0403 03:48:55.961988 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2730.solverstate
I0403 03:48:57.872701 19293 solver.cpp:337] Iteration 2730, Testing net (#0)
I0403 03:50:36.369261 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936637
I0403 03:50:36.369596 19293 solver.cpp:404]     Test net output #1: loss = 0.257145 (* 1 = 0.257145 loss)
I0403 03:50:36.906786 19293 solver.cpp:228] Iteration 2730, loss = 0.0274582
I0403 03:50:36.906872 19293 solver.cpp:244]     Train net output #0: loss = 0.0274581 (* 1 = 0.0274581 loss)
I0403 03:50:37.060147 19293 sgd_solver.cpp:106] Iteration 2730, lr = 5e-05
I0403 03:50:40.628415 19293 solver.cpp:228] Iteration 2735, loss = 0.00968352
I0403 03:50:40.628516 19293 solver.cpp:244]     Train net output #0: loss = 0.00968346 (* 1 = 0.00968346 loss)
I0403 03:50:40.837644 19293 sgd_solver.cpp:106] Iteration 2735, lr = 5e-05
I0403 03:50:44.288197 19293 solver.cpp:228] Iteration 2740, loss = 0.00106558
I0403 03:50:44.288283 19293 solver.cpp:244]     Train net output #0: loss = 0.00106552 (* 1 = 0.00106552 loss)
I0403 03:50:44.469105 19293 sgd_solver.cpp:106] Iteration 2740, lr = 5e-05
I0403 03:50:47.937364 19293 solver.cpp:228] Iteration 2745, loss = 0.00886056
I0403 03:50:47.937469 19293 solver.cpp:244]     Train net output #0: loss = 0.00886051 (* 1 = 0.00886051 loss)
I0403 03:50:48.129937 19293 sgd_solver.cpp:106] Iteration 2745, lr = 5e-05
I0403 03:50:51.601676 19293 solver.cpp:228] Iteration 2750, loss = 0.00434927
I0403 03:50:51.601778 19293 solver.cpp:244]     Train net output #0: loss = 0.00434921 (* 1 = 0.00434921 loss)
I0403 03:50:51.800413 19293 sgd_solver.cpp:106] Iteration 2750, lr = 5e-05
I0403 03:50:55.238279 19293 solver.cpp:228] Iteration 2755, loss = 0.00670142
I0403 03:50:55.238368 19293 solver.cpp:244]     Train net output #0: loss = 0.00670136 (* 1 = 0.00670136 loss)
I0403 03:50:55.398334 19293 sgd_solver.cpp:106] Iteration 2755, lr = 5e-05
I0403 03:50:58.890632 19293 solver.cpp:228] Iteration 2760, loss = 0.0678906
I0403 03:50:58.890732 19293 solver.cpp:244]     Train net output #0: loss = 0.0678906 (* 1 = 0.0678906 loss)
I0403 03:50:59.132014 19293 sgd_solver.cpp:106] Iteration 2760, lr = 5e-05
I0403 03:51:02.570129 19293 solver.cpp:228] Iteration 2765, loss = 0.00510308
I0403 03:51:02.570230 19293 solver.cpp:244]     Train net output #0: loss = 0.00510302 (* 1 = 0.00510302 loss)
I0403 03:51:02.790510 19293 sgd_solver.cpp:106] Iteration 2765, lr = 5e-05
I0403 03:51:06.348269 19293 solver.cpp:228] Iteration 2770, loss = 0.00502256
I0403 03:51:06.348356 19293 solver.cpp:244]     Train net output #0: loss = 0.0050225 (* 1 = 0.0050225 loss)
I0403 03:51:06.515743 19293 sgd_solver.cpp:106] Iteration 2770, lr = 5e-05
I0403 03:51:09.987304 19293 solver.cpp:228] Iteration 2775, loss = 0.00255694
I0403 03:51:09.987408 19293 solver.cpp:244]     Train net output #0: loss = 0.00255688 (* 1 = 0.00255688 loss)
I0403 03:51:10.185863 19293 sgd_solver.cpp:106] Iteration 2775, lr = 5e-05
I0403 03:51:13.590692 19293 solver.cpp:228] Iteration 2780, loss = 0.00596593
I0403 03:51:13.590793 19293 solver.cpp:244]     Train net output #0: loss = 0.00596587 (* 1 = 0.00596587 loss)
I0403 03:51:13.800393 19293 sgd_solver.cpp:106] Iteration 2780, lr = 5e-05
I0403 03:51:17.271488 19293 solver.cpp:228] Iteration 2785, loss = 0.00452988
I0403 03:51:17.271589 19293 solver.cpp:244]     Train net output #0: loss = 0.00452982 (* 1 = 0.00452982 loss)
I0403 03:51:17.463954 19293 sgd_solver.cpp:106] Iteration 2785, lr = 5e-05
I0403 03:51:20.904633 19293 solver.cpp:228] Iteration 2790, loss = 0.00377292
I0403 03:51:20.904731 19293 solver.cpp:244]     Train net output #0: loss = 0.00377286 (* 1 = 0.00377286 loss)
I0403 03:51:21.152148 19293 sgd_solver.cpp:106] Iteration 2790, lr = 5e-05
I0403 03:51:24.588608 19293 solver.cpp:228] Iteration 2795, loss = 0.0164148
I0403 03:51:24.588708 19293 solver.cpp:244]     Train net output #0: loss = 0.0164147 (* 1 = 0.0164147 loss)
I0403 03:51:24.811033 19293 sgd_solver.cpp:106] Iteration 2795, lr = 5e-05
I0403 03:51:28.248064 19293 solver.cpp:228] Iteration 2800, loss = 0.00241206
I0403 03:51:28.248162 19293 solver.cpp:244]     Train net output #0: loss = 0.002412 (* 1 = 0.002412 loss)
I0403 03:51:28.445514 19293 sgd_solver.cpp:106] Iteration 2800, lr = 5e-05
I0403 03:51:31.923871 19293 solver.cpp:228] Iteration 2805, loss = 0.015325
I0403 03:51:31.923970 19293 solver.cpp:244]     Train net output #0: loss = 0.0153249 (* 1 = 0.0153249 loss)
I0403 03:51:32.120479 19293 sgd_solver.cpp:106] Iteration 2805, lr = 5e-05
I0403 03:51:35.561213 19293 solver.cpp:228] Iteration 2810, loss = 0.00455681
I0403 03:51:35.561317 19293 solver.cpp:244]     Train net output #0: loss = 0.00455675 (* 1 = 0.00455675 loss)
I0403 03:51:35.880888 19293 sgd_solver.cpp:106] Iteration 2810, lr = 5e-05
I0403 03:51:39.309487 19293 solver.cpp:228] Iteration 2815, loss = 0.0121704
I0403 03:51:39.312322 19293 solver.cpp:244]     Train net output #0: loss = 0.0121703 (* 1 = 0.0121703 loss)
I0403 03:51:39.519510 19293 sgd_solver.cpp:106] Iteration 2815, lr = 5e-05
I0403 03:51:42.998653 19293 solver.cpp:228] Iteration 2820, loss = 0.000936424
I0403 03:51:42.998738 19293 solver.cpp:244]     Train net output #0: loss = 0.000936365 (* 1 = 0.000936365 loss)
I0403 03:51:43.166715 19293 sgd_solver.cpp:106] Iteration 2820, lr = 5e-05
I0403 03:51:46.618316 19293 solver.cpp:228] Iteration 2825, loss = 0.00645204
I0403 03:51:46.618419 19293 solver.cpp:244]     Train net output #0: loss = 0.00645198 (* 1 = 0.00645198 loss)
I0403 03:51:46.815906 19293 sgd_solver.cpp:106] Iteration 2825, lr = 5e-05
I0403 03:51:50.261143 19293 solver.cpp:228] Iteration 2830, loss = 0.00600612
I0403 03:51:50.261245 19293 solver.cpp:244]     Train net output #0: loss = 0.00600606 (* 1 = 0.00600606 loss)
I0403 03:51:50.449787 19293 sgd_solver.cpp:106] Iteration 2830, lr = 5e-05
I0403 03:51:53.381974 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2835.caffemodel
I0403 03:51:56.125404 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2835.solverstate
I0403 03:51:58.042840 19293 solver.cpp:337] Iteration 2835, Testing net (#0)
I0403 03:53:36.539793 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936705
I0403 03:53:36.540134 19293 solver.cpp:404]     Test net output #1: loss = 0.256902 (* 1 = 0.256902 loss)
I0403 03:53:37.087335 19293 solver.cpp:228] Iteration 2835, loss = 0.0118077
I0403 03:53:37.087419 19293 solver.cpp:244]     Train net output #0: loss = 0.0118076 (* 1 = 0.0118076 loss)
I0403 03:53:37.239948 19293 sgd_solver.cpp:106] Iteration 2835, lr = 5e-05
I0403 03:53:40.783884 19293 solver.cpp:228] Iteration 2840, loss = 0.00971596
I0403 03:53:40.783980 19293 solver.cpp:244]     Train net output #0: loss = 0.0097159 (* 1 = 0.0097159 loss)
I0403 03:53:40.970458 19293 sgd_solver.cpp:106] Iteration 2840, lr = 5e-05
I0403 03:53:44.385854 19293 solver.cpp:228] Iteration 2845, loss = 0.00550193
I0403 03:53:44.385954 19293 solver.cpp:244]     Train net output #0: loss = 0.00550187 (* 1 = 0.00550187 loss)
I0403 03:53:44.634732 19293 sgd_solver.cpp:106] Iteration 2845, lr = 5e-05
I0403 03:53:48.132958 19293 solver.cpp:228] Iteration 2850, loss = 0.0092173
I0403 03:53:48.133061 19293 solver.cpp:244]     Train net output #0: loss = 0.00921724 (* 1 = 0.00921724 loss)
I0403 03:53:48.328213 19293 sgd_solver.cpp:106] Iteration 2850, lr = 5e-05
I0403 03:53:51.780812 19293 solver.cpp:228] Iteration 2855, loss = 0.00465693
I0403 03:53:51.780911 19293 solver.cpp:244]     Train net output #0: loss = 0.00465688 (* 1 = 0.00465688 loss)
I0403 03:53:52.011206 19293 sgd_solver.cpp:106] Iteration 2855, lr = 5e-05
I0403 03:53:55.547225 19293 solver.cpp:228] Iteration 2860, loss = 0.0157286
I0403 03:53:55.547325 19293 solver.cpp:244]     Train net output #0: loss = 0.0157286 (* 1 = 0.0157286 loss)
I0403 03:53:55.736438 19293 sgd_solver.cpp:106] Iteration 2860, lr = 5e-05
I0403 03:53:59.198629 19293 solver.cpp:228] Iteration 2865, loss = 0.00489565
I0403 03:53:59.198732 19293 solver.cpp:244]     Train net output #0: loss = 0.00489559 (* 1 = 0.00489559 loss)
I0403 03:53:59.458338 19293 sgd_solver.cpp:106] Iteration 2865, lr = 5e-05
I0403 03:54:02.947849 19293 solver.cpp:228] Iteration 2870, loss = 0.000603595
I0403 03:54:02.947947 19293 solver.cpp:244]     Train net output #0: loss = 0.000603545 (* 1 = 0.000603545 loss)
I0403 03:54:03.133673 19293 sgd_solver.cpp:106] Iteration 2870, lr = 5e-05
I0403 03:54:06.568230 19293 solver.cpp:228] Iteration 2875, loss = 0.0416987
I0403 03:54:06.568527 19293 solver.cpp:244]     Train net output #0: loss = 0.0416987 (* 1 = 0.0416987 loss)
I0403 03:54:06.740346 19293 sgd_solver.cpp:106] Iteration 2875, lr = 5e-05
I0403 03:54:10.208845 19293 solver.cpp:228] Iteration 2880, loss = 0.00311219
I0403 03:54:10.208947 19293 solver.cpp:244]     Train net output #0: loss = 0.00311214 (* 1 = 0.00311214 loss)
I0403 03:54:10.417670 19293 sgd_solver.cpp:106] Iteration 2880, lr = 5e-05
I0403 03:54:13.918725 19293 solver.cpp:228] Iteration 2885, loss = 0.0033259
I0403 03:54:13.918826 19293 solver.cpp:244]     Train net output #0: loss = 0.00332585 (* 1 = 0.00332585 loss)
I0403 03:54:14.103600 19293 sgd_solver.cpp:106] Iteration 2885, lr = 5e-05
I0403 03:54:17.572166 19293 solver.cpp:228] Iteration 2890, loss = 0.00712753
I0403 03:54:17.572253 19293 solver.cpp:244]     Train net output #0: loss = 0.00712748 (* 1 = 0.00712748 loss)
I0403 03:54:17.741159 19293 sgd_solver.cpp:106] Iteration 2890, lr = 5e-05
I0403 03:54:21.247673 19293 solver.cpp:228] Iteration 2895, loss = 0.0010384
I0403 03:54:21.247772 19293 solver.cpp:244]     Train net output #0: loss = 0.00103835 (* 1 = 0.00103835 loss)
I0403 03:54:21.443440 19293 sgd_solver.cpp:106] Iteration 2895, lr = 5e-05
I0403 03:54:24.934715 19293 solver.cpp:228] Iteration 2900, loss = 0.00122403
I0403 03:54:24.934814 19293 solver.cpp:244]     Train net output #0: loss = 0.00122398 (* 1 = 0.00122398 loss)
I0403 03:54:25.125424 19293 sgd_solver.cpp:106] Iteration 2900, lr = 5e-05
I0403 03:54:28.570814 19293 solver.cpp:228] Iteration 2905, loss = 0.00321073
I0403 03:54:28.570914 19293 solver.cpp:244]     Train net output #0: loss = 0.00321068 (* 1 = 0.00321068 loss)
I0403 03:54:28.758016 19293 sgd_solver.cpp:106] Iteration 2905, lr = 5e-05
I0403 03:54:32.188977 19293 solver.cpp:228] Iteration 2910, loss = 0.00288844
I0403 03:54:32.189079 19293 solver.cpp:244]     Train net output #0: loss = 0.00288839 (* 1 = 0.00288839 loss)
I0403 03:54:32.400019 19293 sgd_solver.cpp:106] Iteration 2910, lr = 5e-05
I0403 03:54:35.936134 19293 solver.cpp:228] Iteration 2915, loss = 0.00206545
I0403 03:54:35.936223 19293 solver.cpp:244]     Train net output #0: loss = 0.0020654 (* 1 = 0.0020654 loss)
I0403 03:54:36.085942 19293 sgd_solver.cpp:106] Iteration 2915, lr = 5e-05
I0403 03:54:39.663542 19293 solver.cpp:228] Iteration 2920, loss = 0.0221769
I0403 03:54:39.663895 19293 solver.cpp:244]     Train net output #0: loss = 0.0221769 (* 1 = 0.0221769 loss)
I0403 03:54:39.855622 19293 sgd_solver.cpp:106] Iteration 2920, lr = 5e-05
I0403 03:54:43.341596 19293 solver.cpp:228] Iteration 2925, loss = 0.00121778
I0403 03:54:43.341697 19293 solver.cpp:244]     Train net output #0: loss = 0.00121773 (* 1 = 0.00121773 loss)
I0403 03:54:43.541040 19293 sgd_solver.cpp:106] Iteration 2925, lr = 5e-05
I0403 03:54:47.027932 19293 solver.cpp:228] Iteration 2930, loss = 0.00419962
I0403 03:54:47.028036 19293 solver.cpp:244]     Train net output #0: loss = 0.00419957 (* 1 = 0.00419957 loss)
I0403 03:54:47.216462 19293 sgd_solver.cpp:106] Iteration 2930, lr = 5e-05
I0403 03:54:50.678782 19293 solver.cpp:228] Iteration 2935, loss = 0.00125228
I0403 03:54:50.678879 19293 solver.cpp:244]     Train net output #0: loss = 0.00125223 (* 1 = 0.00125223 loss)
I0403 03:54:50.871179 19293 sgd_solver.cpp:106] Iteration 2935, lr = 5e-05
I0403 03:54:53.786607 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2940.caffemodel
I0403 03:54:56.539575 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_2940.solverstate
I0403 03:54:58.445062 19293 solver.cpp:337] Iteration 2940, Testing net (#0)
I0403 03:56:36.934509 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936637
I0403 03:56:36.941573 19293 solver.cpp:404]     Test net output #1: loss = 0.257213 (* 1 = 0.257213 loss)
I0403 03:56:37.495457 19293 solver.cpp:228] Iteration 2940, loss = 0.00157838
I0403 03:56:37.495539 19293 solver.cpp:244]     Train net output #0: loss = 0.00157833 (* 1 = 0.00157833 loss)
I0403 03:56:37.645895 19293 sgd_solver.cpp:106] Iteration 2940, lr = 5e-05
I0403 03:56:41.174064 19293 solver.cpp:228] Iteration 2945, loss = 0.00265645
I0403 03:56:41.174166 19293 solver.cpp:244]     Train net output #0: loss = 0.00265641 (* 1 = 0.00265641 loss)
I0403 03:56:41.360460 19293 sgd_solver.cpp:106] Iteration 2945, lr = 5e-05
I0403 03:56:44.818415 19293 solver.cpp:228] Iteration 2950, loss = 0.0119036
I0403 03:56:44.818519 19293 solver.cpp:244]     Train net output #0: loss = 0.0119035 (* 1 = 0.0119035 loss)
I0403 03:56:45.031076 19293 sgd_solver.cpp:106] Iteration 2950, lr = 5e-05
I0403 03:56:48.491952 19293 solver.cpp:228] Iteration 2955, loss = 0.0262933
I0403 03:56:48.492049 19293 solver.cpp:244]     Train net output #0: loss = 0.0262932 (* 1 = 0.0262932 loss)
I0403 03:56:48.694310 19293 sgd_solver.cpp:106] Iteration 2955, lr = 5e-05
I0403 03:56:52.179744 19293 solver.cpp:228] Iteration 2960, loss = 0.00123518
I0403 03:56:52.179829 19293 solver.cpp:244]     Train net output #0: loss = 0.00123514 (* 1 = 0.00123514 loss)
I0403 03:56:52.348314 19293 sgd_solver.cpp:106] Iteration 2960, lr = 5e-05
I0403 03:56:55.825443 19293 solver.cpp:228] Iteration 2965, loss = 0.00153038
I0403 03:56:55.825541 19293 solver.cpp:244]     Train net output #0: loss = 0.00153034 (* 1 = 0.00153034 loss)
I0403 03:56:56.015470 19293 sgd_solver.cpp:106] Iteration 2965, lr = 5e-05
I0403 03:56:59.432903 19293 solver.cpp:228] Iteration 2970, loss = 0.00571463
I0403 03:56:59.433003 19293 solver.cpp:244]     Train net output #0: loss = 0.00571458 (* 1 = 0.00571458 loss)
I0403 03:56:59.680523 19293 sgd_solver.cpp:106] Iteration 2970, lr = 5e-05
I0403 03:57:03.150390 19293 solver.cpp:228] Iteration 2975, loss = 0.00125829
I0403 03:57:03.150482 19293 solver.cpp:244]     Train net output #0: loss = 0.00125824 (* 1 = 0.00125824 loss)
I0403 03:57:03.315312 19293 sgd_solver.cpp:106] Iteration 2975, lr = 5e-05
I0403 03:57:06.822856 19293 solver.cpp:228] Iteration 2980, loss = 0.012884
I0403 03:57:06.822953 19293 solver.cpp:244]     Train net output #0: loss = 0.012884 (* 1 = 0.012884 loss)
I0403 03:57:07.025033 19293 sgd_solver.cpp:106] Iteration 2980, lr = 5e-05
I0403 03:57:10.489763 19293 solver.cpp:228] Iteration 2985, loss = 0.00120324
I0403 03:57:10.489850 19293 solver.cpp:244]     Train net output #0: loss = 0.00120319 (* 1 = 0.00120319 loss)
I0403 03:57:10.665948 19293 sgd_solver.cpp:106] Iteration 2985, lr = 5e-05
I0403 03:57:14.117760 19293 solver.cpp:228] Iteration 2990, loss = 0.0102459
I0403 03:57:14.117846 19293 solver.cpp:244]     Train net output #0: loss = 0.0102458 (* 1 = 0.0102458 loss)
I0403 03:57:14.291100 19293 sgd_solver.cpp:106] Iteration 2990, lr = 5e-05
I0403 03:57:17.777451 19293 solver.cpp:228] Iteration 2995, loss = 0.0106512
I0403 03:57:17.777552 19293 solver.cpp:244]     Train net output #0: loss = 0.0106512 (* 1 = 0.0106512 loss)
I0403 03:57:17.984853 19293 sgd_solver.cpp:106] Iteration 2995, lr = 5e-05
I0403 03:57:21.428581 19293 solver.cpp:228] Iteration 3000, loss = 0.000412717
I0403 03:57:21.428681 19293 solver.cpp:244]     Train net output #0: loss = 0.000412671 (* 1 = 0.000412671 loss)
I0403 03:57:21.619555 19293 sgd_solver.cpp:106] Iteration 3000, lr = 5e-05
I0403 03:57:25.060425 19293 solver.cpp:228] Iteration 3005, loss = 0.011067
I0403 03:57:25.060518 19293 solver.cpp:244]     Train net output #0: loss = 0.011067 (* 1 = 0.011067 loss)
I0403 03:57:25.242260 19293 sgd_solver.cpp:106] Iteration 3005, lr = 5e-05
I0403 03:57:28.692796 19293 solver.cpp:228] Iteration 3010, loss = 0.00479416
I0403 03:57:28.692893 19293 solver.cpp:244]     Train net output #0: loss = 0.00479411 (* 1 = 0.00479411 loss)
I0403 03:57:28.879422 19293 sgd_solver.cpp:106] Iteration 3010, lr = 5e-05
I0403 03:57:32.308591 19293 solver.cpp:228] Iteration 3015, loss = 0.00412336
I0403 03:57:32.308693 19293 solver.cpp:244]     Train net output #0: loss = 0.00412332 (* 1 = 0.00412332 loss)
I0403 03:57:32.500212 19293 sgd_solver.cpp:106] Iteration 3015, lr = 5e-05
I0403 03:57:35.940640 19293 solver.cpp:228] Iteration 3020, loss = 0.0254224
I0403 03:57:35.953816 19293 solver.cpp:244]     Train net output #0: loss = 0.0254224 (* 1 = 0.0254224 loss)
I0403 03:57:36.127621 19293 sgd_solver.cpp:106] Iteration 3020, lr = 5e-05
I0403 03:57:39.544608 19293 solver.cpp:228] Iteration 3025, loss = 0.00593666
I0403 03:57:39.544946 19293 solver.cpp:244]     Train net output #0: loss = 0.00593661 (* 1 = 0.00593661 loss)
I0403 03:57:39.738683 19293 sgd_solver.cpp:106] Iteration 3025, lr = 5e-05
I0403 03:57:43.162124 19293 solver.cpp:228] Iteration 3030, loss = 0.0114398
I0403 03:57:43.162227 19293 solver.cpp:244]     Train net output #0: loss = 0.0114397 (* 1 = 0.0114397 loss)
I0403 03:57:43.355393 19293 sgd_solver.cpp:106] Iteration 3030, lr = 5e-05
I0403 03:57:46.789444 19293 solver.cpp:228] Iteration 3035, loss = 0.000626682
I0403 03:57:46.790535 19293 solver.cpp:244]     Train net output #0: loss = 0.000626636 (* 1 = 0.000626636 loss)
I0403 03:57:46.981081 19293 sgd_solver.cpp:106] Iteration 3035, lr = 5e-05
I0403 03:57:50.401876 19293 solver.cpp:228] Iteration 3040, loss = 0.00370003
I0403 03:57:50.401976 19293 solver.cpp:244]     Train net output #0: loss = 0.00369999 (* 1 = 0.00369999 loss)
I0403 03:57:50.587589 19293 sgd_solver.cpp:106] Iteration 3040, lr = 5e-05
I0403 03:57:53.470620 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_3045.caffemodel
I0403 03:57:56.118937 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_3045.solverstate
I0403 03:57:58.032167 19293 solver.cpp:337] Iteration 3045, Testing net (#0)
I0403 03:59:36.511234 19293 solver.cpp:404]     Test net output #0: accuracy = 0.936797
I0403 03:59:36.511592 19293 solver.cpp:404]     Test net output #1: loss = 0.256711 (* 1 = 0.256711 loss)
I0403 03:59:37.022452 19293 solver.cpp:228] Iteration 3045, loss = 0.00320838
I0403 03:59:37.022538 19293 solver.cpp:244]     Train net output #0: loss = 0.00320833 (* 1 = 0.00320833 loss)
I0403 03:59:37.203403 19293 sgd_solver.cpp:106] Iteration 3045, lr = 5e-05
I0403 03:59:40.633008 19293 solver.cpp:228] Iteration 3050, loss = 0.00302866
I0403 03:59:40.633108 19293 solver.cpp:244]     Train net output #0: loss = 0.00302862 (* 1 = 0.00302862 loss)
I0403 03:59:40.857365 19293 sgd_solver.cpp:106] Iteration 3050, lr = 5e-05
I0403 03:59:44.342602 19293 solver.cpp:228] Iteration 3055, loss = 0.015775
I0403 03:59:44.342700 19293 solver.cpp:244]     Train net output #0: loss = 0.015775 (* 1 = 0.015775 loss)
I0403 03:59:44.539250 19293 sgd_solver.cpp:106] Iteration 3055, lr = 5e-05
I0403 03:59:47.991390 19293 solver.cpp:228] Iteration 3060, loss = 0.0105222
I0403 03:59:47.991497 19293 solver.cpp:244]     Train net output #0: loss = 0.0105221 (* 1 = 0.0105221 loss)
I0403 03:59:48.211308 19293 sgd_solver.cpp:106] Iteration 3060, lr = 5e-05
I0403 03:59:51.672920 19293 solver.cpp:228] Iteration 3065, loss = 0.00418332
I0403 03:59:51.673017 19293 solver.cpp:244]     Train net output #0: loss = 0.00418328 (* 1 = 0.00418328 loss)
I0403 03:59:51.870604 19293 sgd_solver.cpp:106] Iteration 3065, lr = 5e-05
I0403 03:59:55.279690 19293 solver.cpp:228] Iteration 3070, loss = 0.00186823
I0403 03:59:55.279789 19293 solver.cpp:244]     Train net output #0: loss = 0.00186819 (* 1 = 0.00186819 loss)
I0403 03:59:55.492967 19293 sgd_solver.cpp:106] Iteration 3070, lr = 5e-05
I0403 03:59:59.045254 19293 solver.cpp:228] Iteration 3075, loss = 0.00136523
I0403 03:59:59.045354 19293 solver.cpp:244]     Train net output #0: loss = 0.00136518 (* 1 = 0.00136518 loss)
I0403 03:59:59.277750 19293 sgd_solver.cpp:106] Iteration 3075, lr = 5e-05
I0403 04:00:02.748456 19293 solver.cpp:228] Iteration 3080, loss = 0.0031028
I0403 04:00:02.748543 19293 solver.cpp:244]     Train net output #0: loss = 0.00310276 (* 1 = 0.00310276 loss)
I0403 04:00:02.903365 19293 sgd_solver.cpp:106] Iteration 3080, lr = 5e-05
I0403 04:00:06.413636 19293 solver.cpp:228] Iteration 3085, loss = 0.00149177
I0403 04:00:06.413736 19293 solver.cpp:244]     Train net output #0: loss = 0.00149172 (* 1 = 0.00149172 loss)
I0403 04:00:06.598343 19293 sgd_solver.cpp:106] Iteration 3085, lr = 5e-05
I0403 04:00:10.053763 19293 solver.cpp:228] Iteration 3090, loss = 0.00896399
I0403 04:00:10.053869 19293 solver.cpp:244]     Train net output #0: loss = 0.00896394 (* 1 = 0.00896394 loss)
I0403 04:00:10.250767 19293 sgd_solver.cpp:106] Iteration 3090, lr = 5e-05
I0403 04:00:13.676123 19293 solver.cpp:228] Iteration 3095, loss = 0.00182766
I0403 04:00:13.676221 19293 solver.cpp:244]     Train net output #0: loss = 0.00182761 (* 1 = 0.00182761 loss)
I0403 04:00:13.894243 19293 sgd_solver.cpp:106] Iteration 3095, lr = 5e-05
I0403 04:00:17.384093 19293 solver.cpp:228] Iteration 3100, loss = 0.00418142
I0403 04:00:17.385169 19293 solver.cpp:244]     Train net output #0: loss = 0.00418137 (* 1 = 0.00418137 loss)
I0403 04:00:17.574411 19293 sgd_solver.cpp:106] Iteration 3100, lr = 5e-05
I0403 04:00:21.032680 19293 solver.cpp:228] Iteration 3105, loss = 0.0184666
I0403 04:00:21.032790 19293 solver.cpp:244]     Train net output #0: loss = 0.0184666 (* 1 = 0.0184666 loss)
I0403 04:00:21.235864 19293 sgd_solver.cpp:106] Iteration 3105, lr = 5e-05
I0403 04:00:24.783490 19293 solver.cpp:228] Iteration 3110, loss = 0.00221362
I0403 04:00:24.783587 19293 solver.cpp:244]     Train net output #0: loss = 0.00221357 (* 1 = 0.00221357 loss)
I0403 04:00:24.974812 19293 sgd_solver.cpp:106] Iteration 3110, lr = 5e-05
I0403 04:00:28.479665 19293 solver.cpp:228] Iteration 3115, loss = 0.00101011
I0403 04:00:28.479763 19293 solver.cpp:244]     Train net output #0: loss = 0.00101006 (* 1 = 0.00101006 loss)
I0403 04:00:28.690598 19293 sgd_solver.cpp:106] Iteration 3115, lr = 5e-05
I0403 04:00:32.106638 19293 solver.cpp:228] Iteration 3120, loss = 0.0155646
I0403 04:00:32.106725 19293 solver.cpp:244]     Train net output #0: loss = 0.0155646 (* 1 = 0.0155646 loss)
I0403 04:00:32.290418 19293 sgd_solver.cpp:106] Iteration 3120, lr = 5e-05
I0403 04:00:35.719259 19293 solver.cpp:228] Iteration 3125, loss = 0.00437025
I0403 04:00:35.719358 19293 solver.cpp:244]     Train net output #0: loss = 0.0043702 (* 1 = 0.0043702 loss)
I0403 04:00:35.908596 19293 sgd_solver.cpp:106] Iteration 3125, lr = 5e-05
I0403 04:00:39.465333 19293 solver.cpp:228] Iteration 3130, loss = 0.00785468
I0403 04:00:39.465694 19293 solver.cpp:244]     Train net output #0: loss = 0.00785463 (* 1 = 0.00785463 loss)
I0403 04:00:39.683652 19293 sgd_solver.cpp:106] Iteration 3130, lr = 5e-05
I0403 04:00:43.149189 19293 solver.cpp:228] Iteration 3135, loss = 0.00566758
I0403 04:00:43.149287 19293 solver.cpp:244]     Train net output #0: loss = 0.00566754 (* 1 = 0.00566754 loss)
I0403 04:00:43.338901 19293 sgd_solver.cpp:106] Iteration 3135, lr = 5e-05
I0403 04:00:46.791652 19293 solver.cpp:228] Iteration 3140, loss = 0.00561179
I0403 04:00:46.791750 19293 solver.cpp:244]     Train net output #0: loss = 0.00561174 (* 1 = 0.00561174 loss)
I0403 04:00:46.984645 19293 sgd_solver.cpp:106] Iteration 3140, lr = 5e-05
I0403 04:00:50.423847 19293 solver.cpp:228] Iteration 3145, loss = 0.00669256
I0403 04:00:50.423946 19293 solver.cpp:244]     Train net output #0: loss = 0.00669251 (* 1 = 0.00669251 loss)
I0403 04:00:50.614048 19293 sgd_solver.cpp:106] Iteration 3145, lr = 5e-05
I0403 04:00:53.534940 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_3150.caffemodel
I0403 04:00:56.283615 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_3150.solverstate
I0403 04:00:58.195752 19293 solver.cpp:337] Iteration 3150, Testing net (#0)
I0403 04:02:36.710240 19293 solver.cpp:404]     Test net output #0: accuracy = 0.93714
I0403 04:02:36.710567 19293 solver.cpp:404]     Test net output #1: loss = 0.257222 (* 1 = 0.257222 loss)
I0403 04:02:37.241567 19293 solver.cpp:228] Iteration 3150, loss = 0.00293132
I0403 04:02:37.241662 19293 solver.cpp:244]     Train net output #0: loss = 0.00293127 (* 1 = 0.00293127 loss)
I0403 04:02:37.405382 19293 sgd_solver.cpp:106] Iteration 3150, lr = 5e-05
I0403 04:02:40.947872 19293 solver.cpp:228] Iteration 3155, loss = 0.00756827
I0403 04:02:40.947960 19293 solver.cpp:244]     Train net output #0: loss = 0.00756822 (* 1 = 0.00756822 loss)
I0403 04:02:41.109932 19293 sgd_solver.cpp:106] Iteration 3155, lr = 5e-05
I0403 04:02:44.587820 19293 solver.cpp:228] Iteration 3160, loss = 0.01534
I0403 04:02:44.587918 19293 solver.cpp:244]     Train net output #0: loss = 0.01534 (* 1 = 0.01534 loss)
I0403 04:02:44.774766 19293 sgd_solver.cpp:106] Iteration 3160, lr = 5e-05
I0403 04:02:48.216004 19293 solver.cpp:228] Iteration 3165, loss = 0.0033538
I0403 04:02:48.217295 19293 solver.cpp:244]     Train net output #0: loss = 0.00335375 (* 1 = 0.00335375 loss)
I0403 04:02:48.405305 19293 sgd_solver.cpp:106] Iteration 3165, lr = 5e-05
I0403 04:02:51.864758 19293 solver.cpp:228] Iteration 3170, loss = 0.0158879
I0403 04:02:51.864856 19293 solver.cpp:244]     Train net output #0: loss = 0.0158878 (* 1 = 0.0158878 loss)
I0403 04:02:52.060878 19293 sgd_solver.cpp:106] Iteration 3170, lr = 5e-05
I0403 04:02:52.788786 19293 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_3172.caffemodel
I0403 04:02:55.411810 19293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-20-80_finetune/snapshots__iter_3172.solverstate
I0403 04:02:57.210402 19293 solver.cpp:322] Optimization Done.
I0403 04:02:57.351824 19293 caffe.cpp:222] Optimization Done.
