I0403 02:30:27.999513 23740 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.000005 23740 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.000035 23740 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.156015 23740 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.157668 23740 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.159175 23740 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.076069 23740 solver.cpp:48] Initializing solver from parameters: 
test_iter: 324
test_interval: 219
base_lr: 0.005
display: 10
max_iter: 6571
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2190
snapshot: 219
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.094604 23740 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.102581 23740 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.102658 23740 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.103497 23740 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-40-60/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.105268 23740 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.106173 23740 net.cpp:91] Creating Layer data
I0403 02:30:37.106283 23740 net.cpp:399] data -> data
I0403 02:30:37.106477 23740 net.cpp:399] data -> label
I0403 02:30:37.106549 23740 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-40-60/mean.binaryproto
I0403 02:30:37.127329 23747 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-40-60/train_db
I0403 02:30:37.144562 23740 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.285425 23740 net.cpp:141] Setting up data
I0403 02:30:37.285537 23740 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.285564 23740 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.285583 23740 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.285619 23740 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.285675 23740 net.cpp:91] Creating Layer conv1
I0403 02:30:37.285701 23740 net.cpp:425] conv1 <- data
I0403 02:30:37.285739 23740 net.cpp:399] conv1 -> conv1
I0403 02:30:37.295151 23740 net.cpp:141] Setting up conv1
I0403 02:30:37.295195 23740 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.295217 23740 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.295260 23740 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.295294 23740 net.cpp:91] Creating Layer relu1
I0403 02:30:37.295315 23740 net.cpp:425] relu1 <- conv1
I0403 02:30:37.295338 23740 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.295367 23740 net.cpp:141] Setting up relu1
I0403 02:30:37.295390 23740 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.295408 23740 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.295425 23740 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.295449 23740 net.cpp:91] Creating Layer norm1
I0403 02:30:37.295503 23740 net.cpp:425] norm1 <- conv1
I0403 02:30:37.295527 23740 net.cpp:399] norm1 -> norm1
I0403 02:30:37.295598 23740 net.cpp:141] Setting up norm1
I0403 02:30:37.295624 23740 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.295642 23740 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.295660 23740 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.295686 23740 net.cpp:91] Creating Layer pool1
I0403 02:30:37.295706 23740 net.cpp:425] pool1 <- norm1
I0403 02:30:37.295732 23740 net.cpp:399] pool1 -> pool1
I0403 02:30:37.295827 23740 net.cpp:141] Setting up pool1
I0403 02:30:37.295858 23740 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.295876 23740 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.295893 23740 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.295919 23740 net.cpp:91] Creating Layer conv2
I0403 02:30:37.295943 23740 net.cpp:425] conv2 <- pool1
I0403 02:30:37.295971 23740 net.cpp:399] conv2 -> conv2
I0403 02:30:37.296453 23749 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.312144 23740 net.cpp:141] Setting up conv2
I0403 02:30:37.312182 23740 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.312202 23740 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.312228 23740 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.312252 23740 net.cpp:91] Creating Layer relu2
I0403 02:30:37.312273 23740 net.cpp:425] relu2 <- conv2
I0403 02:30:37.312293 23740 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.312315 23740 net.cpp:141] Setting up relu2
I0403 02:30:37.312336 23740 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.312353 23740 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.312371 23740 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.312392 23740 net.cpp:91] Creating Layer norm2
I0403 02:30:37.312412 23740 net.cpp:425] norm2 <- conv2
I0403 02:30:37.312433 23740 net.cpp:399] norm2 -> norm2
I0403 02:30:37.312490 23740 net.cpp:141] Setting up norm2
I0403 02:30:37.312520 23740 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.312536 23740 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.312554 23740 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.312579 23740 net.cpp:91] Creating Layer pool2
I0403 02:30:37.312599 23740 net.cpp:425] pool2 <- norm2
I0403 02:30:37.312620 23740 net.cpp:399] pool2 -> pool2
I0403 02:30:37.312675 23740 net.cpp:141] Setting up pool2
I0403 02:30:37.312702 23740 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.312721 23740 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.312737 23740 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.312763 23740 net.cpp:91] Creating Layer conv3
I0403 02:30:37.312783 23740 net.cpp:425] conv3 <- pool2
I0403 02:30:37.312808 23740 net.cpp:399] conv3 -> conv3
I0403 02:30:37.354611 23740 net.cpp:141] Setting up conv3
I0403 02:30:37.354653 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.354672 23740 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.354698 23740 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.354722 23740 net.cpp:91] Creating Layer relu3
I0403 02:30:37.354740 23740 net.cpp:425] relu3 <- conv3
I0403 02:30:37.354760 23740 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.354784 23740 net.cpp:141] Setting up relu3
I0403 02:30:37.354804 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.354822 23740 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.354840 23740 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.354866 23740 net.cpp:91] Creating Layer conv4
I0403 02:30:37.354887 23740 net.cpp:425] conv4 <- conv3
I0403 02:30:37.354910 23740 net.cpp:399] conv4 -> conv4
I0403 02:30:37.386414 23740 net.cpp:141] Setting up conv4
I0403 02:30:37.386451 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.386471 23740 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.386513 23740 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.386539 23740 net.cpp:91] Creating Layer relu4
I0403 02:30:37.386559 23740 net.cpp:425] relu4 <- conv4
I0403 02:30:37.386580 23740 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.386603 23740 net.cpp:141] Setting up relu4
I0403 02:30:37.386625 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.386641 23740 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.386658 23740 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.386685 23740 net.cpp:91] Creating Layer conv5
I0403 02:30:37.386704 23740 net.cpp:425] conv5 <- conv4
I0403 02:30:37.386728 23740 net.cpp:399] conv5 -> conv5
I0403 02:30:37.407871 23740 net.cpp:141] Setting up conv5
I0403 02:30:37.407912 23740 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.407930 23740 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.407961 23740 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.407989 23740 net.cpp:91] Creating Layer relu5
I0403 02:30:37.408009 23740 net.cpp:425] relu5 <- conv5
I0403 02:30:37.408028 23740 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.408052 23740 net.cpp:141] Setting up relu5
I0403 02:30:37.408072 23740 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.408089 23740 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.408107 23740 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.408128 23740 net.cpp:91] Creating Layer pool5
I0403 02:30:37.408145 23740 net.cpp:425] pool5 <- conv5
I0403 02:30:37.408169 23740 net.cpp:399] pool5 -> pool5
I0403 02:30:37.408227 23740 net.cpp:141] Setting up pool5
I0403 02:30:37.408255 23740 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.408273 23740 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.408291 23740 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.408344 23740 net.cpp:91] Creating Layer fc6
I0403 02:30:37.408367 23740 net.cpp:425] fc6 <- pool5
I0403 02:30:37.408390 23740 net.cpp:399] fc6 -> fc6
I0403 02:30:38.988340 23740 net.cpp:141] Setting up fc6
I0403 02:30:38.988421 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.988437 23740 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.988458 23740 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.988484 23740 net.cpp:91] Creating Layer relu6
I0403 02:30:38.988500 23740 net.cpp:425] relu6 <- fc6
I0403 02:30:38.988519 23740 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.988540 23740 net.cpp:141] Setting up relu6
I0403 02:30:38.988555 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.988569 23740 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.988582 23740 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.988605 23740 net.cpp:91] Creating Layer drop6
I0403 02:30:38.988621 23740 net.cpp:425] drop6 <- fc6
I0403 02:30:38.988636 23740 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.988680 23740 net.cpp:141] Setting up drop6
I0403 02:30:38.988706 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.988721 23740 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.988735 23740 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.988755 23740 net.cpp:91] Creating Layer fc7
I0403 02:30:38.988770 23740 net.cpp:425] fc7 <- fc6
I0403 02:30:38.988786 23740 net.cpp:399] fc7 -> fc7
I0403 02:30:39.602583 23740 net.cpp:141] Setting up fc7
I0403 02:30:39.602663 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.602679 23740 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.602701 23740 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.602725 23740 net.cpp:91] Creating Layer relu7
I0403 02:30:39.602742 23740 net.cpp:425] relu7 <- fc7
I0403 02:30:39.602762 23740 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.602783 23740 net.cpp:141] Setting up relu7
I0403 02:30:39.602800 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.602814 23740 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.602829 23740 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.602879 23740 net.cpp:91] Creating Layer drop7
I0403 02:30:39.602896 23740 net.cpp:425] drop7 <- fc7
I0403 02:30:39.602926 23740 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.602987 23740 net.cpp:141] Setting up drop7
I0403 02:30:39.603010 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.603026 23740 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.603041 23740 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.603062 23740 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.603078 23740 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.603099 23740 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.611394 23740 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.611479 23740 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.611508 23740 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.611552 23740 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.611615 23740 net.cpp:91] Creating Layer loss
I0403 02:30:39.611660 23740 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.611677 23740 net.cpp:425] loss <- label
I0403 02:30:39.611726 23740 net.cpp:399] loss -> loss
I0403 02:30:39.611778 23740 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.611924 23740 net.cpp:141] Setting up loss
I0403 02:30:39.611984 23740 net.cpp:148] Top shape: (1)
I0403 02:30:39.612002 23740 net.cpp:151]     with loss weight 1
I0403 02:30:39.612093 23740 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.612138 23740 net.cpp:217] loss needs backward computation.
I0403 02:30:39.612161 23740 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.612175 23740 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.612218 23740 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.612258 23740 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.612298 23740 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.612329 23740 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.612380 23740 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.612438 23740 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.612480 23740 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.612496 23740 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.612524 23740 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.612561 23740 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.612614 23740 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.612673 23740 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.612706 23740 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.612741 23740 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.612757 23740 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.612772 23740 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.612821 23740 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.612910 23740 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.612936 23740 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.612994 23740 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.613059 23740 net.cpp:219] data does not need backward computation.
I0403 02:30:39.613119 23740 net.cpp:261] This network produces output loss
I0403 02:30:39.613150 23740 net.cpp:274] Network initialization done.
I0403 02:30:39.614399 23740 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.614491 23740 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.615211 23740 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-40-60/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.615406 23740 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.615572 23740 net.cpp:91] Creating Layer data
I0403 02:30:39.615620 23740 net.cpp:399] data -> data
I0403 02:30:39.615646 23740 net.cpp:399] data -> label
I0403 02:30:39.615690 23740 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-40-60/mean.binaryproto
I0403 02:30:39.625341 23753 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-40-60/test_db
I0403 02:30:39.627796 23740 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.807796 23740 net.cpp:141] Setting up data
I0403 02:30:39.807873 23740 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.807920 23740 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.807936 23740 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.807953 23740 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.807996 23740 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.808014 23740 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.808035 23740 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.808058 23740 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.808125 23740 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.808150 23740 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.808166 23740 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.808179 23740 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.808194 23740 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.808231 23740 net.cpp:91] Creating Layer conv1
I0403 02:30:39.808249 23740 net.cpp:425] conv1 <- data
I0403 02:30:39.808269 23740 net.cpp:399] conv1 -> conv1
I0403 02:30:39.809865 23740 net.cpp:141] Setting up conv1
I0403 02:30:39.809892 23740 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.809907 23740 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.809931 23740 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.809952 23740 net.cpp:91] Creating Layer relu1
I0403 02:30:39.809973 23740 net.cpp:425] relu1 <- conv1
I0403 02:30:39.809990 23740 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.810011 23740 net.cpp:141] Setting up relu1
I0403 02:30:39.810029 23740 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.810042 23740 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.810065 23740 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.810086 23740 net.cpp:91] Creating Layer norm1
I0403 02:30:39.810117 23740 net.cpp:425] norm1 <- conv1
I0403 02:30:39.810159 23740 net.cpp:399] norm1 -> norm1
I0403 02:30:39.810247 23740 net.cpp:141] Setting up norm1
I0403 02:30:39.810279 23740 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.810320 23740 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.810359 23740 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.810400 23740 net.cpp:91] Creating Layer pool1
I0403 02:30:39.810416 23740 net.cpp:425] pool1 <- norm1
I0403 02:30:39.810456 23740 net.cpp:399] pool1 -> pool1
I0403 02:30:39.810530 23740 net.cpp:141] Setting up pool1
I0403 02:30:39.810564 23740 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.810602 23740 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.810648 23740 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.810698 23740 net.cpp:91] Creating Layer conv2
I0403 02:30:39.810740 23740 net.cpp:425] conv2 <- pool1
I0403 02:30:39.810763 23740 net.cpp:399] conv2 -> conv2
I0403 02:30:39.832293 23740 net.cpp:141] Setting up conv2
I0403 02:30:39.853520 23740 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.853579 23740 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.853662 23740 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.853756 23740 net.cpp:91] Creating Layer relu2
I0403 02:30:39.853822 23740 net.cpp:425] relu2 <- conv2
I0403 02:30:39.853893 23740 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.853991 23740 net.cpp:141] Setting up relu2
I0403 02:30:39.854059 23740 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.854140 23740 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.854210 23740 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.854302 23740 net.cpp:91] Creating Layer norm2
I0403 02:30:39.854375 23740 net.cpp:425] norm2 <- conv2
I0403 02:30:39.854470 23740 net.cpp:399] norm2 -> norm2
I0403 02:30:39.854575 23740 net.cpp:141] Setting up norm2
I0403 02:30:39.854601 23740 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.854635 23740 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.854671 23740 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.854708 23740 net.cpp:91] Creating Layer pool2
I0403 02:30:39.854725 23740 net.cpp:425] pool2 <- norm2
I0403 02:30:39.854771 23740 net.cpp:399] pool2 -> pool2
I0403 02:30:39.854820 23740 net.cpp:141] Setting up pool2
I0403 02:30:39.854869 23740 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.854884 23740 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.854899 23740 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.854920 23740 net.cpp:91] Creating Layer conv3
I0403 02:30:39.854938 23740 net.cpp:425] conv3 <- pool2
I0403 02:30:39.854959 23740 net.cpp:399] conv3 -> conv3
I0403 02:30:39.893601 23740 net.cpp:141] Setting up conv3
I0403 02:30:39.893651 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.893668 23740 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.893692 23740 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.893717 23740 net.cpp:91] Creating Layer relu3
I0403 02:30:39.893733 23740 net.cpp:425] relu3 <- conv3
I0403 02:30:39.893805 23740 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.893831 23740 net.cpp:141] Setting up relu3
I0403 02:30:39.893847 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.893862 23740 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.893877 23740 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.893900 23740 net.cpp:91] Creating Layer conv4
I0403 02:30:39.893916 23740 net.cpp:425] conv4 <- conv3
I0403 02:30:39.893936 23740 net.cpp:399] conv4 -> conv4
I0403 02:30:39.921550 23740 net.cpp:141] Setting up conv4
I0403 02:30:39.921589 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.921605 23740 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.921624 23740 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.921644 23740 net.cpp:91] Creating Layer relu4
I0403 02:30:39.921661 23740 net.cpp:425] relu4 <- conv4
I0403 02:30:39.921679 23740 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.921700 23740 net.cpp:141] Setting up relu4
I0403 02:30:39.921716 23740 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.921731 23740 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.921746 23740 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.921767 23740 net.cpp:91] Creating Layer conv5
I0403 02:30:39.921783 23740 net.cpp:425] conv5 <- conv4
I0403 02:30:39.921803 23740 net.cpp:399] conv5 -> conv5
I0403 02:30:39.940243 23740 net.cpp:141] Setting up conv5
I0403 02:30:39.940274 23740 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.940318 23740 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.940342 23740 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.940362 23740 net.cpp:91] Creating Layer relu5
I0403 02:30:39.940379 23740 net.cpp:425] relu5 <- conv5
I0403 02:30:39.940397 23740 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.940417 23740 net.cpp:141] Setting up relu5
I0403 02:30:39.940434 23740 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.940448 23740 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.940462 23740 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.940486 23740 net.cpp:91] Creating Layer pool5
I0403 02:30:39.940503 23740 net.cpp:425] pool5 <- conv5
I0403 02:30:39.940522 23740 net.cpp:399] pool5 -> pool5
I0403 02:30:39.940578 23740 net.cpp:141] Setting up pool5
I0403 02:30:39.940603 23740 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.940618 23740 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.940632 23740 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.940652 23740 net.cpp:91] Creating Layer fc6
I0403 02:30:39.940668 23740 net.cpp:425] fc6 <- pool5
I0403 02:30:39.940688 23740 net.cpp:399] fc6 -> fc6
I0403 02:30:41.372030 23740 net.cpp:141] Setting up fc6
I0403 02:30:41.372117 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.372133 23740 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.372154 23740 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.372180 23740 net.cpp:91] Creating Layer relu6
I0403 02:30:41.372198 23740 net.cpp:425] relu6 <- fc6
I0403 02:30:41.372218 23740 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.372239 23740 net.cpp:141] Setting up relu6
I0403 02:30:41.372256 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.372268 23740 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.372282 23740 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.372301 23740 net.cpp:91] Creating Layer drop6
I0403 02:30:41.372316 23740 net.cpp:425] drop6 <- fc6
I0403 02:30:41.372333 23740 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.372370 23740 net.cpp:141] Setting up drop6
I0403 02:30:41.372392 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.372407 23740 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.372421 23740 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.372440 23740 net.cpp:91] Creating Layer fc7
I0403 02:30:41.372454 23740 net.cpp:425] fc7 <- fc6
I0403 02:30:41.372473 23740 net.cpp:399] fc7 -> fc7
I0403 02:30:41.978278 23740 net.cpp:141] Setting up fc7
I0403 02:30:41.978360 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.978377 23740 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.978400 23740 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.978426 23740 net.cpp:91] Creating Layer relu7
I0403 02:30:41.978443 23740 net.cpp:425] relu7 <- fc7
I0403 02:30:41.978463 23740 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.978488 23740 net.cpp:141] Setting up relu7
I0403 02:30:41.978507 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.978523 23740 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.978538 23740 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.978557 23740 net.cpp:91] Creating Layer drop7
I0403 02:30:41.978574 23740 net.cpp:425] drop7 <- fc7
I0403 02:30:41.978590 23740 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.978636 23740 net.cpp:141] Setting up drop7
I0403 02:30:41.978658 23740 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.978673 23740 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.978688 23740 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.978709 23740 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.978725 23740 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.978749 23740 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.985491 23740 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.985524 23740 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.985564 23740 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.985584 23740 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.985605 23740 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.985621 23740 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.985640 23740 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.985661 23740 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.985716 23740 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.985741 23740 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.985757 23740 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.985771 23740 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.985786 23740 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.985807 23740 net.cpp:91] Creating Layer loss
I0403 02:30:41.985826 23740 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.985841 23740 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.985859 23740 net.cpp:399] loss -> loss
I0403 02:30:41.985882 23740 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.985987 23740 net.cpp:141] Setting up loss
I0403 02:30:41.986012 23740 net.cpp:148] Top shape: (1)
I0403 02:30:41.986028 23740 net.cpp:151]     with loss weight 1
I0403 02:30:41.986052 23740 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.986068 23740 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.986089 23740 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.986107 23740 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.986124 23740 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.986145 23740 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.986176 23740 net.cpp:141] Setting up accuracy
I0403 02:30:41.986196 23740 net.cpp:148] Top shape: (1)
I0403 02:30:41.986212 23740 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.986225 23740 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.986240 23740 net.cpp:217] loss needs backward computation.
I0403 02:30:41.986255 23740 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.986270 23740 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.986285 23740 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.986300 23740 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.986315 23740 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.986328 23740 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.986343 23740 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.986358 23740 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.986372 23740 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.986387 23740 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.986402 23740 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.986416 23740 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.986431 23740 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.986446 23740 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.986461 23740 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.986476 23740 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.986491 23740 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.986505 23740 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.986520 23740 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.986534 23740 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.986548 23740 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.986563 23740 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.986577 23740 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.986608 23740 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.986625 23740 net.cpp:219] data does not need backward computation.
I0403 02:30:41.986640 23740 net.cpp:261] This network produces output accuracy
I0403 02:30:41.986656 23740 net.cpp:261] This network produces output loss
I0403 02:30:41.986686 23740 net.cpp:274] Network initialization done.
I0403 02:30:41.986796 23740 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.987326 23740 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.396345 23740 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.396435 23740 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.396474 23740 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.396533 23740 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.831703 23740 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:44.896410 23740 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.901605 23740 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.901675 23740 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:45.901695 23740 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:45.901733 23740 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:46.343824 23740 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:46.385368 23740 net.cpp:753] Ignoring source layer fc8
I0403 02:30:46.412401 23740 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:46.672221 23740 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:49.293299 23740 parallel.cpp:425] Starting Optimization
I0403 02:30:49.293454 23740 solver.cpp:279] Solving 
I0403 02:30:49.293490 23740 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:49.293706 23740 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:32:03.005769 23740 solver.cpp:404]     Test net output #0: accuracy = 0.0203395
I0403 02:32:03.013799 23740 solver.cpp:404]     Test net output #1: loss = 4.05405 (* 1 = 4.05405 loss)
I0403 02:32:03.674492 23740 solver.cpp:228] Iteration 0, loss = 4.65716
I0403 02:32:03.679211 23740 solver.cpp:244]     Train net output #0: loss = 4.65716 (* 1 = 4.65716 loss)
I0403 02:32:03.786046 23740 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:11.277124 23740 solver.cpp:228] Iteration 10, loss = 1.52878
I0403 02:32:11.285151 23740 solver.cpp:244]     Train net output #0: loss = 1.52878 (* 1 = 1.52878 loss)
I0403 02:32:11.488098 23740 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 02:32:18.829358 23740 solver.cpp:228] Iteration 20, loss = 1.02668
I0403 02:32:18.836494 23740 solver.cpp:244]     Train net output #0: loss = 1.02668 (* 1 = 1.02668 loss)
I0403 02:32:19.019523 23740 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 02:32:26.494514 23740 solver.cpp:228] Iteration 30, loss = 0.887615
I0403 02:32:26.500669 23740 solver.cpp:244]     Train net output #0: loss = 0.887615 (* 1 = 0.887615 loss)
I0403 02:32:26.678107 23740 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 02:32:34.048158 23740 solver.cpp:228] Iteration 40, loss = 0.511138
I0403 02:32:34.055516 23740 solver.cpp:244]     Train net output #0: loss = 0.511138 (* 1 = 0.511138 loss)
I0403 02:32:34.245434 23740 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 02:32:41.626257 23740 solver.cpp:228] Iteration 50, loss = 0.357608
I0403 02:32:41.632000 23740 solver.cpp:244]     Train net output #0: loss = 0.357608 (* 1 = 0.357608 loss)
I0403 02:32:41.810341 23740 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 02:32:49.206972 23740 solver.cpp:228] Iteration 60, loss = 0.586918
I0403 02:32:49.213206 23740 solver.cpp:244]     Train net output #0: loss = 0.586918 (* 1 = 0.586918 loss)
I0403 02:32:49.400816 23740 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 02:32:56.773964 23740 solver.cpp:228] Iteration 70, loss = 0.207416
I0403 02:32:56.780025 23740 solver.cpp:244]     Train net output #0: loss = 0.207416 (* 1 = 0.207416 loss)
I0403 02:32:56.974578 23740 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 02:33:04.376127 23740 solver.cpp:228] Iteration 80, loss = 0.469196
I0403 02:33:04.382103 23740 solver.cpp:244]     Train net output #0: loss = 0.469196 (* 1 = 0.469196 loss)
I0403 02:33:04.564263 23740 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:33:11.988780 23740 solver.cpp:228] Iteration 90, loss = 0.439065
I0403 02:33:11.994007 23740 solver.cpp:244]     Train net output #0: loss = 0.439065 (* 1 = 0.439065 loss)
I0403 02:33:12.177175 23740 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 02:33:19.545264 23740 solver.cpp:228] Iteration 100, loss = 0.50039
I0403 02:33:19.552659 23740 solver.cpp:244]     Train net output #0: loss = 0.50039 (* 1 = 0.50039 loss)
I0403 02:33:19.715119 23740 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 02:33:27.216723 23740 solver.cpp:228] Iteration 110, loss = 0.278342
I0403 02:33:27.222898 23740 solver.cpp:244]     Train net output #0: loss = 0.278342 (* 1 = 0.278342 loss)
I0403 02:33:27.377987 23740 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 02:33:34.843222 23740 solver.cpp:228] Iteration 120, loss = 0.224179
I0403 02:33:34.849015 23740 solver.cpp:244]     Train net output #0: loss = 0.224179 (* 1 = 0.224179 loss)
I0403 02:33:35.031554 23740 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 02:33:42.483988 23740 solver.cpp:228] Iteration 130, loss = 0.33
I0403 02:33:42.489878 23740 solver.cpp:244]     Train net output #0: loss = 0.33 (* 1 = 0.33 loss)
I0403 02:33:42.678452 23740 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:33:50.110069 23740 solver.cpp:228] Iteration 140, loss = 0.225136
I0403 02:33:50.115398 23740 solver.cpp:244]     Train net output #0: loss = 0.225136 (* 1 = 0.225136 loss)
I0403 02:33:50.278909 23740 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 02:33:57.767386 23740 solver.cpp:228] Iteration 150, loss = 0.229789
I0403 02:33:57.772548 23740 solver.cpp:244]     Train net output #0: loss = 0.229789 (* 1 = 0.229789 loss)
I0403 02:33:57.964948 23740 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 02:34:05.405156 23740 solver.cpp:228] Iteration 160, loss = 0.223233
I0403 02:34:05.411330 23740 solver.cpp:244]     Train net output #0: loss = 0.223233 (* 1 = 0.223233 loss)
I0403 02:34:05.593063 23740 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:34:12.952008 23740 solver.cpp:228] Iteration 170, loss = 0.160644
I0403 02:34:12.952095 23740 solver.cpp:244]     Train net output #0: loss = 0.160644 (* 1 = 0.160644 loss)
I0403 02:34:13.140166 23740 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 02:34:20.559098 23740 solver.cpp:228] Iteration 180, loss = 0.310513
I0403 02:34:20.565956 23740 solver.cpp:244]     Train net output #0: loss = 0.310513 (* 1 = 0.310513 loss)
I0403 02:34:20.747377 23740 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 02:34:28.106298 23740 solver.cpp:228] Iteration 190, loss = 0.0646566
I0403 02:34:28.111189 23740 solver.cpp:244]     Train net output #0: loss = 0.0646566 (* 1 = 0.0646566 loss)
I0403 02:34:28.317680 23740 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 02:34:35.653872 23740 solver.cpp:228] Iteration 200, loss = 0.348218
I0403 02:34:35.660583 23740 solver.cpp:244]     Train net output #0: loss = 0.348218 (* 1 = 0.348218 loss)
I0403 02:34:35.854244 23740 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 02:34:43.224016 23740 solver.cpp:228] Iteration 210, loss = 0.300717
I0403 02:34:43.229733 23740 solver.cpp:244]     Train net output #0: loss = 0.300717 (* 1 = 0.300717 loss)
I0403 02:34:43.427314 23740 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:34:49.473588 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_219.caffemodel
I0403 02:34:52.420488 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_219.solverstate
I0403 02:34:54.312937 23740 solver.cpp:337] Iteration 219, Testing net (#0)
I0403 02:36:08.006429 23740 solver.cpp:404]     Test net output #0: accuracy = 0.919444
I0403 02:36:08.013480 23740 solver.cpp:404]     Test net output #1: loss = 0.252138 (* 1 = 0.252138 loss)
I0403 02:36:09.336819 23740 solver.cpp:228] Iteration 220, loss = 0.370616
I0403 02:36:09.341418 23740 solver.cpp:244]     Train net output #0: loss = 0.370616 (* 1 = 0.370616 loss)
I0403 02:36:09.543289 23740 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 02:36:16.907989 23740 solver.cpp:228] Iteration 230, loss = 0.281571
I0403 02:36:16.913414 23740 solver.cpp:244]     Train net output #0: loss = 0.281571 (* 1 = 0.281571 loss)
I0403 02:36:17.124555 23740 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 02:36:24.580389 23740 solver.cpp:228] Iteration 240, loss = 0.160122
I0403 02:36:24.585129 23740 solver.cpp:244]     Train net output #0: loss = 0.160122 (* 1 = 0.160122 loss)
I0403 02:36:24.770261 23740 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:36:32.120236 23740 solver.cpp:228] Iteration 250, loss = 0.125318
I0403 02:36:32.126986 23740 solver.cpp:244]     Train net output #0: loss = 0.125318 (* 1 = 0.125318 loss)
I0403 02:36:32.307411 23740 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 02:36:39.794082 23740 solver.cpp:228] Iteration 260, loss = 0.188649
I0403 02:36:39.800261 23740 solver.cpp:244]     Train net output #0: loss = 0.188649 (* 1 = 0.188649 loss)
I0403 02:36:40.061167 23740 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:36:47.487460 23740 solver.cpp:228] Iteration 270, loss = 0.143051
I0403 02:36:47.493904 23740 solver.cpp:244]     Train net output #0: loss = 0.143051 (* 1 = 0.143051 loss)
I0403 02:36:47.694895 23740 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 02:36:55.161183 23740 solver.cpp:228] Iteration 280, loss = 0.0582773
I0403 02:36:55.166584 23740 solver.cpp:244]     Train net output #0: loss = 0.0582773 (* 1 = 0.0582773 loss)
I0403 02:36:55.355389 23740 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 02:37:02.779144 23740 solver.cpp:228] Iteration 290, loss = 0.226362
I0403 02:37:02.785579 23740 solver.cpp:244]     Train net output #0: loss = 0.226362 (* 1 = 0.226362 loss)
I0403 02:37:02.966342 23740 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 02:37:10.439213 23740 solver.cpp:228] Iteration 300, loss = 0.123234
I0403 02:37:10.446274 23740 solver.cpp:244]     Train net output #0: loss = 0.123234 (* 1 = 0.123234 loss)
I0403 02:37:10.562834 23740 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 02:37:18.056319 23740 solver.cpp:228] Iteration 310, loss = 0.105246
I0403 02:37:18.062829 23740 solver.cpp:244]     Train net output #0: loss = 0.105247 (* 1 = 0.105247 loss)
I0403 02:37:18.277762 23740 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 02:37:25.677670 23740 solver.cpp:228] Iteration 320, loss = 0.175553
I0403 02:37:25.685080 23740 solver.cpp:244]     Train net output #0: loss = 0.175553 (* 1 = 0.175553 loss)
I0403 02:37:25.886101 23740 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:37:33.206486 23740 solver.cpp:228] Iteration 330, loss = 0.167934
I0403 02:37:33.212512 23740 solver.cpp:244]     Train net output #0: loss = 0.167934 (* 1 = 0.167934 loss)
I0403 02:37:33.420980 23740 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 02:37:40.855376 23740 solver.cpp:228] Iteration 340, loss = 0.119243
I0403 02:37:40.861824 23740 solver.cpp:244]     Train net output #0: loss = 0.119243 (* 1 = 0.119243 loss)
I0403 02:37:41.045457 23740 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 02:37:48.449215 23740 solver.cpp:228] Iteration 350, loss = 0.0342705
I0403 02:37:48.454809 23740 solver.cpp:244]     Train net output #0: loss = 0.0342705 (* 1 = 0.0342705 loss)
I0403 02:37:48.644266 23740 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 02:37:56.052736 23740 solver.cpp:228] Iteration 360, loss = 0.216761
I0403 02:37:56.052837 23740 solver.cpp:244]     Train net output #0: loss = 0.216761 (* 1 = 0.216761 loss)
I0403 02:37:56.258986 23740 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 02:38:03.769314 23740 solver.cpp:228] Iteration 370, loss = 0.194154
I0403 02:38:03.769397 23740 solver.cpp:244]     Train net output #0: loss = 0.194154 (* 1 = 0.194154 loss)
I0403 02:38:03.961141 23740 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 02:38:11.348501 23740 solver.cpp:228] Iteration 380, loss = 0.171967
I0403 02:38:11.353938 23740 solver.cpp:244]     Train net output #0: loss = 0.171967 (* 1 = 0.171967 loss)
I0403 02:38:11.550186 23740 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 02:38:18.914445 23740 solver.cpp:228] Iteration 390, loss = 0.115675
I0403 02:38:18.920959 23740 solver.cpp:244]     Train net output #0: loss = 0.115675 (* 1 = 0.115675 loss)
I0403 02:38:19.101469 23740 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:38:26.564635 23740 solver.cpp:228] Iteration 400, loss = 0.105467
I0403 02:38:26.570004 23740 solver.cpp:244]     Train net output #0: loss = 0.105467 (* 1 = 0.105467 loss)
I0403 02:38:26.744799 23740 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:38:34.176281 23740 solver.cpp:228] Iteration 410, loss = 0.0300726
I0403 02:38:34.182607 23740 solver.cpp:244]     Train net output #0: loss = 0.0300726 (* 1 = 0.0300726 loss)
I0403 02:38:34.363739 23740 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 02:38:41.967571 23740 solver.cpp:228] Iteration 420, loss = 0.0647679
I0403 02:38:41.967854 23740 solver.cpp:244]     Train net output #0: loss = 0.064768 (* 1 = 0.064768 loss)
I0403 02:38:42.209735 23740 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:38:49.613804 23740 solver.cpp:228] Iteration 430, loss = 0.0638677
I0403 02:38:49.613909 23740 solver.cpp:244]     Train net output #0: loss = 0.0638678 (* 1 = 0.0638678 loss)
I0403 02:38:49.828696 23740 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 02:38:55.366353 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_438.caffemodel
I0403 02:38:58.148897 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_438.solverstate
I0403 02:39:00.010774 23740 solver.cpp:337] Iteration 438, Testing net (#0)
I0403 02:40:13.707278 23740 solver.cpp:404]     Test net output #0: accuracy = 0.954414
I0403 02:40:13.707602 23740 solver.cpp:404]     Test net output #1: loss = 0.148107 (* 1 = 0.148107 loss)
I0403 02:40:15.796301 23740 solver.cpp:228] Iteration 440, loss = 0.109274
I0403 02:40:15.796385 23740 solver.cpp:244]     Train net output #0: loss = 0.109274 (* 1 = 0.109274 loss)
I0403 02:40:15.973639 23740 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 02:40:23.398408 23740 solver.cpp:228] Iteration 450, loss = 0.0435254
I0403 02:40:23.398506 23740 solver.cpp:244]     Train net output #0: loss = 0.0435254 (* 1 = 0.0435254 loss)
I0403 02:40:23.622223 23740 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 02:40:31.139590 23740 solver.cpp:228] Iteration 460, loss = 0.0154641
I0403 02:40:31.139686 23740 solver.cpp:244]     Train net output #0: loss = 0.0154642 (* 1 = 0.0154642 loss)
I0403 02:40:31.336882 23740 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 02:40:38.768332 23740 solver.cpp:228] Iteration 470, loss = 0.132446
I0403 02:40:38.774510 23740 solver.cpp:244]     Train net output #0: loss = 0.132446 (* 1 = 0.132446 loss)
I0403 02:40:38.934209 23740 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 02:40:46.403213 23740 solver.cpp:228] Iteration 480, loss = 0.054267
I0403 02:40:46.410171 23740 solver.cpp:244]     Train net output #0: loss = 0.054267 (* 1 = 0.054267 loss)
I0403 02:40:46.614018 23740 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:40:53.969005 23740 solver.cpp:228] Iteration 490, loss = 0.15424
I0403 02:40:53.975014 23740 solver.cpp:244]     Train net output #0: loss = 0.15424 (* 1 = 0.15424 loss)
I0403 02:40:54.165431 23740 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 02:41:01.756902 23740 solver.cpp:228] Iteration 500, loss = 0.0749356
I0403 02:41:01.762838 23740 solver.cpp:244]     Train net output #0: loss = 0.0749356 (* 1 = 0.0749356 loss)
I0403 02:41:01.922907 23740 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 02:41:09.296988 23740 solver.cpp:228] Iteration 510, loss = 0.0304557
I0403 02:41:09.301520 23740 solver.cpp:244]     Train net output #0: loss = 0.0304558 (* 1 = 0.0304558 loss)
I0403 02:41:09.494168 23740 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 02:41:16.868669 23740 solver.cpp:228] Iteration 520, loss = 0.0475487
I0403 02:41:16.874073 23740 solver.cpp:244]     Train net output #0: loss = 0.0475487 (* 1 = 0.0475487 loss)
I0403 02:41:17.057909 23740 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:41:24.496898 23740 solver.cpp:228] Iteration 530, loss = 0.111553
I0403 02:41:24.503486 23740 solver.cpp:244]     Train net output #0: loss = 0.111553 (* 1 = 0.111553 loss)
I0403 02:41:24.686893 23740 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 02:41:32.223412 23740 solver.cpp:228] Iteration 540, loss = 0.00859176
I0403 02:41:32.228946 23740 solver.cpp:244]     Train net output #0: loss = 0.00859177 (* 1 = 0.00859177 loss)
I0403 02:41:32.411624 23740 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 02:41:39.840497 23740 solver.cpp:228] Iteration 550, loss = 0.107965
I0403 02:41:39.845973 23740 solver.cpp:244]     Train net output #0: loss = 0.107965 (* 1 = 0.107965 loss)
I0403 02:41:40.037189 23740 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 02:41:47.434743 23740 solver.cpp:228] Iteration 560, loss = 0.0527349
I0403 02:41:47.440762 23740 solver.cpp:244]     Train net output #0: loss = 0.0527349 (* 1 = 0.0527349 loss)
I0403 02:41:47.635525 23740 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:41:55.001384 23740 solver.cpp:228] Iteration 570, loss = 0.0379134
I0403 02:41:55.007426 23740 solver.cpp:244]     Train net output #0: loss = 0.0379134 (* 1 = 0.0379134 loss)
I0403 02:41:55.241364 23740 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 02:42:02.770795 23740 solver.cpp:228] Iteration 580, loss = 0.102187
I0403 02:42:02.775916 23740 solver.cpp:244]     Train net output #0: loss = 0.102187 (* 1 = 0.102187 loss)
I0403 02:42:02.974977 23740 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 02:42:10.580030 23740 solver.cpp:228] Iteration 590, loss = 0.0491442
I0403 02:42:10.585747 23740 solver.cpp:244]     Train net output #0: loss = 0.0491442 (* 1 = 0.0491442 loss)
I0403 02:42:10.727617 23740 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 02:42:18.248036 23740 solver.cpp:228] Iteration 600, loss = 0.0727944
I0403 02:42:18.254634 23740 solver.cpp:244]     Train net output #0: loss = 0.0727944 (* 1 = 0.0727944 loss)
I0403 02:42:18.438715 23740 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 02:42:25.768298 23740 solver.cpp:228] Iteration 610, loss = 0.0836231
I0403 02:42:25.773098 23740 solver.cpp:244]     Train net output #0: loss = 0.0836231 (* 1 = 0.0836231 loss)
I0403 02:42:25.967303 23740 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 02:42:33.338253 23740 solver.cpp:228] Iteration 620, loss = 0.129316
I0403 02:42:33.344264 23740 solver.cpp:244]     Train net output #0: loss = 0.129316 (* 1 = 0.129316 loss)
I0403 02:42:33.521694 23740 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 02:42:40.997306 23740 solver.cpp:228] Iteration 630, loss = 0.0872357
I0403 02:42:41.003403 23740 solver.cpp:244]     Train net output #0: loss = 0.0872357 (* 1 = 0.0872357 loss)
I0403 02:42:41.186455 23740 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:42:48.623580 23740 solver.cpp:228] Iteration 640, loss = 0.129501
I0403 02:42:48.629596 23740 solver.cpp:244]     Train net output #0: loss = 0.129501 (* 1 = 0.129501 loss)
I0403 02:42:48.823788 23740 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:42:56.190099 23740 solver.cpp:228] Iteration 650, loss = 0.0766028
I0403 02:42:56.197412 23740 solver.cpp:244]     Train net output #0: loss = 0.0766028 (* 1 = 0.0766028 loss)
I0403 02:42:56.367192 23740 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:43:00.961231 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_657.caffemodel
I0403 02:43:03.732830 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_657.solverstate
I0403 02:43:05.639891 23740 solver.cpp:337] Iteration 657, Testing net (#0)
I0403 02:44:19.354295 23740 solver.cpp:404]     Test net output #0: accuracy = 0.951081
I0403 02:44:19.361075 23740 solver.cpp:404]     Test net output #1: loss = 0.164675 (* 1 = 0.164675 loss)
I0403 02:44:22.224426 23740 solver.cpp:228] Iteration 660, loss = 0.059957
I0403 02:44:22.230084 23740 solver.cpp:244]     Train net output #0: loss = 0.059957 (* 1 = 0.059957 loss)
I0403 02:44:22.406690 23740 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 02:44:29.778153 23740 solver.cpp:228] Iteration 670, loss = 0.0737544
I0403 02:44:29.784036 23740 solver.cpp:244]     Train net output #0: loss = 0.0737544 (* 1 = 0.0737544 loss)
I0403 02:44:29.965494 23740 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 02:44:37.333156 23740 solver.cpp:228] Iteration 680, loss = 0.0886729
I0403 02:44:37.339759 23740 solver.cpp:244]     Train net output #0: loss = 0.0886729 (* 1 = 0.0886729 loss)
I0403 02:44:37.555058 23740 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 02:44:45.023447 23740 solver.cpp:228] Iteration 690, loss = 0.0575497
I0403 02:44:45.029687 23740 solver.cpp:244]     Train net output #0: loss = 0.0575497 (* 1 = 0.0575497 loss)
I0403 02:44:45.195209 23740 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 02:44:52.614348 23740 solver.cpp:228] Iteration 700, loss = 0.0492694
I0403 02:44:52.621150 23740 solver.cpp:244]     Train net output #0: loss = 0.0492694 (* 1 = 0.0492694 loss)
I0403 02:44:52.836612 23740 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 02:45:00.461228 23740 solver.cpp:228] Iteration 710, loss = 0.0758525
I0403 02:45:00.466809 23740 solver.cpp:244]     Train net output #0: loss = 0.0758525 (* 1 = 0.0758525 loss)
I0403 02:45:00.660302 23740 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 02:45:08.018934 23740 solver.cpp:228] Iteration 720, loss = 0.0590972
I0403 02:45:08.024747 23740 solver.cpp:244]     Train net output #0: loss = 0.0590972 (* 1 = 0.0590972 loss)
I0403 02:45:08.220944 23740 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:45:15.657253 23740 solver.cpp:228] Iteration 730, loss = 0.0505747
I0403 02:45:15.663476 23740 solver.cpp:244]     Train net output #0: loss = 0.0505746 (* 1 = 0.0505746 loss)
I0403 02:45:15.856627 23740 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 02:45:23.263734 23740 solver.cpp:228] Iteration 740, loss = 0.0347756
I0403 02:45:23.268823 23740 solver.cpp:244]     Train net output #0: loss = 0.0347756 (* 1 = 0.0347756 loss)
I0403 02:45:23.490514 23740 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 02:45:30.921682 23740 solver.cpp:228] Iteration 750, loss = 0.0432619
I0403 02:45:30.927862 23740 solver.cpp:244]     Train net output #0: loss = 0.0432619 (* 1 = 0.0432619 loss)
I0403 02:45:31.134052 23740 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 02:45:38.488703 23740 solver.cpp:228] Iteration 760, loss = 0.0942495
I0403 02:45:38.493363 23740 solver.cpp:244]     Train net output #0: loss = 0.0942495 (* 1 = 0.0942495 loss)
I0403 02:45:38.685273 23740 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 02:45:46.079147 23740 solver.cpp:228] Iteration 770, loss = 0.0132698
I0403 02:45:46.084841 23740 solver.cpp:244]     Train net output #0: loss = 0.0132698 (* 1 = 0.0132698 loss)
I0403 02:45:46.360663 23740 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 02:45:53.728498 23740 solver.cpp:228] Iteration 780, loss = 0.0825723
I0403 02:45:53.736450 23740 solver.cpp:244]     Train net output #0: loss = 0.0825723 (* 1 = 0.0825723 loss)
I0403 02:45:53.918375 23740 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:46:01.279022 23740 solver.cpp:228] Iteration 790, loss = 0.0597197
I0403 02:46:01.283777 23740 solver.cpp:244]     Train net output #0: loss = 0.0597197 (* 1 = 0.0597197 loss)
I0403 02:46:01.458907 23740 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 02:46:08.812391 23740 solver.cpp:228] Iteration 800, loss = 0.0754891
I0403 02:46:08.816885 23740 solver.cpp:244]     Train net output #0: loss = 0.0754892 (* 1 = 0.0754892 loss)
I0403 02:46:09.017601 23740 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:46:16.397302 23740 solver.cpp:228] Iteration 810, loss = 0.04972
I0403 02:46:16.403818 23740 solver.cpp:244]     Train net output #0: loss = 0.04972 (* 1 = 0.04972 loss)
I0403 02:46:16.589134 23740 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 02:46:23.956591 23740 solver.cpp:228] Iteration 820, loss = 0.0977856
I0403 02:46:23.962769 23740 solver.cpp:244]     Train net output #0: loss = 0.0977856 (* 1 = 0.0977856 loss)
I0403 02:46:24.143590 23740 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 02:46:31.629568 23740 solver.cpp:228] Iteration 830, loss = 0.0277249
I0403 02:46:31.636031 23740 solver.cpp:244]     Train net output #0: loss = 0.0277249 (* 1 = 0.0277249 loss)
I0403 02:46:31.824450 23740 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 02:46:39.340078 23740 solver.cpp:228] Iteration 840, loss = 0.0713576
I0403 02:46:39.345974 23740 solver.cpp:244]     Train net output #0: loss = 0.0713576 (* 1 = 0.0713576 loss)
I0403 02:46:39.523782 23740 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:46:46.870182 23740 solver.cpp:228] Iteration 850, loss = 0.0671354
I0403 02:46:46.876662 23740 solver.cpp:244]     Train net output #0: loss = 0.0671355 (* 1 = 0.0671355 loss)
I0403 02:46:47.048527 23740 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 02:46:54.410671 23740 solver.cpp:228] Iteration 860, loss = 0.0120018
I0403 02:46:54.416685 23740 solver.cpp:244]     Train net output #0: loss = 0.0120019 (* 1 = 0.0120019 loss)
I0403 02:46:54.588146 23740 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 02:47:02.015301 23740 solver.cpp:228] Iteration 870, loss = 0.0644209
I0403 02:47:02.021363 23740 solver.cpp:244]     Train net output #0: loss = 0.0644209 (* 1 = 0.0644209 loss)
I0403 02:47:02.198618 23740 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 02:47:06.076153 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_876.caffemodel
I0403 02:47:08.864537 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_876.solverstate
I0403 02:47:10.786628 23740 solver.cpp:337] Iteration 876, Testing net (#0)
I0403 02:48:24.490172 23740 solver.cpp:404]     Test net output #0: accuracy = 0.972594
I0403 02:48:24.499783 23740 solver.cpp:404]     Test net output #1: loss = 0.0890829 (* 1 = 0.0890829 loss)
I0403 02:48:28.038053 23740 solver.cpp:228] Iteration 880, loss = 0.042613
I0403 02:48:28.045027 23740 solver.cpp:244]     Train net output #0: loss = 0.042613 (* 1 = 0.042613 loss)
I0403 02:48:28.247120 23740 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:48:35.588958 23740 solver.cpp:228] Iteration 890, loss = 0.107171
I0403 02:48:35.595515 23740 solver.cpp:244]     Train net output #0: loss = 0.107171 (* 1 = 0.107171 loss)
I0403 02:48:35.776576 23740 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 02:48:43.146666 23740 solver.cpp:228] Iteration 900, loss = 0.0201219
I0403 02:48:43.152901 23740 solver.cpp:244]     Train net output #0: loss = 0.0201219 (* 1 = 0.0201219 loss)
I0403 02:48:43.335157 23740 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 02:48:50.863155 23740 solver.cpp:228] Iteration 910, loss = 0.0182308
I0403 02:48:50.869712 23740 solver.cpp:244]     Train net output #0: loss = 0.0182309 (* 1 = 0.0182309 loss)
I0403 02:48:51.055430 23740 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:48:58.404187 23740 solver.cpp:228] Iteration 920, loss = 0.0436162
I0403 02:48:58.410362 23740 solver.cpp:244]     Train net output #0: loss = 0.0436162 (* 1 = 0.0436162 loss)
I0403 02:48:58.586963 23740 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 02:49:06.033704 23740 solver.cpp:228] Iteration 930, loss = 0.0172859
I0403 02:49:06.040810 23740 solver.cpp:244]     Train net output #0: loss = 0.017286 (* 1 = 0.017286 loss)
I0403 02:49:06.228160 23740 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 02:49:13.623991 23740 solver.cpp:228] Iteration 940, loss = 0.00522547
I0403 02:49:13.630822 23740 solver.cpp:244]     Train net output #0: loss = 0.00522553 (* 1 = 0.00522553 loss)
I0403 02:49:13.815706 23740 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 02:49:21.172615 23740 solver.cpp:228] Iteration 950, loss = 0.0291549
I0403 02:49:21.179214 23740 solver.cpp:244]     Train net output #0: loss = 0.029155 (* 1 = 0.029155 loss)
I0403 02:49:21.362433 23740 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 02:49:28.767204 23740 solver.cpp:228] Iteration 960, loss = 0.0451107
I0403 02:49:28.773414 23740 solver.cpp:244]     Train net output #0: loss = 0.0451107 (* 1 = 0.0451107 loss)
I0403 02:49:28.938689 23740 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:49:36.575088 23740 solver.cpp:228] Iteration 970, loss = 0.0924497
I0403 02:49:36.581068 23740 solver.cpp:244]     Train net output #0: loss = 0.0924498 (* 1 = 0.0924498 loss)
I0403 02:49:36.756646 23740 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 02:49:44.172588 23740 solver.cpp:228] Iteration 980, loss = 0.0513502
I0403 02:49:44.178212 23740 solver.cpp:244]     Train net output #0: loss = 0.0513502 (* 1 = 0.0513502 loss)
I0403 02:49:44.358331 23740 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 02:49:51.975689 23740 solver.cpp:228] Iteration 990, loss = 0.0316819
I0403 02:49:51.981544 23740 solver.cpp:244]     Train net output #0: loss = 0.0316819 (* 1 = 0.0316819 loss)
I0403 02:49:52.157037 23740 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 02:49:59.628096 23740 solver.cpp:228] Iteration 1000, loss = 0.0490405
I0403 02:49:59.634816 23740 solver.cpp:244]     Train net output #0: loss = 0.0490405 (* 1 = 0.0490405 loss)
I0403 02:49:59.823693 23740 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 02:50:07.200258 23740 solver.cpp:228] Iteration 1010, loss = 0.0141544
I0403 02:50:07.206472 23740 solver.cpp:244]     Train net output #0: loss = 0.0141545 (* 1 = 0.0141545 loss)
I0403 02:50:07.420956 23740 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 02:50:14.757510 23740 solver.cpp:228] Iteration 1020, loss = 0.0113603
I0403 02:50:14.764621 23740 solver.cpp:244]     Train net output #0: loss = 0.0113604 (* 1 = 0.0113604 loss)
I0403 02:50:14.935428 23740 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 02:50:22.376158 23740 solver.cpp:228] Iteration 1030, loss = 0.0360943
I0403 02:50:22.382833 23740 solver.cpp:244]     Train net output #0: loss = 0.0360944 (* 1 = 0.0360944 loss)
I0403 02:50:22.610859 23740 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 02:50:29.996888 23740 solver.cpp:228] Iteration 1040, loss = 0.0196927
I0403 02:50:30.003134 23740 solver.cpp:244]     Train net output #0: loss = 0.0196928 (* 1 = 0.0196928 loss)
I0403 02:50:30.190455 23740 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:50:37.757330 23740 solver.cpp:228] Iteration 1050, loss = 0.0153023
I0403 02:50:37.763001 23740 solver.cpp:244]     Train net output #0: loss = 0.0153023 (* 1 = 0.0153023 loss)
I0403 02:50:37.960993 23740 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 02:50:45.405704 23740 solver.cpp:228] Iteration 1060, loss = 0.0270345
I0403 02:50:45.411638 23740 solver.cpp:244]     Train net output #0: loss = 0.0270346 (* 1 = 0.0270346 loss)
I0403 02:50:45.614511 23740 sgd_solver.cpp:106] Iteration 1060, lr = 0.005
I0403 02:50:53.017599 23740 solver.cpp:228] Iteration 1070, loss = 0.0623193
I0403 02:50:53.023219 23740 solver.cpp:244]     Train net output #0: loss = 0.0623194 (* 1 = 0.0623194 loss)
I0403 02:50:53.227510 23740 sgd_solver.cpp:106] Iteration 1070, lr = 0.005
I0403 02:51:00.655381 23740 solver.cpp:228] Iteration 1080, loss = 0.0680193
I0403 02:51:00.662021 23740 solver.cpp:244]     Train net output #0: loss = 0.0680194 (* 1 = 0.0680194 loss)
I0403 02:51:00.851111 23740 sgd_solver.cpp:106] Iteration 1080, lr = 0.005
I0403 02:51:08.219408 23740 solver.cpp:228] Iteration 1090, loss = 0.00562441
I0403 02:51:08.225766 23740 solver.cpp:244]     Train net output #0: loss = 0.00562445 (* 1 = 0.00562445 loss)
I0403 02:51:08.408521 23740 sgd_solver.cpp:106] Iteration 1090, lr = 0.005
I0403 02:51:11.458456 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1095.caffemodel
I0403 02:51:14.324412 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1095.solverstate
I0403 02:51:16.232195 23740 solver.cpp:337] Iteration 1095, Testing net (#0)
I0403 02:52:29.955875 23740 solver.cpp:404]     Test net output #0: accuracy = 0.971297
I0403 02:52:29.964252 23740 solver.cpp:404]     Test net output #1: loss = 0.09857 (* 1 = 0.09857 loss)
I0403 02:52:34.323848 23740 solver.cpp:228] Iteration 1100, loss = 0.0564131
I0403 02:52:34.329852 23740 solver.cpp:244]     Train net output #0: loss = 0.0564132 (* 1 = 0.0564132 loss)
I0403 02:52:34.536406 23740 sgd_solver.cpp:106] Iteration 1100, lr = 0.005
I0403 02:52:41.904315 23740 solver.cpp:228] Iteration 1110, loss = 0.0211514
I0403 02:52:41.910331 23740 solver.cpp:244]     Train net output #0: loss = 0.0211515 (* 1 = 0.0211515 loss)
I0403 02:52:42.094621 23740 sgd_solver.cpp:106] Iteration 1110, lr = 0.005
I0403 02:52:49.535473 23740 solver.cpp:228] Iteration 1120, loss = 0.0129003
I0403 02:52:49.541554 23740 solver.cpp:244]     Train net output #0: loss = 0.0129003 (* 1 = 0.0129003 loss)
I0403 02:52:49.731611 23740 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 02:52:57.099083 23740 solver.cpp:228] Iteration 1130, loss = 0.0174154
I0403 02:52:57.105226 23740 solver.cpp:244]     Train net output #0: loss = 0.0174154 (* 1 = 0.0174154 loss)
I0403 02:52:57.266265 23740 sgd_solver.cpp:106] Iteration 1130, lr = 0.005
I0403 02:53:04.719949 23740 solver.cpp:228] Iteration 1140, loss = 0.0388451
I0403 02:53:04.726793 23740 solver.cpp:244]     Train net output #0: loss = 0.0388451 (* 1 = 0.0388451 loss)
I0403 02:53:04.912868 23740 sgd_solver.cpp:106] Iteration 1140, lr = 0.005
I0403 02:53:12.396427 23740 solver.cpp:228] Iteration 1150, loss = 0.00782529
I0403 02:53:12.402716 23740 solver.cpp:244]     Train net output #0: loss = 0.00782534 (* 1 = 0.00782534 loss)
I0403 02:53:12.610262 23740 sgd_solver.cpp:106] Iteration 1150, lr = 0.005
I0403 02:53:20.047209 23740 solver.cpp:228] Iteration 1160, loss = 0.00552794
I0403 02:53:20.054443 23740 solver.cpp:244]     Train net output #0: loss = 0.00552798 (* 1 = 0.00552798 loss)
I0403 02:53:20.235537 23740 sgd_solver.cpp:106] Iteration 1160, lr = 0.005
I0403 02:53:27.596750 23740 solver.cpp:228] Iteration 1170, loss = 0.0074735
I0403 02:53:27.602717 23740 solver.cpp:244]     Train net output #0: loss = 0.00747354 (* 1 = 0.00747354 loss)
I0403 02:53:27.817451 23740 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 02:53:35.264072 23740 solver.cpp:228] Iteration 1180, loss = 0.0566061
I0403 02:53:35.270633 23740 solver.cpp:244]     Train net output #0: loss = 0.0566061 (* 1 = 0.0566061 loss)
I0403 02:53:35.450356 23740 sgd_solver.cpp:106] Iteration 1180, lr = 0.005
I0403 02:53:42.924362 23740 solver.cpp:228] Iteration 1190, loss = 0.0101544
I0403 02:53:42.931772 23740 solver.cpp:244]     Train net output #0: loss = 0.0101545 (* 1 = 0.0101545 loss)
I0403 02:53:43.184792 23740 sgd_solver.cpp:106] Iteration 1190, lr = 0.005
I0403 02:53:50.538552 23740 solver.cpp:228] Iteration 1200, loss = 0.0475406
I0403 02:53:50.545629 23740 solver.cpp:244]     Train net output #0: loss = 0.0475406 (* 1 = 0.0475406 loss)
I0403 02:53:50.734658 23740 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 02:53:58.266338 23740 solver.cpp:228] Iteration 1210, loss = 0.0431574
I0403 02:53:58.273592 23740 solver.cpp:244]     Train net output #0: loss = 0.0431574 (* 1 = 0.0431574 loss)
I0403 02:53:58.434219 23740 sgd_solver.cpp:106] Iteration 1210, lr = 0.005
I0403 02:54:06.024490 23740 solver.cpp:228] Iteration 1220, loss = 0.0781865
I0403 02:54:06.030257 23740 solver.cpp:244]     Train net output #0: loss = 0.0781866 (* 1 = 0.0781866 loss)
I0403 02:54:06.226379 23740 sgd_solver.cpp:106] Iteration 1220, lr = 0.005
I0403 02:54:13.659675 23740 solver.cpp:228] Iteration 1230, loss = 0.0109083
I0403 02:54:13.664815 23740 solver.cpp:244]     Train net output #0: loss = 0.0109083 (* 1 = 0.0109083 loss)
I0403 02:54:13.850152 23740 sgd_solver.cpp:106] Iteration 1230, lr = 0.005
I0403 02:54:21.516610 23740 solver.cpp:228] Iteration 1240, loss = 0.0255465
I0403 02:54:21.522219 23740 solver.cpp:244]     Train net output #0: loss = 0.0255466 (* 1 = 0.0255466 loss)
I0403 02:54:21.697741 23740 sgd_solver.cpp:106] Iteration 1240, lr = 0.005
I0403 02:54:29.290817 23740 solver.cpp:228] Iteration 1250, loss = 0.0843117
I0403 02:54:29.296931 23740 solver.cpp:244]     Train net output #0: loss = 0.0843117 (* 1 = 0.0843117 loss)
I0403 02:54:29.406998 23740 sgd_solver.cpp:106] Iteration 1250, lr = 0.005
I0403 02:54:36.993921 23740 solver.cpp:228] Iteration 1260, loss = 0.00363036
I0403 02:54:36.999253 23740 solver.cpp:244]     Train net output #0: loss = 0.00363042 (* 1 = 0.00363042 loss)
I0403 02:54:37.176723 23740 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 02:54:44.538841 23740 solver.cpp:228] Iteration 1270, loss = 0.0043925
I0403 02:54:44.545281 23740 solver.cpp:244]     Train net output #0: loss = 0.00439255 (* 1 = 0.00439255 loss)
I0403 02:54:44.742532 23740 sgd_solver.cpp:106] Iteration 1270, lr = 0.005
I0403 02:54:52.142402 23740 solver.cpp:228] Iteration 1280, loss = 0.0380764
I0403 02:54:52.148988 23740 solver.cpp:244]     Train net output #0: loss = 0.0380764 (* 1 = 0.0380764 loss)
I0403 02:54:52.346782 23740 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 02:54:59.774014 23740 solver.cpp:228] Iteration 1290, loss = 0.0290326
I0403 02:54:59.781399 23740 solver.cpp:244]     Train net output #0: loss = 0.0290326 (* 1 = 0.0290326 loss)
I0403 02:54:59.959967 23740 sgd_solver.cpp:106] Iteration 1290, lr = 0.005
I0403 02:55:07.396966 23740 solver.cpp:228] Iteration 1300, loss = 0.0517811
I0403 02:55:07.403304 23740 solver.cpp:244]     Train net output #0: loss = 0.0517811 (* 1 = 0.0517811 loss)
I0403 02:55:07.563990 23740 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 02:55:15.390766 23740 solver.cpp:228] Iteration 1310, loss = 0.00511839
I0403 02:55:15.398041 23740 solver.cpp:244]     Train net output #0: loss = 0.00511844 (* 1 = 0.00511844 loss)
I0403 02:55:15.547596 23740 sgd_solver.cpp:106] Iteration 1310, lr = 0.005
I0403 02:55:17.888182 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1314.caffemodel
I0403 02:55:20.710280 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1314.solverstate
I0403 02:55:22.614919 23740 solver.cpp:337] Iteration 1314, Testing net (#0)
I0403 02:56:36.325734 23740 solver.cpp:404]     Test net output #0: accuracy = 0.969846
I0403 02:56:36.334239 23740 solver.cpp:404]     Test net output #1: loss = 0.104124 (* 1 = 0.104124 loss)
I0403 02:56:41.448516 23740 solver.cpp:228] Iteration 1320, loss = 0.0194269
I0403 02:56:41.455338 23740 solver.cpp:244]     Train net output #0: loss = 0.019427 (* 1 = 0.019427 loss)
I0403 02:56:41.627586 23740 sgd_solver.cpp:106] Iteration 1320, lr = 0.005
I0403 02:56:49.245326 23740 solver.cpp:228] Iteration 1330, loss = 0.0172541
I0403 02:56:49.251986 23740 solver.cpp:244]     Train net output #0: loss = 0.0172541 (* 1 = 0.0172541 loss)
I0403 02:56:49.401335 23740 sgd_solver.cpp:106] Iteration 1330, lr = 0.005
I0403 02:56:56.951984 23740 solver.cpp:228] Iteration 1340, loss = 0.0041127
I0403 02:56:56.958580 23740 solver.cpp:244]     Train net output #0: loss = 0.00411275 (* 1 = 0.00411275 loss)
I0403 02:56:57.147733 23740 sgd_solver.cpp:106] Iteration 1340, lr = 0.005
I0403 02:57:04.535063 23740 solver.cpp:228] Iteration 1350, loss = 0.00988352
I0403 02:57:04.541708 23740 solver.cpp:244]     Train net output #0: loss = 0.00988357 (* 1 = 0.00988357 loss)
I0403 02:57:04.720922 23740 sgd_solver.cpp:106] Iteration 1350, lr = 0.005
I0403 02:57:12.104254 23740 solver.cpp:228] Iteration 1360, loss = 0.0492417
I0403 02:57:12.110774 23740 solver.cpp:244]     Train net output #0: loss = 0.0492418 (* 1 = 0.0492418 loss)
I0403 02:57:12.291595 23740 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 02:57:19.718024 23740 solver.cpp:228] Iteration 1370, loss = 0.062921
I0403 02:57:19.723887 23740 solver.cpp:244]     Train net output #0: loss = 0.062921 (* 1 = 0.062921 loss)
I0403 02:57:19.930528 23740 sgd_solver.cpp:106] Iteration 1370, lr = 0.005
I0403 02:57:27.284626 23740 solver.cpp:228] Iteration 1380, loss = 0.0454577
I0403 02:57:27.290367 23740 solver.cpp:244]     Train net output #0: loss = 0.0454578 (* 1 = 0.0454578 loss)
I0403 02:57:27.471245 23740 sgd_solver.cpp:106] Iteration 1380, lr = 0.005
I0403 02:57:35.107874 23740 solver.cpp:228] Iteration 1390, loss = 0.0885874
I0403 02:57:35.113945 23740 solver.cpp:244]     Train net output #0: loss = 0.0885875 (* 1 = 0.0885875 loss)
I0403 02:57:35.298030 23740 sgd_solver.cpp:106] Iteration 1390, lr = 0.005
I0403 02:57:42.727596 23740 solver.cpp:228] Iteration 1400, loss = 0.0366305
I0403 02:57:42.733604 23740 solver.cpp:244]     Train net output #0: loss = 0.0366306 (* 1 = 0.0366306 loss)
I0403 02:57:42.893347 23740 sgd_solver.cpp:106] Iteration 1400, lr = 0.005
I0403 02:57:50.404052 23740 solver.cpp:228] Iteration 1410, loss = 0.0105018
I0403 02:57:50.410208 23740 solver.cpp:244]     Train net output #0: loss = 0.0105019 (* 1 = 0.0105019 loss)
I0403 02:57:50.598160 23740 sgd_solver.cpp:106] Iteration 1410, lr = 0.005
I0403 02:57:58.093492 23740 solver.cpp:228] Iteration 1420, loss = 0.116508
I0403 02:57:58.098783 23740 solver.cpp:244]     Train net output #0: loss = 0.116508 (* 1 = 0.116508 loss)
I0403 02:57:58.303555 23740 sgd_solver.cpp:106] Iteration 1420, lr = 0.005
I0403 02:58:05.662555 23740 solver.cpp:228] Iteration 1430, loss = 0.0287053
I0403 02:58:05.668418 23740 solver.cpp:244]     Train net output #0: loss = 0.0287053 (* 1 = 0.0287053 loss)
I0403 02:58:05.879853 23740 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 02:58:13.413589 23740 solver.cpp:228] Iteration 1440, loss = 0.0451999
I0403 02:58:13.420351 23740 solver.cpp:244]     Train net output #0: loss = 0.0452 (* 1 = 0.0452 loss)
I0403 02:58:13.588706 23740 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 02:58:21.126427 23740 solver.cpp:228] Iteration 1450, loss = 0.00815115
I0403 02:58:21.132918 23740 solver.cpp:244]     Train net output #0: loss = 0.00815122 (* 1 = 0.00815122 loss)
I0403 02:58:21.318145 23740 sgd_solver.cpp:106] Iteration 1450, lr = 0.005
I0403 02:58:28.868391 23740 solver.cpp:228] Iteration 1460, loss = 0.0081501
I0403 02:58:28.874570 23740 solver.cpp:244]     Train net output #0: loss = 0.00815016 (* 1 = 0.00815016 loss)
I0403 02:58:29.121470 23740 sgd_solver.cpp:106] Iteration 1460, lr = 0.005
I0403 02:58:36.568589 23740 solver.cpp:228] Iteration 1470, loss = 0.0808227
I0403 02:58:36.574405 23740 solver.cpp:244]     Train net output #0: loss = 0.0808228 (* 1 = 0.0808228 loss)
I0403 02:58:36.682394 23740 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 02:58:44.159500 23740 solver.cpp:228] Iteration 1480, loss = 0.0482931
I0403 02:58:44.170078 23740 solver.cpp:244]     Train net output #0: loss = 0.0482931 (* 1 = 0.0482931 loss)
I0403 02:58:44.353756 23740 sgd_solver.cpp:106] Iteration 1480, lr = 0.005
I0403 02:58:51.791810 23740 solver.cpp:228] Iteration 1490, loss = 0.00111741
I0403 02:58:51.798183 23740 solver.cpp:244]     Train net output #0: loss = 0.00111746 (* 1 = 0.00111746 loss)
I0403 02:58:51.971971 23740 sgd_solver.cpp:106] Iteration 1490, lr = 0.005
I0403 02:58:59.434763 23740 solver.cpp:228] Iteration 1500, loss = 0.00705114
I0403 02:58:59.441032 23740 solver.cpp:244]     Train net output #0: loss = 0.00705119 (* 1 = 0.00705119 loss)
I0403 02:58:59.607439 23740 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0403 02:59:07.083999 23740 solver.cpp:228] Iteration 1510, loss = 0.002442
I0403 02:59:07.090201 23740 solver.cpp:244]     Train net output #0: loss = 0.00244205 (* 1 = 0.00244205 loss)
I0403 02:59:07.268015 23740 sgd_solver.cpp:106] Iteration 1510, lr = 0.005
I0403 02:59:14.733659 23740 solver.cpp:228] Iteration 1520, loss = 0.00670997
I0403 02:59:14.739389 23740 solver.cpp:244]     Train net output #0: loss = 0.00671002 (* 1 = 0.00671002 loss)
I0403 02:59:14.885284 23740 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 02:59:22.411075 23740 solver.cpp:228] Iteration 1530, loss = 0.038539
I0403 02:59:22.417320 23740 solver.cpp:244]     Train net output #0: loss = 0.0385391 (* 1 = 0.0385391 loss)
I0403 02:59:22.597442 23740 sgd_solver.cpp:106] Iteration 1530, lr = 0.005
I0403 02:59:24.095218 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1533.caffemodel
I0403 02:59:26.916806 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1533.solverstate
I0403 02:59:29.890697 23740 solver.cpp:337] Iteration 1533, Testing net (#0)
I0403 03:00:43.625041 23740 solver.cpp:404]     Test net output #0: accuracy = 0.971699
I0403 03:00:43.632961 23740 solver.cpp:404]     Test net output #1: loss = 0.0995584 (* 1 = 0.0995584 loss)
I0403 03:00:49.609174 23740 solver.cpp:228] Iteration 1540, loss = 0.0754494
I0403 03:00:49.614951 23740 solver.cpp:244]     Train net output #0: loss = 0.0754494 (* 1 = 0.0754494 loss)
I0403 03:00:49.804441 23740 sgd_solver.cpp:106] Iteration 1540, lr = 0.005
I0403 03:00:57.222645 23740 solver.cpp:228] Iteration 1550, loss = 0.00530202
I0403 03:00:57.228561 23740 solver.cpp:244]     Train net output #0: loss = 0.00530207 (* 1 = 0.00530207 loss)
I0403 03:00:57.400100 23740 sgd_solver.cpp:106] Iteration 1550, lr = 0.005
I0403 03:01:04.871563 23740 solver.cpp:228] Iteration 1560, loss = 0.00869116
I0403 03:01:04.878667 23740 solver.cpp:244]     Train net output #0: loss = 0.00869121 (* 1 = 0.00869121 loss)
I0403 03:01:05.066419 23740 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 03:01:12.570902 23740 solver.cpp:228] Iteration 1570, loss = 0.00482933
I0403 03:01:12.577484 23740 solver.cpp:244]     Train net output #0: loss = 0.00482939 (* 1 = 0.00482939 loss)
I0403 03:01:12.779253 23740 sgd_solver.cpp:106] Iteration 1570, lr = 0.005
I0403 03:01:20.179468 23740 solver.cpp:228] Iteration 1580, loss = 0.059088
I0403 03:01:20.185752 23740 solver.cpp:244]     Train net output #0: loss = 0.0590881 (* 1 = 0.0590881 loss)
I0403 03:01:20.409242 23740 sgd_solver.cpp:106] Iteration 1580, lr = 0.005
I0403 03:01:27.815232 23740 solver.cpp:228] Iteration 1590, loss = 0.0467103
I0403 03:01:27.820664 23740 solver.cpp:244]     Train net output #0: loss = 0.0467103 (* 1 = 0.0467103 loss)
I0403 03:01:28.020541 23740 sgd_solver.cpp:106] Iteration 1590, lr = 0.005
I0403 03:01:35.394238 23740 solver.cpp:228] Iteration 1600, loss = 0.00475651
I0403 03:01:35.400297 23740 solver.cpp:244]     Train net output #0: loss = 0.00475656 (* 1 = 0.00475656 loss)
I0403 03:01:35.581224 23740 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 03:01:42.998486 23740 solver.cpp:228] Iteration 1610, loss = 0.00561085
I0403 03:01:43.004700 23740 solver.cpp:244]     Train net output #0: loss = 0.00561089 (* 1 = 0.00561089 loss)
I0403 03:01:43.188840 23740 sgd_solver.cpp:106] Iteration 1610, lr = 0.005
I0403 03:01:50.631252 23740 solver.cpp:228] Iteration 1620, loss = 0.00335207
I0403 03:01:50.637461 23740 solver.cpp:244]     Train net output #0: loss = 0.00335212 (* 1 = 0.00335212 loss)
I0403 03:01:50.831096 23740 sgd_solver.cpp:106] Iteration 1620, lr = 0.005
I0403 03:01:58.197120 23740 solver.cpp:228] Iteration 1630, loss = 0.006421
I0403 03:01:58.203413 23740 solver.cpp:244]     Train net output #0: loss = 0.00642105 (* 1 = 0.00642105 loss)
I0403 03:01:58.392741 23740 sgd_solver.cpp:106] Iteration 1630, lr = 0.005
I0403 03:02:05.739115 23740 solver.cpp:228] Iteration 1640, loss = 0.000508423
I0403 03:02:05.745350 23740 solver.cpp:244]     Train net output #0: loss = 0.000508467 (* 1 = 0.000508467 loss)
I0403 03:02:05.927572 23740 sgd_solver.cpp:106] Iteration 1640, lr = 0.005
I0403 03:02:13.237815 23740 solver.cpp:228] Iteration 1650, loss = 0.0202949
I0403 03:02:13.243685 23740 solver.cpp:244]     Train net output #0: loss = 0.020295 (* 1 = 0.020295 loss)
I0403 03:02:13.446894 23740 sgd_solver.cpp:106] Iteration 1650, lr = 0.005
I0403 03:02:20.809435 23740 solver.cpp:228] Iteration 1660, loss = 0.00198187
I0403 03:02:20.816372 23740 solver.cpp:244]     Train net output #0: loss = 0.00198191 (* 1 = 0.00198191 loss)
I0403 03:02:20.997167 23740 sgd_solver.cpp:106] Iteration 1660, lr = 0.005
I0403 03:02:28.402312 23740 solver.cpp:228] Iteration 1670, loss = 0.066286
I0403 03:02:28.408224 23740 solver.cpp:244]     Train net output #0: loss = 0.066286 (* 1 = 0.066286 loss)
I0403 03:02:28.589445 23740 sgd_solver.cpp:106] Iteration 1670, lr = 0.005
I0403 03:02:36.090348 23740 solver.cpp:228] Iteration 1680, loss = 0.017895
I0403 03:02:36.095933 23740 solver.cpp:244]     Train net output #0: loss = 0.0178951 (* 1 = 0.0178951 loss)
I0403 03:02:36.277947 23740 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 03:02:43.599014 23740 solver.cpp:228] Iteration 1690, loss = 0.0166213
I0403 03:02:43.605192 23740 solver.cpp:244]     Train net output #0: loss = 0.0166213 (* 1 = 0.0166213 loss)
I0403 03:02:43.795575 23740 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 03:02:51.139513 23740 solver.cpp:228] Iteration 1700, loss = 0.0134963
I0403 03:02:51.146352 23740 solver.cpp:244]     Train net output #0: loss = 0.0134963 (* 1 = 0.0134963 loss)
I0403 03:02:51.328085 23740 sgd_solver.cpp:106] Iteration 1700, lr = 0.005
I0403 03:02:58.811466 23740 solver.cpp:228] Iteration 1710, loss = 0.0086982
I0403 03:02:58.817885 23740 solver.cpp:244]     Train net output #0: loss = 0.00869825 (* 1 = 0.00869825 loss)
I0403 03:02:58.994949 23740 sgd_solver.cpp:106] Iteration 1710, lr = 0.005
I0403 03:03:06.457185 23740 solver.cpp:228] Iteration 1720, loss = 0.0100137
I0403 03:03:06.463076 23740 solver.cpp:244]     Train net output #0: loss = 0.0100137 (* 1 = 0.0100137 loss)
I0403 03:03:06.651655 23740 sgd_solver.cpp:106] Iteration 1720, lr = 0.005
I0403 03:03:14.084005 23740 solver.cpp:228] Iteration 1730, loss = 0.0151834
I0403 03:03:14.090226 23740 solver.cpp:244]     Train net output #0: loss = 0.0151834 (* 1 = 0.0151834 loss)
I0403 03:03:14.285567 23740 sgd_solver.cpp:106] Iteration 1730, lr = 0.005
I0403 03:03:21.687429 23740 solver.cpp:228] Iteration 1740, loss = 0.0110072
I0403 03:03:21.693418 23740 solver.cpp:244]     Train net output #0: loss = 0.0110072 (* 1 = 0.0110072 loss)
I0403 03:03:21.884013 23740 sgd_solver.cpp:106] Iteration 1740, lr = 0.005
I0403 03:03:29.280922 23740 solver.cpp:228] Iteration 1750, loss = 0.0093591
I0403 03:03:29.288898 23740 solver.cpp:244]     Train net output #0: loss = 0.00935916 (* 1 = 0.00935916 loss)
I0403 03:03:29.483934 23740 sgd_solver.cpp:106] Iteration 1750, lr = 0.005
I0403 03:03:30.266098 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1752.caffemodel
I0403 03:03:32.991298 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1752.solverstate
I0403 03:03:34.869424 23740 solver.cpp:337] Iteration 1752, Testing net (#0)
I0403 03:04:48.573186 23740 solver.cpp:404]     Test net output #0: accuracy = 0.970433
I0403 03:04:48.581915 23740 solver.cpp:404]     Test net output #1: loss = 0.105879 (* 1 = 0.105879 loss)
I0403 03:04:55.214993 23740 solver.cpp:228] Iteration 1760, loss = 0.0399884
I0403 03:04:55.221884 23740 solver.cpp:244]     Train net output #0: loss = 0.0399885 (* 1 = 0.0399885 loss)
I0403 03:04:55.427623 23740 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 03:05:02.810340 23740 solver.cpp:228] Iteration 1770, loss = 0.0130059
I0403 03:05:02.816774 23740 solver.cpp:244]     Train net output #0: loss = 0.013006 (* 1 = 0.013006 loss)
I0403 03:05:02.993657 23740 sgd_solver.cpp:106] Iteration 1770, lr = 0.005
I0403 03:05:10.418416 23740 solver.cpp:228] Iteration 1780, loss = 0.0179512
I0403 03:05:10.424517 23740 solver.cpp:244]     Train net output #0: loss = 0.0179513 (* 1 = 0.0179513 loss)
I0403 03:05:10.607069 23740 sgd_solver.cpp:106] Iteration 1780, lr = 0.005
I0403 03:05:18.025902 23740 solver.cpp:228] Iteration 1790, loss = 0.0010279
I0403 03:05:18.031380 23740 solver.cpp:244]     Train net output #0: loss = 0.00102796 (* 1 = 0.00102796 loss)
I0403 03:05:18.280411 23740 sgd_solver.cpp:106] Iteration 1790, lr = 0.005
I0403 03:05:25.697589 23740 solver.cpp:228] Iteration 1800, loss = 0.0423264
I0403 03:05:25.704128 23740 solver.cpp:244]     Train net output #0: loss = 0.0423265 (* 1 = 0.0423265 loss)
I0403 03:05:25.878151 23740 sgd_solver.cpp:106] Iteration 1800, lr = 0.005
I0403 03:05:33.326866 23740 solver.cpp:228] Iteration 1810, loss = 0.0242831
I0403 03:05:33.333676 23740 solver.cpp:244]     Train net output #0: loss = 0.0242832 (* 1 = 0.0242832 loss)
I0403 03:05:33.521360 23740 sgd_solver.cpp:106] Iteration 1810, lr = 0.005
I0403 03:05:41.004264 23740 solver.cpp:228] Iteration 1820, loss = 0.00098612
I0403 03:05:41.008744 23740 solver.cpp:244]     Train net output #0: loss = 0.000986177 (* 1 = 0.000986177 loss)
I0403 03:05:41.203059 23740 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 03:05:48.619130 23740 solver.cpp:228] Iteration 1830, loss = 0.0191399
I0403 03:05:48.624213 23740 solver.cpp:244]     Train net output #0: loss = 0.01914 (* 1 = 0.01914 loss)
I0403 03:05:48.814577 23740 sgd_solver.cpp:106] Iteration 1830, lr = 0.005
I0403 03:05:56.262200 23740 solver.cpp:228] Iteration 1840, loss = 0.0181672
I0403 03:05:56.268673 23740 solver.cpp:244]     Train net output #0: loss = 0.0181672 (* 1 = 0.0181672 loss)
I0403 03:05:56.449440 23740 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 03:06:03.903322 23740 solver.cpp:228] Iteration 1850, loss = 0.0245869
I0403 03:06:03.909286 23740 solver.cpp:244]     Train net output #0: loss = 0.0245869 (* 1 = 0.0245869 loss)
I0403 03:06:04.101618 23740 sgd_solver.cpp:106] Iteration 1850, lr = 0.005
I0403 03:06:11.566686 23740 solver.cpp:228] Iteration 1860, loss = 0.00333581
I0403 03:06:11.573482 23740 solver.cpp:244]     Train net output #0: loss = 0.00333587 (* 1 = 0.00333587 loss)
I0403 03:06:11.810464 23740 sgd_solver.cpp:106] Iteration 1860, lr = 0.005
I0403 03:06:19.238740 23740 solver.cpp:228] Iteration 1870, loss = 0.0124428
I0403 03:06:19.244392 23740 solver.cpp:244]     Train net output #0: loss = 0.0124429 (* 1 = 0.0124429 loss)
I0403 03:06:19.449843 23740 sgd_solver.cpp:106] Iteration 1870, lr = 0.005
I0403 03:06:26.822818 23740 solver.cpp:228] Iteration 1880, loss = 0.00679415
I0403 03:06:26.829193 23740 solver.cpp:244]     Train net output #0: loss = 0.0067942 (* 1 = 0.0067942 loss)
I0403 03:06:27.013319 23740 sgd_solver.cpp:106] Iteration 1880, lr = 0.005
I0403 03:06:34.418326 23740 solver.cpp:228] Iteration 1890, loss = 0.0576981
I0403 03:06:34.424492 23740 solver.cpp:244]     Train net output #0: loss = 0.0576981 (* 1 = 0.0576981 loss)
I0403 03:06:34.647907 23740 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 03:06:42.037811 23740 solver.cpp:228] Iteration 1900, loss = 0.0112935
I0403 03:06:42.043293 23740 solver.cpp:244]     Train net output #0: loss = 0.0112936 (* 1 = 0.0112936 loss)
I0403 03:06:42.233167 23740 sgd_solver.cpp:106] Iteration 1900, lr = 0.005
I0403 03:06:49.607573 23740 solver.cpp:228] Iteration 1910, loss = 0.0110602
I0403 03:06:49.613605 23740 solver.cpp:244]     Train net output #0: loss = 0.0110603 (* 1 = 0.0110603 loss)
I0403 03:06:49.815369 23740 sgd_solver.cpp:106] Iteration 1910, lr = 0.005
I0403 03:06:57.193563 23740 solver.cpp:228] Iteration 1920, loss = 0.0434557
I0403 03:06:57.204651 23740 solver.cpp:244]     Train net output #0: loss = 0.0434558 (* 1 = 0.0434558 loss)
I0403 03:06:57.357656 23740 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 03:07:04.789261 23740 solver.cpp:228] Iteration 1930, loss = 0.00861206
I0403 03:07:04.795377 23740 solver.cpp:244]     Train net output #0: loss = 0.00861211 (* 1 = 0.00861211 loss)
I0403 03:07:04.986120 23740 sgd_solver.cpp:106] Iteration 1930, lr = 0.005
I0403 03:07:12.316558 23740 solver.cpp:228] Iteration 1940, loss = 0.00971422
I0403 03:07:12.324023 23740 solver.cpp:244]     Train net output #0: loss = 0.00971428 (* 1 = 0.00971428 loss)
I0403 03:07:12.517384 23740 sgd_solver.cpp:106] Iteration 1940, lr = 0.005
I0403 03:07:19.887410 23740 solver.cpp:228] Iteration 1950, loss = 0.0200263
I0403 03:07:19.893589 23740 solver.cpp:244]     Train net output #0: loss = 0.0200263 (* 1 = 0.0200263 loss)
I0403 03:07:20.131516 23740 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 03:07:27.575044 23740 solver.cpp:228] Iteration 1960, loss = 0.0236384
I0403 03:07:27.581128 23740 solver.cpp:244]     Train net output #0: loss = 0.0236384 (* 1 = 0.0236384 loss)
I0403 03:07:27.804947 23740 sgd_solver.cpp:106] Iteration 1960, lr = 0.005
I0403 03:07:35.156160 23740 solver.cpp:228] Iteration 1970, loss = 0.0241741
I0403 03:07:35.161697 23740 solver.cpp:244]     Train net output #0: loss = 0.0241742 (* 1 = 0.0241742 loss)
I0403 03:07:35.346498 23740 sgd_solver.cpp:106] Iteration 1970, lr = 0.005
I0403 03:07:35.346729 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1971.caffemodel
I0403 03:07:38.123412 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_1971.solverstate
I0403 03:07:39.982892 23740 solver.cpp:337] Iteration 1971, Testing net (#0)
I0403 03:08:53.713399 23740 solver.cpp:404]     Test net output #0: accuracy = 0.971883
I0403 03:08:53.721397 23740 solver.cpp:404]     Test net output #1: loss = 0.0957603 (* 1 = 0.0957603 loss)
I0403 03:09:01.291231 23740 solver.cpp:228] Iteration 1980, loss = 0.00663156
I0403 03:09:01.312114 23740 solver.cpp:244]     Train net output #0: loss = 0.00663162 (* 1 = 0.00663162 loss)
I0403 03:09:01.476594 23740 sgd_solver.cpp:106] Iteration 1980, lr = 0.005
I0403 03:09:08.834240 23740 solver.cpp:228] Iteration 1990, loss = 0.0125757
I0403 03:09:08.840664 23740 solver.cpp:244]     Train net output #0: loss = 0.0125758 (* 1 = 0.0125758 loss)
I0403 03:09:09.037740 23740 sgd_solver.cpp:106] Iteration 1990, lr = 0.005
I0403 03:09:16.428774 23740 solver.cpp:228] Iteration 2000, loss = 0.00463126
I0403 03:09:16.435534 23740 solver.cpp:244]     Train net output #0: loss = 0.00463132 (* 1 = 0.00463132 loss)
I0403 03:09:16.629505 23740 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 03:09:24.191155 23740 solver.cpp:228] Iteration 2010, loss = 0.032392
I0403 03:09:24.197302 23740 solver.cpp:244]     Train net output #0: loss = 0.0323921 (* 1 = 0.0323921 loss)
I0403 03:09:24.399849 23740 sgd_solver.cpp:106] Iteration 2010, lr = 0.005
I0403 03:09:31.819993 23740 solver.cpp:228] Iteration 2020, loss = 0.00450458
I0403 03:09:31.826247 23740 solver.cpp:244]     Train net output #0: loss = 0.00450464 (* 1 = 0.00450464 loss)
I0403 03:09:32.050309 23740 sgd_solver.cpp:106] Iteration 2020, lr = 0.005
I0403 03:09:39.468843 23740 solver.cpp:228] Iteration 2030, loss = 0.00197831
I0403 03:09:39.475373 23740 solver.cpp:244]     Train net output #0: loss = 0.00197836 (* 1 = 0.00197836 loss)
I0403 03:09:39.663290 23740 sgd_solver.cpp:106] Iteration 2030, lr = 0.005
I0403 03:09:46.999980 23740 solver.cpp:228] Iteration 2040, loss = 0.00753998
I0403 03:09:47.005532 23740 solver.cpp:244]     Train net output #0: loss = 0.00754003 (* 1 = 0.00754003 loss)
I0403 03:09:47.231489 23740 sgd_solver.cpp:106] Iteration 2040, lr = 0.005
I0403 03:09:54.649263 23740 solver.cpp:228] Iteration 2050, loss = 0.0243264
I0403 03:09:54.656138 23740 solver.cpp:244]     Train net output #0: loss = 0.0243264 (* 1 = 0.0243264 loss)
I0403 03:09:54.869956 23740 sgd_solver.cpp:106] Iteration 2050, lr = 0.005
I0403 03:10:02.295073 23740 solver.cpp:228] Iteration 2060, loss = 0.00154962
I0403 03:10:02.302026 23740 solver.cpp:244]     Train net output #0: loss = 0.00154967 (* 1 = 0.00154967 loss)
I0403 03:10:02.466704 23740 sgd_solver.cpp:106] Iteration 2060, lr = 0.005
I0403 03:10:10.004470 23740 solver.cpp:228] Iteration 2070, loss = 0.00340344
I0403 03:10:10.011050 23740 solver.cpp:244]     Train net output #0: loss = 0.00340348 (* 1 = 0.00340348 loss)
I0403 03:10:10.178351 23740 sgd_solver.cpp:106] Iteration 2070, lr = 0.005
I0403 03:10:17.544553 23740 solver.cpp:228] Iteration 2080, loss = 0.000946788
I0403 03:10:17.551332 23740 solver.cpp:244]     Train net output #0: loss = 0.000946827 (* 1 = 0.000946827 loss)
I0403 03:10:17.777627 23740 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:10:25.189715 23740 solver.cpp:228] Iteration 2090, loss = 0.0213086
I0403 03:10:25.196079 23740 solver.cpp:244]     Train net output #0: loss = 0.0213087 (* 1 = 0.0213087 loss)
I0403 03:10:25.368270 23740 sgd_solver.cpp:106] Iteration 2090, lr = 0.005
I0403 03:10:32.764441 23740 solver.cpp:228] Iteration 2100, loss = 0.00430115
I0403 03:10:32.771301 23740 solver.cpp:244]     Train net output #0: loss = 0.00430119 (* 1 = 0.00430119 loss)
I0403 03:10:32.978374 23740 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 03:10:40.484257 23740 solver.cpp:228] Iteration 2110, loss = 0.0138316
I0403 03:10:40.491086 23740 solver.cpp:244]     Train net output #0: loss = 0.0138316 (* 1 = 0.0138316 loss)
I0403 03:10:40.683502 23740 sgd_solver.cpp:106] Iteration 2110, lr = 0.005
I0403 03:10:48.088876 23740 solver.cpp:228] Iteration 2120, loss = 0.00276625
I0403 03:10:48.095146 23740 solver.cpp:244]     Train net output #0: loss = 0.00276628 (* 1 = 0.00276628 loss)
I0403 03:10:48.287364 23740 sgd_solver.cpp:106] Iteration 2120, lr = 0.005
I0403 03:10:55.653475 23740 solver.cpp:228] Iteration 2130, loss = 0.0295732
I0403 03:10:55.659699 23740 solver.cpp:244]     Train net output #0: loss = 0.0295732 (* 1 = 0.0295732 loss)
I0403 03:10:55.879814 23740 sgd_solver.cpp:106] Iteration 2130, lr = 0.005
I0403 03:11:03.340076 23740 solver.cpp:228] Iteration 2140, loss = 0.00810936
I0403 03:11:03.346673 23740 solver.cpp:244]     Train net output #0: loss = 0.00810939 (* 1 = 0.00810939 loss)
I0403 03:11:03.570464 23740 sgd_solver.cpp:106] Iteration 2140, lr = 0.005
I0403 03:11:11.046006 23740 solver.cpp:228] Iteration 2150, loss = 0.000500969
I0403 03:11:11.051787 23740 solver.cpp:244]     Train net output #0: loss = 0.000501002 (* 1 = 0.000501002 loss)
I0403 03:11:11.240224 23740 sgd_solver.cpp:106] Iteration 2150, lr = 0.005
I0403 03:11:18.644917 23740 solver.cpp:228] Iteration 2160, loss = 0.0687827
I0403 03:11:18.650573 23740 solver.cpp:244]     Train net output #0: loss = 0.0687827 (* 1 = 0.0687827 loss)
I0403 03:11:18.859642 23740 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 03:11:26.244501 23740 solver.cpp:228] Iteration 2170, loss = 0.00113243
I0403 03:11:26.250776 23740 solver.cpp:244]     Train net output #0: loss = 0.00113246 (* 1 = 0.00113246 loss)
I0403 03:11:26.435562 23740 sgd_solver.cpp:106] Iteration 2170, lr = 0.005
I0403 03:11:33.807746 23740 solver.cpp:228] Iteration 2180, loss = 0.012142
I0403 03:11:33.813936 23740 solver.cpp:244]     Train net output #0: loss = 0.0121421 (* 1 = 0.0121421 loss)
I0403 03:11:34.006717 23740 sgd_solver.cpp:106] Iteration 2180, lr = 0.005
I0403 03:11:40.883679 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2190.caffemodel
I0403 03:11:43.618496 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2190.solverstate
I0403 03:11:45.492878 23740 solver.cpp:337] Iteration 2190, Testing net (#0)
I0403 03:12:59.207743 23740 solver.cpp:404]     Test net output #0: accuracy = 0.97642
I0403 03:12:59.215788 23740 solver.cpp:404]     Test net output #1: loss = 0.0826184 (* 1 = 0.0826184 loss)
I0403 03:12:59.768208 23740 solver.cpp:228] Iteration 2190, loss = 0.0389877
I0403 03:12:59.775456 23740 solver.cpp:244]     Train net output #0: loss = 0.0389877 (* 1 = 0.0389877 loss)
I0403 03:12:59.926388 23740 sgd_solver.cpp:106] Iteration 2190, lr = 0.0005
I0403 03:13:07.442492 23740 solver.cpp:228] Iteration 2200, loss = 0.0535026
I0403 03:13:07.448034 23740 solver.cpp:244]     Train net output #0: loss = 0.0535026 (* 1 = 0.0535026 loss)
I0403 03:13:07.664244 23740 sgd_solver.cpp:106] Iteration 2200, lr = 0.0005
I0403 03:13:15.072414 23740 solver.cpp:228] Iteration 2210, loss = 0.0195751
I0403 03:13:15.079025 23740 solver.cpp:244]     Train net output #0: loss = 0.0195751 (* 1 = 0.0195751 loss)
I0403 03:13:15.256953 23740 sgd_solver.cpp:106] Iteration 2210, lr = 0.0005
I0403 03:13:22.589818 23740 solver.cpp:228] Iteration 2220, loss = 0.00119367
I0403 03:13:22.594741 23740 solver.cpp:244]     Train net output #0: loss = 0.00119371 (* 1 = 0.00119371 loss)
I0403 03:13:22.795616 23740 sgd_solver.cpp:106] Iteration 2220, lr = 0.0005
I0403 03:13:30.271616 23740 solver.cpp:228] Iteration 2230, loss = 0.0513561
I0403 03:13:30.279366 23740 solver.cpp:244]     Train net output #0: loss = 0.0513561 (* 1 = 0.0513561 loss)
I0403 03:13:30.459978 23740 sgd_solver.cpp:106] Iteration 2230, lr = 0.0005
I0403 03:13:37.863716 23740 solver.cpp:228] Iteration 2240, loss = 0.00159341
I0403 03:13:37.870129 23740 solver.cpp:244]     Train net output #0: loss = 0.00159345 (* 1 = 0.00159345 loss)
I0403 03:13:38.093206 23740 sgd_solver.cpp:106] Iteration 2240, lr = 0.0005
I0403 03:13:45.484704 23740 solver.cpp:228] Iteration 2250, loss = 0.0014056
I0403 03:13:45.491734 23740 solver.cpp:244]     Train net output #0: loss = 0.00140564 (* 1 = 0.00140564 loss)
I0403 03:13:45.709712 23740 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0403 03:13:53.061556 23740 solver.cpp:228] Iteration 2260, loss = 0.000356006
I0403 03:13:53.066897 23740 solver.cpp:244]     Train net output #0: loss = 0.000356051 (* 1 = 0.000356051 loss)
I0403 03:13:53.247655 23740 sgd_solver.cpp:106] Iteration 2260, lr = 0.0005
I0403 03:14:00.641535 23740 solver.cpp:228] Iteration 2270, loss = 0.00501511
I0403 03:14:00.652009 23740 solver.cpp:244]     Train net output #0: loss = 0.00501515 (* 1 = 0.00501515 loss)
I0403 03:14:00.847537 23740 sgd_solver.cpp:106] Iteration 2270, lr = 0.0005
I0403 03:14:08.228819 23740 solver.cpp:228] Iteration 2280, loss = 0.00801283
I0403 03:14:08.234354 23740 solver.cpp:244]     Train net output #0: loss = 0.00801287 (* 1 = 0.00801287 loss)
I0403 03:14:08.426545 23740 sgd_solver.cpp:106] Iteration 2280, lr = 0.0005
I0403 03:14:15.784956 23740 solver.cpp:228] Iteration 2290, loss = 0.00122918
I0403 03:14:15.791983 23740 solver.cpp:244]     Train net output #0: loss = 0.00122923 (* 1 = 0.00122923 loss)
I0403 03:14:15.954198 23740 sgd_solver.cpp:106] Iteration 2290, lr = 0.0005
I0403 03:14:23.467883 23740 solver.cpp:228] Iteration 2300, loss = 0.00757295
I0403 03:14:23.474977 23740 solver.cpp:244]     Train net output #0: loss = 0.00757299 (* 1 = 0.00757299 loss)
I0403 03:14:23.657037 23740 sgd_solver.cpp:106] Iteration 2300, lr = 0.0005
I0403 03:14:31.105969 23740 solver.cpp:228] Iteration 2310, loss = 0.0167404
I0403 03:14:31.112507 23740 solver.cpp:244]     Train net output #0: loss = 0.0167404 (* 1 = 0.0167404 loss)
I0403 03:14:31.305354 23740 sgd_solver.cpp:106] Iteration 2310, lr = 0.0005
I0403 03:14:38.649657 23740 solver.cpp:228] Iteration 2320, loss = 0.00426412
I0403 03:14:38.654772 23740 solver.cpp:244]     Train net output #0: loss = 0.00426417 (* 1 = 0.00426417 loss)
I0403 03:14:38.843909 23740 sgd_solver.cpp:106] Iteration 2320, lr = 0.0005
I0403 03:14:46.233557 23740 solver.cpp:228] Iteration 2330, loss = 0.00238728
I0403 03:14:46.240031 23740 solver.cpp:244]     Train net output #0: loss = 0.00238732 (* 1 = 0.00238732 loss)
I0403 03:14:46.480746 23740 sgd_solver.cpp:106] Iteration 2330, lr = 0.0005
I0403 03:14:53.940659 23740 solver.cpp:228] Iteration 2340, loss = 0.010114
I0403 03:14:53.946724 23740 solver.cpp:244]     Train net output #0: loss = 0.010114 (* 1 = 0.010114 loss)
I0403 03:14:54.143625 23740 sgd_solver.cpp:106] Iteration 2340, lr = 0.0005
I0403 03:15:01.556920 23740 solver.cpp:228] Iteration 2350, loss = 0.000392893
I0403 03:15:01.562892 23740 solver.cpp:244]     Train net output #0: loss = 0.000392935 (* 1 = 0.000392935 loss)
I0403 03:15:01.747139 23740 sgd_solver.cpp:106] Iteration 2350, lr = 0.0005
I0403 03:15:09.163563 23740 solver.cpp:228] Iteration 2360, loss = 0.00135439
I0403 03:15:09.169442 23740 solver.cpp:244]     Train net output #0: loss = 0.00135443 (* 1 = 0.00135443 loss)
I0403 03:15:09.369887 23740 sgd_solver.cpp:106] Iteration 2360, lr = 0.0005
I0403 03:15:16.734657 23740 solver.cpp:228] Iteration 2370, loss = 0.0143323
I0403 03:15:16.740947 23740 solver.cpp:244]     Train net output #0: loss = 0.0143323 (* 1 = 0.0143323 loss)
I0403 03:15:16.929179 23740 sgd_solver.cpp:106] Iteration 2370, lr = 0.0005
I0403 03:15:24.289680 23740 solver.cpp:228] Iteration 2380, loss = 0.0020458
I0403 03:15:24.295507 23740 solver.cpp:244]     Train net output #0: loss = 0.00204584 (* 1 = 0.00204584 loss)
I0403 03:15:24.477772 23740 sgd_solver.cpp:106] Iteration 2380, lr = 0.0005
I0403 03:15:31.885021 23740 solver.cpp:228] Iteration 2390, loss = 0.00289068
I0403 03:15:31.892664 23740 solver.cpp:244]     Train net output #0: loss = 0.00289072 (* 1 = 0.00289072 loss)
I0403 03:15:32.073979 23740 sgd_solver.cpp:106] Iteration 2390, lr = 0.0005
I0403 03:15:39.487938 23740 solver.cpp:228] Iteration 2400, loss = 0.000707636
I0403 03:15:39.495224 23740 solver.cpp:244]     Train net output #0: loss = 0.000707679 (* 1 = 0.000707679 loss)
I0403 03:15:39.683331 23740 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I0403 03:15:45.786281 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2409.caffemodel
I0403 03:15:48.579262 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2409.solverstate
I0403 03:15:50.468744 23740 solver.cpp:337] Iteration 2409, Testing net (#0)
I0403 03:17:04.185307 23740 solver.cpp:404]     Test net output #0: accuracy = 0.979291
I0403 03:17:04.193967 23740 solver.cpp:404]     Test net output #1: loss = 0.0750559 (* 1 = 0.0750559 loss)
I0403 03:17:05.509016 23740 solver.cpp:228] Iteration 2410, loss = 0.00085579
I0403 03:17:05.515465 23740 solver.cpp:244]     Train net output #0: loss = 0.000855834 (* 1 = 0.000855834 loss)
I0403 03:17:05.687376 23740 sgd_solver.cpp:106] Iteration 2410, lr = 0.0005
I0403 03:17:13.089836 23740 solver.cpp:228] Iteration 2420, loss = 0.00217134
I0403 03:17:13.096076 23740 solver.cpp:244]     Train net output #0: loss = 0.00217138 (* 1 = 0.00217138 loss)
I0403 03:17:13.319773 23740 sgd_solver.cpp:106] Iteration 2420, lr = 0.0005
I0403 03:17:20.789269 23740 solver.cpp:228] Iteration 2430, loss = 0.0031866
I0403 03:17:20.795171 23740 solver.cpp:244]     Train net output #0: loss = 0.00318665 (* 1 = 0.00318665 loss)
I0403 03:17:20.976995 23740 sgd_solver.cpp:106] Iteration 2430, lr = 0.0005
I0403 03:17:28.404819 23740 solver.cpp:228] Iteration 2440, loss = 0.00750694
I0403 03:17:28.412749 23740 solver.cpp:244]     Train net output #0: loss = 0.00750698 (* 1 = 0.00750698 loss)
I0403 03:17:28.594329 23740 sgd_solver.cpp:106] Iteration 2440, lr = 0.0005
I0403 03:17:36.158867 23740 solver.cpp:228] Iteration 2450, loss = 0.000125349
I0403 03:17:36.168210 23740 solver.cpp:244]     Train net output #0: loss = 0.000125395 (* 1 = 0.000125395 loss)
I0403 03:17:36.371333 23740 sgd_solver.cpp:106] Iteration 2450, lr = 0.0005
I0403 03:17:43.795269 23740 solver.cpp:228] Iteration 2460, loss = 0.000922182
I0403 03:17:43.801489 23740 solver.cpp:244]     Train net output #0: loss = 0.000922225 (* 1 = 0.000922225 loss)
I0403 03:17:44.011870 23740 sgd_solver.cpp:106] Iteration 2460, lr = 0.0005
I0403 03:17:51.516717 23740 solver.cpp:228] Iteration 2470, loss = 0.00163433
I0403 03:17:51.523394 23740 solver.cpp:244]     Train net output #0: loss = 0.00163437 (* 1 = 0.00163437 loss)
I0403 03:17:51.743789 23740 sgd_solver.cpp:106] Iteration 2470, lr = 0.0005
I0403 03:17:59.189345 23740 solver.cpp:228] Iteration 2480, loss = 0.00405868
I0403 03:17:59.195222 23740 solver.cpp:244]     Train net output #0: loss = 0.00405873 (* 1 = 0.00405873 loss)
I0403 03:17:59.391015 23740 sgd_solver.cpp:106] Iteration 2480, lr = 0.0005
I0403 03:18:06.811415 23740 solver.cpp:228] Iteration 2490, loss = 0.000389034
I0403 03:18:06.818068 23740 solver.cpp:244]     Train net output #0: loss = 0.000389077 (* 1 = 0.000389077 loss)
I0403 03:18:07.013181 23740 sgd_solver.cpp:106] Iteration 2490, lr = 0.0005
I0403 03:18:14.438606 23740 solver.cpp:228] Iteration 2500, loss = 0.00107824
I0403 03:18:14.444574 23740 solver.cpp:244]     Train net output #0: loss = 0.00107829 (* 1 = 0.00107829 loss)
I0403 03:18:14.632174 23740 sgd_solver.cpp:106] Iteration 2500, lr = 0.0005
I0403 03:18:22.028928 23740 solver.cpp:228] Iteration 2510, loss = 0.00207068
I0403 03:18:22.035055 23740 solver.cpp:244]     Train net output #0: loss = 0.00207072 (* 1 = 0.00207072 loss)
I0403 03:18:22.217047 23740 sgd_solver.cpp:106] Iteration 2510, lr = 0.0005
I0403 03:18:29.725967 23740 solver.cpp:228] Iteration 2520, loss = 0.000772732
I0403 03:18:29.732653 23740 solver.cpp:244]     Train net output #0: loss = 0.000772775 (* 1 = 0.000772775 loss)
I0403 03:18:29.905153 23740 sgd_solver.cpp:106] Iteration 2520, lr = 0.0005
I0403 03:18:37.455101 23740 solver.cpp:228] Iteration 2530, loss = 0.000147859
I0403 03:18:37.461370 23740 solver.cpp:244]     Train net output #0: loss = 0.000147902 (* 1 = 0.000147902 loss)
I0403 03:18:37.663537 23740 sgd_solver.cpp:106] Iteration 2530, lr = 0.0005
I0403 03:18:45.223955 23740 solver.cpp:228] Iteration 2540, loss = 0.000502406
I0403 03:18:45.230209 23740 solver.cpp:244]     Train net output #0: loss = 0.000502449 (* 1 = 0.000502449 loss)
I0403 03:18:45.425843 23740 sgd_solver.cpp:106] Iteration 2540, lr = 0.0005
I0403 03:18:52.956174 23740 solver.cpp:228] Iteration 2550, loss = 0.000710614
I0403 03:18:52.961885 23740 solver.cpp:244]     Train net output #0: loss = 0.000710657 (* 1 = 0.000710657 loss)
I0403 03:18:53.138999 23740 sgd_solver.cpp:106] Iteration 2550, lr = 0.0005
I0403 03:19:00.734159 23740 solver.cpp:228] Iteration 2560, loss = 0.000375767
I0403 03:19:00.740519 23740 solver.cpp:244]     Train net output #0: loss = 0.00037581 (* 1 = 0.00037581 loss)
I0403 03:19:00.928413 23740 sgd_solver.cpp:106] Iteration 2560, lr = 0.0005
I0403 03:19:08.400264 23740 solver.cpp:228] Iteration 2570, loss = 9.26319e-05
I0403 03:19:08.407078 23740 solver.cpp:244]     Train net output #0: loss = 9.26752e-05 (* 1 = 9.26752e-05 loss)
I0403 03:19:08.602404 23740 sgd_solver.cpp:106] Iteration 2570, lr = 0.0005
I0403 03:19:15.937885 23740 solver.cpp:228] Iteration 2580, loss = 0.000745152
I0403 03:19:15.945093 23740 solver.cpp:244]     Train net output #0: loss = 0.000745192 (* 1 = 0.000745192 loss)
I0403 03:19:16.148452 23740 sgd_solver.cpp:106] Iteration 2580, lr = 0.0005
I0403 03:19:23.554618 23740 solver.cpp:228] Iteration 2590, loss = 0.001181
I0403 03:19:23.560549 23740 solver.cpp:244]     Train net output #0: loss = 0.00118104 (* 1 = 0.00118104 loss)
I0403 03:19:23.773762 23740 sgd_solver.cpp:106] Iteration 2590, lr = 0.0005
I0403 03:19:31.154891 23740 solver.cpp:228] Iteration 2600, loss = 0.00650575
I0403 03:19:31.160735 23740 solver.cpp:244]     Train net output #0: loss = 0.00650579 (* 1 = 0.00650579 loss)
I0403 03:19:31.352680 23740 sgd_solver.cpp:106] Iteration 2600, lr = 0.0005
I0403 03:19:38.816751 23740 solver.cpp:228] Iteration 2610, loss = 0.00774436
I0403 03:19:38.823793 23740 solver.cpp:244]     Train net output #0: loss = 0.0077444 (* 1 = 0.0077444 loss)
I0403 03:19:38.997437 23740 sgd_solver.cpp:106] Iteration 2610, lr = 0.0005
I0403 03:19:46.363494 23740 solver.cpp:228] Iteration 2620, loss = 0.00388008
I0403 03:19:46.369715 23740 solver.cpp:244]     Train net output #0: loss = 0.00388012 (* 1 = 0.00388012 loss)
I0403 03:19:46.547479 23740 sgd_solver.cpp:106] Iteration 2620, lr = 0.0005
I0403 03:19:52.079146 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2628.caffemodel
I0403 03:19:54.904872 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2628.solverstate
I0403 03:19:56.791137 23740 solver.cpp:337] Iteration 2628, Testing net (#0)
I0403 03:21:10.519018 23740 solver.cpp:404]     Test net output #0: accuracy = 0.979507
I0403 03:21:10.526753 23740 solver.cpp:404]     Test net output #1: loss = 0.0733962 (* 1 = 0.0733962 loss)
I0403 03:21:12.761049 23740 solver.cpp:228] Iteration 2630, loss = 0.00465405
I0403 03:21:12.767253 23740 solver.cpp:244]     Train net output #0: loss = 0.00465409 (* 1 = 0.00465409 loss)
I0403 03:21:12.884645 23740 sgd_solver.cpp:106] Iteration 2630, lr = 0.0005
I0403 03:21:20.650061 23740 solver.cpp:228] Iteration 2640, loss = 0.00154097
I0403 03:21:20.658067 23740 solver.cpp:244]     Train net output #0: loss = 0.00154101 (* 1 = 0.00154101 loss)
I0403 03:21:20.844262 23740 sgd_solver.cpp:106] Iteration 2640, lr = 0.0005
I0403 03:21:28.293145 23740 solver.cpp:228] Iteration 2650, loss = 0.00073752
I0403 03:21:28.298895 23740 solver.cpp:244]     Train net output #0: loss = 0.000737561 (* 1 = 0.000737561 loss)
I0403 03:21:28.485066 23740 sgd_solver.cpp:106] Iteration 2650, lr = 0.0005
I0403 03:21:36.004708 23740 solver.cpp:228] Iteration 2660, loss = 0.000394377
I0403 03:21:36.011749 23740 solver.cpp:244]     Train net output #0: loss = 0.000394418 (* 1 = 0.000394418 loss)
I0403 03:21:36.206980 23740 sgd_solver.cpp:106] Iteration 2660, lr = 0.0005
I0403 03:21:43.627511 23740 solver.cpp:228] Iteration 2670, loss = 0.00162523
I0403 03:21:43.633714 23740 solver.cpp:244]     Train net output #0: loss = 0.00162527 (* 1 = 0.00162527 loss)
I0403 03:21:43.832144 23740 sgd_solver.cpp:106] Iteration 2670, lr = 0.0005
I0403 03:21:51.200034 23740 solver.cpp:228] Iteration 2680, loss = 0.00108076
I0403 03:21:51.207401 23740 solver.cpp:244]     Train net output #0: loss = 0.00108081 (* 1 = 0.00108081 loss)
I0403 03:21:51.406476 23740 sgd_solver.cpp:106] Iteration 2680, lr = 0.0005
I0403 03:21:58.829108 23740 solver.cpp:228] Iteration 2690, loss = 0.000363754
I0403 03:21:58.835953 23740 solver.cpp:244]     Train net output #0: loss = 0.000363795 (* 1 = 0.000363795 loss)
I0403 03:21:59.026831 23740 sgd_solver.cpp:106] Iteration 2690, lr = 0.0005
I0403 03:22:06.525902 23740 solver.cpp:228] Iteration 2700, loss = 0.000995609
I0403 03:22:06.532608 23740 solver.cpp:244]     Train net output #0: loss = 0.00099565 (* 1 = 0.00099565 loss)
I0403 03:22:06.715097 23740 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I0403 03:22:14.157049 23740 solver.cpp:228] Iteration 2710, loss = 0.000225697
I0403 03:22:14.163826 23740 solver.cpp:244]     Train net output #0: loss = 0.000225738 (* 1 = 0.000225738 loss)
I0403 03:22:14.352459 23740 sgd_solver.cpp:106] Iteration 2710, lr = 0.0005
I0403 03:22:21.745507 23740 solver.cpp:228] Iteration 2720, loss = 0.000243309
I0403 03:22:21.752213 23740 solver.cpp:244]     Train net output #0: loss = 0.00024335 (* 1 = 0.00024335 loss)
I0403 03:22:21.935386 23740 sgd_solver.cpp:106] Iteration 2720, lr = 0.0005
I0403 03:22:29.418279 23740 solver.cpp:228] Iteration 2730, loss = 0.00315904
I0403 03:22:29.424490 23740 solver.cpp:244]     Train net output #0: loss = 0.00315908 (* 1 = 0.00315908 loss)
I0403 03:22:29.608304 23740 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 03:22:37.067929 23740 solver.cpp:228] Iteration 2740, loss = 0.00531339
I0403 03:22:37.074523 23740 solver.cpp:244]     Train net output #0: loss = 0.00531343 (* 1 = 0.00531343 loss)
I0403 03:22:37.258316 23740 sgd_solver.cpp:106] Iteration 2740, lr = 0.0005
I0403 03:22:44.639883 23740 solver.cpp:228] Iteration 2750, loss = 0.00218353
I0403 03:22:44.646594 23740 solver.cpp:244]     Train net output #0: loss = 0.00218357 (* 1 = 0.00218357 loss)
I0403 03:22:44.863431 23740 sgd_solver.cpp:106] Iteration 2750, lr = 0.0005
I0403 03:22:52.335963 23740 solver.cpp:228] Iteration 2760, loss = 0.000169107
I0403 03:22:52.344290 23740 solver.cpp:244]     Train net output #0: loss = 0.000169149 (* 1 = 0.000169149 loss)
I0403 03:22:52.548840 23740 sgd_solver.cpp:106] Iteration 2760, lr = 0.0005
I0403 03:22:59.934556 23740 solver.cpp:228] Iteration 2770, loss = 0.000977319
I0403 03:22:59.941814 23740 solver.cpp:244]     Train net output #0: loss = 0.00097736 (* 1 = 0.00097736 loss)
I0403 03:23:00.123836 23740 sgd_solver.cpp:106] Iteration 2770, lr = 0.0005
I0403 03:23:07.547456 23740 solver.cpp:228] Iteration 2780, loss = 0.00263574
I0403 03:23:07.553985 23740 solver.cpp:244]     Train net output #0: loss = 0.00263578 (* 1 = 0.00263578 loss)
I0403 03:23:07.732373 23740 sgd_solver.cpp:106] Iteration 2780, lr = 0.0005
I0403 03:23:15.196475 23740 solver.cpp:228] Iteration 2790, loss = 0.00179796
I0403 03:23:15.204311 23740 solver.cpp:244]     Train net output #0: loss = 0.001798 (* 1 = 0.001798 loss)
I0403 03:23:15.392453 23740 sgd_solver.cpp:106] Iteration 2790, lr = 0.0005
I0403 03:23:22.810827 23740 solver.cpp:228] Iteration 2800, loss = 0.00114136
I0403 03:23:22.816742 23740 solver.cpp:244]     Train net output #0: loss = 0.0011414 (* 1 = 0.0011414 loss)
I0403 03:23:22.999847 23740 sgd_solver.cpp:106] Iteration 2800, lr = 0.0005
I0403 03:23:30.413730 23740 solver.cpp:228] Iteration 2810, loss = 0.000577338
I0403 03:23:30.419601 23740 solver.cpp:244]     Train net output #0: loss = 0.000577378 (* 1 = 0.000577378 loss)
I0403 03:23:30.604271 23740 sgd_solver.cpp:106] Iteration 2810, lr = 0.0005
I0403 03:23:38.035552 23740 solver.cpp:228] Iteration 2820, loss = 0.000865898
I0403 03:23:38.042476 23740 solver.cpp:244]     Train net output #0: loss = 0.000865938 (* 1 = 0.000865938 loss)
I0403 03:23:38.232841 23740 sgd_solver.cpp:106] Iteration 2820, lr = 0.0005
I0403 03:23:45.615984 23740 solver.cpp:228] Iteration 2830, loss = 0.000303372
I0403 03:23:45.623445 23740 solver.cpp:244]     Train net output #0: loss = 0.000303411 (* 1 = 0.000303411 loss)
I0403 03:23:45.810487 23740 sgd_solver.cpp:106] Iteration 2830, lr = 0.0005
I0403 03:23:53.140506 23740 solver.cpp:228] Iteration 2840, loss = 0.000151461
I0403 03:23:53.146543 23740 solver.cpp:244]     Train net output #0: loss = 0.0001515 (* 1 = 0.0001515 loss)
I0403 03:23:53.331085 23740 sgd_solver.cpp:106] Iteration 2840, lr = 0.0005
I0403 03:23:57.926789 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2847.caffemodel
I0403 03:24:00.726193 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_2847.solverstate
I0403 03:24:02.647058 23740 solver.cpp:337] Iteration 2847, Testing net (#0)
I0403 03:25:16.352738 23740 solver.cpp:404]     Test net output #0: accuracy = 0.980463
I0403 03:25:16.360338 23740 solver.cpp:404]     Test net output #1: loss = 0.0735037 (* 1 = 0.0735037 loss)
I0403 03:25:19.184944 23740 solver.cpp:228] Iteration 2850, loss = 0.000965312
I0403 03:25:19.191803 23740 solver.cpp:244]     Train net output #0: loss = 0.000965351 (* 1 = 0.000965351 loss)
I0403 03:25:19.381642 23740 sgd_solver.cpp:106] Iteration 2850, lr = 0.0005
I0403 03:25:26.799792 23740 solver.cpp:228] Iteration 2860, loss = 0.00996732
I0403 03:25:26.805192 23740 solver.cpp:244]     Train net output #0: loss = 0.00996736 (* 1 = 0.00996736 loss)
I0403 03:25:27.004968 23740 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 03:25:34.561409 23740 solver.cpp:228] Iteration 2870, loss = 0.00351689
I0403 03:25:34.569260 23740 solver.cpp:244]     Train net output #0: loss = 0.00351693 (* 1 = 0.00351693 loss)
I0403 03:25:34.747474 23740 sgd_solver.cpp:106] Iteration 2870, lr = 0.0005
I0403 03:25:42.267747 23740 solver.cpp:228] Iteration 2880, loss = 0.00257275
I0403 03:25:42.272729 23740 solver.cpp:244]     Train net output #0: loss = 0.00257279 (* 1 = 0.00257279 loss)
I0403 03:25:42.415662 23740 sgd_solver.cpp:106] Iteration 2880, lr = 0.0005
I0403 03:25:50.000529 23740 solver.cpp:228] Iteration 2890, loss = 0.000451152
I0403 03:25:50.007323 23740 solver.cpp:244]     Train net output #0: loss = 0.000451192 (* 1 = 0.000451192 loss)
I0403 03:25:50.194833 23740 sgd_solver.cpp:106] Iteration 2890, lr = 0.0005
I0403 03:25:57.791023 23740 solver.cpp:228] Iteration 2900, loss = 0.0258392
I0403 03:25:57.796715 23740 solver.cpp:244]     Train net output #0: loss = 0.0258392 (* 1 = 0.0258392 loss)
I0403 03:25:57.913203 23740 sgd_solver.cpp:106] Iteration 2900, lr = 0.0005
I0403 03:26:05.471088 23740 solver.cpp:228] Iteration 2910, loss = 0.00154804
I0403 03:26:05.477560 23740 solver.cpp:244]     Train net output #0: loss = 0.00154808 (* 1 = 0.00154808 loss)
I0403 03:26:05.674517 23740 sgd_solver.cpp:106] Iteration 2910, lr = 0.0005
I0403 03:26:13.261241 23740 solver.cpp:228] Iteration 2920, loss = 0.000253386
I0403 03:26:13.268129 23740 solver.cpp:244]     Train net output #0: loss = 0.000253427 (* 1 = 0.000253427 loss)
I0403 03:26:13.494125 23740 sgd_solver.cpp:106] Iteration 2920, lr = 0.0005
I0403 03:26:20.948370 23740 solver.cpp:228] Iteration 2930, loss = 0.000636406
I0403 03:26:20.954391 23740 solver.cpp:244]     Train net output #0: loss = 0.000636447 (* 1 = 0.000636447 loss)
I0403 03:26:21.161458 23740 sgd_solver.cpp:106] Iteration 2930, lr = 0.0005
I0403 03:26:28.500725 23740 solver.cpp:228] Iteration 2940, loss = 0.00343625
I0403 03:26:28.506492 23740 solver.cpp:244]     Train net output #0: loss = 0.00343629 (* 1 = 0.00343629 loss)
I0403 03:26:28.723229 23740 sgd_solver.cpp:106] Iteration 2940, lr = 0.0005
I0403 03:26:36.092422 23740 solver.cpp:228] Iteration 2950, loss = 0.00242168
I0403 03:26:36.100219 23740 solver.cpp:244]     Train net output #0: loss = 0.00242172 (* 1 = 0.00242172 loss)
I0403 03:26:36.286857 23740 sgd_solver.cpp:106] Iteration 2950, lr = 0.0005
I0403 03:26:43.660924 23740 solver.cpp:228] Iteration 2960, loss = 0.00221691
I0403 03:26:43.667680 23740 solver.cpp:244]     Train net output #0: loss = 0.00221695 (* 1 = 0.00221695 loss)
I0403 03:26:43.862735 23740 sgd_solver.cpp:106] Iteration 2960, lr = 0.0005
I0403 03:26:51.219529 23740 solver.cpp:228] Iteration 2970, loss = 0.0037079
I0403 03:26:51.231149 23740 solver.cpp:244]     Train net output #0: loss = 0.00370794 (* 1 = 0.00370794 loss)
I0403 03:26:51.408411 23740 sgd_solver.cpp:106] Iteration 2970, lr = 0.0005
I0403 03:26:58.882580 23740 solver.cpp:228] Iteration 2980, loss = 0.000227638
I0403 03:26:58.889042 23740 solver.cpp:244]     Train net output #0: loss = 0.00022768 (* 1 = 0.00022768 loss)
I0403 03:26:59.097441 23740 sgd_solver.cpp:106] Iteration 2980, lr = 0.0005
I0403 03:27:06.524397 23740 solver.cpp:228] Iteration 2990, loss = 0.00194352
I0403 03:27:06.530791 23740 solver.cpp:244]     Train net output #0: loss = 0.00194356 (* 1 = 0.00194356 loss)
I0403 03:27:06.704668 23740 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 03:27:14.163497 23740 solver.cpp:228] Iteration 3000, loss = 0.000378619
I0403 03:27:14.170011 23740 solver.cpp:244]     Train net output #0: loss = 0.000378663 (* 1 = 0.000378663 loss)
I0403 03:27:14.358038 23740 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0403 03:27:21.773097 23740 solver.cpp:228] Iteration 3010, loss = 0.00292465
I0403 03:27:21.779793 23740 solver.cpp:244]     Train net output #0: loss = 0.00292469 (* 1 = 0.00292469 loss)
I0403 03:27:21.969815 23740 sgd_solver.cpp:106] Iteration 3010, lr = 0.0005
I0403 03:27:29.387409 23740 solver.cpp:228] Iteration 3020, loss = 0.00229135
I0403 03:27:29.398180 23740 solver.cpp:244]     Train net output #0: loss = 0.00229139 (* 1 = 0.00229139 loss)
I0403 03:27:29.631615 23740 sgd_solver.cpp:106] Iteration 3020, lr = 0.0005
I0403 03:27:37.090940 23740 solver.cpp:228] Iteration 3030, loss = 0.000116189
I0403 03:27:37.096735 23740 solver.cpp:244]     Train net output #0: loss = 0.000116233 (* 1 = 0.000116233 loss)
I0403 03:27:37.277356 23740 sgd_solver.cpp:106] Iteration 3030, lr = 0.0005
I0403 03:27:44.801431 23740 solver.cpp:228] Iteration 3040, loss = 0.000226862
I0403 03:27:44.807837 23740 solver.cpp:244]     Train net output #0: loss = 0.000226906 (* 1 = 0.000226906 loss)
I0403 03:27:44.923075 23740 sgd_solver.cpp:106] Iteration 3040, lr = 0.0005
I0403 03:27:52.458685 23740 solver.cpp:228] Iteration 3050, loss = 0.000276716
I0403 03:27:52.465986 23740 solver.cpp:244]     Train net output #0: loss = 0.000276761 (* 1 = 0.000276761 loss)
I0403 03:27:52.674484 23740 sgd_solver.cpp:106] Iteration 3050, lr = 0.0005
I0403 03:28:00.098047 23740 solver.cpp:228] Iteration 3060, loss = 0.000489072
I0403 03:28:00.104864 23740 solver.cpp:244]     Train net output #0: loss = 0.000489114 (* 1 = 0.000489114 loss)
I0403 03:28:00.275564 23740 sgd_solver.cpp:106] Iteration 3060, lr = 0.0005
I0403 03:28:04.193763 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3066.caffemodel
I0403 03:28:06.896605 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3066.solverstate
I0403 03:28:08.781080 23740 solver.cpp:337] Iteration 3066, Testing net (#0)
I0403 03:29:22.498416 23740 solver.cpp:404]     Test net output #0: accuracy = 0.980556
I0403 03:29:22.504386 23740 solver.cpp:404]     Test net output #1: loss = 0.0728745 (* 1 = 0.0728745 loss)
I0403 03:29:26.063315 23740 solver.cpp:228] Iteration 3070, loss = 0.0009442
I0403 03:29:26.070816 23740 solver.cpp:244]     Train net output #0: loss = 0.000944242 (* 1 = 0.000944242 loss)
I0403 03:29:26.267177 23740 sgd_solver.cpp:106] Iteration 3070, lr = 0.0005
I0403 03:29:33.629109 23740 solver.cpp:228] Iteration 3080, loss = 0.0147379
I0403 03:29:33.635577 23740 solver.cpp:244]     Train net output #0: loss = 0.0147379 (* 1 = 0.0147379 loss)
I0403 03:29:33.826664 23740 sgd_solver.cpp:106] Iteration 3080, lr = 0.0005
I0403 03:29:41.188451 23740 solver.cpp:228] Iteration 3090, loss = 0.000326416
I0403 03:29:41.194857 23740 solver.cpp:244]     Train net output #0: loss = 0.000326457 (* 1 = 0.000326457 loss)
I0403 03:29:41.378068 23740 sgd_solver.cpp:106] Iteration 3090, lr = 0.0005
I0403 03:29:48.757189 23740 solver.cpp:228] Iteration 3100, loss = 0.000572049
I0403 03:29:48.765060 23740 solver.cpp:244]     Train net output #0: loss = 0.00057209 (* 1 = 0.00057209 loss)
I0403 03:29:48.961210 23740 sgd_solver.cpp:106] Iteration 3100, lr = 0.0005
I0403 03:29:56.298934 23740 solver.cpp:228] Iteration 3110, loss = 0.0114151
I0403 03:29:56.305239 23740 solver.cpp:244]     Train net output #0: loss = 0.0114152 (* 1 = 0.0114152 loss)
I0403 03:29:56.477365 23740 sgd_solver.cpp:106] Iteration 3110, lr = 0.0005
I0403 03:30:03.908659 23740 solver.cpp:228] Iteration 3120, loss = 0.000497252
I0403 03:30:03.916003 23740 solver.cpp:244]     Train net output #0: loss = 0.000497293 (* 1 = 0.000497293 loss)
I0403 03:30:04.085986 23740 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 03:30:11.575541 23740 solver.cpp:228] Iteration 3130, loss = 0.00102999
I0403 03:30:11.581540 23740 solver.cpp:244]     Train net output #0: loss = 0.00103003 (* 1 = 0.00103003 loss)
I0403 03:30:11.741472 23740 sgd_solver.cpp:106] Iteration 3130, lr = 0.0005
I0403 03:30:19.121064 23740 solver.cpp:228] Iteration 3140, loss = 0.000755586
I0403 03:30:19.127487 23740 solver.cpp:244]     Train net output #0: loss = 0.000755628 (* 1 = 0.000755628 loss)
I0403 03:30:19.317086 23740 sgd_solver.cpp:106] Iteration 3140, lr = 0.0005
I0403 03:30:26.727844 23740 solver.cpp:228] Iteration 3150, loss = 0.00188376
I0403 03:30:26.734127 23740 solver.cpp:244]     Train net output #0: loss = 0.0018838 (* 1 = 0.0018838 loss)
I0403 03:30:26.892298 23740 sgd_solver.cpp:106] Iteration 3150, lr = 0.0005
I0403 03:30:34.373170 23740 solver.cpp:228] Iteration 3160, loss = 0.000240663
I0403 03:30:34.379979 23740 solver.cpp:244]     Train net output #0: loss = 0.000240707 (* 1 = 0.000240707 loss)
I0403 03:30:34.563697 23740 sgd_solver.cpp:106] Iteration 3160, lr = 0.0005
I0403 03:30:41.960803 23740 solver.cpp:228] Iteration 3170, loss = 0.00411596
I0403 03:30:41.968230 23740 solver.cpp:244]     Train net output #0: loss = 0.004116 (* 1 = 0.004116 loss)
I0403 03:30:42.240039 23740 sgd_solver.cpp:106] Iteration 3170, lr = 0.0005
I0403 03:30:49.647433 23740 solver.cpp:228] Iteration 3180, loss = 7.96436e-05
I0403 03:30:49.654263 23740 solver.cpp:244]     Train net output #0: loss = 7.96869e-05 (* 1 = 7.96869e-05 loss)
I0403 03:30:49.854491 23740 sgd_solver.cpp:106] Iteration 3180, lr = 0.0005
I0403 03:30:57.384878 23740 solver.cpp:228] Iteration 3190, loss = 0.000385318
I0403 03:30:57.391350 23740 solver.cpp:244]     Train net output #0: loss = 0.000385362 (* 1 = 0.000385362 loss)
I0403 03:30:57.565614 23740 sgd_solver.cpp:106] Iteration 3190, lr = 0.0005
I0403 03:31:05.027452 23740 solver.cpp:228] Iteration 3200, loss = 0.0280168
I0403 03:31:05.034831 23740 solver.cpp:244]     Train net output #0: loss = 0.0280169 (* 1 = 0.0280169 loss)
I0403 03:31:05.233139 23740 sgd_solver.cpp:106] Iteration 3200, lr = 0.0005
I0403 03:31:12.539649 23740 solver.cpp:228] Iteration 3210, loss = 0.00119367
I0403 03:31:12.545290 23740 solver.cpp:244]     Train net output #0: loss = 0.00119371 (* 1 = 0.00119371 loss)
I0403 03:31:12.762481 23740 sgd_solver.cpp:106] Iteration 3210, lr = 0.0005
I0403 03:31:20.175004 23740 solver.cpp:228] Iteration 3220, loss = 0.00241753
I0403 03:31:20.181851 23740 solver.cpp:244]     Train net output #0: loss = 0.00241758 (* 1 = 0.00241758 loss)
I0403 03:31:20.393455 23740 sgd_solver.cpp:106] Iteration 3220, lr = 0.0005
I0403 03:31:27.816272 23740 solver.cpp:228] Iteration 3230, loss = 0.000610018
I0403 03:31:27.822752 23740 solver.cpp:244]     Train net output #0: loss = 0.000610061 (* 1 = 0.000610061 loss)
I0403 03:31:28.023090 23740 sgd_solver.cpp:106] Iteration 3230, lr = 0.0005
I0403 03:31:35.362103 23740 solver.cpp:228] Iteration 3240, loss = 0.000161866
I0403 03:31:35.368499 23740 solver.cpp:244]     Train net output #0: loss = 0.000161909 (* 1 = 0.000161909 loss)
I0403 03:31:35.582334 23740 sgd_solver.cpp:106] Iteration 3240, lr = 0.0005
I0403 03:31:43.016996 23740 solver.cpp:228] Iteration 3250, loss = 0.00018861
I0403 03:31:43.022723 23740 solver.cpp:244]     Train net output #0: loss = 0.000188652 (* 1 = 0.000188652 loss)
I0403 03:31:43.184298 23740 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 03:31:50.554353 23740 solver.cpp:228] Iteration 3260, loss = 0.000935428
I0403 03:31:50.561492 23740 solver.cpp:244]     Train net output #0: loss = 0.00093547 (* 1 = 0.00093547 loss)
I0403 03:31:50.743846 23740 sgd_solver.cpp:106] Iteration 3260, lr = 0.0005
I0403 03:31:58.253612 23740 solver.cpp:228] Iteration 3270, loss = 0.00148378
I0403 03:31:58.260895 23740 solver.cpp:244]     Train net output #0: loss = 0.00148382 (* 1 = 0.00148382 loss)
I0403 03:31:58.444034 23740 sgd_solver.cpp:106] Iteration 3270, lr = 0.0005
I0403 03:32:05.891646 23740 solver.cpp:228] Iteration 3280, loss = 0.000943764
I0403 03:32:05.899740 23740 solver.cpp:244]     Train net output #0: loss = 0.000943806 (* 1 = 0.000943806 loss)
I0403 03:32:06.031901 23740 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 03:32:09.153432 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3285.caffemodel
I0403 03:32:11.914175 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3285.solverstate
I0403 03:32:13.833014 23740 solver.cpp:337] Iteration 3285, Testing net (#0)
I0403 03:33:27.556803 23740 solver.cpp:404]     Test net output #0: accuracy = 0.980988
I0403 03:33:27.564406 23740 solver.cpp:404]     Test net output #1: loss = 0.0706369 (* 1 = 0.0706369 loss)
I0403 03:33:31.987223 23740 solver.cpp:228] Iteration 3290, loss = 0.000798776
I0403 03:33:31.993898 23740 solver.cpp:244]     Train net output #0: loss = 0.000798816 (* 1 = 0.000798816 loss)
I0403 03:33:32.224438 23740 sgd_solver.cpp:106] Iteration 3290, lr = 0.0005
I0403 03:33:39.635047 23740 solver.cpp:228] Iteration 3300, loss = 0.00557334
I0403 03:33:39.641268 23740 solver.cpp:244]     Train net output #0: loss = 0.00557338 (* 1 = 0.00557338 loss)
I0403 03:33:39.824364 23740 sgd_solver.cpp:106] Iteration 3300, lr = 0.0005
I0403 03:33:47.258116 23740 solver.cpp:228] Iteration 3310, loss = 0.000539644
I0403 03:33:47.264250 23740 solver.cpp:244]     Train net output #0: loss = 0.000539683 (* 1 = 0.000539683 loss)
I0403 03:33:47.465534 23740 sgd_solver.cpp:106] Iteration 3310, lr = 0.0005
I0403 03:33:54.884431 23740 solver.cpp:228] Iteration 3320, loss = 0.00032502
I0403 03:33:54.891540 23740 solver.cpp:244]     Train net output #0: loss = 0.00032506 (* 1 = 0.00032506 loss)
I0403 03:33:55.078893 23740 sgd_solver.cpp:106] Iteration 3320, lr = 0.0005
I0403 03:34:02.568755 23740 solver.cpp:228] Iteration 3330, loss = 0.000780128
I0403 03:34:02.569037 23740 solver.cpp:244]     Train net output #0: loss = 0.000780168 (* 1 = 0.000780168 loss)
I0403 03:34:02.793706 23740 sgd_solver.cpp:106] Iteration 3330, lr = 0.0005
I0403 03:34:10.208634 23740 solver.cpp:228] Iteration 3340, loss = 0.000304837
I0403 03:34:10.208722 23740 solver.cpp:244]     Train net output #0: loss = 0.000304878 (* 1 = 0.000304878 loss)
I0403 03:34:10.400756 23740 sgd_solver.cpp:106] Iteration 3340, lr = 0.0005
I0403 03:34:17.832670 23740 solver.cpp:228] Iteration 3350, loss = 0.000157768
I0403 03:34:17.832772 23740 solver.cpp:244]     Train net output #0: loss = 0.000157809 (* 1 = 0.000157809 loss)
I0403 03:34:18.030714 23740 sgd_solver.cpp:106] Iteration 3350, lr = 0.0005
I0403 03:34:25.425107 23740 solver.cpp:228] Iteration 3360, loss = 0.00106955
I0403 03:34:25.425197 23740 solver.cpp:244]     Train net output #0: loss = 0.00106959 (* 1 = 0.00106959 loss)
I0403 03:34:25.618520 23740 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 03:34:33.013620 23740 solver.cpp:228] Iteration 3370, loss = 0.000567452
I0403 03:34:33.013870 23740 solver.cpp:244]     Train net output #0: loss = 0.000567493 (* 1 = 0.000567493 loss)
I0403 03:34:33.210880 23740 sgd_solver.cpp:106] Iteration 3370, lr = 0.0005
I0403 03:34:40.774186 23740 solver.cpp:228] Iteration 3380, loss = 0.029072
I0403 03:34:40.774293 23740 solver.cpp:244]     Train net output #0: loss = 0.029072 (* 1 = 0.029072 loss)
I0403 03:34:41.030483 23740 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 03:34:48.471071 23740 solver.cpp:228] Iteration 3390, loss = 0.00113575
I0403 03:34:48.471156 23740 solver.cpp:244]     Train net output #0: loss = 0.00113579 (* 1 = 0.00113579 loss)
I0403 03:34:48.653681 23740 sgd_solver.cpp:106] Iteration 3390, lr = 0.0005
I0403 03:34:56.014745 23740 solver.cpp:228] Iteration 3400, loss = 0.000270246
I0403 03:34:56.014842 23740 solver.cpp:244]     Train net output #0: loss = 0.000270289 (* 1 = 0.000270289 loss)
I0403 03:34:56.214395 23740 sgd_solver.cpp:106] Iteration 3400, lr = 0.0005
I0403 03:35:03.533023 23740 solver.cpp:228] Iteration 3410, loss = 0.00136538
I0403 03:35:03.533359 23740 solver.cpp:244]     Train net output #0: loss = 0.00136542 (* 1 = 0.00136542 loss)
I0403 03:35:03.749256 23740 sgd_solver.cpp:106] Iteration 3410, lr = 0.0005
I0403 03:35:11.163065 23740 solver.cpp:228] Iteration 3420, loss = 0.000353135
I0403 03:35:11.163164 23740 solver.cpp:244]     Train net output #0: loss = 0.000353177 (* 1 = 0.000353177 loss)
I0403 03:35:11.369170 23740 sgd_solver.cpp:106] Iteration 3420, lr = 0.0005
I0403 03:35:18.805881 23740 solver.cpp:228] Iteration 3430, loss = 0.000186976
I0403 03:35:18.805971 23740 solver.cpp:244]     Train net output #0: loss = 0.000187018 (* 1 = 0.000187018 loss)
I0403 03:35:18.995497 23740 sgd_solver.cpp:106] Iteration 3430, lr = 0.0005
I0403 03:35:26.539229 23740 solver.cpp:228] Iteration 3440, loss = 0.00463382
I0403 03:35:26.539331 23740 solver.cpp:244]     Train net output #0: loss = 0.00463386 (* 1 = 0.00463386 loss)
I0403 03:35:26.760577 23740 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 03:35:34.236055 23740 solver.cpp:228] Iteration 3450, loss = 0.00330123
I0403 03:35:34.236364 23740 solver.cpp:244]     Train net output #0: loss = 0.00330127 (* 1 = 0.00330127 loss)
I0403 03:35:34.440665 23740 sgd_solver.cpp:106] Iteration 3450, lr = 0.0005
I0403 03:35:41.894453 23740 solver.cpp:228] Iteration 3460, loss = 0.000903864
I0403 03:35:41.894541 23740 solver.cpp:244]     Train net output #0: loss = 0.000903905 (* 1 = 0.000903905 loss)
I0403 03:35:42.073338 23740 sgd_solver.cpp:106] Iteration 3460, lr = 0.0005
I0403 03:35:49.582671 23740 solver.cpp:228] Iteration 3470, loss = 0.000533689
I0403 03:35:49.582762 23740 solver.cpp:244]     Train net output #0: loss = 0.00053373 (* 1 = 0.00053373 loss)
I0403 03:35:49.766371 23740 sgd_solver.cpp:106] Iteration 3470, lr = 0.0005
I0403 03:35:57.221776 23740 solver.cpp:228] Iteration 3480, loss = 0.000857407
I0403 03:35:57.221865 23740 solver.cpp:244]     Train net output #0: loss = 0.000857447 (* 1 = 0.000857447 loss)
I0403 03:35:57.388789 23740 sgd_solver.cpp:106] Iteration 3480, lr = 0.0005
I0403 03:36:04.997104 23740 solver.cpp:228] Iteration 3490, loss = 0.00104028
I0403 03:36:04.997400 23740 solver.cpp:244]     Train net output #0: loss = 0.00104032 (* 1 = 0.00104032 loss)
I0403 03:36:05.187990 23740 sgd_solver.cpp:106] Iteration 3490, lr = 0.0005
I0403 03:36:12.641615 23740 solver.cpp:228] Iteration 3500, loss = 0.00160516
I0403 03:36:12.641700 23740 solver.cpp:244]     Train net output #0: loss = 0.0016052 (* 1 = 0.0016052 loss)
I0403 03:36:12.830343 23740 sgd_solver.cpp:106] Iteration 3500, lr = 0.0005
I0403 03:36:15.112566 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3504.caffemodel
I0403 03:36:17.919672 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3504.solverstate
I0403 03:36:19.781775 23740 solver.cpp:337] Iteration 3504, Testing net (#0)
I0403 03:37:33.493772 23740 solver.cpp:404]     Test net output #0: accuracy = 0.980185
I0403 03:37:33.494117 23740 solver.cpp:404]     Test net output #1: loss = 0.0734866 (* 1 = 0.0734866 loss)
I0403 03:37:38.595648 23740 solver.cpp:228] Iteration 3510, loss = 0.0132314
I0403 03:37:38.595734 23740 solver.cpp:244]     Train net output #0: loss = 0.0132315 (* 1 = 0.0132315 loss)
I0403 03:37:38.784435 23740 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 03:37:46.203593 23740 solver.cpp:228] Iteration 3520, loss = 0.000193425
I0403 03:37:46.203680 23740 solver.cpp:244]     Train net output #0: loss = 0.000193466 (* 1 = 0.000193466 loss)
I0403 03:37:46.393513 23740 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 03:37:53.775513 23740 solver.cpp:228] Iteration 3530, loss = 0.000933423
I0403 03:37:53.775612 23740 solver.cpp:244]     Train net output #0: loss = 0.000933465 (* 1 = 0.000933465 loss)
I0403 03:37:53.987031 23740 sgd_solver.cpp:106] Iteration 3530, lr = 0.0005
I0403 03:38:01.389453 23740 solver.cpp:228] Iteration 3540, loss = 0.00309728
I0403 03:38:01.389542 23740 solver.cpp:244]     Train net output #0: loss = 0.00309732 (* 1 = 0.00309732 loss)
I0403 03:38:01.574189 23740 sgd_solver.cpp:106] Iteration 3540, lr = 0.0005
I0403 03:38:09.016857 23740 solver.cpp:228] Iteration 3550, loss = 0.000458982
I0403 03:38:09.017748 23740 solver.cpp:244]     Train net output #0: loss = 0.000459024 (* 1 = 0.000459024 loss)
I0403 03:38:09.206133 23740 sgd_solver.cpp:106] Iteration 3550, lr = 0.0005
I0403 03:38:16.723501 23740 solver.cpp:228] Iteration 3560, loss = 0.000985609
I0403 03:38:16.723589 23740 solver.cpp:244]     Train net output #0: loss = 0.000985651 (* 1 = 0.000985651 loss)
I0403 03:38:16.903899 23740 sgd_solver.cpp:106] Iteration 3560, lr = 0.0005
I0403 03:38:24.314164 23740 solver.cpp:228] Iteration 3570, loss = 0.0150039
I0403 03:38:24.314250 23740 solver.cpp:244]     Train net output #0: loss = 0.0150039 (* 1 = 0.0150039 loss)
I0403 03:38:24.503772 23740 sgd_solver.cpp:106] Iteration 3570, lr = 0.0005
I0403 03:38:31.930943 23740 solver.cpp:228] Iteration 3580, loss = 0.000282018
I0403 03:38:31.931048 23740 solver.cpp:244]     Train net output #0: loss = 0.00028206 (* 1 = 0.00028206 loss)
I0403 03:38:32.141266 23740 sgd_solver.cpp:106] Iteration 3580, lr = 0.0005
I0403 03:38:39.497282 23740 solver.cpp:228] Iteration 3590, loss = 0.00752868
I0403 03:38:39.502287 23740 solver.cpp:244]     Train net output #0: loss = 0.00752872 (* 1 = 0.00752872 loss)
I0403 03:38:39.677311 23740 sgd_solver.cpp:106] Iteration 3590, lr = 0.0005
I0403 03:38:47.179608 23740 solver.cpp:228] Iteration 3600, loss = 0.00174558
I0403 03:38:47.179699 23740 solver.cpp:244]     Train net output #0: loss = 0.00174562 (* 1 = 0.00174562 loss)
I0403 03:38:47.368216 23740 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 03:38:54.852840 23740 solver.cpp:228] Iteration 3610, loss = 0.00691695
I0403 03:38:54.852946 23740 solver.cpp:244]     Train net output #0: loss = 0.00691699 (* 1 = 0.00691699 loss)
I0403 03:38:55.071240 23740 sgd_solver.cpp:106] Iteration 3610, lr = 0.0005
I0403 03:39:02.645884 23740 solver.cpp:228] Iteration 3620, loss = 0.000920596
I0403 03:39:02.645977 23740 solver.cpp:244]     Train net output #0: loss = 0.000920637 (* 1 = 0.000920637 loss)
I0403 03:39:02.819629 23740 sgd_solver.cpp:106] Iteration 3620, lr = 0.0005
I0403 03:39:10.319864 23740 solver.cpp:228] Iteration 3630, loss = 0.00119736
I0403 03:39:10.320159 23740 solver.cpp:244]     Train net output #0: loss = 0.00119741 (* 1 = 0.00119741 loss)
I0403 03:39:10.500133 23740 sgd_solver.cpp:106] Iteration 3630, lr = 0.0005
I0403 03:39:17.933645 23740 solver.cpp:228] Iteration 3640, loss = 0.00140265
I0403 03:39:17.933733 23740 solver.cpp:244]     Train net output #0: loss = 0.00140269 (* 1 = 0.00140269 loss)
I0403 03:39:18.125250 23740 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 03:39:25.606539 23740 solver.cpp:228] Iteration 3650, loss = 0.00100174
I0403 03:39:25.606628 23740 solver.cpp:244]     Train net output #0: loss = 0.00100179 (* 1 = 0.00100179 loss)
I0403 03:39:25.788251 23740 sgd_solver.cpp:106] Iteration 3650, lr = 0.0005
I0403 03:39:33.256458 23740 solver.cpp:228] Iteration 3660, loss = 0.0146538
I0403 03:39:33.256546 23740 solver.cpp:244]     Train net output #0: loss = 0.0146539 (* 1 = 0.0146539 loss)
I0403 03:39:33.444362 23740 sgd_solver.cpp:106] Iteration 3660, lr = 0.0005
I0403 03:39:40.806751 23740 solver.cpp:228] Iteration 3670, loss = 0.000151321
I0403 03:39:40.807052 23740 solver.cpp:244]     Train net output #0: loss = 0.000151361 (* 1 = 0.000151361 loss)
I0403 03:39:41.004618 23740 sgd_solver.cpp:106] Iteration 3670, lr = 0.0005
I0403 03:39:48.467438 23740 solver.cpp:228] Iteration 3680, loss = 0.000831664
I0403 03:39:48.467524 23740 solver.cpp:244]     Train net output #0: loss = 0.000831705 (* 1 = 0.000831705 loss)
I0403 03:39:48.624564 23740 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 03:39:56.342645 23740 solver.cpp:228] Iteration 3690, loss = 0.000246062
I0403 03:39:56.342735 23740 solver.cpp:244]     Train net output #0: loss = 0.000246102 (* 1 = 0.000246102 loss)
I0403 03:39:56.525732 23740 sgd_solver.cpp:106] Iteration 3690, lr = 0.0005
I0403 03:40:04.041105 23740 solver.cpp:228] Iteration 3700, loss = 0.00334826
I0403 03:40:04.041193 23740 solver.cpp:244]     Train net output #0: loss = 0.0033483 (* 1 = 0.0033483 loss)
I0403 03:40:04.219493 23740 sgd_solver.cpp:106] Iteration 3700, lr = 0.0005
I0403 03:40:11.679750 23740 solver.cpp:228] Iteration 3710, loss = 0.000550575
I0403 03:40:11.680090 23740 solver.cpp:244]     Train net output #0: loss = 0.00055062 (* 1 = 0.00055062 loss)
I0403 03:40:11.907048 23740 sgd_solver.cpp:106] Iteration 3710, lr = 0.0005
I0403 03:40:19.267608 23740 solver.cpp:228] Iteration 3720, loss = 0.000302096
I0403 03:40:19.267711 23740 solver.cpp:244]     Train net output #0: loss = 0.000302141 (* 1 = 0.000302141 loss)
I0403 03:40:19.471597 23740 sgd_solver.cpp:106] Iteration 3720, lr = 0.0005
I0403 03:40:20.974198 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3723.caffemodel
I0403 03:40:23.735409 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3723.solverstate
I0403 03:40:25.618417 23740 solver.cpp:337] Iteration 3723, Testing net (#0)
I0403 03:41:39.344120 23740 solver.cpp:404]     Test net output #0: accuracy = 0.980433
I0403 03:41:39.344470 23740 solver.cpp:404]     Test net output #1: loss = 0.0730952 (* 1 = 0.0730952 loss)
I0403 03:41:45.137372 23740 solver.cpp:228] Iteration 3730, loss = 0.000383615
I0403 03:41:45.137472 23740 solver.cpp:244]     Train net output #0: loss = 0.00038366 (* 1 = 0.00038366 loss)
I0403 03:41:45.360957 23740 sgd_solver.cpp:106] Iteration 3730, lr = 0.0005
I0403 03:41:52.697268 23740 solver.cpp:228] Iteration 3740, loss = 0.00106273
I0403 03:41:52.697367 23740 solver.cpp:244]     Train net output #0: loss = 0.00106277 (* 1 = 0.00106277 loss)
I0403 03:41:52.894798 23740 sgd_solver.cpp:106] Iteration 3740, lr = 0.0005
I0403 03:42:00.334856 23740 solver.cpp:228] Iteration 3750, loss = 0.0171607
I0403 03:42:00.334965 23740 solver.cpp:244]     Train net output #0: loss = 0.0171607 (* 1 = 0.0171607 loss)
I0403 03:42:00.553825 23740 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0403 03:42:08.107404 23740 solver.cpp:228] Iteration 3760, loss = 0.000538434
I0403 03:42:08.107504 23740 solver.cpp:244]     Train net output #0: loss = 0.000538478 (* 1 = 0.000538478 loss)
I0403 03:42:08.314921 23740 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 03:42:15.713336 23740 solver.cpp:228] Iteration 3770, loss = 0.000657953
I0403 03:42:15.713642 23740 solver.cpp:244]     Train net output #0: loss = 0.000657997 (* 1 = 0.000657997 loss)
I0403 03:42:15.960851 23740 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 03:42:23.318147 23740 solver.cpp:228] Iteration 3780, loss = 0.00017165
I0403 03:42:23.318238 23740 solver.cpp:244]     Train net output #0: loss = 0.000171694 (* 1 = 0.000171694 loss)
I0403 03:42:23.514112 23740 sgd_solver.cpp:106] Iteration 3780, lr = 0.0005
I0403 03:42:30.984192 23740 solver.cpp:228] Iteration 3790, loss = 0.000342814
I0403 03:42:30.984279 23740 solver.cpp:244]     Train net output #0: loss = 0.000342857 (* 1 = 0.000342857 loss)
I0403 03:42:31.129314 23740 sgd_solver.cpp:106] Iteration 3790, lr = 0.0005
I0403 03:42:38.578694 23740 solver.cpp:228] Iteration 3800, loss = 0.000511956
I0403 03:42:38.578797 23740 solver.cpp:244]     Train net output #0: loss = 0.000512 (* 1 = 0.000512 loss)
I0403 03:42:38.775810 23740 sgd_solver.cpp:106] Iteration 3800, lr = 0.0005
I0403 03:42:46.160112 23740 solver.cpp:228] Iteration 3810, loss = 0.000273347
I0403 03:42:46.160449 23740 solver.cpp:244]     Train net output #0: loss = 0.00027339 (* 1 = 0.00027339 loss)
I0403 03:42:46.380014 23740 sgd_solver.cpp:106] Iteration 3810, lr = 0.0005
I0403 03:42:53.838930 23740 solver.cpp:228] Iteration 3820, loss = 0.000118345
I0403 03:42:53.839017 23740 solver.cpp:244]     Train net output #0: loss = 0.000118391 (* 1 = 0.000118391 loss)
I0403 03:42:54.015290 23740 sgd_solver.cpp:106] Iteration 3820, lr = 0.0005
I0403 03:43:01.523620 23740 solver.cpp:228] Iteration 3830, loss = 0.000397779
I0403 03:43:01.523705 23740 solver.cpp:244]     Train net output #0: loss = 0.000397825 (* 1 = 0.000397825 loss)
I0403 03:43:01.705395 23740 sgd_solver.cpp:106] Iteration 3830, lr = 0.0005
I0403 03:43:09.059594 23740 solver.cpp:228] Iteration 3840, loss = 0.000321902
I0403 03:43:09.059695 23740 solver.cpp:244]     Train net output #0: loss = 0.000321948 (* 1 = 0.000321948 loss)
I0403 03:43:09.260764 23740 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 03:43:16.790935 23740 solver.cpp:228] Iteration 3850, loss = 0.000363471
I0403 03:43:16.791225 23740 solver.cpp:244]     Train net output #0: loss = 0.000363517 (* 1 = 0.000363517 loss)
I0403 03:43:16.967041 23740 sgd_solver.cpp:106] Iteration 3850, lr = 0.0005
I0403 03:43:24.752223 23740 solver.cpp:228] Iteration 3860, loss = 0.00082853
I0403 03:43:24.752315 23740 solver.cpp:244]     Train net output #0: loss = 0.000828575 (* 1 = 0.000828575 loss)
I0403 03:43:24.946807 23740 sgd_solver.cpp:106] Iteration 3860, lr = 0.0005
I0403 03:43:32.525475 23740 solver.cpp:228] Iteration 3870, loss = 0.000954909
I0403 03:43:32.525578 23740 solver.cpp:244]     Train net output #0: loss = 0.000954955 (* 1 = 0.000954955 loss)
I0403 03:43:32.730331 23740 sgd_solver.cpp:106] Iteration 3870, lr = 0.0005
I0403 03:43:40.096735 23740 solver.cpp:228] Iteration 3880, loss = 0.00876762
I0403 03:43:40.096823 23740 solver.cpp:244]     Train net output #0: loss = 0.00876767 (* 1 = 0.00876767 loss)
I0403 03:43:40.266757 23740 sgd_solver.cpp:106] Iteration 3880, lr = 0.0005
I0403 03:43:47.688490 23740 solver.cpp:228] Iteration 3890, loss = 7.85994e-05
I0403 03:43:47.688796 23740 solver.cpp:244]     Train net output #0: loss = 7.86454e-05 (* 1 = 7.86454e-05 loss)
I0403 03:43:47.930065 23740 sgd_solver.cpp:106] Iteration 3890, lr = 0.0005
I0403 03:43:55.321516 23740 solver.cpp:228] Iteration 3900, loss = 0.00121485
I0403 03:43:55.321611 23740 solver.cpp:244]     Train net output #0: loss = 0.0012149 (* 1 = 0.0012149 loss)
I0403 03:43:55.530063 23740 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 03:44:02.997025 23740 solver.cpp:228] Iteration 3910, loss = 0.000231154
I0403 03:44:02.997112 23740 solver.cpp:244]     Train net output #0: loss = 0.000231201 (* 1 = 0.000231201 loss)
I0403 03:44:03.186486 23740 sgd_solver.cpp:106] Iteration 3910, lr = 0.0005
I0403 03:44:10.602123 23740 solver.cpp:228] Iteration 3920, loss = 0.000233347
I0403 03:44:10.602224 23740 solver.cpp:244]     Train net output #0: loss = 0.000233394 (* 1 = 0.000233394 loss)
I0403 03:44:10.804746 23740 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 03:44:18.182493 23740 solver.cpp:228] Iteration 3930, loss = 0.00105305
I0403 03:44:18.182788 23740 solver.cpp:244]     Train net output #0: loss = 0.0010531 (* 1 = 0.0010531 loss)
I0403 03:44:18.383132 23740 sgd_solver.cpp:106] Iteration 3930, lr = 0.0005
I0403 03:44:25.783922 23740 solver.cpp:228] Iteration 3940, loss = 0.000568487
I0403 03:44:25.784024 23740 solver.cpp:244]     Train net output #0: loss = 0.000568535 (* 1 = 0.000568535 loss)
I0403 03:44:25.993288 23740 sgd_solver.cpp:106] Iteration 3940, lr = 0.0005
I0403 03:44:26.753255 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3942.caffemodel
I0403 03:44:29.504588 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_3942.solverstate
I0403 03:44:31.353255 23740 solver.cpp:337] Iteration 3942, Testing net (#0)
I0403 03:45:45.052603 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981204
I0403 03:45:45.052934 23740 solver.cpp:404]     Test net output #1: loss = 0.0717891 (* 1 = 0.0717891 loss)
I0403 03:45:51.751327 23740 solver.cpp:228] Iteration 3950, loss = 0.000157503
I0403 03:45:51.751427 23740 solver.cpp:244]     Train net output #0: loss = 0.000157551 (* 1 = 0.000157551 loss)
I0403 03:45:51.980469 23740 sgd_solver.cpp:106] Iteration 3950, lr = 0.0005
I0403 03:45:59.443259 23740 solver.cpp:228] Iteration 3960, loss = 0.00012324
I0403 03:45:59.443362 23740 solver.cpp:244]     Train net output #0: loss = 0.000123287 (* 1 = 0.000123287 loss)
I0403 03:45:59.670373 23740 sgd_solver.cpp:106] Iteration 3960, lr = 0.0005
I0403 03:46:07.064414 23740 solver.cpp:228] Iteration 3970, loss = 0.000326168
I0403 03:46:07.064517 23740 solver.cpp:244]     Train net output #0: loss = 0.000326215 (* 1 = 0.000326215 loss)
I0403 03:46:07.261587 23740 sgd_solver.cpp:106] Iteration 3970, lr = 0.0005
I0403 03:46:14.669111 23740 solver.cpp:228] Iteration 3980, loss = 0.00603646
I0403 03:46:14.669195 23740 solver.cpp:244]     Train net output #0: loss = 0.00603651 (* 1 = 0.00603651 loss)
I0403 03:46:14.853960 23740 sgd_solver.cpp:106] Iteration 3980, lr = 0.0005
I0403 03:46:22.233990 23740 solver.cpp:228] Iteration 3990, loss = 0.000101666
I0403 03:46:22.234285 23740 solver.cpp:244]     Train net output #0: loss = 0.000101712 (* 1 = 0.000101712 loss)
I0403 03:46:22.414243 23740 sgd_solver.cpp:106] Iteration 3990, lr = 0.0005
I0403 03:46:29.865030 23740 solver.cpp:228] Iteration 4000, loss = 0.00388115
I0403 03:46:29.865115 23740 solver.cpp:244]     Train net output #0: loss = 0.0038812 (* 1 = 0.0038812 loss)
I0403 03:46:30.035187 23740 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 03:46:37.573340 23740 solver.cpp:228] Iteration 4010, loss = 0.000813482
I0403 03:46:37.573429 23740 solver.cpp:244]     Train net output #0: loss = 0.000813528 (* 1 = 0.000813528 loss)
I0403 03:46:37.753304 23740 sgd_solver.cpp:106] Iteration 4010, lr = 0.0005
I0403 03:46:45.196503 23740 solver.cpp:228] Iteration 4020, loss = 0.00230861
I0403 03:46:45.196602 23740 solver.cpp:244]     Train net output #0: loss = 0.00230866 (* 1 = 0.00230866 loss)
I0403 03:46:45.391916 23740 sgd_solver.cpp:106] Iteration 4020, lr = 0.0005
I0403 03:46:52.807986 23740 solver.cpp:228] Iteration 4030, loss = 0.000229392
I0403 03:46:52.808259 23740 solver.cpp:244]     Train net output #0: loss = 0.000229439 (* 1 = 0.000229439 loss)
I0403 03:46:52.993152 23740 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 03:47:00.472533 23740 solver.cpp:228] Iteration 4040, loss = 5.58895e-05
I0403 03:47:00.472620 23740 solver.cpp:244]     Train net output #0: loss = 5.59381e-05 (* 1 = 5.59381e-05 loss)
I0403 03:47:00.640398 23740 sgd_solver.cpp:106] Iteration 4040, lr = 0.0005
I0403 03:47:08.028241 23740 solver.cpp:228] Iteration 4050, loss = 0.00427959
I0403 03:47:08.028329 23740 solver.cpp:244]     Train net output #0: loss = 0.00427963 (* 1 = 0.00427963 loss)
I0403 03:47:08.207696 23740 sgd_solver.cpp:106] Iteration 4050, lr = 0.0005
I0403 03:47:15.584403 23740 solver.cpp:228] Iteration 4060, loss = 0.000862201
I0403 03:47:15.584487 23740 solver.cpp:244]     Train net output #0: loss = 0.00086225 (* 1 = 0.00086225 loss)
I0403 03:47:15.773222 23740 sgd_solver.cpp:106] Iteration 4060, lr = 0.0005
I0403 03:47:23.122263 23740 solver.cpp:228] Iteration 4070, loss = 2.305e-05
I0403 03:47:23.122572 23740 solver.cpp:244]     Train net output #0: loss = 2.30979e-05 (* 1 = 2.30979e-05 loss)
I0403 03:47:23.359413 23740 sgd_solver.cpp:106] Iteration 4070, lr = 0.0005
I0403 03:47:30.741587 23740 solver.cpp:228] Iteration 4080, loss = 0.000643875
I0403 03:47:30.741672 23740 solver.cpp:244]     Train net output #0: loss = 0.000643923 (* 1 = 0.000643923 loss)
I0403 03:47:30.929044 23740 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 03:47:38.347580 23740 solver.cpp:228] Iteration 4090, loss = 0.00310909
I0403 03:47:38.347681 23740 solver.cpp:244]     Train net output #0: loss = 0.00310914 (* 1 = 0.00310914 loss)
I0403 03:47:38.545191 23740 sgd_solver.cpp:106] Iteration 4090, lr = 0.0005
I0403 03:47:45.915056 23740 solver.cpp:228] Iteration 4100, loss = 0.00224765
I0403 03:47:45.915155 23740 solver.cpp:244]     Train net output #0: loss = 0.0022477 (* 1 = 0.0022477 loss)
I0403 03:47:46.122536 23740 sgd_solver.cpp:106] Iteration 4100, lr = 0.0005
I0403 03:47:53.599961 23740 solver.cpp:228] Iteration 4110, loss = 0.00234937
I0403 03:47:53.600253 23740 solver.cpp:244]     Train net output #0: loss = 0.00234942 (* 1 = 0.00234942 loss)
I0403 03:47:53.840456 23740 sgd_solver.cpp:106] Iteration 4110, lr = 0.0005
I0403 03:48:01.225361 23740 solver.cpp:228] Iteration 4120, loss = 6.06303e-05
I0403 03:48:01.225463 23740 solver.cpp:244]     Train net output #0: loss = 6.06801e-05 (* 1 = 6.06801e-05 loss)
I0403 03:48:01.453588 23740 sgd_solver.cpp:106] Iteration 4120, lr = 0.0005
I0403 03:48:08.964135 23740 solver.cpp:228] Iteration 4130, loss = 9.85785e-05
I0403 03:48:08.964231 23740 solver.cpp:244]     Train net output #0: loss = 9.86283e-05 (* 1 = 9.86283e-05 loss)
I0403 03:48:09.134218 23740 sgd_solver.cpp:106] Iteration 4130, lr = 0.0005
I0403 03:48:16.627765 23740 solver.cpp:228] Iteration 4140, loss = 0.000113242
I0403 03:48:16.627866 23740 solver.cpp:244]     Train net output #0: loss = 0.000113292 (* 1 = 0.000113292 loss)
I0403 03:48:16.854456 23740 sgd_solver.cpp:106] Iteration 4140, lr = 0.0005
I0403 03:48:24.267354 23740 solver.cpp:228] Iteration 4150, loss = 0.0167328
I0403 03:48:24.267647 23740 solver.cpp:244]     Train net output #0: loss = 0.0167329 (* 1 = 0.0167329 loss)
I0403 03:48:24.447114 23740 sgd_solver.cpp:106] Iteration 4150, lr = 0.0005
I0403 03:48:31.849182 23740 solver.cpp:228] Iteration 4160, loss = 0.000697932
I0403 03:48:31.849292 23740 solver.cpp:244]     Train net output #0: loss = 0.000697985 (* 1 = 0.000697985 loss)
I0403 03:48:32.047078 23740 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:48:32.047319 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4161.caffemodel
I0403 03:48:34.812098 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4161.solverstate
I0403 03:48:36.694331 23740 solver.cpp:337] Iteration 4161, Testing net (#0)
I0403 03:49:50.395298 23740 solver.cpp:404]     Test net output #0: accuracy = 0.98105
I0403 03:49:50.395619 23740 solver.cpp:404]     Test net output #1: loss = 0.0715372 (* 1 = 0.0715372 loss)
I0403 03:49:57.895009 23740 solver.cpp:228] Iteration 4170, loss = 0.00107234
I0403 03:49:57.895109 23740 solver.cpp:244]     Train net output #0: loss = 0.00107239 (* 1 = 0.00107239 loss)
I0403 03:49:58.102028 23740 sgd_solver.cpp:106] Iteration 4170, lr = 0.0005
I0403 03:50:05.508183 23740 solver.cpp:228] Iteration 4180, loss = 0.000924105
I0403 03:50:05.508270 23740 solver.cpp:244]     Train net output #0: loss = 0.000924158 (* 1 = 0.000924158 loss)
I0403 03:50:05.697077 23740 sgd_solver.cpp:106] Iteration 4180, lr = 0.0005
I0403 03:50:13.127496 23740 solver.cpp:228] Iteration 4190, loss = 0.000391915
I0403 03:50:13.127598 23740 solver.cpp:244]     Train net output #0: loss = 0.000391968 (* 1 = 0.000391968 loss)
I0403 03:50:13.322180 23740 sgd_solver.cpp:106] Iteration 4190, lr = 0.0005
I0403 03:50:20.728657 23740 solver.cpp:228] Iteration 4200, loss = 0.000132401
I0403 03:50:20.728952 23740 solver.cpp:244]     Train net output #0: loss = 0.000132453 (* 1 = 0.000132453 loss)
I0403 03:50:20.916684 23740 sgd_solver.cpp:106] Iteration 4200, lr = 0.0005
I0403 03:50:28.283196 23740 solver.cpp:228] Iteration 4210, loss = 0.00178968
I0403 03:50:28.283283 23740 solver.cpp:244]     Train net output #0: loss = 0.00178973 (* 1 = 0.00178973 loss)
I0403 03:50:28.467056 23740 sgd_solver.cpp:106] Iteration 4210, lr = 0.0005
I0403 03:50:35.933922 23740 solver.cpp:228] Iteration 4220, loss = 0.0005757
I0403 03:50:35.934015 23740 solver.cpp:244]     Train net output #0: loss = 0.000575752 (* 1 = 0.000575752 loss)
I0403 03:50:36.082505 23740 sgd_solver.cpp:106] Iteration 4220, lr = 0.0005
I0403 03:50:43.593732 23740 solver.cpp:228] Iteration 4230, loss = 0.000189792
I0403 03:50:43.593832 23740 solver.cpp:244]     Train net output #0: loss = 0.000189845 (* 1 = 0.000189845 loss)
I0403 03:50:43.788022 23740 sgd_solver.cpp:106] Iteration 4230, lr = 0.0005
I0403 03:50:51.260869 23740 solver.cpp:228] Iteration 4240, loss = 0.000924679
I0403 03:50:51.261176 23740 solver.cpp:244]     Train net output #0: loss = 0.000924731 (* 1 = 0.000924731 loss)
I0403 03:50:51.447947 23740 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 03:50:58.857956 23740 solver.cpp:228] Iteration 4250, loss = 0.00110422
I0403 03:50:58.858041 23740 solver.cpp:244]     Train net output #0: loss = 0.00110427 (* 1 = 0.00110427 loss)
I0403 03:50:59.042650 23740 sgd_solver.cpp:106] Iteration 4250, lr = 0.0005
I0403 03:51:06.458962 23740 solver.cpp:228] Iteration 4260, loss = 0.000489281
I0403 03:51:06.459064 23740 solver.cpp:244]     Train net output #0: loss = 0.000489333 (* 1 = 0.000489333 loss)
I0403 03:51:06.729959 23740 sgd_solver.cpp:106] Iteration 4260, lr = 0.0005
I0403 03:51:14.155973 23740 solver.cpp:228] Iteration 4270, loss = 0.00672622
I0403 03:51:14.156060 23740 solver.cpp:244]     Train net output #0: loss = 0.00672628 (* 1 = 0.00672628 loss)
I0403 03:51:14.349830 23740 sgd_solver.cpp:106] Iteration 4270, lr = 0.0005
I0403 03:51:21.775796 23740 solver.cpp:228] Iteration 4280, loss = 0.00166565
I0403 03:51:21.776098 23740 solver.cpp:244]     Train net output #0: loss = 0.0016657 (* 1 = 0.0016657 loss)
I0403 03:51:21.980363 23740 sgd_solver.cpp:106] Iteration 4280, lr = 0.0005
I0403 03:51:29.383008 23740 solver.cpp:228] Iteration 4290, loss = 0.00904777
I0403 03:51:29.383095 23740 solver.cpp:244]     Train net output #0: loss = 0.00904782 (* 1 = 0.00904782 loss)
I0403 03:51:29.572299 23740 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 03:51:37.055037 23740 solver.cpp:228] Iteration 4300, loss = 0.000228621
I0403 03:51:37.055143 23740 solver.cpp:244]     Train net output #0: loss = 0.000228673 (* 1 = 0.000228673 loss)
I0403 03:51:37.230414 23740 sgd_solver.cpp:106] Iteration 4300, lr = 0.0005
I0403 03:51:44.784719 23740 solver.cpp:228] Iteration 4310, loss = 0.00124087
I0403 03:51:44.784817 23740 solver.cpp:244]     Train net output #0: loss = 0.00124092 (* 1 = 0.00124092 loss)
I0403 03:51:44.979785 23740 sgd_solver.cpp:106] Iteration 4310, lr = 0.0005
I0403 03:51:52.429874 23740 solver.cpp:228] Iteration 4320, loss = 0.00265633
I0403 03:51:52.430148 23740 solver.cpp:244]     Train net output #0: loss = 0.00265638 (* 1 = 0.00265638 loss)
I0403 03:51:52.603970 23740 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 03:52:00.097596 23740 solver.cpp:228] Iteration 4330, loss = 5.63994e-05
I0403 03:52:00.097697 23740 solver.cpp:244]     Train net output #0: loss = 5.64512e-05 (* 1 = 5.64512e-05 loss)
I0403 03:52:00.305249 23740 sgd_solver.cpp:106] Iteration 4330, lr = 0.0005
I0403 03:52:07.667639 23740 solver.cpp:228] Iteration 4340, loss = 2.86759e-05
I0403 03:52:07.667735 23740 solver.cpp:244]     Train net output #0: loss = 2.87273e-05 (* 1 = 2.87273e-05 loss)
I0403 03:52:07.857372 23740 sgd_solver.cpp:106] Iteration 4340, lr = 0.0005
I0403 03:52:15.234475 23740 solver.cpp:228] Iteration 4350, loss = 0.000317201
I0403 03:52:15.234562 23740 solver.cpp:244]     Train net output #0: loss = 0.000317253 (* 1 = 0.000317253 loss)
I0403 03:52:15.417600 23740 sgd_solver.cpp:106] Iteration 4350, lr = 0.0005
I0403 03:52:22.869403 23740 solver.cpp:228] Iteration 4360, loss = 0.00220152
I0403 03:52:22.869683 23740 solver.cpp:244]     Train net output #0: loss = 0.00220157 (* 1 = 0.00220157 loss)
I0403 03:52:23.100160 23740 sgd_solver.cpp:106] Iteration 4360, lr = 0.0005
I0403 03:52:30.478282 23740 solver.cpp:228] Iteration 4370, loss = 0.000567869
I0403 03:52:30.478368 23740 solver.cpp:244]     Train net output #0: loss = 0.00056792 (* 1 = 0.00056792 loss)
I0403 03:52:30.668359 23740 sgd_solver.cpp:106] Iteration 4370, lr = 0.0005
I0403 03:52:37.560052 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4380.caffemodel
I0403 03:52:40.341578 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4380.solverstate
I0403 03:52:42.233901 23740 solver.cpp:337] Iteration 4380, Testing net (#0)
I0403 03:53:55.953748 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981297
I0403 03:53:55.954088 23740 solver.cpp:404]     Test net output #1: loss = 0.0707897 (* 1 = 0.0707897 loss)
I0403 03:53:56.504122 23740 solver.cpp:228] Iteration 4380, loss = 0.00784145
I0403 03:53:56.504205 23740 solver.cpp:244]     Train net output #0: loss = 0.0078415 (* 1 = 0.0078415 loss)
I0403 03:53:56.683106 23740 sgd_solver.cpp:106] Iteration 4380, lr = 5e-05
I0403 03:54:04.204015 23740 solver.cpp:228] Iteration 4390, loss = 0.00389496
I0403 03:54:04.204104 23740 solver.cpp:244]     Train net output #0: loss = 0.003895 (* 1 = 0.003895 loss)
I0403 03:54:04.393903 23740 sgd_solver.cpp:106] Iteration 4390, lr = 5e-05
I0403 03:54:11.783588 23740 solver.cpp:228] Iteration 4400, loss = 0.000784266
I0403 03:54:11.783689 23740 solver.cpp:244]     Train net output #0: loss = 0.000784314 (* 1 = 0.000784314 loss)
I0403 03:54:11.990414 23740 sgd_solver.cpp:106] Iteration 4400, lr = 5e-05
I0403 03:54:19.382797 23740 solver.cpp:228] Iteration 4410, loss = 0.000889818
I0403 03:54:19.382884 23740 solver.cpp:244]     Train net output #0: loss = 0.000889865 (* 1 = 0.000889865 loss)
I0403 03:54:19.573523 23740 sgd_solver.cpp:106] Iteration 4410, lr = 5e-05
I0403 03:54:27.044528 23740 solver.cpp:228] Iteration 4420, loss = 0.00156835
I0403 03:54:27.044836 23740 solver.cpp:244]     Train net output #0: loss = 0.0015684 (* 1 = 0.0015684 loss)
I0403 03:54:27.248543 23740 sgd_solver.cpp:106] Iteration 4420, lr = 5e-05
I0403 03:54:34.662396 23740 solver.cpp:228] Iteration 4430, loss = 0.00713414
I0403 03:54:34.662495 23740 solver.cpp:244]     Train net output #0: loss = 0.00713419 (* 1 = 0.00713419 loss)
I0403 03:54:34.856572 23740 sgd_solver.cpp:106] Iteration 4430, lr = 5e-05
I0403 03:54:42.257033 23740 solver.cpp:228] Iteration 4440, loss = 0.000928596
I0403 03:54:42.257122 23740 solver.cpp:244]     Train net output #0: loss = 0.000928643 (* 1 = 0.000928643 loss)
I0403 03:54:42.435773 23740 sgd_solver.cpp:106] Iteration 4440, lr = 5e-05
I0403 03:54:49.876786 23740 solver.cpp:228] Iteration 4450, loss = 0.0023157
I0403 03:54:49.876885 23740 solver.cpp:244]     Train net output #0: loss = 0.00231575 (* 1 = 0.00231575 loss)
I0403 03:54:50.074316 23740 sgd_solver.cpp:106] Iteration 4450, lr = 5e-05
I0403 03:54:57.508987 23740 solver.cpp:228] Iteration 4460, loss = 0.00182923
I0403 03:54:57.509232 23740 solver.cpp:244]     Train net output #0: loss = 0.00182928 (* 1 = 0.00182928 loss)
I0403 03:54:57.710234 23740 sgd_solver.cpp:106] Iteration 4460, lr = 5e-05
I0403 03:55:05.054059 23740 solver.cpp:228] Iteration 4470, loss = 0.00245312
I0403 03:55:05.060323 23740 solver.cpp:244]     Train net output #0: loss = 0.00245316 (* 1 = 0.00245316 loss)
I0403 03:55:05.243381 23740 sgd_solver.cpp:106] Iteration 4470, lr = 5e-05
I0403 03:55:12.710733 23740 solver.cpp:228] Iteration 4480, loss = 9.95707e-05
I0403 03:55:12.710819 23740 solver.cpp:244]     Train net output #0: loss = 9.96166e-05 (* 1 = 9.96166e-05 loss)
I0403 03:55:12.887883 23740 sgd_solver.cpp:106] Iteration 4480, lr = 5e-05
I0403 03:55:20.380946 23740 solver.cpp:228] Iteration 4490, loss = 0.0020316
I0403 03:55:20.381037 23740 solver.cpp:244]     Train net output #0: loss = 0.00203164 (* 1 = 0.00203164 loss)
I0403 03:55:20.559162 23740 sgd_solver.cpp:106] Iteration 4490, lr = 5e-05
I0403 03:55:27.996541 23740 solver.cpp:228] Iteration 4500, loss = 0.000777187
I0403 03:55:28.002527 23740 solver.cpp:244]     Train net output #0: loss = 0.000777234 (* 1 = 0.000777234 loss)
I0403 03:55:28.191018 23740 sgd_solver.cpp:106] Iteration 4500, lr = 5e-05
I0403 03:55:35.640367 23740 solver.cpp:228] Iteration 4510, loss = 0.00193125
I0403 03:55:35.647629 23740 solver.cpp:244]     Train net output #0: loss = 0.0019313 (* 1 = 0.0019313 loss)
I0403 03:55:35.830245 23740 sgd_solver.cpp:106] Iteration 4510, lr = 5e-05
I0403 03:55:43.237505 23740 solver.cpp:228] Iteration 4520, loss = 0.000743819
I0403 03:55:43.237606 23740 solver.cpp:244]     Train net output #0: loss = 0.000743866 (* 1 = 0.000743866 loss)
I0403 03:55:43.470352 23740 sgd_solver.cpp:106] Iteration 4520, lr = 5e-05
I0403 03:55:50.822717 23740 solver.cpp:228] Iteration 4530, loss = 0.00568269
I0403 03:55:50.822815 23740 solver.cpp:244]     Train net output #0: loss = 0.00568273 (* 1 = 0.00568273 loss)
I0403 03:55:51.032793 23740 sgd_solver.cpp:106] Iteration 4530, lr = 5e-05
I0403 03:55:58.443163 23740 solver.cpp:228] Iteration 4540, loss = 0.000111399
I0403 03:55:58.443476 23740 solver.cpp:244]     Train net output #0: loss = 0.000111446 (* 1 = 0.000111446 loss)
I0403 03:55:58.633867 23740 sgd_solver.cpp:106] Iteration 4540, lr = 5e-05
I0403 03:56:06.040091 23740 solver.cpp:228] Iteration 4550, loss = 0.000960974
I0403 03:56:06.040194 23740 solver.cpp:244]     Train net output #0: loss = 0.000961022 (* 1 = 0.000961022 loss)
I0403 03:56:06.234633 23740 sgd_solver.cpp:106] Iteration 4550, lr = 5e-05
I0403 03:56:13.547489 23740 solver.cpp:228] Iteration 4560, loss = 0.000191276
I0403 03:56:13.547591 23740 solver.cpp:244]     Train net output #0: loss = 0.000191321 (* 1 = 0.000191321 loss)
I0403 03:56:13.745373 23740 sgd_solver.cpp:106] Iteration 4560, lr = 5e-05
I0403 03:56:21.189013 23740 solver.cpp:228] Iteration 4570, loss = 0.0030165
I0403 03:56:21.189115 23740 solver.cpp:244]     Train net output #0: loss = 0.00301655 (* 1 = 0.00301655 loss)
I0403 03:56:21.403918 23740 sgd_solver.cpp:106] Iteration 4570, lr = 5e-05
I0403 03:56:28.735756 23740 solver.cpp:228] Iteration 4580, loss = 0.00168764
I0403 03:56:28.736037 23740 solver.cpp:244]     Train net output #0: loss = 0.00168769 (* 1 = 0.00168769 loss)
I0403 03:56:28.945149 23740 sgd_solver.cpp:106] Iteration 4580, lr = 5e-05
I0403 03:56:36.315306 23740 solver.cpp:228] Iteration 4590, loss = 5.18303e-05
I0403 03:56:36.315397 23740 solver.cpp:244]     Train net output #0: loss = 5.18754e-05 (* 1 = 5.18754e-05 loss)
I0403 03:56:36.503585 23740 sgd_solver.cpp:106] Iteration 4590, lr = 5e-05
I0403 03:56:42.648550 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4599.caffemodel
I0403 03:56:45.495534 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4599.solverstate
I0403 03:56:47.350052 23740 solver.cpp:337] Iteration 4599, Testing net (#0)
I0403 03:58:01.075397 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981266
I0403 03:58:01.075726 23740 solver.cpp:404]     Test net output #1: loss = 0.0719159 (* 1 = 0.0719159 loss)
I0403 03:58:02.451503 23740 solver.cpp:228] Iteration 4600, loss = 0.00579418
I0403 03:58:02.451591 23740 solver.cpp:244]     Train net output #0: loss = 0.00579422 (* 1 = 0.00579422 loss)
I0403 03:58:02.611845 23740 sgd_solver.cpp:106] Iteration 4600, lr = 5e-05
I0403 03:58:10.127311 23740 solver.cpp:228] Iteration 4610, loss = 0.0126491
I0403 03:58:10.127398 23740 solver.cpp:244]     Train net output #0: loss = 0.0126491 (* 1 = 0.0126491 loss)
I0403 03:58:10.320478 23740 sgd_solver.cpp:106] Iteration 4610, lr = 5e-05
I0403 03:58:17.756206 23740 solver.cpp:228] Iteration 4620, loss = 0.00768333
I0403 03:58:17.760601 23740 solver.cpp:244]     Train net output #0: loss = 0.00768337 (* 1 = 0.00768337 loss)
I0403 03:58:17.962191 23740 sgd_solver.cpp:106] Iteration 4620, lr = 5e-05
I0403 03:58:25.417985 23740 solver.cpp:228] Iteration 4630, loss = 9.64062e-05
I0403 03:58:25.418076 23740 solver.cpp:244]     Train net output #0: loss = 9.64504e-05 (* 1 = 9.64504e-05 loss)
I0403 03:58:25.607211 23740 sgd_solver.cpp:106] Iteration 4630, lr = 5e-05
I0403 03:58:33.089010 23740 solver.cpp:228] Iteration 4640, loss = 0.000708871
I0403 03:58:33.090286 23740 solver.cpp:244]     Train net output #0: loss = 0.000708915 (* 1 = 0.000708915 loss)
I0403 03:58:33.315086 23740 sgd_solver.cpp:106] Iteration 4640, lr = 5e-05
I0403 03:58:40.837610 23740 solver.cpp:228] Iteration 4650, loss = 8.47757e-05
I0403 03:58:40.837698 23740 solver.cpp:244]     Train net output #0: loss = 8.482e-05 (* 1 = 8.482e-05 loss)
I0403 03:58:40.952522 23740 sgd_solver.cpp:106] Iteration 4650, lr = 5e-05
I0403 03:58:48.643525 23740 solver.cpp:228] Iteration 4660, loss = 0.000394594
I0403 03:58:48.643628 23740 solver.cpp:244]     Train net output #0: loss = 0.000394639 (* 1 = 0.000394639 loss)
I0403 03:58:48.847728 23740 sgd_solver.cpp:106] Iteration 4660, lr = 5e-05
I0403 03:58:56.256842 23740 solver.cpp:228] Iteration 4670, loss = 4.77525e-05
I0403 03:58:56.256944 23740 solver.cpp:244]     Train net output #0: loss = 4.77983e-05 (* 1 = 4.77983e-05 loss)
I0403 03:58:56.464058 23740 sgd_solver.cpp:106] Iteration 4670, lr = 5e-05
I0403 03:59:03.958370 23740 solver.cpp:228] Iteration 4680, loss = 0.000232768
I0403 03:59:03.958653 23740 solver.cpp:244]     Train net output #0: loss = 0.000232814 (* 1 = 0.000232814 loss)
I0403 03:59:04.147363 23740 sgd_solver.cpp:106] Iteration 4680, lr = 5e-05
I0403 03:59:11.553419 23740 solver.cpp:228] Iteration 4690, loss = 0.000260858
I0403 03:59:11.553508 23740 solver.cpp:244]     Train net output #0: loss = 0.000260904 (* 1 = 0.000260904 loss)
I0403 03:59:11.743214 23740 sgd_solver.cpp:106] Iteration 4690, lr = 5e-05
I0403 03:59:19.156522 23740 solver.cpp:228] Iteration 4700, loss = 0.00182467
I0403 03:59:19.156605 23740 solver.cpp:244]     Train net output #0: loss = 0.00182472 (* 1 = 0.00182472 loss)
I0403 03:59:19.317888 23740 sgd_solver.cpp:106] Iteration 4700, lr = 5e-05
I0403 03:59:26.886895 23740 solver.cpp:228] Iteration 4710, loss = 0.0004078
I0403 03:59:26.887002 23740 solver.cpp:244]     Train net output #0: loss = 0.000407846 (* 1 = 0.000407846 loss)
I0403 03:59:27.069788 23740 sgd_solver.cpp:106] Iteration 4710, lr = 5e-05
I0403 03:59:34.523674 23740 solver.cpp:228] Iteration 4720, loss = 0.00020538
I0403 03:59:34.523960 23740 solver.cpp:244]     Train net output #0: loss = 0.000205426 (* 1 = 0.000205426 loss)
I0403 03:59:34.712721 23740 sgd_solver.cpp:106] Iteration 4720, lr = 5e-05
I0403 03:59:42.178835 23740 solver.cpp:228] Iteration 4730, loss = 0.000298455
I0403 03:59:42.178930 23740 solver.cpp:244]     Train net output #0: loss = 0.000298501 (* 1 = 0.000298501 loss)
I0403 03:59:42.368849 23740 sgd_solver.cpp:106] Iteration 4730, lr = 5e-05
I0403 03:59:49.791978 23740 solver.cpp:228] Iteration 4740, loss = 0.000235911
I0403 03:59:49.792064 23740 solver.cpp:244]     Train net output #0: loss = 0.000235957 (* 1 = 0.000235957 loss)
I0403 03:59:49.964272 23740 sgd_solver.cpp:106] Iteration 4740, lr = 5e-05
I0403 03:59:57.410928 23740 solver.cpp:228] Iteration 4750, loss = 0.000131068
I0403 03:59:57.411015 23740 solver.cpp:244]     Train net output #0: loss = 0.000131115 (* 1 = 0.000131115 loss)
I0403 03:59:57.600181 23740 sgd_solver.cpp:106] Iteration 4750, lr = 5e-05
I0403 04:00:04.987287 23740 solver.cpp:228] Iteration 4760, loss = 0.00058116
I0403 04:00:04.987586 23740 solver.cpp:244]     Train net output #0: loss = 0.000581207 (* 1 = 0.000581207 loss)
I0403 04:00:05.181671 23740 sgd_solver.cpp:106] Iteration 4760, lr = 5e-05
I0403 04:00:12.579773 23740 solver.cpp:228] Iteration 4770, loss = 0.000357685
I0403 04:00:12.579875 23740 solver.cpp:244]     Train net output #0: loss = 0.000357732 (* 1 = 0.000357732 loss)
I0403 04:00:12.781285 23740 sgd_solver.cpp:106] Iteration 4770, lr = 5e-05
I0403 04:00:20.198024 23740 solver.cpp:228] Iteration 4780, loss = 0.000215485
I0403 04:00:20.198124 23740 solver.cpp:244]     Train net output #0: loss = 0.000215532 (* 1 = 0.000215532 loss)
I0403 04:00:20.450333 23740 sgd_solver.cpp:106] Iteration 4780, lr = 5e-05
I0403 04:00:27.939584 23740 solver.cpp:228] Iteration 4790, loss = 0.00139948
I0403 04:00:27.939682 23740 solver.cpp:244]     Train net output #0: loss = 0.00139953 (* 1 = 0.00139953 loss)
I0403 04:00:28.133357 23740 sgd_solver.cpp:106] Iteration 4790, lr = 5e-05
I0403 04:00:35.557052 23740 solver.cpp:228] Iteration 4800, loss = 0.000153686
I0403 04:00:35.557315 23740 solver.cpp:244]     Train net output #0: loss = 0.000153732 (* 1 = 0.000153732 loss)
I0403 04:00:35.744451 23740 sgd_solver.cpp:106] Iteration 4800, lr = 5e-05
I0403 04:00:43.141353 23740 solver.cpp:228] Iteration 4810, loss = 0.000296725
I0403 04:00:43.141443 23740 solver.cpp:244]     Train net output #0: loss = 0.000296771 (* 1 = 0.000296771 loss)
I0403 04:00:43.330839 23740 sgd_solver.cpp:106] Iteration 4810, lr = 5e-05
I0403 04:00:48.666865 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4818.caffemodel
I0403 04:00:51.433306 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_4818.solverstate
I0403 04:00:53.292635 23740 solver.cpp:337] Iteration 4818, Testing net (#0)
I0403 04:02:06.990242 23740 solver.cpp:404]     Test net output #0: accuracy = 0.98142
I0403 04:02:06.990561 23740 solver.cpp:404]     Test net output #1: loss = 0.0713941 (* 1 = 0.0713941 loss)
I0403 04:02:09.018121 23740 solver.cpp:228] Iteration 4820, loss = 0.00119687
I0403 04:02:09.018219 23740 solver.cpp:244]     Train net output #0: loss = 0.00119691 (* 1 = 0.00119691 loss)
I0403 04:02:09.224360 23740 sgd_solver.cpp:106] Iteration 4820, lr = 5e-05
I0403 04:02:16.665166 23740 solver.cpp:228] Iteration 4830, loss = 0.00155778
I0403 04:02:16.665283 23740 solver.cpp:244]     Train net output #0: loss = 0.00155782 (* 1 = 0.00155782 loss)
I0403 04:02:16.900771 23740 sgd_solver.cpp:106] Iteration 4830, lr = 5e-05
I0403 04:02:24.351012 23740 solver.cpp:228] Iteration 4840, loss = 0.00249507
I0403 04:02:24.351099 23740 solver.cpp:244]     Train net output #0: loss = 0.00249512 (* 1 = 0.00249512 loss)
I0403 04:02:24.540736 23740 sgd_solver.cpp:106] Iteration 4840, lr = 5e-05
I0403 04:02:32.019096 23740 solver.cpp:228] Iteration 4850, loss = 0.000125851
I0403 04:02:32.019199 23740 solver.cpp:244]     Train net output #0: loss = 0.000125898 (* 1 = 0.000125898 loss)
I0403 04:02:32.217727 23740 sgd_solver.cpp:106] Iteration 4850, lr = 5e-05
I0403 04:02:39.609055 23740 solver.cpp:228] Iteration 4860, loss = 0.000277119
I0403 04:02:39.609282 23740 solver.cpp:244]     Train net output #0: loss = 0.000277166 (* 1 = 0.000277166 loss)
I0403 04:02:39.785370 23740 sgd_solver.cpp:106] Iteration 4860, lr = 5e-05
I0403 04:02:47.277472 23740 solver.cpp:228] Iteration 4870, loss = 0.00132079
I0403 04:02:47.277576 23740 solver.cpp:244]     Train net output #0: loss = 0.00132083 (* 1 = 0.00132083 loss)
I0403 04:02:47.485795 23740 sgd_solver.cpp:106] Iteration 4870, lr = 5e-05
I0403 04:02:54.895335 23740 solver.cpp:228] Iteration 4880, loss = 0.00212979
I0403 04:02:54.895436 23740 solver.cpp:244]     Train net output #0: loss = 0.00212983 (* 1 = 0.00212983 loss)
I0403 04:02:55.091174 23740 sgd_solver.cpp:106] Iteration 4880, lr = 5e-05
I0403 04:03:02.422981 23740 solver.cpp:228] Iteration 4890, loss = 0.00365217
I0403 04:03:02.423064 23740 solver.cpp:244]     Train net output #0: loss = 0.00365221 (* 1 = 0.00365221 loss)
I0403 04:03:02.611733 23740 sgd_solver.cpp:106] Iteration 4890, lr = 5e-05
I0403 04:03:10.007323 23740 solver.cpp:228] Iteration 4900, loss = 0.000304007
I0403 04:03:10.007591 23740 solver.cpp:244]     Train net output #0: loss = 0.000304053 (* 1 = 0.000304053 loss)
I0403 04:03:10.218704 23740 sgd_solver.cpp:106] Iteration 4900, lr = 5e-05
I0403 04:03:17.659811 23740 solver.cpp:228] Iteration 4910, loss = 0.000473955
I0403 04:03:17.659899 23740 solver.cpp:244]     Train net output #0: loss = 0.000474002 (* 1 = 0.000474002 loss)
I0403 04:03:17.848736 23740 sgd_solver.cpp:106] Iteration 4910, lr = 5e-05
I0403 04:03:25.431799 23740 solver.cpp:228] Iteration 4920, loss = 0.00318944
I0403 04:03:25.431900 23740 solver.cpp:244]     Train net output #0: loss = 0.00318949 (* 1 = 0.00318949 loss)
I0403 04:03:25.635543 23740 sgd_solver.cpp:106] Iteration 4920, lr = 5e-05
I0403 04:03:33.317603 23740 solver.cpp:228] Iteration 4930, loss = 0.000622996
I0403 04:03:33.317706 23740 solver.cpp:244]     Train net output #0: loss = 0.000623043 (* 1 = 0.000623043 loss)
I0403 04:03:33.556721 23740 sgd_solver.cpp:106] Iteration 4930, lr = 5e-05
I0403 04:03:40.978736 23740 solver.cpp:228] Iteration 4940, loss = 0.000222411
I0403 04:03:40.979091 23740 solver.cpp:244]     Train net output #0: loss = 0.000222458 (* 1 = 0.000222458 loss)
I0403 04:03:41.172999 23740 sgd_solver.cpp:106] Iteration 4940, lr = 5e-05
I0403 04:03:48.605048 23740 solver.cpp:228] Iteration 4950, loss = 0.000890864
I0403 04:03:48.605135 23740 solver.cpp:244]     Train net output #0: loss = 0.000890908 (* 1 = 0.000890908 loss)
I0403 04:03:48.796703 23740 sgd_solver.cpp:106] Iteration 4950, lr = 5e-05
I0403 04:03:56.236358 23740 solver.cpp:228] Iteration 4960, loss = 0.000198168
I0403 04:03:56.236448 23740 solver.cpp:244]     Train net output #0: loss = 0.000198212 (* 1 = 0.000198212 loss)
I0403 04:03:56.414966 23740 sgd_solver.cpp:106] Iteration 4960, lr = 5e-05
I0403 04:04:03.856050 23740 solver.cpp:228] Iteration 4970, loss = 0.000323275
I0403 04:04:03.856140 23740 solver.cpp:244]     Train net output #0: loss = 0.000323318 (* 1 = 0.000323318 loss)
I0403 04:04:04.049500 23740 sgd_solver.cpp:106] Iteration 4970, lr = 5e-05
I0403 04:04:11.483891 23740 solver.cpp:228] Iteration 4980, loss = 0.000555581
I0403 04:04:11.484184 23740 solver.cpp:244]     Train net output #0: loss = 0.000555625 (* 1 = 0.000555625 loss)
I0403 04:04:11.672907 23740 sgd_solver.cpp:106] Iteration 4980, lr = 5e-05
I0403 04:04:19.111078 23740 solver.cpp:228] Iteration 4990, loss = 0.000240641
I0403 04:04:19.111160 23740 solver.cpp:244]     Train net output #0: loss = 0.000240685 (* 1 = 0.000240685 loss)
I0403 04:04:19.284622 23740 sgd_solver.cpp:106] Iteration 4990, lr = 5e-05
I0403 04:04:26.890594 23740 solver.cpp:228] Iteration 5000, loss = 0.000608601
I0403 04:04:26.890679 23740 solver.cpp:244]     Train net output #0: loss = 0.000608646 (* 1 = 0.000608646 loss)
I0403 04:04:27.065954 23740 sgd_solver.cpp:106] Iteration 5000, lr = 5e-05
I0403 04:04:34.536490 23740 solver.cpp:228] Iteration 5010, loss = 0.000190472
I0403 04:04:34.536587 23740 solver.cpp:244]     Train net output #0: loss = 0.000190516 (* 1 = 0.000190516 loss)
I0403 04:04:34.746280 23740 sgd_solver.cpp:106] Iteration 5010, lr = 5e-05
I0403 04:04:42.176246 23740 solver.cpp:228] Iteration 5020, loss = 0.000952443
I0403 04:04:42.176512 23740 solver.cpp:244]     Train net output #0: loss = 0.000952488 (* 1 = 0.000952488 loss)
I0403 04:04:42.434847 23740 sgd_solver.cpp:106] Iteration 5020, lr = 5e-05
I0403 04:04:49.816835 23740 solver.cpp:228] Iteration 5030, loss = 0.00027812
I0403 04:04:49.816936 23740 solver.cpp:244]     Train net output #0: loss = 0.000278166 (* 1 = 0.000278166 loss)
I0403 04:04:50.031563 23740 sgd_solver.cpp:106] Iteration 5030, lr = 5e-05
I0403 04:04:54.686486 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5037.caffemodel
I0403 04:04:57.467712 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5037.solverstate
I0403 04:04:59.361022 23740 solver.cpp:337] Iteration 5037, Testing net (#0)
I0403 04:06:13.054119 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981173
I0403 04:06:13.054419 23740 solver.cpp:404]     Test net output #1: loss = 0.0713405 (* 1 = 0.0713405 loss)
I0403 04:06:15.904597 23740 solver.cpp:228] Iteration 5040, loss = 0.00230856
I0403 04:06:15.904692 23740 solver.cpp:244]     Train net output #0: loss = 0.00230861 (* 1 = 0.00230861 loss)
I0403 04:06:16.106297 23740 sgd_solver.cpp:106] Iteration 5040, lr = 5e-05
I0403 04:06:23.570142 23740 solver.cpp:228] Iteration 5050, loss = 0.000179462
I0403 04:06:23.570935 23740 solver.cpp:244]     Train net output #0: loss = 0.000179509 (* 1 = 0.000179509 loss)
I0403 04:06:23.754959 23740 sgd_solver.cpp:106] Iteration 5050, lr = 5e-05
I0403 04:06:31.182356 23740 solver.cpp:228] Iteration 5060, loss = 6.60465e-05
I0403 04:06:31.182457 23740 solver.cpp:244]     Train net output #0: loss = 6.60928e-05 (* 1 = 6.60928e-05 loss)
I0403 04:06:31.402528 23740 sgd_solver.cpp:106] Iteration 5060, lr = 5e-05
I0403 04:06:38.798799 23740 solver.cpp:228] Iteration 5070, loss = 0.00118085
I0403 04:06:38.798900 23740 solver.cpp:244]     Train net output #0: loss = 0.0011809 (* 1 = 0.0011809 loss)
I0403 04:06:39.051544 23740 sgd_solver.cpp:106] Iteration 5070, lr = 5e-05
I0403 04:06:46.637559 23740 solver.cpp:228] Iteration 5080, loss = 0.000453727
I0403 04:06:46.637867 23740 solver.cpp:244]     Train net output #0: loss = 0.000453773 (* 1 = 0.000453773 loss)
I0403 04:06:46.807759 23740 sgd_solver.cpp:106] Iteration 5080, lr = 5e-05
I0403 04:06:54.221961 23740 solver.cpp:228] Iteration 5090, loss = 0.000477076
I0403 04:06:54.222060 23740 solver.cpp:244]     Train net output #0: loss = 0.000477122 (* 1 = 0.000477122 loss)
I0403 04:06:54.417501 23740 sgd_solver.cpp:106] Iteration 5090, lr = 5e-05
I0403 04:07:01.848268 23740 solver.cpp:228] Iteration 5100, loss = 0.00235786
I0403 04:07:01.863411 23740 solver.cpp:244]     Train net output #0: loss = 0.00235791 (* 1 = 0.00235791 loss)
I0403 04:07:02.037284 23740 sgd_solver.cpp:106] Iteration 5100, lr = 5e-05
I0403 04:07:09.411259 23740 solver.cpp:228] Iteration 5110, loss = 0.000617572
I0403 04:07:09.411362 23740 solver.cpp:244]     Train net output #0: loss = 0.000617618 (* 1 = 0.000617618 loss)
I0403 04:07:09.605713 23740 sgd_solver.cpp:106] Iteration 5110, lr = 5e-05
I0403 04:07:17.024966 23740 solver.cpp:228] Iteration 5120, loss = 0.00157967
I0403 04:07:17.025275 23740 solver.cpp:244]     Train net output #0: loss = 0.00157972 (* 1 = 0.00157972 loss)
I0403 04:07:17.213443 23740 sgd_solver.cpp:106] Iteration 5120, lr = 5e-05
I0403 04:07:24.678267 23740 solver.cpp:228] Iteration 5130, loss = 0.000657106
I0403 04:07:24.678354 23740 solver.cpp:244]     Train net output #0: loss = 0.000657152 (* 1 = 0.000657152 loss)
I0403 04:07:24.866169 23740 sgd_solver.cpp:106] Iteration 5130, lr = 5e-05
I0403 04:07:32.358016 23740 solver.cpp:228] Iteration 5140, loss = 0.00150725
I0403 04:07:32.358115 23740 solver.cpp:244]     Train net output #0: loss = 0.00150729 (* 1 = 0.00150729 loss)
I0403 04:07:32.552278 23740 sgd_solver.cpp:106] Iteration 5140, lr = 5e-05
I0403 04:07:40.026022 23740 solver.cpp:228] Iteration 5150, loss = 0.000347959
I0403 04:07:40.026125 23740 solver.cpp:244]     Train net output #0: loss = 0.000348005 (* 1 = 0.000348005 loss)
I0403 04:07:40.220978 23740 sgd_solver.cpp:106] Iteration 5150, lr = 5e-05
I0403 04:07:47.688688 23740 solver.cpp:228] Iteration 5160, loss = 0.000347178
I0403 04:07:47.689002 23740 solver.cpp:244]     Train net output #0: loss = 0.000347223 (* 1 = 0.000347223 loss)
I0403 04:07:47.904228 23740 sgd_solver.cpp:106] Iteration 5160, lr = 5e-05
I0403 04:07:55.278583 23740 solver.cpp:228] Iteration 5170, loss = 0.00197129
I0403 04:07:55.278681 23740 solver.cpp:244]     Train net output #0: loss = 0.00197133 (* 1 = 0.00197133 loss)
I0403 04:07:55.477401 23740 sgd_solver.cpp:106] Iteration 5170, lr = 5e-05
I0403 04:08:02.862076 23740 solver.cpp:228] Iteration 5180, loss = 0.000961298
I0403 04:08:02.862174 23740 solver.cpp:244]     Train net output #0: loss = 0.000961343 (* 1 = 0.000961343 loss)
I0403 04:08:03.073210 23740 sgd_solver.cpp:106] Iteration 5180, lr = 5e-05
I0403 04:08:10.444936 23740 solver.cpp:228] Iteration 5190, loss = 0.000198568
I0403 04:08:10.445026 23740 solver.cpp:244]     Train net output #0: loss = 0.000198613 (* 1 = 0.000198613 loss)
I0403 04:08:10.635607 23740 sgd_solver.cpp:106] Iteration 5190, lr = 5e-05
I0403 04:08:18.108419 23740 solver.cpp:228] Iteration 5200, loss = 0.00472552
I0403 04:08:18.108685 23740 solver.cpp:244]     Train net output #0: loss = 0.00472557 (* 1 = 0.00472557 loss)
I0403 04:08:18.294291 23740 sgd_solver.cpp:106] Iteration 5200, lr = 5e-05
I0403 04:08:25.770995 23740 solver.cpp:228] Iteration 5210, loss = 0.00262367
I0403 04:08:25.771083 23740 solver.cpp:244]     Train net output #0: loss = 0.00262372 (* 1 = 0.00262372 loss)
I0403 04:08:25.921211 23740 sgd_solver.cpp:106] Iteration 5210, lr = 5e-05
I0403 04:08:33.560142 23740 solver.cpp:228] Iteration 5220, loss = 6.54082e-05
I0403 04:08:33.560241 23740 solver.cpp:244]     Train net output #0: loss = 6.54534e-05 (* 1 = 6.54534e-05 loss)
I0403 04:08:33.755719 23740 sgd_solver.cpp:106] Iteration 5220, lr = 5e-05
I0403 04:08:41.159168 23740 solver.cpp:228] Iteration 5230, loss = 5.31975e-05
I0403 04:08:41.159270 23740 solver.cpp:244]     Train net output #0: loss = 5.32426e-05 (* 1 = 5.32426e-05 loss)
I0403 04:08:41.355370 23740 sgd_solver.cpp:106] Iteration 5230, lr = 5e-05
I0403 04:08:48.757140 23740 solver.cpp:228] Iteration 5240, loss = 0.000337487
I0403 04:08:48.757421 23740 solver.cpp:244]     Train net output #0: loss = 0.000337533 (* 1 = 0.000337533 loss)
I0403 04:08:48.948878 23740 sgd_solver.cpp:106] Iteration 5240, lr = 5e-05
I0403 04:08:56.418058 23740 solver.cpp:228] Iteration 5250, loss = 0.00146066
I0403 04:08:56.418148 23740 solver.cpp:244]     Train net output #0: loss = 0.0014607 (* 1 = 0.0014607 loss)
I0403 04:08:56.607558 23740 sgd_solver.cpp:106] Iteration 5250, lr = 5e-05
I0403 04:09:00.443668 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5256.caffemodel
I0403 04:09:03.202811 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5256.solverstate
I0403 04:09:05.093730 23740 solver.cpp:337] Iteration 5256, Testing net (#0)
I0403 04:10:18.798401 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981297
I0403 04:10:18.798702 23740 solver.cpp:404]     Test net output #1: loss = 0.0713858 (* 1 = 0.0713858 loss)
I0403 04:10:22.388191 23740 solver.cpp:228] Iteration 5260, loss = 0.00023637
I0403 04:10:22.388276 23740 solver.cpp:244]     Train net output #0: loss = 0.000236416 (* 1 = 0.000236416 loss)
I0403 04:10:22.578619 23740 sgd_solver.cpp:106] Iteration 5260, lr = 5e-05
I0403 04:10:30.201805 23740 solver.cpp:228] Iteration 5270, loss = 0.000770591
I0403 04:10:30.201897 23740 solver.cpp:244]     Train net output #0: loss = 0.000770637 (* 1 = 0.000770637 loss)
I0403 04:10:30.415341 23740 sgd_solver.cpp:106] Iteration 5270, lr = 5e-05
I0403 04:10:37.898537 23740 solver.cpp:228] Iteration 5280, loss = 8.41146e-05
I0403 04:10:37.898638 23740 solver.cpp:244]     Train net output #0: loss = 8.4162e-05 (* 1 = 8.4162e-05 loss)
I0403 04:10:38.094054 23740 sgd_solver.cpp:106] Iteration 5280, lr = 5e-05
I0403 04:10:45.584890 23740 solver.cpp:228] Iteration 5290, loss = 0.0013469
I0403 04:10:45.584980 23740 solver.cpp:244]     Train net output #0: loss = 0.00134694 (* 1 = 0.00134694 loss)
I0403 04:10:45.774535 23740 sgd_solver.cpp:106] Iteration 5290, lr = 5e-05
I0403 04:10:53.296865 23740 solver.cpp:228] Iteration 5300, loss = 0.00073819
I0403 04:10:53.297159 23740 solver.cpp:244]     Train net output #0: loss = 0.000738237 (* 1 = 0.000738237 loss)
I0403 04:10:53.457974 23740 sgd_solver.cpp:106] Iteration 5300, lr = 5e-05
I0403 04:11:00.915572 23740 solver.cpp:228] Iteration 5310, loss = 0.0008655
I0403 04:11:00.915669 23740 solver.cpp:244]     Train net output #0: loss = 0.000865548 (* 1 = 0.000865548 loss)
I0403 04:11:01.114518 23740 sgd_solver.cpp:106] Iteration 5310, lr = 5e-05
I0403 04:11:08.648341 23740 solver.cpp:228] Iteration 5320, loss = 0.000539553
I0403 04:11:08.648443 23740 solver.cpp:244]     Train net output #0: loss = 0.000539601 (* 1 = 0.000539601 loss)
I0403 04:11:08.842897 23740 sgd_solver.cpp:106] Iteration 5320, lr = 5e-05
I0403 04:11:16.213393 23740 solver.cpp:228] Iteration 5330, loss = 0.000258522
I0403 04:11:16.213493 23740 solver.cpp:244]     Train net output #0: loss = 0.00025857 (* 1 = 0.00025857 loss)
I0403 04:11:16.413758 23740 sgd_solver.cpp:106] Iteration 5330, lr = 5e-05
I0403 04:11:23.783639 23740 solver.cpp:228] Iteration 5340, loss = 0.00191149
I0403 04:11:23.783932 23740 solver.cpp:244]     Train net output #0: loss = 0.00191154 (* 1 = 0.00191154 loss)
I0403 04:11:23.990520 23740 sgd_solver.cpp:106] Iteration 5340, lr = 5e-05
I0403 04:11:31.425277 23740 solver.cpp:228] Iteration 5350, loss = 0.000100658
I0403 04:11:31.425387 23740 solver.cpp:244]     Train net output #0: loss = 0.000100706 (* 1 = 0.000100706 loss)
I0403 04:11:31.620738 23740 sgd_solver.cpp:106] Iteration 5350, lr = 5e-05
I0403 04:11:39.008038 23740 solver.cpp:228] Iteration 5360, loss = 0.000213548
I0403 04:11:39.008138 23740 solver.cpp:244]     Train net output #0: loss = 0.000213596 (* 1 = 0.000213596 loss)
I0403 04:11:39.221076 23740 sgd_solver.cpp:106] Iteration 5360, lr = 5e-05
I0403 04:11:46.599987 23740 solver.cpp:228] Iteration 5370, loss = 0.000995474
I0403 04:11:46.600077 23740 solver.cpp:244]     Train net output #0: loss = 0.000995522 (* 1 = 0.000995522 loss)
I0403 04:11:46.786448 23740 sgd_solver.cpp:106] Iteration 5370, lr = 5e-05
I0403 04:11:54.203604 23740 solver.cpp:228] Iteration 5380, loss = 9.62461e-05
I0403 04:11:54.203896 23740 solver.cpp:244]     Train net output #0: loss = 9.62934e-05 (* 1 = 9.62934e-05 loss)
I0403 04:11:54.390470 23740 sgd_solver.cpp:106] Iteration 5380, lr = 5e-05
I0403 04:12:01.772625 23740 solver.cpp:228] Iteration 5390, loss = 0.000161381
I0403 04:12:01.772713 23740 solver.cpp:244]     Train net output #0: loss = 0.000161429 (* 1 = 0.000161429 loss)
I0403 04:12:01.960759 23740 sgd_solver.cpp:106] Iteration 5390, lr = 5e-05
I0403 04:12:09.335147 23740 solver.cpp:228] Iteration 5400, loss = 0.000375605
I0403 04:12:09.335247 23740 solver.cpp:244]     Train net output #0: loss = 0.000375653 (* 1 = 0.000375653 loss)
I0403 04:12:09.547437 23740 sgd_solver.cpp:106] Iteration 5400, lr = 5e-05
I0403 04:12:16.940067 23740 solver.cpp:228] Iteration 5410, loss = 0.000148383
I0403 04:12:16.940155 23740 solver.cpp:244]     Train net output #0: loss = 0.000148431 (* 1 = 0.000148431 loss)
I0403 04:12:17.127446 23740 sgd_solver.cpp:106] Iteration 5410, lr = 5e-05
I0403 04:12:24.557847 23740 solver.cpp:228] Iteration 5420, loss = 0.000885917
I0403 04:12:24.558140 23740 solver.cpp:244]     Train net output #0: loss = 0.000885965 (* 1 = 0.000885965 loss)
I0403 04:12:24.735589 23740 sgd_solver.cpp:106] Iteration 5420, lr = 5e-05
I0403 04:12:32.260102 23740 solver.cpp:228] Iteration 5430, loss = 5.51951e-05
I0403 04:12:32.260205 23740 solver.cpp:244]     Train net output #0: loss = 5.52436e-05 (* 1 = 5.52436e-05 loss)
I0403 04:12:32.457084 23740 sgd_solver.cpp:106] Iteration 5430, lr = 5e-05
I0403 04:12:39.854092 23740 solver.cpp:228] Iteration 5440, loss = 0.00210277
I0403 04:12:39.854190 23740 solver.cpp:244]     Train net output #0: loss = 0.00210282 (* 1 = 0.00210282 loss)
I0403 04:12:40.057680 23740 sgd_solver.cpp:106] Iteration 5440, lr = 5e-05
I0403 04:12:47.379355 23740 solver.cpp:228] Iteration 5450, loss = 0.00352337
I0403 04:12:47.379441 23740 solver.cpp:244]     Train net output #0: loss = 0.00352341 (* 1 = 0.00352341 loss)
I0403 04:12:47.568598 23740 sgd_solver.cpp:106] Iteration 5450, lr = 5e-05
I0403 04:12:54.964242 23740 solver.cpp:228] Iteration 5460, loss = 0.000641692
I0403 04:12:54.964545 23740 solver.cpp:244]     Train net output #0: loss = 0.000641743 (* 1 = 0.000641743 loss)
I0403 04:12:55.181320 23740 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 04:13:02.521715 23740 solver.cpp:228] Iteration 5470, loss = 0.00413628
I0403 04:13:02.521806 23740 solver.cpp:244]     Train net output #0: loss = 0.00413633 (* 1 = 0.00413633 loss)
I0403 04:13:02.710989 23740 sgd_solver.cpp:106] Iteration 5470, lr = 5e-05
I0403 04:13:05.751235 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5475.caffemodel
I0403 04:13:08.488780 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5475.solverstate
I0403 04:13:10.367383 23740 solver.cpp:337] Iteration 5475, Testing net (#0)
I0403 04:14:24.080771 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981235
I0403 04:14:24.085204 23740 solver.cpp:404]     Test net output #1: loss = 0.0715413 (* 1 = 0.0715413 loss)
I0403 04:14:28.397217 23740 solver.cpp:228] Iteration 5480, loss = 0.000309509
I0403 04:14:28.397317 23740 solver.cpp:244]     Train net output #0: loss = 0.00030956 (* 1 = 0.00030956 loss)
I0403 04:14:28.595048 23740 sgd_solver.cpp:106] Iteration 5480, lr = 5e-05
I0403 04:14:36.006799 23740 solver.cpp:228] Iteration 5490, loss = 0.000134501
I0403 04:14:36.006886 23740 solver.cpp:244]     Train net output #0: loss = 0.000134552 (* 1 = 0.000134552 loss)
I0403 04:14:36.200186 23740 sgd_solver.cpp:106] Iteration 5490, lr = 5e-05
I0403 04:14:43.646878 23740 solver.cpp:228] Iteration 5500, loss = 0.00406078
I0403 04:14:43.646975 23740 solver.cpp:244]     Train net output #0: loss = 0.00406083 (* 1 = 0.00406083 loss)
I0403 04:14:43.837864 23740 sgd_solver.cpp:106] Iteration 5500, lr = 5e-05
I0403 04:14:51.211482 23740 solver.cpp:228] Iteration 5510, loss = 0.000127142
I0403 04:14:51.211580 23740 solver.cpp:244]     Train net output #0: loss = 0.000127193 (* 1 = 0.000127193 loss)
I0403 04:14:51.412855 23740 sgd_solver.cpp:106] Iteration 5510, lr = 5e-05
I0403 04:14:58.787531 23740 solver.cpp:228] Iteration 5520, loss = 0.000857848
I0403 04:14:58.788995 23740 solver.cpp:244]     Train net output #0: loss = 0.000857899 (* 1 = 0.000857899 loss)
I0403 04:14:58.978075 23740 sgd_solver.cpp:106] Iteration 5520, lr = 5e-05
I0403 04:15:06.431944 23740 solver.cpp:228] Iteration 5530, loss = 0.000208442
I0403 04:15:06.432035 23740 solver.cpp:244]     Train net output #0: loss = 0.000208493 (* 1 = 0.000208493 loss)
I0403 04:15:06.568473 23740 sgd_solver.cpp:106] Iteration 5530, lr = 5e-05
I0403 04:15:14.134608 23740 solver.cpp:228] Iteration 5540, loss = 0.000214939
I0403 04:15:14.134697 23740 solver.cpp:244]     Train net output #0: loss = 0.00021499 (* 1 = 0.00021499 loss)
I0403 04:15:14.313355 23740 sgd_solver.cpp:106] Iteration 5540, lr = 5e-05
I0403 04:15:21.777091 23740 solver.cpp:228] Iteration 5550, loss = 6.77952e-05
I0403 04:15:21.777196 23740 solver.cpp:244]     Train net output #0: loss = 6.78456e-05 (* 1 = 6.78456e-05 loss)
I0403 04:15:22.012920 23740 sgd_solver.cpp:106] Iteration 5550, lr = 5e-05
I0403 04:15:29.418752 23740 solver.cpp:228] Iteration 5560, loss = 0.00725205
I0403 04:15:29.419055 23740 solver.cpp:244]     Train net output #0: loss = 0.0072521 (* 1 = 0.0072521 loss)
I0403 04:15:29.622915 23740 sgd_solver.cpp:106] Iteration 5560, lr = 5e-05
I0403 04:15:37.148430 23740 solver.cpp:228] Iteration 5570, loss = 8.57864e-05
I0403 04:15:37.148519 23740 solver.cpp:244]     Train net output #0: loss = 8.58379e-05 (* 1 = 8.58379e-05 loss)
I0403 04:15:37.336768 23740 sgd_solver.cpp:106] Iteration 5570, lr = 5e-05
I0403 04:15:44.723423 23740 solver.cpp:228] Iteration 5580, loss = 0.001332
I0403 04:15:44.731562 23740 solver.cpp:244]     Train net output #0: loss = 0.00133205 (* 1 = 0.00133205 loss)
I0403 04:15:44.926714 23740 sgd_solver.cpp:106] Iteration 5580, lr = 5e-05
I0403 04:15:52.289301 23740 solver.cpp:228] Iteration 5590, loss = 0.000437614
I0403 04:15:52.289404 23740 solver.cpp:244]     Train net output #0: loss = 0.000437665 (* 1 = 0.000437665 loss)
I0403 04:15:52.507167 23740 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 04:15:59.893988 23740 solver.cpp:228] Iteration 5600, loss = 0.000954926
I0403 04:15:59.894281 23740 solver.cpp:244]     Train net output #0: loss = 0.000954978 (* 1 = 0.000954978 loss)
I0403 04:16:00.094033 23740 sgd_solver.cpp:106] Iteration 5600, lr = 5e-05
I0403 04:16:07.487005 23740 solver.cpp:228] Iteration 5610, loss = 0.00222317
I0403 04:16:07.487094 23740 solver.cpp:244]     Train net output #0: loss = 0.00222322 (* 1 = 0.00222322 loss)
I0403 04:16:07.679143 23740 sgd_solver.cpp:106] Iteration 5610, lr = 5e-05
I0403 04:16:15.038527 23740 solver.cpp:228] Iteration 5620, loss = 9.44447e-05
I0403 04:16:15.038628 23740 solver.cpp:244]     Train net output #0: loss = 9.44968e-05 (* 1 = 9.44968e-05 loss)
I0403 04:16:15.272152 23740 sgd_solver.cpp:106] Iteration 5620, lr = 5e-05
I0403 04:16:22.735682 23740 solver.cpp:228] Iteration 5630, loss = 0.000554721
I0403 04:16:22.735765 23740 solver.cpp:244]     Train net output #0: loss = 0.000554774 (* 1 = 0.000554774 loss)
I0403 04:16:22.925495 23740 sgd_solver.cpp:106] Iteration 5630, lr = 5e-05
I0403 04:16:30.509141 23740 solver.cpp:228] Iteration 5640, loss = 0.000153891
I0403 04:16:30.509469 23740 solver.cpp:244]     Train net output #0: loss = 0.000153944 (* 1 = 0.000153944 loss)
I0403 04:16:30.707154 23740 sgd_solver.cpp:106] Iteration 5640, lr = 5e-05
I0403 04:16:38.171159 23740 solver.cpp:228] Iteration 5650, loss = 0.000990075
I0403 04:16:38.171250 23740 solver.cpp:244]     Train net output #0: loss = 0.000990129 (* 1 = 0.000990129 loss)
I0403 04:16:38.302860 23740 sgd_solver.cpp:106] Iteration 5650, lr = 5e-05
I0403 04:16:45.852908 23740 solver.cpp:228] Iteration 5660, loss = 0.00502334
I0403 04:16:45.853014 23740 solver.cpp:244]     Train net output #0: loss = 0.0050234 (* 1 = 0.0050234 loss)
I0403 04:16:46.053186 23740 sgd_solver.cpp:106] Iteration 5660, lr = 5e-05
I0403 04:16:53.418802 23740 solver.cpp:228] Iteration 5670, loss = 0.00654818
I0403 04:16:53.418903 23740 solver.cpp:244]     Train net output #0: loss = 0.00654823 (* 1 = 0.00654823 loss)
I0403 04:16:53.630386 23740 sgd_solver.cpp:106] Iteration 5670, lr = 5e-05
I0403 04:17:01.085618 23740 solver.cpp:228] Iteration 5680, loss = 0.0162458
I0403 04:17:01.085892 23740 solver.cpp:244]     Train net output #0: loss = 0.0162458 (* 1 = 0.0162458 loss)
I0403 04:17:01.274415 23740 sgd_solver.cpp:106] Iteration 5680, lr = 5e-05
I0403 04:17:08.757576 23740 solver.cpp:228] Iteration 5690, loss = 0.000143439
I0403 04:17:08.757665 23740 solver.cpp:244]     Train net output #0: loss = 0.000143494 (* 1 = 0.000143494 loss)
I0403 04:17:08.946898 23740 sgd_solver.cpp:106] Iteration 5690, lr = 5e-05
I0403 04:17:11.224280 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5694.caffemodel
I0403 04:17:14.012861 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5694.solverstate
I0403 04:17:15.902906 23740 solver.cpp:337] Iteration 5694, Testing net (#0)
I0403 04:18:29.604228 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981204
I0403 04:18:29.604573 23740 solver.cpp:404]     Test net output #1: loss = 0.0713503 (* 1 = 0.0713503 loss)
I0403 04:18:34.717875 23740 solver.cpp:228] Iteration 5700, loss = 5.91738e-05
I0403 04:18:34.717980 23740 solver.cpp:244]     Train net output #0: loss = 5.92277e-05 (* 1 = 5.92277e-05 loss)
I0403 04:18:34.916636 23740 sgd_solver.cpp:106] Iteration 5700, lr = 5e-05
I0403 04:18:42.513134 23740 solver.cpp:228] Iteration 5710, loss = 0.000219979
I0403 04:18:42.513223 23740 solver.cpp:244]     Train net output #0: loss = 0.000220033 (* 1 = 0.000220033 loss)
I0403 04:18:42.694011 23740 sgd_solver.cpp:106] Iteration 5710, lr = 5e-05
I0403 04:18:50.159407 23740 solver.cpp:228] Iteration 5720, loss = 0.00285638
I0403 04:18:50.159499 23740 solver.cpp:244]     Train net output #0: loss = 0.00285644 (* 1 = 0.00285644 loss)
I0403 04:18:50.333595 23740 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 04:18:57.838063 23740 solver.cpp:228] Iteration 5730, loss = 6.58856e-05
I0403 04:18:57.838162 23740 solver.cpp:244]     Train net output #0: loss = 6.5939e-05 (* 1 = 6.5939e-05 loss)
I0403 04:18:58.040643 23740 sgd_solver.cpp:106] Iteration 5730, lr = 5e-05
I0403 04:19:05.442301 23740 solver.cpp:228] Iteration 5740, loss = 0.00186576
I0403 04:19:05.442615 23740 solver.cpp:244]     Train net output #0: loss = 0.00186582 (* 1 = 0.00186582 loss)
I0403 04:19:05.649657 23740 sgd_solver.cpp:106] Iteration 5740, lr = 5e-05
I0403 04:19:13.035257 23740 solver.cpp:228] Iteration 5750, loss = 0.000751601
I0403 04:19:13.035359 23740 solver.cpp:244]     Train net output #0: loss = 0.000751655 (* 1 = 0.000751655 loss)
I0403 04:19:13.274821 23740 sgd_solver.cpp:106] Iteration 5750, lr = 5e-05
I0403 04:19:20.679847 23740 solver.cpp:228] Iteration 5760, loss = 0.000184406
I0403 04:19:20.679940 23740 solver.cpp:244]     Train net output #0: loss = 0.00018446 (* 1 = 0.00018446 loss)
I0403 04:19:20.869946 23740 sgd_solver.cpp:106] Iteration 5760, lr = 5e-05
I0403 04:19:28.239809 23740 solver.cpp:228] Iteration 5770, loss = 0.00027466
I0403 04:19:28.239897 23740 solver.cpp:244]     Train net output #0: loss = 0.000274714 (* 1 = 0.000274714 loss)
I0403 04:19:28.418993 23740 sgd_solver.cpp:106] Iteration 5770, lr = 5e-05
I0403 04:19:35.922175 23740 solver.cpp:228] Iteration 5780, loss = 0.000544989
I0403 04:19:35.922459 23740 solver.cpp:244]     Train net output #0: loss = 0.000545043 (* 1 = 0.000545043 loss)
I0403 04:19:36.068857 23740 sgd_solver.cpp:106] Iteration 5780, lr = 5e-05
I0403 04:19:43.618466 23740 solver.cpp:228] Iteration 5790, loss = 0.000987264
I0403 04:19:43.618553 23740 solver.cpp:244]     Train net output #0: loss = 0.000987318 (* 1 = 0.000987318 loss)
I0403 04:19:43.793994 23740 sgd_solver.cpp:106] Iteration 5790, lr = 5e-05
I0403 04:19:51.217169 23740 solver.cpp:228] Iteration 5800, loss = 0.000662047
I0403 04:19:51.217272 23740 solver.cpp:244]     Train net output #0: loss = 0.000662101 (* 1 = 0.000662101 loss)
I0403 04:19:51.441153 23740 sgd_solver.cpp:106] Iteration 5800, lr = 5e-05
I0403 04:19:58.877544 23740 solver.cpp:228] Iteration 5810, loss = 0.000329306
I0403 04:19:58.877632 23740 solver.cpp:244]     Train net output #0: loss = 0.00032936 (* 1 = 0.00032936 loss)
I0403 04:19:59.065634 23740 sgd_solver.cpp:106] Iteration 5810, lr = 5e-05
I0403 04:20:06.478606 23740 solver.cpp:228] Iteration 5820, loss = 0.000113219
I0403 04:20:06.478890 23740 solver.cpp:244]     Train net output #0: loss = 0.000113272 (* 1 = 0.000113272 loss)
I0403 04:20:06.678372 23740 sgd_solver.cpp:106] Iteration 5820, lr = 5e-05
I0403 04:20:14.070106 23740 solver.cpp:228] Iteration 5830, loss = 0.000916441
I0403 04:20:14.070206 23740 solver.cpp:244]     Train net output #0: loss = 0.000916494 (* 1 = 0.000916494 loss)
I0403 04:20:14.264536 23740 sgd_solver.cpp:106] Iteration 5830, lr = 5e-05
I0403 04:20:21.675127 23740 solver.cpp:228] Iteration 5840, loss = 0.000273534
I0403 04:20:21.675231 23740 solver.cpp:244]     Train net output #0: loss = 0.000273587 (* 1 = 0.000273587 loss)
I0403 04:20:21.930691 23740 sgd_solver.cpp:106] Iteration 5840, lr = 5e-05
I0403 04:20:29.442677 23740 solver.cpp:228] Iteration 5850, loss = 0.00145863
I0403 04:20:29.442765 23740 solver.cpp:244]     Train net output #0: loss = 0.00145868 (* 1 = 0.00145868 loss)
I0403 04:20:29.634299 23740 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 04:20:36.994035 23740 solver.cpp:228] Iteration 5860, loss = 0.000336065
I0403 04:20:36.994326 23740 solver.cpp:244]     Train net output #0: loss = 0.000336118 (* 1 = 0.000336118 loss)
I0403 04:20:37.173513 23740 sgd_solver.cpp:106] Iteration 5860, lr = 5e-05
I0403 04:20:44.624552 23740 solver.cpp:228] Iteration 5870, loss = 0.000530924
I0403 04:20:44.624639 23740 solver.cpp:244]     Train net output #0: loss = 0.000530976 (* 1 = 0.000530976 loss)
I0403 04:20:44.814455 23740 sgd_solver.cpp:106] Iteration 5870, lr = 5e-05
I0403 04:20:52.266819 23740 solver.cpp:228] Iteration 5880, loss = 0.000271623
I0403 04:20:52.266921 23740 solver.cpp:244]     Train net output #0: loss = 0.000271675 (* 1 = 0.000271675 loss)
I0403 04:20:52.464543 23740 sgd_solver.cpp:106] Iteration 5880, lr = 5e-05
I0403 04:20:59.846473 23740 solver.cpp:228] Iteration 5890, loss = 0.000704815
I0403 04:20:59.846571 23740 solver.cpp:244]     Train net output #0: loss = 0.000704867 (* 1 = 0.000704867 loss)
I0403 04:21:00.044790 23740 sgd_solver.cpp:106] Iteration 5890, lr = 5e-05
I0403 04:21:07.493034 23740 solver.cpp:228] Iteration 5900, loss = 0.00161103
I0403 04:21:07.494456 23740 solver.cpp:244]     Train net output #0: loss = 0.00161108 (* 1 = 0.00161108 loss)
I0403 04:21:07.682042 23740 sgd_solver.cpp:106] Iteration 5900, lr = 5e-05
I0403 04:21:15.048568 23740 solver.cpp:228] Iteration 5910, loss = 0.000304607
I0403 04:21:15.048668 23740 solver.cpp:244]     Train net output #0: loss = 0.00030466 (* 1 = 0.00030466 loss)
I0403 04:21:15.271154 23740 sgd_solver.cpp:106] Iteration 5910, lr = 5e-05
I0403 04:21:16.796275 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5913.caffemodel
I0403 04:21:19.588032 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_5913.solverstate
I0403 04:21:21.481113 23740 solver.cpp:337] Iteration 5913, Testing net (#0)
I0403 04:22:35.175951 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981482
I0403 04:22:35.176259 23740 solver.cpp:404]     Test net output #1: loss = 0.0713416 (* 1 = 0.0713416 loss)
I0403 04:22:41.142354 23740 solver.cpp:228] Iteration 5920, loss = 0.0141829
I0403 04:22:41.142453 23740 solver.cpp:244]     Train net output #0: loss = 0.014183 (* 1 = 0.014183 loss)
I0403 04:22:41.347985 23740 sgd_solver.cpp:106] Iteration 5920, lr = 5e-05
I0403 04:22:48.733178 23740 solver.cpp:228] Iteration 5930, loss = 7.83293e-05
I0403 04:22:48.733268 23740 solver.cpp:244]     Train net output #0: loss = 7.83831e-05 (* 1 = 7.83831e-05 loss)
I0403 04:22:48.942522 23740 sgd_solver.cpp:106] Iteration 5930, lr = 5e-05
I0403 04:22:56.482444 23740 solver.cpp:228] Iteration 5940, loss = 0.00037479
I0403 04:22:56.482530 23740 solver.cpp:244]     Train net output #0: loss = 0.000374844 (* 1 = 0.000374844 loss)
I0403 04:22:56.664623 23740 sgd_solver.cpp:106] Iteration 5940, lr = 5e-05
I0403 04:23:04.501786 23740 solver.cpp:228] Iteration 5950, loss = 0.00180568
I0403 04:23:04.501878 23740 solver.cpp:244]     Train net output #0: loss = 0.00180574 (* 1 = 0.00180574 loss)
I0403 04:23:04.621582 23740 sgd_solver.cpp:106] Iteration 5950, lr = 5e-05
I0403 04:23:12.117594 23740 solver.cpp:228] Iteration 5960, loss = 0.00460699
I0403 04:23:12.117899 23740 solver.cpp:244]     Train net output #0: loss = 0.00460704 (* 1 = 0.00460704 loss)
I0403 04:23:12.325356 23740 sgd_solver.cpp:106] Iteration 5960, lr = 5e-05
I0403 04:23:19.807313 23740 solver.cpp:228] Iteration 5970, loss = 0.000351215
I0403 04:23:19.807420 23740 solver.cpp:244]     Train net output #0: loss = 0.000351269 (* 1 = 0.000351269 loss)
I0403 04:23:20.011379 23740 sgd_solver.cpp:106] Iteration 5970, lr = 5e-05
I0403 04:23:27.398191 23740 solver.cpp:228] Iteration 5980, loss = 0.00137805
I0403 04:23:27.398283 23740 solver.cpp:244]     Train net output #0: loss = 0.0013781 (* 1 = 0.0013781 loss)
I0403 04:23:27.587895 23740 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 04:23:35.080556 23740 solver.cpp:228] Iteration 5990, loss = 0.00138059
I0403 04:23:35.080646 23740 solver.cpp:244]     Train net output #0: loss = 0.00138064 (* 1 = 0.00138064 loss)
I0403 04:23:35.242409 23740 sgd_solver.cpp:106] Iteration 5990, lr = 5e-05
I0403 04:23:42.739374 23740 solver.cpp:228] Iteration 6000, loss = 0.00058715
I0403 04:23:42.739648 23740 solver.cpp:244]     Train net output #0: loss = 0.000587204 (* 1 = 0.000587204 loss)
I0403 04:23:42.938328 23740 sgd_solver.cpp:106] Iteration 6000, lr = 5e-05
I0403 04:23:50.250900 23740 solver.cpp:228] Iteration 6010, loss = 0.000320559
I0403 04:23:50.251018 23740 solver.cpp:244]     Train net output #0: loss = 0.000320613 (* 1 = 0.000320613 loss)
I0403 04:23:50.450881 23740 sgd_solver.cpp:106] Iteration 6010, lr = 5e-05
I0403 04:23:57.893498 23740 solver.cpp:228] Iteration 6020, loss = 0.000452801
I0403 04:23:57.893586 23740 solver.cpp:244]     Train net output #0: loss = 0.000452851 (* 1 = 0.000452851 loss)
I0403 04:23:58.083463 23740 sgd_solver.cpp:106] Iteration 6020, lr = 5e-05
I0403 04:24:05.548789 23740 solver.cpp:228] Iteration 6030, loss = 0.000178429
I0403 04:24:05.550120 23740 solver.cpp:244]     Train net output #0: loss = 0.00017848 (* 1 = 0.00017848 loss)
I0403 04:24:05.725028 23740 sgd_solver.cpp:106] Iteration 6030, lr = 5e-05
I0403 04:24:13.201025 23740 solver.cpp:228] Iteration 6040, loss = 0.00041493
I0403 04:24:13.201339 23740 solver.cpp:244]     Train net output #0: loss = 0.000414981 (* 1 = 0.000414981 loss)
I0403 04:24:13.388967 23740 sgd_solver.cpp:106] Iteration 6040, lr = 5e-05
I0403 04:24:20.818138 23740 solver.cpp:228] Iteration 6050, loss = 0.00065779
I0403 04:24:20.818225 23740 solver.cpp:244]     Train net output #0: loss = 0.000657841 (* 1 = 0.000657841 loss)
I0403 04:24:21.005632 23740 sgd_solver.cpp:106] Iteration 6050, lr = 5e-05
I0403 04:24:28.363505 23740 solver.cpp:228] Iteration 6060, loss = 0.00156068
I0403 04:24:28.363605 23740 solver.cpp:244]     Train net output #0: loss = 0.00156073 (* 1 = 0.00156073 loss)
I0403 04:24:28.565721 23740 sgd_solver.cpp:106] Iteration 6060, lr = 5e-05
I0403 04:24:35.955518 23740 solver.cpp:228] Iteration 6070, loss = 0.000152887
I0403 04:24:35.955605 23740 solver.cpp:244]     Train net output #0: loss = 0.000152937 (* 1 = 0.000152937 loss)
I0403 04:24:36.137804 23740 sgd_solver.cpp:106] Iteration 6070, lr = 5e-05
I0403 04:24:43.586118 23740 solver.cpp:228] Iteration 6080, loss = 0.000408416
I0403 04:24:43.586427 23740 solver.cpp:244]     Train net output #0: loss = 0.000408467 (* 1 = 0.000408467 loss)
I0403 04:24:43.817613 23740 sgd_solver.cpp:106] Iteration 6080, lr = 5e-05
I0403 04:24:51.220315 23740 solver.cpp:228] Iteration 6090, loss = 0.000683713
I0403 04:24:51.220402 23740 solver.cpp:244]     Train net output #0: loss = 0.000683764 (* 1 = 0.000683764 loss)
I0403 04:24:51.406991 23740 sgd_solver.cpp:106] Iteration 6090, lr = 5e-05
I0403 04:24:58.849149 23740 solver.cpp:228] Iteration 6100, loss = 0.00751734
I0403 04:24:58.849237 23740 solver.cpp:244]     Train net output #0: loss = 0.00751739 (* 1 = 0.00751739 loss)
I0403 04:24:59.040640 23740 sgd_solver.cpp:106] Iteration 6100, lr = 5e-05
I0403 04:25:06.501299 23740 solver.cpp:228] Iteration 6110, loss = 2.69483e-05
I0403 04:25:06.501396 23740 solver.cpp:244]     Train net output #0: loss = 2.69993e-05 (* 1 = 2.69993e-05 loss)
I0403 04:25:06.697211 23740 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 04:25:14.026907 23740 solver.cpp:228] Iteration 6120, loss = 0.000219814
I0403 04:25:14.027164 23740 solver.cpp:244]     Train net output #0: loss = 0.000219865 (* 1 = 0.000219865 loss)
I0403 04:25:14.224951 23740 sgd_solver.cpp:106] Iteration 6120, lr = 5e-05
I0403 04:25:21.694123 23740 solver.cpp:228] Iteration 6130, loss = 0.00632317
I0403 04:25:21.694228 23740 solver.cpp:244]     Train net output #0: loss = 0.00632322 (* 1 = 0.00632322 loss)
I0403 04:25:21.916198 23740 sgd_solver.cpp:106] Iteration 6130, lr = 5e-05
I0403 04:25:22.665704 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6132.caffemodel
I0403 04:25:25.439803 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6132.solverstate
I0403 04:25:27.331382 23740 solver.cpp:337] Iteration 6132, Testing net (#0)
I0403 04:26:41.046039 23740 solver.cpp:404]     Test net output #0: accuracy = 0.98142
I0403 04:26:41.046385 23740 solver.cpp:404]     Test net output #1: loss = 0.0709931 (* 1 = 0.0709931 loss)
I0403 04:26:47.844363 23740 solver.cpp:228] Iteration 6140, loss = 0.00208253
I0403 04:26:47.844463 23740 solver.cpp:244]     Train net output #0: loss = 0.00208258 (* 1 = 0.00208258 loss)
I0403 04:26:48.054612 23740 sgd_solver.cpp:106] Iteration 6140, lr = 5e-05
I0403 04:26:55.464095 23740 solver.cpp:228] Iteration 6150, loss = 0.00149489
I0403 04:26:55.464200 23740 solver.cpp:244]     Train net output #0: loss = 0.00149494 (* 1 = 0.00149494 loss)
I0403 04:26:55.686887 23740 sgd_solver.cpp:106] Iteration 6150, lr = 5e-05
I0403 04:27:03.144543 23740 solver.cpp:228] Iteration 6160, loss = 0.000249942
I0403 04:27:03.144645 23740 solver.cpp:244]     Train net output #0: loss = 0.000249994 (* 1 = 0.000249994 loss)
I0403 04:27:03.354791 23740 sgd_solver.cpp:106] Iteration 6160, lr = 5e-05
I0403 04:27:10.818203 23740 solver.cpp:228] Iteration 6170, loss = 0.000230352
I0403 04:27:10.818295 23740 solver.cpp:244]     Train net output #0: loss = 0.000230403 (* 1 = 0.000230403 loss)
I0403 04:27:11.006994 23740 sgd_solver.cpp:106] Iteration 6170, lr = 5e-05
I0403 04:27:18.484930 23740 solver.cpp:228] Iteration 6180, loss = 8.60349e-05
I0403 04:27:18.494477 23740 solver.cpp:244]     Train net output #0: loss = 8.60866e-05 (* 1 = 8.60866e-05 loss)
I0403 04:27:18.696732 23740 sgd_solver.cpp:106] Iteration 6180, lr = 5e-05
I0403 04:27:26.098829 23740 solver.cpp:228] Iteration 6190, loss = 0.00370901
I0403 04:27:26.098917 23740 solver.cpp:244]     Train net output #0: loss = 0.00370906 (* 1 = 0.00370906 loss)
I0403 04:27:26.280980 23740 sgd_solver.cpp:106] Iteration 6190, lr = 5e-05
I0403 04:27:33.743420 23740 solver.cpp:228] Iteration 6200, loss = 0.00238691
I0403 04:27:33.743506 23740 solver.cpp:244]     Train net output #0: loss = 0.00238696 (* 1 = 0.00238696 loss)
I0403 04:27:33.933204 23740 sgd_solver.cpp:106] Iteration 6200, lr = 5e-05
I0403 04:27:41.316483 23740 solver.cpp:228] Iteration 6210, loss = 0.00023042
I0403 04:27:41.316586 23740 solver.cpp:244]     Train net output #0: loss = 0.000230472 (* 1 = 0.000230472 loss)
I0403 04:27:41.540478 23740 sgd_solver.cpp:106] Iteration 6210, lr = 5e-05
I0403 04:27:48.923084 23740 solver.cpp:228] Iteration 6220, loss = 0.000303942
I0403 04:27:48.923379 23740 solver.cpp:244]     Train net output #0: loss = 0.000303994 (* 1 = 0.000303994 loss)
I0403 04:27:49.117436 23740 sgd_solver.cpp:106] Iteration 6220, lr = 5e-05
I0403 04:27:56.644006 23740 solver.cpp:228] Iteration 6230, loss = 0.000889953
I0403 04:27:56.644094 23740 solver.cpp:244]     Train net output #0: loss = 0.000890005 (* 1 = 0.000890005 loss)
I0403 04:27:56.823083 23740 sgd_solver.cpp:106] Iteration 6230, lr = 5e-05
I0403 04:28:04.227669 23740 solver.cpp:228] Iteration 6240, loss = 0.000373489
I0403 04:28:04.227756 23740 solver.cpp:244]     Train net output #0: loss = 0.000373541 (* 1 = 0.000373541 loss)
I0403 04:28:04.418304 23740 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 04:28:11.796039 23740 solver.cpp:228] Iteration 6250, loss = 0.00108998
I0403 04:28:11.796141 23740 solver.cpp:244]     Train net output #0: loss = 0.00109003 (* 1 = 0.00109003 loss)
I0403 04:28:11.995350 23740 sgd_solver.cpp:106] Iteration 6250, lr = 5e-05
I0403 04:28:19.484756 23740 solver.cpp:228] Iteration 6260, loss = 5.83296e-05
I0403 04:28:19.485066 23740 solver.cpp:244]     Train net output #0: loss = 5.8382e-05 (* 1 = 5.8382e-05 loss)
I0403 04:28:19.679126 23740 sgd_solver.cpp:106] Iteration 6260, lr = 5e-05
I0403 04:28:27.171753 23740 solver.cpp:228] Iteration 6270, loss = 5.93773e-05
I0403 04:28:27.171838 23740 solver.cpp:244]     Train net output #0: loss = 5.94294e-05 (* 1 = 5.94294e-05 loss)
I0403 04:28:27.355859 23740 sgd_solver.cpp:106] Iteration 6270, lr = 5e-05
I0403 04:28:34.777355 23740 solver.cpp:228] Iteration 6280, loss = 0.000416327
I0403 04:28:34.777456 23740 solver.cpp:244]     Train net output #0: loss = 0.000416379 (* 1 = 0.000416379 loss)
I0403 04:28:34.979480 23740 sgd_solver.cpp:106] Iteration 6280, lr = 5e-05
I0403 04:28:42.430642 23740 solver.cpp:228] Iteration 6290, loss = 0.00115575
I0403 04:28:42.430730 23740 solver.cpp:244]     Train net output #0: loss = 0.0011558 (* 1 = 0.0011558 loss)
I0403 04:28:42.523790 23740 sgd_solver.cpp:106] Iteration 6290, lr = 5e-05
I0403 04:28:50.090847 23740 solver.cpp:228] Iteration 6300, loss = 0.000832716
I0403 04:28:50.091145 23740 solver.cpp:244]     Train net output #0: loss = 0.000832769 (* 1 = 0.000832769 loss)
I0403 04:28:50.268517 23740 sgd_solver.cpp:106] Iteration 6300, lr = 5e-05
I0403 04:28:57.796108 23740 solver.cpp:228] Iteration 6310, loss = 0.000306782
I0403 04:28:57.796210 23740 solver.cpp:244]     Train net output #0: loss = 0.000306835 (* 1 = 0.000306835 loss)
I0403 04:28:57.995265 23740 sgd_solver.cpp:106] Iteration 6310, lr = 5e-05
I0403 04:29:05.454063 23740 solver.cpp:228] Iteration 6320, loss = 0.000159616
I0403 04:29:05.454164 23740 solver.cpp:244]     Train net output #0: loss = 0.000159669 (* 1 = 0.000159669 loss)
I0403 04:29:05.689723 23740 sgd_solver.cpp:106] Iteration 6320, lr = 5e-05
I0403 04:29:13.086063 23740 solver.cpp:228] Iteration 6330, loss = 0.000228997
I0403 04:29:13.086163 23740 solver.cpp:244]     Train net output #0: loss = 0.000229049 (* 1 = 0.000229049 loss)
I0403 04:29:13.284348 23740 sgd_solver.cpp:106] Iteration 6330, lr = 5e-05
I0403 04:29:20.743584 23740 solver.cpp:228] Iteration 6340, loss = 4.48632e-05
I0403 04:29:20.743902 23740 solver.cpp:244]     Train net output #0: loss = 4.49153e-05 (* 1 = 4.49153e-05 loss)
I0403 04:29:20.946784 23740 sgd_solver.cpp:106] Iteration 6340, lr = 5e-05
I0403 04:29:28.355206 23740 solver.cpp:228] Iteration 6350, loss = 0.000851921
I0403 04:29:28.355306 23740 solver.cpp:244]     Train net output #0: loss = 0.000851973 (* 1 = 0.000851973 loss)
I0403 04:29:28.549495 23740 sgd_solver.cpp:106] Iteration 6350, lr = 5e-05
I0403 04:29:28.549727 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6351.caffemodel
I0403 04:29:31.296710 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6351.solverstate
I0403 04:29:33.190153 23740 solver.cpp:337] Iteration 6351, Testing net (#0)
I0403 04:30:46.879346 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981297
I0403 04:30:46.879642 23740 solver.cpp:404]     Test net output #1: loss = 0.0711175 (* 1 = 0.0711175 loss)
I0403 04:30:54.406996 23740 solver.cpp:228] Iteration 6360, loss = 0.000495329
I0403 04:30:54.407093 23740 solver.cpp:244]     Train net output #0: loss = 0.000495381 (* 1 = 0.000495381 loss)
I0403 04:30:54.603790 23740 sgd_solver.cpp:106] Iteration 6360, lr = 5e-05
I0403 04:31:01.999807 23740 solver.cpp:228] Iteration 6370, loss = 6.79939e-05
I0403 04:31:01.999908 23740 solver.cpp:244]     Train net output #0: loss = 6.80458e-05 (* 1 = 6.80458e-05 loss)
I0403 04:31:02.203634 23740 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 04:31:09.590567 23740 solver.cpp:228] Iteration 6380, loss = 0.000172229
I0403 04:31:09.590669 23740 solver.cpp:244]     Train net output #0: loss = 0.00017228 (* 1 = 0.00017228 loss)
I0403 04:31:09.795269 23740 sgd_solver.cpp:106] Iteration 6380, lr = 5e-05
I0403 04:31:17.206516 23740 solver.cpp:228] Iteration 6390, loss = 0.00195884
I0403 04:31:17.206797 23740 solver.cpp:244]     Train net output #0: loss = 0.00195889 (* 1 = 0.00195889 loss)
I0403 04:31:17.378605 23740 sgd_solver.cpp:106] Iteration 6390, lr = 5e-05
I0403 04:31:24.927757 23740 solver.cpp:228] Iteration 6400, loss = 0.000459795
I0403 04:31:24.927862 23740 solver.cpp:244]     Train net output #0: loss = 0.000459847 (* 1 = 0.000459847 loss)
I0403 04:31:25.153143 23740 sgd_solver.cpp:106] Iteration 6400, lr = 5e-05
I0403 04:31:32.587738 23740 solver.cpp:228] Iteration 6410, loss = 5.08162e-05
I0403 04:31:32.587837 23740 solver.cpp:244]     Train net output #0: loss = 5.08679e-05 (* 1 = 5.08679e-05 loss)
I0403 04:31:32.784530 23740 sgd_solver.cpp:106] Iteration 6410, lr = 5e-05
I0403 04:31:40.221082 23740 solver.cpp:228] Iteration 6420, loss = 0.000535814
I0403 04:31:40.221171 23740 solver.cpp:244]     Train net output #0: loss = 0.000535865 (* 1 = 0.000535865 loss)
I0403 04:31:40.370455 23740 sgd_solver.cpp:106] Iteration 6420, lr = 5e-05
I0403 04:31:47.829954 23740 solver.cpp:228] Iteration 6430, loss = 2.32787e-05
I0403 04:31:47.830256 23740 solver.cpp:244]     Train net output #0: loss = 2.33303e-05 (* 1 = 2.33303e-05 loss)
I0403 04:31:48.024397 23740 sgd_solver.cpp:106] Iteration 6430, lr = 5e-05
I0403 04:31:55.369387 23740 solver.cpp:228] Iteration 6440, loss = 0.000347152
I0403 04:31:55.370663 23740 solver.cpp:244]     Train net output #0: loss = 0.000347204 (* 1 = 0.000347204 loss)
I0403 04:31:55.569732 23740 sgd_solver.cpp:106] Iteration 6440, lr = 5e-05
I0403 04:32:02.937533 23740 solver.cpp:228] Iteration 6450, loss = 0.00233942
I0403 04:32:02.937633 23740 solver.cpp:244]     Train net output #0: loss = 0.00233948 (* 1 = 0.00233948 loss)
I0403 04:32:03.132844 23740 sgd_solver.cpp:106] Iteration 6450, lr = 5e-05
I0403 04:32:10.498986 23740 solver.cpp:228] Iteration 6460, loss = 0.00567808
I0403 04:32:10.499085 23740 solver.cpp:244]     Train net output #0: loss = 0.00567814 (* 1 = 0.00567814 loss)
I0403 04:32:10.696192 23740 sgd_solver.cpp:106] Iteration 6460, lr = 5e-05
I0403 04:32:18.153163 23740 solver.cpp:228] Iteration 6470, loss = 0.000330223
I0403 04:32:18.153523 23740 solver.cpp:244]     Train net output #0: loss = 0.000330275 (* 1 = 0.000330275 loss)
I0403 04:32:18.352068 23740 sgd_solver.cpp:106] Iteration 6470, lr = 5e-05
I0403 04:32:25.733364 23740 solver.cpp:228] Iteration 6480, loss = 0.00021655
I0403 04:32:25.733466 23740 solver.cpp:244]     Train net output #0: loss = 0.000216601 (* 1 = 0.000216601 loss)
I0403 04:32:25.936327 23740 sgd_solver.cpp:106] Iteration 6480, lr = 5e-05
I0403 04:32:33.318847 23740 solver.cpp:228] Iteration 6490, loss = 0.00334608
I0403 04:32:33.318949 23740 solver.cpp:244]     Train net output #0: loss = 0.00334613 (* 1 = 0.00334613 loss)
I0403 04:32:33.526149 23740 sgd_solver.cpp:106] Iteration 6490, lr = 5e-05
I0403 04:32:41.039046 23740 solver.cpp:228] Iteration 6500, loss = 0.00466099
I0403 04:32:41.039135 23740 solver.cpp:244]     Train net output #0: loss = 0.00466104 (* 1 = 0.00466104 loss)
I0403 04:32:41.218051 23740 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 04:32:48.626075 23740 solver.cpp:228] Iteration 6510, loss = 0.000245576
I0403 04:32:48.626361 23740 solver.cpp:244]     Train net output #0: loss = 0.000245628 (* 1 = 0.000245628 loss)
I0403 04:32:48.819695 23740 sgd_solver.cpp:106] Iteration 6510, lr = 5e-05
I0403 04:32:56.187417 23740 solver.cpp:228] Iteration 6520, loss = 0.00133784
I0403 04:32:56.187505 23740 solver.cpp:244]     Train net output #0: loss = 0.00133789 (* 1 = 0.00133789 loss)
I0403 04:32:56.368989 23740 sgd_solver.cpp:106] Iteration 6520, lr = 5e-05
I0403 04:33:03.902933 23740 solver.cpp:228] Iteration 6530, loss = 0.000239616
I0403 04:33:03.903038 23740 solver.cpp:244]     Train net output #0: loss = 0.000239668 (* 1 = 0.000239668 loss)
I0403 04:33:04.116344 23740 sgd_solver.cpp:106] Iteration 6530, lr = 5e-05
I0403 04:33:11.518342 23740 solver.cpp:228] Iteration 6540, loss = 0.000151998
I0403 04:33:11.518445 23740 solver.cpp:244]     Train net output #0: loss = 0.000152049 (* 1 = 0.000152049 loss)
I0403 04:33:11.714814 23740 sgd_solver.cpp:106] Iteration 6540, lr = 5e-05
I0403 04:33:19.062263 23740 solver.cpp:228] Iteration 6550, loss = 0.00012848
I0403 04:33:19.062557 23740 solver.cpp:244]     Train net output #0: loss = 0.000128531 (* 1 = 0.000128531 loss)
I0403 04:33:19.243893 23740 sgd_solver.cpp:106] Iteration 6550, lr = 5e-05
I0403 04:33:26.737498 23740 solver.cpp:228] Iteration 6560, loss = 0.00622657
I0403 04:33:26.737601 23740 solver.cpp:244]     Train net output #0: loss = 0.00622662 (* 1 = 0.00622662 loss)
I0403 04:33:26.934440 23740 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 04:33:33.765143 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6570.caffemodel
I0403 04:33:36.584776 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6570.solverstate
I0403 04:33:38.783041 23740 solver.cpp:337] Iteration 6570, Testing net (#0)
I0403 04:34:52.492578 23740 solver.cpp:404]     Test net output #0: accuracy = 0.981328
I0403 04:34:52.492902 23740 solver.cpp:404]     Test net output #1: loss = 0.0710513 (* 1 = 0.0710513 loss)
I0403 04:34:53.038305 23740 solver.cpp:228] Iteration 6570, loss = 0.000283231
I0403 04:34:53.039533 23740 solver.cpp:244]     Train net output #0: loss = 0.000283284 (* 1 = 0.000283284 loss)
I0403 04:34:53.207701 23740 sgd_solver.cpp:106] Iteration 6570, lr = 5e-06
I0403 04:34:53.208006 23740 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6571.caffemodel
I0403 04:34:56.091078 23740 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-40-60_finetune/snapshots__iter_6571.solverstate
I0403 04:34:57.986667 23740 solver.cpp:322] Optimization Done.
I0403 04:34:58.093875 23740 caffe.cpp:222] Optimization Done.
