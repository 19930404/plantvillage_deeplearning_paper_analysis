I0403 02:30:28.030982 30256 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.031677 30256 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.031723 30256 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.724584 30256 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.726177 30256 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.727629 30256 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.445703 30256 solver.cpp:48] Initializing solver from parameters: 
test_iter: 105
test_interval: 437
base_lr: 0.005
display: 21
max_iter: 13127
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 4375
snapshot: 437
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.475988 30256 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.487210 30256 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.487388 30256 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.489094 30256 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-80-20/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.492107 30256 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.494027 30256 net.cpp:91] Creating Layer data
I0403 02:30:37.494173 30256 net.cpp:399] data -> data
I0403 02:30:37.494429 30256 net.cpp:399] data -> label
I0403 02:30:37.494570 30256 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-80-20/mean.binaryproto
I0403 02:30:37.515656 30261 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-80-20/train_db
I0403 02:30:37.537127 30256 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.675608 30256 net.cpp:141] Setting up data
I0403 02:30:37.675714 30256 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.675741 30256 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.675761 30256 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.675801 30256 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.675854 30256 net.cpp:91] Creating Layer conv1
I0403 02:30:37.675884 30256 net.cpp:425] conv1 <- data
I0403 02:30:37.675920 30256 net.cpp:399] conv1 -> conv1
I0403 02:30:37.679113 30256 net.cpp:141] Setting up conv1
I0403 02:30:37.679152 30256 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.679172 30256 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.679214 30256 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.679246 30256 net.cpp:91] Creating Layer relu1
I0403 02:30:37.679267 30256 net.cpp:425] relu1 <- conv1
I0403 02:30:37.679288 30256 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.679321 30256 net.cpp:141] Setting up relu1
I0403 02:30:37.679345 30256 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.679363 30256 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.679381 30256 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.679406 30256 net.cpp:91] Creating Layer norm1
I0403 02:30:37.679461 30256 net.cpp:425] norm1 <- conv1
I0403 02:30:37.679484 30256 net.cpp:399] norm1 -> norm1
I0403 02:30:37.685081 30256 net.cpp:141] Setting up norm1
I0403 02:30:37.685124 30256 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.685144 30256 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.685164 30256 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.685191 30256 net.cpp:91] Creating Layer pool1
I0403 02:30:37.685210 30256 net.cpp:425] pool1 <- norm1
I0403 02:30:37.685232 30256 net.cpp:399] pool1 -> pool1
I0403 02:30:37.685308 30256 net.cpp:141] Setting up pool1
I0403 02:30:37.685359 30256 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.685379 30256 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.685397 30256 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.685425 30256 net.cpp:91] Creating Layer conv2
I0403 02:30:37.685446 30256 net.cpp:425] conv2 <- pool1
I0403 02:30:37.685468 30256 net.cpp:399] conv2 -> conv2
I0403 02:30:37.686946 30264 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.702750 30256 net.cpp:141] Setting up conv2
I0403 02:30:37.702788 30256 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.702808 30256 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.702836 30256 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.702859 30256 net.cpp:91] Creating Layer relu2
I0403 02:30:37.702879 30256 net.cpp:425] relu2 <- conv2
I0403 02:30:37.702900 30256 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.702926 30256 net.cpp:141] Setting up relu2
I0403 02:30:37.702947 30256 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.702965 30256 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.702982 30256 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.703004 30256 net.cpp:91] Creating Layer norm2
I0403 02:30:37.703024 30256 net.cpp:425] norm2 <- conv2
I0403 02:30:37.703047 30256 net.cpp:399] norm2 -> norm2
I0403 02:30:37.703102 30256 net.cpp:141] Setting up norm2
I0403 02:30:37.703130 30256 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.703147 30256 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.703166 30256 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.703191 30256 net.cpp:91] Creating Layer pool2
I0403 02:30:37.703209 30256 net.cpp:425] pool2 <- norm2
I0403 02:30:37.703232 30256 net.cpp:399] pool2 -> pool2
I0403 02:30:37.703286 30256 net.cpp:141] Setting up pool2
I0403 02:30:37.703315 30256 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.703344 30256 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.703362 30256 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.703389 30256 net.cpp:91] Creating Layer conv3
I0403 02:30:37.703408 30256 net.cpp:425] conv3 <- pool2
I0403 02:30:37.703430 30256 net.cpp:399] conv3 -> conv3
I0403 02:30:37.745105 30256 net.cpp:141] Setting up conv3
I0403 02:30:37.745144 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.745164 30256 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.745190 30256 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.745214 30256 net.cpp:91] Creating Layer relu3
I0403 02:30:37.745234 30256 net.cpp:425] relu3 <- conv3
I0403 02:30:37.745255 30256 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.745280 30256 net.cpp:141] Setting up relu3
I0403 02:30:37.745334 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.745354 30256 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.745373 30256 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.745399 30256 net.cpp:91] Creating Layer conv4
I0403 02:30:37.745419 30256 net.cpp:425] conv4 <- conv3
I0403 02:30:37.745442 30256 net.cpp:399] conv4 -> conv4
I0403 02:30:37.776880 30256 net.cpp:141] Setting up conv4
I0403 02:30:37.776926 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.776945 30256 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.776968 30256 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.777014 30256 net.cpp:91] Creating Layer relu4
I0403 02:30:37.777036 30256 net.cpp:425] relu4 <- conv4
I0403 02:30:37.777058 30256 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.777083 30256 net.cpp:141] Setting up relu4
I0403 02:30:37.777104 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.777122 30256 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.777139 30256 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.777173 30256 net.cpp:91] Creating Layer conv5
I0403 02:30:37.777194 30256 net.cpp:425] conv5 <- conv4
I0403 02:30:37.777216 30256 net.cpp:399] conv5 -> conv5
I0403 02:30:37.798228 30256 net.cpp:141] Setting up conv5
I0403 02:30:37.798272 30256 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.798292 30256 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.798332 30256 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.798362 30256 net.cpp:91] Creating Layer relu5
I0403 02:30:37.798383 30256 net.cpp:425] relu5 <- conv5
I0403 02:30:37.798405 30256 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.798429 30256 net.cpp:141] Setting up relu5
I0403 02:30:37.798450 30256 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.798468 30256 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.798486 30256 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.798509 30256 net.cpp:91] Creating Layer pool5
I0403 02:30:37.798528 30256 net.cpp:425] pool5 <- conv5
I0403 02:30:37.798557 30256 net.cpp:399] pool5 -> pool5
I0403 02:30:37.798619 30256 net.cpp:141] Setting up pool5
I0403 02:30:37.798648 30256 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.798667 30256 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.798686 30256 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.798720 30256 net.cpp:91] Creating Layer fc6
I0403 02:30:37.798743 30256 net.cpp:425] fc6 <- pool5
I0403 02:30:37.798768 30256 net.cpp:399] fc6 -> fc6
I0403 02:30:39.594801 30256 net.cpp:141] Setting up fc6
I0403 02:30:39.594892 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.594912 30256 net.cpp:156] Memory required for data: 823332800
I0403 02:30:39.594938 30256 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:39.594971 30256 net.cpp:91] Creating Layer relu6
I0403 02:30:39.594992 30256 net.cpp:425] relu6 <- fc6
I0403 02:30:39.595018 30256 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:39.595044 30256 net.cpp:141] Setting up relu6
I0403 02:30:39.595067 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.595083 30256 net.cpp:156] Memory required for data: 824971200
I0403 02:30:39.595101 30256 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:39.595135 30256 net.cpp:91] Creating Layer drop6
I0403 02:30:39.595156 30256 net.cpp:425] drop6 <- fc6
I0403 02:30:39.595180 30256 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:39.595237 30256 net.cpp:141] Setting up drop6
I0403 02:30:39.595266 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.595286 30256 net.cpp:156] Memory required for data: 826609600
I0403 02:30:39.595304 30256 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:39.595336 30256 net.cpp:91] Creating Layer fc7
I0403 02:30:39.595358 30256 net.cpp:425] fc7 <- fc6
I0403 02:30:39.595381 30256 net.cpp:399] fc7 -> fc7
I0403 02:30:40.292646 30256 net.cpp:141] Setting up fc7
I0403 02:30:40.292731 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:40.292747 30256 net.cpp:156] Memory required for data: 828248000
I0403 02:30:40.292768 30256 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:40.292789 30256 net.cpp:91] Creating Layer relu7
I0403 02:30:40.292805 30256 net.cpp:425] relu7 <- fc7
I0403 02:30:40.292824 30256 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:40.292843 30256 net.cpp:141] Setting up relu7
I0403 02:30:40.292860 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:40.292873 30256 net.cpp:156] Memory required for data: 829886400
I0403 02:30:40.292886 30256 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:40.292930 30256 net.cpp:91] Creating Layer drop7
I0403 02:30:40.292946 30256 net.cpp:425] drop7 <- fc7
I0403 02:30:40.292963 30256 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:40.293009 30256 net.cpp:141] Setting up drop7
I0403 02:30:40.293030 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:40.293042 30256 net.cpp:156] Memory required for data: 831524800
I0403 02:30:40.293056 30256 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:40.293076 30256 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:40.293090 30256 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:40.293110 30256 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:40.299253 30256 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:40.299283 30256 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:40.299299 30256 net.cpp:156] Memory required for data: 831540000
I0403 02:30:40.299322 30256 layer_factory.hpp:77] Creating layer loss
I0403 02:30:40.299348 30256 net.cpp:91] Creating Layer loss
I0403 02:30:40.299365 30256 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:40.299382 30256 net.cpp:425] loss <- label
I0403 02:30:40.299403 30256 net.cpp:399] loss -> loss
I0403 02:30:40.299430 30256 layer_factory.hpp:77] Creating layer loss
I0403 02:30:40.299530 30256 net.cpp:141] Setting up loss
I0403 02:30:40.299554 30256 net.cpp:148] Top shape: (1)
I0403 02:30:40.299569 30256 net.cpp:151]     with loss weight 1
I0403 02:30:40.299623 30256 net.cpp:156] Memory required for data: 831540004
I0403 02:30:40.299638 30256 net.cpp:217] loss needs backward computation.
I0403 02:30:40.299652 30256 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:40.299666 30256 net.cpp:217] drop7 needs backward computation.
I0403 02:30:40.299679 30256 net.cpp:217] relu7 needs backward computation.
I0403 02:30:40.299693 30256 net.cpp:217] fc7 needs backward computation.
I0403 02:30:40.299707 30256 net.cpp:217] drop6 needs backward computation.
I0403 02:30:40.299721 30256 net.cpp:217] relu6 needs backward computation.
I0403 02:30:40.299734 30256 net.cpp:217] fc6 needs backward computation.
I0403 02:30:40.299748 30256 net.cpp:217] pool5 needs backward computation.
I0403 02:30:40.299762 30256 net.cpp:217] relu5 needs backward computation.
I0403 02:30:40.299775 30256 net.cpp:217] conv5 needs backward computation.
I0403 02:30:40.299789 30256 net.cpp:217] relu4 needs backward computation.
I0403 02:30:40.299803 30256 net.cpp:217] conv4 needs backward computation.
I0403 02:30:40.299818 30256 net.cpp:217] relu3 needs backward computation.
I0403 02:30:40.299830 30256 net.cpp:217] conv3 needs backward computation.
I0403 02:30:40.299844 30256 net.cpp:217] pool2 needs backward computation.
I0403 02:30:40.299860 30256 net.cpp:217] norm2 needs backward computation.
I0403 02:30:40.299873 30256 net.cpp:217] relu2 needs backward computation.
I0403 02:30:40.299887 30256 net.cpp:217] conv2 needs backward computation.
I0403 02:30:40.299901 30256 net.cpp:217] pool1 needs backward computation.
I0403 02:30:40.299916 30256 net.cpp:217] norm1 needs backward computation.
I0403 02:30:40.299929 30256 net.cpp:217] relu1 needs backward computation.
I0403 02:30:40.299942 30256 net.cpp:217] conv1 needs backward computation.
I0403 02:30:40.299957 30256 net.cpp:219] data does not need backward computation.
I0403 02:30:40.299969 30256 net.cpp:261] This network produces output loss
I0403 02:30:40.299995 30256 net.cpp:274] Network initialization done.
I0403 02:30:40.301030 30256 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:40.301089 30256 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:40.301715 30256 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-80-20/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:40.301872 30256 layer_factory.hpp:77] Creating layer data
I0403 02:30:40.302007 30256 net.cpp:91] Creating Layer data
I0403 02:30:40.302034 30256 net.cpp:399] data -> data
I0403 02:30:40.302057 30256 net.cpp:399] data -> label
I0403 02:30:40.302080 30256 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-80-20/mean.binaryproto
I0403 02:30:40.321059 30270 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-80-20/test_db
I0403 02:30:40.327006 30256 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:40.470074 30256 net.cpp:141] Setting up data
I0403 02:30:40.470217 30256 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:40.470294 30256 net.cpp:148] Top shape: 100 (100)
I0403 02:30:40.470386 30256 net.cpp:156] Memory required for data: 61835200
I0403 02:30:40.470474 30256 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:40.470525 30256 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:40.470602 30256 net.cpp:425] label_data_1_split <- label
I0403 02:30:40.470674 30256 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:40.470762 30256 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:40.470890 30256 net.cpp:141] Setting up label_data_1_split
I0403 02:30:40.470981 30256 net.cpp:148] Top shape: 100 (100)
I0403 02:30:40.471109 30256 net.cpp:148] Top shape: 100 (100)
I0403 02:30:40.471189 30256 net.cpp:156] Memory required for data: 61836000
I0403 02:30:40.471230 30256 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:40.471325 30256 net.cpp:91] Creating Layer conv1
I0403 02:30:40.471429 30256 net.cpp:425] conv1 <- data
I0403 02:30:40.471504 30256 net.cpp:399] conv1 -> conv1
I0403 02:30:40.473178 30256 net.cpp:141] Setting up conv1
I0403 02:30:40.473261 30256 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:40.473341 30256 net.cpp:156] Memory required for data: 177996000
I0403 02:30:40.473446 30256 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:40.473525 30256 net.cpp:91] Creating Layer relu1
I0403 02:30:40.473585 30256 net.cpp:425] relu1 <- conv1
I0403 02:30:40.473670 30256 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:40.473759 30256 net.cpp:141] Setting up relu1
I0403 02:30:40.473842 30256 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:40.473920 30256 net.cpp:156] Memory required for data: 294156000
I0403 02:30:40.474004 30256 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:40.474097 30256 net.cpp:91] Creating Layer norm1
I0403 02:30:40.474669 30256 net.cpp:425] norm1 <- conv1
I0403 02:30:40.474694 30256 net.cpp:399] norm1 -> norm1
I0403 02:30:40.474750 30256 net.cpp:141] Setting up norm1
I0403 02:30:40.474798 30256 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:40.474820 30256 net.cpp:156] Memory required for data: 410316000
I0403 02:30:40.474834 30256 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:40.474854 30256 net.cpp:91] Creating Layer pool1
I0403 02:30:40.474870 30256 net.cpp:425] pool1 <- norm1
I0403 02:30:40.474889 30256 net.cpp:399] pool1 -> pool1
I0403 02:30:40.474949 30256 net.cpp:141] Setting up pool1
I0403 02:30:40.474972 30256 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:40.474987 30256 net.cpp:156] Memory required for data: 438309600
I0403 02:30:40.475023 30256 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:40.475047 30256 net.cpp:91] Creating Layer conv2
I0403 02:30:40.475064 30256 net.cpp:425] conv2 <- pool1
I0403 02:30:40.475082 30256 net.cpp:399] conv2 -> conv2
I0403 02:30:40.487844 30256 net.cpp:141] Setting up conv2
I0403 02:30:40.487880 30256 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:40.487897 30256 net.cpp:156] Memory required for data: 512959200
I0403 02:30:40.487920 30256 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:40.487939 30256 net.cpp:91] Creating Layer relu2
I0403 02:30:40.487956 30256 net.cpp:425] relu2 <- conv2
I0403 02:30:40.487973 30256 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:40.487993 30256 net.cpp:141] Setting up relu2
I0403 02:30:40.488010 30256 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:40.488026 30256 net.cpp:156] Memory required for data: 587608800
I0403 02:30:40.488041 30256 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:40.488061 30256 net.cpp:91] Creating Layer norm2
I0403 02:30:40.488077 30256 net.cpp:425] norm2 <- conv2
I0403 02:30:40.488096 30256 net.cpp:399] norm2 -> norm2
I0403 02:30:40.488148 30256 net.cpp:141] Setting up norm2
I0403 02:30:40.488171 30256 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:40.488186 30256 net.cpp:156] Memory required for data: 662258400
I0403 02:30:40.488201 30256 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:40.488221 30256 net.cpp:91] Creating Layer pool2
I0403 02:30:40.488236 30256 net.cpp:425] pool2 <- norm2
I0403 02:30:40.488255 30256 net.cpp:399] pool2 -> pool2
I0403 02:30:40.488302 30256 net.cpp:141] Setting up pool2
I0403 02:30:40.488325 30256 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.488340 30256 net.cpp:156] Memory required for data: 679564000
I0403 02:30:40.488360 30256 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:40.488384 30256 net.cpp:91] Creating Layer conv3
I0403 02:30:40.488400 30256 net.cpp:425] conv3 <- pool2
I0403 02:30:40.488420 30256 net.cpp:399] conv3 -> conv3
I0403 02:30:40.524714 30256 net.cpp:141] Setting up conv3
I0403 02:30:40.524785 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.524802 30256 net.cpp:156] Memory required for data: 705522400
I0403 02:30:40.524828 30256 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:40.524852 30256 net.cpp:91] Creating Layer relu3
I0403 02:30:40.524869 30256 net.cpp:425] relu3 <- conv3
I0403 02:30:40.524890 30256 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:40.524912 30256 net.cpp:141] Setting up relu3
I0403 02:30:40.524931 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.524946 30256 net.cpp:156] Memory required for data: 731480800
I0403 02:30:40.524961 30256 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:40.524986 30256 net.cpp:91] Creating Layer conv4
I0403 02:30:40.525002 30256 net.cpp:425] conv4 <- conv3
I0403 02:30:40.525022 30256 net.cpp:399] conv4 -> conv4
I0403 02:30:40.552343 30256 net.cpp:141] Setting up conv4
I0403 02:30:40.552391 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.552408 30256 net.cpp:156] Memory required for data: 757439200
I0403 02:30:40.552428 30256 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:40.552450 30256 net.cpp:91] Creating Layer relu4
I0403 02:30:40.552467 30256 net.cpp:425] relu4 <- conv4
I0403 02:30:40.552486 30256 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:40.552507 30256 net.cpp:141] Setting up relu4
I0403 02:30:40.552526 30256 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.552541 30256 net.cpp:156] Memory required for data: 783397600
I0403 02:30:40.552556 30256 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:40.552580 30256 net.cpp:91] Creating Layer conv5
I0403 02:30:40.552597 30256 net.cpp:425] conv5 <- conv4
I0403 02:30:40.552618 30256 net.cpp:399] conv5 -> conv5
I0403 02:30:40.570572 30256 net.cpp:141] Setting up conv5
I0403 02:30:40.570608 30256 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.570624 30256 net.cpp:156] Memory required for data: 800703200
I0403 02:30:40.570672 30256 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:40.570693 30256 net.cpp:91] Creating Layer relu5
I0403 02:30:40.570708 30256 net.cpp:425] relu5 <- conv5
I0403 02:30:40.570729 30256 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:40.570751 30256 net.cpp:141] Setting up relu5
I0403 02:30:40.570773 30256 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.570796 30256 net.cpp:156] Memory required for data: 818008800
I0403 02:30:40.570817 30256 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:40.570847 30256 net.cpp:91] Creating Layer pool5
I0403 02:30:40.570864 30256 net.cpp:425] pool5 <- conv5
I0403 02:30:40.570886 30256 net.cpp:399] pool5 -> pool5
I0403 02:30:40.570942 30256 net.cpp:141] Setting up pool5
I0403 02:30:40.570966 30256 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:40.570981 30256 net.cpp:156] Memory required for data: 821695200
I0403 02:30:40.570997 30256 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:40.571017 30256 net.cpp:91] Creating Layer fc6
I0403 02:30:40.571033 30256 net.cpp:425] fc6 <- pool5
I0403 02:30:40.571053 30256 net.cpp:399] fc6 -> fc6
I0403 02:30:42.015753 30256 net.cpp:141] Setting up fc6
I0403 02:30:42.015836 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.015852 30256 net.cpp:156] Memory required for data: 823333600
I0403 02:30:42.015875 30256 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:42.015902 30256 net.cpp:91] Creating Layer relu6
I0403 02:30:42.015921 30256 net.cpp:425] relu6 <- fc6
I0403 02:30:42.015941 30256 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:42.015962 30256 net.cpp:141] Setting up relu6
I0403 02:30:42.015980 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.015995 30256 net.cpp:156] Memory required for data: 824972000
I0403 02:30:42.016008 30256 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:42.016031 30256 net.cpp:91] Creating Layer drop6
I0403 02:30:42.016047 30256 net.cpp:425] drop6 <- fc6
I0403 02:30:42.016064 30256 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:42.016103 30256 net.cpp:141] Setting up drop6
I0403 02:30:42.016130 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.016146 30256 net.cpp:156] Memory required for data: 826610400
I0403 02:30:42.016160 30256 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:42.016181 30256 net.cpp:91] Creating Layer fc7
I0403 02:30:42.016196 30256 net.cpp:425] fc7 <- fc6
I0403 02:30:42.016216 30256 net.cpp:399] fc7 -> fc7
I0403 02:30:42.639632 30256 net.cpp:141] Setting up fc7
I0403 02:30:42.639716 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.639732 30256 net.cpp:156] Memory required for data: 828248800
I0403 02:30:42.639755 30256 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:42.639777 30256 net.cpp:91] Creating Layer relu7
I0403 02:30:42.639793 30256 net.cpp:425] relu7 <- fc7
I0403 02:30:42.639813 30256 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:42.639834 30256 net.cpp:141] Setting up relu7
I0403 02:30:42.639852 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.639865 30256 net.cpp:156] Memory required for data: 829887200
I0403 02:30:42.639880 30256 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:42.639904 30256 net.cpp:91] Creating Layer drop7
I0403 02:30:42.639920 30256 net.cpp:425] drop7 <- fc7
I0403 02:30:42.639937 30256 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:42.639978 30256 net.cpp:141] Setting up drop7
I0403 02:30:42.640000 30256 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.640014 30256 net.cpp:156] Memory required for data: 831525600
I0403 02:30:42.640028 30256 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:42.640048 30256 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:42.640064 30256 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:42.640084 30256 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:42.646311 30256 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:42.646344 30256 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.646366 30256 net.cpp:156] Memory required for data: 831540800
I0403 02:30:42.646407 30256 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.646428 30256 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.646443 30256 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:42.646461 30256 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.646481 30256 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.646544 30256 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.646567 30256 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.646595 30256 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.646610 30256 net.cpp:156] Memory required for data: 831571200
I0403 02:30:42.646625 30256 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.646643 30256 net.cpp:91] Creating Layer loss
I0403 02:30:42.646659 30256 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.646677 30256 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:42.646697 30256 net.cpp:399] loss -> loss
I0403 02:30:42.646721 30256 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.646831 30256 net.cpp:141] Setting up loss
I0403 02:30:42.646890 30256 net.cpp:148] Top shape: (1)
I0403 02:30:42.646905 30256 net.cpp:151]     with loss weight 1
I0403 02:30:42.646931 30256 net.cpp:156] Memory required for data: 831571204
I0403 02:30:42.646946 30256 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:42.646967 30256 net.cpp:91] Creating Layer accuracy
I0403 02:30:42.646983 30256 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.646999 30256 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:42.647016 30256 net.cpp:399] accuracy -> accuracy
I0403 02:30:42.647045 30256 net.cpp:141] Setting up accuracy
I0403 02:30:42.647064 30256 net.cpp:148] Top shape: (1)
I0403 02:30:42.647078 30256 net.cpp:156] Memory required for data: 831571208
I0403 02:30:42.647094 30256 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:42.647109 30256 net.cpp:217] loss needs backward computation.
I0403 02:30:42.647122 30256 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:42.647136 30256 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:42.647151 30256 net.cpp:217] drop7 needs backward computation.
I0403 02:30:42.647166 30256 net.cpp:217] relu7 needs backward computation.
I0403 02:30:42.647178 30256 net.cpp:217] fc7 needs backward computation.
I0403 02:30:42.647192 30256 net.cpp:217] drop6 needs backward computation.
I0403 02:30:42.647207 30256 net.cpp:217] relu6 needs backward computation.
I0403 02:30:42.647219 30256 net.cpp:217] fc6 needs backward computation.
I0403 02:30:42.647234 30256 net.cpp:217] pool5 needs backward computation.
I0403 02:30:42.647248 30256 net.cpp:217] relu5 needs backward computation.
I0403 02:30:42.647263 30256 net.cpp:217] conv5 needs backward computation.
I0403 02:30:42.647276 30256 net.cpp:217] relu4 needs backward computation.
I0403 02:30:42.647290 30256 net.cpp:217] conv4 needs backward computation.
I0403 02:30:42.647305 30256 net.cpp:217] relu3 needs backward computation.
I0403 02:30:42.647317 30256 net.cpp:217] conv3 needs backward computation.
I0403 02:30:42.647331 30256 net.cpp:217] pool2 needs backward computation.
I0403 02:30:42.647346 30256 net.cpp:217] norm2 needs backward computation.
I0403 02:30:42.647367 30256 net.cpp:217] relu2 needs backward computation.
I0403 02:30:42.647382 30256 net.cpp:217] conv2 needs backward computation.
I0403 02:30:42.647395 30256 net.cpp:217] pool1 needs backward computation.
I0403 02:30:42.647409 30256 net.cpp:217] norm1 needs backward computation.
I0403 02:30:42.647423 30256 net.cpp:217] relu1 needs backward computation.
I0403 02:30:42.647438 30256 net.cpp:217] conv1 needs backward computation.
I0403 02:30:42.647465 30256 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:42.647482 30256 net.cpp:219] data does not need backward computation.
I0403 02:30:42.647496 30256 net.cpp:261] This network produces output accuracy
I0403 02:30:42.647511 30256 net.cpp:261] This network produces output loss
I0403 02:30:42.647538 30256 net.cpp:274] Network initialization done.
I0403 02:30:42.647639 30256 solver.cpp:60] Solver scaffolding done.
I0403 02:30:42.648094 30256 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.487977 30256 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.488054 30256 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.488073 30256 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.488121 30256 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.923939 30256 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.966102 30256 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.548923 30256 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.548998 30256 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.549018 30256 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.549088 30256 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.984308 30256 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.025879 30256 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.052606 30256 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.309859 30256 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.015913 30256 parallel.cpp:425] Starting Optimization
I0403 02:30:48.016436 30256 solver.cpp:279] Solving 
I0403 02:30:48.016460 30256 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.016607 30256 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:11.926229 30256 solver.cpp:404]     Test net output #0: accuracy = 0.0264762
I0403 02:31:11.926429 30256 solver.cpp:404]     Test net output #1: loss = 3.90146 (* 1 = 3.90146 loss)
I0403 02:31:12.499644 30256 solver.cpp:228] Iteration 0, loss = 4.06312
I0403 02:31:12.499730 30256 solver.cpp:244]     Train net output #0: loss = 4.06312 (* 1 = 4.06312 loss)
I0403 02:31:12.687166 30256 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:31:27.560812 30256 solver.cpp:228] Iteration 21, loss = 1.2213
I0403 02:31:27.565593 30256 solver.cpp:244]     Train net output #0: loss = 1.2213 (* 1 = 1.2213 loss)
I0403 02:31:27.751062 30256 sgd_solver.cpp:106] Iteration 21, lr = 0.005
I0403 02:31:42.575018 30256 solver.cpp:228] Iteration 42, loss = 0.642704
I0403 02:31:42.580637 30256 solver.cpp:244]     Train net output #0: loss = 0.642704 (* 1 = 0.642704 loss)
I0403 02:31:42.774489 30256 sgd_solver.cpp:106] Iteration 42, lr = 0.005
I0403 02:31:57.594306 30256 solver.cpp:228] Iteration 63, loss = 0.420919
I0403 02:31:57.599558 30256 solver.cpp:244]     Train net output #0: loss = 0.420919 (* 1 = 0.420919 loss)
I0403 02:31:57.783638 30256 sgd_solver.cpp:106] Iteration 63, lr = 0.005
I0403 02:32:12.877832 30256 solver.cpp:228] Iteration 84, loss = 0.421637
I0403 02:32:12.883795 30256 solver.cpp:244]     Train net output #0: loss = 0.421637 (* 1 = 0.421637 loss)
I0403 02:32:13.104282 30256 sgd_solver.cpp:106] Iteration 84, lr = 0.005
I0403 02:32:27.942332 30256 solver.cpp:228] Iteration 105, loss = 0.282381
I0403 02:32:27.947044 30256 solver.cpp:244]     Train net output #0: loss = 0.282381 (* 1 = 0.282381 loss)
I0403 02:32:28.140718 30256 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 02:32:43.007253 30256 solver.cpp:228] Iteration 126, loss = 0.241527
I0403 02:32:43.012943 30256 solver.cpp:244]     Train net output #0: loss = 0.241527 (* 1 = 0.241527 loss)
I0403 02:32:43.177912 30256 sgd_solver.cpp:106] Iteration 126, lr = 0.005
I0403 02:32:58.035526 30256 solver.cpp:228] Iteration 147, loss = 0.30376
I0403 02:32:58.042448 30256 solver.cpp:244]     Train net output #0: loss = 0.30376 (* 1 = 0.30376 loss)
I0403 02:32:58.222175 30256 sgd_solver.cpp:106] Iteration 147, lr = 0.005
I0403 02:33:13.216287 30256 solver.cpp:228] Iteration 168, loss = 0.248871
I0403 02:33:13.229385 30256 solver.cpp:244]     Train net output #0: loss = 0.248871 (* 1 = 0.248871 loss)
I0403 02:33:13.365841 30256 sgd_solver.cpp:106] Iteration 168, lr = 0.005
I0403 02:33:28.207118 30256 solver.cpp:228] Iteration 189, loss = 0.162452
I0403 02:33:28.212270 30256 solver.cpp:244]     Train net output #0: loss = 0.162452 (* 1 = 0.162452 loss)
I0403 02:33:28.373196 30256 sgd_solver.cpp:106] Iteration 189, lr = 0.005
I0403 02:33:43.275833 30256 solver.cpp:228] Iteration 210, loss = 0.0974481
I0403 02:33:43.283417 30256 solver.cpp:244]     Train net output #0: loss = 0.097448 (* 1 = 0.097448 loss)
I0403 02:33:43.446689 30256 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:33:58.244721 30256 solver.cpp:228] Iteration 231, loss = 0.202086
I0403 02:33:58.252106 30256 solver.cpp:244]     Train net output #0: loss = 0.202086 (* 1 = 0.202086 loss)
I0403 02:33:58.430745 30256 sgd_solver.cpp:106] Iteration 231, lr = 0.005
I0403 02:34:13.462977 30256 solver.cpp:228] Iteration 252, loss = 0.192782
I0403 02:34:13.470386 30256 solver.cpp:244]     Train net output #0: loss = 0.192782 (* 1 = 0.192782 loss)
I0403 02:34:13.584087 30256 sgd_solver.cpp:106] Iteration 252, lr = 0.005
I0403 02:34:28.819128 30256 solver.cpp:228] Iteration 273, loss = 0.0804142
I0403 02:34:28.824439 30256 solver.cpp:244]     Train net output #0: loss = 0.0804141 (* 1 = 0.0804141 loss)
I0403 02:34:29.013962 30256 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 02:34:43.885666 30256 solver.cpp:228] Iteration 294, loss = 0.147133
I0403 02:34:43.891484 30256 solver.cpp:244]     Train net output #0: loss = 0.147133 (* 1 = 0.147133 loss)
I0403 02:34:44.111863 30256 sgd_solver.cpp:106] Iteration 294, lr = 0.005
I0403 02:34:58.986623 30256 solver.cpp:228] Iteration 315, loss = 0.117485
I0403 02:34:58.994433 30256 solver.cpp:244]     Train net output #0: loss = 0.117485 (* 1 = 0.117485 loss)
I0403 02:34:59.185545 30256 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 02:35:14.509835 30256 solver.cpp:228] Iteration 336, loss = 0.0734725
I0403 02:35:14.515681 30256 solver.cpp:244]     Train net output #0: loss = 0.0734725 (* 1 = 0.0734725 loss)
I0403 02:35:14.668067 30256 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 02:35:29.645212 30256 solver.cpp:228] Iteration 357, loss = 0.106664
I0403 02:35:29.651630 30256 solver.cpp:244]     Train net output #0: loss = 0.106664 (* 1 = 0.106664 loss)
I0403 02:35:29.825106 30256 sgd_solver.cpp:106] Iteration 357, lr = 0.005
I0403 02:35:44.796278 30256 solver.cpp:228] Iteration 378, loss = 0.0779697
I0403 02:35:44.802572 30256 solver.cpp:244]     Train net output #0: loss = 0.0779696 (* 1 = 0.0779696 loss)
I0403 02:35:44.986655 30256 sgd_solver.cpp:106] Iteration 378, lr = 0.005
I0403 02:35:59.943579 30256 solver.cpp:228] Iteration 399, loss = 0.0819769
I0403 02:35:59.949635 30256 solver.cpp:244]     Train net output #0: loss = 0.0819769 (* 1 = 0.0819769 loss)
I0403 02:36:00.144311 30256 sgd_solver.cpp:106] Iteration 399, lr = 0.005
I0403 02:36:15.167392 30256 solver.cpp:228] Iteration 420, loss = 0.0774725
I0403 02:36:15.178035 30256 solver.cpp:244]     Train net output #0: loss = 0.0774725 (* 1 = 0.0774725 loss)
I0403 02:36:15.378118 30256 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:36:26.977660 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_437.caffemodel
I0403 02:36:29.960608 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_437.solverstate
I0403 02:36:31.985363 30256 solver.cpp:337] Iteration 437, Testing net (#0)
I0403 02:36:55.443598 30256 solver.cpp:404]     Test net output #0: accuracy = 0.967619
I0403 02:36:55.449707 30256 solver.cpp:404]     Test net output #1: loss = 0.0965371 (* 1 = 0.0965371 loss)
I0403 02:36:58.817121 30256 solver.cpp:228] Iteration 441, loss = 0.0466743
I0403 02:36:58.823685 30256 solver.cpp:244]     Train net output #0: loss = 0.0466742 (* 1 = 0.0466742 loss)
I0403 02:36:58.995600 30256 sgd_solver.cpp:106] Iteration 441, lr = 0.005
I0403 02:37:13.942087 30256 solver.cpp:228] Iteration 462, loss = 0.102641
I0403 02:37:13.948787 30256 solver.cpp:244]     Train net output #0: loss = 0.102641 (* 1 = 0.102641 loss)
I0403 02:37:14.129340 30256 sgd_solver.cpp:106] Iteration 462, lr = 0.005
I0403 02:37:29.517818 30256 solver.cpp:228] Iteration 483, loss = 0.135948
I0403 02:37:29.523903 30256 solver.cpp:244]     Train net output #0: loss = 0.135948 (* 1 = 0.135948 loss)
I0403 02:37:29.705652 30256 sgd_solver.cpp:106] Iteration 483, lr = 0.005
I0403 02:37:44.737972 30256 solver.cpp:228] Iteration 504, loss = 0.120306
I0403 02:37:44.744102 30256 solver.cpp:244]     Train net output #0: loss = 0.120306 (* 1 = 0.120306 loss)
I0403 02:37:44.914638 30256 sgd_solver.cpp:106] Iteration 504, lr = 0.005
I0403 02:37:59.983062 30256 solver.cpp:228] Iteration 525, loss = 0.0409527
I0403 02:37:59.983352 30256 solver.cpp:244]     Train net output #0: loss = 0.0409526 (* 1 = 0.0409526 loss)
I0403 02:38:00.172478 30256 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 02:38:15.155714 30256 solver.cpp:228] Iteration 546, loss = 0.0975335
I0403 02:38:15.161815 30256 solver.cpp:244]     Train net output #0: loss = 0.0975335 (* 1 = 0.0975335 loss)
I0403 02:38:15.384780 30256 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 02:38:30.385422 30256 solver.cpp:228] Iteration 567, loss = 0.121718
I0403 02:38:30.397297 30256 solver.cpp:244]     Train net output #0: loss = 0.121718 (* 1 = 0.121718 loss)
I0403 02:38:30.525101 30256 sgd_solver.cpp:106] Iteration 567, lr = 0.005
I0403 02:38:45.552047 30256 solver.cpp:228] Iteration 588, loss = 0.0376883
I0403 02:38:45.552152 30256 solver.cpp:244]     Train net output #0: loss = 0.0376882 (* 1 = 0.0376882 loss)
I0403 02:38:45.736125 30256 sgd_solver.cpp:106] Iteration 588, lr = 0.005
I0403 02:39:00.894809 30256 solver.cpp:228] Iteration 609, loss = 0.00759403
I0403 02:39:00.895047 30256 solver.cpp:244]     Train net output #0: loss = 0.00759395 (* 1 = 0.00759395 loss)
I0403 02:39:01.111524 30256 sgd_solver.cpp:106] Iteration 609, lr = 0.005
I0403 02:39:16.003852 30256 solver.cpp:228] Iteration 630, loss = 0.12359
I0403 02:39:16.003953 30256 solver.cpp:244]     Train net output #0: loss = 0.12359 (* 1 = 0.12359 loss)
I0403 02:39:16.180847 30256 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:39:31.157852 30256 solver.cpp:228] Iteration 651, loss = 0.0646507
I0403 02:39:31.158146 30256 solver.cpp:244]     Train net output #0: loss = 0.0646506 (* 1 = 0.0646506 loss)
I0403 02:39:31.328119 30256 sgd_solver.cpp:106] Iteration 651, lr = 0.005
I0403 02:39:46.239042 30256 solver.cpp:228] Iteration 672, loss = 0.033048
I0403 02:39:46.239151 30256 solver.cpp:244]     Train net output #0: loss = 0.0330479 (* 1 = 0.0330479 loss)
I0403 02:39:46.416916 30256 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 02:40:01.309537 30256 solver.cpp:228] Iteration 693, loss = 0.0753325
I0403 02:40:01.309834 30256 solver.cpp:244]     Train net output #0: loss = 0.0753324 (* 1 = 0.0753324 loss)
I0403 02:40:01.486816 30256 sgd_solver.cpp:106] Iteration 693, lr = 0.005
I0403 02:40:16.585335 30256 solver.cpp:228] Iteration 714, loss = 0.0972008
I0403 02:40:16.585433 30256 solver.cpp:244]     Train net output #0: loss = 0.0972007 (* 1 = 0.0972007 loss)
I0403 02:40:16.762924 30256 sgd_solver.cpp:106] Iteration 714, lr = 0.005
I0403 02:40:31.759285 30256 solver.cpp:228] Iteration 735, loss = 0.0128365
I0403 02:40:31.759613 30256 solver.cpp:244]     Train net output #0: loss = 0.0128364 (* 1 = 0.0128364 loss)
I0403 02:40:31.912451 30256 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 02:40:47.066504 30256 solver.cpp:228] Iteration 756, loss = 0.0571648
I0403 02:40:47.072650 30256 solver.cpp:244]     Train net output #0: loss = 0.0571647 (* 1 = 0.0571647 loss)
I0403 02:40:47.271373 30256 sgd_solver.cpp:106] Iteration 756, lr = 0.005
I0403 02:41:02.432960 30256 solver.cpp:228] Iteration 777, loss = 0.0281223
I0403 02:41:02.439556 30256 solver.cpp:244]     Train net output #0: loss = 0.0281222 (* 1 = 0.0281222 loss)
I0403 02:41:02.563992 30256 sgd_solver.cpp:106] Iteration 777, lr = 0.005
I0403 02:41:17.696950 30256 solver.cpp:228] Iteration 798, loss = 0.0650432
I0403 02:41:17.703277 30256 solver.cpp:244]     Train net output #0: loss = 0.0650432 (* 1 = 0.0650432 loss)
I0403 02:41:17.872464 30256 sgd_solver.cpp:106] Iteration 798, lr = 0.005
I0403 02:41:33.162566 30256 solver.cpp:228] Iteration 819, loss = 0.0970297
I0403 02:41:33.174072 30256 solver.cpp:244]     Train net output #0: loss = 0.0970296 (* 1 = 0.0970296 loss)
I0403 02:41:33.371918 30256 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 02:41:48.279734 30256 solver.cpp:228] Iteration 840, loss = 0.083393
I0403 02:41:48.289918 30256 solver.cpp:244]     Train net output #0: loss = 0.0833929 (* 1 = 0.0833929 loss)
I0403 02:41:48.465059 30256 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:42:03.451207 30256 solver.cpp:228] Iteration 861, loss = 0.0322261
I0403 02:42:03.457782 30256 solver.cpp:244]     Train net output #0: loss = 0.032226 (* 1 = 0.032226 loss)
I0403 02:42:03.629662 30256 sgd_solver.cpp:106] Iteration 861, lr = 0.005
I0403 02:42:12.295344 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_874.caffemodel
I0403 02:42:15.040577 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_874.solverstate
I0403 02:42:16.882632 30256 solver.cpp:337] Iteration 874, Testing net (#0)
I0403 02:42:40.362494 30256 solver.cpp:404]     Test net output #0: accuracy = 0.973429
I0403 02:42:40.369925 30256 solver.cpp:404]     Test net output #1: loss = 0.0802582 (* 1 = 0.0802582 loss)
I0403 02:42:46.642599 30256 solver.cpp:228] Iteration 882, loss = 0.0208525
I0403 02:42:46.648908 30256 solver.cpp:244]     Train net output #0: loss = 0.0208525 (* 1 = 0.0208525 loss)
I0403 02:42:46.833751 30256 sgd_solver.cpp:106] Iteration 882, lr = 0.005
I0403 02:43:01.645925 30256 solver.cpp:228] Iteration 903, loss = 0.0178517
I0403 02:43:01.651715 30256 solver.cpp:244]     Train net output #0: loss = 0.0178517 (* 1 = 0.0178517 loss)
I0403 02:43:01.832094 30256 sgd_solver.cpp:106] Iteration 903, lr = 0.005
I0403 02:43:16.579835 30256 solver.cpp:228] Iteration 924, loss = 0.0338975
I0403 02:43:16.585685 30256 solver.cpp:244]     Train net output #0: loss = 0.0338975 (* 1 = 0.0338975 loss)
I0403 02:43:16.758559 30256 sgd_solver.cpp:106] Iteration 924, lr = 0.005
I0403 02:43:31.638192 30256 solver.cpp:228] Iteration 945, loss = 0.0955471
I0403 02:43:31.643965 30256 solver.cpp:244]     Train net output #0: loss = 0.0955471 (* 1 = 0.0955471 loss)
I0403 02:43:31.818384 30256 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 02:43:46.777443 30256 solver.cpp:228] Iteration 966, loss = 0.285155
I0403 02:43:46.782639 30256 solver.cpp:244]     Train net output #0: loss = 0.285155 (* 1 = 0.285155 loss)
I0403 02:43:46.928249 30256 sgd_solver.cpp:106] Iteration 966, lr = 0.005
I0403 02:44:02.003206 30256 solver.cpp:228] Iteration 987, loss = 0.0260102
I0403 02:44:02.009063 30256 solver.cpp:244]     Train net output #0: loss = 0.0260101 (* 1 = 0.0260101 loss)
I0403 02:44:02.115344 30256 sgd_solver.cpp:106] Iteration 987, lr = 0.005
I0403 02:44:17.050739 30256 solver.cpp:228] Iteration 1008, loss = 0.167971
I0403 02:44:17.058686 30256 solver.cpp:244]     Train net output #0: loss = 0.167971 (* 1 = 0.167971 loss)
I0403 02:44:17.260947 30256 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 02:44:32.216490 30256 solver.cpp:228] Iteration 1029, loss = 0.0346789
I0403 02:44:32.223045 30256 solver.cpp:244]     Train net output #0: loss = 0.0346789 (* 1 = 0.0346789 loss)
I0403 02:44:32.413693 30256 sgd_solver.cpp:106] Iteration 1029, lr = 0.005
I0403 02:44:47.434625 30256 solver.cpp:228] Iteration 1050, loss = 0.0243802
I0403 02:44:47.440553 30256 solver.cpp:244]     Train net output #0: loss = 0.0243801 (* 1 = 0.0243801 loss)
I0403 02:44:47.617215 30256 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 02:45:02.513505 30256 solver.cpp:228] Iteration 1071, loss = 0.0152135
I0403 02:45:02.520031 30256 solver.cpp:244]     Train net output #0: loss = 0.0152134 (* 1 = 0.0152134 loss)
I0403 02:45:02.694080 30256 sgd_solver.cpp:106] Iteration 1071, lr = 0.005
I0403 02:45:17.600415 30256 solver.cpp:228] Iteration 1092, loss = 0.00213637
I0403 02:45:17.606482 30256 solver.cpp:244]     Train net output #0: loss = 0.00213629 (* 1 = 0.00213629 loss)
I0403 02:45:17.795389 30256 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 02:45:32.666507 30256 solver.cpp:228] Iteration 1113, loss = 0.0126242
I0403 02:45:32.671636 30256 solver.cpp:244]     Train net output #0: loss = 0.0126241 (* 1 = 0.0126241 loss)
I0403 02:45:32.840080 30256 sgd_solver.cpp:106] Iteration 1113, lr = 0.005
I0403 02:45:47.870228 30256 solver.cpp:228] Iteration 1134, loss = 0.00743439
I0403 02:45:47.875735 30256 solver.cpp:244]     Train net output #0: loss = 0.00743429 (* 1 = 0.00743429 loss)
I0403 02:45:48.075129 30256 sgd_solver.cpp:106] Iteration 1134, lr = 0.005
I0403 02:46:02.993512 30256 solver.cpp:228] Iteration 1155, loss = 0.062122
I0403 02:46:02.999513 30256 solver.cpp:244]     Train net output #0: loss = 0.0621219 (* 1 = 0.0621219 loss)
I0403 02:46:03.174191 30256 sgd_solver.cpp:106] Iteration 1155, lr = 0.005
I0403 02:46:18.273397 30256 solver.cpp:228] Iteration 1176, loss = 0.048949
I0403 02:46:18.278448 30256 solver.cpp:244]     Train net output #0: loss = 0.0489489 (* 1 = 0.0489489 loss)
I0403 02:46:18.379883 30256 sgd_solver.cpp:106] Iteration 1176, lr = 0.005
I0403 02:46:33.470774 30256 solver.cpp:228] Iteration 1197, loss = 0.0917815
I0403 02:46:33.477882 30256 solver.cpp:244]     Train net output #0: loss = 0.0917814 (* 1 = 0.0917814 loss)
I0403 02:46:33.656209 30256 sgd_solver.cpp:106] Iteration 1197, lr = 0.005
I0403 02:46:48.562170 30256 solver.cpp:228] Iteration 1218, loss = 0.0604345
I0403 02:46:48.568579 30256 solver.cpp:244]     Train net output #0: loss = 0.0604344 (* 1 = 0.0604344 loss)
I0403 02:46:48.790560 30256 sgd_solver.cpp:106] Iteration 1218, lr = 0.005
I0403 02:47:03.871506 30256 solver.cpp:228] Iteration 1239, loss = 0.0423221
I0403 02:47:03.882550 30256 solver.cpp:244]     Train net output #0: loss = 0.042322 (* 1 = 0.042322 loss)
I0403 02:47:04.115041 30256 sgd_solver.cpp:106] Iteration 1239, lr = 0.005
I0403 02:47:19.198052 30256 solver.cpp:228] Iteration 1260, loss = 0.00929557
I0403 02:47:19.205037 30256 solver.cpp:244]     Train net output #0: loss = 0.00929545 (* 1 = 0.00929545 loss)
I0403 02:47:19.375074 30256 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 02:47:34.390682 30256 solver.cpp:228] Iteration 1281, loss = 0.0250071
I0403 02:47:34.397159 30256 solver.cpp:244]     Train net output #0: loss = 0.025007 (* 1 = 0.025007 loss)
I0403 02:47:34.540117 30256 sgd_solver.cpp:106] Iteration 1281, lr = 0.005
I0403 02:47:49.632239 30256 solver.cpp:228] Iteration 1302, loss = 0.0532449
I0403 02:47:49.638474 30256 solver.cpp:244]     Train net output #0: loss = 0.0532448 (* 1 = 0.0532448 loss)
I0403 02:47:49.811532 30256 sgd_solver.cpp:106] Iteration 1302, lr = 0.005
I0403 02:47:55.583093 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_1311.caffemodel
I0403 02:47:58.332917 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_1311.solverstate
I0403 02:48:00.201954 30256 solver.cpp:337] Iteration 1311, Testing net (#0)
I0403 02:48:23.679931 30256 solver.cpp:404]     Test net output #0: accuracy = 0.983905
I0403 02:48:23.686960 30256 solver.cpp:404]     Test net output #1: loss = 0.0514011 (* 1 = 0.0514011 loss)
I0403 02:48:32.852819 30256 solver.cpp:228] Iteration 1323, loss = 0.00253286
I0403 02:48:32.859506 30256 solver.cpp:244]     Train net output #0: loss = 0.00253276 (* 1 = 0.00253276 loss)
I0403 02:48:33.042630 30256 sgd_solver.cpp:106] Iteration 1323, lr = 0.005
I0403 02:48:48.063982 30256 solver.cpp:228] Iteration 1344, loss = 0.0287033
I0403 02:48:48.069876 30256 solver.cpp:244]     Train net output #0: loss = 0.0287032 (* 1 = 0.0287032 loss)
I0403 02:48:48.241120 30256 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 02:49:03.035161 30256 solver.cpp:228] Iteration 1365, loss = 0.0200496
I0403 02:49:03.041221 30256 solver.cpp:244]     Train net output #0: loss = 0.0200495 (* 1 = 0.0200495 loss)
I0403 02:49:03.226086 30256 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 02:49:18.102864 30256 solver.cpp:228] Iteration 1386, loss = 0.0299935
I0403 02:49:18.108613 30256 solver.cpp:244]     Train net output #0: loss = 0.0299935 (* 1 = 0.0299935 loss)
I0403 02:49:18.332406 30256 sgd_solver.cpp:106] Iteration 1386, lr = 0.005
I0403 02:49:33.503219 30256 solver.cpp:228] Iteration 1407, loss = 0.0520345
I0403 02:49:33.510174 30256 solver.cpp:244]     Train net output #0: loss = 0.0520344 (* 1 = 0.0520344 loss)
I0403 02:49:33.703621 30256 sgd_solver.cpp:106] Iteration 1407, lr = 0.005
I0403 02:49:48.689604 30256 solver.cpp:228] Iteration 1428, loss = 0.0389651
I0403 02:49:48.695962 30256 solver.cpp:244]     Train net output #0: loss = 0.038965 (* 1 = 0.038965 loss)
I0403 02:49:48.839092 30256 sgd_solver.cpp:106] Iteration 1428, lr = 0.005
I0403 02:50:03.855041 30256 solver.cpp:228] Iteration 1449, loss = 0.0570134
I0403 02:50:03.861413 30256 solver.cpp:244]     Train net output #0: loss = 0.0570133 (* 1 = 0.0570133 loss)
I0403 02:50:04.032600 30256 sgd_solver.cpp:106] Iteration 1449, lr = 0.005
I0403 02:50:18.968482 30256 solver.cpp:228] Iteration 1470, loss = 0.0289574
I0403 02:50:18.974797 30256 solver.cpp:244]     Train net output #0: loss = 0.0289573 (* 1 = 0.0289573 loss)
I0403 02:50:19.200990 30256 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 02:50:34.168547 30256 solver.cpp:228] Iteration 1491, loss = 0.0458526
I0403 02:50:34.174163 30256 solver.cpp:244]     Train net output #0: loss = 0.0458525 (* 1 = 0.0458525 loss)
I0403 02:50:34.364614 30256 sgd_solver.cpp:106] Iteration 1491, lr = 0.005
I0403 02:50:49.348170 30256 solver.cpp:228] Iteration 1512, loss = 0.0275005
I0403 02:50:49.354460 30256 solver.cpp:244]     Train net output #0: loss = 0.0275004 (* 1 = 0.0275004 loss)
I0403 02:50:49.530794 30256 sgd_solver.cpp:106] Iteration 1512, lr = 0.005
I0403 02:51:04.610960 30256 solver.cpp:228] Iteration 1533, loss = 0.0494836
I0403 02:51:04.623380 30256 solver.cpp:244]     Train net output #0: loss = 0.0494835 (* 1 = 0.0494835 loss)
I0403 02:51:04.851645 30256 sgd_solver.cpp:106] Iteration 1533, lr = 0.005
I0403 02:51:19.886749 30256 solver.cpp:228] Iteration 1554, loss = 0.0502356
I0403 02:51:19.892771 30256 solver.cpp:244]     Train net output #0: loss = 0.0502355 (* 1 = 0.0502355 loss)
I0403 02:51:20.084360 30256 sgd_solver.cpp:106] Iteration 1554, lr = 0.005
I0403 02:51:35.075439 30256 solver.cpp:228] Iteration 1575, loss = 0.00147565
I0403 02:51:35.082710 30256 solver.cpp:244]     Train net output #0: loss = 0.00147555 (* 1 = 0.00147555 loss)
I0403 02:51:35.255553 30256 sgd_solver.cpp:106] Iteration 1575, lr = 0.005
I0403 02:51:50.185019 30256 solver.cpp:228] Iteration 1596, loss = 0.0127427
I0403 02:51:50.190955 30256 solver.cpp:244]     Train net output #0: loss = 0.0127426 (* 1 = 0.0127426 loss)
I0403 02:51:50.356242 30256 sgd_solver.cpp:106] Iteration 1596, lr = 0.005
I0403 02:52:05.347453 30256 solver.cpp:228] Iteration 1617, loss = 0.0477212
I0403 02:52:05.353835 30256 solver.cpp:244]     Train net output #0: loss = 0.0477211 (* 1 = 0.0477211 loss)
I0403 02:52:05.504950 30256 sgd_solver.cpp:106] Iteration 1617, lr = 0.005
I0403 02:52:20.679160 30256 solver.cpp:228] Iteration 1638, loss = 0.00292882
I0403 02:52:20.685142 30256 solver.cpp:244]     Train net output #0: loss = 0.00292872 (* 1 = 0.00292872 loss)
I0403 02:52:20.858110 30256 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 02:52:35.878334 30256 solver.cpp:228] Iteration 1659, loss = 0.00813423
I0403 02:52:35.884807 30256 solver.cpp:244]     Train net output #0: loss = 0.00813412 (* 1 = 0.00813412 loss)
I0403 02:52:36.056709 30256 sgd_solver.cpp:106] Iteration 1659, lr = 0.005
I0403 02:52:51.286279 30256 solver.cpp:228] Iteration 1680, loss = 0.101063
I0403 02:52:51.291066 30256 solver.cpp:244]     Train net output #0: loss = 0.101063 (* 1 = 0.101063 loss)
I0403 02:52:51.484974 30256 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 02:53:06.598809 30256 solver.cpp:228] Iteration 1701, loss = 0.0528928
I0403 02:53:06.608866 30256 solver.cpp:244]     Train net output #0: loss = 0.0528927 (* 1 = 0.0528927 loss)
I0403 02:53:06.829015 30256 sgd_solver.cpp:106] Iteration 1701, lr = 0.005
I0403 02:53:21.850379 30256 solver.cpp:228] Iteration 1722, loss = 0.0697937
I0403 02:53:21.856541 30256 solver.cpp:244]     Train net output #0: loss = 0.0697936 (* 1 = 0.0697936 loss)
I0403 02:53:22.024390 30256 sgd_solver.cpp:106] Iteration 1722, lr = 0.005
I0403 02:53:36.962653 30256 solver.cpp:228] Iteration 1743, loss = 0.000753634
I0403 02:53:36.968145 30256 solver.cpp:244]     Train net output #0: loss = 0.000753529 (* 1 = 0.000753529 loss)
I0403 02:53:37.190870 30256 sgd_solver.cpp:106] Iteration 1743, lr = 0.005
I0403 02:53:40.161402 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_1748.caffemodel
I0403 02:53:42.958107 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_1748.solverstate
I0403 02:53:44.787713 30256 solver.cpp:337] Iteration 1748, Testing net (#0)
I0403 02:54:08.276882 30256 solver.cpp:404]     Test net output #0: accuracy = 0.983048
I0403 02:54:08.284260 30256 solver.cpp:404]     Test net output #1: loss = 0.0541228 (* 1 = 0.0541228 loss)
I0403 02:54:20.376029 30256 solver.cpp:228] Iteration 1764, loss = 0.0177782
I0403 02:54:20.381352 30256 solver.cpp:244]     Train net output #0: loss = 0.0177781 (* 1 = 0.0177781 loss)
I0403 02:54:20.554661 30256 sgd_solver.cpp:106] Iteration 1764, lr = 0.005
I0403 02:54:35.399476 30256 solver.cpp:228] Iteration 1785, loss = 0.0122513
I0403 02:54:35.406172 30256 solver.cpp:244]     Train net output #0: loss = 0.0122512 (* 1 = 0.0122512 loss)
I0403 02:54:35.615530 30256 sgd_solver.cpp:106] Iteration 1785, lr = 0.005
I0403 02:54:50.439673 30256 solver.cpp:228] Iteration 1806, loss = 0.0507271
I0403 02:54:50.445644 30256 solver.cpp:244]     Train net output #0: loss = 0.0507269 (* 1 = 0.0507269 loss)
I0403 02:54:50.616367 30256 sgd_solver.cpp:106] Iteration 1806, lr = 0.005
I0403 02:55:05.604698 30256 solver.cpp:228] Iteration 1827, loss = 0.0765077
I0403 02:55:05.611928 30256 solver.cpp:244]     Train net output #0: loss = 0.0765076 (* 1 = 0.0765076 loss)
I0403 02:55:05.784095 30256 sgd_solver.cpp:106] Iteration 1827, lr = 0.005
I0403 02:55:20.771389 30256 solver.cpp:228] Iteration 1848, loss = 0.0333941
I0403 02:55:20.777142 30256 solver.cpp:244]     Train net output #0: loss = 0.033394 (* 1 = 0.033394 loss)
I0403 02:55:20.992197 30256 sgd_solver.cpp:106] Iteration 1848, lr = 0.005
I0403 02:55:35.905664 30256 solver.cpp:228] Iteration 1869, loss = 0.0243227
I0403 02:55:35.910897 30256 solver.cpp:244]     Train net output #0: loss = 0.0243226 (* 1 = 0.0243226 loss)
I0403 02:55:36.051249 30256 sgd_solver.cpp:106] Iteration 1869, lr = 0.005
I0403 02:55:51.035714 30256 solver.cpp:228] Iteration 1890, loss = 0.00259213
I0403 02:55:51.042147 30256 solver.cpp:244]     Train net output #0: loss = 0.00259203 (* 1 = 0.00259203 loss)
I0403 02:55:51.236963 30256 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 02:56:06.238483 30256 solver.cpp:228] Iteration 1911, loss = 0.00105919
I0403 02:56:06.244580 30256 solver.cpp:244]     Train net output #0: loss = 0.00105909 (* 1 = 0.00105909 loss)
I0403 02:56:06.450392 30256 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 02:56:21.490041 30256 solver.cpp:228] Iteration 1932, loss = 0.0117297
I0403 02:56:21.496502 30256 solver.cpp:244]     Train net output #0: loss = 0.0117296 (* 1 = 0.0117296 loss)
I0403 02:56:21.640694 30256 sgd_solver.cpp:106] Iteration 1932, lr = 0.005
I0403 02:56:36.846356 30256 solver.cpp:228] Iteration 1953, loss = 0.0216056
I0403 02:56:36.852969 30256 solver.cpp:244]     Train net output #0: loss = 0.0216055 (* 1 = 0.0216055 loss)
I0403 02:56:37.046241 30256 sgd_solver.cpp:106] Iteration 1953, lr = 0.005
I0403 02:56:51.984802 30256 solver.cpp:228] Iteration 1974, loss = 0.0208762
I0403 02:56:51.990733 30256 solver.cpp:244]     Train net output #0: loss = 0.0208761 (* 1 = 0.0208761 loss)
I0403 02:56:52.180122 30256 sgd_solver.cpp:106] Iteration 1974, lr = 0.005
I0403 02:57:07.215608 30256 solver.cpp:228] Iteration 1995, loss = 0.00398814
I0403 02:57:07.221495 30256 solver.cpp:244]     Train net output #0: loss = 0.00398804 (* 1 = 0.00398804 loss)
I0403 02:57:07.406895 30256 sgd_solver.cpp:106] Iteration 1995, lr = 0.005
I0403 02:57:22.276350 30256 solver.cpp:228] Iteration 2016, loss = 0.00647273
I0403 02:57:22.282387 30256 solver.cpp:244]     Train net output #0: loss = 0.00647263 (* 1 = 0.00647263 loss)
I0403 02:57:22.456687 30256 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 02:57:37.460340 30256 solver.cpp:228] Iteration 2037, loss = 0.0105652
I0403 02:57:37.465929 30256 solver.cpp:244]     Train net output #0: loss = 0.0105651 (* 1 = 0.0105651 loss)
I0403 02:57:37.649660 30256 sgd_solver.cpp:106] Iteration 2037, lr = 0.005
I0403 02:57:52.682224 30256 solver.cpp:228] Iteration 2058, loss = 0.0123519
I0403 02:57:52.688529 30256 solver.cpp:244]     Train net output #0: loss = 0.0123518 (* 1 = 0.0123518 loss)
I0403 02:57:52.865389 30256 sgd_solver.cpp:106] Iteration 2058, lr = 0.005
I0403 02:58:07.876840 30256 solver.cpp:228] Iteration 2079, loss = 0.0248981
I0403 02:58:07.883092 30256 solver.cpp:244]     Train net output #0: loss = 0.0248981 (* 1 = 0.0248981 loss)
I0403 02:58:08.075207 30256 sgd_solver.cpp:106] Iteration 2079, lr = 0.005
I0403 02:58:23.110474 30256 solver.cpp:228] Iteration 2100, loss = 0.00182641
I0403 02:58:23.117977 30256 solver.cpp:244]     Train net output #0: loss = 0.00182632 (* 1 = 0.00182632 loss)
I0403 02:58:23.301709 30256 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 02:58:38.315704 30256 solver.cpp:228] Iteration 2121, loss = 0.00310734
I0403 02:58:38.321832 30256 solver.cpp:244]     Train net output #0: loss = 0.00310725 (* 1 = 0.00310725 loss)
I0403 02:58:38.474390 30256 sgd_solver.cpp:106] Iteration 2121, lr = 0.005
I0403 02:58:53.615694 30256 solver.cpp:228] Iteration 2142, loss = 0.0489695
I0403 02:58:53.622007 30256 solver.cpp:244]     Train net output #0: loss = 0.0489694 (* 1 = 0.0489694 loss)
I0403 02:58:53.800460 30256 sgd_solver.cpp:106] Iteration 2142, lr = 0.005
I0403 02:59:08.659037 30256 solver.cpp:228] Iteration 2163, loss = 0.00513471
I0403 02:59:08.663863 30256 solver.cpp:244]     Train net output #0: loss = 0.00513461 (* 1 = 0.00513461 loss)
I0403 02:59:08.846982 30256 sgd_solver.cpp:106] Iteration 2163, lr = 0.005
I0403 02:59:23.928035 30256 solver.cpp:228] Iteration 2184, loss = 0.0126192
I0403 02:59:23.933426 30256 solver.cpp:244]     Train net output #0: loss = 0.0126191 (* 1 = 0.0126191 loss)
I0403 02:59:24.147999 30256 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 02:59:24.153637 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_2185.caffemodel
I0403 02:59:26.970201 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_2185.solverstate
I0403 02:59:29.383139 30256 solver.cpp:337] Iteration 2185, Testing net (#0)
I0403 02:59:52.862231 30256 solver.cpp:404]     Test net output #0: accuracy = 0.979143
I0403 02:59:52.868000 30256 solver.cpp:404]     Test net output #1: loss = 0.0727985 (* 1 = 0.0727985 loss)
I0403 03:00:07.814174 30256 solver.cpp:228] Iteration 2205, loss = 0.0287771
I0403 03:00:07.820238 30256 solver.cpp:244]     Train net output #0: loss = 0.028777 (* 1 = 0.028777 loss)
I0403 03:00:07.986889 30256 sgd_solver.cpp:106] Iteration 2205, lr = 0.005
I0403 03:00:22.786859 30256 solver.cpp:228] Iteration 2226, loss = 0.0263457
I0403 03:00:22.792795 30256 solver.cpp:244]     Train net output #0: loss = 0.0263456 (* 1 = 0.0263456 loss)
I0403 03:00:22.989161 30256 sgd_solver.cpp:106] Iteration 2226, lr = 0.005
I0403 03:00:38.180245 30256 solver.cpp:228] Iteration 2247, loss = 0.012552
I0403 03:00:38.186767 30256 solver.cpp:244]     Train net output #0: loss = 0.0125519 (* 1 = 0.0125519 loss)
I0403 03:00:38.360009 30256 sgd_solver.cpp:106] Iteration 2247, lr = 0.005
I0403 03:00:53.353036 30256 solver.cpp:228] Iteration 2268, loss = 0.00343775
I0403 03:00:53.358518 30256 solver.cpp:244]     Train net output #0: loss = 0.00343763 (* 1 = 0.00343763 loss)
I0403 03:00:53.544667 30256 sgd_solver.cpp:106] Iteration 2268, lr = 0.005
I0403 03:01:08.421113 30256 solver.cpp:228] Iteration 2289, loss = 0.0131463
I0403 03:01:08.427363 30256 solver.cpp:244]     Train net output #0: loss = 0.0131462 (* 1 = 0.0131462 loss)
I0403 03:01:08.609086 30256 sgd_solver.cpp:106] Iteration 2289, lr = 0.005
I0403 03:01:23.571548 30256 solver.cpp:228] Iteration 2310, loss = 0.0487652
I0403 03:01:23.577522 30256 solver.cpp:244]     Train net output #0: loss = 0.048765 (* 1 = 0.048765 loss)
I0403 03:01:23.749019 30256 sgd_solver.cpp:106] Iteration 2310, lr = 0.005
I0403 03:01:38.845340 30256 solver.cpp:228] Iteration 2331, loss = 0.01478
I0403 03:01:38.851915 30256 solver.cpp:244]     Train net output #0: loss = 0.0147799 (* 1 = 0.0147799 loss)
I0403 03:01:38.980185 30256 sgd_solver.cpp:106] Iteration 2331, lr = 0.005
I0403 03:01:54.095093 30256 solver.cpp:228] Iteration 2352, loss = 0.0086194
I0403 03:01:54.101689 30256 solver.cpp:244]     Train net output #0: loss = 0.00861929 (* 1 = 0.00861929 loss)
I0403 03:01:54.307526 30256 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 03:02:09.132076 30256 solver.cpp:228] Iteration 2373, loss = 0.00136817
I0403 03:02:09.138201 30256 solver.cpp:244]     Train net output #0: loss = 0.00136805 (* 1 = 0.00136805 loss)
I0403 03:02:09.325685 30256 sgd_solver.cpp:106] Iteration 2373, lr = 0.005
I0403 03:02:24.108405 30256 solver.cpp:228] Iteration 2394, loss = 0.0453295
I0403 03:02:24.113932 30256 solver.cpp:244]     Train net output #0: loss = 0.0453294 (* 1 = 0.0453294 loss)
I0403 03:02:24.318752 30256 sgd_solver.cpp:106] Iteration 2394, lr = 0.005
I0403 03:02:39.405792 30256 solver.cpp:228] Iteration 2415, loss = 0.00555443
I0403 03:02:39.412204 30256 solver.cpp:244]     Train net output #0: loss = 0.00555433 (* 1 = 0.00555433 loss)
I0403 03:02:39.601856 30256 sgd_solver.cpp:106] Iteration 2415, lr = 0.005
I0403 03:02:54.568482 30256 solver.cpp:228] Iteration 2436, loss = 0.00310946
I0403 03:02:54.573731 30256 solver.cpp:244]     Train net output #0: loss = 0.00310936 (* 1 = 0.00310936 loss)
I0403 03:02:54.839486 30256 sgd_solver.cpp:106] Iteration 2436, lr = 0.005
I0403 03:03:09.749908 30256 solver.cpp:228] Iteration 2457, loss = 0.00188389
I0403 03:03:09.755985 30256 solver.cpp:244]     Train net output #0: loss = 0.00188379 (* 1 = 0.00188379 loss)
I0403 03:03:09.923713 30256 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 03:03:24.778497 30256 solver.cpp:228] Iteration 2478, loss = 0.00673526
I0403 03:03:24.784354 30256 solver.cpp:244]     Train net output #0: loss = 0.00673515 (* 1 = 0.00673515 loss)
I0403 03:03:25.032100 30256 sgd_solver.cpp:106] Iteration 2478, lr = 0.005
I0403 03:03:40.026774 30256 solver.cpp:228] Iteration 2499, loss = 0.00605894
I0403 03:03:40.031632 30256 solver.cpp:244]     Train net output #0: loss = 0.00605883 (* 1 = 0.00605883 loss)
I0403 03:03:40.193030 30256 sgd_solver.cpp:106] Iteration 2499, lr = 0.005
I0403 03:03:55.369263 30256 solver.cpp:228] Iteration 2520, loss = 0.00759097
I0403 03:03:55.374919 30256 solver.cpp:244]     Train net output #0: loss = 0.00759085 (* 1 = 0.00759085 loss)
I0403 03:03:55.564214 30256 sgd_solver.cpp:106] Iteration 2520, lr = 0.005
I0403 03:04:10.550253 30256 solver.cpp:228] Iteration 2541, loss = 0.00152674
I0403 03:04:10.555559 30256 solver.cpp:244]     Train net output #0: loss = 0.00152662 (* 1 = 0.00152662 loss)
I0403 03:04:10.736719 30256 sgd_solver.cpp:106] Iteration 2541, lr = 0.005
I0403 03:04:25.588484 30256 solver.cpp:228] Iteration 2562, loss = 0.0167221
I0403 03:04:25.594535 30256 solver.cpp:244]     Train net output #0: loss = 0.016722 (* 1 = 0.016722 loss)
I0403 03:04:25.766201 30256 sgd_solver.cpp:106] Iteration 2562, lr = 0.005
I0403 03:04:40.580227 30256 solver.cpp:228] Iteration 2583, loss = 0.00790305
I0403 03:04:40.586977 30256 solver.cpp:244]     Train net output #0: loss = 0.00790294 (* 1 = 0.00790294 loss)
I0403 03:04:40.782425 30256 sgd_solver.cpp:106] Iteration 2583, lr = 0.005
I0403 03:04:55.931615 30256 solver.cpp:228] Iteration 2604, loss = 0.00502983
I0403 03:04:55.937958 30256 solver.cpp:244]     Train net output #0: loss = 0.00502972 (* 1 = 0.00502972 loss)
I0403 03:04:56.171380 30256 sgd_solver.cpp:106] Iteration 2604, lr = 0.005
I0403 03:05:08.521203 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_2622.caffemodel
I0403 03:05:11.378609 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_2622.solverstate
I0403 03:05:13.221804 30256 solver.cpp:337] Iteration 2622, Testing net (#0)
I0403 03:05:36.700330 30256 solver.cpp:404]     Test net output #0: accuracy = 0.986667
I0403 03:05:36.706837 30256 solver.cpp:404]     Test net output #1: loss = 0.0399334 (* 1 = 0.0399334 loss)
I0403 03:05:39.442379 30256 solver.cpp:228] Iteration 2625, loss = 0.0124796
I0403 03:05:39.447896 30256 solver.cpp:244]     Train net output #0: loss = 0.0124795 (* 1 = 0.0124795 loss)
I0403 03:05:39.612505 30256 sgd_solver.cpp:106] Iteration 2625, lr = 0.005
I0403 03:05:54.651401 30256 solver.cpp:228] Iteration 2646, loss = 0.0154592
I0403 03:05:54.657022 30256 solver.cpp:244]     Train net output #0: loss = 0.0154591 (* 1 = 0.0154591 loss)
I0403 03:05:54.834544 30256 sgd_solver.cpp:106] Iteration 2646, lr = 0.005
I0403 03:06:09.655974 30256 solver.cpp:228] Iteration 2667, loss = 0.026304
I0403 03:06:09.661809 30256 solver.cpp:244]     Train net output #0: loss = 0.0263039 (* 1 = 0.0263039 loss)
I0403 03:06:09.836549 30256 sgd_solver.cpp:106] Iteration 2667, lr = 0.005
I0403 03:06:24.879603 30256 solver.cpp:228] Iteration 2688, loss = 0.00258539
I0403 03:06:24.885514 30256 solver.cpp:244]     Train net output #0: loss = 0.00258529 (* 1 = 0.00258529 loss)
I0403 03:06:25.063902 30256 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 03:06:39.971076 30256 solver.cpp:228] Iteration 2709, loss = 0.000653267
I0403 03:06:39.976286 30256 solver.cpp:244]     Train net output #0: loss = 0.000653163 (* 1 = 0.000653163 loss)
I0403 03:06:40.174788 30256 sgd_solver.cpp:106] Iteration 2709, lr = 0.005
I0403 03:06:55.299577 30256 solver.cpp:228] Iteration 2730, loss = 0.000351813
I0403 03:06:55.306004 30256 solver.cpp:244]     Train net output #0: loss = 0.00035171 (* 1 = 0.00035171 loss)
I0403 03:06:55.471693 30256 sgd_solver.cpp:106] Iteration 2730, lr = 0.005
I0403 03:07:10.290635 30256 solver.cpp:228] Iteration 2751, loss = 0.0236445
I0403 03:07:10.297034 30256 solver.cpp:244]     Train net output #0: loss = 0.0236444 (* 1 = 0.0236444 loss)
I0403 03:07:10.470866 30256 sgd_solver.cpp:106] Iteration 2751, lr = 0.005
I0403 03:07:25.495247 30256 solver.cpp:228] Iteration 2772, loss = 0.0276122
I0403 03:07:25.501049 30256 solver.cpp:244]     Train net output #0: loss = 0.0276121 (* 1 = 0.0276121 loss)
I0403 03:07:25.664558 30256 sgd_solver.cpp:106] Iteration 2772, lr = 0.005
I0403 03:07:40.630614 30256 solver.cpp:228] Iteration 2793, loss = 0.00826011
I0403 03:07:40.637042 30256 solver.cpp:244]     Train net output #0: loss = 0.00826 (* 1 = 0.00826 loss)
I0403 03:07:40.814630 30256 sgd_solver.cpp:106] Iteration 2793, lr = 0.005
I0403 03:07:55.888005 30256 solver.cpp:228] Iteration 2814, loss = 0.00288661
I0403 03:07:55.895109 30256 solver.cpp:244]     Train net output #0: loss = 0.00288649 (* 1 = 0.00288649 loss)
I0403 03:07:56.080039 30256 sgd_solver.cpp:106] Iteration 2814, lr = 0.005
I0403 03:08:11.021299 30256 solver.cpp:228] Iteration 2835, loss = 0.00282823
I0403 03:08:11.027159 30256 solver.cpp:244]     Train net output #0: loss = 0.00282812 (* 1 = 0.00282812 loss)
I0403 03:08:11.251332 30256 sgd_solver.cpp:106] Iteration 2835, lr = 0.005
I0403 03:08:26.310530 30256 solver.cpp:228] Iteration 2856, loss = 0.0226146
I0403 03:08:26.316774 30256 solver.cpp:244]     Train net output #0: loss = 0.0226145 (* 1 = 0.0226145 loss)
I0403 03:08:26.475855 30256 sgd_solver.cpp:106] Iteration 2856, lr = 0.005
I0403 03:08:41.776484 30256 solver.cpp:228] Iteration 2877, loss = 0.00257256
I0403 03:08:41.782552 30256 solver.cpp:244]     Train net output #0: loss = 0.00257245 (* 1 = 0.00257245 loss)
I0403 03:08:41.984143 30256 sgd_solver.cpp:106] Iteration 2877, lr = 0.005
I0403 03:08:56.873117 30256 solver.cpp:228] Iteration 2898, loss = 0.0113584
I0403 03:08:56.878465 30256 solver.cpp:244]     Train net output #0: loss = 0.0113583 (* 1 = 0.0113583 loss)
I0403 03:08:57.035454 30256 sgd_solver.cpp:106] Iteration 2898, lr = 0.005
I0403 03:09:12.041594 30256 solver.cpp:228] Iteration 2919, loss = 0.0107831
I0403 03:09:12.046955 30256 solver.cpp:244]     Train net output #0: loss = 0.010783 (* 1 = 0.010783 loss)
I0403 03:09:12.228412 30256 sgd_solver.cpp:106] Iteration 2919, lr = 0.005
I0403 03:09:27.434563 30256 solver.cpp:228] Iteration 2940, loss = 0.014756
I0403 03:09:27.439568 30256 solver.cpp:244]     Train net output #0: loss = 0.0147559 (* 1 = 0.0147559 loss)
I0403 03:09:27.603330 30256 sgd_solver.cpp:106] Iteration 2940, lr = 0.005
I0403 03:09:42.532033 30256 solver.cpp:228] Iteration 2961, loss = 0.00375261
I0403 03:09:42.537909 30256 solver.cpp:244]     Train net output #0: loss = 0.00375249 (* 1 = 0.00375249 loss)
I0403 03:09:42.705001 30256 sgd_solver.cpp:106] Iteration 2961, lr = 0.005
I0403 03:09:57.683389 30256 solver.cpp:228] Iteration 2982, loss = 0.0119231
I0403 03:09:57.688992 30256 solver.cpp:244]     Train net output #0: loss = 0.0119229 (* 1 = 0.0119229 loss)
I0403 03:09:57.798996 30256 sgd_solver.cpp:106] Iteration 2982, lr = 0.005
I0403 03:10:13.057585 30256 solver.cpp:228] Iteration 3003, loss = 0.0468592
I0403 03:10:13.063563 30256 solver.cpp:244]     Train net output #0: loss = 0.0468591 (* 1 = 0.0468591 loss)
I0403 03:10:13.246512 30256 sgd_solver.cpp:106] Iteration 3003, lr = 0.005
I0403 03:10:28.258306 30256 solver.cpp:228] Iteration 3024, loss = 0.00105722
I0403 03:10:28.264104 30256 solver.cpp:244]     Train net output #0: loss = 0.00105711 (* 1 = 0.00105711 loss)
I0403 03:10:28.430939 30256 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 03:10:43.364575 30256 solver.cpp:228] Iteration 3045, loss = 0.0299819
I0403 03:10:43.374071 30256 solver.cpp:244]     Train net output #0: loss = 0.0299818 (* 1 = 0.0299818 loss)
I0403 03:10:43.582773 30256 sgd_solver.cpp:106] Iteration 3045, lr = 0.005
I0403 03:10:53.131001 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_3059.caffemodel
I0403 03:10:56.029495 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_3059.solverstate
I0403 03:10:57.951128 30256 solver.cpp:337] Iteration 3059, Testing net (#0)
I0403 03:11:21.425039 30256 solver.cpp:404]     Test net output #0: accuracy = 0.986857
I0403 03:11:21.432209 30256 solver.cpp:404]     Test net output #1: loss = 0.0437971 (* 1 = 0.0437971 loss)
I0403 03:11:26.977717 30256 solver.cpp:228] Iteration 3066, loss = 0.0221307
I0403 03:11:26.982928 30256 solver.cpp:244]     Train net output #0: loss = 0.0221306 (* 1 = 0.0221306 loss)
I0403 03:11:27.223727 30256 sgd_solver.cpp:106] Iteration 3066, lr = 0.005
I0403 03:11:42.050959 30256 solver.cpp:228] Iteration 3087, loss = 0.00258188
I0403 03:11:42.056164 30256 solver.cpp:244]     Train net output #0: loss = 0.00258178 (* 1 = 0.00258178 loss)
I0403 03:11:42.237340 30256 sgd_solver.cpp:106] Iteration 3087, lr = 0.005
I0403 03:11:57.050714 30256 solver.cpp:228] Iteration 3108, loss = 0.0245799
I0403 03:11:57.057435 30256 solver.cpp:244]     Train net output #0: loss = 0.0245798 (* 1 = 0.0245798 loss)
I0403 03:11:57.244663 30256 sgd_solver.cpp:106] Iteration 3108, lr = 0.005
I0403 03:12:12.200547 30256 solver.cpp:228] Iteration 3129, loss = 0.0731052
I0403 03:12:12.207492 30256 solver.cpp:244]     Train net output #0: loss = 0.0731051 (* 1 = 0.0731051 loss)
I0403 03:12:12.385820 30256 sgd_solver.cpp:106] Iteration 3129, lr = 0.005
I0403 03:12:27.314796 30256 solver.cpp:228] Iteration 3150, loss = 0.0550062
I0403 03:12:27.321473 30256 solver.cpp:244]     Train net output #0: loss = 0.0550061 (* 1 = 0.0550061 loss)
I0403 03:12:27.517559 30256 sgd_solver.cpp:106] Iteration 3150, lr = 0.005
I0403 03:12:42.490499 30256 solver.cpp:228] Iteration 3171, loss = 0.0126428
I0403 03:12:42.496150 30256 solver.cpp:244]     Train net output #0: loss = 0.0126427 (* 1 = 0.0126427 loss)
I0403 03:12:42.666880 30256 sgd_solver.cpp:106] Iteration 3171, lr = 0.005
I0403 03:12:57.629258 30256 solver.cpp:228] Iteration 3192, loss = 0.00665708
I0403 03:12:57.635682 30256 solver.cpp:244]     Train net output #0: loss = 0.00665699 (* 1 = 0.00665699 loss)
I0403 03:12:57.843564 30256 sgd_solver.cpp:106] Iteration 3192, lr = 0.005
I0403 03:13:12.721233 30256 solver.cpp:228] Iteration 3213, loss = 0.00230664
I0403 03:13:12.726500 30256 solver.cpp:244]     Train net output #0: loss = 0.00230655 (* 1 = 0.00230655 loss)
I0403 03:13:12.913746 30256 sgd_solver.cpp:106] Iteration 3213, lr = 0.005
I0403 03:13:27.749706 30256 solver.cpp:228] Iteration 3234, loss = 0.000481257
I0403 03:13:27.755312 30256 solver.cpp:244]     Train net output #0: loss = 0.000481169 (* 1 = 0.000481169 loss)
I0403 03:13:27.943461 30256 sgd_solver.cpp:106] Iteration 3234, lr = 0.005
I0403 03:13:42.904456 30256 solver.cpp:228] Iteration 3255, loss = 0.0517715
I0403 03:13:42.909464 30256 solver.cpp:244]     Train net output #0: loss = 0.0517714 (* 1 = 0.0517714 loss)
I0403 03:13:43.102370 30256 sgd_solver.cpp:106] Iteration 3255, lr = 0.005
I0403 03:13:58.088889 30256 solver.cpp:228] Iteration 3276, loss = 0.00646566
I0403 03:13:58.094060 30256 solver.cpp:244]     Train net output #0: loss = 0.00646557 (* 1 = 0.00646557 loss)
I0403 03:13:58.267107 30256 sgd_solver.cpp:106] Iteration 3276, lr = 0.005
I0403 03:14:13.340425 30256 solver.cpp:228] Iteration 3297, loss = 0.00178079
I0403 03:14:13.345916 30256 solver.cpp:244]     Train net output #0: loss = 0.0017807 (* 1 = 0.0017807 loss)
I0403 03:14:13.490311 30256 sgd_solver.cpp:106] Iteration 3297, lr = 0.005
I0403 03:14:28.545999 30256 solver.cpp:228] Iteration 3318, loss = 0.0451861
I0403 03:14:28.551911 30256 solver.cpp:244]     Train net output #0: loss = 0.045186 (* 1 = 0.045186 loss)
I0403 03:14:28.724220 30256 sgd_solver.cpp:106] Iteration 3318, lr = 0.005
I0403 03:14:43.777961 30256 solver.cpp:228] Iteration 3339, loss = 0.00969367
I0403 03:14:43.784008 30256 solver.cpp:244]     Train net output #0: loss = 0.00969359 (* 1 = 0.00969359 loss)
I0403 03:14:43.973851 30256 sgd_solver.cpp:106] Iteration 3339, lr = 0.005
I0403 03:14:58.918274 30256 solver.cpp:228] Iteration 3360, loss = 0.00903721
I0403 03:14:58.924912 30256 solver.cpp:244]     Train net output #0: loss = 0.00903712 (* 1 = 0.00903712 loss)
I0403 03:14:59.095497 30256 sgd_solver.cpp:106] Iteration 3360, lr = 0.005
I0403 03:15:14.105494 30256 solver.cpp:228] Iteration 3381, loss = 0.00633741
I0403 03:15:14.111059 30256 solver.cpp:244]     Train net output #0: loss = 0.00633733 (* 1 = 0.00633733 loss)
I0403 03:15:14.280356 30256 sgd_solver.cpp:106] Iteration 3381, lr = 0.005
I0403 03:15:29.225692 30256 solver.cpp:228] Iteration 3402, loss = 0.00978887
I0403 03:15:29.231147 30256 solver.cpp:244]     Train net output #0: loss = 0.00978879 (* 1 = 0.00978879 loss)
I0403 03:15:29.388144 30256 sgd_solver.cpp:106] Iteration 3402, lr = 0.005
I0403 03:15:44.430147 30256 solver.cpp:228] Iteration 3423, loss = 0.0146343
I0403 03:15:44.435920 30256 solver.cpp:244]     Train net output #0: loss = 0.0146342 (* 1 = 0.0146342 loss)
I0403 03:15:44.614091 30256 sgd_solver.cpp:106] Iteration 3423, lr = 0.005
I0403 03:15:59.565404 30256 solver.cpp:228] Iteration 3444, loss = 0.0034097
I0403 03:15:59.571625 30256 solver.cpp:244]     Train net output #0: loss = 0.00340962 (* 1 = 0.00340962 loss)
I0403 03:15:59.716509 30256 sgd_solver.cpp:106] Iteration 3444, lr = 0.005
I0403 03:16:14.864989 30256 solver.cpp:228] Iteration 3465, loss = 0.00312267
I0403 03:16:14.870060 30256 solver.cpp:244]     Train net output #0: loss = 0.00312259 (* 1 = 0.00312259 loss)
I0403 03:16:15.045799 30256 sgd_solver.cpp:106] Iteration 3465, lr = 0.005
I0403 03:16:30.134255 30256 solver.cpp:228] Iteration 3486, loss = 0.00132463
I0403 03:16:30.142248 30256 solver.cpp:244]     Train net output #0: loss = 0.00132455 (* 1 = 0.00132455 loss)
I0403 03:16:30.301543 30256 sgd_solver.cpp:106] Iteration 3486, lr = 0.005
I0403 03:16:36.791110 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_3496.caffemodel
I0403 03:16:39.523355 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_3496.solverstate
I0403 03:16:41.404007 30256 solver.cpp:337] Iteration 3496, Testing net (#0)
I0403 03:17:04.866401 30256 solver.cpp:404]     Test net output #0: accuracy = 0.986857
I0403 03:17:04.873648 30256 solver.cpp:404]     Test net output #1: loss = 0.0467984 (* 1 = 0.0467984 loss)
I0403 03:17:13.500917 30256 solver.cpp:228] Iteration 3507, loss = 0.000596709
I0403 03:17:13.506813 30256 solver.cpp:244]     Train net output #0: loss = 0.000596624 (* 1 = 0.000596624 loss)
I0403 03:17:13.677501 30256 sgd_solver.cpp:106] Iteration 3507, lr = 0.005
I0403 03:17:28.752441 30256 solver.cpp:228] Iteration 3528, loss = 0.00103729
I0403 03:17:28.758221 30256 solver.cpp:244]     Train net output #0: loss = 0.0010372 (* 1 = 0.0010372 loss)
I0403 03:17:28.941334 30256 sgd_solver.cpp:106] Iteration 3528, lr = 0.005
I0403 03:17:43.963284 30256 solver.cpp:228] Iteration 3549, loss = 0.00257641
I0403 03:17:43.969743 30256 solver.cpp:244]     Train net output #0: loss = 0.00257633 (* 1 = 0.00257633 loss)
I0403 03:17:44.114786 30256 sgd_solver.cpp:106] Iteration 3549, lr = 0.005
I0403 03:17:59.212586 30256 solver.cpp:228] Iteration 3570, loss = 0.0287741
I0403 03:17:59.218508 30256 solver.cpp:244]     Train net output #0: loss = 0.028774 (* 1 = 0.028774 loss)
I0403 03:17:59.370435 30256 sgd_solver.cpp:106] Iteration 3570, lr = 0.005
I0403 03:18:14.439000 30256 solver.cpp:228] Iteration 3591, loss = 0.0099731
I0403 03:18:14.444766 30256 solver.cpp:244]     Train net output #0: loss = 0.00997302 (* 1 = 0.00997302 loss)
I0403 03:18:14.631088 30256 sgd_solver.cpp:106] Iteration 3591, lr = 0.005
I0403 03:18:29.637186 30256 solver.cpp:228] Iteration 3612, loss = 0.00123942
I0403 03:18:29.643527 30256 solver.cpp:244]     Train net output #0: loss = 0.00123934 (* 1 = 0.00123934 loss)
I0403 03:18:29.795017 30256 sgd_solver.cpp:106] Iteration 3612, lr = 0.005
I0403 03:18:44.790328 30256 solver.cpp:228] Iteration 3633, loss = 0.0124027
I0403 03:18:44.795994 30256 solver.cpp:244]     Train net output #0: loss = 0.0124026 (* 1 = 0.0124026 loss)
I0403 03:18:44.984849 30256 sgd_solver.cpp:106] Iteration 3633, lr = 0.005
I0403 03:18:59.889886 30256 solver.cpp:228] Iteration 3654, loss = 0.00239222
I0403 03:18:59.895263 30256 solver.cpp:244]     Train net output #0: loss = 0.00239213 (* 1 = 0.00239213 loss)
I0403 03:19:00.103561 30256 sgd_solver.cpp:106] Iteration 3654, lr = 0.005
I0403 03:19:14.937924 30256 solver.cpp:228] Iteration 3675, loss = 0.0104357
I0403 03:19:14.942873 30256 solver.cpp:244]     Train net output #0: loss = 0.0104356 (* 1 = 0.0104356 loss)
I0403 03:19:15.185307 30256 sgd_solver.cpp:106] Iteration 3675, lr = 0.005
I0403 03:19:30.106636 30256 solver.cpp:228] Iteration 3696, loss = 0.00223839
I0403 03:19:30.168627 30256 solver.cpp:244]     Train net output #0: loss = 0.0022383 (* 1 = 0.0022383 loss)
I0403 03:19:30.283643 30256 sgd_solver.cpp:106] Iteration 3696, lr = 0.005
I0403 03:19:45.530043 30256 solver.cpp:228] Iteration 3717, loss = 0.0124553
I0403 03:19:45.535665 30256 solver.cpp:244]     Train net output #0: loss = 0.0124552 (* 1 = 0.0124552 loss)
I0403 03:19:45.716810 30256 sgd_solver.cpp:106] Iteration 3717, lr = 0.005
I0403 03:20:00.644068 30256 solver.cpp:228] Iteration 3738, loss = 0.00449926
I0403 03:20:00.650602 30256 solver.cpp:244]     Train net output #0: loss = 0.00449917 (* 1 = 0.00449917 loss)
I0403 03:20:00.800889 30256 sgd_solver.cpp:106] Iteration 3738, lr = 0.005
I0403 03:20:15.985329 30256 solver.cpp:228] Iteration 3759, loss = 0.00500024
I0403 03:20:15.991348 30256 solver.cpp:244]     Train net output #0: loss = 0.00500014 (* 1 = 0.00500014 loss)
I0403 03:20:16.163911 30256 sgd_solver.cpp:106] Iteration 3759, lr = 0.005
I0403 03:20:31.063488 30256 solver.cpp:228] Iteration 3780, loss = 0.00376058
I0403 03:20:31.068016 30256 solver.cpp:244]     Train net output #0: loss = 0.00376049 (* 1 = 0.00376049 loss)
I0403 03:20:31.232470 30256 sgd_solver.cpp:106] Iteration 3780, lr = 0.005
I0403 03:20:46.236258 30256 solver.cpp:228] Iteration 3801, loss = 0.000186296
I0403 03:20:46.241731 30256 solver.cpp:244]     Train net output #0: loss = 0.000186203 (* 1 = 0.000186203 loss)
I0403 03:20:46.435639 30256 sgd_solver.cpp:106] Iteration 3801, lr = 0.005
I0403 03:21:01.368505 30256 solver.cpp:228] Iteration 3822, loss = 0.00210951
I0403 03:21:01.374606 30256 solver.cpp:244]     Train net output #0: loss = 0.00210941 (* 1 = 0.00210941 loss)
I0403 03:21:01.548197 30256 sgd_solver.cpp:106] Iteration 3822, lr = 0.005
I0403 03:21:16.449862 30256 solver.cpp:228] Iteration 3843, loss = 0.000803713
I0403 03:21:16.456135 30256 solver.cpp:244]     Train net output #0: loss = 0.000803621 (* 1 = 0.000803621 loss)
I0403 03:21:16.639333 30256 sgd_solver.cpp:106] Iteration 3843, lr = 0.005
I0403 03:21:31.880686 30256 solver.cpp:228] Iteration 3864, loss = 0.00688952
I0403 03:21:31.886615 30256 solver.cpp:244]     Train net output #0: loss = 0.00688942 (* 1 = 0.00688942 loss)
I0403 03:21:32.068924 30256 sgd_solver.cpp:106] Iteration 3864, lr = 0.005
I0403 03:21:47.098906 30256 solver.cpp:228] Iteration 3885, loss = 0.000261078
I0403 03:21:47.104101 30256 solver.cpp:244]     Train net output #0: loss = 0.000260985 (* 1 = 0.000260985 loss)
I0403 03:21:47.297772 30256 sgd_solver.cpp:106] Iteration 3885, lr = 0.005
I0403 03:22:02.230267 30256 solver.cpp:228] Iteration 3906, loss = 0.00272384
I0403 03:22:02.235646 30256 solver.cpp:244]     Train net output #0: loss = 0.00272375 (* 1 = 0.00272375 loss)
I0403 03:22:02.415941 30256 sgd_solver.cpp:106] Iteration 3906, lr = 0.005
I0403 03:22:17.606427 30256 solver.cpp:228] Iteration 3927, loss = 0.00343423
I0403 03:22:17.613188 30256 solver.cpp:244]     Train net output #0: loss = 0.00343414 (* 1 = 0.00343414 loss)
I0403 03:22:17.816486 30256 sgd_solver.cpp:106] Iteration 3927, lr = 0.005
I0403 03:22:21.386955 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_3933.caffemodel
I0403 03:22:24.099448 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_3933.solverstate
I0403 03:22:25.990351 30256 solver.cpp:337] Iteration 3933, Testing net (#0)
I0403 03:22:49.457947 30256 solver.cpp:404]     Test net output #0: accuracy = 0.987524
I0403 03:22:49.465807 30256 solver.cpp:404]     Test net output #1: loss = 0.0413436 (* 1 = 0.0413436 loss)
I0403 03:23:00.808821 30256 solver.cpp:228] Iteration 3948, loss = 0.000261504
I0403 03:23:00.815135 30256 solver.cpp:244]     Train net output #0: loss = 0.000261408 (* 1 = 0.000261408 loss)
I0403 03:23:01.065155 30256 sgd_solver.cpp:106] Iteration 3948, lr = 0.005
I0403 03:23:15.939270 30256 solver.cpp:228] Iteration 3969, loss = 0.00147964
I0403 03:23:15.945631 30256 solver.cpp:244]     Train net output #0: loss = 0.00147954 (* 1 = 0.00147954 loss)
I0403 03:23:16.126971 30256 sgd_solver.cpp:106] Iteration 3969, lr = 0.005
I0403 03:23:31.117723 30256 solver.cpp:228] Iteration 3990, loss = 0.0431126
I0403 03:23:31.123903 30256 solver.cpp:244]     Train net output #0: loss = 0.0431125 (* 1 = 0.0431125 loss)
I0403 03:23:31.295564 30256 sgd_solver.cpp:106] Iteration 3990, lr = 0.005
I0403 03:23:46.325513 30256 solver.cpp:228] Iteration 4011, loss = 0.0142078
I0403 03:23:46.330893 30256 solver.cpp:244]     Train net output #0: loss = 0.0142077 (* 1 = 0.0142077 loss)
I0403 03:23:46.485319 30256 sgd_solver.cpp:106] Iteration 4011, lr = 0.005
I0403 03:24:01.519059 30256 solver.cpp:228] Iteration 4032, loss = 0.00157687
I0403 03:24:01.524857 30256 solver.cpp:244]     Train net output #0: loss = 0.00157678 (* 1 = 0.00157678 loss)
I0403 03:24:01.679304 30256 sgd_solver.cpp:106] Iteration 4032, lr = 0.005
I0403 03:24:16.584827 30256 solver.cpp:228] Iteration 4053, loss = 0.00980273
I0403 03:24:16.591295 30256 solver.cpp:244]     Train net output #0: loss = 0.00980263 (* 1 = 0.00980263 loss)
I0403 03:24:16.764519 30256 sgd_solver.cpp:106] Iteration 4053, lr = 0.005
I0403 03:24:31.708006 30256 solver.cpp:228] Iteration 4074, loss = 0.00414793
I0403 03:24:31.712944 30256 solver.cpp:244]     Train net output #0: loss = 0.00414783 (* 1 = 0.00414783 loss)
I0403 03:24:31.865733 30256 sgd_solver.cpp:106] Iteration 4074, lr = 0.005
I0403 03:24:46.920197 30256 solver.cpp:228] Iteration 4095, loss = 0.0106126
I0403 03:24:46.925493 30256 solver.cpp:244]     Train net output #0: loss = 0.0106125 (* 1 = 0.0106125 loss)
I0403 03:24:47.082871 30256 sgd_solver.cpp:106] Iteration 4095, lr = 0.005
I0403 03:25:02.257755 30256 solver.cpp:228] Iteration 4116, loss = 0.0132552
I0403 03:25:02.263137 30256 solver.cpp:244]     Train net output #0: loss = 0.0132551 (* 1 = 0.0132551 loss)
I0403 03:25:02.434906 30256 sgd_solver.cpp:106] Iteration 4116, lr = 0.005
I0403 03:25:17.445837 30256 solver.cpp:228] Iteration 4137, loss = 0.00403055
I0403 03:25:17.465744 30256 solver.cpp:244]     Train net output #0: loss = 0.00403045 (* 1 = 0.00403045 loss)
I0403 03:25:17.625550 30256 sgd_solver.cpp:106] Iteration 4137, lr = 0.005
I0403 03:25:32.623422 30256 solver.cpp:228] Iteration 4158, loss = 0.00337203
I0403 03:25:32.630355 30256 solver.cpp:244]     Train net output #0: loss = 0.00337193 (* 1 = 0.00337193 loss)
I0403 03:25:32.807813 30256 sgd_solver.cpp:106] Iteration 4158, lr = 0.005
I0403 03:25:47.682533 30256 solver.cpp:228] Iteration 4179, loss = 0.00832321
I0403 03:25:47.689170 30256 solver.cpp:244]     Train net output #0: loss = 0.00832311 (* 1 = 0.00832311 loss)
I0403 03:25:47.861366 30256 sgd_solver.cpp:106] Iteration 4179, lr = 0.005
I0403 03:26:02.850826 30256 solver.cpp:228] Iteration 4200, loss = 0.000659385
I0403 03:26:02.856070 30256 solver.cpp:244]     Train net output #0: loss = 0.000659286 (* 1 = 0.000659286 loss)
I0403 03:26:03.027907 30256 sgd_solver.cpp:106] Iteration 4200, lr = 0.005
I0403 03:26:18.053714 30256 solver.cpp:228] Iteration 4221, loss = 0.00163758
I0403 03:26:18.059448 30256 solver.cpp:244]     Train net output #0: loss = 0.00163748 (* 1 = 0.00163748 loss)
I0403 03:26:18.203232 30256 sgd_solver.cpp:106] Iteration 4221, lr = 0.005
I0403 03:26:33.218204 30256 solver.cpp:228] Iteration 4242, loss = 0.000375996
I0403 03:26:33.224303 30256 solver.cpp:244]     Train net output #0: loss = 0.000375896 (* 1 = 0.000375896 loss)
I0403 03:26:33.394346 30256 sgd_solver.cpp:106] Iteration 4242, lr = 0.005
I0403 03:26:48.241389 30256 solver.cpp:228] Iteration 4263, loss = 0.00161948
I0403 03:26:48.248957 30256 solver.cpp:244]     Train net output #0: loss = 0.00161938 (* 1 = 0.00161938 loss)
I0403 03:26:48.422008 30256 sgd_solver.cpp:106] Iteration 4263, lr = 0.005
I0403 03:27:03.355486 30256 solver.cpp:228] Iteration 4284, loss = 0.000483282
I0403 03:27:03.361901 30256 solver.cpp:244]     Train net output #0: loss = 0.000483178 (* 1 = 0.000483178 loss)
I0403 03:27:03.562387 30256 sgd_solver.cpp:106] Iteration 4284, lr = 0.005
I0403 03:27:18.545949 30256 solver.cpp:228] Iteration 4305, loss = 0.000781578
I0403 03:27:18.551901 30256 solver.cpp:244]     Train net output #0: loss = 0.000781474 (* 1 = 0.000781474 loss)
I0403 03:27:18.716388 30256 sgd_solver.cpp:106] Iteration 4305, lr = 0.005
I0403 03:27:33.827231 30256 solver.cpp:228] Iteration 4326, loss = 0.00587822
I0403 03:27:33.835043 30256 solver.cpp:244]     Train net output #0: loss = 0.00587812 (* 1 = 0.00587812 loss)
I0403 03:27:33.995844 30256 sgd_solver.cpp:106] Iteration 4326, lr = 0.005
I0403 03:27:49.128648 30256 solver.cpp:228] Iteration 4347, loss = 0.0041346
I0403 03:27:49.136402 30256 solver.cpp:244]     Train net output #0: loss = 0.0041345 (* 1 = 0.0041345 loss)
I0403 03:27:49.314862 30256 sgd_solver.cpp:106] Iteration 4347, lr = 0.005
I0403 03:28:04.395910 30256 solver.cpp:228] Iteration 4368, loss = 0.000286273
I0403 03:28:04.402691 30256 solver.cpp:244]     Train net output #0: loss = 0.000286167 (* 1 = 0.000286167 loss)
I0403 03:28:04.533054 30256 sgd_solver.cpp:106] Iteration 4368, lr = 0.005
I0403 03:28:05.353556 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_4370.caffemodel
I0403 03:28:08.157551 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_4370.solverstate
I0403 03:28:10.076803 30256 solver.cpp:337] Iteration 4370, Testing net (#0)
I0403 03:28:33.548775 30256 solver.cpp:404]     Test net output #0: accuracy = 0.988
I0403 03:28:33.555881 30256 solver.cpp:404]     Test net output #1: loss = 0.0433665 (* 1 = 0.0433665 loss)
I0403 03:28:47.784876 30256 solver.cpp:228] Iteration 4389, loss = 0.00689084
I0403 03:28:47.790899 30256 solver.cpp:244]     Train net output #0: loss = 0.00689073 (* 1 = 0.00689073 loss)
I0403 03:28:47.970433 30256 sgd_solver.cpp:106] Iteration 4389, lr = 0.0005
I0403 03:29:02.834455 30256 solver.cpp:228] Iteration 4410, loss = 0.0166048
I0403 03:29:02.840323 30256 solver.cpp:244]     Train net output #0: loss = 0.0166047 (* 1 = 0.0166047 loss)
I0403 03:29:03.061707 30256 sgd_solver.cpp:106] Iteration 4410, lr = 0.0005
I0403 03:29:18.198012 30256 solver.cpp:228] Iteration 4431, loss = 0.000358647
I0403 03:29:18.204030 30256 solver.cpp:244]     Train net output #0: loss = 0.000358532 (* 1 = 0.000358532 loss)
I0403 03:29:18.380573 30256 sgd_solver.cpp:106] Iteration 4431, lr = 0.0005
I0403 03:29:33.251387 30256 solver.cpp:228] Iteration 4452, loss = 0.0259203
I0403 03:29:33.257834 30256 solver.cpp:244]     Train net output #0: loss = 0.0259201 (* 1 = 0.0259201 loss)
I0403 03:29:33.426167 30256 sgd_solver.cpp:106] Iteration 4452, lr = 0.0005
I0403 03:29:48.276052 30256 solver.cpp:228] Iteration 4473, loss = 0.00222955
I0403 03:29:48.280645 30256 solver.cpp:244]     Train net output #0: loss = 0.00222943 (* 1 = 0.00222943 loss)
I0403 03:29:48.454916 30256 sgd_solver.cpp:106] Iteration 4473, lr = 0.0005
I0403 03:30:03.590566 30256 solver.cpp:228] Iteration 4494, loss = 0.000957454
I0403 03:30:03.596006 30256 solver.cpp:244]     Train net output #0: loss = 0.000957339 (* 1 = 0.000957339 loss)
I0403 03:30:03.768136 30256 sgd_solver.cpp:106] Iteration 4494, lr = 0.0005
I0403 03:30:18.715273 30256 solver.cpp:228] Iteration 4515, loss = 0.000433017
I0403 03:30:18.721475 30256 solver.cpp:244]     Train net output #0: loss = 0.000432902 (* 1 = 0.000432902 loss)
I0403 03:30:18.905793 30256 sgd_solver.cpp:106] Iteration 4515, lr = 0.0005
I0403 03:30:33.829823 30256 solver.cpp:228] Iteration 4536, loss = 0.00109388
I0403 03:30:33.836119 30256 solver.cpp:244]     Train net output #0: loss = 0.00109376 (* 1 = 0.00109376 loss)
I0403 03:30:34.019480 30256 sgd_solver.cpp:106] Iteration 4536, lr = 0.0005
I0403 03:30:49.028962 30256 solver.cpp:228] Iteration 4557, loss = 0.000696494
I0403 03:30:49.035176 30256 solver.cpp:244]     Train net output #0: loss = 0.000696378 (* 1 = 0.000696378 loss)
I0403 03:30:49.199226 30256 sgd_solver.cpp:106] Iteration 4557, lr = 0.0005
I0403 03:31:04.320091 30256 solver.cpp:228] Iteration 4578, loss = 0.000823268
I0403 03:31:04.326117 30256 solver.cpp:244]     Train net output #0: loss = 0.000823153 (* 1 = 0.000823153 loss)
I0403 03:31:04.499330 30256 sgd_solver.cpp:106] Iteration 4578, lr = 0.0005
I0403 03:31:19.366539 30256 solver.cpp:228] Iteration 4599, loss = 0.000170787
I0403 03:31:19.373232 30256 solver.cpp:244]     Train net output #0: loss = 0.000170672 (* 1 = 0.000170672 loss)
I0403 03:31:19.567363 30256 sgd_solver.cpp:106] Iteration 4599, lr = 0.0005
I0403 03:31:34.642597 30256 solver.cpp:228] Iteration 4620, loss = 0.00140891
I0403 03:31:34.647580 30256 solver.cpp:244]     Train net output #0: loss = 0.00140879 (* 1 = 0.00140879 loss)
I0403 03:31:34.827370 30256 sgd_solver.cpp:106] Iteration 4620, lr = 0.0005
I0403 03:31:49.787972 30256 solver.cpp:228] Iteration 4641, loss = 0.000698673
I0403 03:31:49.793988 30256 solver.cpp:244]     Train net output #0: loss = 0.000698557 (* 1 = 0.000698557 loss)
I0403 03:31:50.022097 30256 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 03:32:05.019618 30256 solver.cpp:228] Iteration 4662, loss = 0.00476797
I0403 03:32:05.025967 30256 solver.cpp:244]     Train net output #0: loss = 0.00476785 (* 1 = 0.00476785 loss)
I0403 03:32:05.206459 30256 sgd_solver.cpp:106] Iteration 4662, lr = 0.0005
I0403 03:32:20.125619 30256 solver.cpp:228] Iteration 4683, loss = 0.00116118
I0403 03:32:20.131640 30256 solver.cpp:244]     Train net output #0: loss = 0.00116106 (* 1 = 0.00116106 loss)
I0403 03:32:20.308101 30256 sgd_solver.cpp:106] Iteration 4683, lr = 0.0005
I0403 03:32:35.194520 30256 solver.cpp:228] Iteration 4704, loss = 0.00118805
I0403 03:32:35.199687 30256 solver.cpp:244]     Train net output #0: loss = 0.00118793 (* 1 = 0.00118793 loss)
I0403 03:32:35.375200 30256 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 03:32:50.345427 30256 solver.cpp:228] Iteration 4725, loss = 0.00109374
I0403 03:32:50.352013 30256 solver.cpp:244]     Train net output #0: loss = 0.00109362 (* 1 = 0.00109362 loss)
I0403 03:32:50.563010 30256 sgd_solver.cpp:106] Iteration 4725, lr = 0.0005
I0403 03:33:05.454999 30256 solver.cpp:228] Iteration 4746, loss = 0.000245882
I0403 03:33:05.461215 30256 solver.cpp:244]     Train net output #0: loss = 0.000245767 (* 1 = 0.000245767 loss)
I0403 03:33:05.632930 30256 sgd_solver.cpp:106] Iteration 4746, lr = 0.0005
I0403 03:33:20.614233 30256 solver.cpp:228] Iteration 4767, loss = 0.011007
I0403 03:33:20.619915 30256 solver.cpp:244]     Train net output #0: loss = 0.0110069 (* 1 = 0.0110069 loss)
I0403 03:33:20.776890 30256 sgd_solver.cpp:106] Iteration 4767, lr = 0.0005
I0403 03:33:35.958164 30256 solver.cpp:228] Iteration 4788, loss = 0.000211219
I0403 03:33:35.964237 30256 solver.cpp:244]     Train net output #0: loss = 0.000211105 (* 1 = 0.000211105 loss)
I0403 03:33:36.126180 30256 sgd_solver.cpp:106] Iteration 4788, lr = 0.0005
I0403 03:33:49.355319 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_4807.caffemodel
I0403 03:33:52.146280 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_4807.solverstate
I0403 03:33:54.078492 30256 solver.cpp:337] Iteration 4807, Testing net (#0)
I0403 03:34:17.535341 30256 solver.cpp:404]     Test net output #0: accuracy = 0.991714
I0403 03:34:17.539858 30256 solver.cpp:404]     Test net output #1: loss = 0.0283002 (* 1 = 0.0283002 loss)
I0403 03:34:19.512774 30256 solver.cpp:228] Iteration 4809, loss = 0.000391527
I0403 03:34:19.512881 30256 solver.cpp:244]     Train net output #0: loss = 0.000391414 (* 1 = 0.000391414 loss)
I0403 03:34:19.695142 30256 sgd_solver.cpp:106] Iteration 4809, lr = 0.0005
I0403 03:34:34.671788 30256 solver.cpp:228] Iteration 4830, loss = 0.00144002
I0403 03:34:34.672101 30256 solver.cpp:244]     Train net output #0: loss = 0.00143991 (* 1 = 0.00143991 loss)
I0403 03:34:34.867048 30256 sgd_solver.cpp:106] Iteration 4830, lr = 0.0005
I0403 03:34:49.596948 30256 solver.cpp:228] Iteration 4851, loss = 0.00746048
I0403 03:34:49.597062 30256 solver.cpp:244]     Train net output #0: loss = 0.00746037 (* 1 = 0.00746037 loss)
I0403 03:34:49.850988 30256 sgd_solver.cpp:106] Iteration 4851, lr = 0.0005
I0403 03:35:04.755422 30256 solver.cpp:228] Iteration 4872, loss = 0.00187472
I0403 03:35:04.755735 30256 solver.cpp:244]     Train net output #0: loss = 0.00187461 (* 1 = 0.00187461 loss)
I0403 03:35:04.940603 30256 sgd_solver.cpp:106] Iteration 4872, lr = 0.0005
I0403 03:35:20.017899 30256 solver.cpp:228] Iteration 4893, loss = 0.0020674
I0403 03:35:20.018009 30256 solver.cpp:244]     Train net output #0: loss = 0.00206729 (* 1 = 0.00206729 loss)
I0403 03:35:20.206905 30256 sgd_solver.cpp:106] Iteration 4893, lr = 0.0005
I0403 03:35:35.083552 30256 solver.cpp:228] Iteration 4914, loss = 0.000765432
I0403 03:35:35.083801 30256 solver.cpp:244]     Train net output #0: loss = 0.000765319 (* 1 = 0.000765319 loss)
I0403 03:35:35.289702 30256 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 03:35:50.147198 30256 solver.cpp:228] Iteration 4935, loss = 0.00884726
I0403 03:35:50.147307 30256 solver.cpp:244]     Train net output #0: loss = 0.00884714 (* 1 = 0.00884714 loss)
I0403 03:35:50.334857 30256 sgd_solver.cpp:106] Iteration 4935, lr = 0.0005
I0403 03:36:05.207379 30256 solver.cpp:228] Iteration 4956, loss = 0.000224996
I0403 03:36:05.207628 30256 solver.cpp:244]     Train net output #0: loss = 0.000224883 (* 1 = 0.000224883 loss)
I0403 03:36:05.375000 30256 sgd_solver.cpp:106] Iteration 4956, lr = 0.0005
I0403 03:36:20.228191 30256 solver.cpp:228] Iteration 4977, loss = 0.000662724
I0403 03:36:20.228302 30256 solver.cpp:244]     Train net output #0: loss = 0.000662608 (* 1 = 0.000662608 loss)
I0403 03:36:20.417013 30256 sgd_solver.cpp:106] Iteration 4977, lr = 0.0005
I0403 03:36:35.503965 30256 solver.cpp:228] Iteration 4998, loss = 0.000204891
I0403 03:36:35.504210 30256 solver.cpp:244]     Train net output #0: loss = 0.000204774 (* 1 = 0.000204774 loss)
I0403 03:36:35.676928 30256 sgd_solver.cpp:106] Iteration 4998, lr = 0.0005
I0403 03:36:50.589668 30256 solver.cpp:228] Iteration 5019, loss = 0.000906972
I0403 03:36:50.589779 30256 solver.cpp:244]     Train net output #0: loss = 0.000906854 (* 1 = 0.000906854 loss)
I0403 03:36:50.771793 30256 sgd_solver.cpp:106] Iteration 5019, lr = 0.0005
I0403 03:37:05.759039 30256 solver.cpp:228] Iteration 5040, loss = 0.000119638
I0403 03:37:05.759352 30256 solver.cpp:244]     Train net output #0: loss = 0.000119518 (* 1 = 0.000119518 loss)
I0403 03:37:05.955785 30256 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 03:37:20.927417 30256 solver.cpp:228] Iteration 5061, loss = 0.000623079
I0403 03:37:20.927526 30256 solver.cpp:244]     Train net output #0: loss = 0.000622959 (* 1 = 0.000622959 loss)
I0403 03:37:21.107244 30256 sgd_solver.cpp:106] Iteration 5061, lr = 0.0005
I0403 03:37:36.341060 30256 solver.cpp:228] Iteration 5082, loss = 0.00128422
I0403 03:37:36.341410 30256 solver.cpp:244]     Train net output #0: loss = 0.0012841 (* 1 = 0.0012841 loss)
I0403 03:37:36.515059 30256 sgd_solver.cpp:106] Iteration 5082, lr = 0.0005
I0403 03:37:51.377848 30256 solver.cpp:228] Iteration 5103, loss = 0.000335979
I0403 03:37:51.377970 30256 solver.cpp:244]     Train net output #0: loss = 0.000335859 (* 1 = 0.000335859 loss)
I0403 03:37:51.585232 30256 sgd_solver.cpp:106] Iteration 5103, lr = 0.0005
I0403 03:38:06.469249 30256 solver.cpp:228] Iteration 5124, loss = 0.000126261
I0403 03:38:06.469552 30256 solver.cpp:244]     Train net output #0: loss = 0.000126139 (* 1 = 0.000126139 loss)
I0403 03:38:06.646822 30256 sgd_solver.cpp:106] Iteration 5124, lr = 0.0005
I0403 03:38:21.587688 30256 solver.cpp:228] Iteration 5145, loss = 0.000203514
I0403 03:38:21.587796 30256 solver.cpp:244]     Train net output #0: loss = 0.000203393 (* 1 = 0.000203393 loss)
I0403 03:38:21.767392 30256 sgd_solver.cpp:106] Iteration 5145, lr = 0.0005
I0403 03:38:36.636418 30256 solver.cpp:228] Iteration 5166, loss = 0.000399683
I0403 03:38:36.636711 30256 solver.cpp:244]     Train net output #0: loss = 0.000399554 (* 1 = 0.000399554 loss)
I0403 03:38:36.825140 30256 sgd_solver.cpp:106] Iteration 5166, lr = 0.0005
I0403 03:38:51.814970 30256 solver.cpp:228] Iteration 5187, loss = 0.00045755
I0403 03:38:51.815083 30256 solver.cpp:244]     Train net output #0: loss = 0.000457421 (* 1 = 0.000457421 loss)
I0403 03:38:52.001080 30256 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 03:39:07.009670 30256 solver.cpp:228] Iteration 5208, loss = 0.00190357
I0403 03:39:07.009943 30256 solver.cpp:244]     Train net output #0: loss = 0.00190344 (* 1 = 0.00190344 loss)
I0403 03:39:07.165122 30256 sgd_solver.cpp:106] Iteration 5208, lr = 0.0005
I0403 03:39:22.485483 30256 solver.cpp:228] Iteration 5229, loss = 0.00389461
I0403 03:39:22.485594 30256 solver.cpp:244]     Train net output #0: loss = 0.00389449 (* 1 = 0.00389449 loss)
I0403 03:39:22.675143 30256 sgd_solver.cpp:106] Iteration 5229, lr = 0.0005
I0403 03:39:32.823531 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_5244.caffemodel
I0403 03:39:35.610841 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_5244.solverstate
I0403 03:39:37.508781 30256 solver.cpp:337] Iteration 5244, Testing net (#0)
I0403 03:40:00.966150 30256 solver.cpp:404]     Test net output #0: accuracy = 0.991905
I0403 03:40:00.966254 30256 solver.cpp:404]     Test net output #1: loss = 0.0277448 (* 1 = 0.0277448 loss)
I0403 03:40:05.748004 30256 solver.cpp:228] Iteration 5250, loss = 0.000258016
I0403 03:40:05.748111 30256 solver.cpp:244]     Train net output #0: loss = 0.000257888 (* 1 = 0.000257888 loss)
I0403 03:40:05.970569 30256 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0403 03:40:20.993090 30256 solver.cpp:228] Iteration 5271, loss = 0.00128784
I0403 03:40:20.993391 30256 solver.cpp:244]     Train net output #0: loss = 0.00128771 (* 1 = 0.00128771 loss)
I0403 03:40:21.143802 30256 sgd_solver.cpp:106] Iteration 5271, lr = 0.0005
I0403 03:40:36.159065 30256 solver.cpp:228] Iteration 5292, loss = 0.000167779
I0403 03:40:36.159173 30256 solver.cpp:244]     Train net output #0: loss = 0.000167651 (* 1 = 0.000167651 loss)
I0403 03:40:36.346935 30256 sgd_solver.cpp:106] Iteration 5292, lr = 0.0005
I0403 03:40:51.341526 30256 solver.cpp:228] Iteration 5313, loss = 0.000773933
I0403 03:40:51.341836 30256 solver.cpp:244]     Train net output #0: loss = 0.000773805 (* 1 = 0.000773805 loss)
I0403 03:40:51.548779 30256 sgd_solver.cpp:106] Iteration 5313, lr = 0.0005
I0403 03:41:06.509487 30256 solver.cpp:228] Iteration 5334, loss = 0.00176838
I0403 03:41:06.509599 30256 solver.cpp:244]     Train net output #0: loss = 0.00176826 (* 1 = 0.00176826 loss)
I0403 03:41:06.697818 30256 sgd_solver.cpp:106] Iteration 5334, lr = 0.0005
I0403 03:41:21.760131 30256 solver.cpp:228] Iteration 5355, loss = 0.000190069
I0403 03:41:21.760445 30256 solver.cpp:244]     Train net output #0: loss = 0.000189941 (* 1 = 0.000189941 loss)
I0403 03:41:21.934885 30256 sgd_solver.cpp:106] Iteration 5355, lr = 0.0005
I0403 03:41:36.953158 30256 solver.cpp:228] Iteration 5376, loss = 0.000909613
I0403 03:41:36.953284 30256 solver.cpp:244]     Train net output #0: loss = 0.000909485 (* 1 = 0.000909485 loss)
I0403 03:41:37.175516 30256 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 03:41:52.165968 30256 solver.cpp:228] Iteration 5397, loss = 0.0034203
I0403 03:41:52.166268 30256 solver.cpp:244]     Train net output #0: loss = 0.00342017 (* 1 = 0.00342017 loss)
I0403 03:41:52.355738 30256 sgd_solver.cpp:106] Iteration 5397, lr = 0.0005
I0403 03:42:07.320943 30256 solver.cpp:228] Iteration 5418, loss = 0.000112954
I0403 03:42:07.321054 30256 solver.cpp:244]     Train net output #0: loss = 0.000112827 (* 1 = 0.000112827 loss)
I0403 03:42:07.518357 30256 sgd_solver.cpp:106] Iteration 5418, lr = 0.0005
I0403 03:42:22.662873 30256 solver.cpp:228] Iteration 5439, loss = 0.000123933
I0403 03:42:22.663188 30256 solver.cpp:244]     Train net output #0: loss = 0.000123805 (* 1 = 0.000123805 loss)
I0403 03:42:22.901604 30256 sgd_solver.cpp:106] Iteration 5439, lr = 0.0005
I0403 03:42:37.805578 30256 solver.cpp:228] Iteration 5460, loss = 0.000237058
I0403 03:42:37.805703 30256 solver.cpp:244]     Train net output #0: loss = 0.000236929 (* 1 = 0.000236929 loss)
I0403 03:42:37.997594 30256 sgd_solver.cpp:106] Iteration 5460, lr = 0.0005
I0403 03:42:52.822896 30256 solver.cpp:228] Iteration 5481, loss = 0.000599703
I0403 03:42:52.823287 30256 solver.cpp:244]     Train net output #0: loss = 0.000599574 (* 1 = 0.000599574 loss)
I0403 03:42:53.014375 30256 sgd_solver.cpp:106] Iteration 5481, lr = 0.0005
I0403 03:43:07.909554 30256 solver.cpp:228] Iteration 5502, loss = 0.000651742
I0403 03:43:07.909662 30256 solver.cpp:244]     Train net output #0: loss = 0.000651612 (* 1 = 0.000651612 loss)
I0403 03:43:08.097379 30256 sgd_solver.cpp:106] Iteration 5502, lr = 0.0005
I0403 03:43:23.127202 30256 solver.cpp:228] Iteration 5523, loss = 0.0014685
I0403 03:43:23.127523 30256 solver.cpp:244]     Train net output #0: loss = 0.00146837 (* 1 = 0.00146837 loss)
I0403 03:43:23.305184 30256 sgd_solver.cpp:106] Iteration 5523, lr = 0.0005
I0403 03:43:38.353085 30256 solver.cpp:228] Iteration 5544, loss = 0.00101239
I0403 03:43:38.353185 30256 solver.cpp:244]     Train net output #0: loss = 0.00101226 (* 1 = 0.00101226 loss)
I0403 03:43:38.505338 30256 sgd_solver.cpp:106] Iteration 5544, lr = 0.0005
I0403 03:43:53.605501 30256 solver.cpp:228] Iteration 5565, loss = 0.00505368
I0403 03:43:53.605805 30256 solver.cpp:244]     Train net output #0: loss = 0.00505355 (* 1 = 0.00505355 loss)
I0403 03:43:53.779456 30256 sgd_solver.cpp:106] Iteration 5565, lr = 0.0005
I0403 03:44:08.819454 30256 solver.cpp:228] Iteration 5586, loss = 0.00219535
I0403 03:44:08.819561 30256 solver.cpp:244]     Train net output #0: loss = 0.00219522 (* 1 = 0.00219522 loss)
I0403 03:44:09.000808 30256 sgd_solver.cpp:106] Iteration 5586, lr = 0.0005
I0403 03:44:24.007951 30256 solver.cpp:228] Iteration 5607, loss = 0.000480827
I0403 03:44:24.008273 30256 solver.cpp:244]     Train net output #0: loss = 0.000480699 (* 1 = 0.000480699 loss)
I0403 03:44:24.222136 30256 sgd_solver.cpp:106] Iteration 5607, lr = 0.0005
I0403 03:44:39.439523 30256 solver.cpp:228] Iteration 5628, loss = 0.00282782
I0403 03:44:39.439632 30256 solver.cpp:244]     Train net output #0: loss = 0.00282769 (* 1 = 0.00282769 loss)
I0403 03:44:39.671653 30256 sgd_solver.cpp:106] Iteration 5628, lr = 0.0005
I0403 03:44:54.977480 30256 solver.cpp:228] Iteration 5649, loss = 0.000897084
I0403 03:44:54.977768 30256 solver.cpp:244]     Train net output #0: loss = 0.000896953 (* 1 = 0.000896953 loss)
I0403 03:44:55.147505 30256 sgd_solver.cpp:106] Iteration 5649, lr = 0.0005
I0403 03:45:10.074934 30256 solver.cpp:228] Iteration 5670, loss = 0.0040389
I0403 03:45:10.079483 30256 solver.cpp:244]     Train net output #0: loss = 0.00403877 (* 1 = 0.00403877 loss)
I0403 03:45:10.275490 30256 sgd_solver.cpp:106] Iteration 5670, lr = 0.0005
I0403 03:45:17.423692 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_5681.caffemodel
I0403 03:45:20.159648 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_5681.solverstate
I0403 03:45:21.999266 30256 solver.cpp:337] Iteration 5681, Testing net (#0)
I0403 03:45:45.451553 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992095
I0403 03:45:45.451875 30256 solver.cpp:404]     Test net output #1: loss = 0.0276318 (* 1 = 0.0276318 loss)
I0403 03:45:53.115890 30256 solver.cpp:228] Iteration 5691, loss = 0.000456962
I0403 03:45:53.115998 30256 solver.cpp:244]     Train net output #0: loss = 0.000456831 (* 1 = 0.000456831 loss)
I0403 03:45:53.304203 30256 sgd_solver.cpp:106] Iteration 5691, lr = 0.0005
I0403 03:46:08.280223 30256 solver.cpp:228] Iteration 5712, loss = 0.00154242
I0403 03:46:08.280344 30256 solver.cpp:244]     Train net output #0: loss = 0.00154229 (* 1 = 0.00154229 loss)
I0403 03:46:08.511441 30256 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 03:46:23.503768 30256 solver.cpp:228] Iteration 5733, loss = 0.000317649
I0403 03:46:23.504089 30256 solver.cpp:244]     Train net output #0: loss = 0.000317518 (* 1 = 0.000317518 loss)
I0403 03:46:23.697185 30256 sgd_solver.cpp:106] Iteration 5733, lr = 0.0005
I0403 03:46:38.812906 30256 solver.cpp:228] Iteration 5754, loss = 0.00158233
I0403 03:46:38.813005 30256 solver.cpp:244]     Train net output #0: loss = 0.0015822 (* 1 = 0.0015822 loss)
I0403 03:46:38.986063 30256 sgd_solver.cpp:106] Iteration 5754, lr = 0.0005
I0403 03:46:53.924645 30256 solver.cpp:228] Iteration 5775, loss = 0.000982483
I0403 03:46:53.924947 30256 solver.cpp:244]     Train net output #0: loss = 0.000982353 (* 1 = 0.000982353 loss)
I0403 03:46:54.105207 30256 sgd_solver.cpp:106] Iteration 5775, lr = 0.0005
I0403 03:47:09.130584 30256 solver.cpp:228] Iteration 5796, loss = 0.000398028
I0403 03:47:09.130695 30256 solver.cpp:244]     Train net output #0: loss = 0.000397895 (* 1 = 0.000397895 loss)
I0403 03:47:09.319314 30256 sgd_solver.cpp:106] Iteration 5796, lr = 0.0005
I0403 03:47:24.326722 30256 solver.cpp:228] Iteration 5817, loss = 0.000941001
I0403 03:47:24.327016 30256 solver.cpp:244]     Train net output #0: loss = 0.000940869 (* 1 = 0.000940869 loss)
I0403 03:47:24.505780 30256 sgd_solver.cpp:106] Iteration 5817, lr = 0.0005
I0403 03:47:39.487543 30256 solver.cpp:228] Iteration 5838, loss = 0.000135964
I0403 03:47:39.487643 30256 solver.cpp:244]     Train net output #0: loss = 0.000135831 (* 1 = 0.000135831 loss)
I0403 03:47:39.655750 30256 sgd_solver.cpp:106] Iteration 5838, lr = 0.0005
I0403 03:47:54.640121 30256 solver.cpp:228] Iteration 5859, loss = 6.82899e-05
I0403 03:47:54.640629 30256 solver.cpp:244]     Train net output #0: loss = 6.81565e-05 (* 1 = 6.81565e-05 loss)
I0403 03:47:54.871037 30256 sgd_solver.cpp:106] Iteration 5859, lr = 0.0005
I0403 03:48:09.792938 30256 solver.cpp:228] Iteration 5880, loss = 0.000894258
I0403 03:48:09.793040 30256 solver.cpp:244]     Train net output #0: loss = 0.000894125 (* 1 = 0.000894125 loss)
I0403 03:48:09.969980 30256 sgd_solver.cpp:106] Iteration 5880, lr = 0.0005
I0403 03:48:24.846776 30256 solver.cpp:228] Iteration 5901, loss = 0.00229237
I0403 03:48:24.847079 30256 solver.cpp:244]     Train net output #0: loss = 0.00229223 (* 1 = 0.00229223 loss)
I0403 03:48:25.027465 30256 sgd_solver.cpp:106] Iteration 5901, lr = 0.0005
I0403 03:48:39.966265 30256 solver.cpp:228] Iteration 5922, loss = 6.72992e-05
I0403 03:48:39.966377 30256 solver.cpp:244]     Train net output #0: loss = 6.71671e-05 (* 1 = 6.71671e-05 loss)
I0403 03:48:40.116798 30256 sgd_solver.cpp:106] Iteration 5922, lr = 0.0005
I0403 03:48:55.104660 30256 solver.cpp:228] Iteration 5943, loss = 0.00100425
I0403 03:48:55.104996 30256 solver.cpp:244]     Train net output #0: loss = 0.00100412 (* 1 = 0.00100412 loss)
I0403 03:48:55.288239 30256 sgd_solver.cpp:106] Iteration 5943, lr = 0.0005
I0403 03:49:10.149348 30256 solver.cpp:228] Iteration 5964, loss = 0.000464656
I0403 03:49:10.160500 30256 solver.cpp:244]     Train net output #0: loss = 0.000464524 (* 1 = 0.000464524 loss)
I0403 03:49:10.300817 30256 sgd_solver.cpp:106] Iteration 5964, lr = 0.0005
I0403 03:49:25.341665 30256 solver.cpp:228] Iteration 5985, loss = 0.000356354
I0403 03:49:25.341982 30256 solver.cpp:244]     Train net output #0: loss = 0.000356222 (* 1 = 0.000356222 loss)
I0403 03:49:25.533979 30256 sgd_solver.cpp:106] Iteration 5985, lr = 0.0005
I0403 03:49:40.590082 30256 solver.cpp:228] Iteration 6006, loss = 0.000137465
I0403 03:49:40.590181 30256 solver.cpp:244]     Train net output #0: loss = 0.000137333 (* 1 = 0.000137333 loss)
I0403 03:49:40.767099 30256 sgd_solver.cpp:106] Iteration 6006, lr = 0.0005
I0403 03:49:55.679249 30256 solver.cpp:228] Iteration 6027, loss = 0.0013759
I0403 03:49:55.679563 30256 solver.cpp:244]     Train net output #0: loss = 0.00137576 (* 1 = 0.00137576 loss)
I0403 03:49:55.863680 30256 sgd_solver.cpp:106] Iteration 6027, lr = 0.0005
I0403 03:50:11.052597 30256 solver.cpp:228] Iteration 6048, loss = 0.00242187
I0403 03:50:11.052702 30256 solver.cpp:244]     Train net output #0: loss = 0.00242174 (* 1 = 0.00242174 loss)
I0403 03:50:11.208600 30256 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 03:50:26.142411 30256 solver.cpp:228] Iteration 6069, loss = 0.000175502
I0403 03:50:26.142709 30256 solver.cpp:244]     Train net output #0: loss = 0.000175369 (* 1 = 0.000175369 loss)
I0403 03:50:26.317144 30256 sgd_solver.cpp:106] Iteration 6069, lr = 0.0005
I0403 03:50:41.329475 30256 solver.cpp:228] Iteration 6090, loss = 0.000659785
I0403 03:50:41.329586 30256 solver.cpp:244]     Train net output #0: loss = 0.000659655 (* 1 = 0.000659655 loss)
I0403 03:50:41.511119 30256 sgd_solver.cpp:106] Iteration 6090, lr = 0.0005
I0403 03:50:56.322720 30256 solver.cpp:228] Iteration 6111, loss = 0.000210425
I0403 03:50:56.323036 30256 solver.cpp:244]     Train net output #0: loss = 0.000210295 (* 1 = 0.000210295 loss)
I0403 03:50:56.524549 30256 sgd_solver.cpp:106] Iteration 6111, lr = 0.0005
I0403 03:51:00.773968 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_6118.caffemodel
I0403 03:51:03.459347 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_6118.solverstate
I0403 03:51:05.257786 30256 solver.cpp:337] Iteration 6118, Testing net (#0)
I0403 03:51:28.728999 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992667
I0403 03:51:28.729348 30256 solver.cpp:404]     Test net output #1: loss = 0.0273585 (* 1 = 0.0273585 loss)
I0403 03:51:39.438477 30256 solver.cpp:228] Iteration 6132, loss = 0.000224812
I0403 03:51:39.438580 30256 solver.cpp:244]     Train net output #0: loss = 0.000224681 (* 1 = 0.000224681 loss)
I0403 03:51:39.597548 30256 sgd_solver.cpp:106] Iteration 6132, lr = 0.0005
I0403 03:51:54.628892 30256 solver.cpp:228] Iteration 6153, loss = 2.72931e-05
I0403 03:51:54.629007 30256 solver.cpp:244]     Train net output #0: loss = 2.71622e-05 (* 1 = 2.71622e-05 loss)
I0403 03:51:54.892882 30256 sgd_solver.cpp:106] Iteration 6153, lr = 0.0005
I0403 03:52:10.124716 30256 solver.cpp:228] Iteration 6174, loss = 0.000296106
I0403 03:52:10.125001 30256 solver.cpp:244]     Train net output #0: loss = 0.000295975 (* 1 = 0.000295975 loss)
I0403 03:52:10.302634 30256 sgd_solver.cpp:106] Iteration 6174, lr = 0.0005
I0403 03:52:25.459303 30256 solver.cpp:228] Iteration 6195, loss = 0.000296258
I0403 03:52:25.459405 30256 solver.cpp:244]     Train net output #0: loss = 0.000296127 (* 1 = 0.000296127 loss)
I0403 03:52:25.582095 30256 sgd_solver.cpp:106] Iteration 6195, lr = 0.0005
I0403 03:52:40.655849 30256 solver.cpp:228] Iteration 6216, loss = 4.04669e-05
I0403 03:52:40.656204 30256 solver.cpp:244]     Train net output #0: loss = 4.03368e-05 (* 1 = 4.03368e-05 loss)
I0403 03:52:40.844377 30256 sgd_solver.cpp:106] Iteration 6216, lr = 0.0005
I0403 03:52:55.767562 30256 solver.cpp:228] Iteration 6237, loss = 0.00160984
I0403 03:52:55.767662 30256 solver.cpp:244]     Train net output #0: loss = 0.00160971 (* 1 = 0.00160971 loss)
I0403 03:52:55.945626 30256 sgd_solver.cpp:106] Iteration 6237, lr = 0.0005
I0403 03:53:11.045089 30256 solver.cpp:228] Iteration 6258, loss = 0.000127986
I0403 03:53:11.045379 30256 solver.cpp:244]     Train net output #0: loss = 0.000127857 (* 1 = 0.000127857 loss)
I0403 03:53:11.224753 30256 sgd_solver.cpp:106] Iteration 6258, lr = 0.0005
I0403 03:53:26.321470 30256 solver.cpp:228] Iteration 6279, loss = 9.64329e-05
I0403 03:53:26.321584 30256 solver.cpp:244]     Train net output #0: loss = 9.63046e-05 (* 1 = 9.63046e-05 loss)
I0403 03:53:26.507457 30256 sgd_solver.cpp:106] Iteration 6279, lr = 0.0005
I0403 03:53:41.464884 30256 solver.cpp:228] Iteration 6300, loss = 0.00103313
I0403 03:53:41.465200 30256 solver.cpp:244]     Train net output #0: loss = 0.001033 (* 1 = 0.001033 loss)
I0403 03:53:41.658054 30256 sgd_solver.cpp:106] Iteration 6300, lr = 0.0005
I0403 03:53:56.686095 30256 solver.cpp:228] Iteration 6321, loss = 0.000185038
I0403 03:53:56.686194 30256 solver.cpp:244]     Train net output #0: loss = 0.00018491 (* 1 = 0.00018491 loss)
I0403 03:53:56.864969 30256 sgd_solver.cpp:106] Iteration 6321, lr = 0.0005
I0403 03:54:11.811463 30256 solver.cpp:228] Iteration 6342, loss = 0.000502558
I0403 03:54:11.811779 30256 solver.cpp:244]     Train net output #0: loss = 0.000502429 (* 1 = 0.000502429 loss)
I0403 03:54:12.026329 30256 sgd_solver.cpp:106] Iteration 6342, lr = 0.0005
I0403 03:54:27.059542 30256 solver.cpp:228] Iteration 6363, loss = 0.00071911
I0403 03:54:27.059661 30256 solver.cpp:244]     Train net output #0: loss = 0.000718982 (* 1 = 0.000718982 loss)
I0403 03:54:27.247180 30256 sgd_solver.cpp:106] Iteration 6363, lr = 0.0005
I0403 03:54:42.077620 30256 solver.cpp:228] Iteration 6384, loss = 0.000137464
I0403 03:54:42.077941 30256 solver.cpp:244]     Train net output #0: loss = 0.000137337 (* 1 = 0.000137337 loss)
I0403 03:54:42.270928 30256 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 03:54:57.339013 30256 solver.cpp:228] Iteration 6405, loss = 9.13147e-05
I0403 03:54:57.339113 30256 solver.cpp:244]     Train net output #0: loss = 9.11873e-05 (* 1 = 9.11873e-05 loss)
I0403 03:54:57.517259 30256 sgd_solver.cpp:106] Iteration 6405, lr = 0.0005
I0403 03:55:12.388669 30256 solver.cpp:228] Iteration 6426, loss = 0.000638139
I0403 03:55:12.396510 30256 solver.cpp:244]     Train net output #0: loss = 0.000638011 (* 1 = 0.000638011 loss)
I0403 03:55:12.621223 30256 sgd_solver.cpp:106] Iteration 6426, lr = 0.0005
I0403 03:55:27.598978 30256 solver.cpp:228] Iteration 6447, loss = 0.00064544
I0403 03:55:27.604997 30256 solver.cpp:244]     Train net output #0: loss = 0.000645313 (* 1 = 0.000645313 loss)
I0403 03:55:27.793345 30256 sgd_solver.cpp:106] Iteration 6447, lr = 0.0005
I0403 03:55:42.721815 30256 solver.cpp:228] Iteration 6468, loss = 8.02871e-05
I0403 03:55:42.727429 30256 solver.cpp:244]     Train net output #0: loss = 8.01598e-05 (* 1 = 8.01598e-05 loss)
I0403 03:55:42.907457 30256 sgd_solver.cpp:106] Iteration 6468, lr = 0.0005
I0403 03:55:57.877754 30256 solver.cpp:228] Iteration 6489, loss = 0.000308311
I0403 03:55:57.877864 30256 solver.cpp:244]     Train net output #0: loss = 0.000308184 (* 1 = 0.000308184 loss)
I0403 03:55:58.105988 30256 sgd_solver.cpp:106] Iteration 6489, lr = 0.0005
I0403 03:56:12.960068 30256 solver.cpp:228] Iteration 6510, loss = 0.000479742
I0403 03:56:12.960371 30256 solver.cpp:244]     Train net output #0: loss = 0.000479616 (* 1 = 0.000479616 loss)
I0403 03:56:13.160645 30256 sgd_solver.cpp:106] Iteration 6510, lr = 0.0005
I0403 03:56:28.170789 30256 solver.cpp:228] Iteration 6531, loss = 0.00410465
I0403 03:56:28.170892 30256 solver.cpp:244]     Train net output #0: loss = 0.00410452 (* 1 = 0.00410452 loss)
I0403 03:56:28.345453 30256 sgd_solver.cpp:106] Iteration 6531, lr = 0.0005
I0403 03:56:43.268554 30256 solver.cpp:228] Iteration 6552, loss = 0.000251932
I0403 03:56:43.268836 30256 solver.cpp:244]     Train net output #0: loss = 0.000251806 (* 1 = 0.000251806 loss)
I0403 03:56:43.450533 30256 sgd_solver.cpp:106] Iteration 6552, lr = 0.0005
I0403 03:56:44.864923 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_6555.caffemodel
I0403 03:56:47.639024 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_6555.solverstate
I0403 03:56:49.470090 30256 solver.cpp:337] Iteration 6555, Testing net (#0)
I0403 03:57:12.942608 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992286
I0403 03:57:12.942714 30256 solver.cpp:404]     Test net output #1: loss = 0.029176 (* 1 = 0.029176 loss)
I0403 03:57:26.401464 30256 solver.cpp:228] Iteration 6573, loss = 0.000818228
I0403 03:57:26.401765 30256 solver.cpp:244]     Train net output #0: loss = 0.000818102 (* 1 = 0.000818102 loss)
I0403 03:57:26.576892 30256 sgd_solver.cpp:106] Iteration 6573, lr = 0.0005
I0403 03:57:41.595129 30256 solver.cpp:228] Iteration 6594, loss = 0.000696404
I0403 03:57:41.595243 30256 solver.cpp:244]     Train net output #0: loss = 0.000696277 (* 1 = 0.000696277 loss)
I0403 03:57:41.792377 30256 sgd_solver.cpp:106] Iteration 6594, lr = 0.0005
I0403 03:57:56.746606 30256 solver.cpp:228] Iteration 6615, loss = 0.000124387
I0403 03:57:56.746915 30256 solver.cpp:244]     Train net output #0: loss = 0.000124261 (* 1 = 0.000124261 loss)
I0403 03:57:56.934505 30256 sgd_solver.cpp:106] Iteration 6615, lr = 0.0005
I0403 03:58:11.759511 30256 solver.cpp:228] Iteration 6636, loss = 0.000645109
I0403 03:58:11.759621 30256 solver.cpp:244]     Train net output #0: loss = 0.000644982 (* 1 = 0.000644982 loss)
I0403 03:58:11.955703 30256 sgd_solver.cpp:106] Iteration 6636, lr = 0.0005
I0403 03:58:27.131383 30256 solver.cpp:228] Iteration 6657, loss = 6.63969e-06
I0403 03:58:27.131680 30256 solver.cpp:244]     Train net output #0: loss = 6.51216e-06 (* 1 = 6.51216e-06 loss)
I0403 03:58:27.308028 30256 sgd_solver.cpp:106] Iteration 6657, lr = 0.0005
I0403 03:58:42.290171 30256 solver.cpp:228] Iteration 6678, loss = 0.000343254
I0403 03:58:42.290297 30256 solver.cpp:244]     Train net output #0: loss = 0.000343126 (* 1 = 0.000343126 loss)
I0403 03:58:42.478148 30256 sgd_solver.cpp:106] Iteration 6678, lr = 0.0005
I0403 03:58:57.358942 30256 solver.cpp:228] Iteration 6699, loss = 0.00018399
I0403 03:58:57.359253 30256 solver.cpp:244]     Train net output #0: loss = 0.000183862 (* 1 = 0.000183862 loss)
I0403 03:58:57.565237 30256 sgd_solver.cpp:106] Iteration 6699, lr = 0.0005
I0403 03:59:12.539247 30256 solver.cpp:228] Iteration 6720, loss = 0.00307978
I0403 03:59:12.539367 30256 solver.cpp:244]     Train net output #0: loss = 0.00307965 (* 1 = 0.00307965 loss)
I0403 03:59:12.720785 30256 sgd_solver.cpp:106] Iteration 6720, lr = 0.0005
I0403 03:59:27.597628 30256 solver.cpp:228] Iteration 6741, loss = 0.000489918
I0403 03:59:27.597939 30256 solver.cpp:244]     Train net output #0: loss = 0.00048979 (* 1 = 0.00048979 loss)
I0403 03:59:27.794869 30256 sgd_solver.cpp:106] Iteration 6741, lr = 0.0005
I0403 03:59:42.769379 30256 solver.cpp:228] Iteration 6762, loss = 0.000445626
I0403 03:59:42.769480 30256 solver.cpp:244]     Train net output #0: loss = 0.000445499 (* 1 = 0.000445499 loss)
I0403 03:59:42.921111 30256 sgd_solver.cpp:106] Iteration 6762, lr = 0.0005
I0403 03:59:57.839752 30256 solver.cpp:228] Iteration 6783, loss = 0.00219161
I0403 03:59:57.840028 30256 solver.cpp:244]     Train net output #0: loss = 0.00219148 (* 1 = 0.00219148 loss)
I0403 03:59:58.017881 30256 sgd_solver.cpp:106] Iteration 6783, lr = 0.0005
I0403 04:00:12.985963 30256 solver.cpp:228] Iteration 6804, loss = 0.000802451
I0403 04:00:12.986079 30256 solver.cpp:244]     Train net output #0: loss = 0.000802322 (* 1 = 0.000802322 loss)
I0403 04:00:13.181480 30256 sgd_solver.cpp:106] Iteration 6804, lr = 0.0005
I0403 04:00:28.281554 30256 solver.cpp:228] Iteration 6825, loss = 6.9449e-05
I0403 04:00:28.281849 30256 solver.cpp:244]     Train net output #0: loss = 6.93206e-05 (* 1 = 6.93206e-05 loss)
I0403 04:00:28.459556 30256 sgd_solver.cpp:106] Iteration 6825, lr = 0.0005
I0403 04:00:43.432806 30256 solver.cpp:228] Iteration 6846, loss = 0.000177198
I0403 04:00:43.432919 30256 solver.cpp:244]     Train net output #0: loss = 0.000177069 (* 1 = 0.000177069 loss)
I0403 04:00:43.621561 30256 sgd_solver.cpp:106] Iteration 6846, lr = 0.0005
I0403 04:00:58.664686 30256 solver.cpp:228] Iteration 6867, loss = 0.000605636
I0403 04:00:58.664988 30256 solver.cpp:244]     Train net output #0: loss = 0.000605507 (* 1 = 0.000605507 loss)
I0403 04:00:58.833269 30256 sgd_solver.cpp:106] Iteration 6867, lr = 0.0005
I0403 04:01:13.822878 30256 solver.cpp:228] Iteration 6888, loss = 0.000626156
I0403 04:01:13.822988 30256 solver.cpp:244]     Train net output #0: loss = 0.000626029 (* 1 = 0.000626029 loss)
I0403 04:01:14.004922 30256 sgd_solver.cpp:106] Iteration 6888, lr = 0.0005
I0403 04:01:28.981112 30256 solver.cpp:228] Iteration 6909, loss = 0.000520981
I0403 04:01:28.981418 30256 solver.cpp:244]     Train net output #0: loss = 0.000520855 (* 1 = 0.000520855 loss)
I0403 04:01:29.163343 30256 sgd_solver.cpp:106] Iteration 6909, lr = 0.0005
I0403 04:01:44.066161 30256 solver.cpp:228] Iteration 6930, loss = 0.000107088
I0403 04:01:44.066261 30256 solver.cpp:244]     Train net output #0: loss = 0.000106961 (* 1 = 0.000106961 loss)
I0403 04:01:44.245095 30256 sgd_solver.cpp:106] Iteration 6930, lr = 0.0005
I0403 04:01:59.079970 30256 solver.cpp:228] Iteration 6951, loss = 0.00035805
I0403 04:01:59.080267 30256 solver.cpp:244]     Train net output #0: loss = 0.000357925 (* 1 = 0.000357925 loss)
I0403 04:01:59.274238 30256 sgd_solver.cpp:106] Iteration 6951, lr = 0.0005
I0403 04:02:14.176702 30256 solver.cpp:228] Iteration 6972, loss = 0.00010623
I0403 04:02:14.176811 30256 solver.cpp:244]     Train net output #0: loss = 0.000106105 (* 1 = 0.000106105 loss)
I0403 04:02:14.366109 30256 sgd_solver.cpp:106] Iteration 6972, lr = 0.0005
I0403 04:02:28.075183 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_6992.caffemodel
I0403 04:02:30.858108 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_6992.solverstate
I0403 04:02:32.736878 30256 solver.cpp:337] Iteration 6992, Testing net (#0)
I0403 04:02:56.211660 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992857
I0403 04:02:56.211766 30256 solver.cpp:404]     Test net output #1: loss = 0.0285413 (* 1 = 0.0285413 loss)
I0403 04:02:57.438138 30256 solver.cpp:228] Iteration 6993, loss = 0.000199074
I0403 04:02:57.438251 30256 solver.cpp:244]     Train net output #0: loss = 0.000198949 (* 1 = 0.000198949 loss)
I0403 04:02:57.654917 30256 sgd_solver.cpp:106] Iteration 6993, lr = 0.0005
I0403 04:03:12.460214 30256 solver.cpp:228] Iteration 7014, loss = 0.000341336
I0403 04:03:12.460530 30256 solver.cpp:244]     Train net output #0: loss = 0.00034121 (* 1 = 0.00034121 loss)
I0403 04:03:12.659909 30256 sgd_solver.cpp:106] Iteration 7014, lr = 0.0005
I0403 04:03:27.600445 30256 solver.cpp:228] Iteration 7035, loss = 0.000494501
I0403 04:03:27.600543 30256 solver.cpp:244]     Train net output #0: loss = 0.000494375 (* 1 = 0.000494375 loss)
I0403 04:03:27.768591 30256 sgd_solver.cpp:106] Iteration 7035, lr = 0.0005
I0403 04:03:42.700922 30256 solver.cpp:228] Iteration 7056, loss = 0.000344356
I0403 04:03:42.701264 30256 solver.cpp:244]     Train net output #0: loss = 0.00034423 (* 1 = 0.00034423 loss)
I0403 04:03:42.909726 30256 sgd_solver.cpp:106] Iteration 7056, lr = 0.0005
I0403 04:03:57.705677 30256 solver.cpp:228] Iteration 7077, loss = 0.00148359
I0403 04:03:57.705777 30256 solver.cpp:244]     Train net output #0: loss = 0.00148346 (* 1 = 0.00148346 loss)
I0403 04:03:57.867770 30256 sgd_solver.cpp:106] Iteration 7077, lr = 0.0005
I0403 04:04:12.716734 30256 solver.cpp:228] Iteration 7098, loss = 0.00145733
I0403 04:04:12.717023 30256 solver.cpp:244]     Train net output #0: loss = 0.0014572 (* 1 = 0.0014572 loss)
I0403 04:04:12.894621 30256 sgd_solver.cpp:106] Iteration 7098, lr = 0.0005
I0403 04:04:27.846819 30256 solver.cpp:228] Iteration 7119, loss = 0.000350558
I0403 04:04:27.846917 30256 solver.cpp:244]     Train net output #0: loss = 0.000350432 (* 1 = 0.000350432 loss)
I0403 04:04:28.026190 30256 sgd_solver.cpp:106] Iteration 7119, lr = 0.0005
I0403 04:04:43.200937 30256 solver.cpp:228] Iteration 7140, loss = 0.000409278
I0403 04:04:43.201233 30256 solver.cpp:244]     Train net output #0: loss = 0.000409151 (* 1 = 0.000409151 loss)
I0403 04:04:43.377033 30256 sgd_solver.cpp:106] Iteration 7140, lr = 0.0005
I0403 04:04:58.357821 30256 solver.cpp:228] Iteration 7161, loss = 8.64715e-05
I0403 04:04:58.357931 30256 solver.cpp:244]     Train net output #0: loss = 8.63448e-05 (* 1 = 8.63448e-05 loss)
I0403 04:04:58.551857 30256 sgd_solver.cpp:106] Iteration 7161, lr = 0.0005
I0403 04:05:13.547024 30256 solver.cpp:228] Iteration 7182, loss = 0.000588327
I0403 04:05:13.547317 30256 solver.cpp:244]     Train net output #0: loss = 0.0005882 (* 1 = 0.0005882 loss)
I0403 04:05:13.726637 30256 sgd_solver.cpp:106] Iteration 7182, lr = 0.0005
I0403 04:05:28.921183 30256 solver.cpp:228] Iteration 7203, loss = 0.000163953
I0403 04:05:28.921282 30256 solver.cpp:244]     Train net output #0: loss = 0.000163826 (* 1 = 0.000163826 loss)
I0403 04:05:29.090145 30256 sgd_solver.cpp:106] Iteration 7203, lr = 0.0005
I0403 04:05:44.179688 30256 solver.cpp:228] Iteration 7224, loss = 0.000224703
I0403 04:05:44.179988 30256 solver.cpp:244]     Train net output #0: loss = 0.000224576 (* 1 = 0.000224576 loss)
I0403 04:05:44.319417 30256 sgd_solver.cpp:106] Iteration 7224, lr = 0.0005
I0403 04:05:59.175541 30256 solver.cpp:228] Iteration 7245, loss = 0.000693568
I0403 04:05:59.175644 30256 solver.cpp:244]     Train net output #0: loss = 0.000693441 (* 1 = 0.000693441 loss)
I0403 04:05:59.358172 30256 sgd_solver.cpp:106] Iteration 7245, lr = 0.0005
I0403 04:06:14.381647 30256 solver.cpp:228] Iteration 7266, loss = 0.00261563
I0403 04:06:14.381955 30256 solver.cpp:244]     Train net output #0: loss = 0.00261551 (* 1 = 0.00261551 loss)
I0403 04:06:14.572705 30256 sgd_solver.cpp:106] Iteration 7266, lr = 0.0005
I0403 04:06:29.583631 30256 solver.cpp:228] Iteration 7287, loss = 3.98888e-05
I0403 04:06:29.583734 30256 solver.cpp:244]     Train net output #0: loss = 3.97661e-05 (* 1 = 3.97661e-05 loss)
I0403 04:06:29.754057 30256 sgd_solver.cpp:106] Iteration 7287, lr = 0.0005
I0403 04:06:44.930315 30256 solver.cpp:228] Iteration 7308, loss = 0.000353362
I0403 04:06:44.930620 30256 solver.cpp:244]     Train net output #0: loss = 0.000353241 (* 1 = 0.000353241 loss)
I0403 04:06:45.106200 30256 sgd_solver.cpp:106] Iteration 7308, lr = 0.0005
I0403 04:07:00.192885 30256 solver.cpp:228] Iteration 7329, loss = 0.00277546
I0403 04:07:00.192986 30256 solver.cpp:244]     Train net output #0: loss = 0.00277534 (* 1 = 0.00277534 loss)
I0403 04:07:00.336009 30256 sgd_solver.cpp:106] Iteration 7329, lr = 0.0005
I0403 04:07:15.516163 30256 solver.cpp:228] Iteration 7350, loss = 0.000733169
I0403 04:07:15.516456 30256 solver.cpp:244]     Train net output #0: loss = 0.000733046 (* 1 = 0.000733046 loss)
I0403 04:07:15.682754 30256 sgd_solver.cpp:106] Iteration 7350, lr = 0.0005
I0403 04:07:30.696060 30256 solver.cpp:228] Iteration 7371, loss = 9.78675e-05
I0403 04:07:30.696172 30256 solver.cpp:244]     Train net output #0: loss = 9.77452e-05 (* 1 = 9.77452e-05 loss)
I0403 04:07:30.875859 30256 sgd_solver.cpp:106] Iteration 7371, lr = 0.0005
I0403 04:07:45.856254 30256 solver.cpp:228] Iteration 7392, loss = 2.51056e-05
I0403 04:07:45.856518 30256 solver.cpp:244]     Train net output #0: loss = 2.49839e-05 (* 1 = 2.49839e-05 loss)
I0403 04:07:46.020583 30256 sgd_solver.cpp:106] Iteration 7392, lr = 0.0005
I0403 04:08:01.083506 30256 solver.cpp:228] Iteration 7413, loss = 0.000285501
I0403 04:08:01.083617 30256 solver.cpp:244]     Train net output #0: loss = 0.00028538 (* 1 = 0.00028538 loss)
I0403 04:08:01.332175 30256 sgd_solver.cpp:106] Iteration 7413, lr = 0.0005
I0403 04:08:12.067595 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_7429.caffemodel
I0403 04:08:14.848583 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_7429.solverstate
I0403 04:08:16.743127 30256 solver.cpp:337] Iteration 7429, Testing net (#0)
I0403 04:08:40.213405 30256 solver.cpp:404]     Test net output #0: accuracy = 0.993048
I0403 04:08:40.213515 30256 solver.cpp:404]     Test net output #1: loss = 0.0274967 (* 1 = 0.0274967 loss)
I0403 04:08:44.396986 30256 solver.cpp:228] Iteration 7434, loss = 0.000482571
I0403 04:08:44.397095 30256 solver.cpp:244]     Train net output #0: loss = 0.00048245 (* 1 = 0.00048245 loss)
I0403 04:08:44.584990 30256 sgd_solver.cpp:106] Iteration 7434, lr = 0.0005
I0403 04:08:59.415524 30256 solver.cpp:228] Iteration 7455, loss = 3.74748e-05
I0403 04:08:59.415818 30256 solver.cpp:244]     Train net output #0: loss = 3.7354e-05 (* 1 = 3.7354e-05 loss)
I0403 04:08:59.576709 30256 sgd_solver.cpp:106] Iteration 7455, lr = 0.0005
I0403 04:09:14.616281 30256 solver.cpp:228] Iteration 7476, loss = 0.000176448
I0403 04:09:14.616385 30256 solver.cpp:244]     Train net output #0: loss = 0.000176327 (* 1 = 0.000176327 loss)
I0403 04:09:14.789491 30256 sgd_solver.cpp:106] Iteration 7476, lr = 0.0005
I0403 04:09:29.836413 30256 solver.cpp:228] Iteration 7497, loss = 0.00064708
I0403 04:09:29.836712 30256 solver.cpp:244]     Train net output #0: loss = 0.000646959 (* 1 = 0.000646959 loss)
I0403 04:09:30.002168 30256 sgd_solver.cpp:106] Iteration 7497, lr = 0.0005
I0403 04:09:44.938261 30256 solver.cpp:228] Iteration 7518, loss = 0.00466215
I0403 04:09:44.938364 30256 solver.cpp:244]     Train net output #0: loss = 0.00466203 (* 1 = 0.00466203 loss)
I0403 04:09:45.113260 30256 sgd_solver.cpp:106] Iteration 7518, lr = 0.0005
I0403 04:10:00.065001 30256 solver.cpp:228] Iteration 7539, loss = 0.000144561
I0403 04:10:00.065322 30256 solver.cpp:244]     Train net output #0: loss = 0.000144442 (* 1 = 0.000144442 loss)
I0403 04:10:00.290518 30256 sgd_solver.cpp:106] Iteration 7539, lr = 0.0005
I0403 04:10:15.265660 30256 solver.cpp:228] Iteration 7560, loss = 0.00058336
I0403 04:10:15.265756 30256 solver.cpp:244]     Train net output #0: loss = 0.000583241 (* 1 = 0.000583241 loss)
I0403 04:10:15.422960 30256 sgd_solver.cpp:106] Iteration 7560, lr = 0.0005
I0403 04:10:30.561353 30256 solver.cpp:228] Iteration 7581, loss = 0.000143746
I0403 04:10:30.561651 30256 solver.cpp:244]     Train net output #0: loss = 0.000143627 (* 1 = 0.000143627 loss)
I0403 04:10:30.735280 30256 sgd_solver.cpp:106] Iteration 7581, lr = 0.0005
I0403 04:10:45.941357 30256 solver.cpp:228] Iteration 7602, loss = 0.000222338
I0403 04:10:45.941468 30256 solver.cpp:244]     Train net output #0: loss = 0.000222219 (* 1 = 0.000222219 loss)
I0403 04:10:46.147213 30256 sgd_solver.cpp:106] Iteration 7602, lr = 0.0005
I0403 04:11:01.037009 30256 solver.cpp:228] Iteration 7623, loss = 0.000525386
I0403 04:11:01.037307 30256 solver.cpp:244]     Train net output #0: loss = 0.000525267 (* 1 = 0.000525267 loss)
I0403 04:11:01.194300 30256 sgd_solver.cpp:106] Iteration 7623, lr = 0.0005
I0403 04:11:16.166926 30256 solver.cpp:228] Iteration 7644, loss = 9.48433e-05
I0403 04:11:16.167024 30256 solver.cpp:244]     Train net output #0: loss = 9.4724e-05 (* 1 = 9.4724e-05 loss)
I0403 04:11:16.335144 30256 sgd_solver.cpp:106] Iteration 7644, lr = 0.0005
I0403 04:11:31.595243 30256 solver.cpp:228] Iteration 7665, loss = 3.01834e-05
I0403 04:11:31.599457 30256 solver.cpp:244]     Train net output #0: loss = 3.00643e-05 (* 1 = 3.00643e-05 loss)
I0403 04:11:31.791889 30256 sgd_solver.cpp:106] Iteration 7665, lr = 0.0005
I0403 04:11:46.706255 30256 solver.cpp:228] Iteration 7686, loss = 0.000179422
I0403 04:11:46.706374 30256 solver.cpp:244]     Train net output #0: loss = 0.000179302 (* 1 = 0.000179302 loss)
I0403 04:11:46.897156 30256 sgd_solver.cpp:106] Iteration 7686, lr = 0.0005
I0403 04:12:01.762830 30256 solver.cpp:228] Iteration 7707, loss = 7.70031e-05
I0403 04:12:01.763167 30256 solver.cpp:244]     Train net output #0: loss = 7.68838e-05 (* 1 = 7.68838e-05 loss)
I0403 04:12:01.948200 30256 sgd_solver.cpp:106] Iteration 7707, lr = 0.0005
I0403 04:12:16.874104 30256 solver.cpp:228] Iteration 7728, loss = 0.000126835
I0403 04:12:16.874203 30256 solver.cpp:244]     Train net output #0: loss = 0.000126716 (* 1 = 0.000126716 loss)
I0403 04:12:17.039192 30256 sgd_solver.cpp:106] Iteration 7728, lr = 0.0005
I0403 04:12:32.120597 30256 solver.cpp:228] Iteration 7749, loss = 0.000358971
I0403 04:12:32.120906 30256 solver.cpp:244]     Train net output #0: loss = 0.000358852 (* 1 = 0.000358852 loss)
I0403 04:12:32.324883 30256 sgd_solver.cpp:106] Iteration 7749, lr = 0.0005
I0403 04:12:47.337332 30256 solver.cpp:228] Iteration 7770, loss = 0.000777587
I0403 04:12:47.337432 30256 solver.cpp:244]     Train net output #0: loss = 0.000777469 (* 1 = 0.000777469 loss)
I0403 04:12:47.517053 30256 sgd_solver.cpp:106] Iteration 7770, lr = 0.0005
I0403 04:13:02.547404 30256 solver.cpp:228] Iteration 7791, loss = 0.000148378
I0403 04:13:02.547688 30256 solver.cpp:244]     Train net output #0: loss = 0.00014826 (* 1 = 0.00014826 loss)
I0403 04:13:02.734817 30256 sgd_solver.cpp:106] Iteration 7791, lr = 0.0005
I0403 04:13:17.687463 30256 solver.cpp:228] Iteration 7812, loss = 0.000581163
I0403 04:13:17.687564 30256 solver.cpp:244]     Train net output #0: loss = 0.000581045 (* 1 = 0.000581045 loss)
I0403 04:13:17.835947 30256 sgd_solver.cpp:106] Iteration 7812, lr = 0.0005
I0403 04:13:32.902042 30256 solver.cpp:228] Iteration 7833, loss = 1.77745e-05
I0403 04:13:32.902361 30256 solver.cpp:244]     Train net output #0: loss = 1.76565e-05 (* 1 = 1.76565e-05 loss)
I0403 04:13:33.085402 30256 sgd_solver.cpp:106] Iteration 7833, lr = 0.0005
I0403 04:13:48.128465 30256 solver.cpp:228] Iteration 7854, loss = 0.000341205
I0403 04:13:48.128571 30256 solver.cpp:244]     Train net output #0: loss = 0.000341086 (* 1 = 0.000341086 loss)
I0403 04:13:48.314388 30256 sgd_solver.cpp:106] Iteration 7854, lr = 0.0005
I0403 04:13:56.226557 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_7866.caffemodel
I0403 04:13:58.996968 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_7866.solverstate
I0403 04:14:00.917698 30256 solver.cpp:337] Iteration 7866, Testing net (#0)
I0403 04:14:24.384215 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992572
I0403 04:14:24.384522 30256 solver.cpp:404]     Test net output #1: loss = 0.0282247 (* 1 = 0.0282247 loss)
I0403 04:14:31.441426 30256 solver.cpp:228] Iteration 7875, loss = 0.000857398
I0403 04:14:31.441534 30256 solver.cpp:244]     Train net output #0: loss = 0.00085728 (* 1 = 0.00085728 loss)
I0403 04:14:31.655828 30256 sgd_solver.cpp:106] Iteration 7875, lr = 0.0005
I0403 04:14:46.814229 30256 solver.cpp:228] Iteration 7896, loss = 0.000268108
I0403 04:14:46.814338 30256 solver.cpp:244]     Train net output #0: loss = 0.00026799 (* 1 = 0.00026799 loss)
I0403 04:14:46.996088 30256 sgd_solver.cpp:106] Iteration 7896, lr = 0.0005
I0403 04:15:02.138327 30256 solver.cpp:228] Iteration 7917, loss = 0.000147399
I0403 04:15:02.138666 30256 solver.cpp:244]     Train net output #0: loss = 0.000147281 (* 1 = 0.000147281 loss)
I0403 04:15:02.317875 30256 sgd_solver.cpp:106] Iteration 7917, lr = 0.0005
I0403 04:15:17.171103 30256 solver.cpp:228] Iteration 7938, loss = 0.00168097
I0403 04:15:17.171205 30256 solver.cpp:244]     Train net output #0: loss = 0.00168085 (* 1 = 0.00168085 loss)
I0403 04:15:17.348497 30256 sgd_solver.cpp:106] Iteration 7938, lr = 0.0005
I0403 04:15:32.518489 30256 solver.cpp:228] Iteration 7959, loss = 0.000451537
I0403 04:15:32.518774 30256 solver.cpp:244]     Train net output #0: loss = 0.000451419 (* 1 = 0.000451419 loss)
I0403 04:15:32.697753 30256 sgd_solver.cpp:106] Iteration 7959, lr = 0.0005
I0403 04:15:47.459429 30256 solver.cpp:228] Iteration 7980, loss = 0.000347673
I0403 04:15:47.459542 30256 solver.cpp:244]     Train net output #0: loss = 0.000347554 (* 1 = 0.000347554 loss)
I0403 04:15:47.679175 30256 sgd_solver.cpp:106] Iteration 7980, lr = 0.0005
I0403 04:16:02.695683 30256 solver.cpp:228] Iteration 8001, loss = 0.000228024
I0403 04:16:02.695973 30256 solver.cpp:244]     Train net output #0: loss = 0.000227905 (* 1 = 0.000227905 loss)
I0403 04:16:02.844640 30256 sgd_solver.cpp:106] Iteration 8001, lr = 0.0005
I0403 04:16:17.978916 30256 solver.cpp:228] Iteration 8022, loss = 0.00382948
I0403 04:16:17.979027 30256 solver.cpp:244]     Train net output #0: loss = 0.00382936 (* 1 = 0.00382936 loss)
I0403 04:16:18.174110 30256 sgd_solver.cpp:106] Iteration 8022, lr = 0.0005
I0403 04:16:33.255354 30256 solver.cpp:228] Iteration 8043, loss = 7.24139e-05
I0403 04:16:33.255640 30256 solver.cpp:244]     Train net output #0: loss = 7.22968e-05 (* 1 = 7.22968e-05 loss)
I0403 04:16:33.445680 30256 sgd_solver.cpp:106] Iteration 8043, lr = 0.0005
I0403 04:16:48.374213 30256 solver.cpp:228] Iteration 8064, loss = 0.000870055
I0403 04:16:48.374322 30256 solver.cpp:244]     Train net output #0: loss = 0.000869938 (* 1 = 0.000869938 loss)
I0403 04:16:48.575618 30256 sgd_solver.cpp:106] Iteration 8064, lr = 0.0005
I0403 04:17:03.417304 30256 solver.cpp:228] Iteration 8085, loss = 8.56277e-05
I0403 04:17:03.417616 30256 solver.cpp:244]     Train net output #0: loss = 8.55106e-05 (* 1 = 8.55106e-05 loss)
I0403 04:17:03.612010 30256 sgd_solver.cpp:106] Iteration 8085, lr = 0.0005
I0403 04:17:18.463769 30256 solver.cpp:228] Iteration 8106, loss = 0.000178776
I0403 04:17:18.463867 30256 solver.cpp:244]     Train net output #0: loss = 0.000178659 (* 1 = 0.000178659 loss)
I0403 04:17:18.639765 30256 sgd_solver.cpp:106] Iteration 8106, lr = 0.0005
I0403 04:17:33.500018 30256 solver.cpp:228] Iteration 8127, loss = 0.0010074
I0403 04:17:33.500315 30256 solver.cpp:244]     Train net output #0: loss = 0.00100728 (* 1 = 0.00100728 loss)
I0403 04:17:33.715733 30256 sgd_solver.cpp:106] Iteration 8127, lr = 0.0005
I0403 04:17:48.843572 30256 solver.cpp:228] Iteration 8148, loss = 0.000947399
I0403 04:17:48.843677 30256 solver.cpp:244]     Train net output #0: loss = 0.000947282 (* 1 = 0.000947282 loss)
I0403 04:17:48.999845 30256 sgd_solver.cpp:106] Iteration 8148, lr = 0.0005
I0403 04:18:03.959789 30256 solver.cpp:228] Iteration 8169, loss = 0.000563495
I0403 04:18:03.960098 30256 solver.cpp:244]     Train net output #0: loss = 0.000563378 (* 1 = 0.000563378 loss)
I0403 04:18:04.165700 30256 sgd_solver.cpp:106] Iteration 8169, lr = 0.0005
I0403 04:18:19.048373 30256 solver.cpp:228] Iteration 8190, loss = 0.00178994
I0403 04:18:19.048478 30256 solver.cpp:244]     Train net output #0: loss = 0.00178982 (* 1 = 0.00178982 loss)
I0403 04:18:19.237390 30256 sgd_solver.cpp:106] Iteration 8190, lr = 0.0005
I0403 04:18:34.151209 30256 solver.cpp:228] Iteration 8211, loss = 0.000137461
I0403 04:18:34.151509 30256 solver.cpp:244]     Train net output #0: loss = 0.000137345 (* 1 = 0.000137345 loss)
I0403 04:18:34.325415 30256 sgd_solver.cpp:106] Iteration 8211, lr = 0.0005
I0403 04:18:49.392233 30256 solver.cpp:228] Iteration 8232, loss = 0.011163
I0403 04:18:49.392343 30256 solver.cpp:244]     Train net output #0: loss = 0.0111629 (* 1 = 0.0111629 loss)
I0403 04:18:49.573045 30256 sgd_solver.cpp:106] Iteration 8232, lr = 0.0005
I0403 04:19:04.441498 30256 solver.cpp:228] Iteration 8253, loss = 0.00068681
I0403 04:19:04.441838 30256 solver.cpp:244]     Train net output #0: loss = 0.000686694 (* 1 = 0.000686694 loss)
I0403 04:19:04.654121 30256 sgd_solver.cpp:106] Iteration 8253, lr = 0.0005
I0403 04:19:19.758890 30256 solver.cpp:228] Iteration 8274, loss = 6.98378e-05
I0403 04:19:19.758988 30256 solver.cpp:244]     Train net output #0: loss = 6.97241e-05 (* 1 = 6.97241e-05 loss)
I0403 04:19:19.920574 30256 sgd_solver.cpp:106] Iteration 8274, lr = 0.0005
I0403 04:19:35.020516 30256 solver.cpp:228] Iteration 8295, loss = 0.00161484
I0403 04:19:35.020763 30256 solver.cpp:244]     Train net output #0: loss = 0.00161473 (* 1 = 0.00161473 loss)
I0403 04:19:35.206948 30256 sgd_solver.cpp:106] Iteration 8295, lr = 0.0005
I0403 04:19:40.424986 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_8303.caffemodel
I0403 04:19:43.189827 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_8303.solverstate
I0403 04:19:45.060592 30256 solver.cpp:337] Iteration 8303, Testing net (#0)
I0403 04:20:08.526481 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992476
I0403 04:20:08.526803 30256 solver.cpp:404]     Test net output #1: loss = 0.0286468 (* 1 = 0.0286468 loss)
I0403 04:20:18.444279 30256 solver.cpp:228] Iteration 8316, loss = 0.000332516
I0403 04:20:18.444383 30256 solver.cpp:244]     Train net output #0: loss = 0.000332402 (* 1 = 0.000332402 loss)
I0403 04:20:18.616991 30256 sgd_solver.cpp:106] Iteration 8316, lr = 0.0005
I0403 04:20:33.639384 30256 solver.cpp:228] Iteration 8337, loss = 0.00887414
I0403 04:20:33.639495 30256 solver.cpp:244]     Train net output #0: loss = 0.00887403 (* 1 = 0.00887403 loss)
I0403 04:20:33.855022 30256 sgd_solver.cpp:106] Iteration 8337, lr = 0.0005
I0403 04:20:48.916869 30256 solver.cpp:228] Iteration 8358, loss = 0.000248205
I0403 04:20:48.917165 30256 solver.cpp:244]     Train net output #0: loss = 0.000248092 (* 1 = 0.000248092 loss)
I0403 04:20:49.114766 30256 sgd_solver.cpp:106] Iteration 8358, lr = 0.0005
I0403 04:21:04.007828 30256 solver.cpp:228] Iteration 8379, loss = 0.000408916
I0403 04:21:04.007935 30256 solver.cpp:244]     Train net output #0: loss = 0.000408802 (* 1 = 0.000408802 loss)
I0403 04:21:04.203550 30256 sgd_solver.cpp:106] Iteration 8379, lr = 0.0005
I0403 04:21:19.072216 30256 solver.cpp:228] Iteration 8400, loss = 0.00360646
I0403 04:21:19.072525 30256 solver.cpp:244]     Train net output #0: loss = 0.00360634 (* 1 = 0.00360634 loss)
I0403 04:21:19.270143 30256 sgd_solver.cpp:106] Iteration 8400, lr = 0.0005
I0403 04:21:34.280156 30256 solver.cpp:228] Iteration 8421, loss = 0.000253053
I0403 04:21:34.280266 30256 solver.cpp:244]     Train net output #0: loss = 0.00025294 (* 1 = 0.00025294 loss)
I0403 04:21:34.489512 30256 sgd_solver.cpp:106] Iteration 8421, lr = 0.0005
I0403 04:21:49.416563 30256 solver.cpp:228] Iteration 8442, loss = 0.000704646
I0403 04:21:49.416863 30256 solver.cpp:244]     Train net output #0: loss = 0.000704532 (* 1 = 0.000704532 loss)
I0403 04:21:49.586908 30256 sgd_solver.cpp:106] Iteration 8442, lr = 0.0005
I0403 04:22:04.669064 30256 solver.cpp:228] Iteration 8463, loss = 0.000137713
I0403 04:22:04.669162 30256 solver.cpp:244]     Train net output #0: loss = 0.000137599 (* 1 = 0.000137599 loss)
I0403 04:22:04.834254 30256 sgd_solver.cpp:106] Iteration 8463, lr = 0.0005
I0403 04:22:19.870702 30256 solver.cpp:228] Iteration 8484, loss = 7.50031e-05
I0403 04:22:19.871021 30256 solver.cpp:244]     Train net output #0: loss = 7.48886e-05 (* 1 = 7.48886e-05 loss)
I0403 04:22:20.064951 30256 sgd_solver.cpp:106] Iteration 8484, lr = 0.0005
I0403 04:22:35.057924 30256 solver.cpp:228] Iteration 8505, loss = 0.00169929
I0403 04:22:35.058022 30256 solver.cpp:244]     Train net output #0: loss = 0.00169918 (* 1 = 0.00169918 loss)
I0403 04:22:35.235262 30256 sgd_solver.cpp:106] Iteration 8505, lr = 0.0005
I0403 04:22:50.016206 30256 solver.cpp:228] Iteration 8526, loss = 7.60226e-06
I0403 04:22:50.016546 30256 solver.cpp:244]     Train net output #0: loss = 7.48674e-06 (* 1 = 7.48674e-06 loss)
I0403 04:22:50.226904 30256 sgd_solver.cpp:106] Iteration 8526, lr = 0.0005
I0403 04:23:05.451055 30256 solver.cpp:228] Iteration 8547, loss = 8.14916e-05
I0403 04:23:05.451164 30256 solver.cpp:244]     Train net output #0: loss = 8.13776e-05 (* 1 = 8.13776e-05 loss)
I0403 04:23:05.640456 30256 sgd_solver.cpp:106] Iteration 8547, lr = 0.0005
I0403 04:23:20.562288 30256 solver.cpp:228] Iteration 8568, loss = 2.64453e-05
I0403 04:23:20.562626 30256 solver.cpp:244]     Train net output #0: loss = 2.63313e-05 (* 1 = 2.63313e-05 loss)
I0403 04:23:20.770941 30256 sgd_solver.cpp:106] Iteration 8568, lr = 0.0005
I0403 04:23:35.596580 30256 solver.cpp:228] Iteration 8589, loss = 4.98819e-05
I0403 04:23:35.596685 30256 solver.cpp:244]     Train net output #0: loss = 4.97679e-05 (* 1 = 4.97679e-05 loss)
I0403 04:23:35.775785 30256 sgd_solver.cpp:106] Iteration 8589, lr = 0.0005
I0403 04:23:50.699391 30256 solver.cpp:228] Iteration 8610, loss = 0.000105479
I0403 04:23:50.699710 30256 solver.cpp:244]     Train net output #0: loss = 0.000105365 (* 1 = 0.000105365 loss)
I0403 04:23:50.903692 30256 sgd_solver.cpp:106] Iteration 8610, lr = 0.0005
I0403 04:24:05.930469 30256 solver.cpp:228] Iteration 8631, loss = 8.91588e-05
I0403 04:24:05.930570 30256 solver.cpp:244]     Train net output #0: loss = 8.90454e-05 (* 1 = 8.90454e-05 loss)
I0403 04:24:06.108675 30256 sgd_solver.cpp:106] Iteration 8631, lr = 0.0005
I0403 04:24:21.097962 30256 solver.cpp:228] Iteration 8652, loss = 0.000249471
I0403 04:24:21.098242 30256 solver.cpp:244]     Train net output #0: loss = 0.000249357 (* 1 = 0.000249357 loss)
I0403 04:24:21.272438 30256 sgd_solver.cpp:106] Iteration 8652, lr = 0.0005
I0403 04:24:36.162973 30256 solver.cpp:228] Iteration 8673, loss = 6.74916e-05
I0403 04:24:36.163072 30256 solver.cpp:244]     Train net output #0: loss = 6.73781e-05 (* 1 = 6.73781e-05 loss)
I0403 04:24:36.340836 30256 sgd_solver.cpp:106] Iteration 8673, lr = 0.0005
I0403 04:24:51.315839 30256 solver.cpp:228] Iteration 8694, loss = 6.53654e-05
I0403 04:24:51.316134 30256 solver.cpp:244]     Train net output #0: loss = 6.52514e-05 (* 1 = 6.52514e-05 loss)
I0403 04:24:51.478435 30256 sgd_solver.cpp:106] Iteration 8694, lr = 0.0005
I0403 04:25:06.396672 30256 solver.cpp:228] Iteration 8715, loss = 0.00033837
I0403 04:25:06.396783 30256 solver.cpp:244]     Train net output #0: loss = 0.000338257 (* 1 = 0.000338257 loss)
I0403 04:25:06.634860 30256 sgd_solver.cpp:106] Iteration 8715, lr = 0.0005
I0403 04:25:21.737701 30256 solver.cpp:228] Iteration 8736, loss = 0.000326301
I0403 04:25:21.737999 30256 solver.cpp:244]     Train net output #0: loss = 0.000326187 (* 1 = 0.000326187 loss)
I0403 04:25:21.895792 30256 sgd_solver.cpp:106] Iteration 8736, lr = 0.0005
I0403 04:25:24.066121 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_8740.caffemodel
I0403 04:25:26.806931 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_8740.solverstate
I0403 04:25:28.650463 30256 solver.cpp:337] Iteration 8740, Testing net (#0)
I0403 04:25:52.128187 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992952
I0403 04:25:52.128528 30256 solver.cpp:404]     Test net output #1: loss = 0.0266563 (* 1 = 0.0266563 loss)
I0403 04:26:04.878796 30256 solver.cpp:228] Iteration 8757, loss = 0.000202311
I0403 04:26:04.878893 30256 solver.cpp:244]     Train net output #0: loss = 0.000202197 (* 1 = 0.000202197 loss)
I0403 04:26:05.055414 30256 sgd_solver.cpp:106] Iteration 8757, lr = 5e-05
I0403 04:26:19.800112 30256 solver.cpp:228] Iteration 8778, loss = 0.000442837
I0403 04:26:19.800240 30256 solver.cpp:244]     Train net output #0: loss = 0.000442722 (* 1 = 0.000442722 loss)
I0403 04:26:19.981758 30256 sgd_solver.cpp:106] Iteration 8778, lr = 5e-05
I0403 04:26:34.949513 30256 solver.cpp:228] Iteration 8799, loss = 0.000126166
I0403 04:26:34.949770 30256 solver.cpp:244]     Train net output #0: loss = 0.000126051 (* 1 = 0.000126051 loss)
I0403 04:26:35.128408 30256 sgd_solver.cpp:106] Iteration 8799, lr = 5e-05
I0403 04:26:49.966339 30256 solver.cpp:228] Iteration 8820, loss = 9.50779e-05
I0403 04:26:49.966440 30256 solver.cpp:244]     Train net output #0: loss = 9.49636e-05 (* 1 = 9.49636e-05 loss)
I0403 04:26:50.144644 30256 sgd_solver.cpp:106] Iteration 8820, lr = 5e-05
I0403 04:27:05.006721 30256 solver.cpp:228] Iteration 8841, loss = 0.000221692
I0403 04:27:05.007031 30256 solver.cpp:244]     Train net output #0: loss = 0.000221579 (* 1 = 0.000221579 loss)
I0403 04:27:05.206322 30256 sgd_solver.cpp:106] Iteration 8841, lr = 5e-05
I0403 04:27:20.006676 30256 solver.cpp:228] Iteration 8862, loss = 0.0011599
I0403 04:27:20.013690 30256 solver.cpp:244]     Train net output #0: loss = 0.00115979 (* 1 = 0.00115979 loss)
I0403 04:27:20.183408 30256 sgd_solver.cpp:106] Iteration 8862, lr = 5e-05
I0403 04:27:35.000149 30256 solver.cpp:228] Iteration 8883, loss = 0.0119816
I0403 04:27:35.000260 30256 solver.cpp:244]     Train net output #0: loss = 0.0119815 (* 1 = 0.0119815 loss)
I0403 04:27:35.201930 30256 sgd_solver.cpp:106] Iteration 8883, lr = 5e-05
I0403 04:27:50.208775 30256 solver.cpp:228] Iteration 8904, loss = 0.00041714
I0403 04:27:50.208881 30256 solver.cpp:244]     Train net output #0: loss = 0.000417026 (* 1 = 0.000417026 loss)
I0403 04:27:50.391003 30256 sgd_solver.cpp:106] Iteration 8904, lr = 5e-05
I0403 04:28:05.427813 30256 solver.cpp:228] Iteration 8925, loss = 0.00116058
I0403 04:28:05.428119 30256 solver.cpp:244]     Train net output #0: loss = 0.00116047 (* 1 = 0.00116047 loss)
I0403 04:28:05.618440 30256 sgd_solver.cpp:106] Iteration 8925, lr = 5e-05
I0403 04:28:20.520264 30256 solver.cpp:228] Iteration 8946, loss = 0.00079939
I0403 04:28:20.520377 30256 solver.cpp:244]     Train net output #0: loss = 0.000799277 (* 1 = 0.000799277 loss)
I0403 04:28:20.705715 30256 sgd_solver.cpp:106] Iteration 8946, lr = 5e-05
I0403 04:28:35.585239 30256 solver.cpp:228] Iteration 8967, loss = 0.000315528
I0403 04:28:35.585546 30256 solver.cpp:244]     Train net output #0: loss = 0.000315415 (* 1 = 0.000315415 loss)
I0403 04:28:35.765194 30256 sgd_solver.cpp:106] Iteration 8967, lr = 5e-05
I0403 04:28:50.834020 30256 solver.cpp:228] Iteration 8988, loss = 0.000124778
I0403 04:28:50.834130 30256 solver.cpp:244]     Train net output #0: loss = 0.000124664 (* 1 = 0.000124664 loss)
I0403 04:28:51.031844 30256 sgd_solver.cpp:106] Iteration 8988, lr = 5e-05
I0403 04:29:06.197587 30256 solver.cpp:228] Iteration 9009, loss = 0.000106915
I0403 04:29:06.197890 30256 solver.cpp:244]     Train net output #0: loss = 0.000106801 (* 1 = 0.000106801 loss)
I0403 04:29:06.365896 30256 sgd_solver.cpp:106] Iteration 9009, lr = 5e-05
I0403 04:29:21.406622 30256 solver.cpp:228] Iteration 9030, loss = 0.000150113
I0403 04:29:21.406721 30256 solver.cpp:244]     Train net output #0: loss = 0.000149999 (* 1 = 0.000149999 loss)
I0403 04:29:21.582000 30256 sgd_solver.cpp:106] Iteration 9030, lr = 5e-05
I0403 04:29:36.516636 30256 solver.cpp:228] Iteration 9051, loss = 0.000136419
I0403 04:29:36.516918 30256 solver.cpp:244]     Train net output #0: loss = 0.000136304 (* 1 = 0.000136304 loss)
I0403 04:29:36.691714 30256 sgd_solver.cpp:106] Iteration 9051, lr = 5e-05
I0403 04:29:52.030115 30256 solver.cpp:228] Iteration 9072, loss = 0.000419574
I0403 04:29:52.030223 30256 solver.cpp:244]     Train net output #0: loss = 0.00041946 (* 1 = 0.00041946 loss)
I0403 04:29:52.234582 30256 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 04:30:07.565021 30256 solver.cpp:228] Iteration 9093, loss = 0.000466569
I0403 04:30:07.565328 30256 solver.cpp:244]     Train net output #0: loss = 0.000466455 (* 1 = 0.000466455 loss)
I0403 04:30:07.718180 30256 sgd_solver.cpp:106] Iteration 9093, lr = 5e-05
I0403 04:30:22.898437 30256 solver.cpp:228] Iteration 9114, loss = 8.94711e-05
I0403 04:30:22.898548 30256 solver.cpp:244]     Train net output #0: loss = 8.93568e-05 (* 1 = 8.93568e-05 loss)
I0403 04:30:23.084494 30256 sgd_solver.cpp:106] Iteration 9114, lr = 5e-05
I0403 04:30:38.238771 30256 solver.cpp:228] Iteration 9135, loss = 7.26671e-05
I0403 04:30:38.239105 30256 solver.cpp:244]     Train net output #0: loss = 7.25525e-05 (* 1 = 7.25525e-05 loss)
I0403 04:30:38.414870 30256 sgd_solver.cpp:106] Iteration 9135, lr = 5e-05
I0403 04:30:53.411372 30256 solver.cpp:228] Iteration 9156, loss = 8.72652e-05
I0403 04:30:53.411470 30256 solver.cpp:244]     Train net output #0: loss = 8.71497e-05 (* 1 = 8.71497e-05 loss)
I0403 04:30:53.577533 30256 sgd_solver.cpp:106] Iteration 9156, lr = 5e-05
I0403 04:31:07.997658 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_9177.caffemodel
I0403 04:31:10.721253 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_9177.solverstate
I0403 04:31:12.628680 30256 solver.cpp:337] Iteration 9177, Testing net (#0)
I0403 04:31:36.107511 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992762
I0403 04:31:36.107621 30256 solver.cpp:404]     Test net output #1: loss = 0.026255 (* 1 = 0.026255 loss)
I0403 04:31:36.617306 30256 solver.cpp:228] Iteration 9177, loss = 0.00143152
I0403 04:31:36.617405 30256 solver.cpp:244]     Train net output #0: loss = 0.00143141 (* 1 = 0.00143141 loss)
I0403 04:31:36.792387 30256 sgd_solver.cpp:106] Iteration 9177, lr = 5e-05
I0403 04:31:51.685328 30256 solver.cpp:228] Iteration 9198, loss = 0.000210523
I0403 04:31:51.685626 30256 solver.cpp:244]     Train net output #0: loss = 0.000210408 (* 1 = 0.000210408 loss)
I0403 04:31:51.865212 30256 sgd_solver.cpp:106] Iteration 9198, lr = 5e-05
I0403 04:32:06.849257 30256 solver.cpp:228] Iteration 9219, loss = 0.00169671
I0403 04:32:06.849395 30256 solver.cpp:244]     Train net output #0: loss = 0.00169659 (* 1 = 0.00169659 loss)
I0403 04:32:07.041399 30256 sgd_solver.cpp:106] Iteration 9219, lr = 5e-05
I0403 04:32:22.162394 30256 solver.cpp:228] Iteration 9240, loss = 0.000160557
I0403 04:32:22.162705 30256 solver.cpp:244]     Train net output #0: loss = 0.000160442 (* 1 = 0.000160442 loss)
I0403 04:32:22.342327 30256 sgd_solver.cpp:106] Iteration 9240, lr = 5e-05
I0403 04:32:37.219880 30256 solver.cpp:228] Iteration 9261, loss = 8.23393e-05
I0403 04:32:37.219990 30256 solver.cpp:244]     Train net output #0: loss = 8.22244e-05 (* 1 = 8.22244e-05 loss)
I0403 04:32:37.405150 30256 sgd_solver.cpp:106] Iteration 9261, lr = 5e-05
I0403 04:32:52.574671 30256 solver.cpp:228] Iteration 9282, loss = 0.000638412
I0403 04:32:52.574954 30256 solver.cpp:244]     Train net output #0: loss = 0.000638297 (* 1 = 0.000638297 loss)
I0403 04:32:52.752112 30256 sgd_solver.cpp:106] Iteration 9282, lr = 5e-05
I0403 04:33:07.889708 30256 solver.cpp:228] Iteration 9303, loss = 2.39278e-05
I0403 04:33:07.889819 30256 solver.cpp:244]     Train net output #0: loss = 2.3813e-05 (* 1 = 2.3813e-05 loss)
I0403 04:33:08.071048 30256 sgd_solver.cpp:106] Iteration 9303, lr = 5e-05
I0403 04:33:23.018678 30256 solver.cpp:228] Iteration 9324, loss = 0.000158528
I0403 04:33:23.018959 30256 solver.cpp:244]     Train net output #0: loss = 0.000158414 (* 1 = 0.000158414 loss)
I0403 04:33:23.198421 30256 sgd_solver.cpp:106] Iteration 9324, lr = 5e-05
I0403 04:33:38.127998 30256 solver.cpp:228] Iteration 9345, loss = 0.00268829
I0403 04:33:38.128100 30256 solver.cpp:244]     Train net output #0: loss = 0.00268818 (* 1 = 0.00268818 loss)
I0403 04:33:38.306061 30256 sgd_solver.cpp:106] Iteration 9345, lr = 5e-05
I0403 04:33:53.389093 30256 solver.cpp:228] Iteration 9366, loss = 0.00556086
I0403 04:33:53.389410 30256 solver.cpp:244]     Train net output #0: loss = 0.00556075 (* 1 = 0.00556075 loss)
I0403 04:33:53.573225 30256 sgd_solver.cpp:106] Iteration 9366, lr = 5e-05
I0403 04:34:08.447433 30256 solver.cpp:228] Iteration 9387, loss = 0.000482396
I0403 04:34:08.447545 30256 solver.cpp:244]     Train net output #0: loss = 0.000482283 (* 1 = 0.000482283 loss)
I0403 04:34:08.631456 30256 sgd_solver.cpp:106] Iteration 9387, lr = 5e-05
I0403 04:34:23.777770 30256 solver.cpp:228] Iteration 9408, loss = 0.000413315
I0403 04:34:23.778093 30256 solver.cpp:244]     Train net output #0: loss = 0.000413201 (* 1 = 0.000413201 loss)
I0403 04:34:23.955850 30256 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 04:34:38.816710 30256 solver.cpp:228] Iteration 9429, loss = 9.26955e-05
I0403 04:34:38.816822 30256 solver.cpp:244]     Train net output #0: loss = 9.25819e-05 (* 1 = 9.25819e-05 loss)
I0403 04:34:38.996386 30256 sgd_solver.cpp:106] Iteration 9429, lr = 5e-05
I0403 04:34:53.915896 30256 solver.cpp:228] Iteration 9450, loss = 0.00807971
I0403 04:34:53.916215 30256 solver.cpp:244]     Train net output #0: loss = 0.0080796 (* 1 = 0.0080796 loss)
I0403 04:34:54.115766 30256 sgd_solver.cpp:106] Iteration 9450, lr = 5e-05
I0403 04:35:09.014760 30256 solver.cpp:228] Iteration 9471, loss = 0.00527064
I0403 04:35:09.014870 30256 solver.cpp:244]     Train net output #0: loss = 0.00527052 (* 1 = 0.00527052 loss)
I0403 04:35:09.220299 30256 sgd_solver.cpp:106] Iteration 9471, lr = 5e-05
I0403 04:35:24.068054 30256 solver.cpp:228] Iteration 9492, loss = 0.000142628
I0403 04:35:24.068367 30256 solver.cpp:244]     Train net output #0: loss = 0.000142514 (* 1 = 0.000142514 loss)
I0403 04:35:24.247752 30256 sgd_solver.cpp:106] Iteration 9492, lr = 5e-05
I0403 04:35:39.389019 30256 solver.cpp:228] Iteration 9513, loss = 2.08449e-05
I0403 04:35:39.389133 30256 solver.cpp:244]     Train net output #0: loss = 2.07324e-05 (* 1 = 2.07324e-05 loss)
I0403 04:35:39.598400 30256 sgd_solver.cpp:106] Iteration 9513, lr = 5e-05
I0403 04:35:54.614928 30256 solver.cpp:228] Iteration 9534, loss = 0.000148966
I0403 04:35:54.615262 30256 solver.cpp:244]     Train net output #0: loss = 0.000148853 (* 1 = 0.000148853 loss)
I0403 04:35:54.812232 30256 sgd_solver.cpp:106] Iteration 9534, lr = 5e-05
I0403 04:36:09.651674 30256 solver.cpp:228] Iteration 9555, loss = 0.000274753
I0403 04:36:09.651787 30256 solver.cpp:244]     Train net output #0: loss = 0.000274641 (* 1 = 0.000274641 loss)
I0403 04:36:09.835193 30256 sgd_solver.cpp:106] Iteration 9555, lr = 5e-05
I0403 04:36:24.608644 30256 solver.cpp:228] Iteration 9576, loss = 6.04078e-05
I0403 04:36:24.608773 30256 solver.cpp:244]     Train net output #0: loss = 6.02952e-05 (* 1 = 6.02952e-05 loss)
I0403 04:36:24.794040 30256 sgd_solver.cpp:106] Iteration 9576, lr = 5e-05
I0403 04:36:39.749711 30256 solver.cpp:228] Iteration 9597, loss = 0.00110984
I0403 04:36:39.749812 30256 solver.cpp:244]     Train net output #0: loss = 0.00110973 (* 1 = 0.00110973 loss)
I0403 04:36:39.926756 30256 sgd_solver.cpp:106] Iteration 9597, lr = 5e-05
I0403 04:36:51.455584 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_9614.caffemodel
I0403 04:36:54.266536 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_9614.solverstate
I0403 04:36:56.178882 30256 solver.cpp:337] Iteration 9614, Testing net (#0)
I0403 04:37:19.633306 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992571
I0403 04:37:19.633422 30256 solver.cpp:404]     Test net output #1: loss = 0.0268744 (* 1 = 0.0268744 loss)
I0403 04:37:23.032903 30256 solver.cpp:228] Iteration 9618, loss = 0.00150003
I0403 04:37:23.032997 30256 solver.cpp:244]     Train net output #0: loss = 0.00149992 (* 1 = 0.00149992 loss)
I0403 04:37:23.206535 30256 sgd_solver.cpp:106] Iteration 9618, lr = 5e-05
I0403 04:37:38.312960 30256 solver.cpp:228] Iteration 9639, loss = 0.000193663
I0403 04:37:38.313266 30256 solver.cpp:244]     Train net output #0: loss = 0.000193551 (* 1 = 0.000193551 loss)
I0403 04:37:38.495029 30256 sgd_solver.cpp:106] Iteration 9639, lr = 5e-05
I0403 04:37:53.378618 30256 solver.cpp:228] Iteration 9660, loss = 0.00064539
I0403 04:37:53.378718 30256 solver.cpp:244]     Train net output #0: loss = 0.000645278 (* 1 = 0.000645278 loss)
I0403 04:37:53.544759 30256 sgd_solver.cpp:106] Iteration 9660, lr = 5e-05
I0403 04:38:08.573457 30256 solver.cpp:228] Iteration 9681, loss = 0.000189888
I0403 04:38:08.573789 30256 solver.cpp:244]     Train net output #0: loss = 0.000189777 (* 1 = 0.000189777 loss)
I0403 04:38:08.717244 30256 sgd_solver.cpp:106] Iteration 9681, lr = 5e-05
I0403 04:38:23.715258 30256 solver.cpp:228] Iteration 9702, loss = 0.000748992
I0403 04:38:23.716306 30256 solver.cpp:244]     Train net output #0: loss = 0.00074888 (* 1 = 0.00074888 loss)
I0403 04:38:23.878023 30256 sgd_solver.cpp:106] Iteration 9702, lr = 5e-05
I0403 04:38:39.014008 30256 solver.cpp:228] Iteration 9723, loss = 0.00205654
I0403 04:38:39.014313 30256 solver.cpp:244]     Train net output #0: loss = 0.00205643 (* 1 = 0.00205643 loss)
I0403 04:38:39.205586 30256 sgd_solver.cpp:106] Iteration 9723, lr = 5e-05
I0403 04:38:54.030474 30256 solver.cpp:228] Iteration 9744, loss = 0.000235302
I0403 04:38:54.030586 30256 solver.cpp:244]     Train net output #0: loss = 0.00023519 (* 1 = 0.00023519 loss)
I0403 04:38:54.215585 30256 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 04:39:09.223593 30256 solver.cpp:228] Iteration 9765, loss = 0.000133881
I0403 04:39:09.223913 30256 solver.cpp:244]     Train net output #0: loss = 0.00013377 (* 1 = 0.00013377 loss)
I0403 04:39:09.417083 30256 sgd_solver.cpp:106] Iteration 9765, lr = 5e-05
I0403 04:39:24.260191 30256 solver.cpp:228] Iteration 9786, loss = 0.000415391
I0403 04:39:24.260290 30256 solver.cpp:244]     Train net output #0: loss = 0.00041528 (* 1 = 0.00041528 loss)
I0403 04:39:24.407888 30256 sgd_solver.cpp:106] Iteration 9786, lr = 5e-05
I0403 04:39:39.871186 30256 solver.cpp:228] Iteration 9807, loss = 0.000153086
I0403 04:39:39.871459 30256 solver.cpp:244]     Train net output #0: loss = 0.000152975 (* 1 = 0.000152975 loss)
I0403 04:39:40.048643 30256 sgd_solver.cpp:106] Iteration 9807, lr = 5e-05
I0403 04:39:54.909198 30256 solver.cpp:228] Iteration 9828, loss = 0.00109118
I0403 04:39:54.909310 30256 solver.cpp:244]     Train net output #0: loss = 0.00109107 (* 1 = 0.00109107 loss)
I0403 04:39:55.124763 30256 sgd_solver.cpp:106] Iteration 9828, lr = 5e-05
I0403 04:40:10.060215 30256 solver.cpp:228] Iteration 9849, loss = 0.000488483
I0403 04:40:10.060518 30256 solver.cpp:244]     Train net output #0: loss = 0.000488373 (* 1 = 0.000488373 loss)
I0403 04:40:10.233597 30256 sgd_solver.cpp:106] Iteration 9849, lr = 5e-05
I0403 04:40:25.054544 30256 solver.cpp:228] Iteration 9870, loss = 0.000666945
I0403 04:40:25.054653 30256 solver.cpp:244]     Train net output #0: loss = 0.000666835 (* 1 = 0.000666835 loss)
I0403 04:40:25.245860 30256 sgd_solver.cpp:106] Iteration 9870, lr = 5e-05
I0403 04:40:40.256357 30256 solver.cpp:228] Iteration 9891, loss = 0.000442489
I0403 04:40:40.256674 30256 solver.cpp:244]     Train net output #0: loss = 0.000442379 (* 1 = 0.000442379 loss)
I0403 04:40:40.461308 30256 sgd_solver.cpp:106] Iteration 9891, lr = 5e-05
I0403 04:40:55.476007 30256 solver.cpp:228] Iteration 9912, loss = 3.00007e-05
I0403 04:40:55.476119 30256 solver.cpp:244]     Train net output #0: loss = 2.98902e-05 (* 1 = 2.98902e-05 loss)
I0403 04:40:55.661020 30256 sgd_solver.cpp:106] Iteration 9912, lr = 5e-05
I0403 04:41:10.621161 30256 solver.cpp:228] Iteration 9933, loss = 0.000778091
I0403 04:41:10.621465 30256 solver.cpp:244]     Train net output #0: loss = 0.000777981 (* 1 = 0.000777981 loss)
I0403 04:41:10.799379 30256 sgd_solver.cpp:106] Iteration 9933, lr = 5e-05
I0403 04:41:25.947954 30256 solver.cpp:228] Iteration 9954, loss = 0.000750444
I0403 04:41:25.948063 30256 solver.cpp:244]     Train net output #0: loss = 0.000750333 (* 1 = 0.000750333 loss)
I0403 04:41:26.144662 30256 sgd_solver.cpp:106] Iteration 9954, lr = 5e-05
I0403 04:41:40.997066 30256 solver.cpp:228] Iteration 9975, loss = 0.00455906
I0403 04:41:40.997408 30256 solver.cpp:244]     Train net output #0: loss = 0.00455895 (* 1 = 0.00455895 loss)
I0403 04:41:41.157201 30256 sgd_solver.cpp:106] Iteration 9975, lr = 5e-05
I0403 04:41:56.323642 30256 solver.cpp:228] Iteration 9996, loss = 0.000171216
I0403 04:41:56.323741 30256 solver.cpp:244]     Train net output #0: loss = 0.000171105 (* 1 = 0.000171105 loss)
I0403 04:41:56.470589 30256 sgd_solver.cpp:106] Iteration 9996, lr = 5e-05
I0403 04:42:11.431579 30256 solver.cpp:228] Iteration 10017, loss = 6.07985e-05
I0403 04:42:11.431907 30256 solver.cpp:244]     Train net output #0: loss = 6.06878e-05 (* 1 = 6.06878e-05 loss)
I0403 04:42:11.656998 30256 sgd_solver.cpp:106] Iteration 10017, lr = 5e-05
I0403 04:42:26.697232 30256 solver.cpp:228] Iteration 10038, loss = 7.06562e-05
I0403 04:42:26.697348 30256 solver.cpp:244]     Train net output #0: loss = 7.05454e-05 (* 1 = 7.05454e-05 loss)
I0403 04:42:26.881760 30256 sgd_solver.cpp:106] Iteration 10038, lr = 5e-05
I0403 04:42:35.622315 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_10051.caffemodel
I0403 04:42:38.388149 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_10051.solverstate
I0403 04:42:40.278239 30256 solver.cpp:337] Iteration 10051, Testing net (#0)
I0403 04:43:03.738440 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992857
I0403 04:43:03.738752 30256 solver.cpp:404]     Test net output #1: loss = 0.0258009 (* 1 = 0.0258009 loss)
I0403 04:43:10.016336 30256 solver.cpp:228] Iteration 10059, loss = 0.00111463
I0403 04:43:10.016451 30256 solver.cpp:244]     Train net output #0: loss = 0.00111452 (* 1 = 0.00111452 loss)
I0403 04:43:10.198393 30256 sgd_solver.cpp:106] Iteration 10059, lr = 5e-05
I0403 04:43:24.949095 30256 solver.cpp:228] Iteration 10080, loss = 0.000177574
I0403 04:43:24.949203 30256 solver.cpp:244]     Train net output #0: loss = 0.000177464 (* 1 = 0.000177464 loss)
I0403 04:43:25.156522 30256 sgd_solver.cpp:106] Iteration 10080, lr = 5e-05
I0403 04:43:39.970276 30256 solver.cpp:228] Iteration 10101, loss = 0.00584474
I0403 04:43:39.970556 30256 solver.cpp:244]     Train net output #0: loss = 0.00584463 (* 1 = 0.00584463 loss)
I0403 04:43:40.157047 30256 sgd_solver.cpp:106] Iteration 10101, lr = 5e-05
I0403 04:43:55.000943 30256 solver.cpp:228] Iteration 10122, loss = 3.73368e-05
I0403 04:43:55.001044 30256 solver.cpp:244]     Train net output #0: loss = 3.72272e-05 (* 1 = 3.72272e-05 loss)
I0403 04:43:55.173437 30256 sgd_solver.cpp:106] Iteration 10122, lr = 5e-05
I0403 04:44:10.366760 30256 solver.cpp:228] Iteration 10143, loss = 0.000104672
I0403 04:44:10.367068 30256 solver.cpp:244]     Train net output #0: loss = 0.000104562 (* 1 = 0.000104562 loss)
I0403 04:44:10.547405 30256 sgd_solver.cpp:106] Iteration 10143, lr = 5e-05
I0403 04:44:25.505295 30256 solver.cpp:228] Iteration 10164, loss = 0.00461102
I0403 04:44:25.505409 30256 solver.cpp:244]     Train net output #0: loss = 0.00461091 (* 1 = 0.00461091 loss)
I0403 04:44:25.705243 30256 sgd_solver.cpp:106] Iteration 10164, lr = 5e-05
I0403 04:44:40.840152 30256 solver.cpp:228] Iteration 10185, loss = 0.000473437
I0403 04:44:40.840437 30256 solver.cpp:244]     Train net output #0: loss = 0.000473327 (* 1 = 0.000473327 loss)
I0403 04:44:41.012390 30256 sgd_solver.cpp:106] Iteration 10185, lr = 5e-05
I0403 04:44:56.077463 30256 solver.cpp:228] Iteration 10206, loss = 0.000107476
I0403 04:44:56.077572 30256 solver.cpp:244]     Train net output #0: loss = 0.000107366 (* 1 = 0.000107366 loss)
I0403 04:44:56.275327 30256 sgd_solver.cpp:106] Iteration 10206, lr = 5e-05
I0403 04:45:11.208047 30256 solver.cpp:228] Iteration 10227, loss = 0.000241961
I0403 04:45:11.208360 30256 solver.cpp:244]     Train net output #0: loss = 0.000241852 (* 1 = 0.000241852 loss)
I0403 04:45:11.404002 30256 sgd_solver.cpp:106] Iteration 10227, lr = 5e-05
I0403 04:45:26.262352 30256 solver.cpp:228] Iteration 10248, loss = 0.000228168
I0403 04:45:26.262452 30256 solver.cpp:244]     Train net output #0: loss = 0.000228059 (* 1 = 0.000228059 loss)
I0403 04:45:26.450783 30256 sgd_solver.cpp:106] Iteration 10248, lr = 5e-05
I0403 04:45:41.286463 30256 solver.cpp:228] Iteration 10269, loss = 0.000410027
I0403 04:45:41.286798 30256 solver.cpp:244]     Train net output #0: loss = 0.000409918 (* 1 = 0.000409918 loss)
I0403 04:45:41.461199 30256 sgd_solver.cpp:106] Iteration 10269, lr = 5e-05
I0403 04:45:56.469368 30256 solver.cpp:228] Iteration 10290, loss = 0.000208731
I0403 04:45:56.469466 30256 solver.cpp:244]     Train net output #0: loss = 0.000208621 (* 1 = 0.000208621 loss)
I0403 04:45:56.647493 30256 sgd_solver.cpp:106] Iteration 10290, lr = 5e-05
I0403 04:46:11.459384 30256 solver.cpp:228] Iteration 10311, loss = 0.000219947
I0403 04:46:11.462422 30256 solver.cpp:244]     Train net output #0: loss = 0.000219837 (* 1 = 0.000219837 loss)
I0403 04:46:11.728137 30256 sgd_solver.cpp:106] Iteration 10311, lr = 5e-05
I0403 04:46:26.765724 30256 solver.cpp:228] Iteration 10332, loss = 4.17725e-05
I0403 04:46:26.765836 30256 solver.cpp:244]     Train net output #0: loss = 4.16635e-05 (* 1 = 4.16635e-05 loss)
I0403 04:46:26.945994 30256 sgd_solver.cpp:106] Iteration 10332, lr = 5e-05
I0403 04:46:41.895854 30256 solver.cpp:228] Iteration 10353, loss = 0.00150979
I0403 04:46:41.896173 30256 solver.cpp:244]     Train net output #0: loss = 0.00150968 (* 1 = 0.00150968 loss)
I0403 04:46:42.098279 30256 sgd_solver.cpp:106] Iteration 10353, lr = 5e-05
I0403 04:46:57.036327 30256 solver.cpp:228] Iteration 10374, loss = 0.000202656
I0403 04:46:57.036432 30256 solver.cpp:244]     Train net output #0: loss = 0.000202547 (* 1 = 0.000202547 loss)
I0403 04:46:57.207031 30256 sgd_solver.cpp:106] Iteration 10374, lr = 5e-05
I0403 04:47:12.294363 30256 solver.cpp:228] Iteration 10395, loss = 0.0002275
I0403 04:47:12.298233 30256 solver.cpp:244]     Train net output #0: loss = 0.000227391 (* 1 = 0.000227391 loss)
I0403 04:47:12.444686 30256 sgd_solver.cpp:106] Iteration 10395, lr = 5e-05
I0403 04:47:27.593919 30256 solver.cpp:228] Iteration 10416, loss = 0.000151493
I0403 04:47:27.594033 30256 solver.cpp:244]     Train net output #0: loss = 0.000151383 (* 1 = 0.000151383 loss)
I0403 04:47:27.776340 30256 sgd_solver.cpp:106] Iteration 10416, lr = 5e-05
I0403 04:47:42.669703 30256 solver.cpp:228] Iteration 10437, loss = 0.00479157
I0403 04:47:42.670012 30256 solver.cpp:244]     Train net output #0: loss = 0.00479146 (* 1 = 0.00479146 loss)
I0403 04:47:42.856314 30256 sgd_solver.cpp:106] Iteration 10437, lr = 5e-05
I0403 04:47:57.746966 30256 solver.cpp:228] Iteration 10458, loss = 0.000173403
I0403 04:47:57.747077 30256 solver.cpp:244]     Train net output #0: loss = 0.000173293 (* 1 = 0.000173293 loss)
I0403 04:47:57.946472 30256 sgd_solver.cpp:106] Iteration 10458, lr = 5e-05
I0403 04:48:13.109045 30256 solver.cpp:228] Iteration 10479, loss = 0.000214362
I0403 04:48:13.109344 30256 solver.cpp:244]     Train net output #0: loss = 0.000214252 (* 1 = 0.000214252 loss)
I0403 04:48:13.286388 30256 sgd_solver.cpp:106] Iteration 10479, lr = 5e-05
I0403 04:48:19.026820 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_10488.caffemodel
I0403 04:48:21.812711 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_10488.solverstate
I0403 04:48:23.668232 30256 solver.cpp:337] Iteration 10488, Testing net (#0)
I0403 04:48:47.129135 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992952
I0403 04:48:47.129423 30256 solver.cpp:404]     Test net output #1: loss = 0.0268442 (* 1 = 0.0268442 loss)
I0403 04:48:56.369354 30256 solver.cpp:228] Iteration 10500, loss = 0.000195826
I0403 04:48:56.369449 30256 solver.cpp:244]     Train net output #0: loss = 0.000195716 (* 1 = 0.000195716 loss)
I0403 04:48:56.546335 30256 sgd_solver.cpp:106] Iteration 10500, lr = 5e-05
I0403 04:49:11.463964 30256 solver.cpp:228] Iteration 10521, loss = 0.00129277
I0403 04:49:11.464081 30256 solver.cpp:244]     Train net output #0: loss = 0.00129266 (* 1 = 0.00129266 loss)
I0403 04:49:11.659544 30256 sgd_solver.cpp:106] Iteration 10521, lr = 5e-05
I0403 04:49:26.610889 30256 solver.cpp:228] Iteration 10542, loss = 4.13863e-05
I0403 04:49:26.611212 30256 solver.cpp:244]     Train net output #0: loss = 4.12772e-05 (* 1 = 4.12772e-05 loss)
I0403 04:49:26.777395 30256 sgd_solver.cpp:106] Iteration 10542, lr = 5e-05
I0403 04:49:41.677922 30256 solver.cpp:228] Iteration 10563, loss = 4.09505e-05
I0403 04:49:41.678033 30256 solver.cpp:244]     Train net output #0: loss = 4.08417e-05 (* 1 = 4.08417e-05 loss)
I0403 04:49:41.869607 30256 sgd_solver.cpp:106] Iteration 10563, lr = 5e-05
I0403 04:49:56.916326 30256 solver.cpp:228] Iteration 10584, loss = 0.00719766
I0403 04:49:56.916632 30256 solver.cpp:244]     Train net output #0: loss = 0.00719755 (* 1 = 0.00719755 loss)
I0403 04:49:57.115548 30256 sgd_solver.cpp:106] Iteration 10584, lr = 5e-05
I0403 04:50:12.101433 30256 solver.cpp:228] Iteration 10605, loss = 0.000131311
I0403 04:50:12.101547 30256 solver.cpp:244]     Train net output #0: loss = 0.000131203 (* 1 = 0.000131203 loss)
I0403 04:50:12.284515 30256 sgd_solver.cpp:106] Iteration 10605, lr = 5e-05
I0403 04:50:27.283120 30256 solver.cpp:228] Iteration 10626, loss = 0.000187556
I0403 04:50:27.283423 30256 solver.cpp:244]     Train net output #0: loss = 0.000187447 (* 1 = 0.000187447 loss)
I0403 04:50:27.460213 30256 sgd_solver.cpp:106] Iteration 10626, lr = 5e-05
I0403 04:50:42.399086 30256 solver.cpp:228] Iteration 10647, loss = 0.000532748
I0403 04:50:42.399194 30256 solver.cpp:244]     Train net output #0: loss = 0.00053264 (* 1 = 0.00053264 loss)
I0403 04:50:42.586899 30256 sgd_solver.cpp:106] Iteration 10647, lr = 5e-05
I0403 04:50:57.457623 30256 solver.cpp:228] Iteration 10668, loss = 0.000143337
I0403 04:50:57.457926 30256 solver.cpp:244]     Train net output #0: loss = 0.000143229 (* 1 = 0.000143229 loss)
I0403 04:50:57.637363 30256 sgd_solver.cpp:106] Iteration 10668, lr = 5e-05
I0403 04:51:12.642941 30256 solver.cpp:228] Iteration 10689, loss = 7.34379e-05
I0403 04:51:12.643054 30256 solver.cpp:244]     Train net output #0: loss = 7.33296e-05 (* 1 = 7.33296e-05 loss)
I0403 04:51:12.824014 30256 sgd_solver.cpp:106] Iteration 10689, lr = 5e-05
I0403 04:51:27.870036 30256 solver.cpp:228] Iteration 10710, loss = 0.000142386
I0403 04:51:27.870324 30256 solver.cpp:244]     Train net output #0: loss = 0.000142278 (* 1 = 0.000142278 loss)
I0403 04:51:28.054960 30256 sgd_solver.cpp:106] Iteration 10710, lr = 5e-05
I0403 04:51:43.215255 30256 solver.cpp:228] Iteration 10731, loss = 4.34677e-05
I0403 04:51:43.215361 30256 solver.cpp:244]     Train net output #0: loss = 4.33593e-05 (* 1 = 4.33593e-05 loss)
I0403 04:51:43.393093 30256 sgd_solver.cpp:106] Iteration 10731, lr = 5e-05
I0403 04:51:58.447893 30256 solver.cpp:228] Iteration 10752, loss = 0.0010368
I0403 04:51:58.448186 30256 solver.cpp:244]     Train net output #0: loss = 0.00103669 (* 1 = 0.00103669 loss)
I0403 04:51:58.617540 30256 sgd_solver.cpp:106] Iteration 10752, lr = 5e-05
I0403 04:52:13.620241 30256 solver.cpp:228] Iteration 10773, loss = 0.000245131
I0403 04:52:13.620342 30256 solver.cpp:244]     Train net output #0: loss = 0.000245022 (* 1 = 0.000245022 loss)
I0403 04:52:13.741365 30256 sgd_solver.cpp:106] Iteration 10773, lr = 5e-05
I0403 04:52:28.676900 30256 solver.cpp:228] Iteration 10794, loss = 7.39161e-05
I0403 04:52:28.677189 30256 solver.cpp:244]     Train net output #0: loss = 7.3807e-05 (* 1 = 7.3807e-05 loss)
I0403 04:52:28.846227 30256 sgd_solver.cpp:106] Iteration 10794, lr = 5e-05
I0403 04:52:43.818692 30256 solver.cpp:228] Iteration 10815, loss = 4.75626e-05
I0403 04:52:43.818805 30256 solver.cpp:244]     Train net output #0: loss = 4.74535e-05 (* 1 = 4.74535e-05 loss)
I0403 04:52:44.012223 30256 sgd_solver.cpp:106] Iteration 10815, lr = 5e-05
I0403 04:52:58.816920 30256 solver.cpp:228] Iteration 10836, loss = 7.9914e-05
I0403 04:52:58.817227 30256 solver.cpp:244]     Train net output #0: loss = 7.98046e-05 (* 1 = 7.98046e-05 loss)
I0403 04:52:58.986349 30256 sgd_solver.cpp:106] Iteration 10836, lr = 5e-05
I0403 04:53:14.025048 30256 solver.cpp:228] Iteration 10857, loss = 0.000198546
I0403 04:53:14.025161 30256 solver.cpp:244]     Train net output #0: loss = 0.000198437 (* 1 = 0.000198437 loss)
I0403 04:53:14.208287 30256 sgd_solver.cpp:106] Iteration 10857, lr = 5e-05
I0403 04:53:29.211163 30256 solver.cpp:228] Iteration 10878, loss = 0.000118556
I0403 04:53:29.211477 30256 solver.cpp:244]     Train net output #0: loss = 0.000118446 (* 1 = 0.000118446 loss)
I0403 04:53:29.415362 30256 sgd_solver.cpp:106] Iteration 10878, lr = 5e-05
I0403 04:53:44.313400 30256 solver.cpp:228] Iteration 10899, loss = 0.00141009
I0403 04:53:44.313499 30256 solver.cpp:244]     Train net output #0: loss = 0.00140998 (* 1 = 0.00140998 loss)
I0403 04:53:44.491479 30256 sgd_solver.cpp:106] Iteration 10899, lr = 5e-05
I0403 04:53:59.439165 30256 solver.cpp:228] Iteration 10920, loss = 0.00114397
I0403 04:53:59.439463 30256 solver.cpp:244]     Train net output #0: loss = 0.00114386 (* 1 = 0.00114386 loss)
I0403 04:53:59.625032 30256 sgd_solver.cpp:106] Iteration 10920, lr = 5e-05
I0403 04:54:02.472308 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_10925.caffemodel
I0403 04:54:05.254983 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_10925.solverstate
I0403 04:54:07.077201 30256 solver.cpp:337] Iteration 10925, Testing net (#0)
I0403 04:54:30.549677 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992571
I0403 04:54:30.549967 30256 solver.cpp:404]     Test net output #1: loss = 0.0271082 (* 1 = 0.0271082 loss)
I0403 04:54:42.762071 30256 solver.cpp:228] Iteration 10941, loss = 8.88255e-05
I0403 04:54:42.762171 30256 solver.cpp:244]     Train net output #0: loss = 8.87167e-05 (* 1 = 8.87167e-05 loss)
I0403 04:54:42.933796 30256 sgd_solver.cpp:106] Iteration 10941, lr = 5e-05
I0403 04:54:58.026336 30256 solver.cpp:228] Iteration 10962, loss = 0.000658486
I0403 04:54:58.026439 30256 solver.cpp:244]     Train net output #0: loss = 0.000658377 (* 1 = 0.000658377 loss)
I0403 04:54:58.202066 30256 sgd_solver.cpp:106] Iteration 10962, lr = 5e-05
I0403 04:55:13.347620 30256 solver.cpp:228] Iteration 10983, loss = 0.000177562
I0403 04:55:13.347947 30256 solver.cpp:244]     Train net output #0: loss = 0.000177453 (* 1 = 0.000177453 loss)
I0403 04:55:13.552049 30256 sgd_solver.cpp:106] Iteration 10983, lr = 5e-05
I0403 04:55:28.590602 30256 solver.cpp:228] Iteration 11004, loss = 8.5266e-05
I0403 04:55:28.590713 30256 solver.cpp:244]     Train net output #0: loss = 8.51581e-05 (* 1 = 8.51581e-05 loss)
I0403 04:55:28.761250 30256 sgd_solver.cpp:106] Iteration 11004, lr = 5e-05
I0403 04:55:43.804916 30256 solver.cpp:228] Iteration 11025, loss = 0.000282788
I0403 04:55:43.805215 30256 solver.cpp:244]     Train net output #0: loss = 0.00028268 (* 1 = 0.00028268 loss)
I0403 04:55:43.985661 30256 sgd_solver.cpp:106] Iteration 11025, lr = 5e-05
I0403 04:55:58.799199 30256 solver.cpp:228] Iteration 11046, loss = 0.000494809
I0403 04:55:58.799296 30256 solver.cpp:244]     Train net output #0: loss = 0.000494701 (* 1 = 0.000494701 loss)
I0403 04:55:58.975148 30256 sgd_solver.cpp:106] Iteration 11046, lr = 5e-05
I0403 04:56:13.932570 30256 solver.cpp:228] Iteration 11067, loss = 0.00134599
I0403 04:56:13.932860 30256 solver.cpp:244]     Train net output #0: loss = 0.00134589 (* 1 = 0.00134589 loss)
I0403 04:56:14.109810 30256 sgd_solver.cpp:106] Iteration 11067, lr = 5e-05
I0403 04:56:28.950829 30256 solver.cpp:228] Iteration 11088, loss = 0.000703146
I0403 04:56:28.950940 30256 solver.cpp:244]     Train net output #0: loss = 0.000703038 (* 1 = 0.000703038 loss)
I0403 04:56:29.137944 30256 sgd_solver.cpp:106] Iteration 11088, lr = 5e-05
I0403 04:56:44.110764 30256 solver.cpp:228] Iteration 11109, loss = 0.000480293
I0403 04:56:44.114764 30256 solver.cpp:244]     Train net output #0: loss = 0.000480184 (* 1 = 0.000480184 loss)
I0403 04:56:44.331631 30256 sgd_solver.cpp:106] Iteration 11109, lr = 5e-05
I0403 04:56:59.354972 30256 solver.cpp:228] Iteration 11130, loss = 0.000239003
I0403 04:56:59.355078 30256 solver.cpp:244]     Train net output #0: loss = 0.000238892 (* 1 = 0.000238892 loss)
I0403 04:56:59.534973 30256 sgd_solver.cpp:106] Iteration 11130, lr = 5e-05
I0403 04:57:14.456058 30256 solver.cpp:228] Iteration 11151, loss = 0.000105152
I0403 04:57:14.456364 30256 solver.cpp:244]     Train net output #0: loss = 0.000105042 (* 1 = 0.000105042 loss)
I0403 04:57:14.642812 30256 sgd_solver.cpp:106] Iteration 11151, lr = 5e-05
I0403 04:57:29.693784 30256 solver.cpp:228] Iteration 11172, loss = 0.000179788
I0403 04:57:29.693883 30256 solver.cpp:244]     Train net output #0: loss = 0.000179678 (* 1 = 0.000179678 loss)
I0403 04:57:29.847723 30256 sgd_solver.cpp:106] Iteration 11172, lr = 5e-05
I0403 04:57:44.910553 30256 solver.cpp:228] Iteration 11193, loss = 0.000413233
I0403 04:57:44.910856 30256 solver.cpp:244]     Train net output #0: loss = 0.000413123 (* 1 = 0.000413123 loss)
I0403 04:57:45.093708 30256 sgd_solver.cpp:106] Iteration 11193, lr = 5e-05
I0403 04:58:00.030663 30256 solver.cpp:228] Iteration 11214, loss = 0.000105676
I0403 04:58:00.030761 30256 solver.cpp:244]     Train net output #0: loss = 0.000105567 (* 1 = 0.000105567 loss)
I0403 04:58:00.208251 30256 sgd_solver.cpp:106] Iteration 11214, lr = 5e-05
I0403 04:58:15.393129 30256 solver.cpp:228] Iteration 11235, loss = 0.000250133
I0403 04:58:15.393426 30256 solver.cpp:244]     Train net output #0: loss = 0.000250023 (* 1 = 0.000250023 loss)
I0403 04:58:15.500633 30256 sgd_solver.cpp:106] Iteration 11235, lr = 5e-05
I0403 04:58:30.497490 30256 solver.cpp:228] Iteration 11256, loss = 0.00697757
I0403 04:58:30.497587 30256 solver.cpp:244]     Train net output #0: loss = 0.00697746 (* 1 = 0.00697746 loss)
I0403 04:58:30.660356 30256 sgd_solver.cpp:106] Iteration 11256, lr = 5e-05
I0403 04:58:45.749598 30256 solver.cpp:228] Iteration 11277, loss = 0.000150553
I0403 04:58:45.749912 30256 solver.cpp:244]     Train net output #0: loss = 0.000150442 (* 1 = 0.000150442 loss)
I0403 04:58:45.941594 30256 sgd_solver.cpp:106] Iteration 11277, lr = 5e-05
I0403 04:59:00.697620 30256 solver.cpp:228] Iteration 11298, loss = 0.000313358
I0403 04:59:00.697720 30256 solver.cpp:244]     Train net output #0: loss = 0.000313248 (* 1 = 0.000313248 loss)
I0403 04:59:00.876339 30256 sgd_solver.cpp:106] Iteration 11298, lr = 5e-05
I0403 04:59:16.006024 30256 solver.cpp:228] Iteration 11319, loss = 6.30757e-05
I0403 04:59:16.006307 30256 solver.cpp:244]     Train net output #0: loss = 6.29657e-05 (* 1 = 6.29657e-05 loss)
I0403 04:59:16.184684 30256 sgd_solver.cpp:106] Iteration 11319, lr = 5e-05
I0403 04:59:31.258169 30256 solver.cpp:228] Iteration 11340, loss = 2.90535e-05
I0403 04:59:31.258280 30256 solver.cpp:244]     Train net output #0: loss = 2.89436e-05 (* 1 = 2.89436e-05 loss)
I0403 04:59:31.466799 30256 sgd_solver.cpp:106] Iteration 11340, lr = 5e-05
I0403 04:59:46.401499 30256 solver.cpp:228] Iteration 11361, loss = 0.00501146
I0403 04:59:46.406704 30256 solver.cpp:244]     Train net output #0: loss = 0.00501135 (* 1 = 0.00501135 loss)
I0403 04:59:46.630668 30256 sgd_solver.cpp:106] Iteration 11361, lr = 5e-05
I0403 04:59:46.630895 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_11362.caffemodel
I0403 04:59:49.398562 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_11362.solverstate
I0403 04:59:51.252797 30256 solver.cpp:337] Iteration 11362, Testing net (#0)
I0403 05:00:14.719777 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992667
I0403 05:00:14.719883 30256 solver.cpp:404]     Test net output #1: loss = 0.0269735 (* 1 = 0.0269735 loss)
I0403 05:00:29.859855 30256 solver.cpp:228] Iteration 11382, loss = 0.000339732
I0403 05:00:29.860160 30256 solver.cpp:244]     Train net output #0: loss = 0.000339626 (* 1 = 0.000339626 loss)
I0403 05:00:30.045372 30256 sgd_solver.cpp:106] Iteration 11382, lr = 5e-05
I0403 05:00:45.085809 30256 solver.cpp:228] Iteration 11403, loss = 0.00617392
I0403 05:00:45.085921 30256 solver.cpp:244]     Train net output #0: loss = 0.00617381 (* 1 = 0.00617381 loss)
I0403 05:00:45.266856 30256 sgd_solver.cpp:106] Iteration 11403, lr = 5e-05
I0403 05:01:00.179309 30256 solver.cpp:228] Iteration 11424, loss = 0.00102434
I0403 05:01:00.179618 30256 solver.cpp:244]     Train net output #0: loss = 0.00102423 (* 1 = 0.00102423 loss)
I0403 05:01:00.375031 30256 sgd_solver.cpp:106] Iteration 11424, lr = 5e-05
I0403 05:01:15.173671 30256 solver.cpp:228] Iteration 11445, loss = 0.00026671
I0403 05:01:15.173775 30256 solver.cpp:244]     Train net output #0: loss = 0.0002666 (* 1 = 0.0002666 loss)
I0403 05:01:15.341042 30256 sgd_solver.cpp:106] Iteration 11445, lr = 5e-05
I0403 05:01:30.375154 30256 solver.cpp:228] Iteration 11466, loss = 7.13123e-05
I0403 05:01:30.381698 30256 solver.cpp:244]     Train net output #0: loss = 7.12034e-05 (* 1 = 7.12034e-05 loss)
I0403 05:01:30.577808 30256 sgd_solver.cpp:106] Iteration 11466, lr = 5e-05
I0403 05:01:45.577807 30256 solver.cpp:228] Iteration 11487, loss = 0.000216959
I0403 05:01:45.577921 30256 solver.cpp:244]     Train net output #0: loss = 0.000216849 (* 1 = 0.000216849 loss)
I0403 05:01:45.765754 30256 sgd_solver.cpp:106] Iteration 11487, lr = 5e-05
I0403 05:02:00.892130 30256 solver.cpp:228] Iteration 11508, loss = 2.7523e-05
I0403 05:02:00.892421 30256 solver.cpp:244]     Train net output #0: loss = 2.74142e-05 (* 1 = 2.74142e-05 loss)
I0403 05:02:01.092120 30256 sgd_solver.cpp:106] Iteration 11508, lr = 5e-05
I0403 05:02:16.094137 30256 solver.cpp:228] Iteration 11529, loss = 0.00100941
I0403 05:02:16.094236 30256 solver.cpp:244]     Train net output #0: loss = 0.0010093 (* 1 = 0.0010093 loss)
I0403 05:02:16.259485 30256 sgd_solver.cpp:106] Iteration 11529, lr = 5e-05
I0403 05:02:31.209291 30256 solver.cpp:228] Iteration 11550, loss = 0.000642509
I0403 05:02:31.209617 30256 solver.cpp:244]     Train net output #0: loss = 0.0006424 (* 1 = 0.0006424 loss)
I0403 05:02:31.414506 30256 sgd_solver.cpp:106] Iteration 11550, lr = 5e-05
I0403 05:02:46.407343 30256 solver.cpp:228] Iteration 11571, loss = 9.02575e-05
I0403 05:02:46.407457 30256 solver.cpp:244]     Train net output #0: loss = 9.01483e-05 (* 1 = 9.01483e-05 loss)
I0403 05:02:46.608431 30256 sgd_solver.cpp:106] Iteration 11571, lr = 5e-05
I0403 05:03:01.585374 30256 solver.cpp:228] Iteration 11592, loss = 0.00102762
I0403 05:03:01.585711 30256 solver.cpp:244]     Train net output #0: loss = 0.00102751 (* 1 = 0.00102751 loss)
I0403 05:03:01.766306 30256 sgd_solver.cpp:106] Iteration 11592, lr = 5e-05
I0403 05:03:16.713357 30256 solver.cpp:228] Iteration 11613, loss = 0.00150607
I0403 05:03:16.713457 30256 solver.cpp:244]     Train net output #0: loss = 0.00150596 (* 1 = 0.00150596 loss)
I0403 05:03:16.852241 30256 sgd_solver.cpp:106] Iteration 11613, lr = 5e-05
I0403 05:03:32.015364 30256 solver.cpp:228] Iteration 11634, loss = 0.000712718
I0403 05:03:32.015652 30256 solver.cpp:244]     Train net output #0: loss = 0.000712608 (* 1 = 0.000712608 loss)
I0403 05:03:32.178568 30256 sgd_solver.cpp:106] Iteration 11634, lr = 5e-05
I0403 05:03:47.285552 30256 solver.cpp:228] Iteration 11655, loss = 0.000933615
I0403 05:03:47.285676 30256 solver.cpp:244]     Train net output #0: loss = 0.000933505 (* 1 = 0.000933505 loss)
I0403 05:03:47.490038 30256 sgd_solver.cpp:106] Iteration 11655, lr = 5e-05
I0403 05:04:02.651185 30256 solver.cpp:228] Iteration 11676, loss = 0.000321731
I0403 05:04:02.651484 30256 solver.cpp:244]     Train net output #0: loss = 0.000321622 (* 1 = 0.000321622 loss)
I0403 05:04:02.828788 30256 sgd_solver.cpp:106] Iteration 11676, lr = 5e-05
I0403 05:04:17.914896 30256 solver.cpp:228] Iteration 11697, loss = 0.000547719
I0403 05:04:17.914979 30256 solver.cpp:244]     Train net output #0: loss = 0.000547609 (* 1 = 0.000547609 loss)
I0403 05:04:18.048739 30256 sgd_solver.cpp:106] Iteration 11697, lr = 5e-05
I0403 05:04:33.002145 30256 solver.cpp:228] Iteration 11718, loss = 0.000175627
I0403 05:04:33.002444 30256 solver.cpp:244]     Train net output #0: loss = 0.000175516 (* 1 = 0.000175516 loss)
I0403 05:04:33.172186 30256 sgd_solver.cpp:106] Iteration 11718, lr = 5e-05
I0403 05:04:48.118532 30256 solver.cpp:228] Iteration 11739, loss = 0.000399557
I0403 05:04:48.118664 30256 solver.cpp:244]     Train net output #0: loss = 0.000399446 (* 1 = 0.000399446 loss)
I0403 05:04:48.287027 30256 sgd_solver.cpp:106] Iteration 11739, lr = 5e-05
I0403 05:05:03.169544 30256 solver.cpp:228] Iteration 11760, loss = 0.000211211
I0403 05:05:03.169865 30256 solver.cpp:244]     Train net output #0: loss = 0.0002111 (* 1 = 0.0002111 loss)
I0403 05:05:03.364043 30256 sgd_solver.cpp:106] Iteration 11760, lr = 5e-05
I0403 05:05:18.219804 30256 solver.cpp:228] Iteration 11781, loss = 0.000135363
I0403 05:05:18.219915 30256 solver.cpp:244]     Train net output #0: loss = 0.000135253 (* 1 = 0.000135253 loss)
I0403 05:05:18.417806 30256 sgd_solver.cpp:106] Iteration 11781, lr = 5e-05
I0403 05:05:30.625597 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_11799.caffemodel
I0403 05:05:33.388880 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_11799.solverstate
I0403 05:05:35.296533 30256 solver.cpp:337] Iteration 11799, Testing net (#0)
I0403 05:05:58.754067 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992476
I0403 05:05:58.754175 30256 solver.cpp:404]     Test net output #1: loss = 0.0269786 (* 1 = 0.0269786 loss)
I0403 05:06:01.499932 30256 solver.cpp:228] Iteration 11802, loss = 0.00375341
I0403 05:06:01.500030 30256 solver.cpp:244]     Train net output #0: loss = 0.0037533 (* 1 = 0.0037533 loss)
I0403 05:06:01.677826 30256 sgd_solver.cpp:106] Iteration 11802, lr = 5e-05
I0403 05:06:16.796564 30256 solver.cpp:228] Iteration 11823, loss = 2.64817e-05
I0403 05:06:16.796860 30256 solver.cpp:244]     Train net output #0: loss = 2.63707e-05 (* 1 = 2.63707e-05 loss)
I0403 05:06:16.970528 30256 sgd_solver.cpp:106] Iteration 11823, lr = 5e-05
I0403 05:06:31.776082 30256 solver.cpp:228] Iteration 11844, loss = 0.0100834
I0403 05:06:31.776196 30256 solver.cpp:244]     Train net output #0: loss = 0.0100833 (* 1 = 0.0100833 loss)
I0403 05:06:31.973892 30256 sgd_solver.cpp:106] Iteration 11844, lr = 5e-05
I0403 05:06:47.077733 30256 solver.cpp:228] Iteration 11865, loss = 0.000472745
I0403 05:06:47.078052 30256 solver.cpp:244]     Train net output #0: loss = 0.000472633 (* 1 = 0.000472633 loss)
I0403 05:06:47.276371 30256 sgd_solver.cpp:106] Iteration 11865, lr = 5e-05
I0403 05:07:02.079056 30256 solver.cpp:228] Iteration 11886, loss = 0.000132947
I0403 05:07:02.079154 30256 solver.cpp:244]     Train net output #0: loss = 0.000132835 (* 1 = 0.000132835 loss)
I0403 05:07:02.256932 30256 sgd_solver.cpp:106] Iteration 11886, lr = 5e-05
I0403 05:07:17.352195 30256 solver.cpp:228] Iteration 11907, loss = 0.000161063
I0403 05:07:17.352501 30256 solver.cpp:244]     Train net output #0: loss = 0.000160951 (* 1 = 0.000160951 loss)
I0403 05:07:17.535090 30256 sgd_solver.cpp:106] Iteration 11907, lr = 5e-05
I0403 05:07:32.537541 30256 solver.cpp:228] Iteration 11928, loss = 0.000233331
I0403 05:07:32.537642 30256 solver.cpp:244]     Train net output #0: loss = 0.000233219 (* 1 = 0.000233219 loss)
I0403 05:07:32.716835 30256 sgd_solver.cpp:106] Iteration 11928, lr = 5e-05
I0403 05:07:47.718266 30256 solver.cpp:228] Iteration 11949, loss = 3.98303e-05
I0403 05:07:47.718566 30256 solver.cpp:244]     Train net output #0: loss = 3.97183e-05 (* 1 = 3.97183e-05 loss)
I0403 05:07:47.885962 30256 sgd_solver.cpp:106] Iteration 11949, lr = 5e-05
I0403 05:08:03.016600 30256 solver.cpp:228] Iteration 11970, loss = 0.00210606
I0403 05:08:03.016700 30256 solver.cpp:244]     Train net output #0: loss = 0.00210595 (* 1 = 0.00210595 loss)
I0403 05:08:03.187943 30256 sgd_solver.cpp:106] Iteration 11970, lr = 5e-05
I0403 05:08:18.194080 30256 solver.cpp:228] Iteration 11991, loss = 0.00294511
I0403 05:08:18.194406 30256 solver.cpp:244]     Train net output #0: loss = 0.002945 (* 1 = 0.002945 loss)
I0403 05:08:18.385005 30256 sgd_solver.cpp:106] Iteration 11991, lr = 5e-05
I0403 05:08:33.278733 30256 solver.cpp:228] Iteration 12012, loss = 0.0010727
I0403 05:08:33.278843 30256 solver.cpp:244]     Train net output #0: loss = 0.00107259 (* 1 = 0.00107259 loss)
I0403 05:08:33.459714 30256 sgd_solver.cpp:106] Iteration 12012, lr = 5e-05
I0403 05:08:48.231801 30256 solver.cpp:228] Iteration 12033, loss = 0.00373173
I0403 05:08:48.232444 30256 solver.cpp:244]     Train net output #0: loss = 0.00373162 (* 1 = 0.00373162 loss)
I0403 05:08:48.451390 30256 sgd_solver.cpp:106] Iteration 12033, lr = 5e-05
I0403 05:09:03.474685 30256 solver.cpp:228] Iteration 12054, loss = 0.000254832
I0403 05:09:03.474784 30256 solver.cpp:244]     Train net output #0: loss = 0.000254721 (* 1 = 0.000254721 loss)
I0403 05:09:03.652390 30256 sgd_solver.cpp:106] Iteration 12054, lr = 5e-05
I0403 05:09:18.615439 30256 solver.cpp:228] Iteration 12075, loss = 0.00063731
I0403 05:09:18.615751 30256 solver.cpp:244]     Train net output #0: loss = 0.000637198 (* 1 = 0.000637198 loss)
I0403 05:09:18.811035 30256 sgd_solver.cpp:106] Iteration 12075, lr = 5e-05
I0403 05:09:33.737217 30256 solver.cpp:228] Iteration 12096, loss = 0.000610535
I0403 05:09:33.737323 30256 solver.cpp:244]     Train net output #0: loss = 0.000610423 (* 1 = 0.000610423 loss)
I0403 05:09:33.914302 30256 sgd_solver.cpp:106] Iteration 12096, lr = 5e-05
I0403 05:09:48.965654 30256 solver.cpp:228] Iteration 12117, loss = 7.25829e-05
I0403 05:09:48.965956 30256 solver.cpp:244]     Train net output #0: loss = 7.24706e-05 (* 1 = 7.24706e-05 loss)
I0403 05:09:49.149627 30256 sgd_solver.cpp:106] Iteration 12117, lr = 5e-05
I0403 05:10:04.210373 30256 solver.cpp:228] Iteration 12138, loss = 6.92251e-06
I0403 05:10:04.210485 30256 solver.cpp:244]     Train net output #0: loss = 6.81012e-06 (* 1 = 6.81012e-06 loss)
I0403 05:10:04.395699 30256 sgd_solver.cpp:106] Iteration 12138, lr = 5e-05
I0403 05:10:19.279438 30256 solver.cpp:228] Iteration 12159, loss = 5.54825e-05
I0403 05:10:19.279742 30256 solver.cpp:244]     Train net output #0: loss = 5.53701e-05 (* 1 = 5.53701e-05 loss)
I0403 05:10:19.465548 30256 sgd_solver.cpp:106] Iteration 12159, lr = 5e-05
I0403 05:10:34.309438 30256 solver.cpp:228] Iteration 12180, loss = 0.000118663
I0403 05:10:34.309551 30256 solver.cpp:244]     Train net output #0: loss = 0.000118551 (* 1 = 0.000118551 loss)
I0403 05:10:34.500912 30256 sgd_solver.cpp:106] Iteration 12180, lr = 5e-05
I0403 05:10:49.401291 30256 solver.cpp:228] Iteration 12201, loss = 0.000152693
I0403 05:10:49.401612 30256 solver.cpp:244]     Train net output #0: loss = 0.00015258 (* 1 = 0.00015258 loss)
I0403 05:10:49.581099 30256 sgd_solver.cpp:106] Iteration 12201, lr = 5e-05
I0403 05:11:04.506883 30256 solver.cpp:228] Iteration 12222, loss = 0.0196166
I0403 05:11:04.506980 30256 solver.cpp:244]     Train net output #0: loss = 0.0196165 (* 1 = 0.0196165 loss)
I0403 05:11:04.676758 30256 sgd_solver.cpp:106] Iteration 12222, lr = 5e-05
I0403 05:11:14.117215 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_12236.caffemodel
I0403 05:11:16.851975 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_12236.solverstate
I0403 05:11:18.742918 30256 solver.cpp:337] Iteration 12236, Testing net (#0)
I0403 05:11:42.201537 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992857
I0403 05:11:42.201874 30256 solver.cpp:404]     Test net output #1: loss = 0.0267424 (* 1 = 0.0267424 loss)
I0403 05:11:47.918534 30256 solver.cpp:228] Iteration 12243, loss = 0.000233434
I0403 05:11:47.918635 30256 solver.cpp:244]     Train net output #0: loss = 0.000233321 (* 1 = 0.000233321 loss)
I0403 05:11:48.098345 30256 sgd_solver.cpp:106] Iteration 12243, lr = 5e-05
I0403 05:12:03.151777 30256 solver.cpp:228] Iteration 12264, loss = 0.000300561
I0403 05:12:03.151904 30256 solver.cpp:244]     Train net output #0: loss = 0.000300448 (* 1 = 0.000300448 loss)
I0403 05:12:03.338778 30256 sgd_solver.cpp:106] Iteration 12264, lr = 5e-05
I0403 05:12:18.286603 30256 solver.cpp:228] Iteration 12285, loss = 0.000283878
I0403 05:12:18.286913 30256 solver.cpp:244]     Train net output #0: loss = 0.000283765 (* 1 = 0.000283765 loss)
I0403 05:12:18.454465 30256 sgd_solver.cpp:106] Iteration 12285, lr = 5e-05
I0403 05:12:33.596590 30256 solver.cpp:228] Iteration 12306, loss = 2.44391e-05
I0403 05:12:33.596688 30256 solver.cpp:244]     Train net output #0: loss = 2.43254e-05 (* 1 = 2.43254e-05 loss)
I0403 05:12:33.753603 30256 sgd_solver.cpp:106] Iteration 12306, lr = 5e-05
I0403 05:12:48.860453 30256 solver.cpp:228] Iteration 12327, loss = 8.52632e-05
I0403 05:12:48.860735 30256 solver.cpp:244]     Train net output #0: loss = 8.51497e-05 (* 1 = 8.51497e-05 loss)
I0403 05:12:49.026479 30256 sgd_solver.cpp:106] Iteration 12327, lr = 5e-05
I0403 05:13:04.148623 30256 solver.cpp:228] Iteration 12348, loss = 0.000224794
I0403 05:13:04.148723 30256 solver.cpp:244]     Train net output #0: loss = 0.00022468 (* 1 = 0.00022468 loss)
I0403 05:13:04.315556 30256 sgd_solver.cpp:106] Iteration 12348, lr = 5e-05
I0403 05:13:19.244631 30256 solver.cpp:228] Iteration 12369, loss = 0.000271873
I0403 05:13:19.244911 30256 solver.cpp:244]     Train net output #0: loss = 0.000271759 (* 1 = 0.000271759 loss)
I0403 05:13:19.475978 30256 sgd_solver.cpp:106] Iteration 12369, lr = 5e-05
I0403 05:13:34.625927 30256 solver.cpp:228] Iteration 12390, loss = 0.000705045
I0403 05:13:34.626029 30256 solver.cpp:244]     Train net output #0: loss = 0.000704931 (* 1 = 0.000704931 loss)
I0403 05:13:34.775292 30256 sgd_solver.cpp:106] Iteration 12390, lr = 5e-05
I0403 05:13:49.816537 30256 solver.cpp:228] Iteration 12411, loss = 0.00245849
I0403 05:13:49.816781 30256 solver.cpp:244]     Train net output #0: loss = 0.00245838 (* 1 = 0.00245838 loss)
I0403 05:13:49.995169 30256 sgd_solver.cpp:106] Iteration 12411, lr = 5e-05
I0403 05:14:04.885321 30256 solver.cpp:228] Iteration 12432, loss = 0.000157239
I0403 05:14:04.885440 30256 solver.cpp:244]     Train net output #0: loss = 0.000157126 (* 1 = 0.000157126 loss)
I0403 05:14:05.091866 30256 sgd_solver.cpp:106] Iteration 12432, lr = 5e-05
I0403 05:14:20.096835 30256 solver.cpp:228] Iteration 12453, loss = 0.000560879
I0403 05:14:20.097142 30256 solver.cpp:244]     Train net output #0: loss = 0.000560766 (* 1 = 0.000560766 loss)
I0403 05:14:20.299060 30256 sgd_solver.cpp:106] Iteration 12453, lr = 5e-05
I0403 05:14:35.216111 30256 solver.cpp:228] Iteration 12474, loss = 0.000118937
I0403 05:14:35.216220 30256 solver.cpp:244]     Train net output #0: loss = 0.000118823 (* 1 = 0.000118823 loss)
I0403 05:14:35.431694 30256 sgd_solver.cpp:106] Iteration 12474, lr = 5e-05
I0403 05:14:50.374990 30256 solver.cpp:228] Iteration 12495, loss = 0.000465731
I0403 05:14:50.375295 30256 solver.cpp:244]     Train net output #0: loss = 0.000465618 (* 1 = 0.000465618 loss)
I0403 05:14:50.567934 30256 sgd_solver.cpp:106] Iteration 12495, lr = 5e-05
I0403 05:15:05.720000 30256 solver.cpp:228] Iteration 12516, loss = 0.0037627
I0403 05:15:05.720106 30256 solver.cpp:244]     Train net output #0: loss = 0.00376258 (* 1 = 0.00376258 loss)
I0403 05:15:05.899806 30256 sgd_solver.cpp:106] Iteration 12516, lr = 5e-05
I0403 05:15:20.845741 30256 solver.cpp:228] Iteration 12537, loss = 3.01674e-05
I0403 05:15:20.846053 30256 solver.cpp:244]     Train net output #0: loss = 3.00537e-05 (* 1 = 3.00537e-05 loss)
I0403 05:15:21.061678 30256 sgd_solver.cpp:106] Iteration 12537, lr = 5e-05
I0403 05:15:35.945986 30256 solver.cpp:228] Iteration 12558, loss = 0.000184251
I0403 05:15:35.946089 30256 solver.cpp:244]     Train net output #0: loss = 0.000184137 (* 1 = 0.000184137 loss)
I0403 05:15:36.116989 30256 sgd_solver.cpp:106] Iteration 12558, lr = 5e-05
I0403 05:15:51.251010 30256 solver.cpp:228] Iteration 12579, loss = 0.00131173
I0403 05:15:51.251353 30256 solver.cpp:244]     Train net output #0: loss = 0.00131162 (* 1 = 0.00131162 loss)
I0403 05:15:51.443783 30256 sgd_solver.cpp:106] Iteration 12579, lr = 5e-05
I0403 05:16:06.489841 30256 solver.cpp:228] Iteration 12600, loss = 0.00487782
I0403 05:16:06.489950 30256 solver.cpp:244]     Train net output #0: loss = 0.0048777 (* 1 = 0.0048777 loss)
I0403 05:16:06.671030 30256 sgd_solver.cpp:106] Iteration 12600, lr = 5e-05
I0403 05:16:21.784133 30256 solver.cpp:228] Iteration 12621, loss = 0.00016946
I0403 05:16:21.784461 30256 solver.cpp:244]     Train net output #0: loss = 0.000169346 (* 1 = 0.000169346 loss)
I0403 05:16:21.993191 30256 sgd_solver.cpp:106] Iteration 12621, lr = 5e-05
I0403 05:16:36.800593 30256 solver.cpp:228] Iteration 12642, loss = 0.000234098
I0403 05:16:36.800694 30256 solver.cpp:244]     Train net output #0: loss = 0.000233985 (* 1 = 0.000233985 loss)
I0403 05:16:36.978363 30256 sgd_solver.cpp:106] Iteration 12642, lr = 5e-05
I0403 05:16:51.856477 30256 solver.cpp:228] Iteration 12663, loss = 0.000206979
I0403 05:16:51.856794 30256 solver.cpp:244]     Train net output #0: loss = 0.000206866 (* 1 = 0.000206866 loss)
I0403 05:16:52.034042 30256 sgd_solver.cpp:106] Iteration 12663, lr = 5e-05
I0403 05:16:58.537677 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_12673.caffemodel
I0403 05:17:01.316987 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_12673.solverstate
I0403 05:17:03.206248 30256 solver.cpp:337] Iteration 12673, Testing net (#0)
I0403 05:17:26.677341 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992667
I0403 05:17:26.677695 30256 solver.cpp:404]     Test net output #1: loss = 0.0271502 (* 1 = 0.0271502 loss)
I0403 05:17:35.212044 30256 solver.cpp:228] Iteration 12684, loss = 0.00126271
I0403 05:17:35.212154 30256 solver.cpp:244]     Train net output #0: loss = 0.00126259 (* 1 = 0.00126259 loss)
I0403 05:17:35.431922 30256 sgd_solver.cpp:106] Iteration 12684, lr = 5e-05
I0403 05:17:50.337415 30256 solver.cpp:228] Iteration 12705, loss = 0.00029059
I0403 05:17:50.337515 30256 solver.cpp:244]     Train net output #0: loss = 0.000290476 (* 1 = 0.000290476 loss)
I0403 05:17:50.494206 30256 sgd_solver.cpp:106] Iteration 12705, lr = 5e-05
I0403 05:18:05.646894 30256 solver.cpp:228] Iteration 12726, loss = 0.00291262
I0403 05:18:05.647217 30256 solver.cpp:244]     Train net output #0: loss = 0.00291251 (* 1 = 0.00291251 loss)
I0403 05:18:05.827286 30256 sgd_solver.cpp:106] Iteration 12726, lr = 5e-05
I0403 05:18:20.719902 30256 solver.cpp:228] Iteration 12747, loss = 0.000160296
I0403 05:18:20.720011 30256 solver.cpp:244]     Train net output #0: loss = 0.000160181 (* 1 = 0.000160181 loss)
I0403 05:18:20.894996 30256 sgd_solver.cpp:106] Iteration 12747, lr = 5e-05
I0403 05:18:35.999836 30256 solver.cpp:228] Iteration 12768, loss = 9.35582e-05
I0403 05:18:36.000156 30256 solver.cpp:244]     Train net output #0: loss = 9.34425e-05 (* 1 = 9.34425e-05 loss)
I0403 05:18:36.204299 30256 sgd_solver.cpp:106] Iteration 12768, lr = 5e-05
I0403 05:18:51.301434 30256 solver.cpp:228] Iteration 12789, loss = 0.00156204
I0403 05:18:51.301535 30256 solver.cpp:244]     Train net output #0: loss = 0.00156192 (* 1 = 0.00156192 loss)
I0403 05:18:51.466166 30256 sgd_solver.cpp:106] Iteration 12789, lr = 5e-05
I0403 05:19:06.602605 30256 solver.cpp:228] Iteration 12810, loss = 0.00227315
I0403 05:19:06.602917 30256 solver.cpp:244]     Train net output #0: loss = 0.00227303 (* 1 = 0.00227303 loss)
I0403 05:19:06.785776 30256 sgd_solver.cpp:106] Iteration 12810, lr = 5e-05
I0403 05:19:21.808462 30256 solver.cpp:228] Iteration 12831, loss = 0.000116666
I0403 05:19:21.808560 30256 solver.cpp:244]     Train net output #0: loss = 0.000116551 (* 1 = 0.000116551 loss)
I0403 05:19:21.976196 30256 sgd_solver.cpp:106] Iteration 12831, lr = 5e-05
I0403 05:19:36.908294 30256 solver.cpp:228] Iteration 12852, loss = 0.00237057
I0403 05:19:36.908615 30256 solver.cpp:244]     Train net output #0: loss = 0.00237046 (* 1 = 0.00237046 loss)
I0403 05:19:37.106433 30256 sgd_solver.cpp:106] Iteration 12852, lr = 5e-05
I0403 05:19:51.962277 30256 solver.cpp:228] Iteration 12873, loss = 0.000338492
I0403 05:19:51.962417 30256 solver.cpp:244]     Train net output #0: loss = 0.000338377 (* 1 = 0.000338377 loss)
I0403 05:19:52.155171 30256 sgd_solver.cpp:106] Iteration 12873, lr = 5e-05
I0403 05:20:07.045444 30256 solver.cpp:228] Iteration 12894, loss = 0.000619719
I0403 05:20:07.045765 30256 solver.cpp:244]     Train net output #0: loss = 0.000619604 (* 1 = 0.000619604 loss)
I0403 05:20:07.227038 30256 sgd_solver.cpp:106] Iteration 12894, lr = 5e-05
I0403 05:20:22.273176 30256 solver.cpp:228] Iteration 12915, loss = 0.000297006
I0403 05:20:22.273277 30256 solver.cpp:244]     Train net output #0: loss = 0.000296891 (* 1 = 0.000296891 loss)
I0403 05:20:22.421568 30256 sgd_solver.cpp:106] Iteration 12915, lr = 5e-05
I0403 05:20:37.328732 30256 solver.cpp:228] Iteration 12936, loss = 2.98765e-05
I0403 05:20:37.329053 30256 solver.cpp:244]     Train net output #0: loss = 2.97621e-05 (* 1 = 2.97621e-05 loss)
I0403 05:20:37.505136 30256 sgd_solver.cpp:106] Iteration 12936, lr = 5e-05
I0403 05:20:52.503051 30256 solver.cpp:228] Iteration 12957, loss = 0.000558129
I0403 05:20:52.503149 30256 solver.cpp:244]     Train net output #0: loss = 0.000558014 (* 1 = 0.000558014 loss)
I0403 05:20:52.646996 30256 sgd_solver.cpp:106] Iteration 12957, lr = 5e-05
I0403 05:21:07.707790 30256 solver.cpp:228] Iteration 12978, loss = 5.3586e-05
I0403 05:21:07.708073 30256 solver.cpp:244]     Train net output #0: loss = 5.34714e-05 (* 1 = 5.34714e-05 loss)
I0403 05:21:07.886060 30256 sgd_solver.cpp:106] Iteration 12978, lr = 5e-05
I0403 05:21:22.871567 30256 solver.cpp:228] Iteration 12999, loss = 0.00145773
I0403 05:21:22.871686 30256 solver.cpp:244]     Train net output #0: loss = 0.00145762 (* 1 = 0.00145762 loss)
I0403 05:21:23.066051 30256 sgd_solver.cpp:106] Iteration 12999, lr = 5e-05
I0403 05:21:38.006490 30256 solver.cpp:228] Iteration 13020, loss = 0.000782306
I0403 05:21:38.006795 30256 solver.cpp:244]     Train net output #0: loss = 0.000782191 (* 1 = 0.000782191 loss)
I0403 05:21:38.204722 30256 sgd_solver.cpp:106] Iteration 13020, lr = 5e-05
I0403 05:21:53.132575 30256 solver.cpp:228] Iteration 13041, loss = 0.00144933
I0403 05:21:53.132685 30256 solver.cpp:244]     Train net output #0: loss = 0.00144922 (* 1 = 0.00144922 loss)
I0403 05:21:53.316637 30256 sgd_solver.cpp:106] Iteration 13041, lr = 5e-05
I0403 05:22:08.379871 30256 solver.cpp:228] Iteration 13062, loss = 0.000790919
I0403 05:22:08.380162 30256 solver.cpp:244]     Train net output #0: loss = 0.000790804 (* 1 = 0.000790804 loss)
I0403 05:22:08.578294 30256 sgd_solver.cpp:106] Iteration 13062, lr = 5e-05
I0403 05:22:23.526093 30256 solver.cpp:228] Iteration 13083, loss = 0.0178179
I0403 05:22:23.526201 30256 solver.cpp:244]     Train net output #0: loss = 0.0178178 (* 1 = 0.0178178 loss)
I0403 05:22:23.706037 30256 sgd_solver.cpp:106] Iteration 13083, lr = 5e-05
I0403 05:22:38.624805 30256 solver.cpp:228] Iteration 13104, loss = 0.00153084
I0403 05:22:38.625118 30256 solver.cpp:244]     Train net output #0: loss = 0.00153072 (* 1 = 0.00153072 loss)
I0403 05:22:38.815477 30256 sgd_solver.cpp:106] Iteration 13104, lr = 5e-05
I0403 05:22:42.377979 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_13110.caffemodel
I0403 05:22:45.119967 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_13110.solverstate
I0403 05:22:46.917526 30256 solver.cpp:337] Iteration 13110, Testing net (#0)
I0403 05:23:10.394688 30256 solver.cpp:404]     Test net output #0: accuracy = 0.992762
I0403 05:23:10.395007 30256 solver.cpp:404]     Test net output #1: loss = 0.0269779 (* 1 = 0.0269779 loss)
I0403 05:23:21.801362 30256 solver.cpp:228] Iteration 13125, loss = 0.000374926
I0403 05:23:21.801476 30256 solver.cpp:244]     Train net output #0: loss = 0.00037481 (* 1 = 0.00037481 loss)
I0403 05:23:21.984864 30256 sgd_solver.cpp:106] Iteration 13125, lr = 5e-06
I0403 05:23:22.694700 30256 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_13127.caffemodel
I0403 05:23:25.496408 30256 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-80-20_finetune/snapshots__iter_13127.solverstate
I0403 05:23:27.309710 30256 solver.cpp:322] Optimization Done.
I0403 05:23:27.521087 30256 caffe.cpp:222] Optimization Done.
