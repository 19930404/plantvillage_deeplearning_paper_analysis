I0403 02:30:28.142253 19294 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.145462 19294 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.145490 19294 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.204409 19294 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.205988 19294 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.207435 19294 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:36.790292 19294 solver.cpp:48] Initializing solver from parameters: 
test_iter: 325
test_interval: 217
base_lr: 0.005
display: 10
max_iter: 6525
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2175
snapshot: 217
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:36.858503 19294 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:36.868859 19294 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:36.869066 19294 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:36.870930 19294 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-40-60/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:36.873486 19294 layer_factory.hpp:77] Creating layer data
I0403 02:30:36.876122 19294 net.cpp:91] Creating Layer data
I0403 02:30:36.876343 19294 net.cpp:399] data -> data
I0403 02:30:36.876801 19294 net.cpp:399] data -> label
I0403 02:30:36.877068 19294 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-40-60/mean.binaryproto
I0403 02:30:36.922344 19299 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-40-60/train_db
I0403 02:30:36.960454 19294 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.099916 19294 net.cpp:141] Setting up data
I0403 02:30:37.100018 19294 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.100044 19294 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.100064 19294 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.100100 19294 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.100152 19294 net.cpp:91] Creating Layer conv1
I0403 02:30:37.100180 19294 net.cpp:425] conv1 <- data
I0403 02:30:37.100236 19294 net.cpp:399] conv1 -> conv1
I0403 02:30:37.103482 19294 net.cpp:141] Setting up conv1
I0403 02:30:37.103518 19294 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.103540 19294 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.103582 19294 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.103615 19294 net.cpp:91] Creating Layer relu1
I0403 02:30:37.103636 19294 net.cpp:425] relu1 <- conv1
I0403 02:30:37.103657 19294 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.103695 19294 net.cpp:141] Setting up relu1
I0403 02:30:37.103719 19294 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.103737 19294 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.103754 19294 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.103780 19294 net.cpp:91] Creating Layer norm1
I0403 02:30:37.103837 19294 net.cpp:425] norm1 <- conv1
I0403 02:30:37.103862 19294 net.cpp:399] norm1 -> norm1
I0403 02:30:37.109557 19294 net.cpp:141] Setting up norm1
I0403 02:30:37.109601 19294 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.109621 19294 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.109639 19294 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.109666 19294 net.cpp:91] Creating Layer pool1
I0403 02:30:37.109686 19294 net.cpp:425] pool1 <- norm1
I0403 02:30:37.109709 19294 net.cpp:399] pool1 -> pool1
I0403 02:30:37.109787 19294 net.cpp:141] Setting up pool1
I0403 02:30:37.109818 19294 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.109838 19294 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.109856 19294 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.109884 19294 net.cpp:91] Creating Layer conv2
I0403 02:30:37.109905 19294 net.cpp:425] conv2 <- pool1
I0403 02:30:37.109930 19294 net.cpp:399] conv2 -> conv2
I0403 02:30:37.111732 19302 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.129539 19294 net.cpp:141] Setting up conv2
I0403 02:30:37.129577 19294 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.129597 19294 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.129626 19294 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.129650 19294 net.cpp:91] Creating Layer relu2
I0403 02:30:37.129670 19294 net.cpp:425] relu2 <- conv2
I0403 02:30:37.129693 19294 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.129717 19294 net.cpp:141] Setting up relu2
I0403 02:30:37.129739 19294 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.129757 19294 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.129775 19294 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.129796 19294 net.cpp:91] Creating Layer norm2
I0403 02:30:37.129815 19294 net.cpp:425] norm2 <- conv2
I0403 02:30:37.129838 19294 net.cpp:399] norm2 -> norm2
I0403 02:30:37.129897 19294 net.cpp:141] Setting up norm2
I0403 02:30:37.129925 19294 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.129945 19294 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.129962 19294 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.129987 19294 net.cpp:91] Creating Layer pool2
I0403 02:30:37.130007 19294 net.cpp:425] pool2 <- norm2
I0403 02:30:37.130030 19294 net.cpp:399] pool2 -> pool2
I0403 02:30:37.130085 19294 net.cpp:141] Setting up pool2
I0403 02:30:37.130112 19294 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.130131 19294 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.130148 19294 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.130175 19294 net.cpp:91] Creating Layer conv3
I0403 02:30:37.130198 19294 net.cpp:425] conv3 <- pool2
I0403 02:30:37.130228 19294 net.cpp:399] conv3 -> conv3
I0403 02:30:37.172860 19294 net.cpp:141] Setting up conv3
I0403 02:30:37.172899 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.172920 19294 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.172948 19294 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.172972 19294 net.cpp:91] Creating Layer relu3
I0403 02:30:37.172992 19294 net.cpp:425] relu3 <- conv3
I0403 02:30:37.173015 19294 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.173038 19294 net.cpp:141] Setting up relu3
I0403 02:30:37.173059 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.173077 19294 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.173095 19294 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.173122 19294 net.cpp:91] Creating Layer conv4
I0403 02:30:37.173143 19294 net.cpp:425] conv4 <- conv3
I0403 02:30:37.173167 19294 net.cpp:399] conv4 -> conv4
I0403 02:30:37.204604 19294 net.cpp:141] Setting up conv4
I0403 02:30:37.204645 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.204665 19294 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.204689 19294 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.204735 19294 net.cpp:91] Creating Layer relu4
I0403 02:30:37.204758 19294 net.cpp:425] relu4 <- conv4
I0403 02:30:37.204780 19294 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.204804 19294 net.cpp:141] Setting up relu4
I0403 02:30:37.204825 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.204843 19294 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.204862 19294 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.204890 19294 net.cpp:91] Creating Layer conv5
I0403 02:30:37.204910 19294 net.cpp:425] conv5 <- conv4
I0403 02:30:37.204933 19294 net.cpp:399] conv5 -> conv5
I0403 02:30:37.225991 19294 net.cpp:141] Setting up conv5
I0403 02:30:37.226032 19294 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.226052 19294 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.226079 19294 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.226104 19294 net.cpp:91] Creating Layer relu5
I0403 02:30:37.226124 19294 net.cpp:425] relu5 <- conv5
I0403 02:30:37.226145 19294 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.226171 19294 net.cpp:141] Setting up relu5
I0403 02:30:37.226191 19294 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.226214 19294 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.226235 19294 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.226258 19294 net.cpp:91] Creating Layer pool5
I0403 02:30:37.226277 19294 net.cpp:425] pool5 <- conv5
I0403 02:30:37.226303 19294 net.cpp:399] pool5 -> pool5
I0403 02:30:37.226362 19294 net.cpp:141] Setting up pool5
I0403 02:30:37.226389 19294 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.226408 19294 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.226426 19294 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.226462 19294 net.cpp:91] Creating Layer fc6
I0403 02:30:37.226485 19294 net.cpp:425] fc6 <- pool5
I0403 02:30:37.226510 19294 net.cpp:399] fc6 -> fc6
I0403 02:30:38.846765 19294 net.cpp:141] Setting up fc6
I0403 02:30:38.846853 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.846870 19294 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.846894 19294 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.846921 19294 net.cpp:91] Creating Layer relu6
I0403 02:30:38.846940 19294 net.cpp:425] relu6 <- fc6
I0403 02:30:38.846961 19294 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.846983 19294 net.cpp:141] Setting up relu6
I0403 02:30:38.847002 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.847015 19294 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.847030 19294 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.847056 19294 net.cpp:91] Creating Layer drop6
I0403 02:30:38.847074 19294 net.cpp:425] drop6 <- fc6
I0403 02:30:38.847090 19294 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.847137 19294 net.cpp:141] Setting up drop6
I0403 02:30:38.847162 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.847177 19294 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.847193 19294 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.847218 19294 net.cpp:91] Creating Layer fc7
I0403 02:30:38.847235 19294 net.cpp:425] fc7 <- fc6
I0403 02:30:38.847254 19294 net.cpp:399] fc7 -> fc7
I0403 02:30:39.471670 19294 net.cpp:141] Setting up fc7
I0403 02:30:39.471765 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.471784 19294 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.471809 19294 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.471837 19294 net.cpp:91] Creating Layer relu7
I0403 02:30:39.471854 19294 net.cpp:425] relu7 <- fc7
I0403 02:30:39.471875 19294 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.471899 19294 net.cpp:141] Setting up relu7
I0403 02:30:39.471917 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.471935 19294 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.471951 19294 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.472007 19294 net.cpp:91] Creating Layer drop7
I0403 02:30:39.472026 19294 net.cpp:425] drop7 <- fc7
I0403 02:30:39.472044 19294 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.472090 19294 net.cpp:141] Setting up drop7
I0403 02:30:39.472112 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.472128 19294 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.472144 19294 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.472167 19294 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.472184 19294 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.472206 19294 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.478941 19294 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.478974 19294 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.478992 19294 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.479012 19294 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.479039 19294 net.cpp:91] Creating Layer loss
I0403 02:30:39.479058 19294 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.479075 19294 net.cpp:425] loss <- label
I0403 02:30:39.479099 19294 net.cpp:399] loss -> loss
I0403 02:30:39.479128 19294 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.479245 19294 net.cpp:141] Setting up loss
I0403 02:30:39.479270 19294 net.cpp:148] Top shape: (1)
I0403 02:30:39.479287 19294 net.cpp:151]     with loss weight 1
I0403 02:30:39.479341 19294 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.479358 19294 net.cpp:217] loss needs backward computation.
I0403 02:30:39.479375 19294 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.479392 19294 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.479406 19294 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.479420 19294 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.479435 19294 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.479451 19294 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.479466 19294 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.479481 19294 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.479497 19294 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.479512 19294 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.479527 19294 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.479543 19294 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.479559 19294 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.479574 19294 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.479589 19294 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.479605 19294 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.479620 19294 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.479635 19294 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.479651 19294 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.479667 19294 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.479683 19294 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.479698 19294 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.479714 19294 net.cpp:219] data does not need backward computation.
I0403 02:30:39.479729 19294 net.cpp:261] This network produces output loss
I0403 02:30:39.479758 19294 net.cpp:274] Network initialization done.
I0403 02:30:39.480916 19294 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.480994 19294 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.481745 19294 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-40-60/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.481936 19294 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.482105 19294 net.cpp:91] Creating Layer data
I0403 02:30:39.482158 19294 net.cpp:399] data -> data
I0403 02:30:39.482190 19294 net.cpp:399] data -> label
I0403 02:30:39.482256 19294 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-40-60/mean.binaryproto
I0403 02:30:39.506145 19307 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-40-60/test_db
I0403 02:30:39.511157 19294 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.751711 19294 net.cpp:141] Setting up data
I0403 02:30:39.757207 19294 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.757238 19294 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.757254 19294 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.757273 19294 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.757302 19294 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.757318 19294 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.757340 19294 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.757366 19294 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.757434 19294 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.757458 19294 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.757475 19294 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.757489 19294 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.757504 19294 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.757534 19294 net.cpp:91] Creating Layer conv1
I0403 02:30:39.757550 19294 net.cpp:425] conv1 <- data
I0403 02:30:39.757570 19294 net.cpp:399] conv1 -> conv1
I0403 02:30:39.759174 19294 net.cpp:141] Setting up conv1
I0403 02:30:39.759202 19294 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.759222 19294 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.759246 19294 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.759268 19294 net.cpp:91] Creating Layer relu1
I0403 02:30:39.759284 19294 net.cpp:425] relu1 <- conv1
I0403 02:30:39.759301 19294 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.759320 19294 net.cpp:141] Setting up relu1
I0403 02:30:39.759338 19294 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.759353 19294 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.759368 19294 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.759389 19294 net.cpp:91] Creating Layer norm1
I0403 02:30:39.759407 19294 net.cpp:425] norm1 <- conv1
I0403 02:30:39.759424 19294 net.cpp:399] norm1 -> norm1
I0403 02:30:39.759475 19294 net.cpp:141] Setting up norm1
I0403 02:30:39.759498 19294 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.759513 19294 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.759528 19294 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.759547 19294 net.cpp:91] Creating Layer pool1
I0403 02:30:39.759563 19294 net.cpp:425] pool1 <- norm1
I0403 02:30:39.759582 19294 net.cpp:399] pool1 -> pool1
I0403 02:30:39.759631 19294 net.cpp:141] Setting up pool1
I0403 02:30:39.759654 19294 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.759668 19294 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.759716 19294 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.759739 19294 net.cpp:91] Creating Layer conv2
I0403 02:30:39.759757 19294 net.cpp:425] conv2 <- pool1
I0403 02:30:39.759776 19294 net.cpp:399] conv2 -> conv2
I0403 02:30:39.773736 19294 net.cpp:141] Setting up conv2
I0403 02:30:39.808320 19294 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.808341 19294 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.808367 19294 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.808389 19294 net.cpp:91] Creating Layer relu2
I0403 02:30:39.808406 19294 net.cpp:425] relu2 <- conv2
I0403 02:30:39.808425 19294 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.808447 19294 net.cpp:141] Setting up relu2
I0403 02:30:39.808466 19294 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.808490 19294 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.808504 19294 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.808526 19294 net.cpp:91] Creating Layer norm2
I0403 02:30:39.808542 19294 net.cpp:425] norm2 <- conv2
I0403 02:30:39.808562 19294 net.cpp:399] norm2 -> norm2
I0403 02:30:39.808624 19294 net.cpp:141] Setting up norm2
I0403 02:30:39.808647 19294 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.808662 19294 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.808678 19294 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.808697 19294 net.cpp:91] Creating Layer pool2
I0403 02:30:39.808713 19294 net.cpp:425] pool2 <- norm2
I0403 02:30:39.808732 19294 net.cpp:399] pool2 -> pool2
I0403 02:30:39.808792 19294 net.cpp:141] Setting up pool2
I0403 02:30:39.808815 19294 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.808830 19294 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.808845 19294 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.808868 19294 net.cpp:91] Creating Layer conv3
I0403 02:30:39.808886 19294 net.cpp:425] conv3 <- pool2
I0403 02:30:39.808905 19294 net.cpp:399] conv3 -> conv3
I0403 02:30:39.861747 19294 net.cpp:141] Setting up conv3
I0403 02:30:39.861795 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.861812 19294 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.861837 19294 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.861879 19294 net.cpp:91] Creating Layer relu3
I0403 02:30:39.861912 19294 net.cpp:425] relu3 <- conv3
I0403 02:30:39.861960 19294 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.861984 19294 net.cpp:141] Setting up relu3
I0403 02:30:39.862001 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.862016 19294 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.862030 19294 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.862056 19294 net.cpp:91] Creating Layer conv4
I0403 02:30:39.862071 19294 net.cpp:425] conv4 <- conv3
I0403 02:30:39.862092 19294 net.cpp:399] conv4 -> conv4
I0403 02:30:39.901265 19294 net.cpp:141] Setting up conv4
I0403 02:30:39.901321 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.901338 19294 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.901360 19294 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.901382 19294 net.cpp:91] Creating Layer relu4
I0403 02:30:39.901401 19294 net.cpp:425] relu4 <- conv4
I0403 02:30:39.901429 19294 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.901453 19294 net.cpp:141] Setting up relu4
I0403 02:30:39.901470 19294 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.901485 19294 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.901500 19294 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.901525 19294 net.cpp:91] Creating Layer conv5
I0403 02:30:39.901542 19294 net.cpp:425] conv5 <- conv4
I0403 02:30:39.901562 19294 net.cpp:399] conv5 -> conv5
I0403 02:30:39.920624 19294 net.cpp:141] Setting up conv5
I0403 02:30:39.920660 19294 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.920676 19294 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.920742 19294 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.920763 19294 net.cpp:91] Creating Layer relu5
I0403 02:30:39.920779 19294 net.cpp:425] relu5 <- conv5
I0403 02:30:39.920799 19294 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.920821 19294 net.cpp:141] Setting up relu5
I0403 02:30:39.920840 19294 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.920855 19294 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.920868 19294 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.920892 19294 net.cpp:91] Creating Layer pool5
I0403 02:30:39.920907 19294 net.cpp:425] pool5 <- conv5
I0403 02:30:39.920924 19294 net.cpp:399] pool5 -> pool5
I0403 02:30:39.920980 19294 net.cpp:141] Setting up pool5
I0403 02:30:39.921003 19294 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.921018 19294 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.921035 19294 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.921056 19294 net.cpp:91] Creating Layer fc6
I0403 02:30:39.921072 19294 net.cpp:425] fc6 <- pool5
I0403 02:30:39.921093 19294 net.cpp:399] fc6 -> fc6
I0403 02:30:41.337452 19294 net.cpp:141] Setting up fc6
I0403 02:30:41.337548 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.337563 19294 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.337586 19294 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.337612 19294 net.cpp:91] Creating Layer relu6
I0403 02:30:41.337631 19294 net.cpp:425] relu6 <- fc6
I0403 02:30:41.337651 19294 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.337672 19294 net.cpp:141] Setting up relu6
I0403 02:30:41.337688 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.337702 19294 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.337716 19294 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.337736 19294 net.cpp:91] Creating Layer drop6
I0403 02:30:41.337752 19294 net.cpp:425] drop6 <- fc6
I0403 02:30:41.337769 19294 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.337805 19294 net.cpp:141] Setting up drop6
I0403 02:30:41.337828 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.337843 19294 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.337857 19294 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.337877 19294 net.cpp:91] Creating Layer fc7
I0403 02:30:41.337893 19294 net.cpp:425] fc7 <- fc6
I0403 02:30:41.337910 19294 net.cpp:399] fc7 -> fc7
I0403 02:30:41.968686 19294 net.cpp:141] Setting up fc7
I0403 02:30:41.968789 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.968807 19294 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.968833 19294 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.968860 19294 net.cpp:91] Creating Layer relu7
I0403 02:30:41.968881 19294 net.cpp:425] relu7 <- fc7
I0403 02:30:41.968907 19294 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.968933 19294 net.cpp:141] Setting up relu7
I0403 02:30:41.968953 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.968968 19294 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.968984 19294 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.969008 19294 net.cpp:91] Creating Layer drop7
I0403 02:30:41.969027 19294 net.cpp:425] drop7 <- fc7
I0403 02:30:41.969045 19294 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.969092 19294 net.cpp:141] Setting up drop7
I0403 02:30:41.969116 19294 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.969131 19294 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.969147 19294 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.969171 19294 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.969190 19294 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.969218 19294 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.976033 19294 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.976069 19294 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.976088 19294 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.976140 19294 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.976162 19294 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.976181 19294 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.976199 19294 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.976227 19294 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.976284 19294 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.976308 19294 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.976326 19294 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.976343 19294 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.976358 19294 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.976382 19294 net.cpp:91] Creating Layer loss
I0403 02:30:41.976398 19294 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.976416 19294 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.976435 19294 net.cpp:399] loss -> loss
I0403 02:30:41.976461 19294 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.976563 19294 net.cpp:141] Setting up loss
I0403 02:30:41.976588 19294 net.cpp:148] Top shape: (1)
I0403 02:30:41.976603 19294 net.cpp:151]     with loss weight 1
I0403 02:30:41.976627 19294 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.976644 19294 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.976668 19294 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.976688 19294 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.976706 19294 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.976729 19294 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.976764 19294 net.cpp:141] Setting up accuracy
I0403 02:30:41.976785 19294 net.cpp:148] Top shape: (1)
I0403 02:30:41.976801 19294 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.976816 19294 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.976832 19294 net.cpp:217] loss needs backward computation.
I0403 02:30:41.976850 19294 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.976866 19294 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.976881 19294 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.976897 19294 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.976912 19294 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.976928 19294 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.976944 19294 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.976959 19294 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.976975 19294 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.976991 19294 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.977006 19294 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.977022 19294 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.977037 19294 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.977053 19294 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.977069 19294 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.977084 19294 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.977102 19294 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.977116 19294 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.977133 19294 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.977147 19294 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.977164 19294 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.977180 19294 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.977195 19294 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.977231 19294 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.977251 19294 net.cpp:219] data does not need backward computation.
I0403 02:30:41.977265 19294 net.cpp:261] This network produces output accuracy
I0403 02:30:41.977282 19294 net.cpp:261] This network produces output loss
I0403 02:30:41.977313 19294 net.cpp:274] Network initialization done.
I0403 02:30:41.977432 19294 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.977941 19294 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.284579 19294 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.284660 19294 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.284692 19294 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.284739 19294 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.665647 19294 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.701807 19294 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.492439 19294 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.492547 19294 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.492593 19294 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.492633 19294 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.868206 19294 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:44.905056 19294 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.931516 19294 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.187510 19294 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:47.822217 19294 parallel.cpp:425] Starting Optimization
I0403 02:30:47.822425 19294 solver.cpp:279] Solving 
I0403 02:30:47.822449 19294 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:47.822595 19294 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:32:02.703994 19294 solver.cpp:404]     Test net output #0: accuracy = 0.0456924
I0403 02:32:02.710350 19294 solver.cpp:404]     Test net output #1: loss = 3.69646 (* 1 = 3.69646 loss)
I0403 02:32:03.285357 19294 solver.cpp:228] Iteration 0, loss = 3.87741
I0403 02:32:03.288959 19294 solver.cpp:244]     Train net output #0: loss = 3.87741 (* 1 = 3.87741 loss)
I0403 02:32:03.449910 19294 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:10.650002 19294 solver.cpp:228] Iteration 10, loss = 1.70178
I0403 02:32:10.657412 19294 solver.cpp:244]     Train net output #0: loss = 1.70178 (* 1 = 1.70178 loss)
I0403 02:32:10.825640 19294 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 02:32:17.868546 19294 solver.cpp:228] Iteration 20, loss = 0.866207
I0403 02:32:17.874841 19294 solver.cpp:244]     Train net output #0: loss = 0.866207 (* 1 = 0.866207 loss)
I0403 02:32:18.049080 19294 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 02:32:25.130182 19294 solver.cpp:228] Iteration 30, loss = 1.02335
I0403 02:32:25.136756 19294 solver.cpp:244]     Train net output #0: loss = 1.02335 (* 1 = 1.02335 loss)
I0403 02:32:25.332716 19294 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 02:32:32.622287 19294 solver.cpp:228] Iteration 40, loss = 0.646128
I0403 02:32:32.666735 19294 solver.cpp:244]     Train net output #0: loss = 0.646128 (* 1 = 0.646128 loss)
I0403 02:32:32.806767 19294 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 02:32:39.851024 19294 solver.cpp:228] Iteration 50, loss = 0.328688
I0403 02:32:39.858023 19294 solver.cpp:244]     Train net output #0: loss = 0.328688 (* 1 = 0.328688 loss)
I0403 02:32:40.038305 19294 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 02:32:47.176985 19294 solver.cpp:228] Iteration 60, loss = 0.457484
I0403 02:32:47.179926 19294 solver.cpp:244]     Train net output #0: loss = 0.457484 (* 1 = 0.457484 loss)
I0403 02:32:47.370079 19294 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 02:32:54.541388 19294 solver.cpp:228] Iteration 70, loss = 0.263191
I0403 02:32:54.545912 19294 solver.cpp:244]     Train net output #0: loss = 0.263191 (* 1 = 0.263191 loss)
I0403 02:32:54.734182 19294 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 02:33:01.764904 19294 solver.cpp:228] Iteration 80, loss = 0.307937
I0403 02:33:01.770663 19294 solver.cpp:244]     Train net output #0: loss = 0.307937 (* 1 = 0.307937 loss)
I0403 02:33:01.916105 19294 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:33:09.150377 19294 solver.cpp:228] Iteration 90, loss = 0.13412
I0403 02:33:09.156625 19294 solver.cpp:244]     Train net output #0: loss = 0.13412 (* 1 = 0.13412 loss)
I0403 02:33:09.329921 19294 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 02:33:16.419123 19294 solver.cpp:228] Iteration 100, loss = 0.290932
I0403 02:33:16.425521 19294 solver.cpp:244]     Train net output #0: loss = 0.290932 (* 1 = 0.290932 loss)
I0403 02:33:16.613064 19294 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 02:33:23.676847 19294 solver.cpp:228] Iteration 110, loss = 0.167913
I0403 02:33:23.681713 19294 solver.cpp:244]     Train net output #0: loss = 0.167913 (* 1 = 0.167913 loss)
I0403 02:33:23.868607 19294 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 02:33:30.993041 19294 solver.cpp:228] Iteration 120, loss = 0.273753
I0403 02:33:30.993150 19294 solver.cpp:244]     Train net output #0: loss = 0.273753 (* 1 = 0.273753 loss)
I0403 02:33:31.183933 19294 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 02:33:38.269347 19294 solver.cpp:228] Iteration 130, loss = 0.202173
I0403 02:33:38.275786 19294 solver.cpp:244]     Train net output #0: loss = 0.202173 (* 1 = 0.202173 loss)
I0403 02:33:38.451900 19294 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:33:45.634994 19294 solver.cpp:228] Iteration 140, loss = 0.263
I0403 02:33:45.662143 19294 solver.cpp:244]     Train net output #0: loss = 0.263 (* 1 = 0.263 loss)
I0403 02:33:45.814538 19294 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 02:33:52.882355 19294 solver.cpp:228] Iteration 150, loss = 0.246481
I0403 02:33:52.888465 19294 solver.cpp:244]     Train net output #0: loss = 0.246481 (* 1 = 0.246481 loss)
I0403 02:33:53.059245 19294 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 02:34:00.106971 19294 solver.cpp:228] Iteration 160, loss = 0.235999
I0403 02:34:00.112566 19294 solver.cpp:244]     Train net output #0: loss = 0.235999 (* 1 = 0.235999 loss)
I0403 02:34:00.288466 19294 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:34:07.366964 19294 solver.cpp:228] Iteration 170, loss = 0.203721
I0403 02:34:07.373155 19294 solver.cpp:244]     Train net output #0: loss = 0.203721 (* 1 = 0.203721 loss)
I0403 02:34:07.537783 19294 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 02:34:14.738011 19294 solver.cpp:228] Iteration 180, loss = 0.164784
I0403 02:34:14.744055 19294 solver.cpp:244]     Train net output #0: loss = 0.164784 (* 1 = 0.164784 loss)
I0403 02:34:14.934772 19294 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 02:34:22.032377 19294 solver.cpp:228] Iteration 190, loss = 0.22049
I0403 02:34:22.037628 19294 solver.cpp:244]     Train net output #0: loss = 0.22049 (* 1 = 0.22049 loss)
I0403 02:34:22.208780 19294 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 02:34:29.366039 19294 solver.cpp:228] Iteration 200, loss = 0.102784
I0403 02:34:29.371976 19294 solver.cpp:244]     Train net output #0: loss = 0.102784 (* 1 = 0.102784 loss)
I0403 02:34:29.584264 19294 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 02:34:36.693650 19294 solver.cpp:228] Iteration 210, loss = 0.198282
I0403 02:34:36.699985 19294 solver.cpp:244]     Train net output #0: loss = 0.198282 (* 1 = 0.198282 loss)
I0403 02:34:36.862817 19294 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:34:41.269541 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_217.caffemodel
I0403 02:34:44.073802 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_217.solverstate
I0403 02:34:45.944883 19294 solver.cpp:337] Iteration 217, Testing net (#0)
I0403 02:35:59.420720 19294 solver.cpp:404]     Test net output #0: accuracy = 0.950708
I0403 02:35:59.427443 19294 solver.cpp:404]     Test net output #1: loss = 0.149172 (* 1 = 0.149172 loss)
I0403 02:36:02.119518 19294 solver.cpp:228] Iteration 220, loss = 0.152274
I0403 02:36:02.125658 19294 solver.cpp:244]     Train net output #0: loss = 0.152274 (* 1 = 0.152274 loss)
I0403 02:36:02.314697 19294 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 02:36:09.425138 19294 solver.cpp:228] Iteration 230, loss = 0.0600966
I0403 02:36:09.435660 19294 solver.cpp:244]     Train net output #0: loss = 0.0600966 (* 1 = 0.0600966 loss)
I0403 02:36:09.654438 19294 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 02:36:16.728485 19294 solver.cpp:228] Iteration 240, loss = 0.147369
I0403 02:36:16.733587 19294 solver.cpp:244]     Train net output #0: loss = 0.147369 (* 1 = 0.147369 loss)
I0403 02:36:16.928213 19294 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:36:24.024477 19294 solver.cpp:228] Iteration 250, loss = 0.211993
I0403 02:36:24.030634 19294 solver.cpp:244]     Train net output #0: loss = 0.211993 (* 1 = 0.211993 loss)
I0403 02:36:24.210039 19294 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 02:36:31.261109 19294 solver.cpp:228] Iteration 260, loss = 0.0837977
I0403 02:36:31.268203 19294 solver.cpp:244]     Train net output #0: loss = 0.0837978 (* 1 = 0.0837978 loss)
I0403 02:36:31.462419 19294 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:36:38.679476 19294 solver.cpp:228] Iteration 270, loss = 0.055187
I0403 02:36:38.686616 19294 solver.cpp:244]     Train net output #0: loss = 0.055187 (* 1 = 0.055187 loss)
I0403 02:36:38.894737 19294 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 02:36:45.958796 19294 solver.cpp:228] Iteration 280, loss = 0.120127
I0403 02:36:45.972790 19294 solver.cpp:244]     Train net output #0: loss = 0.120127 (* 1 = 0.120127 loss)
I0403 02:36:46.144301 19294 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 02:36:53.136049 19294 solver.cpp:228] Iteration 290, loss = 0.133204
I0403 02:36:53.142189 19294 solver.cpp:244]     Train net output #0: loss = 0.133204 (* 1 = 0.133204 loss)
I0403 02:36:53.317769 19294 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 02:37:00.351052 19294 solver.cpp:228] Iteration 300, loss = 0.155232
I0403 02:37:00.356678 19294 solver.cpp:244]     Train net output #0: loss = 0.155232 (* 1 = 0.155232 loss)
I0403 02:37:00.559940 19294 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 02:37:07.736989 19294 solver.cpp:228] Iteration 310, loss = 0.140346
I0403 02:37:07.743918 19294 solver.cpp:244]     Train net output #0: loss = 0.140346 (* 1 = 0.140346 loss)
I0403 02:37:07.994948 19294 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 02:37:15.304772 19294 solver.cpp:228] Iteration 320, loss = 0.121573
I0403 02:37:15.311224 19294 solver.cpp:244]     Train net output #0: loss = 0.121573 (* 1 = 0.121573 loss)
I0403 02:37:15.462582 19294 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:37:22.654136 19294 solver.cpp:228] Iteration 330, loss = 0.0592178
I0403 02:37:22.660293 19294 solver.cpp:244]     Train net output #0: loss = 0.0592178 (* 1 = 0.0592178 loss)
I0403 02:37:22.797369 19294 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 02:37:30.051882 19294 solver.cpp:228] Iteration 340, loss = 0.107644
I0403 02:37:30.057598 19294 solver.cpp:244]     Train net output #0: loss = 0.107644 (* 1 = 0.107644 loss)
I0403 02:37:30.230839 19294 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 02:37:37.239523 19294 solver.cpp:228] Iteration 350, loss = 0.0219244
I0403 02:37:37.249405 19294 solver.cpp:244]     Train net output #0: loss = 0.0219245 (* 1 = 0.0219245 loss)
I0403 02:37:37.471572 19294 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 02:37:44.540858 19294 solver.cpp:228] Iteration 360, loss = 0.0582271
I0403 02:37:44.547509 19294 solver.cpp:244]     Train net output #0: loss = 0.0582271 (* 1 = 0.0582271 loss)
I0403 02:37:44.712282 19294 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 02:37:51.885099 19294 solver.cpp:228] Iteration 370, loss = 0.0911748
I0403 02:37:51.885202 19294 solver.cpp:244]     Train net output #0: loss = 0.0911748 (* 1 = 0.0911748 loss)
I0403 02:37:52.014752 19294 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 02:37:59.251425 19294 solver.cpp:228] Iteration 380, loss = 0.0969037
I0403 02:37:59.251533 19294 solver.cpp:244]     Train net output #0: loss = 0.0969038 (* 1 = 0.0969038 loss)
I0403 02:37:59.434034 19294 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 02:38:06.540462 19294 solver.cpp:228] Iteration 390, loss = 0.111789
I0403 02:38:06.547155 19294 solver.cpp:244]     Train net output #0: loss = 0.111789 (* 1 = 0.111789 loss)
I0403 02:38:06.728843 19294 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:38:13.738556 19294 solver.cpp:228] Iteration 400, loss = 0.0792753
I0403 02:38:13.744585 19294 solver.cpp:244]     Train net output #0: loss = 0.0792753 (* 1 = 0.0792753 loss)
I0403 02:38:13.955132 19294 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:38:21.035758 19294 solver.cpp:228] Iteration 410, loss = 0.185136
I0403 02:38:21.041849 19294 solver.cpp:244]     Train net output #0: loss = 0.185136 (* 1 = 0.185136 loss)
I0403 02:38:21.245585 19294 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 02:38:28.389161 19294 solver.cpp:228] Iteration 420, loss = 0.0676239
I0403 02:38:28.394919 19294 solver.cpp:244]     Train net output #0: loss = 0.0676239 (* 1 = 0.0676239 loss)
I0403 02:38:28.542390 19294 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:38:35.631394 19294 solver.cpp:228] Iteration 430, loss = 0.0839432
I0403 02:38:35.638339 19294 solver.cpp:244]     Train net output #0: loss = 0.0839432 (* 1 = 0.0839432 loss)
I0403 02:38:35.831061 19294 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 02:38:38.004693 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_434.caffemodel
I0403 02:38:40.684983 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_434.solverstate
I0403 02:38:42.457368 19294 solver.cpp:337] Iteration 434, Testing net (#0)
I0403 02:39:56.021339 19294 solver.cpp:404]     Test net output #0: accuracy = 0.967231
I0403 02:39:56.021697 19294 solver.cpp:404]     Test net output #1: loss = 0.106503 (* 1 = 0.106503 loss)
I0403 02:40:00.892961 19294 solver.cpp:228] Iteration 440, loss = 0.0941502
I0403 02:40:00.893059 19294 solver.cpp:244]     Train net output #0: loss = 0.0941502 (* 1 = 0.0941502 loss)
I0403 02:40:01.059362 19294 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 02:40:08.457240 19294 solver.cpp:228] Iteration 450, loss = 0.110107
I0403 02:40:08.457350 19294 solver.cpp:244]     Train net output #0: loss = 0.110107 (* 1 = 0.110107 loss)
I0403 02:40:08.648922 19294 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 02:40:15.641638 19294 solver.cpp:228] Iteration 460, loss = 0.108811
I0403 02:40:15.641747 19294 solver.cpp:244]     Train net output #0: loss = 0.108811 (* 1 = 0.108811 loss)
I0403 02:40:15.858639 19294 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 02:40:23.044828 19294 solver.cpp:228] Iteration 470, loss = 0.0354397
I0403 02:40:23.044937 19294 solver.cpp:244]     Train net output #0: loss = 0.0354397 (* 1 = 0.0354397 loss)
I0403 02:40:23.230528 19294 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 02:40:30.312463 19294 solver.cpp:228] Iteration 480, loss = 0.0523856
I0403 02:40:30.312808 19294 solver.cpp:244]     Train net output #0: loss = 0.0523855 (* 1 = 0.0523855 loss)
I0403 02:40:30.489261 19294 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:40:37.599144 19294 solver.cpp:228] Iteration 490, loss = 0.0630356
I0403 02:40:37.604662 19294 solver.cpp:244]     Train net output #0: loss = 0.0630356 (* 1 = 0.0630356 loss)
I0403 02:40:37.758841 19294 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 02:40:44.976770 19294 solver.cpp:228] Iteration 500, loss = 0.0976708
I0403 02:40:44.982825 19294 solver.cpp:244]     Train net output #0: loss = 0.0976708 (* 1 = 0.0976708 loss)
I0403 02:40:45.143760 19294 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 02:40:52.170259 19294 solver.cpp:228] Iteration 510, loss = 0.0404256
I0403 02:40:52.177112 19294 solver.cpp:244]     Train net output #0: loss = 0.0404256 (* 1 = 0.0404256 loss)
I0403 02:40:52.359266 19294 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 02:40:59.383080 19294 solver.cpp:228] Iteration 520, loss = 0.0968062
I0403 02:40:59.388993 19294 solver.cpp:244]     Train net output #0: loss = 0.0968062 (* 1 = 0.0968062 loss)
I0403 02:40:59.560487 19294 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:41:06.718350 19294 solver.cpp:228] Iteration 530, loss = 0.0413092
I0403 02:41:06.724530 19294 solver.cpp:244]     Train net output #0: loss = 0.0413092 (* 1 = 0.0413092 loss)
I0403 02:41:06.887718 19294 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 02:41:13.965554 19294 solver.cpp:228] Iteration 540, loss = 0.0458726
I0403 02:41:13.971891 19294 solver.cpp:244]     Train net output #0: loss = 0.0458726 (* 1 = 0.0458726 loss)
I0403 02:41:14.144338 19294 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 02:41:21.193336 19294 solver.cpp:228] Iteration 550, loss = 0.015244
I0403 02:41:21.198981 19294 solver.cpp:244]     Train net output #0: loss = 0.015244 (* 1 = 0.015244 loss)
I0403 02:41:21.386339 19294 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 02:41:28.478920 19294 solver.cpp:228] Iteration 560, loss = 0.12084
I0403 02:41:28.485244 19294 solver.cpp:244]     Train net output #0: loss = 0.12084 (* 1 = 0.12084 loss)
I0403 02:41:28.658962 19294 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:41:35.727967 19294 solver.cpp:228] Iteration 570, loss = 0.0868889
I0403 02:41:35.734340 19294 solver.cpp:244]     Train net output #0: loss = 0.0868889 (* 1 = 0.0868889 loss)
I0403 02:41:35.899458 19294 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 02:41:43.013622 19294 solver.cpp:228] Iteration 580, loss = 0.0422905
I0403 02:41:43.019258 19294 solver.cpp:244]     Train net output #0: loss = 0.0422904 (* 1 = 0.0422904 loss)
I0403 02:41:43.199163 19294 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 02:41:50.364120 19294 solver.cpp:228] Iteration 590, loss = 0.0416842
I0403 02:41:50.369073 19294 solver.cpp:244]     Train net output #0: loss = 0.0416842 (* 1 = 0.0416842 loss)
I0403 02:41:50.550302 19294 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 02:41:57.738636 19294 solver.cpp:228] Iteration 600, loss = 0.130667
I0403 02:41:57.744113 19294 solver.cpp:244]     Train net output #0: loss = 0.130667 (* 1 = 0.130667 loss)
I0403 02:41:57.909704 19294 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 02:42:05.315148 19294 solver.cpp:228] Iteration 610, loss = 0.018619
I0403 02:42:05.320727 19294 solver.cpp:244]     Train net output #0: loss = 0.018619 (* 1 = 0.018619 loss)
I0403 02:42:05.486160 19294 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 02:42:12.583250 19294 solver.cpp:228] Iteration 620, loss = 0.0132971
I0403 02:42:12.589701 19294 solver.cpp:244]     Train net output #0: loss = 0.0132971 (* 1 = 0.0132971 loss)
I0403 02:42:12.768206 19294 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 02:42:20.046574 19294 solver.cpp:228] Iteration 630, loss = 0.0358554
I0403 02:42:20.052728 19294 solver.cpp:244]     Train net output #0: loss = 0.0358554 (* 1 = 0.0358554 loss)
I0403 02:42:20.196792 19294 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:42:27.408289 19294 solver.cpp:228] Iteration 640, loss = 0.0118373
I0403 02:42:27.414031 19294 solver.cpp:244]     Train net output #0: loss = 0.0118373 (* 1 = 0.0118373 loss)
I0403 02:42:27.609289 19294 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:42:34.711933 19294 solver.cpp:228] Iteration 650, loss = 0.0599353
I0403 02:42:34.717839 19294 solver.cpp:244]     Train net output #0: loss = 0.0599353 (* 1 = 0.0599353 loss)
I0403 02:42:34.937881 19294 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:42:34.938113 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_651.caffemodel
I0403 02:42:37.695678 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_651.solverstate
I0403 02:42:39.596366 19294 solver.cpp:337] Iteration 651, Testing net (#0)
I0403 02:43:53.138689 19294 solver.cpp:404]     Test net output #0: accuracy = 0.967478
I0403 02:43:53.146299 19294 solver.cpp:404]     Test net output #1: loss = 0.110702 (* 1 = 0.110702 loss)
I0403 02:44:00.118311 19294 solver.cpp:228] Iteration 660, loss = 0.0834804
I0403 02:44:00.124171 19294 solver.cpp:244]     Train net output #0: loss = 0.0834804 (* 1 = 0.0834804 loss)
I0403 02:44:00.307045 19294 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 02:44:07.248714 19294 solver.cpp:228] Iteration 670, loss = 0.0238532
I0403 02:44:07.255034 19294 solver.cpp:244]     Train net output #0: loss = 0.0238532 (* 1 = 0.0238532 loss)
I0403 02:44:07.458720 19294 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 02:44:14.561485 19294 solver.cpp:228] Iteration 680, loss = 0.0527015
I0403 02:44:14.567445 19294 solver.cpp:244]     Train net output #0: loss = 0.0527015 (* 1 = 0.0527015 loss)
I0403 02:44:14.771924 19294 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 02:44:21.998746 19294 solver.cpp:228] Iteration 690, loss = 0.0520303
I0403 02:44:22.005200 19294 solver.cpp:244]     Train net output #0: loss = 0.0520303 (* 1 = 0.0520303 loss)
I0403 02:44:22.204066 19294 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 02:44:29.293627 19294 solver.cpp:228] Iteration 700, loss = 0.0158246
I0403 02:44:29.306306 19294 solver.cpp:244]     Train net output #0: loss = 0.0158246 (* 1 = 0.0158246 loss)
I0403 02:44:29.515415 19294 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 02:44:36.543696 19294 solver.cpp:228] Iteration 710, loss = 0.0109838
I0403 02:44:36.551156 19294 solver.cpp:244]     Train net output #0: loss = 0.0109838 (* 1 = 0.0109838 loss)
I0403 02:44:36.728870 19294 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 02:44:43.894497 19294 solver.cpp:228] Iteration 720, loss = 0.0919219
I0403 02:44:43.901052 19294 solver.cpp:244]     Train net output #0: loss = 0.0919219 (* 1 = 0.0919219 loss)
I0403 02:44:44.063555 19294 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:44:51.109798 19294 solver.cpp:228] Iteration 730, loss = 0.0521286
I0403 02:44:51.116703 19294 solver.cpp:244]     Train net output #0: loss = 0.0521286 (* 1 = 0.0521286 loss)
I0403 02:44:51.384101 19294 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 02:44:58.512557 19294 solver.cpp:228] Iteration 740, loss = 0.203738
I0403 02:44:58.525954 19294 solver.cpp:244]     Train net output #0: loss = 0.203738 (* 1 = 0.203738 loss)
I0403 02:44:58.693733 19294 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 02:45:05.718278 19294 solver.cpp:228] Iteration 750, loss = 0.0252816
I0403 02:45:05.724272 19294 solver.cpp:244]     Train net output #0: loss = 0.0252816 (* 1 = 0.0252816 loss)
I0403 02:45:05.929610 19294 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 02:45:13.117332 19294 solver.cpp:228] Iteration 760, loss = 0.0411084
I0403 02:45:13.124061 19294 solver.cpp:244]     Train net output #0: loss = 0.0411084 (* 1 = 0.0411084 loss)
I0403 02:45:13.315119 19294 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 02:45:20.433306 19294 solver.cpp:228] Iteration 770, loss = 0.0347117
I0403 02:45:20.439805 19294 solver.cpp:244]     Train net output #0: loss = 0.0347117 (* 1 = 0.0347117 loss)
I0403 02:45:20.627264 19294 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 02:45:27.711168 19294 solver.cpp:228] Iteration 780, loss = 0.0655744
I0403 02:45:27.716744 19294 solver.cpp:244]     Train net output #0: loss = 0.0655743 (* 1 = 0.0655743 loss)
I0403 02:45:27.907310 19294 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:45:35.134423 19294 solver.cpp:228] Iteration 790, loss = 0.0902124
I0403 02:45:35.140816 19294 solver.cpp:244]     Train net output #0: loss = 0.0902124 (* 1 = 0.0902124 loss)
I0403 02:45:35.308017 19294 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 02:45:42.350291 19294 solver.cpp:228] Iteration 800, loss = 0.0858543
I0403 02:45:42.357069 19294 solver.cpp:244]     Train net output #0: loss = 0.0858543 (* 1 = 0.0858543 loss)
I0403 02:45:42.551262 19294 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:45:49.564003 19294 solver.cpp:228] Iteration 810, loss = 0.0542704
I0403 02:45:49.570076 19294 solver.cpp:244]     Train net output #0: loss = 0.0542703 (* 1 = 0.0542703 loss)
I0403 02:45:49.737761 19294 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 02:45:56.881706 19294 solver.cpp:228] Iteration 820, loss = 0.0589052
I0403 02:45:56.887281 19294 solver.cpp:244]     Train net output #0: loss = 0.0589051 (* 1 = 0.0589051 loss)
I0403 02:45:57.067221 19294 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 02:46:04.328001 19294 solver.cpp:228] Iteration 830, loss = 0.064041
I0403 02:46:04.335927 19294 solver.cpp:244]     Train net output #0: loss = 0.064041 (* 1 = 0.064041 loss)
I0403 02:46:04.484989 19294 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 02:46:11.655737 19294 solver.cpp:228] Iteration 840, loss = 0.01011
I0403 02:46:11.661561 19294 solver.cpp:244]     Train net output #0: loss = 0.0101099 (* 1 = 0.0101099 loss)
I0403 02:46:11.894783 19294 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:46:18.928961 19294 solver.cpp:228] Iteration 850, loss = 0.0306429
I0403 02:46:18.934801 19294 solver.cpp:244]     Train net output #0: loss = 0.0306429 (* 1 = 0.0306429 loss)
I0403 02:46:19.127398 19294 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 02:46:26.258373 19294 solver.cpp:228] Iteration 860, loss = 0.0121334
I0403 02:46:26.263996 19294 solver.cpp:244]     Train net output #0: loss = 0.0121334 (* 1 = 0.0121334 loss)
I0403 02:46:26.416813 19294 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 02:46:31.547533 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_868.caffemodel
I0403 02:46:34.318488 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_868.solverstate
I0403 02:46:36.182433 19294 solver.cpp:337] Iteration 868, Testing net (#0)
I0403 02:47:49.661453 19294 solver.cpp:404]     Test net output #0: accuracy = 0.977447
I0403 02:47:49.668913 19294 solver.cpp:404]     Test net output #1: loss = 0.0723432 (* 1 = 0.0723432 loss)
I0403 02:47:51.688122 19294 solver.cpp:228] Iteration 870, loss = 0.0350312
I0403 02:47:51.693923 19294 solver.cpp:244]     Train net output #0: loss = 0.0350312 (* 1 = 0.0350312 loss)
I0403 02:47:51.870905 19294 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 02:47:59.006826 19294 solver.cpp:228] Iteration 880, loss = 0.0601
I0403 02:47:59.012956 19294 solver.cpp:244]     Train net output #0: loss = 0.0601 (* 1 = 0.0601 loss)
I0403 02:47:59.185036 19294 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:48:06.313071 19294 solver.cpp:228] Iteration 890, loss = 0.023768
I0403 02:48:06.320317 19294 solver.cpp:244]     Train net output #0: loss = 0.023768 (* 1 = 0.023768 loss)
I0403 02:48:06.550570 19294 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 02:48:13.761240 19294 solver.cpp:228] Iteration 900, loss = 0.102179
I0403 02:48:13.767601 19294 solver.cpp:244]     Train net output #0: loss = 0.102179 (* 1 = 0.102179 loss)
I0403 02:48:13.933477 19294 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 02:48:21.050489 19294 solver.cpp:228] Iteration 910, loss = 0.123183
I0403 02:48:21.055265 19294 solver.cpp:244]     Train net output #0: loss = 0.123183 (* 1 = 0.123183 loss)
I0403 02:48:21.258872 19294 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:48:28.267910 19294 solver.cpp:228] Iteration 920, loss = 0.0495448
I0403 02:48:28.274174 19294 solver.cpp:244]     Train net output #0: loss = 0.0495447 (* 1 = 0.0495447 loss)
I0403 02:48:28.459332 19294 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 02:48:35.555491 19294 solver.cpp:228] Iteration 930, loss = 0.121427
I0403 02:48:35.562314 19294 solver.cpp:244]     Train net output #0: loss = 0.121427 (* 1 = 0.121427 loss)
I0403 02:48:35.730355 19294 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 02:48:42.823218 19294 solver.cpp:228] Iteration 940, loss = 0.0949814
I0403 02:48:42.828533 19294 solver.cpp:244]     Train net output #0: loss = 0.0949814 (* 1 = 0.0949814 loss)
I0403 02:48:43.011797 19294 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 02:48:50.126487 19294 solver.cpp:228] Iteration 950, loss = 0.0199992
I0403 02:48:50.132544 19294 solver.cpp:244]     Train net output #0: loss = 0.0199992 (* 1 = 0.0199992 loss)
I0403 02:48:50.308471 19294 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 02:48:57.508347 19294 solver.cpp:228] Iteration 960, loss = 0.0280154
I0403 02:48:57.514709 19294 solver.cpp:244]     Train net output #0: loss = 0.0280154 (* 1 = 0.0280154 loss)
I0403 02:48:57.667129 19294 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:49:04.958273 19294 solver.cpp:228] Iteration 970, loss = 0.006929
I0403 02:49:04.965169 19294 solver.cpp:244]     Train net output #0: loss = 0.00692898 (* 1 = 0.00692898 loss)
I0403 02:49:05.129546 19294 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 02:49:12.341212 19294 solver.cpp:228] Iteration 980, loss = 0.0141326
I0403 02:49:12.348260 19294 solver.cpp:244]     Train net output #0: loss = 0.0141326 (* 1 = 0.0141326 loss)
I0403 02:49:12.527875 19294 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 02:49:19.724974 19294 solver.cpp:228] Iteration 990, loss = 0.0236641
I0403 02:49:19.730957 19294 solver.cpp:244]     Train net output #0: loss = 0.0236641 (* 1 = 0.0236641 loss)
I0403 02:49:19.860743 19294 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 02:49:27.029594 19294 solver.cpp:228] Iteration 1000, loss = 0.0179909
I0403 02:49:27.035778 19294 solver.cpp:244]     Train net output #0: loss = 0.0179909 (* 1 = 0.0179909 loss)
I0403 02:49:27.208536 19294 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 02:49:34.279410 19294 solver.cpp:228] Iteration 1010, loss = 0.0752176
I0403 02:49:34.286679 19294 solver.cpp:244]     Train net output #0: loss = 0.0752176 (* 1 = 0.0752176 loss)
I0403 02:49:34.468219 19294 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 02:49:41.526146 19294 solver.cpp:228] Iteration 1020, loss = 0.0282186
I0403 02:49:41.532850 19294 solver.cpp:244]     Train net output #0: loss = 0.0282186 (* 1 = 0.0282186 loss)
I0403 02:49:41.702561 19294 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 02:49:48.793184 19294 solver.cpp:228] Iteration 1030, loss = 0.0384785
I0403 02:49:48.799350 19294 solver.cpp:244]     Train net output #0: loss = 0.0384785 (* 1 = 0.0384785 loss)
I0403 02:49:48.952119 19294 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 02:49:56.153301 19294 solver.cpp:228] Iteration 1040, loss = 0.0382972
I0403 02:49:56.159365 19294 solver.cpp:244]     Train net output #0: loss = 0.0382972 (* 1 = 0.0382972 loss)
I0403 02:49:56.338490 19294 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:50:03.543287 19294 solver.cpp:228] Iteration 1050, loss = 0.00682382
I0403 02:50:03.550312 19294 solver.cpp:244]     Train net output #0: loss = 0.0068238 (* 1 = 0.0068238 loss)
I0403 02:50:03.717885 19294 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 02:50:10.953646 19294 solver.cpp:228] Iteration 1060, loss = 0.039028
I0403 02:50:10.960808 19294 solver.cpp:244]     Train net output #0: loss = 0.0390279 (* 1 = 0.0390279 loss)
I0403 02:50:11.133589 19294 sgd_solver.cpp:106] Iteration 1060, lr = 0.005
I0403 02:50:18.274508 19294 solver.cpp:228] Iteration 1070, loss = 0.0507689
I0403 02:50:18.281018 19294 solver.cpp:244]     Train net output #0: loss = 0.0507689 (* 1 = 0.0507689 loss)
I0403 02:50:18.523668 19294 sgd_solver.cpp:106] Iteration 1070, lr = 0.005
I0403 02:50:25.792577 19294 solver.cpp:228] Iteration 1080, loss = 0.031859
I0403 02:50:25.798667 19294 solver.cpp:244]     Train net output #0: loss = 0.031859 (* 1 = 0.031859 loss)
I0403 02:50:25.943511 19294 sgd_solver.cpp:106] Iteration 1080, lr = 0.005
I0403 02:50:28.968511 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1085.caffemodel
I0403 02:50:31.703811 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1085.solverstate
I0403 02:50:33.585767 19294 solver.cpp:337] Iteration 1085, Testing net (#0)
I0403 02:51:47.060730 19294 solver.cpp:404]     Test net output #0: accuracy = 0.968062
I0403 02:51:47.067492 19294 solver.cpp:404]     Test net output #1: loss = 0.11003 (* 1 = 0.11003 loss)
I0403 02:51:51.263629 19294 solver.cpp:228] Iteration 1090, loss = 0.020241
I0403 02:51:51.269968 19294 solver.cpp:244]     Train net output #0: loss = 0.020241 (* 1 = 0.020241 loss)
I0403 02:51:51.451251 19294 sgd_solver.cpp:106] Iteration 1090, lr = 0.005
I0403 02:51:58.534715 19294 solver.cpp:228] Iteration 1100, loss = 0.0131119
I0403 02:51:58.541030 19294 solver.cpp:244]     Train net output #0: loss = 0.0131119 (* 1 = 0.0131119 loss)
I0403 02:51:58.712643 19294 sgd_solver.cpp:106] Iteration 1100, lr = 0.005
I0403 02:52:05.813192 19294 solver.cpp:228] Iteration 1110, loss = 0.0114041
I0403 02:52:05.824013 19294 solver.cpp:244]     Train net output #0: loss = 0.0114041 (* 1 = 0.0114041 loss)
I0403 02:52:06.015143 19294 sgd_solver.cpp:106] Iteration 1110, lr = 0.005
I0403 02:52:13.031955 19294 solver.cpp:228] Iteration 1120, loss = 0.0742867
I0403 02:52:13.038408 19294 solver.cpp:244]     Train net output #0: loss = 0.0742867 (* 1 = 0.0742867 loss)
I0403 02:52:13.232146 19294 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 02:52:20.323921 19294 solver.cpp:228] Iteration 1130, loss = 0.0112842
I0403 02:52:20.330540 19294 solver.cpp:244]     Train net output #0: loss = 0.0112842 (* 1 = 0.0112842 loss)
I0403 02:52:20.512017 19294 sgd_solver.cpp:106] Iteration 1130, lr = 0.005
I0403 02:52:27.600618 19294 solver.cpp:228] Iteration 1140, loss = 0.0171619
I0403 02:52:27.606240 19294 solver.cpp:244]     Train net output #0: loss = 0.0171619 (* 1 = 0.0171619 loss)
I0403 02:52:27.772056 19294 sgd_solver.cpp:106] Iteration 1140, lr = 0.005
I0403 02:52:34.781891 19294 solver.cpp:228] Iteration 1150, loss = 0.0394135
I0403 02:52:34.787842 19294 solver.cpp:244]     Train net output #0: loss = 0.0394135 (* 1 = 0.0394135 loss)
I0403 02:52:34.957274 19294 sgd_solver.cpp:106] Iteration 1150, lr = 0.005
I0403 02:52:41.998638 19294 solver.cpp:228] Iteration 1160, loss = 0.0341946
I0403 02:52:42.005220 19294 solver.cpp:244]     Train net output #0: loss = 0.0341946 (* 1 = 0.0341946 loss)
I0403 02:52:42.166707 19294 sgd_solver.cpp:106] Iteration 1160, lr = 0.005
I0403 02:52:49.228718 19294 solver.cpp:228] Iteration 1170, loss = 0.00461939
I0403 02:52:49.235790 19294 solver.cpp:244]     Train net output #0: loss = 0.00461937 (* 1 = 0.00461937 loss)
I0403 02:52:49.409397 19294 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 02:52:56.476948 19294 solver.cpp:228] Iteration 1180, loss = 0.0378602
I0403 02:52:56.483398 19294 solver.cpp:244]     Train net output #0: loss = 0.0378602 (* 1 = 0.0378602 loss)
I0403 02:52:56.658241 19294 sgd_solver.cpp:106] Iteration 1180, lr = 0.005
I0403 02:53:03.767848 19294 solver.cpp:228] Iteration 1190, loss = 0.0312401
I0403 02:53:03.775073 19294 solver.cpp:244]     Train net output #0: loss = 0.0312401 (* 1 = 0.0312401 loss)
I0403 02:53:03.894363 19294 sgd_solver.cpp:106] Iteration 1190, lr = 0.005
I0403 02:53:11.024327 19294 solver.cpp:228] Iteration 1200, loss = 0.013572
I0403 02:53:11.030763 19294 solver.cpp:244]     Train net output #0: loss = 0.013572 (* 1 = 0.013572 loss)
I0403 02:53:11.217413 19294 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 02:53:18.330413 19294 solver.cpp:228] Iteration 1210, loss = 0.00928321
I0403 02:53:18.336714 19294 solver.cpp:244]     Train net output #0: loss = 0.00928319 (* 1 = 0.00928319 loss)
I0403 02:53:18.517956 19294 sgd_solver.cpp:106] Iteration 1210, lr = 0.005
I0403 02:53:25.600560 19294 solver.cpp:228] Iteration 1220, loss = 0.0103665
I0403 02:53:25.606092 19294 solver.cpp:244]     Train net output #0: loss = 0.0103665 (* 1 = 0.0103665 loss)
I0403 02:53:25.778573 19294 sgd_solver.cpp:106] Iteration 1220, lr = 0.005
I0403 02:53:33.042248 19294 solver.cpp:228] Iteration 1230, loss = 0.00982029
I0403 02:53:33.048683 19294 solver.cpp:244]     Train net output #0: loss = 0.00982027 (* 1 = 0.00982027 loss)
I0403 02:53:33.193557 19294 sgd_solver.cpp:106] Iteration 1230, lr = 0.005
I0403 02:53:40.443595 19294 solver.cpp:228] Iteration 1240, loss = 0.0503404
I0403 02:53:40.450202 19294 solver.cpp:244]     Train net output #0: loss = 0.0503404 (* 1 = 0.0503404 loss)
I0403 02:53:40.625840 19294 sgd_solver.cpp:106] Iteration 1240, lr = 0.005
I0403 02:53:47.693847 19294 solver.cpp:228] Iteration 1250, loss = 0.0499013
I0403 02:53:47.700279 19294 solver.cpp:244]     Train net output #0: loss = 0.0499013 (* 1 = 0.0499013 loss)
I0403 02:53:47.880326 19294 sgd_solver.cpp:106] Iteration 1250, lr = 0.005
I0403 02:53:55.025619 19294 solver.cpp:228] Iteration 1260, loss = 0.0646896
I0403 02:53:55.031697 19294 solver.cpp:244]     Train net output #0: loss = 0.0646896 (* 1 = 0.0646896 loss)
I0403 02:53:55.217604 19294 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 02:54:02.364688 19294 solver.cpp:228] Iteration 1270, loss = 0.00305904
I0403 02:54:02.370879 19294 solver.cpp:244]     Train net output #0: loss = 0.00305901 (* 1 = 0.00305901 loss)
I0403 02:54:02.533758 19294 sgd_solver.cpp:106] Iteration 1270, lr = 0.005
I0403 02:54:09.647155 19294 solver.cpp:228] Iteration 1280, loss = 0.0189927
I0403 02:54:09.654363 19294 solver.cpp:244]     Train net output #0: loss = 0.0189927 (* 1 = 0.0189927 loss)
I0403 02:54:09.818974 19294 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 02:54:17.004601 19294 solver.cpp:228] Iteration 1290, loss = 0.00872354
I0403 02:54:17.009909 19294 solver.cpp:244]     Train net output #0: loss = 0.00872352 (* 1 = 0.00872352 loss)
I0403 02:54:17.190124 19294 sgd_solver.cpp:106] Iteration 1290, lr = 0.005
I0403 02:54:24.267614 19294 solver.cpp:228] Iteration 1300, loss = 0.0263316
I0403 02:54:24.274080 19294 solver.cpp:244]     Train net output #0: loss = 0.0263316 (* 1 = 0.0263316 loss)
I0403 02:54:24.439374 19294 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 02:54:25.175420 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1302.caffemodel
I0403 02:54:27.932387 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1302.solverstate
I0403 02:54:29.790109 19294 solver.cpp:337] Iteration 1302, Testing net (#0)
I0403 02:55:43.313201 19294 solver.cpp:404]     Test net output #0: accuracy = 0.978155
I0403 02:55:43.320863 19294 solver.cpp:404]     Test net output #1: loss = 0.0740658 (* 1 = 0.0740658 loss)
I0403 02:55:49.716418 19294 solver.cpp:228] Iteration 1310, loss = 0.0196215
I0403 02:55:49.722968 19294 solver.cpp:244]     Train net output #0: loss = 0.0196214 (* 1 = 0.0196214 loss)
I0403 02:55:49.916803 19294 sgd_solver.cpp:106] Iteration 1310, lr = 0.005
I0403 02:55:57.054314 19294 solver.cpp:228] Iteration 1320, loss = 0.00943413
I0403 02:55:57.060144 19294 solver.cpp:244]     Train net output #0: loss = 0.00943411 (* 1 = 0.00943411 loss)
I0403 02:55:57.225738 19294 sgd_solver.cpp:106] Iteration 1320, lr = 0.005
I0403 02:56:04.248612 19294 solver.cpp:228] Iteration 1330, loss = 0.00761877
I0403 02:56:04.254789 19294 solver.cpp:244]     Train net output #0: loss = 0.00761874 (* 1 = 0.00761874 loss)
I0403 02:56:04.438204 19294 sgd_solver.cpp:106] Iteration 1330, lr = 0.005
I0403 02:56:11.485121 19294 solver.cpp:228] Iteration 1340, loss = 0.000729886
I0403 02:56:11.491307 19294 solver.cpp:244]     Train net output #0: loss = 0.000729865 (* 1 = 0.000729865 loss)
I0403 02:56:11.659554 19294 sgd_solver.cpp:106] Iteration 1340, lr = 0.005
I0403 02:56:18.912111 19294 solver.cpp:228] Iteration 1350, loss = 0.020063
I0403 02:56:18.918640 19294 solver.cpp:244]     Train net output #0: loss = 0.020063 (* 1 = 0.020063 loss)
I0403 02:56:19.092113 19294 sgd_solver.cpp:106] Iteration 1350, lr = 0.005
I0403 02:56:26.252218 19294 solver.cpp:228] Iteration 1360, loss = 0.00780975
I0403 02:56:26.258673 19294 solver.cpp:244]     Train net output #0: loss = 0.00780972 (* 1 = 0.00780972 loss)
I0403 02:56:26.430686 19294 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 02:56:33.765162 19294 solver.cpp:228] Iteration 1370, loss = 0.0666363
I0403 02:56:33.771917 19294 solver.cpp:244]     Train net output #0: loss = 0.0666363 (* 1 = 0.0666363 loss)
I0403 02:56:33.929903 19294 sgd_solver.cpp:106] Iteration 1370, lr = 0.005
I0403 02:56:41.093739 19294 solver.cpp:228] Iteration 1380, loss = 0.00290066
I0403 02:56:41.100528 19294 solver.cpp:244]     Train net output #0: loss = 0.00290063 (* 1 = 0.00290063 loss)
I0403 02:56:41.270059 19294 sgd_solver.cpp:106] Iteration 1380, lr = 0.005
I0403 02:56:48.352579 19294 solver.cpp:228] Iteration 1390, loss = 0.0219492
I0403 02:56:48.358937 19294 solver.cpp:244]     Train net output #0: loss = 0.0219492 (* 1 = 0.0219492 loss)
I0403 02:56:48.538830 19294 sgd_solver.cpp:106] Iteration 1390, lr = 0.005
I0403 02:56:55.791829 19294 solver.cpp:228] Iteration 1400, loss = 0.0110583
I0403 02:56:55.797845 19294 solver.cpp:244]     Train net output #0: loss = 0.0110583 (* 1 = 0.0110583 loss)
I0403 02:56:55.963876 19294 sgd_solver.cpp:106] Iteration 1400, lr = 0.005
I0403 02:57:03.006139 19294 solver.cpp:228] Iteration 1410, loss = 0.00229585
I0403 02:57:03.012029 19294 solver.cpp:244]     Train net output #0: loss = 0.00229583 (* 1 = 0.00229583 loss)
I0403 02:57:03.190206 19294 sgd_solver.cpp:106] Iteration 1410, lr = 0.005
I0403 02:57:10.320369 19294 solver.cpp:228] Iteration 1420, loss = 0.0635381
I0403 02:57:10.326941 19294 solver.cpp:244]     Train net output #0: loss = 0.063538 (* 1 = 0.063538 loss)
I0403 02:57:10.492313 19294 sgd_solver.cpp:106] Iteration 1420, lr = 0.005
I0403 02:57:17.629890 19294 solver.cpp:228] Iteration 1430, loss = 0.00208424
I0403 02:57:17.635828 19294 solver.cpp:244]     Train net output #0: loss = 0.00208422 (* 1 = 0.00208422 loss)
I0403 02:57:17.811283 19294 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 02:57:24.918790 19294 solver.cpp:228] Iteration 1440, loss = 0.0651555
I0403 02:57:24.925616 19294 solver.cpp:244]     Train net output #0: loss = 0.0651555 (* 1 = 0.0651555 loss)
I0403 02:57:25.097939 19294 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 02:57:32.440191 19294 solver.cpp:228] Iteration 1450, loss = 0.00885706
I0403 02:57:32.446941 19294 solver.cpp:244]     Train net output #0: loss = 0.00885704 (* 1 = 0.00885704 loss)
I0403 02:57:32.632961 19294 sgd_solver.cpp:106] Iteration 1450, lr = 0.005
I0403 02:57:39.757550 19294 solver.cpp:228] Iteration 1460, loss = 0.0439038
I0403 02:57:39.764207 19294 solver.cpp:244]     Train net output #0: loss = 0.0439038 (* 1 = 0.0439038 loss)
I0403 02:57:39.917187 19294 sgd_solver.cpp:106] Iteration 1460, lr = 0.005
I0403 02:57:47.043262 19294 solver.cpp:228] Iteration 1470, loss = 0.00850026
I0403 02:57:47.065620 19294 solver.cpp:244]     Train net output #0: loss = 0.00850024 (* 1 = 0.00850024 loss)
I0403 02:57:47.241526 19294 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 02:57:54.510692 19294 solver.cpp:228] Iteration 1480, loss = 0.024716
I0403 02:57:54.516384 19294 solver.cpp:244]     Train net output #0: loss = 0.024716 (* 1 = 0.024716 loss)
I0403 02:57:54.685225 19294 sgd_solver.cpp:106] Iteration 1480, lr = 0.005
I0403 02:58:01.818828 19294 solver.cpp:228] Iteration 1490, loss = 0.00805882
I0403 02:58:01.825013 19294 solver.cpp:244]     Train net output #0: loss = 0.0080588 (* 1 = 0.0080588 loss)
I0403 02:58:02.002091 19294 sgd_solver.cpp:106] Iteration 1490, lr = 0.005
I0403 02:58:09.305172 19294 solver.cpp:228] Iteration 1500, loss = 0.030984
I0403 02:58:09.310791 19294 solver.cpp:244]     Train net output #0: loss = 0.030984 (* 1 = 0.030984 loss)
I0403 02:58:09.405375 19294 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0403 02:58:16.673882 19294 solver.cpp:228] Iteration 1510, loss = 0.00335991
I0403 02:58:16.680512 19294 solver.cpp:244]     Train net output #0: loss = 0.00335989 (* 1 = 0.00335989 loss)
I0403 02:58:16.852489 19294 sgd_solver.cpp:106] Iteration 1510, lr = 0.005
I0403 02:58:22.684869 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1519.caffemodel
I0403 02:58:25.401686 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1519.solverstate
I0403 02:58:27.285430 19294 solver.cpp:337] Iteration 1519, Testing net (#0)
I0403 02:59:40.785115 19294 solver.cpp:404]     Test net output #0: accuracy = 0.978555
I0403 02:59:40.792198 19294 solver.cpp:404]     Test net output #1: loss = 0.0700174 (* 1 = 0.0700174 loss)
I0403 02:59:42.045714 19294 solver.cpp:228] Iteration 1520, loss = 0.0373911
I0403 02:59:42.051765 19294 solver.cpp:244]     Train net output #0: loss = 0.0373911 (* 1 = 0.0373911 loss)
I0403 02:59:42.247081 19294 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 02:59:49.470299 19294 solver.cpp:228] Iteration 1530, loss = 0.00829698
I0403 02:59:49.476249 19294 solver.cpp:244]     Train net output #0: loss = 0.00829696 (* 1 = 0.00829696 loss)
I0403 02:59:49.717967 19294 sgd_solver.cpp:106] Iteration 1530, lr = 0.005
I0403 02:59:56.814939 19294 solver.cpp:228] Iteration 1540, loss = 0.00124164
I0403 02:59:56.821187 19294 solver.cpp:244]     Train net output #0: loss = 0.00124162 (* 1 = 0.00124162 loss)
I0403 02:59:56.978008 19294 sgd_solver.cpp:106] Iteration 1540, lr = 0.005
I0403 03:00:04.080150 19294 solver.cpp:228] Iteration 1550, loss = 0.041455
I0403 03:00:04.086326 19294 solver.cpp:244]     Train net output #0: loss = 0.0414549 (* 1 = 0.0414549 loss)
I0403 03:00:04.270731 19294 sgd_solver.cpp:106] Iteration 1550, lr = 0.005
I0403 03:00:11.306895 19294 solver.cpp:228] Iteration 1560, loss = 0.0479127
I0403 03:00:11.312911 19294 solver.cpp:244]     Train net output #0: loss = 0.0479127 (* 1 = 0.0479127 loss)
I0403 03:00:11.502040 19294 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 03:00:18.507303 19294 solver.cpp:228] Iteration 1570, loss = 0.0179386
I0403 03:00:18.513278 19294 solver.cpp:244]     Train net output #0: loss = 0.0179386 (* 1 = 0.0179386 loss)
I0403 03:00:18.705641 19294 sgd_solver.cpp:106] Iteration 1570, lr = 0.005
I0403 03:00:25.719419 19294 solver.cpp:228] Iteration 1580, loss = 0.0608206
I0403 03:00:25.724200 19294 solver.cpp:244]     Train net output #0: loss = 0.0608206 (* 1 = 0.0608206 loss)
I0403 03:00:25.918527 19294 sgd_solver.cpp:106] Iteration 1580, lr = 0.005
I0403 03:00:32.943949 19294 solver.cpp:228] Iteration 1590, loss = 0.0742083
I0403 03:00:32.950191 19294 solver.cpp:244]     Train net output #0: loss = 0.0742083 (* 1 = 0.0742083 loss)
I0403 03:00:33.158169 19294 sgd_solver.cpp:106] Iteration 1590, lr = 0.005
I0403 03:00:40.220042 19294 solver.cpp:228] Iteration 1600, loss = 0.0253466
I0403 03:00:40.226254 19294 solver.cpp:244]     Train net output #0: loss = 0.0253466 (* 1 = 0.0253466 loss)
I0403 03:00:40.408568 19294 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 03:00:47.614866 19294 solver.cpp:228] Iteration 1610, loss = 0.00153011
I0403 03:00:47.620503 19294 solver.cpp:244]     Train net output #0: loss = 0.00153009 (* 1 = 0.00153009 loss)
I0403 03:00:47.779563 19294 sgd_solver.cpp:106] Iteration 1610, lr = 0.005
I0403 03:00:54.863050 19294 solver.cpp:228] Iteration 1620, loss = 0.0449089
I0403 03:00:54.869352 19294 solver.cpp:244]     Train net output #0: loss = 0.0449088 (* 1 = 0.0449088 loss)
I0403 03:00:55.093696 19294 sgd_solver.cpp:106] Iteration 1620, lr = 0.005
I0403 03:01:02.202347 19294 solver.cpp:228] Iteration 1630, loss = 0.144963
I0403 03:01:02.209058 19294 solver.cpp:244]     Train net output #0: loss = 0.144963 (* 1 = 0.144963 loss)
I0403 03:01:02.380206 19294 sgd_solver.cpp:106] Iteration 1630, lr = 0.005
I0403 03:01:09.476236 19294 solver.cpp:228] Iteration 1640, loss = 0.0714677
I0403 03:01:09.482446 19294 solver.cpp:244]     Train net output #0: loss = 0.0714677 (* 1 = 0.0714677 loss)
I0403 03:01:09.651099 19294 sgd_solver.cpp:106] Iteration 1640, lr = 0.005
I0403 03:01:16.708386 19294 solver.cpp:228] Iteration 1650, loss = 0.0223849
I0403 03:01:16.714833 19294 solver.cpp:244]     Train net output #0: loss = 0.0223849 (* 1 = 0.0223849 loss)
I0403 03:01:16.881600 19294 sgd_solver.cpp:106] Iteration 1650, lr = 0.005
I0403 03:01:23.904096 19294 solver.cpp:228] Iteration 1660, loss = 0.0103496
I0403 03:01:23.911702 19294 solver.cpp:244]     Train net output #0: loss = 0.0103496 (* 1 = 0.0103496 loss)
I0403 03:01:24.090514 19294 sgd_solver.cpp:106] Iteration 1660, lr = 0.005
I0403 03:01:31.112018 19294 solver.cpp:228] Iteration 1670, loss = 0.0408245
I0403 03:01:31.118535 19294 solver.cpp:244]     Train net output #0: loss = 0.0408245 (* 1 = 0.0408245 loss)
I0403 03:01:31.272395 19294 sgd_solver.cpp:106] Iteration 1670, lr = 0.005
I0403 03:01:38.420331 19294 solver.cpp:228] Iteration 1680, loss = 0.0316541
I0403 03:01:38.426440 19294 solver.cpp:244]     Train net output #0: loss = 0.0316541 (* 1 = 0.0316541 loss)
I0403 03:01:38.618707 19294 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 03:01:45.732460 19294 solver.cpp:228] Iteration 1690, loss = 0.00635345
I0403 03:01:45.738858 19294 solver.cpp:244]     Train net output #0: loss = 0.00635344 (* 1 = 0.00635344 loss)
I0403 03:01:45.983959 19294 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 03:01:53.103283 19294 solver.cpp:228] Iteration 1700, loss = 0.00742218
I0403 03:01:53.109282 19294 solver.cpp:244]     Train net output #0: loss = 0.00742218 (* 1 = 0.00742218 loss)
I0403 03:01:53.283311 19294 sgd_solver.cpp:106] Iteration 1700, lr = 0.005
I0403 03:02:00.439193 19294 solver.cpp:228] Iteration 1710, loss = 0.00747466
I0403 03:02:00.445718 19294 solver.cpp:244]     Train net output #0: loss = 0.00747466 (* 1 = 0.00747466 loss)
I0403 03:02:00.616888 19294 sgd_solver.cpp:106] Iteration 1710, lr = 0.005
I0403 03:02:07.890213 19294 solver.cpp:228] Iteration 1720, loss = 0.0203172
I0403 03:02:07.895990 19294 solver.cpp:244]     Train net output #0: loss = 0.0203172 (* 1 = 0.0203172 loss)
I0403 03:02:08.069820 19294 sgd_solver.cpp:106] Iteration 1720, lr = 0.005
I0403 03:02:15.235060 19294 solver.cpp:228] Iteration 1730, loss = 0.0123288
I0403 03:02:15.240593 19294 solver.cpp:244]     Train net output #0: loss = 0.0123288 (* 1 = 0.0123288 loss)
I0403 03:02:15.390827 19294 sgd_solver.cpp:106] Iteration 1730, lr = 0.005
I0403 03:02:19.139662 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1736.caffemodel
I0403 03:02:21.905292 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1736.solverstate
I0403 03:02:23.768240 19294 solver.cpp:337] Iteration 1736, Testing net (#0)
I0403 03:03:37.235942 19294 solver.cpp:404]     Test net output #0: accuracy = 0.982647
I0403 03:03:37.242285 19294 solver.cpp:404]     Test net output #1: loss = 0.0574154 (* 1 = 0.0574154 loss)
I0403 03:03:40.754050 19294 solver.cpp:228] Iteration 1740, loss = 0.0221119
I0403 03:03:40.759475 19294 solver.cpp:244]     Train net output #0: loss = 0.0221119 (* 1 = 0.0221119 loss)
I0403 03:03:40.946352 19294 sgd_solver.cpp:106] Iteration 1740, lr = 0.005
I0403 03:03:47.982293 19294 solver.cpp:228] Iteration 1750, loss = 0.00567841
I0403 03:03:47.988334 19294 solver.cpp:244]     Train net output #0: loss = 0.00567841 (* 1 = 0.00567841 loss)
I0403 03:03:48.181890 19294 sgd_solver.cpp:106] Iteration 1750, lr = 0.005
I0403 03:03:55.638909 19294 solver.cpp:228] Iteration 1760, loss = 0.00161259
I0403 03:03:55.647769 19294 solver.cpp:244]     Train net output #0: loss = 0.0016126 (* 1 = 0.0016126 loss)
I0403 03:03:55.827723 19294 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 03:04:02.868585 19294 solver.cpp:228] Iteration 1770, loss = 0.00288062
I0403 03:04:02.874830 19294 solver.cpp:244]     Train net output #0: loss = 0.00288062 (* 1 = 0.00288062 loss)
I0403 03:04:03.045989 19294 sgd_solver.cpp:106] Iteration 1770, lr = 0.005
I0403 03:04:10.125090 19294 solver.cpp:228] Iteration 1780, loss = 0.00426414
I0403 03:04:10.131335 19294 solver.cpp:244]     Train net output #0: loss = 0.00426413 (* 1 = 0.00426413 loss)
I0403 03:04:10.318610 19294 sgd_solver.cpp:106] Iteration 1780, lr = 0.005
I0403 03:04:17.426017 19294 solver.cpp:228] Iteration 1790, loss = 0.00124298
I0403 03:04:17.432904 19294 solver.cpp:244]     Train net output #0: loss = 0.00124298 (* 1 = 0.00124298 loss)
I0403 03:04:17.627106 19294 sgd_solver.cpp:106] Iteration 1790, lr = 0.005
I0403 03:04:24.912174 19294 solver.cpp:228] Iteration 1800, loss = 0.0365734
I0403 03:04:24.917865 19294 solver.cpp:244]     Train net output #0: loss = 0.0365734 (* 1 = 0.0365734 loss)
I0403 03:04:25.109685 19294 sgd_solver.cpp:106] Iteration 1800, lr = 0.005
I0403 03:04:32.209367 19294 solver.cpp:228] Iteration 1810, loss = 0.0189393
I0403 03:04:32.215255 19294 solver.cpp:244]     Train net output #0: loss = 0.0189393 (* 1 = 0.0189393 loss)
I0403 03:04:32.399971 19294 sgd_solver.cpp:106] Iteration 1810, lr = 0.005
I0403 03:04:39.428261 19294 solver.cpp:228] Iteration 1820, loss = 0.0106786
I0403 03:04:39.434279 19294 solver.cpp:244]     Train net output #0: loss = 0.0106786 (* 1 = 0.0106786 loss)
I0403 03:04:39.635700 19294 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 03:04:46.720609 19294 solver.cpp:228] Iteration 1830, loss = 0.00916296
I0403 03:04:46.726285 19294 solver.cpp:244]     Train net output #0: loss = 0.00916295 (* 1 = 0.00916295 loss)
I0403 03:04:46.941771 19294 sgd_solver.cpp:106] Iteration 1830, lr = 0.005
I0403 03:04:54.290132 19294 solver.cpp:228] Iteration 1840, loss = 0.00191502
I0403 03:04:54.295825 19294 solver.cpp:244]     Train net output #0: loss = 0.00191501 (* 1 = 0.00191501 loss)
I0403 03:04:54.472255 19294 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 03:05:01.504865 19294 solver.cpp:228] Iteration 1850, loss = 0.00307558
I0403 03:05:01.517400 19294 solver.cpp:244]     Train net output #0: loss = 0.00307558 (* 1 = 0.00307558 loss)
I0403 03:05:01.721168 19294 sgd_solver.cpp:106] Iteration 1850, lr = 0.005
I0403 03:05:08.742216 19294 solver.cpp:228] Iteration 1860, loss = 0.0208935
I0403 03:05:08.748206 19294 solver.cpp:244]     Train net output #0: loss = 0.0208935 (* 1 = 0.0208935 loss)
I0403 03:05:09.010258 19294 sgd_solver.cpp:106] Iteration 1860, lr = 0.005
I0403 03:05:16.280881 19294 solver.cpp:228] Iteration 1870, loss = 0.0112352
I0403 03:05:16.286258 19294 solver.cpp:244]     Train net output #0: loss = 0.0112352 (* 1 = 0.0112352 loss)
I0403 03:05:16.474450 19294 sgd_solver.cpp:106] Iteration 1870, lr = 0.005
I0403 03:05:23.560385 19294 solver.cpp:228] Iteration 1880, loss = 0.00221601
I0403 03:05:23.567266 19294 solver.cpp:244]     Train net output #0: loss = 0.002216 (* 1 = 0.002216 loss)
I0403 03:05:23.774394 19294 sgd_solver.cpp:106] Iteration 1880, lr = 0.005
I0403 03:05:30.838898 19294 solver.cpp:228] Iteration 1890, loss = 0.00423849
I0403 03:05:30.844599 19294 solver.cpp:244]     Train net output #0: loss = 0.00423847 (* 1 = 0.00423847 loss)
I0403 03:05:31.027844 19294 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 03:05:38.207187 19294 solver.cpp:228] Iteration 1900, loss = 0.00490853
I0403 03:05:38.213227 19294 solver.cpp:244]     Train net output #0: loss = 0.00490851 (* 1 = 0.00490851 loss)
I0403 03:05:38.385365 19294 sgd_solver.cpp:106] Iteration 1900, lr = 0.005
I0403 03:05:45.613215 19294 solver.cpp:228] Iteration 1910, loss = 0.00099669
I0403 03:05:45.619489 19294 solver.cpp:244]     Train net output #0: loss = 0.00099667 (* 1 = 0.00099667 loss)
I0403 03:05:45.792796 19294 sgd_solver.cpp:106] Iteration 1910, lr = 0.005
I0403 03:05:52.895151 19294 solver.cpp:228] Iteration 1920, loss = 0.00743708
I0403 03:05:52.900648 19294 solver.cpp:244]     Train net output #0: loss = 0.00743706 (* 1 = 0.00743706 loss)
I0403 03:05:53.076279 19294 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 03:06:00.229008 19294 solver.cpp:228] Iteration 1930, loss = 0.0181285
I0403 03:06:00.235096 19294 solver.cpp:244]     Train net output #0: loss = 0.0181285 (* 1 = 0.0181285 loss)
I0403 03:06:00.414501 19294 sgd_solver.cpp:106] Iteration 1930, lr = 0.005
I0403 03:06:07.492816 19294 solver.cpp:228] Iteration 1940, loss = 0.00775804
I0403 03:06:07.498723 19294 solver.cpp:244]     Train net output #0: loss = 0.00775802 (* 1 = 0.00775802 loss)
I0403 03:06:07.720322 19294 sgd_solver.cpp:106] Iteration 1940, lr = 0.005
I0403 03:06:14.769244 19294 solver.cpp:228] Iteration 1950, loss = 0.00518944
I0403 03:06:14.774585 19294 solver.cpp:244]     Train net output #0: loss = 0.00518942 (* 1 = 0.00518942 loss)
I0403 03:06:14.890563 19294 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 03:06:16.444633 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1953.caffemodel
I0403 03:06:19.207381 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_1953.solverstate
I0403 03:06:21.024570 19294 solver.cpp:337] Iteration 1953, Testing net (#0)
I0403 03:07:34.586051 19294 solver.cpp:404]     Test net output #0: accuracy = 0.9768
I0403 03:07:34.592305 19294 solver.cpp:404]     Test net output #1: loss = 0.0820877 (* 1 = 0.0820877 loss)
I0403 03:07:40.294736 19294 solver.cpp:228] Iteration 1960, loss = 0.000936867
I0403 03:07:40.301108 19294 solver.cpp:244]     Train net output #0: loss = 0.000936849 (* 1 = 0.000936849 loss)
I0403 03:07:40.491200 19294 sgd_solver.cpp:106] Iteration 1960, lr = 0.005
I0403 03:07:47.706527 19294 solver.cpp:228] Iteration 1970, loss = 0.0154489
I0403 03:07:47.713256 19294 solver.cpp:244]     Train net output #0: loss = 0.0154489 (* 1 = 0.0154489 loss)
I0403 03:07:47.885537 19294 sgd_solver.cpp:106] Iteration 1970, lr = 0.005
I0403 03:07:54.994000 19294 solver.cpp:228] Iteration 1980, loss = 0.00629727
I0403 03:07:55.001050 19294 solver.cpp:244]     Train net output #0: loss = 0.00629725 (* 1 = 0.00629725 loss)
I0403 03:07:55.204188 19294 sgd_solver.cpp:106] Iteration 1980, lr = 0.005
I0403 03:08:02.301894 19294 solver.cpp:228] Iteration 1990, loss = 0.00540926
I0403 03:08:02.308689 19294 solver.cpp:244]     Train net output #0: loss = 0.00540924 (* 1 = 0.00540924 loss)
I0403 03:08:02.438920 19294 sgd_solver.cpp:106] Iteration 1990, lr = 0.005
I0403 03:08:09.634390 19294 solver.cpp:228] Iteration 2000, loss = 0.0175532
I0403 03:08:09.641115 19294 solver.cpp:244]     Train net output #0: loss = 0.0175532 (* 1 = 0.0175532 loss)
I0403 03:08:09.818099 19294 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 03:08:16.805029 19294 solver.cpp:228] Iteration 2010, loss = 0.00271699
I0403 03:08:16.810540 19294 solver.cpp:244]     Train net output #0: loss = 0.00271697 (* 1 = 0.00271697 loss)
I0403 03:08:16.980667 19294 sgd_solver.cpp:106] Iteration 2010, lr = 0.005
I0403 03:08:24.178433 19294 solver.cpp:228] Iteration 2020, loss = 0.00795231
I0403 03:08:24.184032 19294 solver.cpp:244]     Train net output #0: loss = 0.0079523 (* 1 = 0.0079523 loss)
I0403 03:08:24.327366 19294 sgd_solver.cpp:106] Iteration 2020, lr = 0.005
I0403 03:08:31.626759 19294 solver.cpp:228] Iteration 2030, loss = 0.00521274
I0403 03:08:31.633359 19294 solver.cpp:244]     Train net output #0: loss = 0.00521272 (* 1 = 0.00521272 loss)
I0403 03:08:31.834715 19294 sgd_solver.cpp:106] Iteration 2030, lr = 0.005
I0403 03:08:39.003383 19294 solver.cpp:228] Iteration 2040, loss = 0.00285118
I0403 03:08:39.009209 19294 solver.cpp:244]     Train net output #0: loss = 0.00285116 (* 1 = 0.00285116 loss)
I0403 03:08:39.187927 19294 sgd_solver.cpp:106] Iteration 2040, lr = 0.005
I0403 03:08:46.180125 19294 solver.cpp:228] Iteration 2050, loss = 0.00379497
I0403 03:08:46.186465 19294 solver.cpp:244]     Train net output #0: loss = 0.00379495 (* 1 = 0.00379495 loss)
I0403 03:08:46.450479 19294 sgd_solver.cpp:106] Iteration 2050, lr = 0.005
I0403 03:08:53.660287 19294 solver.cpp:228] Iteration 2060, loss = 0.00189295
I0403 03:08:53.666287 19294 solver.cpp:244]     Train net output #0: loss = 0.00189294 (* 1 = 0.00189294 loss)
I0403 03:08:53.858908 19294 sgd_solver.cpp:106] Iteration 2060, lr = 0.005
I0403 03:09:01.113744 19294 solver.cpp:228] Iteration 2070, loss = 0.013617
I0403 03:09:01.120048 19294 solver.cpp:244]     Train net output #0: loss = 0.013617 (* 1 = 0.013617 loss)
I0403 03:09:01.297734 19294 sgd_solver.cpp:106] Iteration 2070, lr = 0.005
I0403 03:09:08.393571 19294 solver.cpp:228] Iteration 2080, loss = 0.0249472
I0403 03:09:08.399612 19294 solver.cpp:244]     Train net output #0: loss = 0.0249472 (* 1 = 0.0249472 loss)
I0403 03:09:08.561404 19294 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:09:15.611554 19294 solver.cpp:228] Iteration 2090, loss = 0.0163548
I0403 03:09:15.618000 19294 solver.cpp:244]     Train net output #0: loss = 0.0163548 (* 1 = 0.0163548 loss)
I0403 03:09:15.794432 19294 sgd_solver.cpp:106] Iteration 2090, lr = 0.005
I0403 03:09:22.884459 19294 solver.cpp:228] Iteration 2100, loss = 0.00804455
I0403 03:09:22.891573 19294 solver.cpp:244]     Train net output #0: loss = 0.00804454 (* 1 = 0.00804454 loss)
I0403 03:09:23.036201 19294 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 03:09:30.254355 19294 solver.cpp:228] Iteration 2110, loss = 0.0110572
I0403 03:09:30.259690 19294 solver.cpp:244]     Train net output #0: loss = 0.0110572 (* 1 = 0.0110572 loss)
I0403 03:09:30.419426 19294 sgd_solver.cpp:106] Iteration 2110, lr = 0.005
I0403 03:09:37.501205 19294 solver.cpp:228] Iteration 2120, loss = 0.00175795
I0403 03:09:37.506618 19294 solver.cpp:244]     Train net output #0: loss = 0.00175793 (* 1 = 0.00175793 loss)
I0403 03:09:37.690673 19294 sgd_solver.cpp:106] Iteration 2120, lr = 0.005
I0403 03:09:44.674021 19294 solver.cpp:228] Iteration 2130, loss = 0.00651464
I0403 03:09:44.679954 19294 solver.cpp:244]     Train net output #0: loss = 0.00651463 (* 1 = 0.00651463 loss)
I0403 03:09:44.859360 19294 sgd_solver.cpp:106] Iteration 2130, lr = 0.005
I0403 03:09:51.998760 19294 solver.cpp:228] Iteration 2140, loss = 0.0178738
I0403 03:09:52.004648 19294 solver.cpp:244]     Train net output #0: loss = 0.0178738 (* 1 = 0.0178738 loss)
I0403 03:09:52.181951 19294 sgd_solver.cpp:106] Iteration 2140, lr = 0.005
I0403 03:09:59.207717 19294 solver.cpp:228] Iteration 2150, loss = 0.0187529
I0403 03:09:59.214381 19294 solver.cpp:244]     Train net output #0: loss = 0.0187529 (* 1 = 0.0187529 loss)
I0403 03:09:59.386534 19294 sgd_solver.cpp:106] Iteration 2150, lr = 0.005
I0403 03:10:06.442909 19294 solver.cpp:228] Iteration 2160, loss = 0.00138895
I0403 03:10:06.448911 19294 solver.cpp:244]     Train net output #0: loss = 0.00138894 (* 1 = 0.00138894 loss)
I0403 03:10:06.640671 19294 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 03:10:13.151424 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2170.caffemodel
I0403 03:10:15.893875 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2170.solverstate
I0403 03:10:17.767138 19294 solver.cpp:337] Iteration 2170, Testing net (#0)
I0403 03:11:31.233281 19294 solver.cpp:404]     Test net output #0: accuracy = 0.98117
I0403 03:11:31.242048 19294 solver.cpp:404]     Test net output #1: loss = 0.0665939 (* 1 = 0.0665939 loss)
I0403 03:11:31.781486 19294 solver.cpp:228] Iteration 2170, loss = 0.00965872
I0403 03:11:31.787786 19294 solver.cpp:244]     Train net output #0: loss = 0.0096587 (* 1 = 0.0096587 loss)
I0403 03:11:31.932068 19294 sgd_solver.cpp:106] Iteration 2170, lr = 0.005
I0403 03:11:39.211369 19294 solver.cpp:228] Iteration 2180, loss = 0.0213714
I0403 03:11:39.217644 19294 solver.cpp:244]     Train net output #0: loss = 0.0213714 (* 1 = 0.0213714 loss)
I0403 03:11:39.382035 19294 sgd_solver.cpp:106] Iteration 2180, lr = 0.0005
I0403 03:11:46.428889 19294 solver.cpp:228] Iteration 2190, loss = 0.00909589
I0403 03:11:46.434387 19294 solver.cpp:244]     Train net output #0: loss = 0.00909587 (* 1 = 0.00909587 loss)
I0403 03:11:46.607975 19294 sgd_solver.cpp:106] Iteration 2190, lr = 0.0005
I0403 03:11:53.634286 19294 solver.cpp:228] Iteration 2200, loss = 0.00860851
I0403 03:11:53.640949 19294 solver.cpp:244]     Train net output #0: loss = 0.00860849 (* 1 = 0.00860849 loss)
I0403 03:11:53.848564 19294 sgd_solver.cpp:106] Iteration 2200, lr = 0.0005
I0403 03:12:00.880656 19294 solver.cpp:228] Iteration 2210, loss = 0.000204604
I0403 03:12:00.887341 19294 solver.cpp:244]     Train net output #0: loss = 0.000204587 (* 1 = 0.000204587 loss)
I0403 03:12:01.075837 19294 sgd_solver.cpp:106] Iteration 2210, lr = 0.0005
I0403 03:12:08.134233 19294 solver.cpp:228] Iteration 2220, loss = 0.00830203
I0403 03:12:08.140817 19294 solver.cpp:244]     Train net output #0: loss = 0.00830201 (* 1 = 0.00830201 loss)
I0403 03:12:08.352361 19294 sgd_solver.cpp:106] Iteration 2220, lr = 0.0005
I0403 03:12:15.383196 19294 solver.cpp:228] Iteration 2230, loss = 0.00481751
I0403 03:12:15.389015 19294 solver.cpp:244]     Train net output #0: loss = 0.00481749 (* 1 = 0.00481749 loss)
I0403 03:12:15.578094 19294 sgd_solver.cpp:106] Iteration 2230, lr = 0.0005
I0403 03:12:22.620911 19294 solver.cpp:228] Iteration 2240, loss = 0.00328762
I0403 03:12:22.627518 19294 solver.cpp:244]     Train net output #0: loss = 0.0032876 (* 1 = 0.0032876 loss)
I0403 03:12:22.775012 19294 sgd_solver.cpp:106] Iteration 2240, lr = 0.0005
I0403 03:12:30.123530 19294 solver.cpp:228] Iteration 2250, loss = 0.000253416
I0403 03:12:30.129058 19294 solver.cpp:244]     Train net output #0: loss = 0.000253397 (* 1 = 0.000253397 loss)
I0403 03:12:30.321852 19294 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0403 03:12:37.523342 19294 solver.cpp:228] Iteration 2260, loss = 0.00215735
I0403 03:12:37.529273 19294 solver.cpp:244]     Train net output #0: loss = 0.00215733 (* 1 = 0.00215733 loss)
I0403 03:12:37.709076 19294 sgd_solver.cpp:106] Iteration 2260, lr = 0.0005
I0403 03:12:44.762594 19294 solver.cpp:228] Iteration 2270, loss = 0.00833911
I0403 03:12:44.768436 19294 solver.cpp:244]     Train net output #0: loss = 0.00833909 (* 1 = 0.00833909 loss)
I0403 03:12:44.967111 19294 sgd_solver.cpp:106] Iteration 2270, lr = 0.0005
I0403 03:12:52.102771 19294 solver.cpp:228] Iteration 2280, loss = 0.00119129
I0403 03:12:52.107134 19294 solver.cpp:244]     Train net output #0: loss = 0.00119127 (* 1 = 0.00119127 loss)
I0403 03:12:52.281466 19294 sgd_solver.cpp:106] Iteration 2280, lr = 0.0005
I0403 03:12:59.545079 19294 solver.cpp:228] Iteration 2290, loss = 0.00130348
I0403 03:12:59.555274 19294 solver.cpp:244]     Train net output #0: loss = 0.00130347 (* 1 = 0.00130347 loss)
I0403 03:12:59.774154 19294 sgd_solver.cpp:106] Iteration 2290, lr = 0.0005
I0403 03:13:06.878744 19294 solver.cpp:228] Iteration 2300, loss = 0.000664566
I0403 03:13:06.885790 19294 solver.cpp:244]     Train net output #0: loss = 0.000664549 (* 1 = 0.000664549 loss)
I0403 03:13:07.078789 19294 sgd_solver.cpp:106] Iteration 2300, lr = 0.0005
I0403 03:13:14.114404 19294 solver.cpp:228] Iteration 2310, loss = 0.000666481
I0403 03:13:14.119885 19294 solver.cpp:244]     Train net output #0: loss = 0.000666465 (* 1 = 0.000666465 loss)
I0403 03:13:14.301688 19294 sgd_solver.cpp:106] Iteration 2310, lr = 0.0005
I0403 03:13:21.277384 19294 solver.cpp:228] Iteration 2320, loss = 0.00177685
I0403 03:13:21.283731 19294 solver.cpp:244]     Train net output #0: loss = 0.00177683 (* 1 = 0.00177683 loss)
I0403 03:13:21.462255 19294 sgd_solver.cpp:106] Iteration 2320, lr = 0.0005
I0403 03:13:28.555683 19294 solver.cpp:228] Iteration 2330, loss = 0.000114236
I0403 03:13:28.561497 19294 solver.cpp:244]     Train net output #0: loss = 0.00011422 (* 1 = 0.00011422 loss)
I0403 03:13:28.738306 19294 sgd_solver.cpp:106] Iteration 2330, lr = 0.0005
I0403 03:13:35.787802 19294 solver.cpp:228] Iteration 2340, loss = 9.42578e-05
I0403 03:13:35.793726 19294 solver.cpp:244]     Train net output #0: loss = 9.42418e-05 (* 1 = 9.42418e-05 loss)
I0403 03:13:35.978138 19294 sgd_solver.cpp:106] Iteration 2340, lr = 0.0005
I0403 03:13:43.284126 19294 solver.cpp:228] Iteration 2350, loss = 0.00842191
I0403 03:13:43.290446 19294 solver.cpp:244]     Train net output #0: loss = 0.0084219 (* 1 = 0.0084219 loss)
I0403 03:13:43.469880 19294 sgd_solver.cpp:106] Iteration 2350, lr = 0.0005
I0403 03:13:50.701062 19294 solver.cpp:228] Iteration 2360, loss = 0.0149584
I0403 03:13:50.707070 19294 solver.cpp:244]     Train net output #0: loss = 0.0149584 (* 1 = 0.0149584 loss)
I0403 03:13:50.862613 19294 sgd_solver.cpp:106] Iteration 2360, lr = 0.0005
I0403 03:13:57.986778 19294 solver.cpp:228] Iteration 2370, loss = 0.00180178
I0403 03:13:57.993930 19294 solver.cpp:244]     Train net output #0: loss = 0.00180176 (* 1 = 0.00180176 loss)
I0403 03:13:58.166877 19294 sgd_solver.cpp:106] Iteration 2370, lr = 0.0005
I0403 03:14:05.422890 19294 solver.cpp:228] Iteration 2380, loss = 0.00490748
I0403 03:14:05.430016 19294 solver.cpp:244]     Train net output #0: loss = 0.00490747 (* 1 = 0.00490747 loss)
I0403 03:14:05.614116 19294 sgd_solver.cpp:106] Iteration 2380, lr = 0.0005
I0403 03:14:09.957027 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2387.caffemodel
I0403 03:14:12.716081 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2387.solverstate
I0403 03:14:14.573482 19294 solver.cpp:337] Iteration 2387, Testing net (#0)
I0403 03:15:28.060120 19294 solver.cpp:404]     Test net output #0: accuracy = 0.984246
I0403 03:15:28.066815 19294 solver.cpp:404]     Test net output #1: loss = 0.0546365 (* 1 = 0.0546365 loss)
I0403 03:15:30.820945 19294 solver.cpp:228] Iteration 2390, loss = 0.0004431
I0403 03:15:30.827426 19294 solver.cpp:244]     Train net output #0: loss = 0.000443088 (* 1 = 0.000443088 loss)
I0403 03:15:30.988756 19294 sgd_solver.cpp:106] Iteration 2390, lr = 0.0005
I0403 03:15:38.260890 19294 solver.cpp:228] Iteration 2400, loss = 0.00788569
I0403 03:15:38.269091 19294 solver.cpp:244]     Train net output #0: loss = 0.00788568 (* 1 = 0.00788568 loss)
I0403 03:15:38.457749 19294 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I0403 03:15:45.563964 19294 solver.cpp:228] Iteration 2410, loss = 0.0171974
I0403 03:15:45.570320 19294 solver.cpp:244]     Train net output #0: loss = 0.0171974 (* 1 = 0.0171974 loss)
I0403 03:15:45.741605 19294 sgd_solver.cpp:106] Iteration 2410, lr = 0.0005
I0403 03:15:52.861364 19294 solver.cpp:228] Iteration 2420, loss = 0.0127064
I0403 03:15:52.866312 19294 solver.cpp:244]     Train net output #0: loss = 0.0127064 (* 1 = 0.0127064 loss)
I0403 03:15:53.074666 19294 sgd_solver.cpp:106] Iteration 2420, lr = 0.0005
I0403 03:16:00.096014 19294 solver.cpp:228] Iteration 2430, loss = 0.000308886
I0403 03:16:00.102146 19294 solver.cpp:244]     Train net output #0: loss = 0.000308876 (* 1 = 0.000308876 loss)
I0403 03:16:00.293761 19294 sgd_solver.cpp:106] Iteration 2430, lr = 0.0005
I0403 03:16:07.352998 19294 solver.cpp:228] Iteration 2440, loss = 0.000162956
I0403 03:16:07.360811 19294 solver.cpp:244]     Train net output #0: loss = 0.000162947 (* 1 = 0.000162947 loss)
I0403 03:16:07.583338 19294 sgd_solver.cpp:106] Iteration 2440, lr = 0.0005
I0403 03:16:14.713253 19294 solver.cpp:228] Iteration 2450, loss = 0.014936
I0403 03:16:14.718858 19294 solver.cpp:244]     Train net output #0: loss = 0.014936 (* 1 = 0.014936 loss)
I0403 03:16:14.892524 19294 sgd_solver.cpp:106] Iteration 2450, lr = 0.0005
I0403 03:16:21.930248 19294 solver.cpp:228] Iteration 2460, loss = 0.000867299
I0403 03:16:21.935644 19294 solver.cpp:244]     Train net output #0: loss = 0.000867288 (* 1 = 0.000867288 loss)
I0403 03:16:22.105221 19294 sgd_solver.cpp:106] Iteration 2460, lr = 0.0005
I0403 03:16:29.182451 19294 solver.cpp:228] Iteration 2470, loss = 0.000103921
I0403 03:16:29.188319 19294 solver.cpp:244]     Train net output #0: loss = 0.000103911 (* 1 = 0.000103911 loss)
I0403 03:16:29.366961 19294 sgd_solver.cpp:106] Iteration 2470, lr = 0.0005
I0403 03:16:36.479290 19294 solver.cpp:228] Iteration 2480, loss = 0.00119935
I0403 03:16:36.486258 19294 solver.cpp:244]     Train net output #0: loss = 0.00119934 (* 1 = 0.00119934 loss)
I0403 03:16:36.660557 19294 sgd_solver.cpp:106] Iteration 2480, lr = 0.0005
I0403 03:16:43.671176 19294 solver.cpp:228] Iteration 2490, loss = 0.0192446
I0403 03:16:43.676457 19294 solver.cpp:244]     Train net output #0: loss = 0.0192445 (* 1 = 0.0192445 loss)
I0403 03:16:43.849272 19294 sgd_solver.cpp:106] Iteration 2490, lr = 0.0005
I0403 03:16:50.914877 19294 solver.cpp:228] Iteration 2500, loss = 0.000608239
I0403 03:16:50.921847 19294 solver.cpp:244]     Train net output #0: loss = 0.00060823 (* 1 = 0.00060823 loss)
I0403 03:16:51.082011 19294 sgd_solver.cpp:106] Iteration 2500, lr = 0.0005
I0403 03:16:58.209991 19294 solver.cpp:228] Iteration 2510, loss = 0.00121234
I0403 03:16:58.216998 19294 solver.cpp:244]     Train net output #0: loss = 0.00121233 (* 1 = 0.00121233 loss)
I0403 03:16:58.379659 19294 sgd_solver.cpp:106] Iteration 2510, lr = 0.0005
I0403 03:17:05.489876 19294 solver.cpp:228] Iteration 2520, loss = 0.000170333
I0403 03:17:05.495671 19294 solver.cpp:244]     Train net output #0: loss = 0.000170324 (* 1 = 0.000170324 loss)
I0403 03:17:05.671146 19294 sgd_solver.cpp:106] Iteration 2520, lr = 0.0005
I0403 03:17:12.692749 19294 solver.cpp:228] Iteration 2530, loss = 0.000536046
I0403 03:17:12.699206 19294 solver.cpp:244]     Train net output #0: loss = 0.000536037 (* 1 = 0.000536037 loss)
I0403 03:17:12.872638 19294 sgd_solver.cpp:106] Iteration 2530, lr = 0.0005
I0403 03:17:20.010535 19294 solver.cpp:228] Iteration 2540, loss = 0.00245739
I0403 03:17:20.016700 19294 solver.cpp:244]     Train net output #0: loss = 0.00245738 (* 1 = 0.00245738 loss)
I0403 03:17:20.234088 19294 sgd_solver.cpp:106] Iteration 2540, lr = 0.0005
I0403 03:17:27.243023 19294 solver.cpp:228] Iteration 2550, loss = 0.000166431
I0403 03:17:27.250526 19294 solver.cpp:244]     Train net output #0: loss = 0.00016642 (* 1 = 0.00016642 loss)
I0403 03:17:27.412040 19294 sgd_solver.cpp:106] Iteration 2550, lr = 0.0005
I0403 03:17:34.580550 19294 solver.cpp:228] Iteration 2560, loss = 0.00133569
I0403 03:17:34.586612 19294 solver.cpp:244]     Train net output #0: loss = 0.00133568 (* 1 = 0.00133568 loss)
I0403 03:17:34.749121 19294 sgd_solver.cpp:106] Iteration 2560, lr = 0.0005
I0403 03:17:42.029433 19294 solver.cpp:228] Iteration 2570, loss = 0.0016516
I0403 03:17:42.039172 19294 solver.cpp:244]     Train net output #0: loss = 0.00165159 (* 1 = 0.00165159 loss)
I0403 03:17:42.189340 19294 sgd_solver.cpp:106] Iteration 2570, lr = 0.0005
I0403 03:17:49.419296 19294 solver.cpp:228] Iteration 2580, loss = 0.00023938
I0403 03:17:49.424553 19294 solver.cpp:244]     Train net output #0: loss = 0.000239373 (* 1 = 0.000239373 loss)
I0403 03:17:49.610528 19294 sgd_solver.cpp:106] Iteration 2580, lr = 0.0005
I0403 03:17:56.608844 19294 solver.cpp:228] Iteration 2590, loss = 0.000647494
I0403 03:17:56.614919 19294 solver.cpp:244]     Train net output #0: loss = 0.00064749 (* 1 = 0.00064749 loss)
I0403 03:17:56.834643 19294 sgd_solver.cpp:106] Iteration 2590, lr = 0.0005
I0403 03:18:03.903337 19294 solver.cpp:228] Iteration 2600, loss = 0.000238564
I0403 03:18:03.909073 19294 solver.cpp:244]     Train net output #0: loss = 0.000238559 (* 1 = 0.000238559 loss)
I0403 03:18:04.087262 19294 sgd_solver.cpp:106] Iteration 2600, lr = 0.0005
I0403 03:18:06.284876 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2604.caffemodel
I0403 03:18:09.069128 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2604.solverstate
I0403 03:18:10.952724 19294 solver.cpp:337] Iteration 2604, Testing net (#0)
I0403 03:19:24.490149 19294 solver.cpp:404]     Test net output #0: accuracy = 0.985139
I0403 03:19:24.498105 19294 solver.cpp:404]     Test net output #1: loss = 0.0530936 (* 1 = 0.0530936 loss)
I0403 03:19:29.349056 19294 solver.cpp:228] Iteration 2610, loss = 0.0031017
I0403 03:19:29.355051 19294 solver.cpp:244]     Train net output #0: loss = 0.0031017 (* 1 = 0.0031017 loss)
I0403 03:19:29.528554 19294 sgd_solver.cpp:106] Iteration 2610, lr = 0.0005
I0403 03:19:36.647069 19294 solver.cpp:228] Iteration 2620, loss = 0.00840787
I0403 03:19:36.652640 19294 solver.cpp:244]     Train net output #0: loss = 0.00840787 (* 1 = 0.00840787 loss)
I0403 03:19:36.808924 19294 sgd_solver.cpp:106] Iteration 2620, lr = 0.0005
I0403 03:19:44.007707 19294 solver.cpp:228] Iteration 2630, loss = 0.00207177
I0403 03:19:44.014228 19294 solver.cpp:244]     Train net output #0: loss = 0.00207177 (* 1 = 0.00207177 loss)
I0403 03:19:44.187479 19294 sgd_solver.cpp:106] Iteration 2630, lr = 0.0005
I0403 03:19:51.342263 19294 solver.cpp:228] Iteration 2640, loss = 0.000554658
I0403 03:19:51.348363 19294 solver.cpp:244]     Train net output #0: loss = 0.000554654 (* 1 = 0.000554654 loss)
I0403 03:19:51.506242 19294 sgd_solver.cpp:106] Iteration 2640, lr = 0.0005
I0403 03:19:58.830202 19294 solver.cpp:228] Iteration 2650, loss = 0.000501372
I0403 03:19:58.838598 19294 solver.cpp:244]     Train net output #0: loss = 0.000501369 (* 1 = 0.000501369 loss)
I0403 03:19:59.018457 19294 sgd_solver.cpp:106] Iteration 2650, lr = 0.0005
I0403 03:20:06.226392 19294 solver.cpp:228] Iteration 2660, loss = 0.000192507
I0403 03:20:06.232677 19294 solver.cpp:244]     Train net output #0: loss = 0.000192504 (* 1 = 0.000192504 loss)
I0403 03:20:06.408262 19294 sgd_solver.cpp:106] Iteration 2660, lr = 0.0005
I0403 03:20:13.482141 19294 solver.cpp:228] Iteration 2670, loss = 0.00233488
I0403 03:20:13.492827 19294 solver.cpp:244]     Train net output #0: loss = 0.00233487 (* 1 = 0.00233487 loss)
I0403 03:20:13.709363 19294 sgd_solver.cpp:106] Iteration 2670, lr = 0.0005
I0403 03:20:20.738311 19294 solver.cpp:228] Iteration 2680, loss = 0.00089172
I0403 03:20:20.744042 19294 solver.cpp:244]     Train net output #0: loss = 0.000891716 (* 1 = 0.000891716 loss)
I0403 03:20:20.918593 19294 sgd_solver.cpp:106] Iteration 2680, lr = 0.0005
I0403 03:20:28.021651 19294 solver.cpp:228] Iteration 2690, loss = 0.00105242
I0403 03:20:28.027267 19294 solver.cpp:244]     Train net output #0: loss = 0.00105242 (* 1 = 0.00105242 loss)
I0403 03:20:28.217774 19294 sgd_solver.cpp:106] Iteration 2690, lr = 0.0005
I0403 03:20:35.282268 19294 solver.cpp:228] Iteration 2700, loss = 2.50679e-05
I0403 03:20:35.289018 19294 solver.cpp:244]     Train net output #0: loss = 2.50646e-05 (* 1 = 2.50646e-05 loss)
I0403 03:20:35.490406 19294 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I0403 03:20:42.582852 19294 solver.cpp:228] Iteration 2710, loss = 0.000368607
I0403 03:20:42.588871 19294 solver.cpp:244]     Train net output #0: loss = 0.000368604 (* 1 = 0.000368604 loss)
I0403 03:20:42.751715 19294 sgd_solver.cpp:106] Iteration 2710, lr = 0.0005
I0403 03:20:50.002990 19294 solver.cpp:228] Iteration 2720, loss = 0.0077394
I0403 03:20:50.009464 19294 solver.cpp:244]     Train net output #0: loss = 0.00773939 (* 1 = 0.00773939 loss)
I0403 03:20:50.151836 19294 sgd_solver.cpp:106] Iteration 2720, lr = 0.0005
I0403 03:20:57.306777 19294 solver.cpp:228] Iteration 2730, loss = 0.00146509
I0403 03:20:57.312549 19294 solver.cpp:244]     Train net output #0: loss = 0.00146508 (* 1 = 0.00146508 loss)
I0403 03:20:57.507709 19294 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 03:21:04.558670 19294 solver.cpp:228] Iteration 2740, loss = 0.000748346
I0403 03:21:04.565842 19294 solver.cpp:244]     Train net output #0: loss = 0.000748341 (* 1 = 0.000748341 loss)
I0403 03:21:04.738293 19294 sgd_solver.cpp:106] Iteration 2740, lr = 0.0005
I0403 03:21:11.764803 19294 solver.cpp:228] Iteration 2750, loss = 0.00314597
I0403 03:21:11.771096 19294 solver.cpp:244]     Train net output #0: loss = 0.00314597 (* 1 = 0.00314597 loss)
I0403 03:21:11.964157 19294 sgd_solver.cpp:106] Iteration 2750, lr = 0.0005
I0403 03:21:18.951022 19294 solver.cpp:228] Iteration 2760, loss = 0.00130167
I0403 03:21:18.957376 19294 solver.cpp:244]     Train net output #0: loss = 0.00130167 (* 1 = 0.00130167 loss)
I0403 03:21:19.147609 19294 sgd_solver.cpp:106] Iteration 2760, lr = 0.0005
I0403 03:21:26.197373 19294 solver.cpp:228] Iteration 2770, loss = 0.000296322
I0403 03:21:26.202582 19294 solver.cpp:244]     Train net output #0: loss = 0.000296317 (* 1 = 0.000296317 loss)
I0403 03:21:26.398208 19294 sgd_solver.cpp:106] Iteration 2770, lr = 0.0005
I0403 03:21:33.532487 19294 solver.cpp:228] Iteration 2780, loss = 0.00476735
I0403 03:21:33.538853 19294 solver.cpp:244]     Train net output #0: loss = 0.00476734 (* 1 = 0.00476734 loss)
I0403 03:21:33.727821 19294 sgd_solver.cpp:106] Iteration 2780, lr = 0.0005
I0403 03:21:40.721055 19294 solver.cpp:228] Iteration 2790, loss = 0.00270131
I0403 03:21:40.725962 19294 solver.cpp:244]     Train net output #0: loss = 0.0027013 (* 1 = 0.0027013 loss)
I0403 03:21:40.911948 19294 sgd_solver.cpp:106] Iteration 2790, lr = 0.0005
I0403 03:21:47.996997 19294 solver.cpp:228] Iteration 2800, loss = 0.00384377
I0403 03:21:48.004312 19294 solver.cpp:244]     Train net output #0: loss = 0.00384376 (* 1 = 0.00384376 loss)
I0403 03:21:48.202507 19294 sgd_solver.cpp:106] Iteration 2800, lr = 0.0005
I0403 03:21:55.289108 19294 solver.cpp:228] Iteration 2810, loss = 0.000577417
I0403 03:21:55.294452 19294 solver.cpp:244]     Train net output #0: loss = 0.000577411 (* 1 = 0.000577411 loss)
I0403 03:21:55.474223 19294 sgd_solver.cpp:106] Iteration 2810, lr = 0.0005
I0403 03:22:02.545291 19294 solver.cpp:228] Iteration 2820, loss = 0.00403175
I0403 03:22:02.550971 19294 solver.cpp:244]     Train net output #0: loss = 0.00403175 (* 1 = 0.00403175 loss)
I0403 03:22:02.672914 19294 sgd_solver.cpp:106] Iteration 2820, lr = 0.0005
I0403 03:22:02.673166 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2821.caffemodel
I0403 03:22:05.506573 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_2821.solverstate
I0403 03:22:07.372508 19294 solver.cpp:337] Iteration 2821, Testing net (#0)
I0403 03:23:20.850813 19294 solver.cpp:404]     Test net output #0: accuracy = 0.984862
I0403 03:23:20.860018 19294 solver.cpp:404]     Test net output #1: loss = 0.0527623 (* 1 = 0.0527623 loss)
I0403 03:23:27.961875 19294 solver.cpp:228] Iteration 2830, loss = 0.000865438
I0403 03:23:27.968446 19294 solver.cpp:244]     Train net output #0: loss = 0.000865434 (* 1 = 0.000865434 loss)
I0403 03:23:28.145841 19294 sgd_solver.cpp:106] Iteration 2830, lr = 0.0005
I0403 03:23:35.184756 19294 solver.cpp:228] Iteration 2840, loss = 0.000396431
I0403 03:23:35.191141 19294 solver.cpp:244]     Train net output #0: loss = 0.000396427 (* 1 = 0.000396427 loss)
I0403 03:23:35.385128 19294 sgd_solver.cpp:106] Iteration 2840, lr = 0.0005
I0403 03:23:42.488039 19294 solver.cpp:228] Iteration 2850, loss = 0.00183189
I0403 03:23:42.493489 19294 solver.cpp:244]     Train net output #0: loss = 0.00183189 (* 1 = 0.00183189 loss)
I0403 03:23:42.669459 19294 sgd_solver.cpp:106] Iteration 2850, lr = 0.0005
I0403 03:23:49.647922 19294 solver.cpp:228] Iteration 2860, loss = 0.0108124
I0403 03:23:49.663233 19294 solver.cpp:244]     Train net output #0: loss = 0.0108124 (* 1 = 0.0108124 loss)
I0403 03:23:49.827711 19294 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 03:23:56.873982 19294 solver.cpp:228] Iteration 2870, loss = 0.000174726
I0403 03:23:56.880086 19294 solver.cpp:244]     Train net output #0: loss = 0.000174724 (* 1 = 0.000174724 loss)
I0403 03:23:57.038002 19294 sgd_solver.cpp:106] Iteration 2870, lr = 0.0005
I0403 03:24:04.099308 19294 solver.cpp:228] Iteration 2880, loss = 0.000281427
I0403 03:24:04.104703 19294 solver.cpp:244]     Train net output #0: loss = 0.000281425 (* 1 = 0.000281425 loss)
I0403 03:24:04.298408 19294 sgd_solver.cpp:106] Iteration 2880, lr = 0.0005
I0403 03:24:11.492465 19294 solver.cpp:228] Iteration 2890, loss = 0.000193924
I0403 03:24:11.498922 19294 solver.cpp:244]     Train net output #0: loss = 0.000193923 (* 1 = 0.000193923 loss)
I0403 03:24:11.660704 19294 sgd_solver.cpp:106] Iteration 2890, lr = 0.0005
I0403 03:24:19.024130 19294 solver.cpp:228] Iteration 2900, loss = 0.000389945
I0403 03:24:19.029605 19294 solver.cpp:244]     Train net output #0: loss = 0.000389944 (* 1 = 0.000389944 loss)
I0403 03:24:19.195250 19294 sgd_solver.cpp:106] Iteration 2900, lr = 0.0005
I0403 03:24:26.300755 19294 solver.cpp:228] Iteration 2910, loss = 0.000113059
I0403 03:24:26.305677 19294 solver.cpp:244]     Train net output #0: loss = 0.000113058 (* 1 = 0.000113058 loss)
I0403 03:24:26.501070 19294 sgd_solver.cpp:106] Iteration 2910, lr = 0.0005
I0403 03:24:33.757519 19294 solver.cpp:228] Iteration 2920, loss = 0.000271462
I0403 03:24:33.762895 19294 solver.cpp:244]     Train net output #0: loss = 0.000271461 (* 1 = 0.000271461 loss)
I0403 03:24:33.910750 19294 sgd_solver.cpp:106] Iteration 2920, lr = 0.0005
I0403 03:24:41.074043 19294 solver.cpp:228] Iteration 2930, loss = 0.00360888
I0403 03:24:41.079946 19294 solver.cpp:244]     Train net output #0: loss = 0.00360887 (* 1 = 0.00360887 loss)
I0403 03:24:41.260334 19294 sgd_solver.cpp:106] Iteration 2930, lr = 0.0005
I0403 03:24:48.344374 19294 solver.cpp:228] Iteration 2940, loss = 0.000191908
I0403 03:24:48.350000 19294 solver.cpp:244]     Train net output #0: loss = 0.000191907 (* 1 = 0.000191907 loss)
I0403 03:24:48.535178 19294 sgd_solver.cpp:106] Iteration 2940, lr = 0.0005
I0403 03:24:55.640130 19294 solver.cpp:228] Iteration 2950, loss = 0.000398787
I0403 03:24:55.645898 19294 solver.cpp:244]     Train net output #0: loss = 0.000398785 (* 1 = 0.000398785 loss)
I0403 03:24:55.857313 19294 sgd_solver.cpp:106] Iteration 2950, lr = 0.0005
I0403 03:25:02.983641 19294 solver.cpp:228] Iteration 2960, loss = 0.000237221
I0403 03:25:02.991576 19294 solver.cpp:244]     Train net output #0: loss = 0.000237219 (* 1 = 0.000237219 loss)
I0403 03:25:03.159215 19294 sgd_solver.cpp:106] Iteration 2960, lr = 0.0005
I0403 03:25:10.310080 19294 solver.cpp:228] Iteration 2970, loss = 0.000842807
I0403 03:25:10.321671 19294 solver.cpp:244]     Train net output #0: loss = 0.000842804 (* 1 = 0.000842804 loss)
I0403 03:25:10.495460 19294 sgd_solver.cpp:106] Iteration 2970, lr = 0.0005
I0403 03:25:17.635710 19294 solver.cpp:228] Iteration 2980, loss = 0.000527596
I0403 03:25:17.641418 19294 solver.cpp:244]     Train net output #0: loss = 0.000527593 (* 1 = 0.000527593 loss)
I0403 03:25:17.791100 19294 sgd_solver.cpp:106] Iteration 2980, lr = 0.0005
I0403 03:25:25.296988 19294 solver.cpp:228] Iteration 2990, loss = 2.03873e-05
I0403 03:25:25.304378 19294 solver.cpp:244]     Train net output #0: loss = 2.03845e-05 (* 1 = 2.03845e-05 loss)
I0403 03:25:25.475136 19294 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 03:25:32.679471 19294 solver.cpp:228] Iteration 3000, loss = 0.0013898
I0403 03:25:32.686542 19294 solver.cpp:244]     Train net output #0: loss = 0.0013898 (* 1 = 0.0013898 loss)
I0403 03:25:32.860699 19294 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0403 03:25:39.882537 19294 solver.cpp:228] Iteration 3010, loss = 0.00167786
I0403 03:25:39.889232 19294 solver.cpp:244]     Train net output #0: loss = 0.00167786 (* 1 = 0.00167786 loss)
I0403 03:25:40.061029 19294 sgd_solver.cpp:106] Iteration 3010, lr = 0.0005
I0403 03:25:47.272876 19294 solver.cpp:228] Iteration 3020, loss = 0.00106389
I0403 03:25:47.281325 19294 solver.cpp:244]     Train net output #0: loss = 0.00106389 (* 1 = 0.00106389 loss)
I0403 03:25:47.473222 19294 sgd_solver.cpp:106] Iteration 3020, lr = 0.0005
I0403 03:25:54.659844 19294 solver.cpp:228] Iteration 3030, loss = 0.000171744
I0403 03:25:54.666216 19294 solver.cpp:244]     Train net output #0: loss = 0.00017174 (* 1 = 0.00017174 loss)
I0403 03:25:54.838837 19294 sgd_solver.cpp:106] Iteration 3030, lr = 0.0005
I0403 03:26:00.040535 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3038.caffemodel
I0403 03:26:02.790500 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3038.solverstate
I0403 03:26:04.663012 19294 solver.cpp:337] Iteration 3038, Testing net (#0)
I0403 03:27:18.150629 19294 solver.cpp:404]     Test net output #0: accuracy = 0.985754
I0403 03:27:18.161927 19294 solver.cpp:404]     Test net output #1: loss = 0.051641 (* 1 = 0.051641 loss)
I0403 03:27:20.141223 19294 solver.cpp:228] Iteration 3040, loss = 0.000323168
I0403 03:27:20.147946 19294 solver.cpp:244]     Train net output #0: loss = 0.000323164 (* 1 = 0.000323164 loss)
I0403 03:27:20.321723 19294 sgd_solver.cpp:106] Iteration 3040, lr = 0.0005
I0403 03:27:27.567981 19294 solver.cpp:228] Iteration 3050, loss = 0.00063686
I0403 03:27:27.574758 19294 solver.cpp:244]     Train net output #0: loss = 0.000636857 (* 1 = 0.000636857 loss)
I0403 03:27:27.769412 19294 sgd_solver.cpp:106] Iteration 3050, lr = 0.0005
I0403 03:27:34.832432 19294 solver.cpp:228] Iteration 3060, loss = 0.00424886
I0403 03:27:34.838620 19294 solver.cpp:244]     Train net output #0: loss = 0.00424885 (* 1 = 0.00424885 loss)
I0403 03:27:34.999573 19294 sgd_solver.cpp:106] Iteration 3060, lr = 0.0005
I0403 03:27:42.084269 19294 solver.cpp:228] Iteration 3070, loss = 0.00236895
I0403 03:27:42.089593 19294 solver.cpp:244]     Train net output #0: loss = 0.00236895 (* 1 = 0.00236895 loss)
I0403 03:27:42.264837 19294 sgd_solver.cpp:106] Iteration 3070, lr = 0.0005
I0403 03:27:49.369498 19294 solver.cpp:228] Iteration 3080, loss = 0.000680102
I0403 03:27:49.376456 19294 solver.cpp:244]     Train net output #0: loss = 0.000680098 (* 1 = 0.000680098 loss)
I0403 03:27:49.548357 19294 sgd_solver.cpp:106] Iteration 3080, lr = 0.0005
I0403 03:27:56.594774 19294 solver.cpp:228] Iteration 3090, loss = 0.000433732
I0403 03:27:56.600941 19294 solver.cpp:244]     Train net output #0: loss = 0.000433728 (* 1 = 0.000433728 loss)
I0403 03:27:56.773941 19294 sgd_solver.cpp:106] Iteration 3090, lr = 0.0005
I0403 03:28:03.742506 19294 solver.cpp:228] Iteration 3100, loss = 0.000126931
I0403 03:28:03.748065 19294 solver.cpp:244]     Train net output #0: loss = 0.000126927 (* 1 = 0.000126927 loss)
I0403 03:28:03.931089 19294 sgd_solver.cpp:106] Iteration 3100, lr = 0.0005
I0403 03:28:11.052892 19294 solver.cpp:228] Iteration 3110, loss = 0.00396811
I0403 03:28:11.058221 19294 solver.cpp:244]     Train net output #0: loss = 0.0039681 (* 1 = 0.0039681 loss)
I0403 03:28:11.197674 19294 sgd_solver.cpp:106] Iteration 3110, lr = 0.0005
I0403 03:28:18.405133 19294 solver.cpp:228] Iteration 3120, loss = 0.00199142
I0403 03:28:18.411273 19294 solver.cpp:244]     Train net output #0: loss = 0.00199142 (* 1 = 0.00199142 loss)
I0403 03:28:18.582051 19294 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 03:28:25.708364 19294 solver.cpp:228] Iteration 3130, loss = 0.00101076
I0403 03:28:25.713759 19294 solver.cpp:244]     Train net output #0: loss = 0.00101075 (* 1 = 0.00101075 loss)
I0403 03:28:25.905913 19294 sgd_solver.cpp:106] Iteration 3130, lr = 0.0005
I0403 03:28:32.980571 19294 solver.cpp:228] Iteration 3140, loss = 0.00662593
I0403 03:28:32.986402 19294 solver.cpp:244]     Train net output #0: loss = 0.00662593 (* 1 = 0.00662593 loss)
I0403 03:28:33.161794 19294 sgd_solver.cpp:106] Iteration 3140, lr = 0.0005
I0403 03:28:40.234290 19294 solver.cpp:228] Iteration 3150, loss = 0.00119712
I0403 03:28:40.240033 19294 solver.cpp:244]     Train net output #0: loss = 0.00119711 (* 1 = 0.00119711 loss)
I0403 03:28:40.412544 19294 sgd_solver.cpp:106] Iteration 3150, lr = 0.0005
I0403 03:28:47.504247 19294 solver.cpp:228] Iteration 3160, loss = 0.00165839
I0403 03:28:47.510097 19294 solver.cpp:244]     Train net output #0: loss = 0.00165839 (* 1 = 0.00165839 loss)
I0403 03:28:47.700736 19294 sgd_solver.cpp:106] Iteration 3160, lr = 0.0005
I0403 03:28:54.808549 19294 solver.cpp:228] Iteration 3170, loss = 0.00293804
I0403 03:28:54.815292 19294 solver.cpp:244]     Train net output #0: loss = 0.00293804 (* 1 = 0.00293804 loss)
I0403 03:28:54.979208 19294 sgd_solver.cpp:106] Iteration 3170, lr = 0.0005
I0403 03:29:02.098808 19294 solver.cpp:228] Iteration 3180, loss = 0.00034292
I0403 03:29:02.105280 19294 solver.cpp:244]     Train net output #0: loss = 0.000342917 (* 1 = 0.000342917 loss)
I0403 03:29:02.275331 19294 sgd_solver.cpp:106] Iteration 3180, lr = 0.0005
I0403 03:29:09.292564 19294 solver.cpp:228] Iteration 3190, loss = 0.000172902
I0403 03:29:09.298277 19294 solver.cpp:244]     Train net output #0: loss = 0.000172899 (* 1 = 0.000172899 loss)
I0403 03:29:09.477370 19294 sgd_solver.cpp:106] Iteration 3190, lr = 0.0005
I0403 03:29:16.565465 19294 solver.cpp:228] Iteration 3200, loss = 3.10576e-05
I0403 03:29:16.572227 19294 solver.cpp:244]     Train net output #0: loss = 3.1055e-05 (* 1 = 3.1055e-05 loss)
I0403 03:29:16.726066 19294 sgd_solver.cpp:106] Iteration 3200, lr = 0.0005
I0403 03:29:23.873549 19294 solver.cpp:228] Iteration 3210, loss = 0.000146277
I0403 03:29:23.880995 19294 solver.cpp:244]     Train net output #0: loss = 0.000146274 (* 1 = 0.000146274 loss)
I0403 03:29:24.044471 19294 sgd_solver.cpp:106] Iteration 3210, lr = 0.0005
I0403 03:29:31.102682 19294 solver.cpp:228] Iteration 3220, loss = 0.000581485
I0403 03:29:31.109005 19294 solver.cpp:244]     Train net output #0: loss = 0.000581482 (* 1 = 0.000581482 loss)
I0403 03:29:31.286542 19294 sgd_solver.cpp:106] Iteration 3220, lr = 0.0005
I0403 03:29:38.322401 19294 solver.cpp:228] Iteration 3230, loss = 0.000730225
I0403 03:29:38.329334 19294 solver.cpp:244]     Train net output #0: loss = 0.000730222 (* 1 = 0.000730222 loss)
I0403 03:29:38.503928 19294 sgd_solver.cpp:106] Iteration 3230, lr = 0.0005
I0403 03:29:45.557080 19294 solver.cpp:228] Iteration 3240, loss = 0.00924398
I0403 03:29:45.564472 19294 solver.cpp:244]     Train net output #0: loss = 0.00924398 (* 1 = 0.00924398 loss)
I0403 03:29:45.742384 19294 sgd_solver.cpp:106] Iteration 3240, lr = 0.0005
I0403 03:29:53.070933 19294 solver.cpp:228] Iteration 3250, loss = 0.000378367
I0403 03:29:53.077129 19294 solver.cpp:244]     Train net output #0: loss = 0.000378369 (* 1 = 0.000378369 loss)
I0403 03:29:53.260078 19294 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 03:29:56.113802 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3255.caffemodel
I0403 03:29:58.868852 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3255.solverstate
I0403 03:30:00.715739 19294 solver.cpp:337] Iteration 3255, Testing net (#0)
I0403 03:31:14.267323 19294 solver.cpp:404]     Test net output #0: accuracy = 0.985293
I0403 03:31:14.275722 19294 solver.cpp:404]     Test net output #1: loss = 0.0514161 (* 1 = 0.0514161 loss)
I0403 03:31:18.432343 19294 solver.cpp:228] Iteration 3260, loss = 0.00149003
I0403 03:31:18.438653 19294 solver.cpp:244]     Train net output #0: loss = 0.00149004 (* 1 = 0.00149004 loss)
I0403 03:31:18.642341 19294 sgd_solver.cpp:106] Iteration 3260, lr = 0.0005
I0403 03:31:25.861726 19294 solver.cpp:228] Iteration 3270, loss = 0.000342584
I0403 03:31:25.867316 19294 solver.cpp:244]     Train net output #0: loss = 0.000342587 (* 1 = 0.000342587 loss)
I0403 03:31:26.034127 19294 sgd_solver.cpp:106] Iteration 3270, lr = 0.0005
I0403 03:31:33.214768 19294 solver.cpp:228] Iteration 3280, loss = 0.000368382
I0403 03:31:33.221649 19294 solver.cpp:244]     Train net output #0: loss = 0.000368384 (* 1 = 0.000368384 loss)
I0403 03:31:33.407886 19294 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 03:31:40.500689 19294 solver.cpp:228] Iteration 3290, loss = 0.000298459
I0403 03:31:40.506983 19294 solver.cpp:244]     Train net output #0: loss = 0.000298462 (* 1 = 0.000298462 loss)
I0403 03:31:40.682389 19294 sgd_solver.cpp:106] Iteration 3290, lr = 0.0005
I0403 03:31:47.820242 19294 solver.cpp:228] Iteration 3300, loss = 8.16367e-05
I0403 03:31:47.826637 19294 solver.cpp:244]     Train net output #0: loss = 8.16398e-05 (* 1 = 8.16398e-05 loss)
I0403 03:31:48.045111 19294 sgd_solver.cpp:106] Iteration 3300, lr = 0.0005
I0403 03:31:55.101842 19294 solver.cpp:228] Iteration 3310, loss = 8.51005e-05
I0403 03:31:55.107990 19294 solver.cpp:244]     Train net output #0: loss = 8.51037e-05 (* 1 = 8.51037e-05 loss)
I0403 03:31:55.287691 19294 sgd_solver.cpp:106] Iteration 3310, lr = 0.0005
I0403 03:32:02.460337 19294 solver.cpp:228] Iteration 3320, loss = 0.000331105
I0403 03:32:02.467123 19294 solver.cpp:244]     Train net output #0: loss = 0.000331102 (* 1 = 0.000331102 loss)
I0403 03:32:02.650818 19294 sgd_solver.cpp:106] Iteration 3320, lr = 0.0005
I0403 03:32:09.741653 19294 solver.cpp:228] Iteration 3330, loss = 0.00205413
I0403 03:32:09.748131 19294 solver.cpp:244]     Train net output #0: loss = 0.00205413 (* 1 = 0.00205413 loss)
I0403 03:32:09.953500 19294 sgd_solver.cpp:106] Iteration 3330, lr = 0.0005
I0403 03:32:16.952739 19294 solver.cpp:228] Iteration 3340, loss = 0.00966078
I0403 03:32:16.958505 19294 solver.cpp:244]     Train net output #0: loss = 0.00966078 (* 1 = 0.00966078 loss)
I0403 03:32:17.129041 19294 sgd_solver.cpp:106] Iteration 3340, lr = 0.0005
I0403 03:32:24.165482 19294 solver.cpp:228] Iteration 3350, loss = 0.000154702
I0403 03:32:24.171926 19294 solver.cpp:244]     Train net output #0: loss = 0.000154699 (* 1 = 0.000154699 loss)
I0403 03:32:24.358309 19294 sgd_solver.cpp:106] Iteration 3350, lr = 0.0005
I0403 03:32:31.358459 19294 solver.cpp:228] Iteration 3360, loss = 0.00137973
I0403 03:32:31.364828 19294 solver.cpp:244]     Train net output #0: loss = 0.00137973 (* 1 = 0.00137973 loss)
I0403 03:32:31.539592 19294 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 03:32:38.566546 19294 solver.cpp:228] Iteration 3370, loss = 0.000734235
I0403 03:32:38.573045 19294 solver.cpp:244]     Train net output #0: loss = 0.000734232 (* 1 = 0.000734232 loss)
I0403 03:32:38.747763 19294 sgd_solver.cpp:106] Iteration 3370, lr = 0.0005
I0403 03:32:45.759922 19294 solver.cpp:228] Iteration 3380, loss = 0.00257632
I0403 03:32:45.767657 19294 solver.cpp:244]     Train net output #0: loss = 0.00257632 (* 1 = 0.00257632 loss)
I0403 03:32:45.958941 19294 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 03:32:53.047287 19294 solver.cpp:228] Iteration 3390, loss = 0.00185741
I0403 03:32:53.054472 19294 solver.cpp:244]     Train net output #0: loss = 0.00185741 (* 1 = 0.00185741 loss)
I0403 03:32:53.226824 19294 sgd_solver.cpp:106] Iteration 3390, lr = 0.0005
I0403 03:33:00.392623 19294 solver.cpp:228] Iteration 3400, loss = 0.000849613
I0403 03:33:00.401412 19294 solver.cpp:244]     Train net output #0: loss = 0.00084961 (* 1 = 0.00084961 loss)
I0403 03:33:00.598423 19294 sgd_solver.cpp:106] Iteration 3400, lr = 0.0005
I0403 03:33:07.698027 19294 solver.cpp:228] Iteration 3410, loss = 0.000104343
I0403 03:33:07.703872 19294 solver.cpp:244]     Train net output #0: loss = 0.00010434 (* 1 = 0.00010434 loss)
I0403 03:33:07.879226 19294 sgd_solver.cpp:106] Iteration 3410, lr = 0.0005
I0403 03:33:14.939834 19294 solver.cpp:228] Iteration 3420, loss = 0.000208261
I0403 03:33:14.946553 19294 solver.cpp:244]     Train net output #0: loss = 0.000208259 (* 1 = 0.000208259 loss)
I0403 03:33:15.119361 19294 sgd_solver.cpp:106] Iteration 3420, lr = 0.0005
I0403 03:33:22.289575 19294 solver.cpp:228] Iteration 3430, loss = 3.17118e-05
I0403 03:33:22.295855 19294 solver.cpp:244]     Train net output #0: loss = 3.1709e-05 (* 1 = 3.1709e-05 loss)
I0403 03:33:22.469594 19294 sgd_solver.cpp:106] Iteration 3430, lr = 0.0005
I0403 03:33:29.548774 19294 solver.cpp:228] Iteration 3440, loss = 0.00526826
I0403 03:33:29.554189 19294 solver.cpp:244]     Train net output #0: loss = 0.00526826 (* 1 = 0.00526826 loss)
I0403 03:33:29.785270 19294 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 03:33:36.962220 19294 solver.cpp:228] Iteration 3450, loss = 0.00017753
I0403 03:33:36.968124 19294 solver.cpp:244]     Train net output #0: loss = 0.000177527 (* 1 = 0.000177527 loss)
I0403 03:33:37.113045 19294 sgd_solver.cpp:106] Iteration 3450, lr = 0.0005
I0403 03:33:44.159665 19294 solver.cpp:228] Iteration 3460, loss = 0.00319935
I0403 03:33:44.165354 19294 solver.cpp:244]     Train net output #0: loss = 0.00319935 (* 1 = 0.00319935 loss)
I0403 03:33:44.427466 19294 sgd_solver.cpp:106] Iteration 3460, lr = 0.0005
I0403 03:33:51.419631 19294 solver.cpp:228] Iteration 3470, loss = 0.00175179
I0403 03:33:51.425899 19294 solver.cpp:244]     Train net output #0: loss = 0.00175178 (* 1 = 0.00175178 loss)
I0403 03:33:51.615700 19294 sgd_solver.cpp:106] Iteration 3470, lr = 0.0005
I0403 03:33:52.341565 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3472.caffemodel
I0403 03:33:55.662266 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3472.solverstate
I0403 03:33:57.493309 19294 solver.cpp:337] Iteration 3472, Testing net (#0)
I0403 03:35:10.960455 19294 solver.cpp:404]     Test net output #0: accuracy = 0.985939
I0403 03:35:10.960772 19294 solver.cpp:404]     Test net output #1: loss = 0.0511802 (* 1 = 0.0511802 loss)
I0403 03:35:17.283309 19294 solver.cpp:228] Iteration 3480, loss = 0.000466849
I0403 03:35:17.283408 19294 solver.cpp:244]     Train net output #0: loss = 0.000466847 (* 1 = 0.000466847 loss)
I0403 03:35:17.443455 19294 sgd_solver.cpp:106] Iteration 3480, lr = 0.0005
I0403 03:35:24.789458 19294 solver.cpp:228] Iteration 3490, loss = 0.00117463
I0403 03:35:24.789571 19294 solver.cpp:244]     Train net output #0: loss = 0.00117463 (* 1 = 0.00117463 loss)
I0403 03:35:24.980301 19294 sgd_solver.cpp:106] Iteration 3490, lr = 0.0005
I0403 03:35:32.078749 19294 solver.cpp:228] Iteration 3500, loss = 0.00104435
I0403 03:35:32.078851 19294 solver.cpp:244]     Train net output #0: loss = 0.00104435 (* 1 = 0.00104435 loss)
I0403 03:35:32.246914 19294 sgd_solver.cpp:106] Iteration 3500, lr = 0.0005
I0403 03:35:39.357975 19294 solver.cpp:228] Iteration 3510, loss = 0.000560829
I0403 03:35:39.358078 19294 solver.cpp:244]     Train net output #0: loss = 0.000560828 (* 1 = 0.000560828 loss)
I0403 03:35:39.538308 19294 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 03:35:46.523322 19294 solver.cpp:228] Iteration 3520, loss = 0.00555809
I0403 03:35:46.523634 19294 solver.cpp:244]     Train net output #0: loss = 0.00555808 (* 1 = 0.00555808 loss)
I0403 03:35:46.707597 19294 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 03:35:53.839699 19294 solver.cpp:228] Iteration 3530, loss = 0.000824455
I0403 03:35:53.839799 19294 solver.cpp:244]     Train net output #0: loss = 0.000824453 (* 1 = 0.000824453 loss)
I0403 03:35:53.998023 19294 sgd_solver.cpp:106] Iteration 3530, lr = 0.0005
I0403 03:36:01.190559 19294 solver.cpp:228] Iteration 3540, loss = 0.000997418
I0403 03:36:01.190655 19294 solver.cpp:244]     Train net output #0: loss = 0.000997416 (* 1 = 0.000997416 loss)
I0403 03:36:01.367938 19294 sgd_solver.cpp:106] Iteration 3540, lr = 0.0005
I0403 03:36:08.450770 19294 solver.cpp:228] Iteration 3550, loss = 0.000800848
I0403 03:36:08.450871 19294 solver.cpp:244]     Train net output #0: loss = 0.000800846 (* 1 = 0.000800846 loss)
I0403 03:36:08.629547 19294 sgd_solver.cpp:106] Iteration 3550, lr = 0.0005
I0403 03:36:15.692497 19294 solver.cpp:228] Iteration 3560, loss = 0.000405185
I0403 03:36:15.692598 19294 solver.cpp:244]     Train net output #0: loss = 0.000405183 (* 1 = 0.000405183 loss)
I0403 03:36:15.870062 19294 sgd_solver.cpp:106] Iteration 3560, lr = 0.0005
I0403 03:36:22.924651 19294 solver.cpp:228] Iteration 3570, loss = 0.000432863
I0403 03:36:22.924988 19294 solver.cpp:244]     Train net output #0: loss = 0.000432861 (* 1 = 0.000432861 loss)
I0403 03:36:23.111759 19294 sgd_solver.cpp:106] Iteration 3570, lr = 0.0005
I0403 03:36:30.309595 19294 solver.cpp:228] Iteration 3580, loss = 0.000732944
I0403 03:36:30.309706 19294 solver.cpp:244]     Train net output #0: loss = 0.000732942 (* 1 = 0.000732942 loss)
I0403 03:36:30.498889 19294 sgd_solver.cpp:106] Iteration 3580, lr = 0.0005
I0403 03:36:37.598393 19294 solver.cpp:228] Iteration 3590, loss = 0.00129244
I0403 03:36:37.598506 19294 solver.cpp:244]     Train net output #0: loss = 0.00129244 (* 1 = 0.00129244 loss)
I0403 03:36:37.775730 19294 sgd_solver.cpp:106] Iteration 3590, lr = 0.0005
I0403 03:36:44.893507 19294 solver.cpp:228] Iteration 3600, loss = 0.00173078
I0403 03:36:44.893610 19294 solver.cpp:244]     Train net output #0: loss = 0.00173078 (* 1 = 0.00173078 loss)
I0403 03:36:45.092316 19294 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 03:36:52.108966 19294 solver.cpp:228] Iteration 3610, loss = 0.000389733
I0403 03:36:52.109069 19294 solver.cpp:244]     Train net output #0: loss = 0.000389732 (* 1 = 0.000389732 loss)
I0403 03:36:52.277614 19294 sgd_solver.cpp:106] Iteration 3610, lr = 0.0005
I0403 03:36:59.547479 19294 solver.cpp:228] Iteration 3620, loss = 0.000232437
I0403 03:36:59.547801 19294 solver.cpp:244]     Train net output #0: loss = 0.000232435 (* 1 = 0.000232435 loss)
I0403 03:36:59.753331 19294 sgd_solver.cpp:106] Iteration 3620, lr = 0.0005
I0403 03:37:06.925427 19294 solver.cpp:228] Iteration 3630, loss = 0.00310349
I0403 03:37:06.925526 19294 solver.cpp:244]     Train net output #0: loss = 0.00310349 (* 1 = 0.00310349 loss)
I0403 03:37:07.091919 19294 sgd_solver.cpp:106] Iteration 3630, lr = 0.0005
I0403 03:37:14.164944 19294 solver.cpp:228] Iteration 3640, loss = 0.00155115
I0403 03:37:14.165045 19294 solver.cpp:244]     Train net output #0: loss = 0.00155115 (* 1 = 0.00155115 loss)
I0403 03:37:14.331552 19294 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 03:37:21.471660 19294 solver.cpp:228] Iteration 3650, loss = 0.00014177
I0403 03:37:21.471760 19294 solver.cpp:244]     Train net output #0: loss = 0.000141769 (* 1 = 0.000141769 loss)
I0403 03:37:21.633740 19294 sgd_solver.cpp:106] Iteration 3650, lr = 0.0005
I0403 03:37:29.005626 19294 solver.cpp:228] Iteration 3660, loss = 0.000352912
I0403 03:37:29.005729 19294 solver.cpp:244]     Train net output #0: loss = 0.000352911 (* 1 = 0.000352911 loss)
I0403 03:37:29.170397 19294 sgd_solver.cpp:106] Iteration 3660, lr = 0.0005
I0403 03:37:36.381770 19294 solver.cpp:228] Iteration 3670, loss = 0.00158926
I0403 03:37:36.382086 19294 solver.cpp:244]     Train net output #0: loss = 0.00158926 (* 1 = 0.00158926 loss)
I0403 03:37:36.570634 19294 sgd_solver.cpp:106] Iteration 3670, lr = 0.0005
I0403 03:37:43.611079 19294 solver.cpp:228] Iteration 3680, loss = 0.00121209
I0403 03:37:43.611193 19294 solver.cpp:244]     Train net output #0: loss = 0.00121209 (* 1 = 0.00121209 loss)
I0403 03:37:43.801815 19294 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 03:37:49.606441 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3689.caffemodel
I0403 03:37:52.365134 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3689.solverstate
I0403 03:37:54.187369 19294 solver.cpp:337] Iteration 3689, Testing net (#0)
I0403 03:39:07.644107 19294 solver.cpp:404]     Test net output #0: accuracy = 0.985847
I0403 03:39:07.644448 19294 solver.cpp:404]     Test net output #1: loss = 0.0507449 (* 1 = 0.0507449 loss)
I0403 03:39:08.920140 19294 solver.cpp:228] Iteration 3690, loss = 0.000512883
I0403 03:39:08.920233 19294 solver.cpp:244]     Train net output #0: loss = 0.000512883 (* 1 = 0.000512883 loss)
I0403 03:39:09.084318 19294 sgd_solver.cpp:106] Iteration 3690, lr = 0.0005
I0403 03:39:16.363171 19294 solver.cpp:228] Iteration 3700, loss = 4.94022e-05
I0403 03:39:16.363278 19294 solver.cpp:244]     Train net output #0: loss = 4.94023e-05 (* 1 = 4.94023e-05 loss)
I0403 03:39:16.536845 19294 sgd_solver.cpp:106] Iteration 3700, lr = 0.0005
I0403 03:39:23.667395 19294 solver.cpp:228] Iteration 3710, loss = 0.00040912
I0403 03:39:23.667496 19294 solver.cpp:244]     Train net output #0: loss = 0.00040912 (* 1 = 0.00040912 loss)
I0403 03:39:23.846150 19294 sgd_solver.cpp:106] Iteration 3710, lr = 0.0005
I0403 03:39:30.885061 19294 solver.cpp:228] Iteration 3720, loss = 0.000636647
I0403 03:39:30.885171 19294 solver.cpp:244]     Train net output #0: loss = 0.000636646 (* 1 = 0.000636646 loss)
I0403 03:39:31.104449 19294 sgd_solver.cpp:106] Iteration 3720, lr = 0.0005
I0403 03:39:38.215215 19294 solver.cpp:228] Iteration 3730, loss = 0.0033983
I0403 03:39:38.215523 19294 solver.cpp:244]     Train net output #0: loss = 0.00339829 (* 1 = 0.00339829 loss)
I0403 03:39:38.378223 19294 sgd_solver.cpp:106] Iteration 3730, lr = 0.0005
I0403 03:39:45.474972 19294 solver.cpp:228] Iteration 3740, loss = 0.00259709
I0403 03:39:45.475074 19294 solver.cpp:244]     Train net output #0: loss = 0.00259709 (* 1 = 0.00259709 loss)
I0403 03:39:45.654847 19294 sgd_solver.cpp:106] Iteration 3740, lr = 0.0005
I0403 03:39:52.689420 19294 solver.cpp:228] Iteration 3750, loss = 0.000218133
I0403 03:39:52.689524 19294 solver.cpp:244]     Train net output #0: loss = 0.000218129 (* 1 = 0.000218129 loss)
I0403 03:39:52.868165 19294 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0403 03:39:59.995869 19294 solver.cpp:228] Iteration 3760, loss = 0.000390558
I0403 03:39:59.995965 19294 solver.cpp:244]     Train net output #0: loss = 0.000390554 (* 1 = 0.000390554 loss)
I0403 03:40:00.142271 19294 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 03:40:07.589485 19294 solver.cpp:228] Iteration 3770, loss = 0.00141274
I0403 03:40:07.589586 19294 solver.cpp:244]     Train net output #0: loss = 0.00141274 (* 1 = 0.00141274 loss)
I0403 03:40:07.768611 19294 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 03:40:14.938252 19294 solver.cpp:228] Iteration 3780, loss = 0.0017484
I0403 03:40:14.938552 19294 solver.cpp:244]     Train net output #0: loss = 0.0017484 (* 1 = 0.0017484 loss)
I0403 03:40:15.084132 19294 sgd_solver.cpp:106] Iteration 3780, lr = 0.0005
I0403 03:40:22.552852 19294 solver.cpp:228] Iteration 3790, loss = 0.000320545
I0403 03:40:22.552953 19294 solver.cpp:244]     Train net output #0: loss = 0.000320542 (* 1 = 0.000320542 loss)
I0403 03:40:22.697999 19294 sgd_solver.cpp:106] Iteration 3790, lr = 0.0005
I0403 03:40:29.835551 19294 solver.cpp:228] Iteration 3800, loss = 0.00188114
I0403 03:40:29.835651 19294 solver.cpp:244]     Train net output #0: loss = 0.00188114 (* 1 = 0.00188114 loss)
I0403 03:40:29.972515 19294 sgd_solver.cpp:106] Iteration 3800, lr = 0.0005
I0403 03:40:37.084121 19294 solver.cpp:228] Iteration 3810, loss = 0.00235312
I0403 03:40:37.084234 19294 solver.cpp:244]     Train net output #0: loss = 0.00235312 (* 1 = 0.00235312 loss)
I0403 03:40:37.266932 19294 sgd_solver.cpp:106] Iteration 3810, lr = 0.0005
I0403 03:40:44.374887 19294 solver.cpp:228] Iteration 3820, loss = 0.000157836
I0403 03:40:44.375839 19294 solver.cpp:244]     Train net output #0: loss = 0.000157833 (* 1 = 0.000157833 loss)
I0403 03:40:44.554383 19294 sgd_solver.cpp:106] Iteration 3820, lr = 0.0005
I0403 03:40:51.779144 19294 solver.cpp:228] Iteration 3830, loss = 0.000335691
I0403 03:40:51.779495 19294 solver.cpp:244]     Train net output #0: loss = 0.000335687 (* 1 = 0.000335687 loss)
I0403 03:40:51.978080 19294 sgd_solver.cpp:106] Iteration 3830, lr = 0.0005
I0403 03:40:59.027943 19294 solver.cpp:228] Iteration 3840, loss = 0.000259697
I0403 03:40:59.028045 19294 solver.cpp:244]     Train net output #0: loss = 0.000259694 (* 1 = 0.000259694 loss)
I0403 03:40:59.209317 19294 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 03:41:06.269707 19294 solver.cpp:228] Iteration 3850, loss = 0.000229323
I0403 03:41:06.269807 19294 solver.cpp:244]     Train net output #0: loss = 0.00022932 (* 1 = 0.00022932 loss)
I0403 03:41:06.448279 19294 sgd_solver.cpp:106] Iteration 3850, lr = 0.0005
I0403 03:41:13.493995 19294 solver.cpp:228] Iteration 3860, loss = 3.20107e-05
I0403 03:41:13.494108 19294 solver.cpp:244]     Train net output #0: loss = 3.20076e-05 (* 1 = 3.20076e-05 loss)
I0403 03:41:13.704792 19294 sgd_solver.cpp:106] Iteration 3860, lr = 0.0005
I0403 03:41:20.827837 19294 solver.cpp:228] Iteration 3870, loss = 0.000852912
I0403 03:41:20.827950 19294 solver.cpp:244]     Train net output #0: loss = 0.000852908 (* 1 = 0.000852908 loss)
I0403 03:41:21.051604 19294 sgd_solver.cpp:106] Iteration 3870, lr = 0.0005
I0403 03:41:28.396224 19294 solver.cpp:228] Iteration 3880, loss = 0.00158131
I0403 03:41:28.396528 19294 solver.cpp:244]     Train net output #0: loss = 0.0015813 (* 1 = 0.0015813 loss)
I0403 03:41:28.568442 19294 sgd_solver.cpp:106] Iteration 3880, lr = 0.0005
I0403 03:41:35.749099 19294 solver.cpp:228] Iteration 3890, loss = 3.02874e-05
I0403 03:41:35.749188 19294 solver.cpp:244]     Train net output #0: loss = 3.02832e-05 (* 1 = 3.02832e-05 loss)
I0403 03:41:35.916991 19294 sgd_solver.cpp:106] Iteration 3890, lr = 0.0005
I0403 03:41:43.040670 19294 solver.cpp:228] Iteration 3900, loss = 0.000410215
I0403 03:41:43.040781 19294 solver.cpp:244]     Train net output #0: loss = 0.000410211 (* 1 = 0.000410211 loss)
I0403 03:41:43.234810 19294 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 03:41:46.845535 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3906.caffemodel
I0403 03:41:49.629051 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_3906.solverstate
I0403 03:41:51.490694 19294 solver.cpp:337] Iteration 3906, Testing net (#0)
I0403 03:43:05.039263 19294 solver.cpp:404]     Test net output #0: accuracy = 0.985847
I0403 03:43:05.039583 19294 solver.cpp:404]     Test net output #1: loss = 0.0505264 (* 1 = 0.0505264 loss)
I0403 03:43:08.444528 19294 solver.cpp:228] Iteration 3910, loss = 0.0011485
I0403 03:43:08.444638 19294 solver.cpp:244]     Train net output #0: loss = 0.0011485 (* 1 = 0.0011485 loss)
I0403 03:43:08.643926 19294 sgd_solver.cpp:106] Iteration 3910, lr = 0.0005
I0403 03:43:15.721657 19294 solver.cpp:228] Iteration 3920, loss = 0.000138259
I0403 03:43:15.721794 19294 solver.cpp:244]     Train net output #0: loss = 0.000138255 (* 1 = 0.000138255 loss)
I0403 03:43:15.906147 19294 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 03:43:22.926126 19294 solver.cpp:228] Iteration 3930, loss = 0.00382733
I0403 03:43:22.926234 19294 solver.cpp:244]     Train net output #0: loss = 0.00382733 (* 1 = 0.00382733 loss)
I0403 03:43:23.091373 19294 sgd_solver.cpp:106] Iteration 3930, lr = 0.0005
I0403 03:43:30.171896 19294 solver.cpp:228] Iteration 3940, loss = 0.00860483
I0403 03:43:30.171994 19294 solver.cpp:244]     Train net output #0: loss = 0.00860482 (* 1 = 0.00860482 loss)
I0403 03:43:30.331565 19294 sgd_solver.cpp:106] Iteration 3940, lr = 0.0005
I0403 03:43:37.530700 19294 solver.cpp:228] Iteration 3950, loss = 0.000352291
I0403 03:43:37.531051 19294 solver.cpp:244]     Train net output #0: loss = 0.000352281 (* 1 = 0.000352281 loss)
I0403 03:43:37.719364 19294 sgd_solver.cpp:106] Iteration 3950, lr = 0.0005
I0403 03:43:44.784983 19294 solver.cpp:228] Iteration 3960, loss = 0.000356435
I0403 03:43:44.785092 19294 solver.cpp:244]     Train net output #0: loss = 0.000356425 (* 1 = 0.000356425 loss)
I0403 03:43:44.969769 19294 sgd_solver.cpp:106] Iteration 3960, lr = 0.0005
I0403 03:43:52.245266 19294 solver.cpp:228] Iteration 3970, loss = 0.000662024
I0403 03:43:52.245378 19294 solver.cpp:244]     Train net output #0: loss = 0.000662014 (* 1 = 0.000662014 loss)
I0403 03:43:52.458221 19294 sgd_solver.cpp:106] Iteration 3970, lr = 0.0005
I0403 03:43:59.569106 19294 solver.cpp:228] Iteration 3980, loss = 0.00100041
I0403 03:43:59.569226 19294 solver.cpp:244]     Train net output #0: loss = 0.0010004 (* 1 = 0.0010004 loss)
I0403 03:43:59.750802 19294 sgd_solver.cpp:106] Iteration 3980, lr = 0.0005
I0403 03:44:06.905933 19294 solver.cpp:228] Iteration 3990, loss = 0.00128679
I0403 03:44:06.906033 19294 solver.cpp:244]     Train net output #0: loss = 0.00128678 (* 1 = 0.00128678 loss)
I0403 03:44:07.083555 19294 sgd_solver.cpp:106] Iteration 3990, lr = 0.0005
I0403 03:44:14.211638 19294 solver.cpp:228] Iteration 4000, loss = 0.000442222
I0403 03:44:14.211967 19294 solver.cpp:244]     Train net output #0: loss = 0.000442213 (* 1 = 0.000442213 loss)
I0403 03:44:14.402734 19294 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 03:44:21.412305 19294 solver.cpp:228] Iteration 4010, loss = 0.000953746
I0403 03:44:21.412415 19294 solver.cpp:244]     Train net output #0: loss = 0.000953735 (* 1 = 0.000953735 loss)
I0403 03:44:21.605149 19294 sgd_solver.cpp:106] Iteration 4010, lr = 0.0005
I0403 03:44:28.800521 19294 solver.cpp:228] Iteration 4020, loss = 0.00146752
I0403 03:44:28.800629 19294 solver.cpp:244]     Train net output #0: loss = 0.00146751 (* 1 = 0.00146751 loss)
I0403 03:44:28.987645 19294 sgd_solver.cpp:106] Iteration 4020, lr = 0.0005
I0403 03:44:36.122038 19294 solver.cpp:228] Iteration 4030, loss = 0.000111357
I0403 03:44:36.122120 19294 solver.cpp:244]     Train net output #0: loss = 0.000111347 (* 1 = 0.000111347 loss)
I0403 03:44:36.267664 19294 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 03:44:43.453420 19294 solver.cpp:228] Iteration 4040, loss = 0.00140765
I0403 03:44:43.453505 19294 solver.cpp:244]     Train net output #0: loss = 0.00140765 (* 1 = 0.00140765 loss)
I0403 03:44:43.632053 19294 sgd_solver.cpp:106] Iteration 4040, lr = 0.0005
I0403 03:44:50.662914 19294 solver.cpp:228] Iteration 4050, loss = 4.46206e-05
I0403 03:44:50.663234 19294 solver.cpp:244]     Train net output #0: loss = 4.46107e-05 (* 1 = 4.46107e-05 loss)
I0403 03:44:50.849035 19294 sgd_solver.cpp:106] Iteration 4050, lr = 0.0005
I0403 03:44:57.952116 19294 solver.cpp:228] Iteration 4060, loss = 0.000108178
I0403 03:44:57.952240 19294 solver.cpp:244]     Train net output #0: loss = 0.000108171 (* 1 = 0.000108171 loss)
I0403 03:44:58.141695 19294 sgd_solver.cpp:106] Iteration 4060, lr = 0.0005
I0403 03:45:05.173239 19294 solver.cpp:228] Iteration 4070, loss = 3.39493e-05
I0403 03:45:05.173344 19294 solver.cpp:244]     Train net output #0: loss = 3.39424e-05 (* 1 = 3.39424e-05 loss)
I0403 03:45:05.336029 19294 sgd_solver.cpp:106] Iteration 4070, lr = 0.0005
I0403 03:45:12.462903 19294 solver.cpp:228] Iteration 4080, loss = 8.11362e-05
I0403 03:45:12.463011 19294 solver.cpp:244]     Train net output #0: loss = 8.11294e-05 (* 1 = 8.11294e-05 loss)
I0403 03:45:12.656894 19294 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 03:45:19.925663 19294 solver.cpp:228] Iteration 4090, loss = 0.00129228
I0403 03:45:19.925766 19294 solver.cpp:244]     Train net output #0: loss = 0.00129227 (* 1 = 0.00129227 loss)
I0403 03:45:20.095005 19294 sgd_solver.cpp:106] Iteration 4090, lr = 0.0005
I0403 03:45:27.198258 19294 solver.cpp:228] Iteration 4100, loss = 0.00138688
I0403 03:45:27.198603 19294 solver.cpp:244]     Train net output #0: loss = 0.00138687 (* 1 = 0.00138687 loss)
I0403 03:45:27.384266 19294 sgd_solver.cpp:106] Iteration 4100, lr = 0.0005
I0403 03:45:34.403914 19294 solver.cpp:228] Iteration 4110, loss = 0.000381576
I0403 03:45:34.404022 19294 solver.cpp:244]     Train net output #0: loss = 0.000381569 (* 1 = 0.000381569 loss)
I0403 03:45:34.591553 19294 sgd_solver.cpp:106] Iteration 4110, lr = 0.0005
I0403 03:45:41.712343 19294 solver.cpp:228] Iteration 4120, loss = 0.00017337
I0403 03:45:41.712458 19294 solver.cpp:244]     Train net output #0: loss = 0.000173362 (* 1 = 0.000173362 loss)
I0403 03:45:41.934262 19294 sgd_solver.cpp:106] Iteration 4120, lr = 0.0005
I0403 03:45:43.360780 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4123.caffemodel
I0403 03:45:46.127723 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4123.solverstate
I0403 03:45:47.975831 19294 solver.cpp:337] Iteration 4123, Testing net (#0)
I0403 03:47:01.535743 19294 solver.cpp:404]     Test net output #0: accuracy = 0.985847
I0403 03:47:01.536059 19294 solver.cpp:404]     Test net output #1: loss = 0.0505266 (* 1 = 0.0505266 loss)
I0403 03:47:07.244988 19294 solver.cpp:228] Iteration 4130, loss = 0.000774013
I0403 03:47:07.245103 19294 solver.cpp:244]     Train net output #0: loss = 0.000774005 (* 1 = 0.000774005 loss)
I0403 03:47:07.415644 19294 sgd_solver.cpp:106] Iteration 4130, lr = 0.0005
I0403 03:47:14.523778 19294 solver.cpp:228] Iteration 4140, loss = 0.000274746
I0403 03:47:14.523876 19294 solver.cpp:244]     Train net output #0: loss = 0.000274738 (* 1 = 0.000274738 loss)
I0403 03:47:14.703414 19294 sgd_solver.cpp:106] Iteration 4140, lr = 0.0005
I0403 03:47:21.773313 19294 solver.cpp:228] Iteration 4150, loss = 0.000105787
I0403 03:47:21.773421 19294 solver.cpp:244]     Train net output #0: loss = 0.000105779 (* 1 = 0.000105779 loss)
I0403 03:47:21.955839 19294 sgd_solver.cpp:106] Iteration 4150, lr = 0.0005
I0403 03:47:29.112229 19294 solver.cpp:228] Iteration 4160, loss = 0.000346199
I0403 03:47:29.112331 19294 solver.cpp:244]     Train net output #0: loss = 0.000346192 (* 1 = 0.000346192 loss)
I0403 03:47:29.290927 19294 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:47:36.360049 19294 solver.cpp:228] Iteration 4170, loss = 9.95272e-05
I0403 03:47:36.360360 19294 solver.cpp:244]     Train net output #0: loss = 9.952e-05 (* 1 = 9.952e-05 loss)
I0403 03:47:36.603763 19294 sgd_solver.cpp:106] Iteration 4170, lr = 0.0005
I0403 03:47:43.622370 19294 solver.cpp:228] Iteration 4180, loss = 0.000169497
I0403 03:47:43.622478 19294 solver.cpp:244]     Train net output #0: loss = 0.000169489 (* 1 = 0.000169489 loss)
I0403 03:47:43.804538 19294 sgd_solver.cpp:106] Iteration 4180, lr = 0.0005
I0403 03:47:50.862552 19294 solver.cpp:228] Iteration 4190, loss = 0.000251401
I0403 03:47:50.862643 19294 solver.cpp:244]     Train net output #0: loss = 0.000251393 (* 1 = 0.000251393 loss)
I0403 03:47:51.030546 19294 sgd_solver.cpp:106] Iteration 4190, lr = 0.0005
I0403 03:47:58.092643 19294 solver.cpp:228] Iteration 4200, loss = 0.00157244
I0403 03:47:58.092743 19294 solver.cpp:244]     Train net output #0: loss = 0.00157244 (* 1 = 0.00157244 loss)
I0403 03:47:58.270866 19294 sgd_solver.cpp:106] Iteration 4200, lr = 0.0005
I0403 03:48:05.458240 19294 solver.cpp:228] Iteration 4210, loss = 0.00928817
I0403 03:48:05.458343 19294 solver.cpp:244]     Train net output #0: loss = 0.00928816 (* 1 = 0.00928816 loss)
I0403 03:48:05.637981 19294 sgd_solver.cpp:106] Iteration 4210, lr = 0.0005
I0403 03:48:12.699352 19294 solver.cpp:228] Iteration 4220, loss = 0.0210747
I0403 03:48:12.699656 19294 solver.cpp:244]     Train net output #0: loss = 0.0210747 (* 1 = 0.0210747 loss)
I0403 03:48:12.858245 19294 sgd_solver.cpp:106] Iteration 4220, lr = 0.0005
I0403 03:48:19.996297 19294 solver.cpp:228] Iteration 4230, loss = 0.000417393
I0403 03:48:19.997403 19294 solver.cpp:244]     Train net output #0: loss = 0.000417387 (* 1 = 0.000417387 loss)
I0403 03:48:20.171658 19294 sgd_solver.cpp:106] Iteration 4230, lr = 0.0005
I0403 03:48:27.369385 19294 solver.cpp:228] Iteration 4240, loss = 0.000470191
I0403 03:48:27.369500 19294 solver.cpp:244]     Train net output #0: loss = 0.000470185 (* 1 = 0.000470185 loss)
I0403 03:48:27.545975 19294 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 03:48:34.634959 19294 solver.cpp:228] Iteration 4250, loss = 0.0205892
I0403 03:48:34.635069 19294 solver.cpp:244]     Train net output #0: loss = 0.0205892 (* 1 = 0.0205892 loss)
I0403 03:48:34.824120 19294 sgd_solver.cpp:106] Iteration 4250, lr = 0.0005
I0403 03:48:41.932843 19294 solver.cpp:228] Iteration 4260, loss = 0.00152447
I0403 03:48:41.932946 19294 solver.cpp:244]     Train net output #0: loss = 0.00152446 (* 1 = 0.00152446 loss)
I0403 03:48:42.101775 19294 sgd_solver.cpp:106] Iteration 4260, lr = 0.0005
I0403 03:48:49.189432 19294 solver.cpp:228] Iteration 4270, loss = 0.00718659
I0403 03:48:49.189786 19294 solver.cpp:244]     Train net output #0: loss = 0.00718658 (* 1 = 0.00718658 loss)
I0403 03:48:49.376852 19294 sgd_solver.cpp:106] Iteration 4270, lr = 0.0005
I0403 03:48:56.486181 19294 solver.cpp:228] Iteration 4280, loss = 0.000104547
I0403 03:48:56.486285 19294 solver.cpp:244]     Train net output #0: loss = 0.000104539 (* 1 = 0.000104539 loss)
I0403 03:48:56.665462 19294 sgd_solver.cpp:106] Iteration 4280, lr = 0.0005
I0403 03:49:03.869700 19294 solver.cpp:228] Iteration 4290, loss = 0.000539605
I0403 03:49:03.869810 19294 solver.cpp:244]     Train net output #0: loss = 0.000539597 (* 1 = 0.000539597 loss)
I0403 03:49:04.060694 19294 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 03:49:11.141109 19294 solver.cpp:228] Iteration 4300, loss = 0.000234544
I0403 03:49:11.141221 19294 solver.cpp:244]     Train net output #0: loss = 0.000234537 (* 1 = 0.000234537 loss)
I0403 03:49:11.344673 19294 sgd_solver.cpp:106] Iteration 4300, lr = 0.0005
I0403 03:49:18.538976 19294 solver.cpp:228] Iteration 4310, loss = 0.00063123
I0403 03:49:18.539088 19294 solver.cpp:244]     Train net output #0: loss = 0.000631223 (* 1 = 0.000631223 loss)
I0403 03:49:18.740087 19294 sgd_solver.cpp:106] Iteration 4310, lr = 0.0005
I0403 03:49:25.736459 19294 solver.cpp:228] Iteration 4320, loss = 7.31592e-05
I0403 03:49:25.736770 19294 solver.cpp:244]     Train net output #0: loss = 7.31518e-05 (* 1 = 7.31518e-05 loss)
I0403 03:49:25.917101 19294 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 03:49:32.958087 19294 solver.cpp:228] Iteration 4330, loss = 0.000115605
I0403 03:49:32.958206 19294 solver.cpp:244]     Train net output #0: loss = 0.000115597 (* 1 = 0.000115597 loss)
I0403 03:49:33.146949 19294 sgd_solver.cpp:106] Iteration 4330, lr = 0.0005
I0403 03:49:39.721388 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4340.caffemodel
I0403 03:49:42.486879 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4340.solverstate
I0403 03:49:44.328641 19294 solver.cpp:337] Iteration 4340, Testing net (#0)
I0403 03:50:57.825018 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986216
I0403 03:50:57.828611 19294 solver.cpp:404]     Test net output #1: loss = 0.0500211 (* 1 = 0.0500211 loss)
I0403 03:50:58.333909 19294 solver.cpp:228] Iteration 4340, loss = 0.000120289
I0403 03:50:58.334007 19294 solver.cpp:244]     Train net output #0: loss = 0.000120281 (* 1 = 0.000120281 loss)
I0403 03:50:58.512320 19294 sgd_solver.cpp:106] Iteration 4340, lr = 0.0005
I0403 03:51:05.696368 19294 solver.cpp:228] Iteration 4350, loss = 0.00274896
I0403 03:51:05.696477 19294 solver.cpp:244]     Train net output #0: loss = 0.00274895 (* 1 = 0.00274895 loss)
I0403 03:51:05.888335 19294 sgd_solver.cpp:106] Iteration 4350, lr = 5e-05
I0403 03:51:12.947604 19294 solver.cpp:228] Iteration 4360, loss = 0.002571
I0403 03:51:12.948390 19294 solver.cpp:244]     Train net output #0: loss = 0.002571 (* 1 = 0.002571 loss)
I0403 03:51:13.117383 19294 sgd_solver.cpp:106] Iteration 4360, lr = 5e-05
I0403 03:51:20.197005 19294 solver.cpp:228] Iteration 4370, loss = 0.00670082
I0403 03:51:20.197116 19294 solver.cpp:244]     Train net output #0: loss = 0.00670081 (* 1 = 0.00670081 loss)
I0403 03:51:20.390015 19294 sgd_solver.cpp:106] Iteration 4370, lr = 5e-05
I0403 03:51:27.433511 19294 solver.cpp:228] Iteration 4380, loss = 0.00137082
I0403 03:51:27.433610 19294 solver.cpp:244]     Train net output #0: loss = 0.00137081 (* 1 = 0.00137081 loss)
I0403 03:51:27.601876 19294 sgd_solver.cpp:106] Iteration 4380, lr = 5e-05
I0403 03:51:34.708758 19294 solver.cpp:228] Iteration 4390, loss = 9.60097e-05
I0403 03:51:34.709110 19294 solver.cpp:244]     Train net output #0: loss = 9.60019e-05 (* 1 = 9.60019e-05 loss)
I0403 03:51:34.914285 19294 sgd_solver.cpp:106] Iteration 4390, lr = 5e-05
I0403 03:51:41.958024 19294 solver.cpp:228] Iteration 4400, loss = 0.00038475
I0403 03:51:41.958124 19294 solver.cpp:244]     Train net output #0: loss = 0.000384742 (* 1 = 0.000384742 loss)
I0403 03:51:42.137078 19294 sgd_solver.cpp:106] Iteration 4400, lr = 5e-05
I0403 03:51:49.279038 19294 solver.cpp:228] Iteration 4410, loss = 0.00689325
I0403 03:51:49.279139 19294 solver.cpp:244]     Train net output #0: loss = 0.00689324 (* 1 = 0.00689324 loss)
I0403 03:51:49.442239 19294 sgd_solver.cpp:106] Iteration 4410, lr = 5e-05
I0403 03:51:56.610381 19294 solver.cpp:228] Iteration 4420, loss = 0.00275725
I0403 03:51:56.610489 19294 solver.cpp:244]     Train net output #0: loss = 0.00275724 (* 1 = 0.00275724 loss)
I0403 03:51:56.770330 19294 sgd_solver.cpp:106] Iteration 4420, lr = 5e-05
I0403 03:52:03.978930 19294 solver.cpp:228] Iteration 4430, loss = 8.8846e-05
I0403 03:52:03.979037 19294 solver.cpp:244]     Train net output #0: loss = 8.88393e-05 (* 1 = 8.88393e-05 loss)
I0403 03:52:04.175643 19294 sgd_solver.cpp:106] Iteration 4430, lr = 5e-05
I0403 03:52:11.183156 19294 solver.cpp:228] Iteration 4440, loss = 0.000279728
I0403 03:52:11.183472 19294 solver.cpp:244]     Train net output #0: loss = 0.000279721 (* 1 = 0.000279721 loss)
I0403 03:52:11.354434 19294 sgd_solver.cpp:106] Iteration 4440, lr = 5e-05
I0403 03:52:18.450549 19294 solver.cpp:228] Iteration 4450, loss = 0.000750203
I0403 03:52:18.450649 19294 solver.cpp:244]     Train net output #0: loss = 0.000750196 (* 1 = 0.000750196 loss)
I0403 03:52:18.630687 19294 sgd_solver.cpp:106] Iteration 4450, lr = 5e-05
I0403 03:52:25.890677 19294 solver.cpp:228] Iteration 4460, loss = 0.000300681
I0403 03:52:25.890779 19294 solver.cpp:244]     Train net output #0: loss = 0.000300674 (* 1 = 0.000300674 loss)
I0403 03:52:26.058763 19294 sgd_solver.cpp:106] Iteration 4460, lr = 5e-05
I0403 03:52:33.183398 19294 solver.cpp:228] Iteration 4470, loss = 0.000158871
I0403 03:52:33.183501 19294 solver.cpp:244]     Train net output #0: loss = 0.000158864 (* 1 = 0.000158864 loss)
I0403 03:52:33.362414 19294 sgd_solver.cpp:106] Iteration 4470, lr = 5e-05
I0403 03:52:40.391160 19294 solver.cpp:228] Iteration 4480, loss = 0.000832499
I0403 03:52:40.391274 19294 solver.cpp:244]     Train net output #0: loss = 0.000832491 (* 1 = 0.000832491 loss)
I0403 03:52:40.578760 19294 sgd_solver.cpp:106] Iteration 4480, lr = 5e-05
I0403 03:52:47.654706 19294 solver.cpp:228] Iteration 4490, loss = 6.73082e-05
I0403 03:52:47.655011 19294 solver.cpp:244]     Train net output #0: loss = 6.7301e-05 (* 1 = 6.7301e-05 loss)
I0403 03:52:47.808732 19294 sgd_solver.cpp:106] Iteration 4490, lr = 5e-05
I0403 03:52:55.050753 19294 solver.cpp:228] Iteration 4500, loss = 0.000861705
I0403 03:52:55.050854 19294 solver.cpp:244]     Train net output #0: loss = 0.000861698 (* 1 = 0.000861698 loss)
I0403 03:52:55.201980 19294 sgd_solver.cpp:106] Iteration 4500, lr = 5e-05
I0403 03:53:02.451144 19294 solver.cpp:228] Iteration 4510, loss = 0.00110042
I0403 03:53:02.451270 19294 solver.cpp:244]     Train net output #0: loss = 0.00110041 (* 1 = 0.00110041 loss)
I0403 03:53:02.633216 19294 sgd_solver.cpp:106] Iteration 4510, lr = 5e-05
I0403 03:53:09.801281 19294 solver.cpp:228] Iteration 4520, loss = 8.24445e-05
I0403 03:53:09.801390 19294 solver.cpp:244]     Train net output #0: loss = 8.24372e-05 (* 1 = 8.24372e-05 loss)
I0403 03:53:09.983362 19294 sgd_solver.cpp:106] Iteration 4520, lr = 5e-05
I0403 03:53:17.020548 19294 solver.cpp:228] Iteration 4530, loss = 0.000380599
I0403 03:53:17.020654 19294 solver.cpp:244]     Train net output #0: loss = 0.000380592 (* 1 = 0.000380592 loss)
I0403 03:53:17.200284 19294 sgd_solver.cpp:106] Iteration 4530, lr = 5e-05
I0403 03:53:24.210824 19294 solver.cpp:228] Iteration 4540, loss = 0.000558858
I0403 03:53:24.211158 19294 solver.cpp:244]     Train net output #0: loss = 0.00055885 (* 1 = 0.00055885 loss)
I0403 03:53:24.391650 19294 sgd_solver.cpp:106] Iteration 4540, lr = 5e-05
I0403 03:53:31.425604 19294 solver.cpp:228] Iteration 4550, loss = 0.000146349
I0403 03:53:31.425709 19294 solver.cpp:244]     Train net output #0: loss = 0.000146342 (* 1 = 0.000146342 loss)
I0403 03:53:31.604507 19294 sgd_solver.cpp:106] Iteration 4550, lr = 5e-05
I0403 03:53:35.969615 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4557.caffemodel
I0403 03:53:38.720964 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4557.solverstate
I0403 03:53:40.584535 19294 solver.cpp:337] Iteration 4557, Testing net (#0)
I0403 03:54:54.050345 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986124
I0403 03:54:54.050674 19294 solver.cpp:404]     Test net output #1: loss = 0.0503951 (* 1 = 0.0503951 loss)
I0403 03:54:56.778774 19294 solver.cpp:228] Iteration 4560, loss = 4.1184e-05
I0403 03:54:56.778889 19294 solver.cpp:244]     Train net output #0: loss = 4.11764e-05 (* 1 = 4.11764e-05 loss)
I0403 03:54:56.959399 19294 sgd_solver.cpp:106] Iteration 4560, lr = 5e-05
I0403 03:55:04.098163 19294 solver.cpp:228] Iteration 4570, loss = 0.00400704
I0403 03:55:04.102771 19294 solver.cpp:244]     Train net output #0: loss = 0.00400703 (* 1 = 0.00400703 loss)
I0403 03:55:04.296298 19294 sgd_solver.cpp:106] Iteration 4570, lr = 5e-05
I0403 03:55:11.368958 19294 solver.cpp:228] Iteration 4580, loss = 1.70225e-05
I0403 03:55:11.375706 19294 solver.cpp:244]     Train net output #0: loss = 1.70151e-05 (* 1 = 1.70151e-05 loss)
I0403 03:55:11.551928 19294 sgd_solver.cpp:106] Iteration 4580, lr = 5e-05
I0403 03:55:18.596748 19294 solver.cpp:228] Iteration 4590, loss = 0.000159611
I0403 03:55:18.596859 19294 solver.cpp:244]     Train net output #0: loss = 0.000159603 (* 1 = 0.000159603 loss)
I0403 03:55:18.797549 19294 sgd_solver.cpp:106] Iteration 4590, lr = 5e-05
I0403 03:55:25.808043 19294 solver.cpp:228] Iteration 4600, loss = 0.00484171
I0403 03:55:25.814748 19294 solver.cpp:244]     Train net output #0: loss = 0.00484171 (* 1 = 0.00484171 loss)
I0403 03:55:26.014685 19294 sgd_solver.cpp:106] Iteration 4600, lr = 5e-05
I0403 03:55:33.175801 19294 solver.cpp:228] Iteration 4610, loss = 0.000499164
I0403 03:55:33.181855 19294 solver.cpp:244]     Train net output #0: loss = 0.000499156 (* 1 = 0.000499156 loss)
I0403 03:55:33.355872 19294 sgd_solver.cpp:106] Iteration 4610, lr = 5e-05
I0403 03:55:40.347667 19294 solver.cpp:228] Iteration 4620, loss = 0.000196447
I0403 03:55:40.347776 19294 solver.cpp:244]     Train net output #0: loss = 0.000196439 (* 1 = 0.000196439 loss)
I0403 03:55:40.533957 19294 sgd_solver.cpp:106] Iteration 4620, lr = 5e-05
I0403 03:55:47.569289 19294 solver.cpp:228] Iteration 4630, loss = 0.000653956
I0403 03:55:47.569401 19294 solver.cpp:244]     Train net output #0: loss = 0.000653949 (* 1 = 0.000653949 loss)
I0403 03:55:47.795095 19294 sgd_solver.cpp:106] Iteration 4630, lr = 5e-05
I0403 03:55:54.900974 19294 solver.cpp:228] Iteration 4640, loss = 0.00152794
I0403 03:55:54.901077 19294 solver.cpp:244]     Train net output #0: loss = 0.00152793 (* 1 = 0.00152793 loss)
I0403 03:55:55.055670 19294 sgd_solver.cpp:106] Iteration 4640, lr = 5e-05
I0403 03:56:02.098228 19294 solver.cpp:228] Iteration 4650, loss = 7.62545e-05
I0403 03:56:02.098565 19294 solver.cpp:244]     Train net output #0: loss = 7.62469e-05 (* 1 = 7.62469e-05 loss)
I0403 03:56:02.270673 19294 sgd_solver.cpp:106] Iteration 4650, lr = 5e-05
I0403 03:56:09.324941 19294 solver.cpp:228] Iteration 4660, loss = 0.000103825
I0403 03:56:09.325052 19294 solver.cpp:244]     Train net output #0: loss = 0.000103818 (* 1 = 0.000103818 loss)
I0403 03:56:09.515681 19294 sgd_solver.cpp:106] Iteration 4660, lr = 5e-05
I0403 03:56:16.652216 19294 solver.cpp:228] Iteration 4670, loss = 0.00472291
I0403 03:56:16.652318 19294 solver.cpp:244]     Train net output #0: loss = 0.00472291 (* 1 = 0.00472291 loss)
I0403 03:56:16.831923 19294 sgd_solver.cpp:106] Iteration 4670, lr = 5e-05
I0403 03:56:23.945801 19294 solver.cpp:228] Iteration 4680, loss = 0.000536422
I0403 03:56:23.945901 19294 solver.cpp:244]     Train net output #0: loss = 0.000536415 (* 1 = 0.000536415 loss)
I0403 03:56:24.109289 19294 sgd_solver.cpp:106] Iteration 4680, lr = 5e-05
I0403 03:56:31.211592 19294 solver.cpp:228] Iteration 4690, loss = 0.000427183
I0403 03:56:31.211699 19294 solver.cpp:244]     Train net output #0: loss = 0.000427176 (* 1 = 0.000427176 loss)
I0403 03:56:31.454190 19294 sgd_solver.cpp:106] Iteration 4690, lr = 5e-05
I0403 03:56:38.722877 19294 solver.cpp:228] Iteration 4700, loss = 0.00037039
I0403 03:56:38.723188 19294 solver.cpp:244]     Train net output #0: loss = 0.000370383 (* 1 = 0.000370383 loss)
I0403 03:56:38.894662 19294 sgd_solver.cpp:106] Iteration 4700, lr = 5e-05
I0403 03:56:46.072299 19294 solver.cpp:228] Iteration 4710, loss = 0.000167309
I0403 03:56:46.072401 19294 solver.cpp:244]     Train net output #0: loss = 0.000167303 (* 1 = 0.000167303 loss)
I0403 03:56:46.250893 19294 sgd_solver.cpp:106] Iteration 4710, lr = 5e-05
I0403 03:56:53.313372 19294 solver.cpp:228] Iteration 4720, loss = 0.000118945
I0403 03:56:53.313474 19294 solver.cpp:244]     Train net output #0: loss = 0.000118939 (* 1 = 0.000118939 loss)
I0403 03:56:53.489734 19294 sgd_solver.cpp:106] Iteration 4720, lr = 5e-05
I0403 03:57:00.601490 19294 solver.cpp:228] Iteration 4730, loss = 0.0002678
I0403 03:57:00.601594 19294 solver.cpp:244]     Train net output #0: loss = 0.000267794 (* 1 = 0.000267794 loss)
I0403 03:57:00.783298 19294 sgd_solver.cpp:106] Iteration 4730, lr = 5e-05
I0403 03:57:07.751109 19294 solver.cpp:228] Iteration 4740, loss = 0.00098636
I0403 03:57:07.751226 19294 solver.cpp:244]     Train net output #0: loss = 0.000986355 (* 1 = 0.000986355 loss)
I0403 03:57:07.934918 19294 sgd_solver.cpp:106] Iteration 4740, lr = 5e-05
I0403 03:57:14.964449 19294 solver.cpp:228] Iteration 4750, loss = 0.00273989
I0403 03:57:14.964723 19294 solver.cpp:244]     Train net output #0: loss = 0.00273989 (* 1 = 0.00273989 loss)
I0403 03:57:15.141194 19294 sgd_solver.cpp:106] Iteration 4750, lr = 5e-05
I0403 03:57:22.335865 19294 solver.cpp:228] Iteration 4760, loss = 0.000745117
I0403 03:57:22.335963 19294 solver.cpp:244]     Train net output #0: loss = 0.000745111 (* 1 = 0.000745111 loss)
I0403 03:57:22.502671 19294 sgd_solver.cpp:106] Iteration 4760, lr = 5e-05
I0403 03:57:29.677605 19294 solver.cpp:228] Iteration 4770, loss = 0.000658989
I0403 03:57:29.677717 19294 solver.cpp:244]     Train net output #0: loss = 0.000658983 (* 1 = 0.000658983 loss)
I0403 03:57:29.883316 19294 sgd_solver.cpp:106] Iteration 4770, lr = 5e-05
I0403 03:57:32.100039 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4774.caffemodel
I0403 03:57:34.870126 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4774.solverstate
I0403 03:57:36.721000 19294 solver.cpp:337] Iteration 4774, Testing net (#0)
I0403 03:58:50.242837 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986062
I0403 03:58:50.244128 19294 solver.cpp:404]     Test net output #1: loss = 0.049888 (* 1 = 0.049888 loss)
I0403 03:58:55.102381 19294 solver.cpp:228] Iteration 4780, loss = 0.00161156
I0403 03:58:55.102491 19294 solver.cpp:244]     Train net output #0: loss = 0.00161155 (* 1 = 0.00161155 loss)
I0403 03:58:55.290078 19294 sgd_solver.cpp:106] Iteration 4780, lr = 5e-05
I0403 03:59:02.417974 19294 solver.cpp:228] Iteration 4790, loss = 8.01964e-05
I0403 03:59:02.418076 19294 solver.cpp:244]     Train net output #0: loss = 8.01898e-05 (* 1 = 8.01898e-05 loss)
I0403 03:59:02.588533 19294 sgd_solver.cpp:106] Iteration 4790, lr = 5e-05
I0403 03:59:09.655755 19294 solver.cpp:228] Iteration 4800, loss = 0.000501625
I0403 03:59:09.655865 19294 solver.cpp:244]     Train net output #0: loss = 0.000501618 (* 1 = 0.000501618 loss)
I0403 03:59:09.873841 19294 sgd_solver.cpp:106] Iteration 4800, lr = 5e-05
I0403 03:59:16.893563 19294 solver.cpp:228] Iteration 4810, loss = 0.00173358
I0403 03:59:16.893677 19294 solver.cpp:244]     Train net output #0: loss = 0.00173357 (* 1 = 0.00173357 loss)
I0403 03:59:17.103366 19294 sgd_solver.cpp:106] Iteration 4810, lr = 5e-05
I0403 03:59:24.124225 19294 solver.cpp:228] Iteration 4820, loss = 0.000151006
I0403 03:59:24.124536 19294 solver.cpp:244]     Train net output #0: loss = 0.000151 (* 1 = 0.000151 loss)
I0403 03:59:24.313253 19294 sgd_solver.cpp:106] Iteration 4820, lr = 5e-05
I0403 03:59:31.425879 19294 solver.cpp:228] Iteration 4830, loss = 0.000160744
I0403 03:59:31.425989 19294 solver.cpp:244]     Train net output #0: loss = 0.000160738 (* 1 = 0.000160738 loss)
I0403 03:59:31.607849 19294 sgd_solver.cpp:106] Iteration 4830, lr = 5e-05
I0403 03:59:38.926456 19294 solver.cpp:228] Iteration 4840, loss = 0.000526795
I0403 03:59:38.926554 19294 solver.cpp:244]     Train net output #0: loss = 0.000526789 (* 1 = 0.000526789 loss)
I0403 03:59:39.111461 19294 sgd_solver.cpp:106] Iteration 4840, lr = 5e-05
I0403 03:59:46.244020 19294 solver.cpp:228] Iteration 4850, loss = 0.00227593
I0403 03:59:46.244128 19294 solver.cpp:244]     Train net output #0: loss = 0.00227592 (* 1 = 0.00227592 loss)
I0403 03:59:46.435710 19294 sgd_solver.cpp:106] Iteration 4850, lr = 5e-05
I0403 03:59:53.478047 19294 solver.cpp:228] Iteration 4860, loss = 0.000233115
I0403 03:59:53.478152 19294 solver.cpp:244]     Train net output #0: loss = 0.000233108 (* 1 = 0.000233108 loss)
I0403 03:59:53.655069 19294 sgd_solver.cpp:106] Iteration 4860, lr = 5e-05
I0403 04:00:00.779531 19294 solver.cpp:228] Iteration 4870, loss = 0.000241705
I0403 04:00:00.780583 19294 solver.cpp:244]     Train net output #0: loss = 0.000241698 (* 1 = 0.000241698 loss)
I0403 04:00:00.973599 19294 sgd_solver.cpp:106] Iteration 4870, lr = 5e-05
I0403 04:00:08.032549 19294 solver.cpp:228] Iteration 4880, loss = 0.000405983
I0403 04:00:08.032661 19294 solver.cpp:244]     Train net output #0: loss = 0.000405975 (* 1 = 0.000405975 loss)
I0403 04:00:08.230725 19294 sgd_solver.cpp:106] Iteration 4880, lr = 5e-05
I0403 04:00:15.349921 19294 solver.cpp:228] Iteration 4890, loss = 5.52441e-05
I0403 04:00:15.350023 19294 solver.cpp:244]     Train net output #0: loss = 5.52386e-05 (* 1 = 5.52386e-05 loss)
I0403 04:00:15.531571 19294 sgd_solver.cpp:106] Iteration 4890, lr = 5e-05
I0403 04:00:22.550209 19294 solver.cpp:228] Iteration 4900, loss = 0.000368682
I0403 04:00:22.550321 19294 solver.cpp:244]     Train net output #0: loss = 0.000368677 (* 1 = 0.000368677 loss)
I0403 04:00:22.734230 19294 sgd_solver.cpp:106] Iteration 4900, lr = 5e-05
I0403 04:00:29.844207 19294 solver.cpp:228] Iteration 4910, loss = 9.24254e-05
I0403 04:00:29.844308 19294 solver.cpp:244]     Train net output #0: loss = 9.24203e-05 (* 1 = 9.24203e-05 loss)
I0403 04:00:30.017068 19294 sgd_solver.cpp:106] Iteration 4910, lr = 5e-05
I0403 04:00:37.162600 19294 solver.cpp:228] Iteration 4920, loss = 0.00175806
I0403 04:00:37.162931 19294 solver.cpp:244]     Train net output #0: loss = 0.00175805 (* 1 = 0.00175805 loss)
I0403 04:00:37.339488 19294 sgd_solver.cpp:106] Iteration 4920, lr = 5e-05
I0403 04:00:44.502868 19294 solver.cpp:228] Iteration 4930, loss = 0.000164434
I0403 04:00:44.502979 19294 solver.cpp:244]     Train net output #0: loss = 0.000164429 (* 1 = 0.000164429 loss)
I0403 04:00:44.688928 19294 sgd_solver.cpp:106] Iteration 4930, lr = 5e-05
I0403 04:00:51.832885 19294 solver.cpp:228] Iteration 4940, loss = 0.000171851
I0403 04:00:51.832994 19294 solver.cpp:244]     Train net output #0: loss = 0.000171845 (* 1 = 0.000171845 loss)
I0403 04:00:52.025117 19294 sgd_solver.cpp:106] Iteration 4940, lr = 5e-05
I0403 04:00:59.091878 19294 solver.cpp:228] Iteration 4950, loss = 0.000190464
I0403 04:00:59.091971 19294 solver.cpp:244]     Train net output #0: loss = 0.000190458 (* 1 = 0.000190458 loss)
I0403 04:00:59.271917 19294 sgd_solver.cpp:106] Iteration 4950, lr = 5e-05
I0403 04:01:06.348796 19294 solver.cpp:228] Iteration 4960, loss = 0.00127112
I0403 04:01:06.348907 19294 solver.cpp:244]     Train net output #0: loss = 0.00127111 (* 1 = 0.00127111 loss)
I0403 04:01:06.553267 19294 sgd_solver.cpp:106] Iteration 4960, lr = 5e-05
I0403 04:01:13.603399 19294 solver.cpp:228] Iteration 4970, loss = 0.00179637
I0403 04:01:13.603633 19294 solver.cpp:244]     Train net output #0: loss = 0.00179636 (* 1 = 0.00179636 loss)
I0403 04:01:13.789341 19294 sgd_solver.cpp:106] Iteration 4970, lr = 5e-05
I0403 04:01:20.913446 19294 solver.cpp:228] Iteration 4980, loss = 0.0016524
I0403 04:01:20.913547 19294 solver.cpp:244]     Train net output #0: loss = 0.00165239 (* 1 = 0.00165239 loss)
I0403 04:01:21.089583 19294 sgd_solver.cpp:106] Iteration 4980, lr = 5e-05
I0403 04:01:28.215602 19294 solver.cpp:228] Iteration 4990, loss = 0.000314644
I0403 04:01:28.215710 19294 solver.cpp:244]     Train net output #0: loss = 0.000314638 (* 1 = 0.000314638 loss)
I0403 04:01:28.455456 19294 sgd_solver.cpp:106] Iteration 4990, lr = 5e-05
I0403 04:01:28.455687 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4991.caffemodel
I0403 04:01:31.181782 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_4991.solverstate
I0403 04:01:33.043102 19294 solver.cpp:337] Iteration 4991, Testing net (#0)
I0403 04:02:46.507071 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986
I0403 04:02:46.507378 19294 solver.cpp:404]     Test net output #1: loss = 0.0498511 (* 1 = 0.0498511 loss)
I0403 04:02:53.704175 19294 solver.cpp:228] Iteration 5000, loss = 2.06523e-05
I0403 04:02:53.704280 19294 solver.cpp:244]     Train net output #0: loss = 2.06459e-05 (* 1 = 2.06459e-05 loss)
I0403 04:02:53.888442 19294 sgd_solver.cpp:106] Iteration 5000, lr = 5e-05
I0403 04:03:01.004060 19294 solver.cpp:228] Iteration 5010, loss = 0.0061485
I0403 04:03:01.004184 19294 solver.cpp:244]     Train net output #0: loss = 0.00614849 (* 1 = 0.00614849 loss)
I0403 04:03:01.166362 19294 sgd_solver.cpp:106] Iteration 5010, lr = 5e-05
I0403 04:03:08.455154 19294 solver.cpp:228] Iteration 5020, loss = 0.00033579
I0403 04:03:08.455263 19294 solver.cpp:244]     Train net output #0: loss = 0.000335784 (* 1 = 0.000335784 loss)
I0403 04:03:08.635210 19294 sgd_solver.cpp:106] Iteration 5020, lr = 5e-05
I0403 04:03:15.677237 19294 solver.cpp:228] Iteration 5030, loss = 0.00116946
I0403 04:03:15.677336 19294 solver.cpp:244]     Train net output #0: loss = 0.00116946 (* 1 = 0.00116946 loss)
I0403 04:03:15.857867 19294 sgd_solver.cpp:106] Iteration 5030, lr = 5e-05
I0403 04:03:22.925328 19294 solver.cpp:228] Iteration 5040, loss = 0.00126906
I0403 04:03:22.925606 19294 solver.cpp:244]     Train net output #0: loss = 0.00126905 (* 1 = 0.00126905 loss)
I0403 04:03:23.100021 19294 sgd_solver.cpp:106] Iteration 5040, lr = 5e-05
I0403 04:03:30.339916 19294 solver.cpp:228] Iteration 5050, loss = 0.0286374
I0403 04:03:30.340009 19294 solver.cpp:244]     Train net output #0: loss = 0.0286374 (* 1 = 0.0286374 loss)
I0403 04:03:30.515576 19294 sgd_solver.cpp:106] Iteration 5050, lr = 5e-05
I0403 04:03:37.537160 19294 solver.cpp:228] Iteration 5060, loss = 0.00174102
I0403 04:03:37.537262 19294 solver.cpp:244]     Train net output #0: loss = 0.00174101 (* 1 = 0.00174101 loss)
I0403 04:03:37.711432 19294 sgd_solver.cpp:106] Iteration 5060, lr = 5e-05
I0403 04:03:44.780406 19294 solver.cpp:228] Iteration 5070, loss = 0.000161246
I0403 04:03:44.780508 19294 solver.cpp:244]     Train net output #0: loss = 0.000161239 (* 1 = 0.000161239 loss)
I0403 04:03:44.956588 19294 sgd_solver.cpp:106] Iteration 5070, lr = 5e-05
I0403 04:03:52.148262 19294 solver.cpp:228] Iteration 5080, loss = 0.000300345
I0403 04:03:52.148360 19294 solver.cpp:244]     Train net output #0: loss = 0.000300339 (* 1 = 0.000300339 loss)
I0403 04:03:52.327049 19294 sgd_solver.cpp:106] Iteration 5080, lr = 5e-05
I0403 04:03:59.426157 19294 solver.cpp:228] Iteration 5090, loss = 7.55302e-05
I0403 04:03:59.426481 19294 solver.cpp:244]     Train net output #0: loss = 7.55234e-05 (* 1 = 7.55234e-05 loss)
I0403 04:03:59.601737 19294 sgd_solver.cpp:106] Iteration 5090, lr = 5e-05
I0403 04:04:06.645078 19294 solver.cpp:228] Iteration 5100, loss = 0.0027977
I0403 04:04:06.645181 19294 solver.cpp:244]     Train net output #0: loss = 0.00279769 (* 1 = 0.00279769 loss)
I0403 04:04:06.828743 19294 sgd_solver.cpp:106] Iteration 5100, lr = 5e-05
I0403 04:04:13.874230 19294 solver.cpp:228] Iteration 5110, loss = 0.000197678
I0403 04:04:13.874332 19294 solver.cpp:244]     Train net output #0: loss = 0.000197672 (* 1 = 0.000197672 loss)
I0403 04:04:14.100744 19294 sgd_solver.cpp:106] Iteration 5110, lr = 5e-05
I0403 04:04:21.175416 19294 solver.cpp:228] Iteration 5120, loss = 0.00136116
I0403 04:04:21.175520 19294 solver.cpp:244]     Train net output #0: loss = 0.00136115 (* 1 = 0.00136115 loss)
I0403 04:04:21.396695 19294 sgd_solver.cpp:106] Iteration 5120, lr = 5e-05
I0403 04:04:28.467818 19294 solver.cpp:228] Iteration 5130, loss = 0.0058077
I0403 04:04:28.467921 19294 solver.cpp:244]     Train net output #0: loss = 0.00580769 (* 1 = 0.00580769 loss)
I0403 04:04:28.667026 19294 sgd_solver.cpp:106] Iteration 5130, lr = 5e-05
I0403 04:04:35.801766 19294 solver.cpp:228] Iteration 5140, loss = 0.00215267
I0403 04:04:35.802054 19294 solver.cpp:244]     Train net output #0: loss = 0.00215267 (* 1 = 0.00215267 loss)
I0403 04:04:35.980296 19294 sgd_solver.cpp:106] Iteration 5140, lr = 5e-05
I0403 04:04:43.167920 19294 solver.cpp:228] Iteration 5150, loss = 0.00127509
I0403 04:04:43.168025 19294 solver.cpp:244]     Train net output #0: loss = 0.00127509 (* 1 = 0.00127509 loss)
I0403 04:04:43.349262 19294 sgd_solver.cpp:106] Iteration 5150, lr = 5e-05
I0403 04:04:50.409101 19294 solver.cpp:228] Iteration 5160, loss = 0.00134056
I0403 04:04:50.409195 19294 solver.cpp:244]     Train net output #0: loss = 0.00134056 (* 1 = 0.00134056 loss)
I0403 04:04:50.589855 19294 sgd_solver.cpp:106] Iteration 5160, lr = 5e-05
I0403 04:04:57.652966 19294 solver.cpp:228] Iteration 5170, loss = 0.000334634
I0403 04:04:57.653074 19294 solver.cpp:244]     Train net output #0: loss = 0.000334629 (* 1 = 0.000334629 loss)
I0403 04:04:57.914252 19294 sgd_solver.cpp:106] Iteration 5170, lr = 5e-05
I0403 04:05:05.136121 19294 solver.cpp:228] Iteration 5180, loss = 0.00058592
I0403 04:05:05.136225 19294 solver.cpp:244]     Train net output #0: loss = 0.000585914 (* 1 = 0.000585914 loss)
I0403 04:05:05.307333 19294 sgd_solver.cpp:106] Iteration 5180, lr = 5e-05
I0403 04:05:12.456997 19294 solver.cpp:228] Iteration 5190, loss = 0.000258271
I0403 04:05:12.457306 19294 solver.cpp:244]     Train net output #0: loss = 0.000258266 (* 1 = 0.000258266 loss)
I0403 04:05:12.640570 19294 sgd_solver.cpp:106] Iteration 5190, lr = 5e-05
I0403 04:05:19.839166 19294 solver.cpp:228] Iteration 5200, loss = 0.00204499
I0403 04:05:19.839277 19294 solver.cpp:244]     Train net output #0: loss = 0.00204499 (* 1 = 0.00204499 loss)
I0403 04:05:20.021708 19294 sgd_solver.cpp:106] Iteration 5200, lr = 5e-05
I0403 04:05:25.023555 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5208.caffemodel
I0403 04:05:27.960566 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5208.solverstate
I0403 04:05:29.866581 19294 solver.cpp:337] Iteration 5208, Testing net (#0)
I0403 04:06:43.370932 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986
I0403 04:06:43.371213 19294 solver.cpp:404]     Test net output #1: loss = 0.049879 (* 1 = 0.049879 loss)
I0403 04:06:45.361141 19294 solver.cpp:228] Iteration 5210, loss = 3.87521e-05
I0403 04:06:45.361245 19294 solver.cpp:244]     Train net output #0: loss = 3.87456e-05 (* 1 = 3.87456e-05 loss)
I0403 04:06:45.553876 19294 sgd_solver.cpp:106] Iteration 5210, lr = 5e-05
I0403 04:06:52.647495 19294 solver.cpp:228] Iteration 5220, loss = 0.000503599
I0403 04:06:52.647591 19294 solver.cpp:244]     Train net output #0: loss = 0.000503593 (* 1 = 0.000503593 loss)
I0403 04:06:52.821894 19294 sgd_solver.cpp:106] Iteration 5220, lr = 5e-05
I0403 04:06:59.813756 19294 solver.cpp:228] Iteration 5230, loss = 0.0411243
I0403 04:06:59.813860 19294 solver.cpp:244]     Train net output #0: loss = 0.0411243 (* 1 = 0.0411243 loss)
I0403 04:07:00.011533 19294 sgd_solver.cpp:106] Iteration 5230, lr = 5e-05
I0403 04:07:07.029536 19294 solver.cpp:228] Iteration 5240, loss = 0.00113447
I0403 04:07:07.029634 19294 solver.cpp:244]     Train net output #0: loss = 0.00113447 (* 1 = 0.00113447 loss)
I0403 04:07:07.208950 19294 sgd_solver.cpp:106] Iteration 5240, lr = 5e-05
I0403 04:07:14.247398 19294 solver.cpp:228] Iteration 5250, loss = 0.000174441
I0403 04:07:14.247617 19294 solver.cpp:244]     Train net output #0: loss = 0.000174437 (* 1 = 0.000174437 loss)
I0403 04:07:14.411274 19294 sgd_solver.cpp:106] Iteration 5250, lr = 5e-05
I0403 04:07:21.516386 19294 solver.cpp:228] Iteration 5260, loss = 0.00154967
I0403 04:07:21.516482 19294 solver.cpp:244]     Train net output #0: loss = 0.00154966 (* 1 = 0.00154966 loss)
I0403 04:07:21.689941 19294 sgd_solver.cpp:106] Iteration 5260, lr = 5e-05
I0403 04:07:28.808493 19294 solver.cpp:228] Iteration 5270, loss = 0.000105527
I0403 04:07:28.808589 19294 solver.cpp:244]     Train net output #0: loss = 0.000105523 (* 1 = 0.000105523 loss)
I0403 04:07:28.988550 19294 sgd_solver.cpp:106] Iteration 5270, lr = 5e-05
I0403 04:07:36.000813 19294 solver.cpp:228] Iteration 5280, loss = 0.00752882
I0403 04:07:36.000910 19294 solver.cpp:244]     Train net output #0: loss = 0.00752881 (* 1 = 0.00752881 loss)
I0403 04:07:36.175369 19294 sgd_solver.cpp:106] Iteration 5280, lr = 5e-05
I0403 04:07:43.361353 19294 solver.cpp:228] Iteration 5290, loss = 0.00111339
I0403 04:07:43.361457 19294 solver.cpp:244]     Train net output #0: loss = 0.00111338 (* 1 = 0.00111338 loss)
I0403 04:07:43.548348 19294 sgd_solver.cpp:106] Iteration 5290, lr = 5e-05
I0403 04:07:50.598708 19294 solver.cpp:228] Iteration 5300, loss = 0.000139612
I0403 04:07:50.599036 19294 solver.cpp:244]     Train net output #0: loss = 0.000139608 (* 1 = 0.000139608 loss)
I0403 04:07:50.770133 19294 sgd_solver.cpp:106] Iteration 5300, lr = 5e-05
I0403 04:07:57.880054 19294 solver.cpp:228] Iteration 5310, loss = 0.00127138
I0403 04:07:57.880149 19294 solver.cpp:244]     Train net output #0: loss = 0.00127137 (* 1 = 0.00127137 loss)
I0403 04:07:58.059873 19294 sgd_solver.cpp:106] Iteration 5310, lr = 5e-05
I0403 04:08:05.064961 19294 solver.cpp:228] Iteration 5320, loss = 0.00431354
I0403 04:08:05.065073 19294 solver.cpp:244]     Train net output #0: loss = 0.00431353 (* 1 = 0.00431353 loss)
I0403 04:08:05.294790 19294 sgd_solver.cpp:106] Iteration 5320, lr = 5e-05
I0403 04:08:12.385243 19294 solver.cpp:228] Iteration 5330, loss = 0.001719
I0403 04:08:12.385351 19294 solver.cpp:244]     Train net output #0: loss = 0.001719 (* 1 = 0.001719 loss)
I0403 04:08:12.591449 19294 sgd_solver.cpp:106] Iteration 5330, lr = 5e-05
I0403 04:08:19.703122 19294 solver.cpp:228] Iteration 5340, loss = 0.00148723
I0403 04:08:19.703927 19294 solver.cpp:244]     Train net output #0: loss = 0.00148723 (* 1 = 0.00148723 loss)
I0403 04:08:19.867736 19294 sgd_solver.cpp:106] Iteration 5340, lr = 5e-05
I0403 04:08:26.973100 19294 solver.cpp:228] Iteration 5350, loss = 6.04831e-05
I0403 04:08:26.973414 19294 solver.cpp:244]     Train net output #0: loss = 6.04779e-05 (* 1 = 6.04779e-05 loss)
I0403 04:08:27.178992 19294 sgd_solver.cpp:106] Iteration 5350, lr = 5e-05
I0403 04:08:34.235220 19294 solver.cpp:228] Iteration 5360, loss = 0.000257643
I0403 04:08:34.235327 19294 solver.cpp:244]     Train net output #0: loss = 0.000257638 (* 1 = 0.000257638 loss)
I0403 04:08:34.442982 19294 sgd_solver.cpp:106] Iteration 5360, lr = 5e-05
I0403 04:08:41.762692 19294 solver.cpp:228] Iteration 5370, loss = 0.00233902
I0403 04:08:41.762792 19294 solver.cpp:244]     Train net output #0: loss = 0.00233901 (* 1 = 0.00233901 loss)
I0403 04:08:41.928714 19294 sgd_solver.cpp:106] Iteration 5370, lr = 5e-05
I0403 04:08:48.957803 19294 solver.cpp:228] Iteration 5380, loss = 0.000960972
I0403 04:08:48.957911 19294 solver.cpp:244]     Train net output #0: loss = 0.000960967 (* 1 = 0.000960967 loss)
I0403 04:08:49.234956 19294 sgd_solver.cpp:106] Iteration 5380, lr = 5e-05
I0403 04:08:56.305297 19294 solver.cpp:228] Iteration 5390, loss = 0.000417962
I0403 04:08:56.305405 19294 solver.cpp:244]     Train net output #0: loss = 0.000417957 (* 1 = 0.000417957 loss)
I0403 04:08:56.505787 19294 sgd_solver.cpp:106] Iteration 5390, lr = 5e-05
I0403 04:09:03.673594 19294 solver.cpp:228] Iteration 5400, loss = 0.000981483
I0403 04:09:03.673890 19294 solver.cpp:244]     Train net output #0: loss = 0.00098148 (* 1 = 0.00098148 loss)
I0403 04:09:03.893126 19294 sgd_solver.cpp:106] Iteration 5400, lr = 5e-05
I0403 04:09:10.887338 19294 solver.cpp:228] Iteration 5410, loss = 0.00850517
I0403 04:09:10.887431 19294 solver.cpp:244]     Train net output #0: loss = 0.00850517 (* 1 = 0.00850517 loss)
I0403 04:09:11.060442 19294 sgd_solver.cpp:106] Iteration 5410, lr = 5e-05
I0403 04:09:18.145612 19294 solver.cpp:228] Iteration 5420, loss = 7.17105e-05
I0403 04:09:18.145721 19294 solver.cpp:244]     Train net output #0: loss = 7.17068e-05 (* 1 = 7.17068e-05 loss)
I0403 04:09:18.347198 19294 sgd_solver.cpp:106] Iteration 5420, lr = 5e-05
I0403 04:09:21.228471 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5425.caffemodel
I0403 04:09:24.056821 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5425.solverstate
I0403 04:09:25.970263 19294 solver.cpp:337] Iteration 5425, Testing net (#0)
I0403 04:10:39.450222 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986123
I0403 04:10:39.450502 19294 solver.cpp:404]     Test net output #1: loss = 0.0498741 (* 1 = 0.0498741 loss)
I0403 04:10:43.598687 19294 solver.cpp:228] Iteration 5430, loss = 0.000500836
I0403 04:10:43.598780 19294 solver.cpp:244]     Train net output #0: loss = 0.000500832 (* 1 = 0.000500832 loss)
I0403 04:10:43.758616 19294 sgd_solver.cpp:106] Iteration 5430, lr = 5e-05
I0403 04:10:50.834053 19294 solver.cpp:228] Iteration 5440, loss = 0.00039406
I0403 04:10:50.834157 19294 solver.cpp:244]     Train net output #0: loss = 0.000394056 (* 1 = 0.000394056 loss)
I0403 04:10:51.016577 19294 sgd_solver.cpp:106] Iteration 5440, lr = 5e-05
I0403 04:10:58.140564 19294 solver.cpp:228] Iteration 5450, loss = 0.0032525
I0403 04:10:58.140671 19294 solver.cpp:244]     Train net output #0: loss = 0.0032525 (* 1 = 0.0032525 loss)
I0403 04:10:58.363246 19294 sgd_solver.cpp:106] Iteration 5450, lr = 5e-05
I0403 04:11:05.445997 19294 solver.cpp:228] Iteration 5460, loss = 0.000627205
I0403 04:11:05.446094 19294 solver.cpp:244]     Train net output #0: loss = 0.000627201 (* 1 = 0.000627201 loss)
I0403 04:11:05.624913 19294 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 04:11:12.692692 19294 solver.cpp:228] Iteration 5470, loss = 0.0037162
I0403 04:11:12.693771 19294 solver.cpp:244]     Train net output #0: loss = 0.00371619 (* 1 = 0.00371619 loss)
I0403 04:11:12.857342 19294 sgd_solver.cpp:106] Iteration 5470, lr = 5e-05
I0403 04:11:20.080590 19294 solver.cpp:228] Iteration 5480, loss = 0.000170994
I0403 04:11:20.080687 19294 solver.cpp:244]     Train net output #0: loss = 0.00017099 (* 1 = 0.00017099 loss)
I0403 04:11:20.248769 19294 sgd_solver.cpp:106] Iteration 5480, lr = 5e-05
I0403 04:11:27.574259 19294 solver.cpp:228] Iteration 5490, loss = 0.000143379
I0403 04:11:27.574365 19294 solver.cpp:244]     Train net output #0: loss = 0.000143376 (* 1 = 0.000143376 loss)
I0403 04:11:27.759950 19294 sgd_solver.cpp:106] Iteration 5490, lr = 5e-05
I0403 04:11:34.799103 19294 solver.cpp:228] Iteration 5500, loss = 0.000715364
I0403 04:11:34.799216 19294 solver.cpp:244]     Train net output #0: loss = 0.00071536 (* 1 = 0.00071536 loss)
I0403 04:11:34.962543 19294 sgd_solver.cpp:106] Iteration 5500, lr = 5e-05
I0403 04:11:42.040351 19294 solver.cpp:228] Iteration 5510, loss = 0.000226404
I0403 04:11:42.040455 19294 solver.cpp:244]     Train net output #0: loss = 0.000226399 (* 1 = 0.000226399 loss)
I0403 04:11:42.222357 19294 sgd_solver.cpp:106] Iteration 5510, lr = 5e-05
I0403 04:11:49.336617 19294 solver.cpp:228] Iteration 5520, loss = 5.76943e-05
I0403 04:11:49.336923 19294 solver.cpp:244]     Train net output #0: loss = 5.7688e-05 (* 1 = 5.7688e-05 loss)
I0403 04:11:49.518276 19294 sgd_solver.cpp:106] Iteration 5520, lr = 5e-05
I0403 04:11:56.528684 19294 solver.cpp:228] Iteration 5530, loss = 0.000161878
I0403 04:11:56.528779 19294 solver.cpp:244]     Train net output #0: loss = 0.000161872 (* 1 = 0.000161872 loss)
I0403 04:11:56.691352 19294 sgd_solver.cpp:106] Iteration 5530, lr = 5e-05
I0403 04:12:03.781831 19294 solver.cpp:228] Iteration 5540, loss = 0.000180188
I0403 04:12:03.781930 19294 solver.cpp:244]     Train net output #0: loss = 0.000180182 (* 1 = 0.000180182 loss)
I0403 04:12:03.952245 19294 sgd_solver.cpp:106] Iteration 5540, lr = 5e-05
I0403 04:12:11.072177 19294 solver.cpp:228] Iteration 5550, loss = 0.000110582
I0403 04:12:11.072280 19294 solver.cpp:244]     Train net output #0: loss = 0.000110577 (* 1 = 0.000110577 loss)
I0403 04:12:11.250651 19294 sgd_solver.cpp:106] Iteration 5550, lr = 5e-05
I0403 04:12:18.284237 19294 solver.cpp:228] Iteration 5560, loss = 0.00892217
I0403 04:12:18.284348 19294 solver.cpp:244]     Train net output #0: loss = 0.00892216 (* 1 = 0.00892216 loss)
I0403 04:12:18.521250 19294 sgd_solver.cpp:106] Iteration 5560, lr = 5e-05
I0403 04:12:25.581507 19294 solver.cpp:228] Iteration 5570, loss = 0.000109579
I0403 04:12:25.581809 19294 solver.cpp:244]     Train net output #0: loss = 0.000109574 (* 1 = 0.000109574 loss)
I0403 04:12:25.769502 19294 sgd_solver.cpp:106] Iteration 5570, lr = 5e-05
I0403 04:12:32.870239 19294 solver.cpp:228] Iteration 5580, loss = 0.000256628
I0403 04:12:32.870342 19294 solver.cpp:244]     Train net output #0: loss = 0.000256623 (* 1 = 0.000256623 loss)
I0403 04:12:33.043939 19294 sgd_solver.cpp:106] Iteration 5580, lr = 5e-05
I0403 04:12:40.230013 19294 solver.cpp:228] Iteration 5590, loss = 0.000536097
I0403 04:12:40.230129 19294 solver.cpp:244]     Train net output #0: loss = 0.000536092 (* 1 = 0.000536092 loss)
I0403 04:12:40.464095 19294 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 04:12:47.681602 19294 solver.cpp:228] Iteration 5600, loss = 0.011013
I0403 04:12:47.681713 19294 solver.cpp:244]     Train net output #0: loss = 0.011013 (* 1 = 0.011013 loss)
I0403 04:12:47.867815 19294 sgd_solver.cpp:106] Iteration 5600, lr = 5e-05
I0403 04:12:54.900569 19294 solver.cpp:228] Iteration 5610, loss = 0.000112206
I0403 04:12:54.900671 19294 solver.cpp:244]     Train net output #0: loss = 0.000112201 (* 1 = 0.000112201 loss)
I0403 04:12:55.069783 19294 sgd_solver.cpp:106] Iteration 5610, lr = 5e-05
I0403 04:13:02.168323 19294 solver.cpp:228] Iteration 5620, loss = 0.000475168
I0403 04:13:02.168660 19294 solver.cpp:244]     Train net output #0: loss = 0.000475162 (* 1 = 0.000475162 loss)
I0403 04:13:02.383699 19294 sgd_solver.cpp:106] Iteration 5620, lr = 5e-05
I0403 04:13:09.517146 19294 solver.cpp:228] Iteration 5630, loss = 0.004116
I0403 04:13:09.517261 19294 solver.cpp:244]     Train net output #0: loss = 0.00411599 (* 1 = 0.00411599 loss)
I0403 04:13:09.714776 19294 sgd_solver.cpp:106] Iteration 5630, lr = 5e-05
I0403 04:13:16.863041 19294 solver.cpp:228] Iteration 5640, loss = 0.000869287
I0403 04:13:16.863143 19294 solver.cpp:244]     Train net output #0: loss = 0.000869281 (* 1 = 0.000869281 loss)
I0403 04:13:17.029472 19294 sgd_solver.cpp:106] Iteration 5640, lr = 5e-05
I0403 04:13:17.794001 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5642.caffemodel
I0403 04:13:20.530396 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5642.solverstate
I0403 04:13:22.381058 19294 solver.cpp:337] Iteration 5642, Testing net (#0)
I0403 04:14:35.862387 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986062
I0403 04:14:35.862720 19294 solver.cpp:404]     Test net output #1: loss = 0.0497025 (* 1 = 0.0497025 loss)
I0403 04:14:42.267913 19294 solver.cpp:228] Iteration 5650, loss = 0.000979678
I0403 04:14:42.268023 19294 solver.cpp:244]     Train net output #0: loss = 0.000979672 (* 1 = 0.000979672 loss)
I0403 04:14:42.465039 19294 sgd_solver.cpp:106] Iteration 5650, lr = 5e-05
I0403 04:14:49.788409 19294 solver.cpp:228] Iteration 5660, loss = 4.64006e-05
I0403 04:14:49.788511 19294 solver.cpp:244]     Train net output #0: loss = 4.63942e-05 (* 1 = 4.63942e-05 loss)
I0403 04:14:49.935510 19294 sgd_solver.cpp:106] Iteration 5660, lr = 5e-05
I0403 04:14:57.231470 19294 solver.cpp:228] Iteration 5670, loss = 0.00667056
I0403 04:14:57.231572 19294 solver.cpp:244]     Train net output #0: loss = 0.00667055 (* 1 = 0.00667055 loss)
I0403 04:14:57.408586 19294 sgd_solver.cpp:106] Iteration 5670, lr = 5e-05
I0403 04:15:04.415817 19294 solver.cpp:228] Iteration 5680, loss = 0.000950165
I0403 04:15:04.415920 19294 solver.cpp:244]     Train net output #0: loss = 0.000950156 (* 1 = 0.000950156 loss)
I0403 04:15:04.584257 19294 sgd_solver.cpp:106] Iteration 5680, lr = 5e-05
I0403 04:15:11.663631 19294 solver.cpp:228] Iteration 5690, loss = 9.93027e-05
I0403 04:15:11.663933 19294 solver.cpp:244]     Train net output #0: loss = 9.92943e-05 (* 1 = 9.92943e-05 loss)
I0403 04:15:11.842517 19294 sgd_solver.cpp:106] Iteration 5690, lr = 5e-05
I0403 04:15:19.128881 19294 solver.cpp:228] Iteration 5700, loss = 0.000106664
I0403 04:15:19.128993 19294 solver.cpp:244]     Train net output #0: loss = 0.000106656 (* 1 = 0.000106656 loss)
I0403 04:15:19.370245 19294 sgd_solver.cpp:106] Iteration 5700, lr = 5e-05
I0403 04:15:26.532483 19294 solver.cpp:228] Iteration 5710, loss = 0.00063398
I0403 04:15:26.532584 19294 solver.cpp:244]     Train net output #0: loss = 0.000633972 (* 1 = 0.000633972 loss)
I0403 04:15:26.694619 19294 sgd_solver.cpp:106] Iteration 5710, lr = 5e-05
I0403 04:15:33.892101 19294 solver.cpp:228] Iteration 5720, loss = 0.000808558
I0403 04:15:33.892204 19294 solver.cpp:244]     Train net output #0: loss = 0.00080855 (* 1 = 0.00080855 loss)
I0403 04:15:34.068087 19294 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 04:15:41.120494 19294 solver.cpp:228] Iteration 5730, loss = 0.000392061
I0403 04:15:41.120602 19294 solver.cpp:244]     Train net output #0: loss = 0.000392053 (* 1 = 0.000392053 loss)
I0403 04:15:41.331688 19294 sgd_solver.cpp:106] Iteration 5730, lr = 5e-05
I0403 04:15:48.611557 19294 solver.cpp:228] Iteration 5740, loss = 0.000259139
I0403 04:15:48.611860 19294 solver.cpp:244]     Train net output #0: loss = 0.000259131 (* 1 = 0.000259131 loss)
I0403 04:15:48.771984 19294 sgd_solver.cpp:106] Iteration 5740, lr = 5e-05
I0403 04:15:55.777750 19294 solver.cpp:228] Iteration 5750, loss = 0.0063445
I0403 04:15:55.777861 19294 solver.cpp:244]     Train net output #0: loss = 0.00634449 (* 1 = 0.00634449 loss)
I0403 04:15:55.977079 19294 sgd_solver.cpp:106] Iteration 5750, lr = 5e-05
I0403 04:16:03.040913 19294 solver.cpp:228] Iteration 5760, loss = 0.000157941
I0403 04:16:03.041016 19294 solver.cpp:244]     Train net output #0: loss = 0.000157934 (* 1 = 0.000157934 loss)
I0403 04:16:03.198602 19294 sgd_solver.cpp:106] Iteration 5760, lr = 5e-05
I0403 04:16:10.346081 19294 solver.cpp:228] Iteration 5770, loss = 7.62879e-05
I0403 04:16:10.346189 19294 solver.cpp:244]     Train net output #0: loss = 7.62804e-05 (* 1 = 7.62804e-05 loss)
I0403 04:16:10.594949 19294 sgd_solver.cpp:106] Iteration 5770, lr = 5e-05
I0403 04:16:17.566293 19294 solver.cpp:228] Iteration 5780, loss = 0.00067693
I0403 04:16:17.566404 19294 solver.cpp:244]     Train net output #0: loss = 0.000676922 (* 1 = 0.000676922 loss)
I0403 04:16:17.793576 19294 sgd_solver.cpp:106] Iteration 5780, lr = 5e-05
I0403 04:16:24.841183 19294 solver.cpp:228] Iteration 5790, loss = 0.000408478
I0403 04:16:24.841500 19294 solver.cpp:244]     Train net output #0: loss = 0.000408469 (* 1 = 0.000408469 loss)
I0403 04:16:25.016959 19294 sgd_solver.cpp:106] Iteration 5790, lr = 5e-05
I0403 04:16:32.292459 19294 solver.cpp:228] Iteration 5800, loss = 0.000166791
I0403 04:16:32.292569 19294 solver.cpp:244]     Train net output #0: loss = 0.000166783 (* 1 = 0.000166783 loss)
I0403 04:16:32.476001 19294 sgd_solver.cpp:106] Iteration 5800, lr = 5e-05
I0403 04:16:39.499858 19294 solver.cpp:228] Iteration 5810, loss = 0.000304051
I0403 04:16:39.499959 19294 solver.cpp:244]     Train net output #0: loss = 0.000304042 (* 1 = 0.000304042 loss)
I0403 04:16:39.679667 19294 sgd_solver.cpp:106] Iteration 5810, lr = 5e-05
I0403 04:16:46.764637 19294 solver.cpp:228] Iteration 5820, loss = 0.000143086
I0403 04:16:46.764735 19294 solver.cpp:244]     Train net output #0: loss = 0.000143077 (* 1 = 0.000143077 loss)
I0403 04:16:46.942579 19294 sgd_solver.cpp:106] Iteration 5820, lr = 5e-05
I0403 04:16:54.066642 19294 solver.cpp:228] Iteration 5830, loss = 0.00247216
I0403 04:16:54.066743 19294 solver.cpp:244]     Train net output #0: loss = 0.00247215 (* 1 = 0.00247215 loss)
I0403 04:16:54.242084 19294 sgd_solver.cpp:106] Iteration 5830, lr = 5e-05
I0403 04:17:01.382050 19294 solver.cpp:228] Iteration 5840, loss = 0.000154193
I0403 04:17:01.382277 19294 solver.cpp:244]     Train net output #0: loss = 0.000154183 (* 1 = 0.000154183 loss)
I0403 04:17:01.558681 19294 sgd_solver.cpp:106] Iteration 5840, lr = 5e-05
I0403 04:17:08.612314 19294 solver.cpp:228] Iteration 5850, loss = 0.000928311
I0403 04:17:08.612426 19294 solver.cpp:244]     Train net output #0: loss = 0.000928302 (* 1 = 0.000928302 loss)
I0403 04:17:08.800724 19294 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 04:17:14.697187 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5859.caffemodel
I0403 04:17:17.500938 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_5859.solverstate
I0403 04:17:19.358424 19294 solver.cpp:337] Iteration 5859, Testing net (#0)
I0403 04:18:32.832023 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986277
I0403 04:18:32.832356 19294 solver.cpp:404]     Test net output #1: loss = 0.0495317 (* 1 = 0.0495317 loss)
I0403 04:18:34.095590 19294 solver.cpp:228] Iteration 5860, loss = 0.00548049
I0403 04:18:34.095697 19294 solver.cpp:244]     Train net output #0: loss = 0.00548048 (* 1 = 0.00548048 loss)
I0403 04:18:34.308957 19294 sgd_solver.cpp:106] Iteration 5860, lr = 5e-05
I0403 04:18:41.387866 19294 solver.cpp:228] Iteration 5870, loss = 0.000239911
I0403 04:18:41.388005 19294 solver.cpp:244]     Train net output #0: loss = 0.000239902 (* 1 = 0.000239902 loss)
I0403 04:18:41.635426 19294 sgd_solver.cpp:106] Iteration 5870, lr = 5e-05
I0403 04:18:48.763887 19294 solver.cpp:228] Iteration 5880, loss = 0.000242422
I0403 04:18:48.764941 19294 solver.cpp:244]     Train net output #0: loss = 0.000242413 (* 1 = 0.000242413 loss)
I0403 04:18:48.958621 19294 sgd_solver.cpp:106] Iteration 5880, lr = 5e-05
I0403 04:18:56.125481 19294 solver.cpp:228] Iteration 5890, loss = 0.000510597
I0403 04:18:56.125597 19294 solver.cpp:244]     Train net output #0: loss = 0.000510587 (* 1 = 0.000510587 loss)
I0403 04:18:56.299988 19294 sgd_solver.cpp:106] Iteration 5890, lr = 5e-05
I0403 04:19:03.287382 19294 solver.cpp:228] Iteration 5900, loss = 0.00160537
I0403 04:19:03.287706 19294 solver.cpp:244]     Train net output #0: loss = 0.00160536 (* 1 = 0.00160536 loss)
I0403 04:19:03.484966 19294 sgd_solver.cpp:106] Iteration 5900, lr = 5e-05
I0403 04:19:10.530485 19294 solver.cpp:228] Iteration 5910, loss = 0.000592082
I0403 04:19:10.530593 19294 solver.cpp:244]     Train net output #0: loss = 0.000592072 (* 1 = 0.000592072 loss)
I0403 04:19:10.738093 19294 sgd_solver.cpp:106] Iteration 5910, lr = 5e-05
I0403 04:19:17.928637 19294 solver.cpp:228] Iteration 5920, loss = 4.4279e-05
I0403 04:19:17.928746 19294 solver.cpp:244]     Train net output #0: loss = 4.42696e-05 (* 1 = 4.42696e-05 loss)
I0403 04:19:18.113903 19294 sgd_solver.cpp:106] Iteration 5920, lr = 5e-05
I0403 04:19:25.169471 19294 solver.cpp:228] Iteration 5930, loss = 7.03316e-05
I0403 04:19:25.169572 19294 solver.cpp:244]     Train net output #0: loss = 7.03223e-05 (* 1 = 7.03223e-05 loss)
I0403 04:19:25.341722 19294 sgd_solver.cpp:106] Iteration 5930, lr = 5e-05
I0403 04:19:32.383184 19294 solver.cpp:228] Iteration 5940, loss = 4.67457e-05
I0403 04:19:32.383290 19294 solver.cpp:244]     Train net output #0: loss = 4.67361e-05 (* 1 = 4.67361e-05 loss)
I0403 04:19:32.561122 19294 sgd_solver.cpp:106] Iteration 5940, lr = 5e-05
I0403 04:19:39.644076 19294 solver.cpp:228] Iteration 5950, loss = 0.00014619
I0403 04:19:39.644382 19294 solver.cpp:244]     Train net output #0: loss = 0.00014618 (* 1 = 0.00014618 loss)
I0403 04:19:39.830924 19294 sgd_solver.cpp:106] Iteration 5950, lr = 5e-05
I0403 04:19:47.150934 19294 solver.cpp:228] Iteration 5960, loss = 0.000247959
I0403 04:19:47.151043 19294 solver.cpp:244]     Train net output #0: loss = 0.000247948 (* 1 = 0.000247948 loss)
I0403 04:19:47.335919 19294 sgd_solver.cpp:106] Iteration 5960, lr = 5e-05
I0403 04:19:54.396751 19294 solver.cpp:228] Iteration 5970, loss = 0.000210609
I0403 04:19:54.396862 19294 solver.cpp:244]     Train net output #0: loss = 0.000210598 (* 1 = 0.000210598 loss)
I0403 04:19:54.609161 19294 sgd_solver.cpp:106] Iteration 5970, lr = 5e-05
I0403 04:20:01.613649 19294 solver.cpp:228] Iteration 5980, loss = 0.000459432
I0403 04:20:01.613760 19294 solver.cpp:244]     Train net output #0: loss = 0.000459422 (* 1 = 0.000459422 loss)
I0403 04:20:01.797587 19294 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 04:20:08.874660 19294 solver.cpp:228] Iteration 5990, loss = 0.000822088
I0403 04:20:08.874770 19294 solver.cpp:244]     Train net output #0: loss = 0.000822078 (* 1 = 0.000822078 loss)
I0403 04:20:09.074573 19294 sgd_solver.cpp:106] Iteration 5990, lr = 5e-05
I0403 04:20:16.188877 19294 solver.cpp:228] Iteration 6000, loss = 0.000200693
I0403 04:20:16.189201 19294 solver.cpp:244]     Train net output #0: loss = 0.000200686 (* 1 = 0.000200686 loss)
I0403 04:20:16.367516 19294 sgd_solver.cpp:106] Iteration 6000, lr = 5e-05
I0403 04:20:23.433863 19294 solver.cpp:228] Iteration 6010, loss = 6.09895e-05
I0403 04:20:23.433972 19294 solver.cpp:244]     Train net output #0: loss = 6.09827e-05 (* 1 = 6.09827e-05 loss)
I0403 04:20:23.643337 19294 sgd_solver.cpp:106] Iteration 6010, lr = 5e-05
I0403 04:20:30.905676 19294 solver.cpp:228] Iteration 6020, loss = 9.47459e-05
I0403 04:20:30.905779 19294 solver.cpp:244]     Train net output #0: loss = 9.47397e-05 (* 1 = 9.47397e-05 loss)
I0403 04:20:31.080138 19294 sgd_solver.cpp:106] Iteration 6020, lr = 5e-05
I0403 04:20:38.268283 19294 solver.cpp:228] Iteration 6030, loss = 0.00859021
I0403 04:20:38.268393 19294 solver.cpp:244]     Train net output #0: loss = 0.0085902 (* 1 = 0.0085902 loss)
I0403 04:20:38.458904 19294 sgd_solver.cpp:106] Iteration 6030, lr = 5e-05
I0403 04:20:45.550457 19294 solver.cpp:228] Iteration 6040, loss = 0.000232609
I0403 04:20:45.550557 19294 solver.cpp:244]     Train net output #0: loss = 0.000232602 (* 1 = 0.000232602 loss)
I0403 04:20:45.720536 19294 sgd_solver.cpp:106] Iteration 6040, lr = 5e-05
I0403 04:20:53.026178 19294 solver.cpp:228] Iteration 6050, loss = 0.000548125
I0403 04:20:53.026522 19294 solver.cpp:244]     Train net output #0: loss = 0.000548117 (* 1 = 0.000548117 loss)
I0403 04:20:53.198765 19294 sgd_solver.cpp:106] Iteration 6050, lr = 5e-05
I0403 04:21:00.229388 19294 solver.cpp:228] Iteration 6060, loss = 7.32247e-05
I0403 04:21:00.229501 19294 solver.cpp:244]     Train net output #0: loss = 7.32168e-05 (* 1 = 7.32168e-05 loss)
I0403 04:21:00.464778 19294 sgd_solver.cpp:106] Iteration 6060, lr = 5e-05
I0403 04:21:07.603222 19294 solver.cpp:228] Iteration 6070, loss = 0.000354836
I0403 04:21:07.603324 19294 solver.cpp:244]     Train net output #0: loss = 0.000354828 (* 1 = 0.000354828 loss)
I0403 04:21:07.780664 19294 sgd_solver.cpp:106] Iteration 6070, lr = 5e-05
I0403 04:21:11.587363 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6076.caffemodel
I0403 04:21:14.450667 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6076.solverstate
I0403 04:21:16.314656 19294 solver.cpp:337] Iteration 6076, Testing net (#0)
I0403 04:22:29.783058 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986093
I0403 04:22:29.785590 19294 solver.cpp:404]     Test net output #1: loss = 0.0496532 (* 1 = 0.0496532 loss)
I0403 04:22:33.293591 19294 solver.cpp:228] Iteration 6080, loss = 8.22631e-05
I0403 04:22:33.293699 19294 solver.cpp:244]     Train net output #0: loss = 8.22552e-05 (* 1 = 8.22552e-05 loss)
I0403 04:22:33.481683 19294 sgd_solver.cpp:106] Iteration 6080, lr = 5e-05
I0403 04:22:40.560858 19294 solver.cpp:228] Iteration 6090, loss = 0.000733823
I0403 04:22:40.560966 19294 solver.cpp:244]     Train net output #0: loss = 0.000733815 (* 1 = 0.000733815 loss)
I0403 04:22:40.758353 19294 sgd_solver.cpp:106] Iteration 6090, lr = 5e-05
I0403 04:22:47.853832 19294 solver.cpp:228] Iteration 6100, loss = 0.000510878
I0403 04:22:47.853934 19294 solver.cpp:244]     Train net output #0: loss = 0.00051087 (* 1 = 0.00051087 loss)
I0403 04:22:48.031018 19294 sgd_solver.cpp:106] Iteration 6100, lr = 5e-05
I0403 04:22:55.125025 19294 solver.cpp:228] Iteration 6110, loss = 0.000296145
I0403 04:22:55.125136 19294 solver.cpp:244]     Train net output #0: loss = 0.000296137 (* 1 = 0.000296137 loss)
I0403 04:22:55.321964 19294 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 04:23:02.307533 19294 solver.cpp:228] Iteration 6120, loss = 0.000168196
I0403 04:23:02.307838 19294 solver.cpp:244]     Train net output #0: loss = 0.000168188 (* 1 = 0.000168188 loss)
I0403 04:23:02.489028 19294 sgd_solver.cpp:106] Iteration 6120, lr = 5e-05
I0403 04:23:09.641093 19294 solver.cpp:228] Iteration 6130, loss = 0.000609428
I0403 04:23:09.641196 19294 solver.cpp:244]     Train net output #0: loss = 0.000609421 (* 1 = 0.000609421 loss)
I0403 04:23:09.811887 19294 sgd_solver.cpp:106] Iteration 6130, lr = 5e-05
I0403 04:23:17.012118 19294 solver.cpp:228] Iteration 6140, loss = 9.402e-05
I0403 04:23:17.012235 19294 solver.cpp:244]     Train net output #0: loss = 9.40126e-05 (* 1 = 9.40126e-05 loss)
I0403 04:23:17.204092 19294 sgd_solver.cpp:106] Iteration 6140, lr = 5e-05
I0403 04:23:24.250401 19294 solver.cpp:228] Iteration 6150, loss = 0.000488139
I0403 04:23:24.250512 19294 solver.cpp:244]     Train net output #0: loss = 0.000488131 (* 1 = 0.000488131 loss)
I0403 04:23:24.438657 19294 sgd_solver.cpp:106] Iteration 6150, lr = 5e-05
I0403 04:23:31.519598 19294 solver.cpp:228] Iteration 6160, loss = 0.00322784
I0403 04:23:31.519695 19294 solver.cpp:244]     Train net output #0: loss = 0.00322783 (* 1 = 0.00322783 loss)
I0403 04:23:31.694598 19294 sgd_solver.cpp:106] Iteration 6160, lr = 5e-05
I0403 04:23:38.921521 19294 solver.cpp:228] Iteration 6170, loss = 0.00694091
I0403 04:23:38.921870 19294 solver.cpp:244]     Train net output #0: loss = 0.0069409 (* 1 = 0.0069409 loss)
I0403 04:23:39.124608 19294 sgd_solver.cpp:106] Iteration 6170, lr = 5e-05
I0403 04:23:46.126430 19294 solver.cpp:228] Iteration 6180, loss = 5.80022e-05
I0403 04:23:46.126539 19294 solver.cpp:244]     Train net output #0: loss = 5.79952e-05 (* 1 = 5.79952e-05 loss)
I0403 04:23:46.314250 19294 sgd_solver.cpp:106] Iteration 6180, lr = 5e-05
I0403 04:23:53.393345 19294 solver.cpp:228] Iteration 6190, loss = 0.00119016
I0403 04:23:53.393460 19294 solver.cpp:244]     Train net output #0: loss = 0.00119015 (* 1 = 0.00119015 loss)
I0403 04:23:53.586621 19294 sgd_solver.cpp:106] Iteration 6190, lr = 5e-05
I0403 04:24:00.610915 19294 solver.cpp:228] Iteration 6200, loss = 0.0010282
I0403 04:24:00.611026 19294 solver.cpp:244]     Train net output #0: loss = 0.0010282 (* 1 = 0.0010282 loss)
I0403 04:24:00.851642 19294 sgd_solver.cpp:106] Iteration 6200, lr = 5e-05
I0403 04:24:08.158903 19294 solver.cpp:228] Iteration 6210, loss = 4.85849e-05
I0403 04:24:08.159016 19294 solver.cpp:244]     Train net output #0: loss = 4.85773e-05 (* 1 = 4.85773e-05 loss)
I0403 04:24:08.338801 19294 sgd_solver.cpp:106] Iteration 6210, lr = 5e-05
I0403 04:24:15.397939 19294 solver.cpp:228] Iteration 6220, loss = 0.000313898
I0403 04:24:15.402302 19294 solver.cpp:244]     Train net output #0: loss = 0.000313891 (* 1 = 0.000313891 loss)
I0403 04:24:15.605214 19294 sgd_solver.cpp:106] Iteration 6220, lr = 5e-05
I0403 04:24:22.637694 19294 solver.cpp:228] Iteration 6230, loss = 0.00187469
I0403 04:24:22.637794 19294 solver.cpp:244]     Train net output #0: loss = 0.00187468 (* 1 = 0.00187468 loss)
I0403 04:24:22.812788 19294 sgd_solver.cpp:106] Iteration 6230, lr = 5e-05
I0403 04:24:29.892622 19294 solver.cpp:228] Iteration 6240, loss = 0.00028417
I0403 04:24:29.892722 19294 solver.cpp:244]     Train net output #0: loss = 0.000284162 (* 1 = 0.000284162 loss)
I0403 04:24:30.072880 19294 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 04:24:37.146745 19294 solver.cpp:228] Iteration 6250, loss = 0.000408608
I0403 04:24:37.146857 19294 solver.cpp:244]     Train net output #0: loss = 0.0004086 (* 1 = 0.0004086 loss)
I0403 04:24:37.335785 19294 sgd_solver.cpp:106] Iteration 6250, lr = 5e-05
I0403 04:24:44.353951 19294 solver.cpp:228] Iteration 6260, loss = 0.000248479
I0403 04:24:44.354053 19294 solver.cpp:244]     Train net output #0: loss = 0.000248471 (* 1 = 0.000248471 loss)
I0403 04:24:44.530855 19294 sgd_solver.cpp:106] Iteration 6260, lr = 5e-05
I0403 04:24:51.756729 19294 solver.cpp:228] Iteration 6270, loss = 0.000415324
I0403 04:24:51.757031 19294 solver.cpp:244]     Train net output #0: loss = 0.000415316 (* 1 = 0.000415316 loss)
I0403 04:24:51.964917 19294 sgd_solver.cpp:106] Iteration 6270, lr = 5e-05
I0403 04:24:58.985256 19294 solver.cpp:228] Iteration 6280, loss = 0.000415627
I0403 04:24:58.985357 19294 solver.cpp:244]     Train net output #0: loss = 0.00041562 (* 1 = 0.00041562 loss)
I0403 04:24:59.161979 19294 sgd_solver.cpp:106] Iteration 6280, lr = 5e-05
I0403 04:25:06.179174 19294 solver.cpp:228] Iteration 6290, loss = 0.000194389
I0403 04:25:06.179293 19294 solver.cpp:244]     Train net output #0: loss = 0.000194382 (* 1 = 0.000194382 loss)
I0403 04:25:06.381075 19294 sgd_solver.cpp:106] Iteration 6290, lr = 5e-05
I0403 04:25:07.825273 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6293.caffemodel
I0403 04:25:10.556530 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6293.solverstate
I0403 04:25:12.394029 19294 solver.cpp:337] Iteration 6293, Testing net (#0)
I0403 04:26:25.879781 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986031
I0403 04:26:25.881222 19294 solver.cpp:404]     Test net output #1: loss = 0.049636 (* 1 = 0.049636 loss)
I0403 04:26:31.641093 19294 solver.cpp:228] Iteration 6300, loss = 0.000201427
I0403 04:26:31.641203 19294 solver.cpp:244]     Train net output #0: loss = 0.00020142 (* 1 = 0.00020142 loss)
I0403 04:26:31.823184 19294 sgd_solver.cpp:106] Iteration 6300, lr = 5e-05
I0403 04:26:38.914729 19294 solver.cpp:228] Iteration 6310, loss = 0.000296799
I0403 04:26:38.914837 19294 solver.cpp:244]     Train net output #0: loss = 0.000296793 (* 1 = 0.000296793 loss)
I0403 04:26:39.097579 19294 sgd_solver.cpp:106] Iteration 6310, lr = 5e-05
I0403 04:26:46.270032 19294 solver.cpp:228] Iteration 6320, loss = 0.00203314
I0403 04:26:46.270135 19294 solver.cpp:244]     Train net output #0: loss = 0.00203313 (* 1 = 0.00203313 loss)
I0403 04:26:46.448717 19294 sgd_solver.cpp:106] Iteration 6320, lr = 5e-05
I0403 04:26:53.463959 19294 solver.cpp:228] Iteration 6330, loss = 0.000598219
I0403 04:26:53.464069 19294 solver.cpp:244]     Train net output #0: loss = 0.000598213 (* 1 = 0.000598213 loss)
I0403 04:26:53.664070 19294 sgd_solver.cpp:106] Iteration 6330, lr = 5e-05
I0403 04:27:00.760670 19294 solver.cpp:228] Iteration 6340, loss = 0.00250309
I0403 04:27:00.760931 19294 solver.cpp:244]     Train net output #0: loss = 0.00250308 (* 1 = 0.00250308 loss)
I0403 04:27:00.948876 19294 sgd_solver.cpp:106] Iteration 6340, lr = 5e-05
I0403 04:27:07.947001 19294 solver.cpp:228] Iteration 6350, loss = 0.000156675
I0403 04:27:07.947109 19294 solver.cpp:244]     Train net output #0: loss = 0.000156669 (* 1 = 0.000156669 loss)
I0403 04:27:08.168720 19294 sgd_solver.cpp:106] Iteration 6350, lr = 5e-05
I0403 04:27:15.208408 19294 solver.cpp:228] Iteration 6360, loss = 0.00119333
I0403 04:27:15.208513 19294 solver.cpp:244]     Train net output #0: loss = 0.00119332 (* 1 = 0.00119332 loss)
I0403 04:27:15.371194 19294 sgd_solver.cpp:106] Iteration 6360, lr = 5e-05
I0403 04:27:22.590837 19294 solver.cpp:228] Iteration 6370, loss = 0.002029
I0403 04:27:22.598098 19294 solver.cpp:244]     Train net output #0: loss = 0.002029 (* 1 = 0.002029 loss)
I0403 04:27:22.742619 19294 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 04:27:30.018213 19294 solver.cpp:228] Iteration 6380, loss = 0.00441885
I0403 04:27:30.018324 19294 solver.cpp:244]     Train net output #0: loss = 0.00441884 (* 1 = 0.00441884 loss)
I0403 04:27:30.202258 19294 sgd_solver.cpp:106] Iteration 6380, lr = 5e-05
I0403 04:27:37.218842 19294 solver.cpp:228] Iteration 6390, loss = 0.00018501
I0403 04:27:37.219151 19294 solver.cpp:244]     Train net output #0: loss = 0.000185005 (* 1 = 0.000185005 loss)
I0403 04:27:37.418283 19294 sgd_solver.cpp:106] Iteration 6390, lr = 5e-05
I0403 04:27:44.461195 19294 solver.cpp:228] Iteration 6400, loss = 0.0187597
I0403 04:27:44.461297 19294 solver.cpp:244]     Train net output #0: loss = 0.0187597 (* 1 = 0.0187597 loss)
I0403 04:27:44.638200 19294 sgd_solver.cpp:106] Iteration 6400, lr = 5e-05
I0403 04:27:51.711295 19294 solver.cpp:228] Iteration 6410, loss = 0.00156005
I0403 04:27:51.711405 19294 solver.cpp:244]     Train net output #0: loss = 0.00156004 (* 1 = 0.00156004 loss)
I0403 04:27:51.904305 19294 sgd_solver.cpp:106] Iteration 6410, lr = 5e-05
I0403 04:27:59.001078 19294 solver.cpp:228] Iteration 6420, loss = 0.000121376
I0403 04:27:59.001181 19294 solver.cpp:244]     Train net output #0: loss = 0.000121371 (* 1 = 0.000121371 loss)
I0403 04:27:59.178992 19294 sgd_solver.cpp:106] Iteration 6420, lr = 5e-05
I0403 04:28:06.211895 19294 solver.cpp:228] Iteration 6430, loss = 0.000969906
I0403 04:28:06.211997 19294 solver.cpp:244]     Train net output #0: loss = 0.000969901 (* 1 = 0.000969901 loss)
I0403 04:28:06.391386 19294 sgd_solver.cpp:106] Iteration 6430, lr = 5e-05
I0403 04:28:13.472905 19294 solver.cpp:228] Iteration 6440, loss = 3.6525e-05
I0403 04:28:13.473225 19294 solver.cpp:244]     Train net output #0: loss = 3.65206e-05 (* 1 = 3.65206e-05 loss)
I0403 04:28:13.667290 19294 sgd_solver.cpp:106] Iteration 6440, lr = 5e-05
I0403 04:28:20.736938 19294 solver.cpp:228] Iteration 6450, loss = 3.96743e-05
I0403 04:28:20.737036 19294 solver.cpp:244]     Train net output #0: loss = 3.96713e-05 (* 1 = 3.96713e-05 loss)
I0403 04:28:20.900791 19294 sgd_solver.cpp:106] Iteration 6450, lr = 5e-05
I0403 04:28:28.151785 19294 solver.cpp:228] Iteration 6460, loss = 0.000246766
I0403 04:28:28.151892 19294 solver.cpp:244]     Train net output #0: loss = 0.000246761 (* 1 = 0.000246761 loss)
I0403 04:28:28.344427 19294 sgd_solver.cpp:106] Iteration 6460, lr = 5e-05
I0403 04:28:35.421468 19294 solver.cpp:228] Iteration 6470, loss = 0.000223692
I0403 04:28:35.421579 19294 solver.cpp:244]     Train net output #0: loss = 0.000223688 (* 1 = 0.000223688 loss)
I0403 04:28:35.655010 19294 sgd_solver.cpp:106] Iteration 6470, lr = 5e-05
I0403 04:28:42.761297 19294 solver.cpp:228] Iteration 6480, loss = 0.00220543
I0403 04:28:42.761400 19294 solver.cpp:244]     Train net output #0: loss = 0.00220543 (* 1 = 0.00220543 loss)
I0403 04:28:42.938908 19294 sgd_solver.cpp:106] Iteration 6480, lr = 5e-05
I0403 04:28:50.030230 19294 solver.cpp:228] Iteration 6490, loss = 0.000505418
I0403 04:28:50.030560 19294 solver.cpp:244]     Train net output #0: loss = 0.000505415 (* 1 = 0.000505415 loss)
I0403 04:28:50.202116 19294 sgd_solver.cpp:106] Iteration 6490, lr = 5e-05
I0403 04:28:57.303778 19294 solver.cpp:228] Iteration 6500, loss = 0.00224056
I0403 04:28:57.303891 19294 solver.cpp:244]     Train net output #0: loss = 0.00224055 (* 1 = 0.00224055 loss)
I0403 04:28:57.550565 19294 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 04:29:04.141978 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6510.caffemodel
I0403 04:29:06.879209 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6510.solverstate
I0403 04:29:08.715461 19294 solver.cpp:337] Iteration 6510, Testing net (#0)
I0403 04:30:22.178439 19294 solver.cpp:404]     Test net output #0: accuracy = 0.986032
I0403 04:30:22.178735 19294 solver.cpp:404]     Test net output #1: loss = 0.0494626 (* 1 = 0.0494626 loss)
I0403 04:30:22.680665 19294 solver.cpp:228] Iteration 6510, loss = 0.000424042
I0403 04:30:22.680773 19294 solver.cpp:244]     Train net output #0: loss = 0.00042404 (* 1 = 0.00042404 loss)
I0403 04:30:22.905426 19294 sgd_solver.cpp:106] Iteration 6510, lr = 5e-05
I0403 04:30:29.909257 19294 solver.cpp:228] Iteration 6520, loss = 0.0025798
I0403 04:30:29.909335 19294 solver.cpp:244]     Train net output #0: loss = 0.0025798 (* 1 = 0.0025798 loss)
I0403 04:30:30.089067 19294 sgd_solver.cpp:106] Iteration 6520, lr = 5e-05
I0403 04:30:32.980124 19294 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6525.caffemodel
I0403 04:30:35.703491 19294 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-40-60_finetune/snapshots__iter_6525.solverstate
I0403 04:30:37.540647 19294 solver.cpp:322] Optimization Done.
I0403 04:30:37.628713 19294 caffe.cpp:222] Optimization Done.
