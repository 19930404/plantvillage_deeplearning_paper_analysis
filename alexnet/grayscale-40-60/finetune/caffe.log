I0403 02:30:27.970618 32199 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:27.977413 32199 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:27.977444 32199 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:35.893599 32199 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:35.895261 32199 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:35.896785 32199 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.006695 32199 solver.cpp:48] Initializing solver from parameters: 
test_iter: 323
test_interval: 219
base_lr: 0.005
display: 10
max_iter: 6589
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2196
snapshot: 219
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.033064 32199 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.043988 32199 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.044119 32199 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.045817 32199 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.047000 32199 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.048666 32199 net.cpp:91] Creating Layer data
I0403 02:30:37.048738 32199 net.cpp:399] data -> data
I0403 02:30:37.048816 32199 net.cpp:399] data -> label
I0403 02:30:37.048883 32199 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto
I0403 02:30:37.090299 32204 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/train_db
I0403 02:30:37.108870 32199 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.247458 32199 net.cpp:141] Setting up data
I0403 02:30:37.247576 32199 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.247604 32199 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.247623 32199 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.247663 32199 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.247717 32199 net.cpp:91] Creating Layer conv1
I0403 02:30:37.247745 32199 net.cpp:425] conv1 <- data
I0403 02:30:37.247786 32199 net.cpp:399] conv1 -> conv1
I0403 02:30:37.251385 32199 net.cpp:141] Setting up conv1
I0403 02:30:37.251423 32199 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.251444 32199 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.251503 32199 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.251551 32199 net.cpp:91] Creating Layer relu1
I0403 02:30:37.251574 32199 net.cpp:425] relu1 <- conv1
I0403 02:30:37.251596 32199 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.251639 32199 net.cpp:141] Setting up relu1
I0403 02:30:37.251662 32199 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.251680 32199 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.251698 32199 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.251721 32199 net.cpp:91] Creating Layer norm1
I0403 02:30:37.251787 32199 net.cpp:425] norm1 <- conv1
I0403 02:30:37.251811 32199 net.cpp:399] norm1 -> norm1
I0403 02:30:37.257331 32199 net.cpp:141] Setting up norm1
I0403 02:30:37.257380 32199 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.257400 32199 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.257418 32199 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.257444 32199 net.cpp:91] Creating Layer pool1
I0403 02:30:37.257465 32199 net.cpp:425] pool1 <- norm1
I0403 02:30:37.257488 32199 net.cpp:399] pool1 -> pool1
I0403 02:30:37.257580 32199 net.cpp:141] Setting up pool1
I0403 02:30:37.257611 32199 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.257630 32199 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.257648 32199 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.257676 32199 net.cpp:91] Creating Layer conv2
I0403 02:30:37.257699 32199 net.cpp:425] conv2 <- pool1
I0403 02:30:37.257722 32199 net.cpp:399] conv2 -> conv2
I0403 02:30:37.259619 32205 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.273674 32199 net.cpp:141] Setting up conv2
I0403 02:30:37.273710 32199 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.273731 32199 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.273757 32199 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.273782 32199 net.cpp:91] Creating Layer relu2
I0403 02:30:37.273802 32199 net.cpp:425] relu2 <- conv2
I0403 02:30:37.273824 32199 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.273849 32199 net.cpp:141] Setting up relu2
I0403 02:30:37.273869 32199 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.273887 32199 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.273905 32199 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.273927 32199 net.cpp:91] Creating Layer norm2
I0403 02:30:37.273947 32199 net.cpp:425] norm2 <- conv2
I0403 02:30:37.273967 32199 net.cpp:399] norm2 -> norm2
I0403 02:30:37.274024 32199 net.cpp:141] Setting up norm2
I0403 02:30:37.274050 32199 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.274068 32199 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.274087 32199 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.274113 32199 net.cpp:91] Creating Layer pool2
I0403 02:30:37.274134 32199 net.cpp:425] pool2 <- norm2
I0403 02:30:37.274158 32199 net.cpp:399] pool2 -> pool2
I0403 02:30:37.274210 32199 net.cpp:141] Setting up pool2
I0403 02:30:37.274237 32199 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.274255 32199 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.274273 32199 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.274301 32199 net.cpp:91] Creating Layer conv3
I0403 02:30:37.274322 32199 net.cpp:425] conv3 <- pool2
I0403 02:30:37.274354 32199 net.cpp:399] conv3 -> conv3
I0403 02:30:37.316129 32199 net.cpp:141] Setting up conv3
I0403 02:30:37.316171 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.316191 32199 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.316218 32199 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.316242 32199 net.cpp:91] Creating Layer relu3
I0403 02:30:37.316262 32199 net.cpp:425] relu3 <- conv3
I0403 02:30:37.316285 32199 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.316309 32199 net.cpp:141] Setting up relu3
I0403 02:30:37.316330 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.316355 32199 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.316375 32199 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.316401 32199 net.cpp:91] Creating Layer conv4
I0403 02:30:37.316422 32199 net.cpp:425] conv4 <- conv3
I0403 02:30:37.316447 32199 net.cpp:399] conv4 -> conv4
I0403 02:30:37.347924 32199 net.cpp:141] Setting up conv4
I0403 02:30:37.347965 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.347985 32199 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.348026 32199 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.348052 32199 net.cpp:91] Creating Layer relu4
I0403 02:30:37.348069 32199 net.cpp:425] relu4 <- conv4
I0403 02:30:37.348093 32199 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.348115 32199 net.cpp:141] Setting up relu4
I0403 02:30:37.348137 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.348155 32199 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.348175 32199 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.348201 32199 net.cpp:91] Creating Layer conv5
I0403 02:30:37.348222 32199 net.cpp:425] conv5 <- conv4
I0403 02:30:37.348247 32199 net.cpp:399] conv5 -> conv5
I0403 02:30:37.369352 32199 net.cpp:141] Setting up conv5
I0403 02:30:37.369392 32199 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.369412 32199 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.369439 32199 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.369463 32199 net.cpp:91] Creating Layer relu5
I0403 02:30:37.369484 32199 net.cpp:425] relu5 <- conv5
I0403 02:30:37.369508 32199 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.369532 32199 net.cpp:141] Setting up relu5
I0403 02:30:37.369554 32199 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.369571 32199 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.369590 32199 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.369611 32199 net.cpp:91] Creating Layer pool5
I0403 02:30:37.369632 32199 net.cpp:425] pool5 <- conv5
I0403 02:30:37.369653 32199 net.cpp:399] pool5 -> pool5
I0403 02:30:37.369712 32199 net.cpp:141] Setting up pool5
I0403 02:30:37.369740 32199 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.369758 32199 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.369777 32199 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.369827 32199 net.cpp:91] Creating Layer fc6
I0403 02:30:37.369853 32199 net.cpp:425] fc6 <- pool5
I0403 02:30:37.369879 32199 net.cpp:399] fc6 -> fc6
I0403 02:30:38.893580 32199 net.cpp:141] Setting up fc6
I0403 02:30:38.893664 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.893682 32199 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.893702 32199 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.893726 32199 net.cpp:91] Creating Layer relu6
I0403 02:30:38.893746 32199 net.cpp:425] relu6 <- fc6
I0403 02:30:38.893766 32199 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.893787 32199 net.cpp:141] Setting up relu6
I0403 02:30:38.893803 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.893816 32199 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.893831 32199 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.893882 32199 net.cpp:91] Creating Layer drop6
I0403 02:30:38.893900 32199 net.cpp:425] drop6 <- fc6
I0403 02:30:38.893916 32199 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.893975 32199 net.cpp:141] Setting up drop6
I0403 02:30:38.893996 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.894009 32199 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.894023 32199 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.894042 32199 net.cpp:91] Creating Layer fc7
I0403 02:30:38.894057 32199 net.cpp:425] fc7 <- fc6
I0403 02:30:38.894075 32199 net.cpp:399] fc7 -> fc7
I0403 02:30:39.502823 32199 net.cpp:141] Setting up fc7
I0403 02:30:39.502904 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.502919 32199 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.502940 32199 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.502966 32199 net.cpp:91] Creating Layer relu7
I0403 02:30:39.502985 32199 net.cpp:425] relu7 <- fc7
I0403 02:30:39.503003 32199 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.503024 32199 net.cpp:141] Setting up relu7
I0403 02:30:39.503041 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.503053 32199 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.503067 32199 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.503125 32199 net.cpp:91] Creating Layer drop7
I0403 02:30:39.503154 32199 net.cpp:425] drop7 <- fc7
I0403 02:30:39.503170 32199 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.503207 32199 net.cpp:141] Setting up drop7
I0403 02:30:39.503231 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.503245 32199 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.503258 32199 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.503278 32199 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.503293 32199 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.503314 32199 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.509361 32199 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.509387 32199 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.509402 32199 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.509419 32199 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.509464 32199 net.cpp:91] Creating Layer loss
I0403 02:30:39.509482 32199 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.509497 32199 net.cpp:425] loss <- label
I0403 02:30:39.509521 32199 net.cpp:399] loss -> loss
I0403 02:30:39.509557 32199 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.509681 32199 net.cpp:141] Setting up loss
I0403 02:30:39.509703 32199 net.cpp:148] Top shape: (1)
I0403 02:30:39.509716 32199 net.cpp:151]     with loss weight 1
I0403 02:30:39.509773 32199 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.509788 32199 net.cpp:217] loss needs backward computation.
I0403 02:30:39.509801 32199 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.509815 32199 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.509829 32199 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.509841 32199 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.509855 32199 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.509867 32199 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.509881 32199 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.509893 32199 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.509907 32199 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.509919 32199 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.509932 32199 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.509945 32199 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.509959 32199 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.509973 32199 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.509985 32199 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.509999 32199 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.510012 32199 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.510025 32199 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.510040 32199 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.510052 32199 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.510066 32199 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.510078 32199 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.510093 32199 net.cpp:219] data does not need backward computation.
I0403 02:30:39.510107 32199 net.cpp:261] This network produces output loss
I0403 02:30:39.510143 32199 net.cpp:274] Network initialization done.
I0403 02:30:39.511215 32199 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.511271 32199 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.511890 32199 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.512058 32199 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.512222 32199 net.cpp:91] Creating Layer data
I0403 02:30:39.512246 32199 net.cpp:399] data -> data
I0403 02:30:39.512275 32199 net.cpp:399] data -> label
I0403 02:30:39.512298 32199 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto
I0403 02:30:39.527808 32207 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/test_db
I0403 02:30:39.534864 32199 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.733429 32199 net.cpp:141] Setting up data
I0403 02:30:39.733537 32199 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.733651 32199 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.733772 32199 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.733873 32199 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.733994 32199 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.734132 32199 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.734164 32199 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.734266 32199 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.734477 32199 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.734638 32199 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.735128 32199 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.735507 32199 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.735589 32199 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.735716 32199 net.cpp:91] Creating Layer conv1
I0403 02:30:39.735874 32199 net.cpp:425] conv1 <- data
I0403 02:30:39.735975 32199 net.cpp:399] conv1 -> conv1
I0403 02:30:39.748699 32199 net.cpp:141] Setting up conv1
I0403 02:30:39.773144 32199 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.773270 32199 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.773334 32199 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.773459 32199 net.cpp:91] Creating Layer relu1
I0403 02:30:39.773710 32199 net.cpp:425] relu1 <- conv1
I0403 02:30:39.773907 32199 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.774204 32199 net.cpp:141] Setting up relu1
I0403 02:30:39.774420 32199 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.774521 32199 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.774847 32199 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.774958 32199 net.cpp:91] Creating Layer norm1
I0403 02:30:39.775056 32199 net.cpp:425] norm1 <- conv1
I0403 02:30:39.775135 32199 net.cpp:399] norm1 -> norm1
I0403 02:30:39.775285 32199 net.cpp:141] Setting up norm1
I0403 02:30:39.775391 32199 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.775436 32199 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.775509 32199 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.775593 32199 net.cpp:91] Creating Layer pool1
I0403 02:30:39.775670 32199 net.cpp:425] pool1 <- norm1
I0403 02:30:39.775748 32199 net.cpp:399] pool1 -> pool1
I0403 02:30:39.775951 32199 net.cpp:141] Setting up pool1
I0403 02:30:39.776029 32199 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.776108 32199 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.776265 32199 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.776404 32199 net.cpp:91] Creating Layer conv2
I0403 02:30:39.776497 32199 net.cpp:425] conv2 <- pool1
I0403 02:30:39.776593 32199 net.cpp:399] conv2 -> conv2
I0403 02:30:39.806195 32199 net.cpp:141] Setting up conv2
I0403 02:30:39.874553 32199 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.874617 32199 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.874680 32199 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.874733 32199 net.cpp:91] Creating Layer relu2
I0403 02:30:39.874775 32199 net.cpp:425] relu2 <- conv2
I0403 02:30:39.874824 32199 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.874876 32199 net.cpp:141] Setting up relu2
I0403 02:30:39.874925 32199 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.874969 32199 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.875008 32199 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.875066 32199 net.cpp:91] Creating Layer norm2
I0403 02:30:39.875108 32199 net.cpp:425] norm2 <- conv2
I0403 02:30:39.875155 32199 net.cpp:399] norm2 -> norm2
I0403 02:30:39.875335 32199 net.cpp:141] Setting up norm2
I0403 02:30:39.875406 32199 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.875445 32199 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.875483 32199 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.875751 32199 net.cpp:91] Creating Layer pool2
I0403 02:30:39.875844 32199 net.cpp:425] pool2 <- norm2
I0403 02:30:39.875895 32199 net.cpp:399] pool2 -> pool2
I0403 02:30:39.876067 32199 net.cpp:141] Setting up pool2
I0403 02:30:39.876147 32199 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.876222 32199 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.876305 32199 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.876407 32199 net.cpp:91] Creating Layer conv3
I0403 02:30:39.876505 32199 net.cpp:425] conv3 <- pool2
I0403 02:30:39.876591 32199 net.cpp:399] conv3 -> conv3
I0403 02:30:39.919322 32199 net.cpp:141] Setting up conv3
I0403 02:30:39.919356 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.919414 32199 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.919522 32199 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.919679 32199 net.cpp:91] Creating Layer relu3
I0403 02:30:39.919739 32199 net.cpp:425] relu3 <- conv3
I0403 02:30:39.919780 32199 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.919878 32199 net.cpp:141] Setting up relu3
I0403 02:30:39.919934 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.919965 32199 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.920016 32199 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.920138 32199 net.cpp:91] Creating Layer conv4
I0403 02:30:39.920469 32199 net.cpp:425] conv4 <- conv3
I0403 02:30:39.920521 32199 net.cpp:399] conv4 -> conv4
I0403 02:30:39.949388 32199 net.cpp:141] Setting up conv4
I0403 02:30:39.949429 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.949446 32199 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.949466 32199 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.949488 32199 net.cpp:91] Creating Layer relu4
I0403 02:30:39.949506 32199 net.cpp:425] relu4 <- conv4
I0403 02:30:39.949524 32199 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.949545 32199 net.cpp:141] Setting up relu4
I0403 02:30:39.949563 32199 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.949578 32199 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.949592 32199 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.949616 32199 net.cpp:91] Creating Layer conv5
I0403 02:30:39.949633 32199 net.cpp:425] conv5 <- conv4
I0403 02:30:39.949653 32199 net.cpp:399] conv5 -> conv5
I0403 02:30:39.968399 32199 net.cpp:141] Setting up conv5
I0403 02:30:39.968430 32199 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.968474 32199 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.968500 32199 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.968524 32199 net.cpp:91] Creating Layer relu5
I0403 02:30:39.968543 32199 net.cpp:425] relu5 <- conv5
I0403 02:30:39.968561 32199 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.968581 32199 net.cpp:141] Setting up relu5
I0403 02:30:39.968600 32199 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.968614 32199 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.968628 32199 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.968650 32199 net.cpp:91] Creating Layer pool5
I0403 02:30:39.968667 32199 net.cpp:425] pool5 <- conv5
I0403 02:30:39.968686 32199 net.cpp:399] pool5 -> pool5
I0403 02:30:39.968832 32199 net.cpp:141] Setting up pool5
I0403 02:30:39.968858 32199 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.968873 32199 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.968888 32199 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.968909 32199 net.cpp:91] Creating Layer fc6
I0403 02:30:39.968926 32199 net.cpp:425] fc6 <- pool5
I0403 02:30:39.968948 32199 net.cpp:399] fc6 -> fc6
I0403 02:30:41.394845 32199 net.cpp:141] Setting up fc6
I0403 02:30:41.394934 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.394949 32199 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.394973 32199 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.394999 32199 net.cpp:91] Creating Layer relu6
I0403 02:30:41.395015 32199 net.cpp:425] relu6 <- fc6
I0403 02:30:41.395037 32199 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.395061 32199 net.cpp:141] Setting up relu6
I0403 02:30:41.395076 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.395090 32199 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.395104 32199 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.395123 32199 net.cpp:91] Creating Layer drop6
I0403 02:30:41.395149 32199 net.cpp:425] drop6 <- fc6
I0403 02:30:41.395165 32199 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.395208 32199 net.cpp:141] Setting up drop6
I0403 02:30:41.395231 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.395243 32199 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.395258 32199 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.395279 32199 net.cpp:91] Creating Layer fc7
I0403 02:30:41.395294 32199 net.cpp:425] fc7 <- fc6
I0403 02:30:41.395313 32199 net.cpp:399] fc7 -> fc7
I0403 02:30:42.002950 32199 net.cpp:141] Setting up fc7
I0403 02:30:42.003039 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.003075 32199 net.cpp:156] Memory required for data: 828248800
I0403 02:30:42.003109 32199 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:42.003185 32199 net.cpp:91] Creating Layer relu7
I0403 02:30:42.003237 32199 net.cpp:425] relu7 <- fc7
I0403 02:30:42.003262 32199 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:42.003285 32199 net.cpp:141] Setting up relu7
I0403 02:30:42.003303 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.003316 32199 net.cpp:156] Memory required for data: 829887200
I0403 02:30:42.003330 32199 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:42.003355 32199 net.cpp:91] Creating Layer drop7
I0403 02:30:42.003372 32199 net.cpp:425] drop7 <- fc7
I0403 02:30:42.003389 32199 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:42.003427 32199 net.cpp:141] Setting up drop7
I0403 02:30:42.003448 32199 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.003463 32199 net.cpp:156] Memory required for data: 831525600
I0403 02:30:42.003482 32199 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:42.003516 32199 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:42.003538 32199 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:42.003571 32199 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:42.009855 32199 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:42.009883 32199 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.009928 32199 net.cpp:156] Memory required for data: 831540800
I0403 02:30:42.009946 32199 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.009968 32199 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.010004 32199 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:42.010025 32199 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.010049 32199 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.010098 32199 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.010123 32199 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.010140 32199 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.010156 32199 net.cpp:156] Memory required for data: 831571200
I0403 02:30:42.010170 32199 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.010187 32199 net.cpp:91] Creating Layer loss
I0403 02:30:42.010202 32199 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.010217 32199 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:42.010233 32199 net.cpp:399] loss -> loss
I0403 02:30:42.010256 32199 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.010347 32199 net.cpp:141] Setting up loss
I0403 02:30:42.010371 32199 net.cpp:148] Top shape: (1)
I0403 02:30:42.010386 32199 net.cpp:151]     with loss weight 1
I0403 02:30:42.010408 32199 net.cpp:156] Memory required for data: 831571204
I0403 02:30:42.010426 32199 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:42.010449 32199 net.cpp:91] Creating Layer accuracy
I0403 02:30:42.010467 32199 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.010481 32199 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:42.010499 32199 net.cpp:399] accuracy -> accuracy
I0403 02:30:42.010525 32199 net.cpp:141] Setting up accuracy
I0403 02:30:42.010543 32199 net.cpp:148] Top shape: (1)
I0403 02:30:42.010557 32199 net.cpp:156] Memory required for data: 831571208
I0403 02:30:42.010571 32199 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:42.010586 32199 net.cpp:217] loss needs backward computation.
I0403 02:30:42.010601 32199 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:42.010614 32199 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:42.010627 32199 net.cpp:217] drop7 needs backward computation.
I0403 02:30:42.010640 32199 net.cpp:217] relu7 needs backward computation.
I0403 02:30:42.010653 32199 net.cpp:217] fc7 needs backward computation.
I0403 02:30:42.010669 32199 net.cpp:217] drop6 needs backward computation.
I0403 02:30:42.010689 32199 net.cpp:217] relu6 needs backward computation.
I0403 02:30:42.010702 32199 net.cpp:217] fc6 needs backward computation.
I0403 02:30:42.010715 32199 net.cpp:217] pool5 needs backward computation.
I0403 02:30:42.010730 32199 net.cpp:217] relu5 needs backward computation.
I0403 02:30:42.010742 32199 net.cpp:217] conv5 needs backward computation.
I0403 02:30:42.010756 32199 net.cpp:217] relu4 needs backward computation.
I0403 02:30:42.010769 32199 net.cpp:217] conv4 needs backward computation.
I0403 02:30:42.010783 32199 net.cpp:217] relu3 needs backward computation.
I0403 02:30:42.010797 32199 net.cpp:217] conv3 needs backward computation.
I0403 02:30:42.010809 32199 net.cpp:217] pool2 needs backward computation.
I0403 02:30:42.010823 32199 net.cpp:217] norm2 needs backward computation.
I0403 02:30:42.010838 32199 net.cpp:217] relu2 needs backward computation.
I0403 02:30:42.010850 32199 net.cpp:217] conv2 needs backward computation.
I0403 02:30:42.010864 32199 net.cpp:217] pool1 needs backward computation.
I0403 02:30:42.010879 32199 net.cpp:217] norm1 needs backward computation.
I0403 02:30:42.010891 32199 net.cpp:217] relu1 needs backward computation.
I0403 02:30:42.010905 32199 net.cpp:217] conv1 needs backward computation.
I0403 02:30:42.010932 32199 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:42.010948 32199 net.cpp:219] data does not need backward computation.
I0403 02:30:42.010962 32199 net.cpp:261] This network produces output accuracy
I0403 02:30:42.010975 32199 net.cpp:261] This network produces output loss
I0403 02:30:42.011004 32199 net.cpp:274] Network initialization done.
I0403 02:30:42.011104 32199 solver.cpp:60] Solver scaffolding done.
I0403 02:30:42.011551 32199 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.449301 32199 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.449437 32199 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.449482 32199 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.449558 32199 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.888118 32199 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.930363 32199 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.058367 32199 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.058472 32199 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:45.058501 32199 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:45.058548 32199 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.529036 32199 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.570582 32199 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.597923 32199 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.920292 32199 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.502866 32199 parallel.cpp:425] Starting Optimization
I0403 02:30:48.503006 32199 solver.cpp:279] Solving 
I0403 02:30:48.503029 32199 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.503218 32199 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:32:02.358754 32199 solver.cpp:404]     Test net output #0: accuracy = 0.0278019
I0403 02:32:02.366950 32199 solver.cpp:404]     Test net output #1: loss = 3.87587 (* 1 = 3.87587 loss)
I0403 02:32:02.942665 32199 solver.cpp:228] Iteration 0, loss = 4.32593
I0403 02:32:02.949357 32199 solver.cpp:244]     Train net output #0: loss = 4.32593 (* 1 = 4.32593 loss)
I0403 02:32:03.110924 32199 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:10.369884 32199 solver.cpp:228] Iteration 10, loss = 1.84651
I0403 02:32:10.375494 32199 solver.cpp:244]     Train net output #0: loss = 1.84651 (* 1 = 1.84651 loss)
I0403 02:32:10.542099 32199 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 02:32:17.703331 32199 solver.cpp:228] Iteration 20, loss = 1.91088
I0403 02:32:17.710175 32199 solver.cpp:244]     Train net output #0: loss = 1.91088 (* 1 = 1.91088 loss)
I0403 02:32:17.890570 32199 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 02:32:25.236783 32199 solver.cpp:228] Iteration 30, loss = 1.20175
I0403 02:32:25.243916 32199 solver.cpp:244]     Train net output #0: loss = 1.20175 (* 1 = 1.20175 loss)
I0403 02:32:25.411423 32199 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 02:32:32.648360 32199 solver.cpp:228] Iteration 40, loss = 0.89625
I0403 02:32:32.667840 32199 solver.cpp:244]     Train net output #0: loss = 0.89625 (* 1 = 0.89625 loss)
I0403 02:32:32.824672 32199 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 02:32:39.906245 32199 solver.cpp:228] Iteration 50, loss = 0.836914
I0403 02:32:39.912341 32199 solver.cpp:244]     Train net output #0: loss = 0.836914 (* 1 = 0.836914 loss)
I0403 02:32:40.083597 32199 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 02:32:47.177613 32199 solver.cpp:228] Iteration 60, loss = 0.912665
I0403 02:32:47.183511 32199 solver.cpp:244]     Train net output #0: loss = 0.912665 (* 1 = 0.912665 loss)
I0403 02:32:47.382464 32199 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 02:32:54.394213 32199 solver.cpp:228] Iteration 70, loss = 0.620608
I0403 02:32:54.400084 32199 solver.cpp:244]     Train net output #0: loss = 0.620608 (* 1 = 0.620608 loss)
I0403 02:32:54.570665 32199 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 02:33:01.631186 32199 solver.cpp:228] Iteration 80, loss = 0.546622
I0403 02:33:01.637871 32199 solver.cpp:244]     Train net output #0: loss = 0.546622 (* 1 = 0.546622 loss)
I0403 02:33:01.837972 32199 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:33:09.032179 32199 solver.cpp:228] Iteration 90, loss = 0.637718
I0403 02:33:09.039381 32199 solver.cpp:244]     Train net output #0: loss = 0.637718 (* 1 = 0.637718 loss)
I0403 02:33:09.210916 32199 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 02:33:16.313938 32199 solver.cpp:228] Iteration 100, loss = 0.684424
I0403 02:33:16.320163 32199 solver.cpp:244]     Train net output #0: loss = 0.684424 (* 1 = 0.684424 loss)
I0403 02:33:16.497537 32199 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 02:33:23.617928 32199 solver.cpp:228] Iteration 110, loss = 0.609511
I0403 02:33:23.624055 32199 solver.cpp:244]     Train net output #0: loss = 0.609511 (* 1 = 0.609511 loss)
I0403 02:33:23.801535 32199 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 02:33:31.014042 32199 solver.cpp:228] Iteration 120, loss = 0.433454
I0403 02:33:31.014135 32199 solver.cpp:244]     Train net output #0: loss = 0.433454 (* 1 = 0.433454 loss)
I0403 02:33:31.181923 32199 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 02:33:38.432956 32199 solver.cpp:228] Iteration 130, loss = 0.693925
I0403 02:33:38.438644 32199 solver.cpp:244]     Train net output #0: loss = 0.693925 (* 1 = 0.693925 loss)
I0403 02:33:38.582186 32199 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:33:45.794580 32199 solver.cpp:228] Iteration 140, loss = 0.510013
I0403 02:33:45.802119 32199 solver.cpp:244]     Train net output #0: loss = 0.510013 (* 1 = 0.510013 loss)
I0403 02:33:45.970919 32199 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 02:33:53.060597 32199 solver.cpp:228] Iteration 150, loss = 0.426565
I0403 02:33:53.067427 32199 solver.cpp:244]     Train net output #0: loss = 0.426565 (* 1 = 0.426565 loss)
I0403 02:33:53.238633 32199 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 02:34:00.437394 32199 solver.cpp:228] Iteration 160, loss = 0.519927
I0403 02:34:00.443815 32199 solver.cpp:244]     Train net output #0: loss = 0.519927 (* 1 = 0.519927 loss)
I0403 02:34:00.631630 32199 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:34:07.796670 32199 solver.cpp:228] Iteration 170, loss = 0.287348
I0403 02:34:07.803481 32199 solver.cpp:244]     Train net output #0: loss = 0.287348 (* 1 = 0.287348 loss)
I0403 02:34:07.991966 32199 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 02:34:15.291297 32199 solver.cpp:228] Iteration 180, loss = 0.401352
I0403 02:34:15.297765 32199 solver.cpp:244]     Train net output #0: loss = 0.401352 (* 1 = 0.401352 loss)
I0403 02:34:15.450974 32199 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 02:34:22.604354 32199 solver.cpp:228] Iteration 190, loss = 0.43457
I0403 02:34:22.652819 32199 solver.cpp:244]     Train net output #0: loss = 0.43457 (* 1 = 0.43457 loss)
I0403 02:34:22.797317 32199 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 02:34:29.999909 32199 solver.cpp:228] Iteration 200, loss = 0.427215
I0403 02:34:30.006135 32199 solver.cpp:244]     Train net output #0: loss = 0.427215 (* 1 = 0.427215 loss)
I0403 02:34:30.204740 32199 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 02:34:37.290482 32199 solver.cpp:228] Iteration 210, loss = 0.370387
I0403 02:34:37.296922 32199 solver.cpp:244]     Train net output #0: loss = 0.370387 (* 1 = 0.370387 loss)
I0403 02:34:37.510932 32199 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:34:43.478430 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_219.caffemodel
I0403 02:34:46.353775 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_219.solverstate
I0403 02:34:48.276758 32199 solver.cpp:337] Iteration 219, Testing net (#0)
I0403 02:36:02.067265 32199 solver.cpp:404]     Test net output #0: accuracy = 0.888081
I0403 02:36:02.074368 32199 solver.cpp:404]     Test net output #1: loss = 0.345902 (* 1 = 0.345902 loss)
I0403 02:36:03.336048 32199 solver.cpp:228] Iteration 220, loss = 0.24298
I0403 02:36:03.342180 32199 solver.cpp:244]     Train net output #0: loss = 0.24298 (* 1 = 0.24298 loss)
I0403 02:36:03.522866 32199 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 02:36:10.647009 32199 solver.cpp:228] Iteration 230, loss = 0.324444
I0403 02:36:10.652489 32199 solver.cpp:244]     Train net output #0: loss = 0.324444 (* 1 = 0.324444 loss)
I0403 02:36:10.876817 32199 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 02:36:18.051257 32199 solver.cpp:228] Iteration 240, loss = 0.521449
I0403 02:36:18.057469 32199 solver.cpp:244]     Train net output #0: loss = 0.521449 (* 1 = 0.521449 loss)
I0403 02:36:18.219732 32199 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:36:25.321302 32199 solver.cpp:228] Iteration 250, loss = 0.506252
I0403 02:36:25.327592 32199 solver.cpp:244]     Train net output #0: loss = 0.506252 (* 1 = 0.506252 loss)
I0403 02:36:25.491830 32199 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 02:36:32.628077 32199 solver.cpp:228] Iteration 260, loss = 0.395949
I0403 02:36:32.634130 32199 solver.cpp:244]     Train net output #0: loss = 0.395949 (* 1 = 0.395949 loss)
I0403 02:36:32.838927 32199 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:36:40.170598 32199 solver.cpp:228] Iteration 270, loss = 0.255606
I0403 02:36:40.176518 32199 solver.cpp:244]     Train net output #0: loss = 0.255606 (* 1 = 0.255606 loss)
I0403 02:36:40.358137 32199 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 02:36:47.561584 32199 solver.cpp:228] Iteration 280, loss = 0.33949
I0403 02:36:47.567435 32199 solver.cpp:244]     Train net output #0: loss = 0.33949 (* 1 = 0.33949 loss)
I0403 02:36:47.764274 32199 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 02:36:54.916270 32199 solver.cpp:228] Iteration 290, loss = 0.317525
I0403 02:36:54.923279 32199 solver.cpp:244]     Train net output #0: loss = 0.317525 (* 1 = 0.317525 loss)
I0403 02:36:55.102581 32199 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 02:37:02.202267 32199 solver.cpp:228] Iteration 300, loss = 0.241651
I0403 02:37:02.208837 32199 solver.cpp:244]     Train net output #0: loss = 0.241651 (* 1 = 0.241651 loss)
I0403 02:37:02.387207 32199 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 02:37:09.554275 32199 solver.cpp:228] Iteration 310, loss = 0.401141
I0403 02:37:09.561131 32199 solver.cpp:244]     Train net output #0: loss = 0.401141 (* 1 = 0.401141 loss)
I0403 02:37:09.774098 32199 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 02:37:17.020413 32199 solver.cpp:228] Iteration 320, loss = 0.266539
I0403 02:37:17.027184 32199 solver.cpp:244]     Train net output #0: loss = 0.266539 (* 1 = 0.266539 loss)
I0403 02:37:17.178163 32199 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:37:24.357887 32199 solver.cpp:228] Iteration 330, loss = 0.204259
I0403 02:37:24.364616 32199 solver.cpp:244]     Train net output #0: loss = 0.204259 (* 1 = 0.204259 loss)
I0403 02:37:24.581526 32199 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 02:37:31.714282 32199 solver.cpp:228] Iteration 340, loss = 0.267697
I0403 02:37:31.720255 32199 solver.cpp:244]     Train net output #0: loss = 0.267697 (* 1 = 0.267697 loss)
I0403 02:37:31.881602 32199 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 02:37:39.339776 32199 solver.cpp:228] Iteration 350, loss = 0.292076
I0403 02:37:39.346210 32199 solver.cpp:244]     Train net output #0: loss = 0.292076 (* 1 = 0.292076 loss)
I0403 02:37:39.531950 32199 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 02:37:46.766784 32199 solver.cpp:228] Iteration 360, loss = 0.43932
I0403 02:37:46.773396 32199 solver.cpp:244]     Train net output #0: loss = 0.43932 (* 1 = 0.43932 loss)
I0403 02:37:46.918205 32199 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 02:37:54.317894 32199 solver.cpp:228] Iteration 370, loss = 0.228264
I0403 02:37:54.317983 32199 solver.cpp:244]     Train net output #0: loss = 0.228264 (* 1 = 0.228264 loss)
I0403 02:37:54.496454 32199 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 02:38:01.655123 32199 solver.cpp:228] Iteration 380, loss = 0.168887
I0403 02:38:01.655226 32199 solver.cpp:244]     Train net output #0: loss = 0.168887 (* 1 = 0.168887 loss)
I0403 02:38:01.838539 32199 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 02:38:08.971952 32199 solver.cpp:228] Iteration 390, loss = 0.181411
I0403 02:38:08.977988 32199 solver.cpp:244]     Train net output #0: loss = 0.181411 (* 1 = 0.181411 loss)
I0403 02:38:09.109740 32199 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:38:16.260767 32199 solver.cpp:228] Iteration 400, loss = 0.231301
I0403 02:38:16.267933 32199 solver.cpp:244]     Train net output #0: loss = 0.231301 (* 1 = 0.231301 loss)
I0403 02:38:16.436455 32199 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:38:23.650657 32199 solver.cpp:228] Iteration 410, loss = 0.417454
I0403 02:38:23.657196 32199 solver.cpp:244]     Train net output #0: loss = 0.417454 (* 1 = 0.417454 loss)
I0403 02:38:23.861546 32199 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 02:38:31.046439 32199 solver.cpp:228] Iteration 420, loss = 0.155895
I0403 02:38:31.053277 32199 solver.cpp:244]     Train net output #0: loss = 0.155895 (* 1 = 0.155895 loss)
I0403 02:38:31.244832 32199 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:38:38.494259 32199 solver.cpp:228] Iteration 430, loss = 0.179341
I0403 02:38:38.494349 32199 solver.cpp:244]     Train net output #0: loss = 0.179341 (* 1 = 0.179341 loss)
I0403 02:38:38.632411 32199 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 02:38:43.817118 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_438.caffemodel
I0403 02:38:46.600128 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_438.solverstate
I0403 02:38:48.409466 32199 solver.cpp:337] Iteration 438, Testing net (#0)
I0403 02:40:02.193150 32199 solver.cpp:404]     Test net output #0: accuracy = 0.90873
I0403 02:40:02.196725 32199 solver.cpp:404]     Test net output #1: loss = 0.272564 (* 1 = 0.272564 loss)
I0403 02:40:04.234738 32199 solver.cpp:228] Iteration 440, loss = 0.164411
I0403 02:40:04.234843 32199 solver.cpp:244]     Train net output #0: loss = 0.164411 (* 1 = 0.164411 loss)
I0403 02:40:04.453958 32199 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 02:40:11.733855 32199 solver.cpp:228] Iteration 450, loss = 0.238824
I0403 02:40:11.733947 32199 solver.cpp:244]     Train net output #0: loss = 0.238824 (* 1 = 0.238824 loss)
I0403 02:40:11.916905 32199 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 02:40:19.018507 32199 solver.cpp:228] Iteration 460, loss = 0.354398
I0403 02:40:19.018610 32199 solver.cpp:244]     Train net output #0: loss = 0.354398 (* 1 = 0.354398 loss)
I0403 02:40:19.228266 32199 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 02:40:26.456668 32199 solver.cpp:228] Iteration 470, loss = 0.430381
I0403 02:40:26.456758 32199 solver.cpp:244]     Train net output #0: loss = 0.430381 (* 1 = 0.430381 loss)
I0403 02:40:26.583598 32199 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 02:40:33.796950 32199 solver.cpp:228] Iteration 480, loss = 0.294375
I0403 02:40:33.803606 32199 solver.cpp:244]     Train net output #0: loss = 0.294375 (* 1 = 0.294375 loss)
I0403 02:40:33.967756 32199 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:40:41.142370 32199 solver.cpp:228] Iteration 490, loss = 0.185022
I0403 02:40:41.149127 32199 solver.cpp:244]     Train net output #0: loss = 0.185022 (* 1 = 0.185022 loss)
I0403 02:40:41.307209 32199 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 02:40:48.515054 32199 solver.cpp:228] Iteration 500, loss = 0.191787
I0403 02:40:48.521926 32199 solver.cpp:244]     Train net output #0: loss = 0.191787 (* 1 = 0.191787 loss)
I0403 02:40:48.675196 32199 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 02:40:55.877327 32199 solver.cpp:228] Iteration 510, loss = 0.188051
I0403 02:40:55.884479 32199 solver.cpp:244]     Train net output #0: loss = 0.188051 (* 1 = 0.188051 loss)
I0403 02:40:56.030735 32199 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 02:41:03.409615 32199 solver.cpp:228] Iteration 520, loss = 0.24559
I0403 02:41:03.416666 32199 solver.cpp:244]     Train net output #0: loss = 0.24559 (* 1 = 0.24559 loss)
I0403 02:41:03.587918 32199 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:41:10.736758 32199 solver.cpp:228] Iteration 530, loss = 0.214854
I0403 02:41:10.743481 32199 solver.cpp:244]     Train net output #0: loss = 0.214854 (* 1 = 0.214854 loss)
I0403 02:41:10.889827 32199 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 02:41:18.090368 32199 solver.cpp:228] Iteration 540, loss = 0.271883
I0403 02:41:18.096618 32199 solver.cpp:244]     Train net output #0: loss = 0.271883 (* 1 = 0.271883 loss)
I0403 02:41:18.277845 32199 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 02:41:25.517983 32199 solver.cpp:228] Iteration 550, loss = 0.240527
I0403 02:41:25.523996 32199 solver.cpp:244]     Train net output #0: loss = 0.240527 (* 1 = 0.240527 loss)
I0403 02:41:25.682288 32199 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 02:41:32.900881 32199 solver.cpp:228] Iteration 560, loss = 0.333507
I0403 02:41:32.907742 32199 solver.cpp:244]     Train net output #0: loss = 0.333507 (* 1 = 0.333507 loss)
I0403 02:41:33.078814 32199 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:41:40.190850 32199 solver.cpp:228] Iteration 570, loss = 0.252836
I0403 02:41:40.197804 32199 solver.cpp:244]     Train net output #0: loss = 0.252836 (* 1 = 0.252836 loss)
I0403 02:41:40.368589 32199 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 02:41:47.461719 32199 solver.cpp:228] Iteration 580, loss = 0.240379
I0403 02:41:47.467787 32199 solver.cpp:244]     Train net output #0: loss = 0.240379 (* 1 = 0.240379 loss)
I0403 02:41:47.627281 32199 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 02:41:54.785554 32199 solver.cpp:228] Iteration 590, loss = 0.271702
I0403 02:41:54.792290 32199 solver.cpp:244]     Train net output #0: loss = 0.271702 (* 1 = 0.271702 loss)
I0403 02:41:54.964915 32199 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 02:42:02.147701 32199 solver.cpp:228] Iteration 600, loss = 0.170075
I0403 02:42:02.154839 32199 solver.cpp:244]     Train net output #0: loss = 0.170075 (* 1 = 0.170075 loss)
I0403 02:42:02.311395 32199 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 02:42:09.454640 32199 solver.cpp:228] Iteration 610, loss = 0.231392
I0403 02:42:09.462036 32199 solver.cpp:244]     Train net output #0: loss = 0.231392 (* 1 = 0.231392 loss)
I0403 02:42:09.622165 32199 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 02:42:16.711616 32199 solver.cpp:228] Iteration 620, loss = 0.137287
I0403 02:42:16.718945 32199 solver.cpp:244]     Train net output #0: loss = 0.137287 (* 1 = 0.137287 loss)
I0403 02:42:16.897614 32199 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 02:42:23.956135 32199 solver.cpp:228] Iteration 630, loss = 0.238742
I0403 02:42:23.968638 32199 solver.cpp:244]     Train net output #0: loss = 0.238742 (* 1 = 0.238742 loss)
I0403 02:42:24.164902 32199 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:42:31.392952 32199 solver.cpp:228] Iteration 640, loss = 0.123065
I0403 02:42:31.399444 32199 solver.cpp:244]     Train net output #0: loss = 0.123066 (* 1 = 0.123066 loss)
I0403 02:42:31.573825 32199 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:42:38.848203 32199 solver.cpp:228] Iteration 650, loss = 0.143129
I0403 02:42:38.854578 32199 solver.cpp:244]     Train net output #0: loss = 0.14313 (* 1 = 0.14313 loss)
I0403 02:42:38.987434 32199 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:42:43.530547 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_657.caffemodel
I0403 02:42:46.314852 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_657.solverstate
I0403 02:42:48.246116 32199 solver.cpp:337] Iteration 657, Testing net (#0)
I0403 02:44:02.058593 32199 solver.cpp:404]     Test net output #0: accuracy = 0.917678
I0403 02:44:02.064894 32199 solver.cpp:404]     Test net output #1: loss = 0.261321 (* 1 = 0.261321 loss)
I0403 02:44:04.878098 32199 solver.cpp:228] Iteration 660, loss = 0.178873
I0403 02:44:04.883550 32199 solver.cpp:244]     Train net output #0: loss = 0.178873 (* 1 = 0.178873 loss)
I0403 02:44:05.081313 32199 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 02:44:12.221837 32199 solver.cpp:228] Iteration 670, loss = 0.17888
I0403 02:44:12.227820 32199 solver.cpp:244]     Train net output #0: loss = 0.17888 (* 1 = 0.17888 loss)
I0403 02:44:12.438426 32199 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 02:44:19.583015 32199 solver.cpp:228] Iteration 680, loss = 0.225888
I0403 02:44:19.590126 32199 solver.cpp:244]     Train net output #0: loss = 0.225888 (* 1 = 0.225888 loss)
I0403 02:44:19.759783 32199 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 02:44:26.830965 32199 solver.cpp:228] Iteration 690, loss = 0.212427
I0403 02:44:26.836699 32199 solver.cpp:244]     Train net output #0: loss = 0.212427 (* 1 = 0.212427 loss)
I0403 02:44:27.034497 32199 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 02:44:34.306944 32199 solver.cpp:228] Iteration 700, loss = 0.137595
I0403 02:44:34.314056 32199 solver.cpp:244]     Train net output #0: loss = 0.137595 (* 1 = 0.137595 loss)
I0403 02:44:34.441789 32199 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 02:44:41.756600 32199 solver.cpp:228] Iteration 710, loss = 0.0855822
I0403 02:44:41.763945 32199 solver.cpp:244]     Train net output #0: loss = 0.0855822 (* 1 = 0.0855822 loss)
I0403 02:44:41.921996 32199 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 02:44:49.081074 32199 solver.cpp:228] Iteration 720, loss = 0.19341
I0403 02:44:49.087767 32199 solver.cpp:244]     Train net output #0: loss = 0.19341 (* 1 = 0.19341 loss)
I0403 02:44:49.264518 32199 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:44:56.392535 32199 solver.cpp:228] Iteration 730, loss = 0.0670156
I0403 02:44:56.398427 32199 solver.cpp:244]     Train net output #0: loss = 0.0670156 (* 1 = 0.0670156 loss)
I0403 02:44:56.554019 32199 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 02:45:03.692248 32199 solver.cpp:228] Iteration 740, loss = 0.23456
I0403 02:45:03.698300 32199 solver.cpp:244]     Train net output #0: loss = 0.23456 (* 1 = 0.23456 loss)
I0403 02:45:03.860954 32199 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 02:45:11.061328 32199 solver.cpp:228] Iteration 750, loss = 0.207489
I0403 02:45:11.067739 32199 solver.cpp:244]     Train net output #0: loss = 0.207489 (* 1 = 0.207489 loss)
I0403 02:45:11.228898 32199 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 02:45:18.364042 32199 solver.cpp:228] Iteration 760, loss = 0.272592
I0403 02:45:18.370496 32199 solver.cpp:244]     Train net output #0: loss = 0.272592 (* 1 = 0.272592 loss)
I0403 02:45:18.561872 32199 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 02:45:25.935037 32199 solver.cpp:228] Iteration 770, loss = 0.259028
I0403 02:45:25.941861 32199 solver.cpp:244]     Train net output #0: loss = 0.259028 (* 1 = 0.259028 loss)
I0403 02:45:26.118770 32199 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 02:45:33.324110 32199 solver.cpp:228] Iteration 780, loss = 0.303151
I0403 02:45:33.330942 32199 solver.cpp:244]     Train net output #0: loss = 0.303151 (* 1 = 0.303151 loss)
I0403 02:45:33.462554 32199 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:45:41.159890 32199 solver.cpp:228] Iteration 790, loss = 0.130249
I0403 02:45:41.166229 32199 solver.cpp:244]     Train net output #0: loss = 0.130249 (* 1 = 0.130249 loss)
I0403 02:45:41.343363 32199 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 02:45:48.611245 32199 solver.cpp:228] Iteration 800, loss = 0.232146
I0403 02:45:48.617287 32199 solver.cpp:244]     Train net output #0: loss = 0.232146 (* 1 = 0.232146 loss)
I0403 02:45:48.794850 32199 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:45:56.114585 32199 solver.cpp:228] Iteration 810, loss = 0.154724
I0403 02:45:56.121019 32199 solver.cpp:244]     Train net output #0: loss = 0.154724 (* 1 = 0.154724 loss)
I0403 02:45:56.304522 32199 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 02:46:03.527318 32199 solver.cpp:228] Iteration 820, loss = 0.0578326
I0403 02:46:03.532946 32199 solver.cpp:244]     Train net output #0: loss = 0.0578326 (* 1 = 0.0578326 loss)
I0403 02:46:03.672585 32199 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 02:46:11.001835 32199 solver.cpp:228] Iteration 830, loss = 0.133289
I0403 02:46:11.007905 32199 solver.cpp:244]     Train net output #0: loss = 0.133289 (* 1 = 0.133289 loss)
I0403 02:46:11.178581 32199 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 02:46:18.390231 32199 solver.cpp:228] Iteration 840, loss = 0.0827945
I0403 02:46:18.396441 32199 solver.cpp:244]     Train net output #0: loss = 0.0827945 (* 1 = 0.0827945 loss)
I0403 02:46:18.568130 32199 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:46:25.658133 32199 solver.cpp:228] Iteration 850, loss = 0.360965
I0403 02:46:25.665043 32199 solver.cpp:244]     Train net output #0: loss = 0.360965 (* 1 = 0.360965 loss)
I0403 02:46:25.856696 32199 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 02:46:33.147882 32199 solver.cpp:228] Iteration 860, loss = 0.0654322
I0403 02:46:33.154093 32199 solver.cpp:244]     Train net output #0: loss = 0.0654322 (* 1 = 0.0654322 loss)
I0403 02:46:33.256992 32199 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 02:46:40.575811 32199 solver.cpp:228] Iteration 870, loss = 0.131957
I0403 02:46:40.582003 32199 solver.cpp:244]     Train net output #0: loss = 0.131957 (* 1 = 0.131957 loss)
I0403 02:46:40.751771 32199 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 02:46:44.439877 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_876.caffemodel
I0403 02:46:47.079996 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_876.solverstate
I0403 02:46:48.895797 32199 solver.cpp:337] Iteration 876, Testing net (#0)
I0403 02:48:02.676950 32199 solver.cpp:404]     Test net output #0: accuracy = 0.933901
I0403 02:48:02.684684 32199 solver.cpp:404]     Test net output #1: loss = 0.209696 (* 1 = 0.209696 loss)
I0403 02:48:06.140647 32199 solver.cpp:228] Iteration 880, loss = 0.20707
I0403 02:48:06.146772 32199 solver.cpp:244]     Train net output #0: loss = 0.20707 (* 1 = 0.20707 loss)
I0403 02:48:06.314963 32199 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:48:13.528364 32199 solver.cpp:228] Iteration 890, loss = 0.175092
I0403 02:48:13.533927 32199 solver.cpp:244]     Train net output #0: loss = 0.175092 (* 1 = 0.175092 loss)
I0403 02:48:13.707947 32199 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 02:48:20.790916 32199 solver.cpp:228] Iteration 900, loss = 0.0531772
I0403 02:48:20.797243 32199 solver.cpp:244]     Train net output #0: loss = 0.0531773 (* 1 = 0.0531773 loss)
I0403 02:48:20.961809 32199 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 02:48:28.061331 32199 solver.cpp:228] Iteration 910, loss = 0.159796
I0403 02:48:28.066540 32199 solver.cpp:244]     Train net output #0: loss = 0.159796 (* 1 = 0.159796 loss)
I0403 02:48:28.231142 32199 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:48:35.357710 32199 solver.cpp:228] Iteration 920, loss = 0.0904238
I0403 02:48:35.364686 32199 solver.cpp:244]     Train net output #0: loss = 0.0904239 (* 1 = 0.0904239 loss)
I0403 02:48:35.512835 32199 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 02:48:42.889233 32199 solver.cpp:228] Iteration 930, loss = 0.109124
I0403 02:48:42.895200 32199 solver.cpp:244]     Train net output #0: loss = 0.109124 (* 1 = 0.109124 loss)
I0403 02:48:43.065614 32199 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 02:48:50.290738 32199 solver.cpp:228] Iteration 940, loss = 0.114843
I0403 02:48:50.297135 32199 solver.cpp:244]     Train net output #0: loss = 0.114843 (* 1 = 0.114843 loss)
I0403 02:48:50.468053 32199 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 02:48:57.620115 32199 solver.cpp:228] Iteration 950, loss = 0.111157
I0403 02:48:57.625612 32199 solver.cpp:244]     Train net output #0: loss = 0.111157 (* 1 = 0.111157 loss)
I0403 02:48:57.787253 32199 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 02:49:05.114852 32199 solver.cpp:228] Iteration 960, loss = 0.137189
I0403 02:49:05.120914 32199 solver.cpp:244]     Train net output #0: loss = 0.137189 (* 1 = 0.137189 loss)
I0403 02:49:05.289187 32199 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:49:12.344461 32199 solver.cpp:228] Iteration 970, loss = 0.119709
I0403 02:49:12.350061 32199 solver.cpp:244]     Train net output #0: loss = 0.11971 (* 1 = 0.11971 loss)
I0403 02:49:12.531858 32199 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 02:49:19.662822 32199 solver.cpp:228] Iteration 980, loss = 0.118027
I0403 02:49:19.669395 32199 solver.cpp:244]     Train net output #0: loss = 0.118027 (* 1 = 0.118027 loss)
I0403 02:49:19.835242 32199 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 02:49:27.047269 32199 solver.cpp:228] Iteration 990, loss = 0.128623
I0403 02:49:27.052606 32199 solver.cpp:244]     Train net output #0: loss = 0.128623 (* 1 = 0.128623 loss)
I0403 02:49:27.203544 32199 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 02:49:34.545975 32199 solver.cpp:228] Iteration 1000, loss = 0.127065
I0403 02:49:34.552985 32199 solver.cpp:244]     Train net output #0: loss = 0.127065 (* 1 = 0.127065 loss)
I0403 02:49:34.724297 32199 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 02:49:41.783704 32199 solver.cpp:228] Iteration 1010, loss = 0.0719745
I0403 02:49:41.790366 32199 solver.cpp:244]     Train net output #0: loss = 0.0719745 (* 1 = 0.0719745 loss)
I0403 02:49:41.984097 32199 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 02:49:49.085283 32199 solver.cpp:228] Iteration 1020, loss = 0.122506
I0403 02:49:49.096298 32199 solver.cpp:244]     Train net output #0: loss = 0.122506 (* 1 = 0.122506 loss)
I0403 02:49:49.281513 32199 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 02:49:56.274564 32199 solver.cpp:228] Iteration 1030, loss = 0.120492
I0403 02:49:56.281031 32199 solver.cpp:244]     Train net output #0: loss = 0.120492 (* 1 = 0.120492 loss)
I0403 02:49:56.465253 32199 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 02:50:03.710847 32199 solver.cpp:228] Iteration 1040, loss = 0.060901
I0403 02:50:03.716820 32199 solver.cpp:244]     Train net output #0: loss = 0.0609011 (* 1 = 0.0609011 loss)
I0403 02:50:03.910156 32199 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:50:11.044689 32199 solver.cpp:228] Iteration 1050, loss = 0.0969808
I0403 02:50:11.051553 32199 solver.cpp:244]     Train net output #0: loss = 0.0969809 (* 1 = 0.0969809 loss)
I0403 02:50:11.182778 32199 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 02:50:18.568833 32199 solver.cpp:228] Iteration 1060, loss = 0.0649452
I0403 02:50:18.574270 32199 solver.cpp:244]     Train net output #0: loss = 0.0649452 (* 1 = 0.0649452 loss)
I0403 02:50:18.717314 32199 sgd_solver.cpp:106] Iteration 1060, lr = 0.005
I0403 02:50:25.986050 32199 solver.cpp:228] Iteration 1070, loss = 0.182814
I0403 02:50:25.992202 32199 solver.cpp:244]     Train net output #0: loss = 0.182815 (* 1 = 0.182815 loss)
I0403 02:50:26.169673 32199 sgd_solver.cpp:106] Iteration 1070, lr = 0.005
I0403 02:50:33.300494 32199 solver.cpp:228] Iteration 1080, loss = 0.143827
I0403 02:50:33.306749 32199 solver.cpp:244]     Train net output #0: loss = 0.143827 (* 1 = 0.143827 loss)
I0403 02:50:33.475639 32199 sgd_solver.cpp:106] Iteration 1080, lr = 0.005
I0403 02:50:40.685147 32199 solver.cpp:228] Iteration 1090, loss = 0.0901565
I0403 02:50:40.691897 32199 solver.cpp:244]     Train net output #0: loss = 0.0901566 (* 1 = 0.0901566 loss)
I0403 02:50:40.901254 32199 sgd_solver.cpp:106] Iteration 1090, lr = 0.005
I0403 02:50:43.849063 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1095.caffemodel
I0403 02:50:46.635707 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1095.solverstate
I0403 02:50:48.561378 32199 solver.cpp:337] Iteration 1095, Testing net (#0)
I0403 02:52:02.368122 32199 solver.cpp:404]     Test net output #0: accuracy = 0.931889
I0403 02:52:02.375181 32199 solver.cpp:404]     Test net output #1: loss = 0.222622 (* 1 = 0.222622 loss)
I0403 02:52:06.628371 32199 solver.cpp:228] Iteration 1100, loss = 0.0855033
I0403 02:52:06.634281 32199 solver.cpp:244]     Train net output #0: loss = 0.0855034 (* 1 = 0.0855034 loss)
I0403 02:52:06.817698 32199 sgd_solver.cpp:106] Iteration 1100, lr = 0.005
I0403 02:52:13.931967 32199 solver.cpp:228] Iteration 1110, loss = 0.09446
I0403 02:52:13.938684 32199 solver.cpp:244]     Train net output #0: loss = 0.09446 (* 1 = 0.09446 loss)
I0403 02:52:14.113389 32199 sgd_solver.cpp:106] Iteration 1110, lr = 0.005
I0403 02:52:21.330461 32199 solver.cpp:228] Iteration 1120, loss = 0.0611881
I0403 02:52:21.335942 32199 solver.cpp:244]     Train net output #0: loss = 0.0611882 (* 1 = 0.0611882 loss)
I0403 02:52:21.506434 32199 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 02:52:28.650733 32199 solver.cpp:228] Iteration 1130, loss = 0.0534443
I0403 02:52:28.657995 32199 solver.cpp:244]     Train net output #0: loss = 0.0534443 (* 1 = 0.0534443 loss)
I0403 02:52:28.839313 32199 sgd_solver.cpp:106] Iteration 1130, lr = 0.005
I0403 02:52:35.903259 32199 solver.cpp:228] Iteration 1140, loss = 0.0535503
I0403 02:52:35.909399 32199 solver.cpp:244]     Train net output #0: loss = 0.0535503 (* 1 = 0.0535503 loss)
I0403 02:52:36.092706 32199 sgd_solver.cpp:106] Iteration 1140, lr = 0.005
I0403 02:52:43.159565 32199 solver.cpp:228] Iteration 1150, loss = 0.0763719
I0403 02:52:43.166157 32199 solver.cpp:244]     Train net output #0: loss = 0.0763719 (* 1 = 0.0763719 loss)
I0403 02:52:43.322510 32199 sgd_solver.cpp:106] Iteration 1150, lr = 0.005
I0403 02:52:50.778342 32199 solver.cpp:228] Iteration 1160, loss = 0.142429
I0403 02:52:50.784631 32199 solver.cpp:244]     Train net output #0: loss = 0.142429 (* 1 = 0.142429 loss)
I0403 02:52:50.962784 32199 sgd_solver.cpp:106] Iteration 1160, lr = 0.005
I0403 02:52:58.085963 32199 solver.cpp:228] Iteration 1170, loss = 0.053458
I0403 02:52:58.092135 32199 solver.cpp:244]     Train net output #0: loss = 0.0534581 (* 1 = 0.0534581 loss)
I0403 02:52:58.269909 32199 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 02:53:05.424206 32199 solver.cpp:228] Iteration 1180, loss = 0.194648
I0403 02:53:05.429965 32199 solver.cpp:244]     Train net output #0: loss = 0.194648 (* 1 = 0.194648 loss)
I0403 02:53:05.617246 32199 sgd_solver.cpp:106] Iteration 1180, lr = 0.005
I0403 02:53:12.870501 32199 solver.cpp:228] Iteration 1190, loss = 0.118009
I0403 02:53:12.877059 32199 solver.cpp:244]     Train net output #0: loss = 0.118009 (* 1 = 0.118009 loss)
I0403 02:53:13.047245 32199 sgd_solver.cpp:106] Iteration 1190, lr = 0.005
I0403 02:53:20.206974 32199 solver.cpp:228] Iteration 1200, loss = 0.0640687
I0403 02:53:20.212999 32199 solver.cpp:244]     Train net output #0: loss = 0.0640688 (* 1 = 0.0640688 loss)
I0403 02:53:20.378624 32199 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 02:53:27.619704 32199 solver.cpp:228] Iteration 1210, loss = 0.0431982
I0403 02:53:27.626369 32199 solver.cpp:244]     Train net output #0: loss = 0.0431982 (* 1 = 0.0431982 loss)
I0403 02:53:27.780944 32199 sgd_solver.cpp:106] Iteration 1210, lr = 0.005
I0403 02:53:34.990727 32199 solver.cpp:228] Iteration 1220, loss = 0.13544
I0403 02:53:34.997395 32199 solver.cpp:244]     Train net output #0: loss = 0.13544 (* 1 = 0.13544 loss)
I0403 02:53:35.160466 32199 sgd_solver.cpp:106] Iteration 1220, lr = 0.005
I0403 02:53:42.333212 32199 solver.cpp:228] Iteration 1230, loss = 0.075194
I0403 02:53:42.339716 32199 solver.cpp:244]     Train net output #0: loss = 0.0751941 (* 1 = 0.0751941 loss)
I0403 02:53:42.508533 32199 sgd_solver.cpp:106] Iteration 1230, lr = 0.005
I0403 02:53:49.694846 32199 solver.cpp:228] Iteration 1240, loss = 0.0551099
I0403 02:53:49.701578 32199 solver.cpp:244]     Train net output #0: loss = 0.0551099 (* 1 = 0.0551099 loss)
I0403 02:53:49.851279 32199 sgd_solver.cpp:106] Iteration 1240, lr = 0.005
I0403 02:53:57.150832 32199 solver.cpp:228] Iteration 1250, loss = 0.106298
I0403 02:53:57.157696 32199 solver.cpp:244]     Train net output #0: loss = 0.106298 (* 1 = 0.106298 loss)
I0403 02:53:57.352108 32199 sgd_solver.cpp:106] Iteration 1250, lr = 0.005
I0403 02:54:04.521239 32199 solver.cpp:228] Iteration 1260, loss = 0.153087
I0403 02:54:04.527436 32199 solver.cpp:244]     Train net output #0: loss = 0.153087 (* 1 = 0.153087 loss)
I0403 02:54:04.730617 32199 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 02:54:11.889418 32199 solver.cpp:228] Iteration 1270, loss = 0.0758995
I0403 02:54:11.894883 32199 solver.cpp:244]     Train net output #0: loss = 0.0758996 (* 1 = 0.0758996 loss)
I0403 02:54:12.073724 32199 sgd_solver.cpp:106] Iteration 1270, lr = 0.005
I0403 02:54:19.136770 32199 solver.cpp:228] Iteration 1280, loss = 0.0242663
I0403 02:54:19.142523 32199 solver.cpp:244]     Train net output #0: loss = 0.0242664 (* 1 = 0.0242664 loss)
I0403 02:54:19.311861 32199 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 02:54:26.386157 32199 solver.cpp:228] Iteration 1290, loss = 0.126674
I0403 02:54:26.392884 32199 solver.cpp:244]     Train net output #0: loss = 0.126674 (* 1 = 0.126674 loss)
I0403 02:54:26.551863 32199 sgd_solver.cpp:106] Iteration 1290, lr = 0.005
I0403 02:54:33.923072 32199 solver.cpp:228] Iteration 1300, loss = 0.0769917
I0403 02:54:33.929405 32199 solver.cpp:244]     Train net output #0: loss = 0.0769918 (* 1 = 0.0769918 loss)
I0403 02:54:34.009969 32199 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 02:54:41.325412 32199 solver.cpp:228] Iteration 1310, loss = 0.0921612
I0403 02:54:41.332044 32199 solver.cpp:244]     Train net output #0: loss = 0.0921613 (* 1 = 0.0921613 loss)
I0403 02:54:41.527566 32199 sgd_solver.cpp:106] Iteration 1310, lr = 0.005
I0403 02:54:43.687505 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1314.caffemodel
I0403 02:54:46.459630 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1314.solverstate
I0403 02:54:48.386070 32199 solver.cpp:337] Iteration 1314, Testing net (#0)
I0403 02:56:02.196490 32199 solver.cpp:404]     Test net output #0: accuracy = 0.933066
I0403 02:56:02.203737 32199 solver.cpp:404]     Test net output #1: loss = 0.214748 (* 1 = 0.214748 loss)
I0403 02:56:07.145097 32199 solver.cpp:228] Iteration 1320, loss = 0.125447
I0403 02:56:07.150787 32199 solver.cpp:244]     Train net output #0: loss = 0.125447 (* 1 = 0.125447 loss)
I0403 02:56:07.317265 32199 sgd_solver.cpp:106] Iteration 1320, lr = 0.005
I0403 02:56:14.593257 32199 solver.cpp:228] Iteration 1330, loss = 0.0652554
I0403 02:56:14.599313 32199 solver.cpp:244]     Train net output #0: loss = 0.0652555 (* 1 = 0.0652555 loss)
I0403 02:56:14.777173 32199 sgd_solver.cpp:106] Iteration 1330, lr = 0.005
I0403 02:56:22.012153 32199 solver.cpp:228] Iteration 1340, loss = 0.0399558
I0403 02:56:22.018666 32199 solver.cpp:244]     Train net output #0: loss = 0.0399558 (* 1 = 0.0399558 loss)
I0403 02:56:22.201314 32199 sgd_solver.cpp:106] Iteration 1340, lr = 0.005
I0403 02:56:29.423312 32199 solver.cpp:228] Iteration 1350, loss = 0.00769036
I0403 02:56:29.430186 32199 solver.cpp:244]     Train net output #0: loss = 0.00769043 (* 1 = 0.00769043 loss)
I0403 02:56:29.593636 32199 sgd_solver.cpp:106] Iteration 1350, lr = 0.005
I0403 02:56:36.954277 32199 solver.cpp:228] Iteration 1360, loss = 0.067413
I0403 02:56:36.961283 32199 solver.cpp:244]     Train net output #0: loss = 0.0674131 (* 1 = 0.0674131 loss)
I0403 02:56:37.093370 32199 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 02:56:44.289968 32199 solver.cpp:228] Iteration 1370, loss = 0.0807493
I0403 02:56:44.296221 32199 solver.cpp:244]     Train net output #0: loss = 0.0807494 (* 1 = 0.0807494 loss)
I0403 02:56:44.460728 32199 sgd_solver.cpp:106] Iteration 1370, lr = 0.005
I0403 02:56:51.725453 32199 solver.cpp:228] Iteration 1380, loss = 0.150126
I0403 02:56:51.731215 32199 solver.cpp:244]     Train net output #0: loss = 0.150126 (* 1 = 0.150126 loss)
I0403 02:56:51.886488 32199 sgd_solver.cpp:106] Iteration 1380, lr = 0.005
I0403 02:56:59.042709 32199 solver.cpp:228] Iteration 1390, loss = 0.0823636
I0403 02:56:59.049113 32199 solver.cpp:244]     Train net output #0: loss = 0.0823636 (* 1 = 0.0823636 loss)
I0403 02:56:59.248926 32199 sgd_solver.cpp:106] Iteration 1390, lr = 0.005
I0403 02:57:06.410254 32199 solver.cpp:228] Iteration 1400, loss = 0.0482893
I0403 02:57:06.416491 32199 solver.cpp:244]     Train net output #0: loss = 0.0482894 (* 1 = 0.0482894 loss)
I0403 02:57:06.536908 32199 sgd_solver.cpp:106] Iteration 1400, lr = 0.005
I0403 02:57:13.705273 32199 solver.cpp:228] Iteration 1410, loss = 0.179561
I0403 02:57:13.711472 32199 solver.cpp:244]     Train net output #0: loss = 0.179561 (* 1 = 0.179561 loss)
I0403 02:57:13.934303 32199 sgd_solver.cpp:106] Iteration 1410, lr = 0.005
I0403 02:57:21.164676 32199 solver.cpp:228] Iteration 1420, loss = 0.0592374
I0403 02:57:21.170549 32199 solver.cpp:244]     Train net output #0: loss = 0.0592375 (* 1 = 0.0592375 loss)
I0403 02:57:21.306740 32199 sgd_solver.cpp:106] Iteration 1420, lr = 0.005
I0403 02:57:28.690038 32199 solver.cpp:228] Iteration 1430, loss = 0.0697622
I0403 02:57:28.695557 32199 solver.cpp:244]     Train net output #0: loss = 0.0697623 (* 1 = 0.0697623 loss)
I0403 02:57:28.893630 32199 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 02:57:35.999703 32199 solver.cpp:228] Iteration 1440, loss = 0.144876
I0403 02:57:36.006193 32199 solver.cpp:244]     Train net output #0: loss = 0.144877 (* 1 = 0.144877 loss)
I0403 02:57:36.179596 32199 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 02:57:43.282691 32199 solver.cpp:228] Iteration 1450, loss = 0.168568
I0403 02:57:43.288600 32199 solver.cpp:244]     Train net output #0: loss = 0.168568 (* 1 = 0.168568 loss)
I0403 02:57:43.451953 32199 sgd_solver.cpp:106] Iteration 1450, lr = 0.005
I0403 02:57:50.565650 32199 solver.cpp:228] Iteration 1460, loss = 0.111862
I0403 02:57:50.573096 32199 solver.cpp:244]     Train net output #0: loss = 0.111862 (* 1 = 0.111862 loss)
I0403 02:57:50.749224 32199 sgd_solver.cpp:106] Iteration 1460, lr = 0.005
I0403 02:57:57.844805 32199 solver.cpp:228] Iteration 1470, loss = 0.0410292
I0403 02:57:57.849602 32199 solver.cpp:244]     Train net output #0: loss = 0.0410293 (* 1 = 0.0410293 loss)
I0403 02:57:58.094965 32199 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 02:58:05.279263 32199 solver.cpp:228] Iteration 1480, loss = 0.104006
I0403 02:58:05.284821 32199 solver.cpp:244]     Train net output #0: loss = 0.104006 (* 1 = 0.104006 loss)
I0403 02:58:05.483906 32199 sgd_solver.cpp:106] Iteration 1480, lr = 0.005
I0403 02:58:12.643157 32199 solver.cpp:228] Iteration 1490, loss = 0.105864
I0403 02:58:12.649065 32199 solver.cpp:244]     Train net output #0: loss = 0.105865 (* 1 = 0.105865 loss)
I0403 02:58:12.826468 32199 sgd_solver.cpp:106] Iteration 1490, lr = 0.005
I0403 02:58:20.125785 32199 solver.cpp:228] Iteration 1500, loss = 0.0191416
I0403 02:58:20.132206 32199 solver.cpp:244]     Train net output #0: loss = 0.0191417 (* 1 = 0.0191417 loss)
I0403 02:58:20.321880 32199 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0403 02:58:27.532567 32199 solver.cpp:228] Iteration 1510, loss = 0.111634
I0403 02:58:27.539712 32199 solver.cpp:244]     Train net output #0: loss = 0.111634 (* 1 = 0.111634 loss)
I0403 02:58:27.737483 32199 sgd_solver.cpp:106] Iteration 1510, lr = 0.005
I0403 02:58:34.903107 32199 solver.cpp:228] Iteration 1520, loss = 0.0647162
I0403 02:58:34.909093 32199 solver.cpp:244]     Train net output #0: loss = 0.0647163 (* 1 = 0.0647163 loss)
I0403 02:58:35.115259 32199 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 02:58:42.368607 32199 solver.cpp:228] Iteration 1530, loss = 0.0233881
I0403 02:58:42.373765 32199 solver.cpp:244]     Train net output #0: loss = 0.0233882 (* 1 = 0.0233882 loss)
I0403 02:58:42.541399 32199 sgd_solver.cpp:106] Iteration 1530, lr = 0.005
I0403 02:58:44.012862 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1533.caffemodel
I0403 02:58:46.805604 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1533.solverstate
I0403 02:58:48.733577 32199 solver.cpp:337] Iteration 1533, Testing net (#0)
I0403 03:00:02.527112 32199 solver.cpp:404]     Test net output #0: accuracy = 0.939071
I0403 03:00:02.533695 32199 solver.cpp:404]     Test net output #1: loss = 0.196329 (* 1 = 0.196329 loss)
I0403 03:00:08.232269 32199 solver.cpp:228] Iteration 1540, loss = 0.0644429
I0403 03:00:08.238268 32199 solver.cpp:244]     Train net output #0: loss = 0.064443 (* 1 = 0.064443 loss)
I0403 03:00:08.465119 32199 sgd_solver.cpp:106] Iteration 1540, lr = 0.005
I0403 03:00:15.583333 32199 solver.cpp:228] Iteration 1550, loss = 0.052694
I0403 03:00:15.590795 32199 solver.cpp:244]     Train net output #0: loss = 0.0526941 (* 1 = 0.0526941 loss)
I0403 03:00:15.768090 32199 sgd_solver.cpp:106] Iteration 1550, lr = 0.005
I0403 03:00:23.008662 32199 solver.cpp:228] Iteration 1560, loss = 0.0453018
I0403 03:00:23.016507 32199 solver.cpp:244]     Train net output #0: loss = 0.0453018 (* 1 = 0.0453018 loss)
I0403 03:00:23.234799 32199 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 03:00:30.391365 32199 solver.cpp:228] Iteration 1570, loss = 0.0603462
I0403 03:00:30.397528 32199 solver.cpp:244]     Train net output #0: loss = 0.0603463 (* 1 = 0.0603463 loss)
I0403 03:00:30.632094 32199 sgd_solver.cpp:106] Iteration 1570, lr = 0.005
I0403 03:00:37.860622 32199 solver.cpp:228] Iteration 1580, loss = 0.0592418
I0403 03:00:37.867410 32199 solver.cpp:244]     Train net output #0: loss = 0.0592419 (* 1 = 0.0592419 loss)
I0403 03:00:38.063400 32199 sgd_solver.cpp:106] Iteration 1580, lr = 0.005
I0403 03:00:45.329597 32199 solver.cpp:228] Iteration 1590, loss = 0.090164
I0403 03:00:45.334226 32199 solver.cpp:244]     Train net output #0: loss = 0.0901641 (* 1 = 0.0901641 loss)
I0403 03:00:45.541584 32199 sgd_solver.cpp:106] Iteration 1590, lr = 0.005
I0403 03:00:52.623944 32199 solver.cpp:228] Iteration 1600, loss = 0.0918748
I0403 03:00:52.629744 32199 solver.cpp:244]     Train net output #0: loss = 0.0918749 (* 1 = 0.0918749 loss)
I0403 03:00:52.803601 32199 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 03:00:59.904731 32199 solver.cpp:228] Iteration 1610, loss = 0.108394
I0403 03:00:59.911214 32199 solver.cpp:244]     Train net output #0: loss = 0.108394 (* 1 = 0.108394 loss)
I0403 03:01:00.080000 32199 sgd_solver.cpp:106] Iteration 1610, lr = 0.005
I0403 03:01:07.137082 32199 solver.cpp:228] Iteration 1620, loss = 0.0865082
I0403 03:01:07.143226 32199 solver.cpp:244]     Train net output #0: loss = 0.0865083 (* 1 = 0.0865083 loss)
I0403 03:01:07.310641 32199 sgd_solver.cpp:106] Iteration 1620, lr = 0.005
I0403 03:01:14.590418 32199 solver.cpp:228] Iteration 1630, loss = 0.0532641
I0403 03:01:14.597090 32199 solver.cpp:244]     Train net output #0: loss = 0.0532642 (* 1 = 0.0532642 loss)
I0403 03:01:14.751524 32199 sgd_solver.cpp:106] Iteration 1630, lr = 0.005
I0403 03:01:21.900324 32199 solver.cpp:228] Iteration 1640, loss = 0.0565963
I0403 03:01:21.906649 32199 solver.cpp:244]     Train net output #0: loss = 0.0565964 (* 1 = 0.0565964 loss)
I0403 03:01:22.061668 32199 sgd_solver.cpp:106] Iteration 1640, lr = 0.005
I0403 03:01:29.255990 32199 solver.cpp:228] Iteration 1650, loss = 0.0929294
I0403 03:01:29.261803 32199 solver.cpp:244]     Train net output #0: loss = 0.0929295 (* 1 = 0.0929295 loss)
I0403 03:01:29.431541 32199 sgd_solver.cpp:106] Iteration 1650, lr = 0.005
I0403 03:01:36.572798 32199 solver.cpp:228] Iteration 1660, loss = 0.101243
I0403 03:01:36.579048 32199 solver.cpp:244]     Train net output #0: loss = 0.101243 (* 1 = 0.101243 loss)
I0403 03:01:36.740810 32199 sgd_solver.cpp:106] Iteration 1660, lr = 0.005
I0403 03:01:43.970904 32199 solver.cpp:228] Iteration 1670, loss = 0.0105498
I0403 03:01:43.977164 32199 solver.cpp:244]     Train net output #0: loss = 0.0105499 (* 1 = 0.0105499 loss)
I0403 03:01:44.139832 32199 sgd_solver.cpp:106] Iteration 1670, lr = 0.005
I0403 03:01:51.306155 32199 solver.cpp:228] Iteration 1680, loss = 0.0595906
I0403 03:01:51.311554 32199 solver.cpp:244]     Train net output #0: loss = 0.0595907 (* 1 = 0.0595907 loss)
I0403 03:01:51.481055 32199 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 03:01:58.865114 32199 solver.cpp:228] Iteration 1690, loss = 0.0906065
I0403 03:01:58.870132 32199 solver.cpp:244]     Train net output #0: loss = 0.0906065 (* 1 = 0.0906065 loss)
I0403 03:01:59.040630 32199 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 03:02:06.152920 32199 solver.cpp:228] Iteration 1700, loss = 0.0365185
I0403 03:02:06.159066 32199 solver.cpp:244]     Train net output #0: loss = 0.0365186 (* 1 = 0.0365186 loss)
I0403 03:02:06.329597 32199 sgd_solver.cpp:106] Iteration 1700, lr = 0.005
I0403 03:02:13.445950 32199 solver.cpp:228] Iteration 1710, loss = 0.0188473
I0403 03:02:13.450839 32199 solver.cpp:244]     Train net output #0: loss = 0.0188474 (* 1 = 0.0188474 loss)
I0403 03:02:13.644016 32199 sgd_solver.cpp:106] Iteration 1710, lr = 0.005
I0403 03:02:20.726450 32199 solver.cpp:228] Iteration 1720, loss = 0.0655572
I0403 03:02:20.732828 32199 solver.cpp:244]     Train net output #0: loss = 0.0655573 (* 1 = 0.0655573 loss)
I0403 03:02:20.892278 32199 sgd_solver.cpp:106] Iteration 1720, lr = 0.005
I0403 03:02:28.171381 32199 solver.cpp:228] Iteration 1730, loss = 0.0343187
I0403 03:02:28.177775 32199 solver.cpp:244]     Train net output #0: loss = 0.0343188 (* 1 = 0.0343188 loss)
I0403 03:02:28.340307 32199 sgd_solver.cpp:106] Iteration 1730, lr = 0.005
I0403 03:02:35.536301 32199 solver.cpp:228] Iteration 1740, loss = 0.0267717
I0403 03:02:35.542457 32199 solver.cpp:244]     Train net output #0: loss = 0.0267718 (* 1 = 0.0267718 loss)
I0403 03:02:35.721539 32199 sgd_solver.cpp:106] Iteration 1740, lr = 0.005
I0403 03:02:42.848625 32199 solver.cpp:228] Iteration 1750, loss = 0.0802359
I0403 03:02:42.855625 32199 solver.cpp:244]     Train net output #0: loss = 0.080236 (* 1 = 0.080236 loss)
I0403 03:02:43.028364 32199 sgd_solver.cpp:106] Iteration 1750, lr = 0.005
I0403 03:02:43.749981 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1752.caffemodel
I0403 03:02:46.516450 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1752.solverstate
I0403 03:02:48.433701 32199 solver.cpp:337] Iteration 1752, Testing net (#0)
I0403 03:04:02.214494 32199 solver.cpp:404]     Test net output #0: accuracy = 0.929598
I0403 03:04:02.220863 32199 solver.cpp:404]     Test net output #1: loss = 0.238767 (* 1 = 0.238767 loss)
I0403 03:04:08.687335 32199 solver.cpp:228] Iteration 1760, loss = 0.079964
I0403 03:04:08.693948 32199 solver.cpp:244]     Train net output #0: loss = 0.079964 (* 1 = 0.079964 loss)
I0403 03:04:08.834204 32199 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 03:04:16.060457 32199 solver.cpp:228] Iteration 1770, loss = 0.0803018
I0403 03:04:16.065994 32199 solver.cpp:244]     Train net output #0: loss = 0.0803018 (* 1 = 0.0803018 loss)
I0403 03:04:16.244067 32199 sgd_solver.cpp:106] Iteration 1770, lr = 0.005
I0403 03:04:23.377789 32199 solver.cpp:228] Iteration 1780, loss = 0.0512554
I0403 03:04:23.383327 32199 solver.cpp:244]     Train net output #0: loss = 0.0512555 (* 1 = 0.0512555 loss)
I0403 03:04:23.538506 32199 sgd_solver.cpp:106] Iteration 1780, lr = 0.005
I0403 03:04:30.822690 32199 solver.cpp:228] Iteration 1790, loss = 0.0221754
I0403 03:04:30.829180 32199 solver.cpp:244]     Train net output #0: loss = 0.0221755 (* 1 = 0.0221755 loss)
I0403 03:04:31.035787 32199 sgd_solver.cpp:106] Iteration 1790, lr = 0.005
I0403 03:04:38.234179 32199 solver.cpp:228] Iteration 1800, loss = 0.116549
I0403 03:04:38.240731 32199 solver.cpp:244]     Train net output #0: loss = 0.116549 (* 1 = 0.116549 loss)
I0403 03:04:38.330679 32199 sgd_solver.cpp:106] Iteration 1800, lr = 0.005
I0403 03:04:45.687585 32199 solver.cpp:228] Iteration 1810, loss = 0.04746
I0403 03:04:45.693292 32199 solver.cpp:244]     Train net output #0: loss = 0.04746 (* 1 = 0.04746 loss)
I0403 03:04:45.870988 32199 sgd_solver.cpp:106] Iteration 1810, lr = 0.005
I0403 03:04:53.144593 32199 solver.cpp:228] Iteration 1820, loss = 0.059871
I0403 03:04:53.151033 32199 solver.cpp:244]     Train net output #0: loss = 0.059871 (* 1 = 0.059871 loss)
I0403 03:04:53.281968 32199 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 03:05:00.580700 32199 solver.cpp:228] Iteration 1830, loss = 0.161335
I0403 03:05:00.587158 32199 solver.cpp:244]     Train net output #0: loss = 0.161335 (* 1 = 0.161335 loss)
I0403 03:05:00.787747 32199 sgd_solver.cpp:106] Iteration 1830, lr = 0.005
I0403 03:05:07.855528 32199 solver.cpp:228] Iteration 1840, loss = 0.0186767
I0403 03:05:07.861840 32199 solver.cpp:244]     Train net output #0: loss = 0.0186768 (* 1 = 0.0186768 loss)
I0403 03:05:08.051998 32199 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 03:05:15.240466 32199 solver.cpp:228] Iteration 1850, loss = 0.0556868
I0403 03:05:15.245863 32199 solver.cpp:244]     Train net output #0: loss = 0.0556869 (* 1 = 0.0556869 loss)
I0403 03:05:15.431674 32199 sgd_solver.cpp:106] Iteration 1850, lr = 0.005
I0403 03:05:22.600383 32199 solver.cpp:228] Iteration 1860, loss = 0.0338374
I0403 03:05:22.605908 32199 solver.cpp:244]     Train net output #0: loss = 0.0338374 (* 1 = 0.0338374 loss)
I0403 03:05:22.722045 32199 sgd_solver.cpp:106] Iteration 1860, lr = 0.005
I0403 03:05:29.960083 32199 solver.cpp:228] Iteration 1870, loss = 0.0574165
I0403 03:05:29.966429 32199 solver.cpp:244]     Train net output #0: loss = 0.0574166 (* 1 = 0.0574166 loss)
I0403 03:05:30.127748 32199 sgd_solver.cpp:106] Iteration 1870, lr = 0.005
I0403 03:05:37.253738 32199 solver.cpp:228] Iteration 1880, loss = 0.0304269
I0403 03:05:37.259802 32199 solver.cpp:244]     Train net output #0: loss = 0.030427 (* 1 = 0.030427 loss)
I0403 03:05:37.420007 32199 sgd_solver.cpp:106] Iteration 1880, lr = 0.005
I0403 03:05:44.642372 32199 solver.cpp:228] Iteration 1890, loss = 0.0160057
I0403 03:05:44.648263 32199 solver.cpp:244]     Train net output #0: loss = 0.0160058 (* 1 = 0.0160058 loss)
I0403 03:05:44.786043 32199 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 03:05:52.114753 32199 solver.cpp:228] Iteration 1900, loss = 0.0811692
I0403 03:05:52.121927 32199 solver.cpp:244]     Train net output #0: loss = 0.0811693 (* 1 = 0.0811693 loss)
I0403 03:05:52.265455 32199 sgd_solver.cpp:106] Iteration 1900, lr = 0.005
I0403 03:05:59.391494 32199 solver.cpp:228] Iteration 1910, loss = 0.00747273
I0403 03:05:59.397071 32199 solver.cpp:244]     Train net output #0: loss = 0.00747278 (* 1 = 0.00747278 loss)
I0403 03:05:59.581504 32199 sgd_solver.cpp:106] Iteration 1910, lr = 0.005
I0403 03:06:06.774195 32199 solver.cpp:228] Iteration 1920, loss = 0.018732
I0403 03:06:06.780536 32199 solver.cpp:244]     Train net output #0: loss = 0.018732 (* 1 = 0.018732 loss)
I0403 03:06:06.948142 32199 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 03:06:14.005636 32199 solver.cpp:228] Iteration 1930, loss = 0.0517419
I0403 03:06:14.012049 32199 solver.cpp:244]     Train net output #0: loss = 0.051742 (* 1 = 0.051742 loss)
I0403 03:06:14.189827 32199 sgd_solver.cpp:106] Iteration 1930, lr = 0.005
I0403 03:06:21.440090 32199 solver.cpp:228] Iteration 1940, loss = 0.11959
I0403 03:06:21.446641 32199 solver.cpp:244]     Train net output #0: loss = 0.11959 (* 1 = 0.11959 loss)
I0403 03:06:21.607717 32199 sgd_solver.cpp:106] Iteration 1940, lr = 0.005
I0403 03:06:28.842142 32199 solver.cpp:228] Iteration 1950, loss = 0.0295155
I0403 03:06:28.848719 32199 solver.cpp:244]     Train net output #0: loss = 0.0295155 (* 1 = 0.0295155 loss)
I0403 03:06:28.999182 32199 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 03:06:36.302008 32199 solver.cpp:228] Iteration 1960, loss = 0.063408
I0403 03:06:36.307916 32199 solver.cpp:244]     Train net output #0: loss = 0.0634081 (* 1 = 0.0634081 loss)
I0403 03:06:36.481796 32199 sgd_solver.cpp:106] Iteration 1960, lr = 0.005
I0403 03:06:43.611145 32199 solver.cpp:228] Iteration 1970, loss = 0.0296426
I0403 03:06:43.618126 32199 solver.cpp:244]     Train net output #0: loss = 0.0296427 (* 1 = 0.0296427 loss)
I0403 03:06:43.770648 32199 sgd_solver.cpp:106] Iteration 1970, lr = 0.005
I0403 03:06:43.770884 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1971.caffemodel
I0403 03:06:46.511229 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_1971.solverstate
I0403 03:06:48.356103 32199 solver.cpp:337] Iteration 1971, Testing net (#0)
I0403 03:08:02.161182 32199 solver.cpp:404]     Test net output #0: accuracy = 0.942075
I0403 03:08:02.168015 32199 solver.cpp:404]     Test net output #1: loss = 0.195876 (* 1 = 0.195876 loss)
I0403 03:08:09.349545 32199 solver.cpp:228] Iteration 1980, loss = 0.0757185
I0403 03:08:09.355398 32199 solver.cpp:244]     Train net output #0: loss = 0.0757186 (* 1 = 0.0757186 loss)
I0403 03:08:09.556756 32199 sgd_solver.cpp:106] Iteration 1980, lr = 0.005
I0403 03:08:16.688213 32199 solver.cpp:228] Iteration 1990, loss = 0.0471225
I0403 03:08:16.693665 32199 solver.cpp:244]     Train net output #0: loss = 0.0471226 (* 1 = 0.0471226 loss)
I0403 03:08:16.878681 32199 sgd_solver.cpp:106] Iteration 1990, lr = 0.005
I0403 03:08:24.092608 32199 solver.cpp:228] Iteration 2000, loss = 0.0403272
I0403 03:08:24.097923 32199 solver.cpp:244]     Train net output #0: loss = 0.0403273 (* 1 = 0.0403273 loss)
I0403 03:08:24.269505 32199 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 03:08:31.408290 32199 solver.cpp:228] Iteration 2010, loss = 0.034842
I0403 03:08:31.414597 32199 solver.cpp:244]     Train net output #0: loss = 0.034842 (* 1 = 0.034842 loss)
I0403 03:08:31.644979 32199 sgd_solver.cpp:106] Iteration 2010, lr = 0.005
I0403 03:08:38.990988 32199 solver.cpp:228] Iteration 2020, loss = 0.0150291
I0403 03:08:38.997627 32199 solver.cpp:244]     Train net output #0: loss = 0.0150291 (* 1 = 0.0150291 loss)
I0403 03:08:39.165633 32199 sgd_solver.cpp:106] Iteration 2020, lr = 0.005
I0403 03:08:46.364068 32199 solver.cpp:228] Iteration 2030, loss = 0.0567946
I0403 03:08:46.370306 32199 solver.cpp:244]     Train net output #0: loss = 0.0567947 (* 1 = 0.0567947 loss)
I0403 03:08:46.536993 32199 sgd_solver.cpp:106] Iteration 2030, lr = 0.005
I0403 03:08:53.690927 32199 solver.cpp:228] Iteration 2040, loss = 0.0904572
I0403 03:08:53.697486 32199 solver.cpp:244]     Train net output #0: loss = 0.0904573 (* 1 = 0.0904573 loss)
I0403 03:08:53.862296 32199 sgd_solver.cpp:106] Iteration 2040, lr = 0.005
I0403 03:09:01.442816 32199 solver.cpp:228] Iteration 2050, loss = 0.0202944
I0403 03:09:01.449342 32199 solver.cpp:244]     Train net output #0: loss = 0.0202945 (* 1 = 0.0202945 loss)
I0403 03:09:01.617900 32199 sgd_solver.cpp:106] Iteration 2050, lr = 0.005
I0403 03:09:08.794085 32199 solver.cpp:228] Iteration 2060, loss = 0.0337297
I0403 03:09:08.800390 32199 solver.cpp:244]     Train net output #0: loss = 0.0337298 (* 1 = 0.0337298 loss)
I0403 03:09:08.913820 32199 sgd_solver.cpp:106] Iteration 2060, lr = 0.005
I0403 03:09:16.162147 32199 solver.cpp:228] Iteration 2070, loss = 0.0804009
I0403 03:09:16.168596 32199 solver.cpp:244]     Train net output #0: loss = 0.0804009 (* 1 = 0.0804009 loss)
I0403 03:09:16.338415 32199 sgd_solver.cpp:106] Iteration 2070, lr = 0.005
I0403 03:09:23.680152 32199 solver.cpp:228] Iteration 2080, loss = 0.0275684
I0403 03:09:23.685354 32199 solver.cpp:244]     Train net output #0: loss = 0.0275685 (* 1 = 0.0275685 loss)
I0403 03:09:23.845685 32199 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:09:31.439600 32199 solver.cpp:228] Iteration 2090, loss = 0.00863082
I0403 03:09:31.446228 32199 solver.cpp:244]     Train net output #0: loss = 0.00863089 (* 1 = 0.00863089 loss)
I0403 03:09:31.648250 32199 sgd_solver.cpp:106] Iteration 2090, lr = 0.005
I0403 03:09:38.898279 32199 solver.cpp:228] Iteration 2100, loss = 0.0103538
I0403 03:09:38.914891 32199 solver.cpp:244]     Train net output #0: loss = 0.0103539 (* 1 = 0.0103539 loss)
I0403 03:09:39.031594 32199 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 03:09:46.321115 32199 solver.cpp:228] Iteration 2110, loss = 0.082844
I0403 03:09:46.326843 32199 solver.cpp:244]     Train net output #0: loss = 0.0828441 (* 1 = 0.0828441 loss)
I0403 03:09:46.485157 32199 sgd_solver.cpp:106] Iteration 2110, lr = 0.005
I0403 03:09:53.744424 32199 solver.cpp:228] Iteration 2120, loss = 0.016447
I0403 03:09:53.751327 32199 solver.cpp:244]     Train net output #0: loss = 0.016447 (* 1 = 0.016447 loss)
I0403 03:09:53.945989 32199 sgd_solver.cpp:106] Iteration 2120, lr = 0.005
I0403 03:10:01.026618 32199 solver.cpp:228] Iteration 2130, loss = 0.0502727
I0403 03:10:01.032651 32199 solver.cpp:244]     Train net output #0: loss = 0.0502728 (* 1 = 0.0502728 loss)
I0403 03:10:01.210237 32199 sgd_solver.cpp:106] Iteration 2130, lr = 0.005
I0403 03:10:08.224238 32199 solver.cpp:228] Iteration 2140, loss = 0.00831875
I0403 03:10:08.230873 32199 solver.cpp:244]     Train net output #0: loss = 0.00831883 (* 1 = 0.00831883 loss)
I0403 03:10:08.394563 32199 sgd_solver.cpp:106] Iteration 2140, lr = 0.005
I0403 03:10:15.621351 32199 solver.cpp:228] Iteration 2150, loss = 0.061493
I0403 03:10:15.626852 32199 solver.cpp:244]     Train net output #0: loss = 0.0614931 (* 1 = 0.0614931 loss)
I0403 03:10:15.834095 32199 sgd_solver.cpp:106] Iteration 2150, lr = 0.005
I0403 03:10:22.895594 32199 solver.cpp:228] Iteration 2160, loss = 0.0540908
I0403 03:10:22.902292 32199 solver.cpp:244]     Train net output #0: loss = 0.0540909 (* 1 = 0.0540909 loss)
I0403 03:10:23.072716 32199 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 03:10:30.223125 32199 solver.cpp:228] Iteration 2170, loss = 0.00833827
I0403 03:10:30.229444 32199 solver.cpp:244]     Train net output #0: loss = 0.00833833 (* 1 = 0.00833833 loss)
I0403 03:10:30.399358 32199 sgd_solver.cpp:106] Iteration 2170, lr = 0.005
I0403 03:10:37.500771 32199 solver.cpp:228] Iteration 2180, loss = 0.0487012
I0403 03:10:37.507616 32199 solver.cpp:244]     Train net output #0: loss = 0.0487013 (* 1 = 0.0487013 loss)
I0403 03:10:37.684046 32199 sgd_solver.cpp:106] Iteration 2180, lr = 0.005
I0403 03:10:44.417178 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2190.caffemodel
I0403 03:10:47.090054 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2190.solverstate
I0403 03:10:48.917629 32199 solver.cpp:337] Iteration 2190, Testing net (#0)
I0403 03:12:02.726290 32199 solver.cpp:404]     Test net output #0: accuracy = 0.938823
I0403 03:12:02.731971 32199 solver.cpp:404]     Test net output #1: loss = 0.212063 (* 1 = 0.212063 loss)
I0403 03:12:03.244979 32199 solver.cpp:228] Iteration 2190, loss = 0.0187307
I0403 03:12:03.250865 32199 solver.cpp:244]     Train net output #0: loss = 0.0187308 (* 1 = 0.0187308 loss)
I0403 03:12:03.428696 32199 sgd_solver.cpp:106] Iteration 2190, lr = 0.005
I0403 03:12:10.597427 32199 solver.cpp:228] Iteration 2200, loss = 0.147869
I0403 03:12:10.604020 32199 solver.cpp:244]     Train net output #0: loss = 0.147869 (* 1 = 0.147869 loss)
I0403 03:12:10.762712 32199 sgd_solver.cpp:106] Iteration 2200, lr = 0.0005
I0403 03:12:17.977032 32199 solver.cpp:228] Iteration 2210, loss = 0.0992366
I0403 03:12:17.983489 32199 solver.cpp:244]     Train net output #0: loss = 0.0992366 (* 1 = 0.0992366 loss)
I0403 03:12:18.148548 32199 sgd_solver.cpp:106] Iteration 2210, lr = 0.0005
I0403 03:12:25.367370 32199 solver.cpp:228] Iteration 2220, loss = 0.0274215
I0403 03:12:25.373960 32199 solver.cpp:244]     Train net output #0: loss = 0.0274216 (* 1 = 0.0274216 loss)
I0403 03:12:25.524891 32199 sgd_solver.cpp:106] Iteration 2220, lr = 0.0005
I0403 03:12:32.688093 32199 solver.cpp:228] Iteration 2230, loss = 0.0245527
I0403 03:12:32.694147 32199 solver.cpp:244]     Train net output #0: loss = 0.0245528 (* 1 = 0.0245528 loss)
I0403 03:12:32.856441 32199 sgd_solver.cpp:106] Iteration 2230, lr = 0.0005
I0403 03:12:39.992400 32199 solver.cpp:228] Iteration 2240, loss = 0.0612884
I0403 03:12:39.998858 32199 solver.cpp:244]     Train net output #0: loss = 0.0612885 (* 1 = 0.0612885 loss)
I0403 03:12:40.171792 32199 sgd_solver.cpp:106] Iteration 2240, lr = 0.0005
I0403 03:12:47.266844 32199 solver.cpp:228] Iteration 2250, loss = 0.00294186
I0403 03:12:47.272651 32199 solver.cpp:244]     Train net output #0: loss = 0.00294191 (* 1 = 0.00294191 loss)
I0403 03:12:47.458322 32199 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0403 03:12:54.560667 32199 solver.cpp:228] Iteration 2260, loss = 0.0416877
I0403 03:12:54.567741 32199 solver.cpp:244]     Train net output #0: loss = 0.0416877 (* 1 = 0.0416877 loss)
I0403 03:12:54.728240 32199 sgd_solver.cpp:106] Iteration 2260, lr = 0.0005
I0403 03:13:01.847501 32199 solver.cpp:228] Iteration 2270, loss = 0.0159727
I0403 03:13:01.853893 32199 solver.cpp:244]     Train net output #0: loss = 0.0159727 (* 1 = 0.0159727 loss)
I0403 03:13:02.044785 32199 sgd_solver.cpp:106] Iteration 2270, lr = 0.0005
I0403 03:13:09.117244 32199 solver.cpp:228] Iteration 2280, loss = 0.00752727
I0403 03:13:09.122808 32199 solver.cpp:244]     Train net output #0: loss = 0.00752731 (* 1 = 0.00752731 loss)
I0403 03:13:09.279701 32199 sgd_solver.cpp:106] Iteration 2280, lr = 0.0005
I0403 03:13:16.513810 32199 solver.cpp:228] Iteration 2290, loss = 0.0757555
I0403 03:13:16.519704 32199 solver.cpp:244]     Train net output #0: loss = 0.0757556 (* 1 = 0.0757556 loss)
I0403 03:13:16.637640 32199 sgd_solver.cpp:106] Iteration 2290, lr = 0.0005
I0403 03:13:23.977591 32199 solver.cpp:228] Iteration 2300, loss = 0.00145434
I0403 03:13:23.983001 32199 solver.cpp:244]     Train net output #0: loss = 0.00145438 (* 1 = 0.00145438 loss)
I0403 03:13:24.154125 32199 sgd_solver.cpp:106] Iteration 2300, lr = 0.0005
I0403 03:13:31.253063 32199 solver.cpp:228] Iteration 2310, loss = 0.00785673
I0403 03:13:31.259531 32199 solver.cpp:244]     Train net output #0: loss = 0.00785677 (* 1 = 0.00785677 loss)
I0403 03:13:31.431164 32199 sgd_solver.cpp:106] Iteration 2310, lr = 0.0005
I0403 03:13:38.574434 32199 solver.cpp:228] Iteration 2320, loss = 0.0354618
I0403 03:13:38.580684 32199 solver.cpp:244]     Train net output #0: loss = 0.0354618 (* 1 = 0.0354618 loss)
I0403 03:13:38.751845 32199 sgd_solver.cpp:106] Iteration 2320, lr = 0.0005
I0403 03:13:45.883790 32199 solver.cpp:228] Iteration 2330, loss = 0.0317831
I0403 03:13:45.889861 32199 solver.cpp:244]     Train net output #0: loss = 0.0317832 (* 1 = 0.0317832 loss)
I0403 03:13:46.077462 32199 sgd_solver.cpp:106] Iteration 2330, lr = 0.0005
I0403 03:13:53.192900 32199 solver.cpp:228] Iteration 2340, loss = 0.00491862
I0403 03:13:53.197720 32199 solver.cpp:244]     Train net output #0: loss = 0.00491866 (* 1 = 0.00491866 loss)
I0403 03:13:53.377913 32199 sgd_solver.cpp:106] Iteration 2340, lr = 0.0005
I0403 03:14:00.488214 32199 solver.cpp:228] Iteration 2350, loss = 0.0202275
I0403 03:14:00.494115 32199 solver.cpp:244]     Train net output #0: loss = 0.0202276 (* 1 = 0.0202276 loss)
I0403 03:14:00.659994 32199 sgd_solver.cpp:106] Iteration 2350, lr = 0.0005
I0403 03:14:07.786799 32199 solver.cpp:228] Iteration 2360, loss = 0.0205121
I0403 03:14:07.793426 32199 solver.cpp:244]     Train net output #0: loss = 0.0205121 (* 1 = 0.0205121 loss)
I0403 03:14:08.014714 32199 sgd_solver.cpp:106] Iteration 2360, lr = 0.0005
I0403 03:14:15.162740 32199 solver.cpp:228] Iteration 2370, loss = 0.0127598
I0403 03:14:15.168278 32199 solver.cpp:244]     Train net output #0: loss = 0.0127598 (* 1 = 0.0127598 loss)
I0403 03:14:15.316076 32199 sgd_solver.cpp:106] Iteration 2370, lr = 0.0005
I0403 03:14:22.481243 32199 solver.cpp:228] Iteration 2380, loss = 0.00630112
I0403 03:14:22.487167 32199 solver.cpp:244]     Train net output #0: loss = 0.00630116 (* 1 = 0.00630116 loss)
I0403 03:14:22.657557 32199 sgd_solver.cpp:106] Iteration 2380, lr = 0.0005
I0403 03:14:29.968387 32199 solver.cpp:228] Iteration 2390, loss = 0.0122844
I0403 03:14:29.974344 32199 solver.cpp:244]     Train net output #0: loss = 0.0122844 (* 1 = 0.0122844 loss)
I0403 03:14:30.117679 32199 sgd_solver.cpp:106] Iteration 2390, lr = 0.0005
I0403 03:14:37.373205 32199 solver.cpp:228] Iteration 2400, loss = 0.0044284
I0403 03:14:37.379566 32199 solver.cpp:244]     Train net output #0: loss = 0.00442845 (* 1 = 0.00442845 loss)
I0403 03:14:37.590910 32199 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I0403 03:14:43.411443 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2409.caffemodel
I0403 03:14:46.201241 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2409.solverstate
I0403 03:14:48.118484 32199 solver.cpp:337] Iteration 2409, Testing net (#0)
I0403 03:16:01.905971 32199 solver.cpp:404]     Test net output #0: accuracy = 0.954335
I0403 03:16:01.913400 32199 solver.cpp:404]     Test net output #1: loss = 0.159635 (* 1 = 0.159635 loss)
I0403 03:16:03.187084 32199 solver.cpp:228] Iteration 2410, loss = 0.00430203
I0403 03:16:03.193151 32199 solver.cpp:244]     Train net output #0: loss = 0.00430208 (* 1 = 0.00430208 loss)
I0403 03:16:03.371354 32199 sgd_solver.cpp:106] Iteration 2410, lr = 0.0005
I0403 03:16:10.565073 32199 solver.cpp:228] Iteration 2420, loss = 0.0433434
I0403 03:16:10.575891 32199 solver.cpp:244]     Train net output #0: loss = 0.0433435 (* 1 = 0.0433435 loss)
I0403 03:16:10.782044 32199 sgd_solver.cpp:106] Iteration 2420, lr = 0.0005
I0403 03:16:18.017671 32199 solver.cpp:228] Iteration 2430, loss = 0.0133162
I0403 03:16:18.023886 32199 solver.cpp:244]     Train net output #0: loss = 0.0133163 (* 1 = 0.0133163 loss)
I0403 03:16:18.161054 32199 sgd_solver.cpp:106] Iteration 2430, lr = 0.0005
I0403 03:16:25.459064 32199 solver.cpp:228] Iteration 2440, loss = 0.0100372
I0403 03:16:25.464550 32199 solver.cpp:244]     Train net output #0: loss = 0.0100373 (* 1 = 0.0100373 loss)
I0403 03:16:25.655881 32199 sgd_solver.cpp:106] Iteration 2440, lr = 0.0005
I0403 03:16:32.930908 32199 solver.cpp:228] Iteration 2450, loss = 0.0391107
I0403 03:16:32.938319 32199 solver.cpp:244]     Train net output #0: loss = 0.0391107 (* 1 = 0.0391107 loss)
I0403 03:16:33.204884 32199 sgd_solver.cpp:106] Iteration 2450, lr = 0.0005
I0403 03:16:40.516005 32199 solver.cpp:228] Iteration 2460, loss = 0.0038845
I0403 03:16:40.521531 32199 solver.cpp:244]     Train net output #0: loss = 0.00388454 (* 1 = 0.00388454 loss)
I0403 03:16:40.670729 32199 sgd_solver.cpp:106] Iteration 2460, lr = 0.0005
I0403 03:16:47.921454 32199 solver.cpp:228] Iteration 2470, loss = 0.00676619
I0403 03:16:47.927628 32199 solver.cpp:244]     Train net output #0: loss = 0.00676624 (* 1 = 0.00676624 loss)
I0403 03:16:48.091387 32199 sgd_solver.cpp:106] Iteration 2470, lr = 0.0005
I0403 03:16:55.170845 32199 solver.cpp:228] Iteration 2480, loss = 0.0218145
I0403 03:16:55.176661 32199 solver.cpp:244]     Train net output #0: loss = 0.0218146 (* 1 = 0.0218146 loss)
I0403 03:16:55.357779 32199 sgd_solver.cpp:106] Iteration 2480, lr = 0.0005
I0403 03:17:02.543100 32199 solver.cpp:228] Iteration 2490, loss = 0.0296495
I0403 03:17:02.549788 32199 solver.cpp:244]     Train net output #0: loss = 0.0296496 (* 1 = 0.0296496 loss)
I0403 03:17:02.722153 32199 sgd_solver.cpp:106] Iteration 2490, lr = 0.0005
I0403 03:17:09.902065 32199 solver.cpp:228] Iteration 2500, loss = 0.0117481
I0403 03:17:09.908397 32199 solver.cpp:244]     Train net output #0: loss = 0.0117482 (* 1 = 0.0117482 loss)
I0403 03:17:10.103222 32199 sgd_solver.cpp:106] Iteration 2500, lr = 0.0005
I0403 03:17:17.254081 32199 solver.cpp:228] Iteration 2510, loss = 0.0044696
I0403 03:17:17.260474 32199 solver.cpp:244]     Train net output #0: loss = 0.00446964 (* 1 = 0.00446964 loss)
I0403 03:17:17.472337 32199 sgd_solver.cpp:106] Iteration 2510, lr = 0.0005
I0403 03:17:24.625172 32199 solver.cpp:228] Iteration 2520, loss = 0.000532599
I0403 03:17:24.633255 32199 solver.cpp:244]     Train net output #0: loss = 0.000532642 (* 1 = 0.000532642 loss)
I0403 03:17:24.847340 32199 sgd_solver.cpp:106] Iteration 2520, lr = 0.0005
I0403 03:17:31.943404 32199 solver.cpp:228] Iteration 2530, loss = 0.019955
I0403 03:17:31.950204 32199 solver.cpp:244]     Train net output #0: loss = 0.0199551 (* 1 = 0.0199551 loss)
I0403 03:17:32.138705 32199 sgd_solver.cpp:106] Iteration 2530, lr = 0.0005
I0403 03:17:39.405742 32199 solver.cpp:228] Iteration 2540, loss = 0.00502795
I0403 03:17:39.414175 32199 solver.cpp:244]     Train net output #0: loss = 0.00502799 (* 1 = 0.00502799 loss)
I0403 03:17:39.536281 32199 sgd_solver.cpp:106] Iteration 2540, lr = 0.0005
I0403 03:17:47.016103 32199 solver.cpp:228] Iteration 2550, loss = 0.0158593
I0403 03:17:47.024468 32199 solver.cpp:244]     Train net output #0: loss = 0.0158593 (* 1 = 0.0158593 loss)
I0403 03:17:47.191671 32199 sgd_solver.cpp:106] Iteration 2550, lr = 0.0005
I0403 03:17:54.367094 32199 solver.cpp:228] Iteration 2560, loss = 0.000875001
I0403 03:17:54.376176 32199 solver.cpp:244]     Train net output #0: loss = 0.000875042 (* 1 = 0.000875042 loss)
I0403 03:17:54.573477 32199 sgd_solver.cpp:106] Iteration 2560, lr = 0.0005
I0403 03:18:01.703255 32199 solver.cpp:228] Iteration 2570, loss = 0.00698635
I0403 03:18:01.708714 32199 solver.cpp:244]     Train net output #0: loss = 0.00698639 (* 1 = 0.00698639 loss)
I0403 03:18:01.887670 32199 sgd_solver.cpp:106] Iteration 2570, lr = 0.0005
I0403 03:18:09.031126 32199 solver.cpp:228] Iteration 2580, loss = 0.0100429
I0403 03:18:09.037137 32199 solver.cpp:244]     Train net output #0: loss = 0.0100429 (* 1 = 0.0100429 loss)
I0403 03:18:09.233311 32199 sgd_solver.cpp:106] Iteration 2580, lr = 0.0005
I0403 03:18:16.476830 32199 solver.cpp:228] Iteration 2590, loss = 0.0161319
I0403 03:18:16.482749 32199 solver.cpp:244]     Train net output #0: loss = 0.016132 (* 1 = 0.016132 loss)
I0403 03:18:16.662425 32199 sgd_solver.cpp:106] Iteration 2590, lr = 0.0005
I0403 03:18:23.845520 32199 solver.cpp:228] Iteration 2600, loss = 0.00438285
I0403 03:18:23.852874 32199 solver.cpp:244]     Train net output #0: loss = 0.0043829 (* 1 = 0.0043829 loss)
I0403 03:18:24.018558 32199 sgd_solver.cpp:106] Iteration 2600, lr = 0.0005
I0403 03:18:31.201253 32199 solver.cpp:228] Iteration 2610, loss = 0.0284042
I0403 03:18:31.206852 32199 solver.cpp:244]     Train net output #0: loss = 0.0284043 (* 1 = 0.0284043 loss)
I0403 03:18:31.464553 32199 sgd_solver.cpp:106] Iteration 2610, lr = 0.0005
I0403 03:18:38.690532 32199 solver.cpp:228] Iteration 2620, loss = 0.00986621
I0403 03:18:38.697221 32199 solver.cpp:244]     Train net output #0: loss = 0.00986626 (* 1 = 0.00986626 loss)
I0403 03:18:38.864451 32199 sgd_solver.cpp:106] Iteration 2620, lr = 0.0005
I0403 03:18:44.024031 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2628.caffemodel
I0403 03:18:46.799564 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2628.solverstate
I0403 03:18:48.719466 32199 solver.cpp:337] Iteration 2628, Testing net (#0)
I0403 03:20:02.546123 32199 solver.cpp:404]     Test net output #0: accuracy = 0.954521
I0403 03:20:02.552963 32199 solver.cpp:404]     Test net output #1: loss = 0.16516 (* 1 = 0.16516 loss)
I0403 03:20:04.587776 32199 solver.cpp:228] Iteration 2630, loss = 0.00250234
I0403 03:20:04.593989 32199 solver.cpp:244]     Train net output #0: loss = 0.00250239 (* 1 = 0.00250239 loss)
I0403 03:20:04.750792 32199 sgd_solver.cpp:106] Iteration 2630, lr = 0.0005
I0403 03:20:12.043673 32199 solver.cpp:228] Iteration 2640, loss = 0.00277712
I0403 03:20:12.049777 32199 solver.cpp:244]     Train net output #0: loss = 0.00277717 (* 1 = 0.00277717 loss)
I0403 03:20:12.228425 32199 sgd_solver.cpp:106] Iteration 2640, lr = 0.0005
I0403 03:20:19.343274 32199 solver.cpp:228] Iteration 2650, loss = 0.035982
I0403 03:20:19.348500 32199 solver.cpp:244]     Train net output #0: loss = 0.0359821 (* 1 = 0.0359821 loss)
I0403 03:20:19.515915 32199 sgd_solver.cpp:106] Iteration 2650, lr = 0.0005
I0403 03:20:26.661109 32199 solver.cpp:228] Iteration 2660, loss = 0.023469
I0403 03:20:26.666533 32199 solver.cpp:244]     Train net output #0: loss = 0.0234691 (* 1 = 0.0234691 loss)
I0403 03:20:26.854207 32199 sgd_solver.cpp:106] Iteration 2660, lr = 0.0005
I0403 03:20:33.950806 32199 solver.cpp:228] Iteration 2670, loss = 0.0106419
I0403 03:20:33.957679 32199 solver.cpp:244]     Train net output #0: loss = 0.010642 (* 1 = 0.010642 loss)
I0403 03:20:34.154458 32199 sgd_solver.cpp:106] Iteration 2670, lr = 0.0005
I0403 03:20:41.444528 32199 solver.cpp:228] Iteration 2680, loss = 0.00381863
I0403 03:20:41.455725 32199 solver.cpp:244]     Train net output #0: loss = 0.00381868 (* 1 = 0.00381868 loss)
I0403 03:20:41.636977 32199 sgd_solver.cpp:106] Iteration 2680, lr = 0.0005
I0403 03:20:48.843960 32199 solver.cpp:228] Iteration 2690, loss = 0.00165926
I0403 03:20:48.850055 32199 solver.cpp:244]     Train net output #0: loss = 0.0016593 (* 1 = 0.0016593 loss)
I0403 03:20:49.062679 32199 sgd_solver.cpp:106] Iteration 2690, lr = 0.0005
I0403 03:20:56.270838 32199 solver.cpp:228] Iteration 2700, loss = 0.00936329
I0403 03:20:56.277063 32199 solver.cpp:244]     Train net output #0: loss = 0.00936334 (* 1 = 0.00936334 loss)
I0403 03:20:56.484998 32199 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I0403 03:21:03.544929 32199 solver.cpp:228] Iteration 2710, loss = 0.0101304
I0403 03:21:03.551096 32199 solver.cpp:244]     Train net output #0: loss = 0.0101304 (* 1 = 0.0101304 loss)
I0403 03:21:03.738546 32199 sgd_solver.cpp:106] Iteration 2710, lr = 0.0005
I0403 03:21:10.977998 32199 solver.cpp:228] Iteration 2720, loss = 0.0050545
I0403 03:21:10.983772 32199 solver.cpp:244]     Train net output #0: loss = 0.00505455 (* 1 = 0.00505455 loss)
I0403 03:21:11.138666 32199 sgd_solver.cpp:106] Iteration 2720, lr = 0.0005
I0403 03:21:18.433810 32199 solver.cpp:228] Iteration 2730, loss = 0.0214145
I0403 03:21:18.440500 32199 solver.cpp:244]     Train net output #0: loss = 0.0214146 (* 1 = 0.0214146 loss)
I0403 03:21:18.644134 32199 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 03:21:25.715850 32199 solver.cpp:228] Iteration 2740, loss = 0.0104912
I0403 03:21:25.721762 32199 solver.cpp:244]     Train net output #0: loss = 0.0104912 (* 1 = 0.0104912 loss)
I0403 03:21:25.884532 32199 sgd_solver.cpp:106] Iteration 2740, lr = 0.0005
I0403 03:21:33.006536 32199 solver.cpp:228] Iteration 2750, loss = 0.00890277
I0403 03:21:33.013247 32199 solver.cpp:244]     Train net output #0: loss = 0.00890282 (* 1 = 0.00890282 loss)
I0403 03:21:33.173681 32199 sgd_solver.cpp:106] Iteration 2750, lr = 0.0005
I0403 03:21:40.375913 32199 solver.cpp:228] Iteration 2760, loss = 0.0114477
I0403 03:21:40.381697 32199 solver.cpp:244]     Train net output #0: loss = 0.0114477 (* 1 = 0.0114477 loss)
I0403 03:21:40.564340 32199 sgd_solver.cpp:106] Iteration 2760, lr = 0.0005
I0403 03:21:47.680002 32199 solver.cpp:228] Iteration 2770, loss = 0.0535645
I0403 03:21:47.688240 32199 solver.cpp:244]     Train net output #0: loss = 0.0535646 (* 1 = 0.0535646 loss)
I0403 03:21:47.831746 32199 sgd_solver.cpp:106] Iteration 2770, lr = 0.0005
I0403 03:21:54.981290 32199 solver.cpp:228] Iteration 2780, loss = 0.0137857
I0403 03:21:54.987962 32199 solver.cpp:244]     Train net output #0: loss = 0.0137858 (* 1 = 0.0137858 loss)
I0403 03:21:55.184296 32199 sgd_solver.cpp:106] Iteration 2780, lr = 0.0005
I0403 03:22:02.381857 32199 solver.cpp:228] Iteration 2790, loss = 0.00181216
I0403 03:22:02.387956 32199 solver.cpp:244]     Train net output #0: loss = 0.00181221 (* 1 = 0.00181221 loss)
I0403 03:22:02.558203 32199 sgd_solver.cpp:106] Iteration 2790, lr = 0.0005
I0403 03:22:09.716243 32199 solver.cpp:228] Iteration 2800, loss = 0.00857522
I0403 03:22:09.722662 32199 solver.cpp:244]     Train net output #0: loss = 0.00857526 (* 1 = 0.00857526 loss)
I0403 03:22:09.901288 32199 sgd_solver.cpp:106] Iteration 2800, lr = 0.0005
I0403 03:22:16.976038 32199 solver.cpp:228] Iteration 2810, loss = 0.00772357
I0403 03:22:16.982245 32199 solver.cpp:244]     Train net output #0: loss = 0.00772362 (* 1 = 0.00772362 loss)
I0403 03:22:17.164130 32199 sgd_solver.cpp:106] Iteration 2810, lr = 0.0005
I0403 03:22:24.236829 32199 solver.cpp:228] Iteration 2820, loss = 0.00373522
I0403 03:22:24.242995 32199 solver.cpp:244]     Train net output #0: loss = 0.00373527 (* 1 = 0.00373527 loss)
I0403 03:22:24.433275 32199 sgd_solver.cpp:106] Iteration 2820, lr = 0.0005
I0403 03:22:31.601311 32199 solver.cpp:228] Iteration 2830, loss = 0.0185711
I0403 03:22:31.607594 32199 solver.cpp:244]     Train net output #0: loss = 0.0185711 (* 1 = 0.0185711 loss)
I0403 03:22:31.769656 32199 sgd_solver.cpp:106] Iteration 2830, lr = 0.0005
I0403 03:22:39.083511 32199 solver.cpp:228] Iteration 2840, loss = 0.0265946
I0403 03:22:39.090648 32199 solver.cpp:244]     Train net output #0: loss = 0.0265946 (* 1 = 0.0265946 loss)
I0403 03:22:39.248517 32199 sgd_solver.cpp:106] Iteration 2840, lr = 0.0005
I0403 03:22:43.707684 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2847.caffemodel
I0403 03:22:46.485584 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_2847.solverstate
I0403 03:22:48.328202 32199 solver.cpp:337] Iteration 2847, Testing net (#0)
I0403 03:24:02.135426 32199 solver.cpp:404]     Test net output #0: accuracy = 0.956781
I0403 03:24:02.141476 32199 solver.cpp:404]     Test net output #1: loss = 0.157403 (* 1 = 0.157403 loss)
I0403 03:24:04.860138 32199 solver.cpp:228] Iteration 2850, loss = 0.00564934
I0403 03:24:04.871053 32199 solver.cpp:244]     Train net output #0: loss = 0.00564939 (* 1 = 0.00564939 loss)
I0403 03:24:05.092921 32199 sgd_solver.cpp:106] Iteration 2850, lr = 0.0005
I0403 03:24:12.178225 32199 solver.cpp:228] Iteration 2860, loss = 0.00404066
I0403 03:24:12.185958 32199 solver.cpp:244]     Train net output #0: loss = 0.00404071 (* 1 = 0.00404071 loss)
I0403 03:24:12.348580 32199 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 03:24:19.466873 32199 solver.cpp:228] Iteration 2870, loss = 0.0111781
I0403 03:24:19.473316 32199 solver.cpp:244]     Train net output #0: loss = 0.0111782 (* 1 = 0.0111782 loss)
I0403 03:24:19.658414 32199 sgd_solver.cpp:106] Iteration 2870, lr = 0.0005
I0403 03:24:26.809165 32199 solver.cpp:228] Iteration 2880, loss = 0.00233951
I0403 03:24:26.815948 32199 solver.cpp:244]     Train net output #0: loss = 0.00233956 (* 1 = 0.00233956 loss)
I0403 03:24:26.997479 32199 sgd_solver.cpp:106] Iteration 2880, lr = 0.0005
I0403 03:24:34.103884 32199 solver.cpp:228] Iteration 2890, loss = 0.00873317
I0403 03:24:34.112653 32199 solver.cpp:244]     Train net output #0: loss = 0.00873323 (* 1 = 0.00873323 loss)
I0403 03:24:34.282193 32199 sgd_solver.cpp:106] Iteration 2890, lr = 0.0005
I0403 03:24:41.596465 32199 solver.cpp:228] Iteration 2900, loss = 0.0136383
I0403 03:24:41.603391 32199 solver.cpp:244]     Train net output #0: loss = 0.0136384 (* 1 = 0.0136384 loss)
I0403 03:24:41.768223 32199 sgd_solver.cpp:106] Iteration 2900, lr = 0.0005
I0403 03:24:48.933070 32199 solver.cpp:228] Iteration 2910, loss = 0.00135008
I0403 03:24:48.939828 32199 solver.cpp:244]     Train net output #0: loss = 0.00135013 (* 1 = 0.00135013 loss)
I0403 03:24:49.111477 32199 sgd_solver.cpp:106] Iteration 2910, lr = 0.0005
I0403 03:24:56.163656 32199 solver.cpp:228] Iteration 2920, loss = 0.021511
I0403 03:24:56.171078 32199 solver.cpp:244]     Train net output #0: loss = 0.021511 (* 1 = 0.021511 loss)
I0403 03:24:56.360636 32199 sgd_solver.cpp:106] Iteration 2920, lr = 0.0005
I0403 03:25:03.527627 32199 solver.cpp:228] Iteration 2930, loss = 0.00753547
I0403 03:25:03.534373 32199 solver.cpp:244]     Train net output #0: loss = 0.00753553 (* 1 = 0.00753553 loss)
I0403 03:25:03.724445 32199 sgd_solver.cpp:106] Iteration 2930, lr = 0.0005
I0403 03:25:10.817232 32199 solver.cpp:228] Iteration 2940, loss = 0.0271756
I0403 03:25:10.823729 32199 solver.cpp:244]     Train net output #0: loss = 0.0271757 (* 1 = 0.0271757 loss)
I0403 03:25:10.991778 32199 sgd_solver.cpp:106] Iteration 2940, lr = 0.0005
I0403 03:25:18.110240 32199 solver.cpp:228] Iteration 2950, loss = 0.00320202
I0403 03:25:18.116475 32199 solver.cpp:244]     Train net output #0: loss = 0.00320208 (* 1 = 0.00320208 loss)
I0403 03:25:18.269543 32199 sgd_solver.cpp:106] Iteration 2950, lr = 0.0005
I0403 03:25:25.654433 32199 solver.cpp:228] Iteration 2960, loss = 0.00196342
I0403 03:25:25.661216 32199 solver.cpp:244]     Train net output #0: loss = 0.00196348 (* 1 = 0.00196348 loss)
I0403 03:25:25.827592 32199 sgd_solver.cpp:106] Iteration 2960, lr = 0.0005
I0403 03:25:33.042928 32199 solver.cpp:228] Iteration 2970, loss = 0.00197376
I0403 03:25:33.049723 32199 solver.cpp:244]     Train net output #0: loss = 0.00197381 (* 1 = 0.00197381 loss)
I0403 03:25:33.215728 32199 sgd_solver.cpp:106] Iteration 2970, lr = 0.0005
I0403 03:25:40.373801 32199 solver.cpp:228] Iteration 2980, loss = 0.00738982
I0403 03:25:40.379801 32199 solver.cpp:244]     Train net output #0: loss = 0.00738988 (* 1 = 0.00738988 loss)
I0403 03:25:40.557811 32199 sgd_solver.cpp:106] Iteration 2980, lr = 0.0005
I0403 03:25:47.631211 32199 solver.cpp:228] Iteration 2990, loss = 0.0177396
I0403 03:25:47.637608 32199 solver.cpp:244]     Train net output #0: loss = 0.0177396 (* 1 = 0.0177396 loss)
I0403 03:25:47.800722 32199 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 03:25:54.991964 32199 solver.cpp:228] Iteration 3000, loss = 0.00268158
I0403 03:25:54.999379 32199 solver.cpp:244]     Train net output #0: loss = 0.00268163 (* 1 = 0.00268163 loss)
I0403 03:25:55.221549 32199 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0403 03:26:02.360117 32199 solver.cpp:228] Iteration 3010, loss = 0.00987891
I0403 03:26:02.366420 32199 solver.cpp:244]     Train net output #0: loss = 0.00987897 (* 1 = 0.00987897 loss)
I0403 03:26:02.544533 32199 sgd_solver.cpp:106] Iteration 3010, lr = 0.0005
I0403 03:26:09.762267 32199 solver.cpp:228] Iteration 3020, loss = 0.00519968
I0403 03:26:09.767827 32199 solver.cpp:244]     Train net output #0: loss = 0.00519973 (* 1 = 0.00519973 loss)
I0403 03:26:09.940330 32199 sgd_solver.cpp:106] Iteration 3020, lr = 0.0005
I0403 03:26:17.274195 32199 solver.cpp:228] Iteration 3030, loss = 0.0199395
I0403 03:26:17.281339 32199 solver.cpp:244]     Train net output #0: loss = 0.0199396 (* 1 = 0.0199396 loss)
I0403 03:26:17.451045 32199 sgd_solver.cpp:106] Iteration 3030, lr = 0.0005
I0403 03:26:24.714089 32199 solver.cpp:228] Iteration 3040, loss = 0.0616931
I0403 03:26:24.720073 32199 solver.cpp:244]     Train net output #0: loss = 0.0616931 (* 1 = 0.0616931 loss)
I0403 03:26:24.915846 32199 sgd_solver.cpp:106] Iteration 3040, lr = 0.0005
I0403 03:26:32.052404 32199 solver.cpp:228] Iteration 3050, loss = 0.00037631
I0403 03:26:32.058375 32199 solver.cpp:244]     Train net output #0: loss = 0.000376369 (* 1 = 0.000376369 loss)
I0403 03:26:32.246462 32199 sgd_solver.cpp:106] Iteration 3050, lr = 0.0005
I0403 03:26:39.471556 32199 solver.cpp:228] Iteration 3060, loss = 0.019457
I0403 03:26:39.477612 32199 solver.cpp:244]     Train net output #0: loss = 0.0194571 (* 1 = 0.0194571 loss)
I0403 03:26:39.633853 32199 sgd_solver.cpp:106] Iteration 3060, lr = 0.0005
I0403 03:26:43.255754 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3066.caffemodel
I0403 03:26:46.044301 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3066.solverstate
I0403 03:26:47.967800 32199 solver.cpp:337] Iteration 3066, Testing net (#0)
I0403 03:28:01.742053 32199 solver.cpp:404]     Test net output #0: accuracy = 0.955821
I0403 03:28:01.747380 32199 solver.cpp:404]     Test net output #1: loss = 0.163849 (* 1 = 0.163849 loss)
I0403 03:28:05.191923 32199 solver.cpp:228] Iteration 3070, loss = 0.00536182
I0403 03:28:05.198510 32199 solver.cpp:244]     Train net output #0: loss = 0.00536188 (* 1 = 0.00536188 loss)
I0403 03:28:05.361158 32199 sgd_solver.cpp:106] Iteration 3070, lr = 0.0005
I0403 03:28:12.461851 32199 solver.cpp:228] Iteration 3080, loss = 0.00826387
I0403 03:28:12.470309 32199 solver.cpp:244]     Train net output #0: loss = 0.00826393 (* 1 = 0.00826393 loss)
I0403 03:28:12.647436 32199 sgd_solver.cpp:106] Iteration 3080, lr = 0.0005
I0403 03:28:19.681527 32199 solver.cpp:228] Iteration 3090, loss = 0.00382326
I0403 03:28:19.688935 32199 solver.cpp:244]     Train net output #0: loss = 0.00382332 (* 1 = 0.00382332 loss)
I0403 03:28:19.864631 32199 sgd_solver.cpp:106] Iteration 3090, lr = 0.0005
I0403 03:28:26.952239 32199 solver.cpp:228] Iteration 3100, loss = 0.0180641
I0403 03:28:26.957764 32199 solver.cpp:244]     Train net output #0: loss = 0.0180641 (* 1 = 0.0180641 loss)
I0403 03:28:27.153990 32199 sgd_solver.cpp:106] Iteration 3100, lr = 0.0005
I0403 03:28:34.333125 32199 solver.cpp:228] Iteration 3110, loss = 0.00423141
I0403 03:28:34.340605 32199 solver.cpp:244]     Train net output #0: loss = 0.00423147 (* 1 = 0.00423147 loss)
I0403 03:28:34.516510 32199 sgd_solver.cpp:106] Iteration 3110, lr = 0.0005
I0403 03:28:41.630614 32199 solver.cpp:228] Iteration 3120, loss = 0.00505824
I0403 03:28:41.637342 32199 solver.cpp:244]     Train net output #0: loss = 0.00505829 (* 1 = 0.00505829 loss)
I0403 03:28:41.811342 32199 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 03:28:49.215855 32199 solver.cpp:228] Iteration 3130, loss = 0.0108591
I0403 03:28:49.222012 32199 solver.cpp:244]     Train net output #0: loss = 0.0108591 (* 1 = 0.0108591 loss)
I0403 03:28:49.399416 32199 sgd_solver.cpp:106] Iteration 3130, lr = 0.0005
I0403 03:28:56.518327 32199 solver.cpp:228] Iteration 3140, loss = 0.00541834
I0403 03:28:56.525569 32199 solver.cpp:244]     Train net output #0: loss = 0.0054184 (* 1 = 0.0054184 loss)
I0403 03:28:56.718955 32199 sgd_solver.cpp:106] Iteration 3140, lr = 0.0005
I0403 03:29:03.772727 32199 solver.cpp:228] Iteration 3150, loss = 0.00143068
I0403 03:29:03.778683 32199 solver.cpp:244]     Train net output #0: loss = 0.00143074 (* 1 = 0.00143074 loss)
I0403 03:29:03.948324 32199 sgd_solver.cpp:106] Iteration 3150, lr = 0.0005
I0403 03:29:11.157387 32199 solver.cpp:228] Iteration 3160, loss = 0.00494032
I0403 03:29:11.185331 32199 solver.cpp:244]     Train net output #0: loss = 0.00494038 (* 1 = 0.00494038 loss)
I0403 03:29:11.313771 32199 sgd_solver.cpp:106] Iteration 3160, lr = 0.0005
I0403 03:29:18.726508 32199 solver.cpp:228] Iteration 3170, loss = 0.00164288
I0403 03:29:18.733417 32199 solver.cpp:244]     Train net output #0: loss = 0.00164294 (* 1 = 0.00164294 loss)
I0403 03:29:18.912206 32199 sgd_solver.cpp:106] Iteration 3170, lr = 0.0005
I0403 03:29:26.034320 32199 solver.cpp:228] Iteration 3180, loss = 0.00201821
I0403 03:29:26.045856 32199 solver.cpp:244]     Train net output #0: loss = 0.00201827 (* 1 = 0.00201827 loss)
I0403 03:29:26.225955 32199 sgd_solver.cpp:106] Iteration 3180, lr = 0.0005
I0403 03:29:33.453297 32199 solver.cpp:228] Iteration 3190, loss = 0.00183377
I0403 03:29:33.459830 32199 solver.cpp:244]     Train net output #0: loss = 0.00183383 (* 1 = 0.00183383 loss)
I0403 03:29:33.651607 32199 sgd_solver.cpp:106] Iteration 3190, lr = 0.0005
I0403 03:29:40.795152 32199 solver.cpp:228] Iteration 3200, loss = 0.0435521
I0403 03:29:40.802027 32199 solver.cpp:244]     Train net output #0: loss = 0.0435522 (* 1 = 0.0435522 loss)
I0403 03:29:40.958272 32199 sgd_solver.cpp:106] Iteration 3200, lr = 0.0005
I0403 03:29:48.246481 32199 solver.cpp:228] Iteration 3210, loss = 0.00283967
I0403 03:29:48.252521 32199 solver.cpp:244]     Train net output #0: loss = 0.00283973 (* 1 = 0.00283973 loss)
I0403 03:29:48.419837 32199 sgd_solver.cpp:106] Iteration 3210, lr = 0.0005
I0403 03:29:55.479022 32199 solver.cpp:228] Iteration 3220, loss = 0.000747912
I0403 03:29:55.483705 32199 solver.cpp:244]     Train net output #0: loss = 0.00074797 (* 1 = 0.00074797 loss)
I0403 03:29:55.659543 32199 sgd_solver.cpp:106] Iteration 3220, lr = 0.0005
I0403 03:30:02.925415 32199 solver.cpp:228] Iteration 3230, loss = 0.00107474
I0403 03:30:02.940603 32199 solver.cpp:244]     Train net output #0: loss = 0.0010748 (* 1 = 0.0010748 loss)
I0403 03:30:03.113715 32199 sgd_solver.cpp:106] Iteration 3230, lr = 0.0005
I0403 03:30:10.267117 32199 solver.cpp:228] Iteration 3240, loss = 0.00796201
I0403 03:30:10.275686 32199 solver.cpp:244]     Train net output #0: loss = 0.00796207 (* 1 = 0.00796207 loss)
I0403 03:30:10.417889 32199 sgd_solver.cpp:106] Iteration 3240, lr = 0.0005
I0403 03:30:17.606899 32199 solver.cpp:228] Iteration 3250, loss = 0.0024711
I0403 03:30:17.614769 32199 solver.cpp:244]     Train net output #0: loss = 0.00247116 (* 1 = 0.00247116 loss)
I0403 03:30:17.789213 32199 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 03:30:24.856540 32199 solver.cpp:228] Iteration 3260, loss = 0.00455504
I0403 03:30:24.862802 32199 solver.cpp:244]     Train net output #0: loss = 0.0045551 (* 1 = 0.0045551 loss)
I0403 03:30:25.031193 32199 sgd_solver.cpp:106] Iteration 3260, lr = 0.0005
I0403 03:30:32.258481 32199 solver.cpp:228] Iteration 3270, loss = 0.00576818
I0403 03:30:32.265156 32199 solver.cpp:244]     Train net output #0: loss = 0.00576824 (* 1 = 0.00576824 loss)
I0403 03:30:32.434404 32199 sgd_solver.cpp:106] Iteration 3270, lr = 0.0005
I0403 03:30:39.553992 32199 solver.cpp:228] Iteration 3280, loss = 0.00667662
I0403 03:30:39.560776 32199 solver.cpp:244]     Train net output #0: loss = 0.00667667 (* 1 = 0.00667667 loss)
I0403 03:30:39.760260 32199 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 03:30:42.661594 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3285.caffemodel
I0403 03:30:45.413854 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3285.solverstate
I0403 03:30:47.349541 32199 solver.cpp:337] Iteration 3285, Testing net (#0)
I0403 03:32:01.158485 32199 solver.cpp:404]     Test net output #0: accuracy = 0.956904
I0403 03:32:01.165117 32199 solver.cpp:404]     Test net output #1: loss = 0.159457 (* 1 = 0.159457 loss)
I0403 03:32:05.420344 32199 solver.cpp:228] Iteration 3290, loss = 0.00294998
I0403 03:32:05.428218 32199 solver.cpp:244]     Train net output #0: loss = 0.00295003 (* 1 = 0.00295003 loss)
I0403 03:32:05.610419 32199 sgd_solver.cpp:106] Iteration 3290, lr = 0.0005
I0403 03:32:12.811058 32199 solver.cpp:228] Iteration 3300, loss = 0.0177329
I0403 03:32:12.818426 32199 solver.cpp:244]     Train net output #0: loss = 0.017733 (* 1 = 0.017733 loss)
I0403 03:32:12.988191 32199 sgd_solver.cpp:106] Iteration 3300, lr = 0.0005
I0403 03:32:20.067009 32199 solver.cpp:228] Iteration 3310, loss = 0.00890712
I0403 03:32:20.073148 32199 solver.cpp:244]     Train net output #0: loss = 0.00890718 (* 1 = 0.00890718 loss)
I0403 03:32:20.242184 32199 sgd_solver.cpp:106] Iteration 3310, lr = 0.0005
I0403 03:32:27.417970 32199 solver.cpp:228] Iteration 3320, loss = 0.00193845
I0403 03:32:27.424675 32199 solver.cpp:244]     Train net output #0: loss = 0.0019385 (* 1 = 0.0019385 loss)
I0403 03:32:27.602571 32199 sgd_solver.cpp:106] Iteration 3320, lr = 0.0005
I0403 03:32:34.725263 32199 solver.cpp:228] Iteration 3330, loss = 0.000304322
I0403 03:32:34.731564 32199 solver.cpp:244]     Train net output #0: loss = 0.000304374 (* 1 = 0.000304374 loss)
I0403 03:32:34.914063 32199 sgd_solver.cpp:106] Iteration 3330, lr = 0.0005
I0403 03:32:42.197363 32199 solver.cpp:228] Iteration 3340, loss = 0.0313813
I0403 03:32:42.204279 32199 solver.cpp:244]     Train net output #0: loss = 0.0313814 (* 1 = 0.0313814 loss)
I0403 03:32:42.361663 32199 sgd_solver.cpp:106] Iteration 3340, lr = 0.0005
I0403 03:32:49.481796 32199 solver.cpp:228] Iteration 3350, loss = 0.00303632
I0403 03:32:49.488435 32199 solver.cpp:244]     Train net output #0: loss = 0.00303637 (* 1 = 0.00303637 loss)
I0403 03:32:49.668756 32199 sgd_solver.cpp:106] Iteration 3350, lr = 0.0005
I0403 03:32:56.946836 32199 solver.cpp:228] Iteration 3360, loss = 0.00273501
I0403 03:32:56.953825 32199 solver.cpp:244]     Train net output #0: loss = 0.00273506 (* 1 = 0.00273506 loss)
I0403 03:32:57.147658 32199 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 03:33:04.331013 32199 solver.cpp:228] Iteration 3370, loss = 0.00439598
I0403 03:33:04.338945 32199 solver.cpp:244]     Train net output #0: loss = 0.00439603 (* 1 = 0.00439603 loss)
I0403 03:33:04.501871 32199 sgd_solver.cpp:106] Iteration 3370, lr = 0.0005
I0403 03:33:11.695591 32199 solver.cpp:228] Iteration 3380, loss = 0.00334537
I0403 03:33:11.703169 32199 solver.cpp:244]     Train net output #0: loss = 0.00334542 (* 1 = 0.00334542 loss)
I0403 03:33:11.900938 32199 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 03:33:18.980717 32199 solver.cpp:228] Iteration 3390, loss = 0.00807721
I0403 03:33:18.990963 32199 solver.cpp:244]     Train net output #0: loss = 0.00807726 (* 1 = 0.00807726 loss)
I0403 03:33:19.194265 32199 sgd_solver.cpp:106] Iteration 3390, lr = 0.0005
I0403 03:33:26.313367 32199 solver.cpp:228] Iteration 3400, loss = 0.00561273
I0403 03:33:26.320173 32199 solver.cpp:244]     Train net output #0: loss = 0.00561278 (* 1 = 0.00561278 loss)
I0403 03:33:26.499914 32199 sgd_solver.cpp:106] Iteration 3400, lr = 0.0005
I0403 03:33:33.670794 32199 solver.cpp:228] Iteration 3410, loss = 0.0049517
I0403 03:33:33.677021 32199 solver.cpp:244]     Train net output #0: loss = 0.00495175 (* 1 = 0.00495175 loss)
I0403 03:33:33.849169 32199 sgd_solver.cpp:106] Iteration 3410, lr = 0.0005
I0403 03:33:40.951835 32199 solver.cpp:228] Iteration 3420, loss = 0.0115348
I0403 03:33:40.958430 32199 solver.cpp:244]     Train net output #0: loss = 0.0115349 (* 1 = 0.0115349 loss)
I0403 03:33:41.126473 32199 sgd_solver.cpp:106] Iteration 3420, lr = 0.0005
I0403 03:33:48.276808 32199 solver.cpp:228] Iteration 3430, loss = 0.00318578
I0403 03:33:48.283236 32199 solver.cpp:244]     Train net output #0: loss = 0.00318584 (* 1 = 0.00318584 loss)
I0403 03:33:48.451649 32199 sgd_solver.cpp:106] Iteration 3430, lr = 0.0005
I0403 03:33:55.577175 32199 solver.cpp:228] Iteration 3440, loss = 0.00238218
I0403 03:33:55.583765 32199 solver.cpp:244]     Train net output #0: loss = 0.00238224 (* 1 = 0.00238224 loss)
I0403 03:33:55.747313 32199 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 03:34:02.883796 32199 solver.cpp:228] Iteration 3450, loss = 0.00113873
I0403 03:34:02.883901 32199 solver.cpp:244]     Train net output #0: loss = 0.00113878 (* 1 = 0.00113878 loss)
I0403 03:34:03.104723 32199 sgd_solver.cpp:106] Iteration 3450, lr = 0.0005
I0403 03:34:10.199898 32199 solver.cpp:228] Iteration 3460, loss = 0.00407222
I0403 03:34:10.199990 32199 solver.cpp:244]     Train net output #0: loss = 0.00407227 (* 1 = 0.00407227 loss)
I0403 03:34:10.354830 32199 sgd_solver.cpp:106] Iteration 3460, lr = 0.0005
I0403 03:34:17.494118 32199 solver.cpp:228] Iteration 3470, loss = 0.013806
I0403 03:34:17.494207 32199 solver.cpp:244]     Train net output #0: loss = 0.013806 (* 1 = 0.013806 loss)
I0403 03:34:17.670507 32199 sgd_solver.cpp:106] Iteration 3470, lr = 0.0005
I0403 03:34:24.752818 32199 solver.cpp:228] Iteration 3480, loss = 0.000946288
I0403 03:34:24.753118 32199 solver.cpp:244]     Train net output #0: loss = 0.000946344 (* 1 = 0.000946344 loss)
I0403 03:34:24.923640 32199 sgd_solver.cpp:106] Iteration 3480, lr = 0.0005
I0403 03:34:31.981400 32199 solver.cpp:228] Iteration 3490, loss = 0.00055966
I0403 03:34:31.981489 32199 solver.cpp:244]     Train net output #0: loss = 0.000559715 (* 1 = 0.000559715 loss)
I0403 03:34:32.153970 32199 sgd_solver.cpp:106] Iteration 3490, lr = 0.0005
I0403 03:34:39.239181 32199 solver.cpp:228] Iteration 3500, loss = 0.0130665
I0403 03:34:39.239274 32199 solver.cpp:244]     Train net output #0: loss = 0.0130666 (* 1 = 0.0130666 loss)
I0403 03:34:39.417417 32199 sgd_solver.cpp:106] Iteration 3500, lr = 0.0005
I0403 03:34:41.647896 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3504.caffemodel
I0403 03:34:44.510093 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3504.solverstate
I0403 03:34:46.409065 32199 solver.cpp:337] Iteration 3504, Testing net (#0)
I0403 03:36:00.211704 32199 solver.cpp:404]     Test net output #0: accuracy = 0.956936
I0403 03:36:00.211971 32199 solver.cpp:404]     Test net output #1: loss = 0.160641 (* 1 = 0.160641 loss)
I0403 03:36:05.293339 32199 solver.cpp:228] Iteration 3510, loss = 0.00549284
I0403 03:36:05.293450 32199 solver.cpp:244]     Train net output #0: loss = 0.0054929 (* 1 = 0.0054929 loss)
I0403 03:36:05.479562 32199 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 03:36:12.521132 32199 solver.cpp:228] Iteration 3520, loss = 0.000872772
I0403 03:36:12.521224 32199 solver.cpp:244]     Train net output #0: loss = 0.000872833 (* 1 = 0.000872833 loss)
I0403 03:36:12.699024 32199 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 03:36:19.811460 32199 solver.cpp:228] Iteration 3530, loss = 0.00837548
I0403 03:36:19.811550 32199 solver.cpp:244]     Train net output #0: loss = 0.00837554 (* 1 = 0.00837554 loss)
I0403 03:36:19.983889 32199 sgd_solver.cpp:106] Iteration 3530, lr = 0.0005
I0403 03:36:27.153022 32199 solver.cpp:228] Iteration 3540, loss = 0.00990583
I0403 03:36:27.153113 32199 solver.cpp:244]     Train net output #0: loss = 0.00990589 (* 1 = 0.00990589 loss)
I0403 03:36:27.319589 32199 sgd_solver.cpp:106] Iteration 3540, lr = 0.0005
I0403 03:36:34.455906 32199 solver.cpp:228] Iteration 3550, loss = 0.000165839
I0403 03:36:34.456238 32199 solver.cpp:244]     Train net output #0: loss = 0.000165894 (* 1 = 0.000165894 loss)
I0403 03:36:34.661001 32199 sgd_solver.cpp:106] Iteration 3550, lr = 0.0005
I0403 03:36:41.999796 32199 solver.cpp:228] Iteration 3560, loss = 0.0158824
I0403 03:36:41.999887 32199 solver.cpp:244]     Train net output #0: loss = 0.0158824 (* 1 = 0.0158824 loss)
I0403 03:36:42.167564 32199 sgd_solver.cpp:106] Iteration 3560, lr = 0.0005
I0403 03:36:49.246493 32199 solver.cpp:228] Iteration 3570, loss = 0.00101072
I0403 03:36:49.246582 32199 solver.cpp:244]     Train net output #0: loss = 0.00101077 (* 1 = 0.00101077 loss)
I0403 03:36:49.408438 32199 sgd_solver.cpp:106] Iteration 3570, lr = 0.0005
I0403 03:36:56.705935 32199 solver.cpp:228] Iteration 3580, loss = 0.019803
I0403 03:36:56.706023 32199 solver.cpp:244]     Train net output #0: loss = 0.0198031 (* 1 = 0.0198031 loss)
I0403 03:36:56.866876 32199 sgd_solver.cpp:106] Iteration 3580, lr = 0.0005
I0403 03:37:04.215086 32199 solver.cpp:228] Iteration 3590, loss = 0.00922833
I0403 03:37:04.215175 32199 solver.cpp:244]     Train net output #0: loss = 0.00922838 (* 1 = 0.00922838 loss)
I0403 03:37:04.394788 32199 sgd_solver.cpp:106] Iteration 3590, lr = 0.0005
I0403 03:37:11.566952 32199 solver.cpp:228] Iteration 3600, loss = 0.00126941
I0403 03:37:11.567258 32199 solver.cpp:244]     Train net output #0: loss = 0.00126946 (* 1 = 0.00126946 loss)
I0403 03:37:11.750504 32199 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 03:37:18.945153 32199 solver.cpp:228] Iteration 3610, loss = 0.00169529
I0403 03:37:18.945260 32199 solver.cpp:244]     Train net output #0: loss = 0.00169535 (* 1 = 0.00169535 loss)
I0403 03:37:19.150224 32199 sgd_solver.cpp:106] Iteration 3610, lr = 0.0005
I0403 03:37:26.270277 32199 solver.cpp:228] Iteration 3620, loss = 0.00109394
I0403 03:37:26.270390 32199 solver.cpp:244]     Train net output #0: loss = 0.00109399 (* 1 = 0.00109399 loss)
I0403 03:37:26.454736 32199 sgd_solver.cpp:106] Iteration 3620, lr = 0.0005
I0403 03:37:33.776195 32199 solver.cpp:228] Iteration 3630, loss = 0.0220352
I0403 03:37:33.776296 32199 solver.cpp:244]     Train net output #0: loss = 0.0220353 (* 1 = 0.0220353 loss)
I0403 03:37:33.965246 32199 sgd_solver.cpp:106] Iteration 3630, lr = 0.0005
I0403 03:37:41.360755 32199 solver.cpp:228] Iteration 3640, loss = 0.00495466
I0403 03:37:41.360844 32199 solver.cpp:244]     Train net output #0: loss = 0.00495472 (* 1 = 0.00495472 loss)
I0403 03:37:41.537811 32199 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 03:37:48.676890 32199 solver.cpp:228] Iteration 3650, loss = 0.00217873
I0403 03:37:48.677211 32199 solver.cpp:244]     Train net output #0: loss = 0.00217879 (* 1 = 0.00217879 loss)
I0403 03:37:48.867408 32199 sgd_solver.cpp:106] Iteration 3650, lr = 0.0005
I0403 03:37:55.923846 32199 solver.cpp:228] Iteration 3660, loss = 0.00326519
I0403 03:37:55.923939 32199 solver.cpp:244]     Train net output #0: loss = 0.00326525 (* 1 = 0.00326525 loss)
I0403 03:37:56.098707 32199 sgd_solver.cpp:106] Iteration 3660, lr = 0.0005
I0403 03:38:03.289952 32199 solver.cpp:228] Iteration 3670, loss = 0.00380782
I0403 03:38:03.290045 32199 solver.cpp:244]     Train net output #0: loss = 0.00380787 (* 1 = 0.00380787 loss)
I0403 03:38:03.468675 32199 sgd_solver.cpp:106] Iteration 3670, lr = 0.0005
I0403 03:38:10.585494 32199 solver.cpp:228] Iteration 3680, loss = 0.00495107
I0403 03:38:10.585593 32199 solver.cpp:244]     Train net output #0: loss = 0.00495113 (* 1 = 0.00495113 loss)
I0403 03:38:10.779609 32199 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 03:38:17.796649 32199 solver.cpp:228] Iteration 3690, loss = 0.00258981
I0403 03:38:17.796739 32199 solver.cpp:244]     Train net output #0: loss = 0.00258987 (* 1 = 0.00258987 loss)
I0403 03:38:17.974388 32199 sgd_solver.cpp:106] Iteration 3690, lr = 0.0005
I0403 03:38:25.136111 32199 solver.cpp:228] Iteration 3700, loss = 0.013168
I0403 03:38:25.136437 32199 solver.cpp:244]     Train net output #0: loss = 0.013168 (* 1 = 0.013168 loss)
I0403 03:38:25.323729 32199 sgd_solver.cpp:106] Iteration 3700, lr = 0.0005
I0403 03:38:32.441115 32199 solver.cpp:228] Iteration 3710, loss = 0.00203417
I0403 03:38:32.441202 32199 solver.cpp:244]     Train net output #0: loss = 0.00203423 (* 1 = 0.00203423 loss)
I0403 03:38:32.615547 32199 sgd_solver.cpp:106] Iteration 3710, lr = 0.0005
I0403 03:38:39.716217 32199 solver.cpp:228] Iteration 3720, loss = 0.00232849
I0403 03:38:39.716305 32199 solver.cpp:244]     Train net output #0: loss = 0.00232854 (* 1 = 0.00232854 loss)
I0403 03:38:39.893519 32199 sgd_solver.cpp:106] Iteration 3720, lr = 0.0005
I0403 03:38:41.354971 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3723.caffemodel
I0403 03:38:44.119837 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3723.solverstate
I0403 03:38:46.035434 32199 solver.cpp:337] Iteration 3723, Testing net (#0)
I0403 03:39:59.821799 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958081
I0403 03:39:59.822149 32199 solver.cpp:404]     Test net output #1: loss = 0.157745 (* 1 = 0.157745 loss)
I0403 03:40:05.456218 32199 solver.cpp:228] Iteration 3730, loss = 0.0148078
I0403 03:40:05.456306 32199 solver.cpp:244]     Train net output #0: loss = 0.0148079 (* 1 = 0.0148079 loss)
I0403 03:40:05.634328 32199 sgd_solver.cpp:106] Iteration 3730, lr = 0.0005
I0403 03:40:12.849756 32199 solver.cpp:228] Iteration 3740, loss = 0.000608635
I0403 03:40:12.849849 32199 solver.cpp:244]     Train net output #0: loss = 0.00060869 (* 1 = 0.00060869 loss)
I0403 03:40:13.026842 32199 sgd_solver.cpp:106] Iteration 3740, lr = 0.0005
I0403 03:40:20.203382 32199 solver.cpp:228] Iteration 3750, loss = 0.0130255
I0403 03:40:20.203472 32199 solver.cpp:244]     Train net output #0: loss = 0.0130256 (* 1 = 0.0130256 loss)
I0403 03:40:20.373530 32199 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0403 03:40:27.686523 32199 solver.cpp:228] Iteration 3760, loss = 0.000749283
I0403 03:40:27.686625 32199 solver.cpp:244]     Train net output #0: loss = 0.000749346 (* 1 = 0.000749346 loss)
I0403 03:40:27.873744 32199 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 03:40:35.054975 32199 solver.cpp:228] Iteration 3770, loss = 0.0391568
I0403 03:40:35.055294 32199 solver.cpp:244]     Train net output #0: loss = 0.0391568 (* 1 = 0.0391568 loss)
I0403 03:40:35.244276 32199 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 03:40:42.272964 32199 solver.cpp:228] Iteration 3780, loss = 0.00215517
I0403 03:40:42.273067 32199 solver.cpp:244]     Train net output #0: loss = 0.00215523 (* 1 = 0.00215523 loss)
I0403 03:40:42.462426 32199 sgd_solver.cpp:106] Iteration 3780, lr = 0.0005
I0403 03:40:49.582094 32199 solver.cpp:228] Iteration 3790, loss = 0.00392721
I0403 03:40:49.582200 32199 solver.cpp:244]     Train net output #0: loss = 0.00392727 (* 1 = 0.00392727 loss)
I0403 03:40:49.836030 32199 sgd_solver.cpp:106] Iteration 3790, lr = 0.0005
I0403 03:40:56.980911 32199 solver.cpp:228] Iteration 3800, loss = 0.00308685
I0403 03:40:56.980999 32199 solver.cpp:244]     Train net output #0: loss = 0.00308691 (* 1 = 0.00308691 loss)
I0403 03:40:57.148705 32199 sgd_solver.cpp:106] Iteration 3800, lr = 0.0005
I0403 03:41:04.330265 32199 solver.cpp:228] Iteration 3810, loss = 0.00556186
I0403 03:41:04.330359 32199 solver.cpp:244]     Train net output #0: loss = 0.00556192 (* 1 = 0.00556192 loss)
I0403 03:41:04.499802 32199 sgd_solver.cpp:106] Iteration 3810, lr = 0.0005
I0403 03:41:11.614943 32199 solver.cpp:228] Iteration 3820, loss = 0.000852171
I0403 03:41:11.615569 32199 solver.cpp:244]     Train net output #0: loss = 0.000852233 (* 1 = 0.000852233 loss)
I0403 03:41:11.844240 32199 sgd_solver.cpp:106] Iteration 3820, lr = 0.0005
I0403 03:41:19.031087 32199 solver.cpp:228] Iteration 3830, loss = 0.0278018
I0403 03:41:19.031194 32199 solver.cpp:244]     Train net output #0: loss = 0.0278018 (* 1 = 0.0278018 loss)
I0403 03:41:19.217797 32199 sgd_solver.cpp:106] Iteration 3830, lr = 0.0005
I0403 03:41:26.399319 32199 solver.cpp:228] Iteration 3840, loss = 0.00531147
I0403 03:41:26.399427 32199 solver.cpp:244]     Train net output #0: loss = 0.00531153 (* 1 = 0.00531153 loss)
I0403 03:41:26.598016 32199 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 03:41:33.737257 32199 solver.cpp:228] Iteration 3850, loss = 0.00350096
I0403 03:41:33.737346 32199 solver.cpp:244]     Train net output #0: loss = 0.00350102 (* 1 = 0.00350102 loss)
I0403 03:41:33.855357 32199 sgd_solver.cpp:106] Iteration 3850, lr = 0.0005
I0403 03:41:41.203953 32199 solver.cpp:228] Iteration 3860, loss = 0.013621
I0403 03:41:41.204041 32199 solver.cpp:244]     Train net output #0: loss = 0.0136211 (* 1 = 0.0136211 loss)
I0403 03:41:41.371016 32199 sgd_solver.cpp:106] Iteration 3860, lr = 0.0005
I0403 03:41:48.509039 32199 solver.cpp:228] Iteration 3870, loss = 0.000686601
I0403 03:41:48.509359 32199 solver.cpp:244]     Train net output #0: loss = 0.000686659 (* 1 = 0.000686659 loss)
I0403 03:41:48.659271 32199 sgd_solver.cpp:106] Iteration 3870, lr = 0.0005
I0403 03:41:55.866366 32199 solver.cpp:228] Iteration 3880, loss = 0.0495926
I0403 03:41:55.866480 32199 solver.cpp:244]     Train net output #0: loss = 0.0495927 (* 1 = 0.0495927 loss)
I0403 03:41:56.060864 32199 sgd_solver.cpp:106] Iteration 3880, lr = 0.0005
I0403 03:42:03.278080 32199 solver.cpp:228] Iteration 3890, loss = 0.00204712
I0403 03:42:03.278177 32199 solver.cpp:244]     Train net output #0: loss = 0.00204718 (* 1 = 0.00204718 loss)
I0403 03:42:03.416755 32199 sgd_solver.cpp:106] Iteration 3890, lr = 0.0005
I0403 03:42:10.596580 32199 solver.cpp:228] Iteration 3900, loss = 0.0115971
I0403 03:42:10.596681 32199 solver.cpp:244]     Train net output #0: loss = 0.0115972 (* 1 = 0.0115972 loss)
I0403 03:42:10.815304 32199 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 03:42:17.875511 32199 solver.cpp:228] Iteration 3910, loss = 0.0129252
I0403 03:42:17.875600 32199 solver.cpp:244]     Train net output #0: loss = 0.0129252 (* 1 = 0.0129252 loss)
I0403 03:42:18.057387 32199 sgd_solver.cpp:106] Iteration 3910, lr = 0.0005
I0403 03:42:25.246083 32199 solver.cpp:228] Iteration 3920, loss = 0.00499546
I0403 03:42:25.246415 32199 solver.cpp:244]     Train net output #0: loss = 0.00499552 (* 1 = 0.00499552 loss)
I0403 03:42:25.429936 32199 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 03:42:32.716567 32199 solver.cpp:228] Iteration 3930, loss = 0.00695457
I0403 03:42:32.716667 32199 solver.cpp:244]     Train net output #0: loss = 0.00695462 (* 1 = 0.00695462 loss)
I0403 03:42:32.909751 32199 sgd_solver.cpp:106] Iteration 3930, lr = 0.0005
I0403 03:42:40.114270 32199 solver.cpp:228] Iteration 3940, loss = 0.00175967
I0403 03:42:40.114384 32199 solver.cpp:244]     Train net output #0: loss = 0.00175972 (* 1 = 0.00175972 loss)
I0403 03:42:40.315724 32199 sgd_solver.cpp:106] Iteration 3940, lr = 0.0005
I0403 03:42:41.020931 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3942.caffemodel
I0403 03:42:43.816658 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_3942.solverstate
I0403 03:42:45.709481 32199 solver.cpp:337] Iteration 3942, Testing net (#0)
I0403 03:43:59.491828 32199 solver.cpp:404]     Test net output #0: accuracy = 0.956781
I0403 03:43:59.492146 32199 solver.cpp:404]     Test net output #1: loss = 0.166368 (* 1 = 0.166368 loss)
I0403 03:44:05.904009 32199 solver.cpp:228] Iteration 3950, loss = 0.00225332
I0403 03:44:05.904111 32199 solver.cpp:244]     Train net output #0: loss = 0.00225338 (* 1 = 0.00225338 loss)
I0403 03:44:06.089771 32199 sgd_solver.cpp:106] Iteration 3950, lr = 0.0005
I0403 03:44:13.244652 32199 solver.cpp:228] Iteration 3960, loss = 0.000422748
I0403 03:44:13.244756 32199 solver.cpp:244]     Train net output #0: loss = 0.000422807 (* 1 = 0.000422807 loss)
I0403 03:44:13.429214 32199 sgd_solver.cpp:106] Iteration 3960, lr = 0.0005
I0403 03:44:20.490131 32199 solver.cpp:228] Iteration 3970, loss = 0.020176
I0403 03:44:20.490236 32199 solver.cpp:244]     Train net output #0: loss = 0.0201761 (* 1 = 0.0201761 loss)
I0403 03:44:20.673694 32199 sgd_solver.cpp:106] Iteration 3970, lr = 0.0005
I0403 03:44:27.839679 32199 solver.cpp:228] Iteration 3980, loss = 0.00494253
I0403 03:44:27.839779 32199 solver.cpp:244]     Train net output #0: loss = 0.00494259 (* 1 = 0.00494259 loss)
I0403 03:44:28.092388 32199 sgd_solver.cpp:106] Iteration 3980, lr = 0.0005
I0403 03:44:35.346606 32199 solver.cpp:228] Iteration 3990, loss = 0.00690523
I0403 03:44:35.346964 32199 solver.cpp:244]     Train net output #0: loss = 0.00690529 (* 1 = 0.00690529 loss)
I0403 03:44:35.530138 32199 sgd_solver.cpp:106] Iteration 3990, lr = 0.0005
I0403 03:44:42.661957 32199 solver.cpp:228] Iteration 4000, loss = 0.00594501
I0403 03:44:42.662056 32199 solver.cpp:244]     Train net output #0: loss = 0.00594507 (* 1 = 0.00594507 loss)
I0403 03:44:42.845604 32199 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 03:44:49.953668 32199 solver.cpp:228] Iteration 4010, loss = 0.00324398
I0403 03:44:49.953770 32199 solver.cpp:244]     Train net output #0: loss = 0.00324404 (* 1 = 0.00324404 loss)
I0403 03:44:50.151669 32199 sgd_solver.cpp:106] Iteration 4010, lr = 0.0005
I0403 03:44:57.241736 32199 solver.cpp:228] Iteration 4020, loss = 0.00340247
I0403 03:44:57.241838 32199 solver.cpp:244]     Train net output #0: loss = 0.00340253 (* 1 = 0.00340253 loss)
I0403 03:44:57.427616 32199 sgd_solver.cpp:106] Iteration 4020, lr = 0.0005
I0403 03:45:04.598222 32199 solver.cpp:228] Iteration 4030, loss = 0.0181458
I0403 03:45:04.598331 32199 solver.cpp:244]     Train net output #0: loss = 0.0181458 (* 1 = 0.0181458 loss)
I0403 03:45:04.816471 32199 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 03:45:11.979893 32199 solver.cpp:228] Iteration 4040, loss = 0.00130221
I0403 03:45:11.980212 32199 solver.cpp:244]     Train net output #0: loss = 0.00130227 (* 1 = 0.00130227 loss)
I0403 03:45:12.158146 32199 sgd_solver.cpp:106] Iteration 4040, lr = 0.0005
I0403 03:45:19.326297 32199 solver.cpp:228] Iteration 4050, loss = 0.00120922
I0403 03:45:19.326391 32199 solver.cpp:244]     Train net output #0: loss = 0.00120928 (* 1 = 0.00120928 loss)
I0403 03:45:19.492009 32199 sgd_solver.cpp:106] Iteration 4050, lr = 0.0005
I0403 03:45:26.711655 32199 solver.cpp:228] Iteration 4060, loss = 0.000922575
I0403 03:45:26.711740 32199 solver.cpp:244]     Train net output #0: loss = 0.000922635 (* 1 = 0.000922635 loss)
I0403 03:45:26.880630 32199 sgd_solver.cpp:106] Iteration 4060, lr = 0.0005
I0403 03:45:34.093600 32199 solver.cpp:228] Iteration 4070, loss = 0.00503182
I0403 03:45:34.093710 32199 solver.cpp:244]     Train net output #0: loss = 0.00503188 (* 1 = 0.00503188 loss)
I0403 03:45:34.277384 32199 sgd_solver.cpp:106] Iteration 4070, lr = 0.0005
I0403 03:45:41.492810 32199 solver.cpp:228] Iteration 4080, loss = 0.00550605
I0403 03:45:41.492911 32199 solver.cpp:244]     Train net output #0: loss = 0.00550611 (* 1 = 0.00550611 loss)
I0403 03:45:41.684914 32199 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 03:45:49.034744 32199 solver.cpp:228] Iteration 4090, loss = 0.00394599
I0403 03:45:49.035063 32199 solver.cpp:244]     Train net output #0: loss = 0.00394605 (* 1 = 0.00394605 loss)
I0403 03:45:49.272114 32199 sgd_solver.cpp:106] Iteration 4090, lr = 0.0005
I0403 03:45:56.403517 32199 solver.cpp:228] Iteration 4100, loss = 0.0163527
I0403 03:45:56.403609 32199 solver.cpp:244]     Train net output #0: loss = 0.0163528 (* 1 = 0.0163528 loss)
I0403 03:45:56.571748 32199 sgd_solver.cpp:106] Iteration 4100, lr = 0.0005
I0403 03:46:03.684177 32199 solver.cpp:228] Iteration 4110, loss = 0.0162346
I0403 03:46:03.684268 32199 solver.cpp:244]     Train net output #0: loss = 0.0162347 (* 1 = 0.0162347 loss)
I0403 03:46:03.861510 32199 sgd_solver.cpp:106] Iteration 4110, lr = 0.0005
I0403 03:46:10.935969 32199 solver.cpp:228] Iteration 4120, loss = 0.00642033
I0403 03:46:10.936074 32199 solver.cpp:244]     Train net output #0: loss = 0.00642039 (* 1 = 0.00642039 loss)
I0403 03:46:11.161764 32199 sgd_solver.cpp:106] Iteration 4120, lr = 0.0005
I0403 03:46:18.437686 32199 solver.cpp:228] Iteration 4130, loss = 0.00357565
I0403 03:46:18.437777 32199 solver.cpp:244]     Train net output #0: loss = 0.00357572 (* 1 = 0.00357572 loss)
I0403 03:46:18.583844 32199 sgd_solver.cpp:106] Iteration 4130, lr = 0.0005
I0403 03:46:25.886008 32199 solver.cpp:228] Iteration 4140, loss = 0.00923705
I0403 03:46:25.886359 32199 solver.cpp:244]     Train net output #0: loss = 0.00923711 (* 1 = 0.00923711 loss)
I0403 03:46:26.063832 32199 sgd_solver.cpp:106] Iteration 4140, lr = 0.0005
I0403 03:46:33.316552 32199 solver.cpp:228] Iteration 4150, loss = 0.00219219
I0403 03:46:33.316642 32199 solver.cpp:244]     Train net output #0: loss = 0.00219226 (* 1 = 0.00219226 loss)
I0403 03:46:33.483008 32199 sgd_solver.cpp:106] Iteration 4150, lr = 0.0005
I0403 03:46:40.791016 32199 solver.cpp:228] Iteration 4160, loss = 0.00034314
I0403 03:46:40.791116 32199 solver.cpp:244]     Train net output #0: loss = 0.000343202 (* 1 = 0.000343202 loss)
I0403 03:46:40.987727 32199 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:46:40.987963 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4161.caffemodel
I0403 03:46:43.639313 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4161.solverstate
I0403 03:46:45.419977 32199 solver.cpp:337] Iteration 4161, Testing net (#0)
I0403 03:47:59.231067 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958143
I0403 03:47:59.231406 32199 solver.cpp:404]     Test net output #1: loss = 0.159453 (* 1 = 0.159453 loss)
I0403 03:48:06.316689 32199 solver.cpp:228] Iteration 4170, loss = 0.0029488
I0403 03:48:06.316793 32199 solver.cpp:244]     Train net output #0: loss = 0.00294886 (* 1 = 0.00294886 loss)
I0403 03:48:06.538045 32199 sgd_solver.cpp:106] Iteration 4170, lr = 0.0005
I0403 03:48:13.768652 32199 solver.cpp:228] Iteration 4180, loss = 0.0133355
I0403 03:48:13.768738 32199 solver.cpp:244]     Train net output #0: loss = 0.0133356 (* 1 = 0.0133356 loss)
I0403 03:48:13.931057 32199 sgd_solver.cpp:106] Iteration 4180, lr = 0.0005
I0403 03:48:21.100687 32199 solver.cpp:228] Iteration 4190, loss = 0.0065358
I0403 03:48:21.100780 32199 solver.cpp:244]     Train net output #0: loss = 0.00653586 (* 1 = 0.00653586 loss)
I0403 03:48:21.247040 32199 sgd_solver.cpp:106] Iteration 4190, lr = 0.0005
I0403 03:48:28.682534 32199 solver.cpp:228] Iteration 4200, loss = 0.000755652
I0403 03:48:28.682626 32199 solver.cpp:244]     Train net output #0: loss = 0.000755716 (* 1 = 0.000755716 loss)
I0403 03:48:28.849490 32199 sgd_solver.cpp:106] Iteration 4200, lr = 0.0005
I0403 03:48:35.994999 32199 solver.cpp:228] Iteration 4210, loss = 0.0316002
I0403 03:48:35.995215 32199 solver.cpp:244]     Train net output #0: loss = 0.0316003 (* 1 = 0.0316003 loss)
I0403 03:48:36.161613 32199 sgd_solver.cpp:106] Iteration 4210, lr = 0.0005
I0403 03:48:43.620002 32199 solver.cpp:228] Iteration 4220, loss = 0.00429963
I0403 03:48:43.620093 32199 solver.cpp:244]     Train net output #0: loss = 0.00429969 (* 1 = 0.00429969 loss)
I0403 03:48:43.793442 32199 sgd_solver.cpp:106] Iteration 4220, lr = 0.0005
I0403 03:48:51.029778 32199 solver.cpp:228] Iteration 4230, loss = 0.00937348
I0403 03:48:51.029881 32199 solver.cpp:244]     Train net output #0: loss = 0.00937355 (* 1 = 0.00937355 loss)
I0403 03:48:51.218505 32199 sgd_solver.cpp:106] Iteration 4230, lr = 0.0005
I0403 03:48:58.373404 32199 solver.cpp:228] Iteration 4240, loss = 0.00123302
I0403 03:48:58.373498 32199 solver.cpp:244]     Train net output #0: loss = 0.00123308 (* 1 = 0.00123308 loss)
I0403 03:48:58.549520 32199 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 03:49:05.774610 32199 solver.cpp:228] Iteration 4250, loss = 0.00896242
I0403 03:49:05.774711 32199 solver.cpp:244]     Train net output #0: loss = 0.00896248 (* 1 = 0.00896248 loss)
I0403 03:49:05.982242 32199 sgd_solver.cpp:106] Iteration 4250, lr = 0.0005
I0403 03:49:13.094398 32199 solver.cpp:228] Iteration 4260, loss = 0.00316705
I0403 03:49:13.094769 32199 solver.cpp:244]     Train net output #0: loss = 0.00316712 (* 1 = 0.00316712 loss)
I0403 03:49:13.332152 32199 sgd_solver.cpp:106] Iteration 4260, lr = 0.0005
I0403 03:49:20.453794 32199 solver.cpp:228] Iteration 4270, loss = 0.0126311
I0403 03:49:20.453902 32199 solver.cpp:244]     Train net output #0: loss = 0.0126312 (* 1 = 0.0126312 loss)
I0403 03:49:20.664222 32199 sgd_solver.cpp:106] Iteration 4270, lr = 0.0005
I0403 03:49:27.905365 32199 solver.cpp:228] Iteration 4280, loss = 0.0224842
I0403 03:49:27.905464 32199 solver.cpp:244]     Train net output #0: loss = 0.0224842 (* 1 = 0.0224842 loss)
I0403 03:49:28.077950 32199 sgd_solver.cpp:106] Iteration 4280, lr = 0.0005
I0403 03:49:35.367269 32199 solver.cpp:228] Iteration 4290, loss = 0.00370033
I0403 03:49:35.367379 32199 solver.cpp:244]     Train net output #0: loss = 0.00370039 (* 1 = 0.00370039 loss)
I0403 03:49:35.548521 32199 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 03:49:42.744474 32199 solver.cpp:228] Iteration 4300, loss = 0.0031294
I0403 03:49:42.744565 32199 solver.cpp:244]     Train net output #0: loss = 0.00312947 (* 1 = 0.00312947 loss)
I0403 03:49:42.910289 32199 sgd_solver.cpp:106] Iteration 4300, lr = 0.0005
I0403 03:49:50.071751 32199 solver.cpp:228] Iteration 4310, loss = 0.000812564
I0403 03:49:50.072044 32199 solver.cpp:244]     Train net output #0: loss = 0.000812634 (* 1 = 0.000812634 loss)
I0403 03:49:50.238632 32199 sgd_solver.cpp:106] Iteration 4310, lr = 0.0005
I0403 03:49:57.372233 32199 solver.cpp:228] Iteration 4320, loss = 0.0187943
I0403 03:49:57.372329 32199 solver.cpp:244]     Train net output #0: loss = 0.0187944 (* 1 = 0.0187944 loss)
I0403 03:49:57.551015 32199 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 03:50:04.780628 32199 solver.cpp:228] Iteration 4330, loss = 0.00215061
I0403 03:50:04.780714 32199 solver.cpp:244]     Train net output #0: loss = 0.00215068 (* 1 = 0.00215068 loss)
I0403 03:50:04.946614 32199 sgd_solver.cpp:106] Iteration 4330, lr = 0.0005
I0403 03:50:11.982676 32199 solver.cpp:228] Iteration 4340, loss = 0.00425559
I0403 03:50:11.982777 32199 solver.cpp:244]     Train net output #0: loss = 0.00425566 (* 1 = 0.00425566 loss)
I0403 03:50:12.175653 32199 sgd_solver.cpp:106] Iteration 4340, lr = 0.0005
I0403 03:50:19.676784 32199 solver.cpp:228] Iteration 4350, loss = 0.0269594
I0403 03:50:19.676874 32199 solver.cpp:244]     Train net output #0: loss = 0.0269595 (* 1 = 0.0269595 loss)
I0403 03:50:19.801054 32199 sgd_solver.cpp:106] Iteration 4350, lr = 0.0005
I0403 03:50:27.057194 32199 solver.cpp:228] Iteration 4360, loss = 0.0270123
I0403 03:50:27.057525 32199 solver.cpp:244]     Train net output #0: loss = 0.0270123 (* 1 = 0.0270123 loss)
I0403 03:50:27.238378 32199 sgd_solver.cpp:106] Iteration 4360, lr = 0.0005
I0403 03:50:34.329916 32199 solver.cpp:228] Iteration 4370, loss = 0.00509347
I0403 03:50:34.330008 32199 solver.cpp:244]     Train net output #0: loss = 0.00509354 (* 1 = 0.00509354 loss)
I0403 03:50:34.507834 32199 sgd_solver.cpp:106] Iteration 4370, lr = 0.0005
I0403 03:50:41.100272 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4380.caffemodel
I0403 03:50:43.710649 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4380.solverstate
I0403 03:50:45.498119 32199 solver.cpp:337] Iteration 4380, Testing net (#0)
I0403 03:51:59.291453 32199 solver.cpp:404]     Test net output #0: accuracy = 0.957554
I0403 03:51:59.291770 32199 solver.cpp:404]     Test net output #1: loss = 0.159677 (* 1 = 0.159677 loss)
I0403 03:51:59.814330 32199 solver.cpp:228] Iteration 4380, loss = 0.00190482
I0403 03:51:59.814419 32199 solver.cpp:244]     Train net output #0: loss = 0.00190489 (* 1 = 0.00190489 loss)
I0403 03:51:59.971865 32199 sgd_solver.cpp:106] Iteration 4380, lr = 0.0005
I0403 03:52:07.178436 32199 solver.cpp:228] Iteration 4390, loss = 0.012245
I0403 03:52:07.178547 32199 solver.cpp:244]     Train net output #0: loss = 0.0122451 (* 1 = 0.0122451 loss)
I0403 03:52:07.395190 32199 sgd_solver.cpp:106] Iteration 4390, lr = 0.0005
I0403 03:52:14.545730 32199 solver.cpp:228] Iteration 4400, loss = 0.0086776
I0403 03:52:14.545822 32199 solver.cpp:244]     Train net output #0: loss = 0.00867767 (* 1 = 0.00867767 loss)
I0403 03:52:14.709590 32199 sgd_solver.cpp:106] Iteration 4400, lr = 5e-05
I0403 03:52:21.919895 32199 solver.cpp:228] Iteration 4410, loss = 0.00281989
I0403 03:52:21.919981 32199 solver.cpp:244]     Train net output #0: loss = 0.00281996 (* 1 = 0.00281996 loss)
I0403 03:52:22.088364 32199 sgd_solver.cpp:106] Iteration 4410, lr = 5e-05
I0403 03:52:29.405675 32199 solver.cpp:228] Iteration 4420, loss = 0.00175665
I0403 03:52:29.409898 32199 solver.cpp:244]     Train net output #0: loss = 0.00175672 (* 1 = 0.00175672 loss)
I0403 03:52:29.567478 32199 sgd_solver.cpp:106] Iteration 4420, lr = 5e-05
I0403 03:52:36.686650 32199 solver.cpp:228] Iteration 4430, loss = 0.0108542
I0403 03:52:36.686751 32199 solver.cpp:244]     Train net output #0: loss = 0.0108543 (* 1 = 0.0108543 loss)
I0403 03:52:36.884295 32199 sgd_solver.cpp:106] Iteration 4430, lr = 5e-05
I0403 03:52:43.949986 32199 solver.cpp:228] Iteration 4440, loss = 0.00407384
I0403 03:52:43.950078 32199 solver.cpp:244]     Train net output #0: loss = 0.00407391 (* 1 = 0.00407391 loss)
I0403 03:52:44.108029 32199 sgd_solver.cpp:106] Iteration 4440, lr = 5e-05
I0403 03:52:51.307231 32199 solver.cpp:228] Iteration 4450, loss = 0.0100078
I0403 03:52:51.307324 32199 solver.cpp:244]     Train net output #0: loss = 0.0100079 (* 1 = 0.0100079 loss)
I0403 03:52:51.481354 32199 sgd_solver.cpp:106] Iteration 4450, lr = 5e-05
I0403 03:52:58.636780 32199 solver.cpp:228] Iteration 4460, loss = 0.00147087
I0403 03:52:58.636869 32199 solver.cpp:244]     Train net output #0: loss = 0.00147095 (* 1 = 0.00147095 loss)
I0403 03:52:58.811743 32199 sgd_solver.cpp:106] Iteration 4460, lr = 5e-05
I0403 03:53:05.927644 32199 solver.cpp:228] Iteration 4470, loss = 0.000475286
I0403 03:53:05.927956 32199 solver.cpp:244]     Train net output #0: loss = 0.000475357 (* 1 = 0.000475357 loss)
I0403 03:53:06.101717 32199 sgd_solver.cpp:106] Iteration 4470, lr = 5e-05
I0403 03:53:13.451819 32199 solver.cpp:228] Iteration 4480, loss = 0.00473496
I0403 03:53:13.451905 32199 solver.cpp:244]     Train net output #0: loss = 0.00473503 (* 1 = 0.00473503 loss)
I0403 03:53:13.627799 32199 sgd_solver.cpp:106] Iteration 4480, lr = 5e-05
I0403 03:53:20.846410 32199 solver.cpp:228] Iteration 4490, loss = 0.00641066
I0403 03:53:20.846499 32199 solver.cpp:244]     Train net output #0: loss = 0.00641074 (* 1 = 0.00641074 loss)
I0403 03:53:21.023417 32199 sgd_solver.cpp:106] Iteration 4490, lr = 5e-05
I0403 03:53:28.226944 32199 solver.cpp:228] Iteration 4500, loss = 0.00174594
I0403 03:53:28.227038 32199 solver.cpp:244]     Train net output #0: loss = 0.00174601 (* 1 = 0.00174601 loss)
I0403 03:53:28.400220 32199 sgd_solver.cpp:106] Iteration 4500, lr = 5e-05
I0403 03:53:35.727268 32199 solver.cpp:228] Iteration 4510, loss = 0.0121467
I0403 03:53:35.727360 32199 solver.cpp:244]     Train net output #0: loss = 0.0121468 (* 1 = 0.0121468 loss)
I0403 03:53:35.840414 32199 sgd_solver.cpp:106] Iteration 4510, lr = 5e-05
I0403 03:53:43.113255 32199 solver.cpp:228] Iteration 4520, loss = 0.0194965
I0403 03:53:43.113591 32199 solver.cpp:244]     Train net output #0: loss = 0.0194965 (* 1 = 0.0194965 loss)
I0403 03:53:43.304611 32199 sgd_solver.cpp:106] Iteration 4520, lr = 5e-05
I0403 03:53:50.591847 32199 solver.cpp:228] Iteration 4530, loss = 0.000423662
I0403 03:53:50.591938 32199 solver.cpp:244]     Train net output #0: loss = 0.000423733 (* 1 = 0.000423733 loss)
I0403 03:53:50.769248 32199 sgd_solver.cpp:106] Iteration 4530, lr = 5e-05
I0403 03:53:57.872069 32199 solver.cpp:228] Iteration 4540, loss = 0.00238438
I0403 03:53:57.872169 32199 solver.cpp:244]     Train net output #0: loss = 0.00238445 (* 1 = 0.00238445 loss)
I0403 03:53:58.075613 32199 sgd_solver.cpp:106] Iteration 4540, lr = 5e-05
I0403 03:54:05.411223 32199 solver.cpp:228] Iteration 4550, loss = 0.0128452
I0403 03:54:05.411327 32199 solver.cpp:244]     Train net output #0: loss = 0.0128452 (* 1 = 0.0128452 loss)
I0403 03:54:05.594740 32199 sgd_solver.cpp:106] Iteration 4550, lr = 5e-05
I0403 03:54:12.879976 32199 solver.cpp:228] Iteration 4560, loss = 0.0134133
I0403 03:54:12.880067 32199 solver.cpp:244]     Train net output #0: loss = 0.0134134 (* 1 = 0.0134134 loss)
I0403 03:54:13.058099 32199 sgd_solver.cpp:106] Iteration 4560, lr = 5e-05
I0403 03:54:20.324790 32199 solver.cpp:228] Iteration 4570, loss = 0.0042007
I0403 03:54:20.325125 32199 solver.cpp:244]     Train net output #0: loss = 0.00420078 (* 1 = 0.00420078 loss)
I0403 03:54:20.474989 32199 sgd_solver.cpp:106] Iteration 4570, lr = 5e-05
I0403 03:54:27.743685 32199 solver.cpp:228] Iteration 4580, loss = 0.00125284
I0403 03:54:27.743788 32199 solver.cpp:244]     Train net output #0: loss = 0.00125291 (* 1 = 0.00125291 loss)
I0403 03:54:27.931886 32199 sgd_solver.cpp:106] Iteration 4580, lr = 5e-05
I0403 03:54:35.033265 32199 solver.cpp:228] Iteration 4590, loss = 0.00471987
I0403 03:54:35.033360 32199 solver.cpp:244]     Train net output #0: loss = 0.00471994 (* 1 = 0.00471994 loss)
I0403 03:54:35.210489 32199 sgd_solver.cpp:106] Iteration 4590, lr = 5e-05
I0403 03:54:41.001471 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4599.caffemodel
I0403 03:54:43.698985 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4599.solverstate
I0403 03:54:45.477596 32199 solver.cpp:337] Iteration 4599, Testing net (#0)
I0403 03:55:59.281438 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958143
I0403 03:55:59.289196 32199 solver.cpp:404]     Test net output #1: loss = 0.159015 (* 1 = 0.159015 loss)
I0403 03:56:00.533305 32199 solver.cpp:228] Iteration 4600, loss = 0.015547
I0403 03:56:00.533395 32199 solver.cpp:244]     Train net output #0: loss = 0.0155471 (* 1 = 0.0155471 loss)
I0403 03:56:00.701387 32199 sgd_solver.cpp:106] Iteration 4600, lr = 5e-05
I0403 03:56:07.838570 32199 solver.cpp:228] Iteration 4610, loss = 0.00521606
I0403 03:56:07.838681 32199 solver.cpp:244]     Train net output #0: loss = 0.00521613 (* 1 = 0.00521613 loss)
I0403 03:56:08.024471 32199 sgd_solver.cpp:106] Iteration 4610, lr = 5e-05
I0403 03:56:15.032217 32199 solver.cpp:228] Iteration 4620, loss = 0.00523578
I0403 03:56:15.032318 32199 solver.cpp:244]     Train net output #0: loss = 0.00523585 (* 1 = 0.00523585 loss)
I0403 03:56:15.245520 32199 sgd_solver.cpp:106] Iteration 4620, lr = 5e-05
I0403 03:56:22.454912 32199 solver.cpp:228] Iteration 4630, loss = 0.00320546
I0403 03:56:22.455003 32199 solver.cpp:244]     Train net output #0: loss = 0.00320553 (* 1 = 0.00320553 loss)
I0403 03:56:22.636194 32199 sgd_solver.cpp:106] Iteration 4630, lr = 5e-05
I0403 03:56:29.773155 32199 solver.cpp:228] Iteration 4640, loss = 0.00331582
I0403 03:56:29.773468 32199 solver.cpp:244]     Train net output #0: loss = 0.00331589 (* 1 = 0.00331589 loss)
I0403 03:56:29.928014 32199 sgd_solver.cpp:106] Iteration 4640, lr = 5e-05
I0403 03:56:37.227255 32199 solver.cpp:228] Iteration 4650, loss = 0.00359273
I0403 03:56:37.227349 32199 solver.cpp:244]     Train net output #0: loss = 0.0035928 (* 1 = 0.0035928 loss)
I0403 03:56:37.377876 32199 sgd_solver.cpp:106] Iteration 4650, lr = 5e-05
I0403 03:56:44.616863 32199 solver.cpp:228] Iteration 4660, loss = 0.00356857
I0403 03:56:44.616967 32199 solver.cpp:244]     Train net output #0: loss = 0.00356863 (* 1 = 0.00356863 loss)
I0403 03:56:44.802212 32199 sgd_solver.cpp:106] Iteration 4660, lr = 5e-05
I0403 03:56:52.016269 32199 solver.cpp:228] Iteration 4670, loss = 0.00233085
I0403 03:56:52.016377 32199 solver.cpp:244]     Train net output #0: loss = 0.00233092 (* 1 = 0.00233092 loss)
I0403 03:56:52.224486 32199 sgd_solver.cpp:106] Iteration 4670, lr = 5e-05
I0403 03:56:59.359822 32199 solver.cpp:228] Iteration 4680, loss = 0.00272977
I0403 03:56:59.359923 32199 solver.cpp:244]     Train net output #0: loss = 0.00272984 (* 1 = 0.00272984 loss)
I0403 03:56:59.556978 32199 sgd_solver.cpp:106] Iteration 4680, lr = 5e-05
I0403 03:57:06.621592 32199 solver.cpp:228] Iteration 4690, loss = 0.0014898
I0403 03:57:06.621942 32199 solver.cpp:244]     Train net output #0: loss = 0.00148987 (* 1 = 0.00148987 loss)
I0403 03:57:06.799695 32199 sgd_solver.cpp:106] Iteration 4690, lr = 5e-05
I0403 03:57:14.131356 32199 solver.cpp:228] Iteration 4700, loss = 0.00852243
I0403 03:57:14.131461 32199 solver.cpp:244]     Train net output #0: loss = 0.0085225 (* 1 = 0.0085225 loss)
I0403 03:57:14.328706 32199 sgd_solver.cpp:106] Iteration 4700, lr = 5e-05
I0403 03:57:21.489154 32199 solver.cpp:228] Iteration 4710, loss = 0.0014812
I0403 03:57:21.489248 32199 solver.cpp:244]     Train net output #0: loss = 0.00148127 (* 1 = 0.00148127 loss)
I0403 03:57:21.648526 32199 sgd_solver.cpp:106] Iteration 4710, lr = 5e-05
I0403 03:57:28.994309 32199 solver.cpp:228] Iteration 4720, loss = 0.0258392
I0403 03:57:28.994412 32199 solver.cpp:244]     Train net output #0: loss = 0.0258392 (* 1 = 0.0258392 loss)
I0403 03:57:29.177881 32199 sgd_solver.cpp:106] Iteration 4720, lr = 5e-05
I0403 03:57:36.340606 32199 solver.cpp:228] Iteration 4730, loss = 0.00357188
I0403 03:57:36.340697 32199 solver.cpp:244]     Train net output #0: loss = 0.00357195 (* 1 = 0.00357195 loss)
I0403 03:57:36.516365 32199 sgd_solver.cpp:106] Iteration 4730, lr = 5e-05
I0403 03:57:43.585646 32199 solver.cpp:228] Iteration 4740, loss = 0.0197447
I0403 03:57:43.585991 32199 solver.cpp:244]     Train net output #0: loss = 0.0197447 (* 1 = 0.0197447 loss)
I0403 03:57:43.814927 32199 sgd_solver.cpp:106] Iteration 4740, lr = 5e-05
I0403 03:57:51.014295 32199 solver.cpp:228] Iteration 4750, loss = 0.0029494
I0403 03:57:51.014387 32199 solver.cpp:244]     Train net output #0: loss = 0.00294947 (* 1 = 0.00294947 loss)
I0403 03:57:51.189569 32199 sgd_solver.cpp:106] Iteration 4750, lr = 5e-05
I0403 03:57:58.306890 32199 solver.cpp:228] Iteration 4760, loss = 0.0118968
I0403 03:57:58.306996 32199 solver.cpp:244]     Train net output #0: loss = 0.0118969 (* 1 = 0.0118969 loss)
I0403 03:57:58.505767 32199 sgd_solver.cpp:106] Iteration 4760, lr = 5e-05
I0403 03:58:05.763145 32199 solver.cpp:228] Iteration 4770, loss = 0.0096577
I0403 03:58:05.763236 32199 solver.cpp:244]     Train net output #0: loss = 0.00965777 (* 1 = 0.00965777 loss)
I0403 03:58:05.922621 32199 sgd_solver.cpp:106] Iteration 4770, lr = 5e-05
I0403 03:58:13.134780 32199 solver.cpp:228] Iteration 4780, loss = 0.0062605
I0403 03:58:13.134872 32199 solver.cpp:244]     Train net output #0: loss = 0.00626057 (* 1 = 0.00626057 loss)
I0403 03:58:13.290233 32199 sgd_solver.cpp:106] Iteration 4780, lr = 5e-05
I0403 03:58:20.568035 32199 solver.cpp:228] Iteration 4790, loss = 0.0021421
I0403 03:58:20.572327 32199 solver.cpp:244]     Train net output #0: loss = 0.00214217 (* 1 = 0.00214217 loss)
I0403 03:58:20.798804 32199 sgd_solver.cpp:106] Iteration 4790, lr = 5e-05
I0403 03:58:28.056929 32199 solver.cpp:228] Iteration 4800, loss = 0.0011111
I0403 03:58:28.057029 32199 solver.cpp:244]     Train net output #0: loss = 0.00111117 (* 1 = 0.00111117 loss)
I0403 03:58:28.192497 32199 sgd_solver.cpp:106] Iteration 4800, lr = 5e-05
I0403 03:58:35.413378 32199 solver.cpp:228] Iteration 4810, loss = 0.00985768
I0403 03:58:35.413470 32199 solver.cpp:244]     Train net output #0: loss = 0.00985774 (* 1 = 0.00985774 loss)
I0403 03:58:35.587947 32199 sgd_solver.cpp:106] Iteration 4810, lr = 5e-05
I0403 03:58:40.807948 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4818.caffemodel
I0403 03:58:43.612452 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_4818.solverstate
I0403 03:58:45.438124 32199 solver.cpp:337] Iteration 4818, Testing net (#0)
I0403 03:59:59.250089 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958484
I0403 03:59:59.250447 32199 solver.cpp:404]     Test net output #1: loss = 0.15821 (* 1 = 0.15821 loss)
I0403 04:00:01.249932 32199 solver.cpp:228] Iteration 4820, loss = 0.0361881
I0403 04:00:01.250041 32199 solver.cpp:244]     Train net output #0: loss = 0.0361882 (* 1 = 0.0361882 loss)
I0403 04:00:01.455174 32199 sgd_solver.cpp:106] Iteration 4820, lr = 5e-05
I0403 04:00:08.551895 32199 solver.cpp:228] Iteration 4830, loss = 0.00108692
I0403 04:00:08.552006 32199 solver.cpp:244]     Train net output #0: loss = 0.00108699 (* 1 = 0.00108699 loss)
I0403 04:00:08.741569 32199 sgd_solver.cpp:106] Iteration 4830, lr = 5e-05
I0403 04:00:15.961952 32199 solver.cpp:228] Iteration 4840, loss = 0.0386646
I0403 04:00:15.962044 32199 solver.cpp:244]     Train net output #0: loss = 0.0386646 (* 1 = 0.0386646 loss)
I0403 04:00:16.137672 32199 sgd_solver.cpp:106] Iteration 4840, lr = 5e-05
I0403 04:00:23.201969 32199 solver.cpp:228] Iteration 4850, loss = 0.00306592
I0403 04:00:23.202076 32199 solver.cpp:244]     Train net output #0: loss = 0.00306599 (* 1 = 0.00306599 loss)
I0403 04:00:23.464520 32199 sgd_solver.cpp:106] Iteration 4850, lr = 5e-05
I0403 04:00:30.651918 32199 solver.cpp:228] Iteration 4860, loss = 0.000558732
I0403 04:00:30.652252 32199 solver.cpp:244]     Train net output #0: loss = 0.000558796 (* 1 = 0.000558796 loss)
I0403 04:00:30.837244 32199 sgd_solver.cpp:106] Iteration 4860, lr = 5e-05
I0403 04:00:38.042505 32199 solver.cpp:228] Iteration 4870, loss = 0.00103534
I0403 04:00:38.042606 32199 solver.cpp:244]     Train net output #0: loss = 0.00103541 (* 1 = 0.00103541 loss)
I0403 04:00:38.226176 32199 sgd_solver.cpp:106] Iteration 4870, lr = 5e-05
I0403 04:00:45.571395 32199 solver.cpp:228] Iteration 4880, loss = 0.000765288
I0403 04:00:45.571486 32199 solver.cpp:244]     Train net output #0: loss = 0.000765353 (* 1 = 0.000765353 loss)
I0403 04:00:45.727784 32199 sgd_solver.cpp:106] Iteration 4880, lr = 5e-05
I0403 04:00:52.938086 32199 solver.cpp:228] Iteration 4890, loss = 0.00494769
I0403 04:00:52.938174 32199 solver.cpp:244]     Train net output #0: loss = 0.00494775 (* 1 = 0.00494775 loss)
I0403 04:00:53.116593 32199 sgd_solver.cpp:106] Iteration 4890, lr = 5e-05
I0403 04:01:00.195610 32199 solver.cpp:228] Iteration 4900, loss = 0.0041574
I0403 04:01:00.195698 32199 solver.cpp:244]     Train net output #0: loss = 0.00415747 (* 1 = 0.00415747 loss)
I0403 04:01:00.371254 32199 sgd_solver.cpp:106] Iteration 4900, lr = 5e-05
I0403 04:01:07.543056 32199 solver.cpp:228] Iteration 4910, loss = 0.00228587
I0403 04:01:07.543380 32199 solver.cpp:244]     Train net output #0: loss = 0.00228593 (* 1 = 0.00228593 loss)
I0403 04:01:07.721875 32199 sgd_solver.cpp:106] Iteration 4910, lr = 5e-05
I0403 04:01:14.980609 32199 solver.cpp:228] Iteration 4920, loss = 0.00437209
I0403 04:01:14.980702 32199 solver.cpp:244]     Train net output #0: loss = 0.00437215 (* 1 = 0.00437215 loss)
I0403 04:01:15.148008 32199 sgd_solver.cpp:106] Iteration 4920, lr = 5e-05
I0403 04:01:22.401538 32199 solver.cpp:228] Iteration 4930, loss = 0.00352836
I0403 04:01:22.401653 32199 solver.cpp:244]     Train net output #0: loss = 0.00352843 (* 1 = 0.00352843 loss)
I0403 04:01:22.622141 32199 sgd_solver.cpp:106] Iteration 4930, lr = 5e-05
I0403 04:01:29.786617 32199 solver.cpp:228] Iteration 4940, loss = 0.00279046
I0403 04:01:29.786705 32199 solver.cpp:244]     Train net output #0: loss = 0.00279052 (* 1 = 0.00279052 loss)
I0403 04:01:29.957387 32199 sgd_solver.cpp:106] Iteration 4940, lr = 5e-05
I0403 04:01:37.042567 32199 solver.cpp:228] Iteration 4950, loss = 0.0186853
I0403 04:01:37.042661 32199 solver.cpp:244]     Train net output #0: loss = 0.0186854 (* 1 = 0.0186854 loss)
I0403 04:01:37.211438 32199 sgd_solver.cpp:106] Iteration 4950, lr = 5e-05
I0403 04:01:44.524025 32199 solver.cpp:228] Iteration 4960, loss = 0.00195879
I0403 04:01:44.524389 32199 solver.cpp:244]     Train net output #0: loss = 0.00195886 (* 1 = 0.00195886 loss)
I0403 04:01:44.714511 32199 sgd_solver.cpp:106] Iteration 4960, lr = 5e-05
I0403 04:01:51.775984 32199 solver.cpp:228] Iteration 4970, loss = 0.000662511
I0403 04:01:51.776082 32199 solver.cpp:244]     Train net output #0: loss = 0.000662573 (* 1 = 0.000662573 loss)
I0403 04:01:51.972385 32199 sgd_solver.cpp:106] Iteration 4970, lr = 5e-05
I0403 04:01:59.450821 32199 solver.cpp:228] Iteration 4980, loss = 0.00147309
I0403 04:01:59.450906 32199 solver.cpp:244]     Train net output #0: loss = 0.00147315 (* 1 = 0.00147315 loss)
I0403 04:01:59.623589 32199 sgd_solver.cpp:106] Iteration 4980, lr = 5e-05
I0403 04:02:06.706751 32199 solver.cpp:228] Iteration 4990, loss = 0.0016643
I0403 04:02:06.706841 32199 solver.cpp:244]     Train net output #0: loss = 0.00166436 (* 1 = 0.00166436 loss)
I0403 04:02:06.879755 32199 sgd_solver.cpp:106] Iteration 4990, lr = 5e-05
I0403 04:02:14.019994 32199 solver.cpp:228] Iteration 5000, loss = 0.035537
I0403 04:02:14.020099 32199 solver.cpp:244]     Train net output #0: loss = 0.0355371 (* 1 = 0.0355371 loss)
I0403 04:02:14.208004 32199 sgd_solver.cpp:106] Iteration 5000, lr = 5e-05
I0403 04:02:21.510432 32199 solver.cpp:228] Iteration 5010, loss = 0.0047054
I0403 04:02:21.512084 32199 solver.cpp:244]     Train net output #0: loss = 0.00470546 (* 1 = 0.00470546 loss)
I0403 04:02:21.708106 32199 sgd_solver.cpp:106] Iteration 5010, lr = 5e-05
I0403 04:02:29.046120 32199 solver.cpp:228] Iteration 5020, loss = 0.00853404
I0403 04:02:29.046217 32199 solver.cpp:244]     Train net output #0: loss = 0.0085341 (* 1 = 0.0085341 loss)
I0403 04:02:29.221370 32199 sgd_solver.cpp:106] Iteration 5020, lr = 5e-05
I0403 04:02:36.384480 32199 solver.cpp:228] Iteration 5030, loss = 0.00956453
I0403 04:02:36.384572 32199 solver.cpp:244]     Train net output #0: loss = 0.00956459 (* 1 = 0.00956459 loss)
I0403 04:02:36.565884 32199 sgd_solver.cpp:106] Iteration 5030, lr = 5e-05
I0403 04:02:40.984199 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5037.caffemodel
I0403 04:02:43.627228 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5037.solverstate
I0403 04:02:45.433490 32199 solver.cpp:337] Iteration 5037, Testing net (#0)
I0403 04:03:59.238301 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958545
I0403 04:03:59.238632 32199 solver.cpp:404]     Test net output #1: loss = 0.158938 (* 1 = 0.158938 loss)
I0403 04:04:01.982550 32199 solver.cpp:228] Iteration 5040, loss = 0.00137372
I0403 04:04:01.982653 32199 solver.cpp:244]     Train net output #0: loss = 0.00137379 (* 1 = 0.00137379 loss)
I0403 04:04:02.204643 32199 sgd_solver.cpp:106] Iteration 5040, lr = 5e-05
I0403 04:04:09.336169 32199 solver.cpp:228] Iteration 5050, loss = 0.00409963
I0403 04:04:09.336256 32199 solver.cpp:244]     Train net output #0: loss = 0.00409969 (* 1 = 0.00409969 loss)
I0403 04:04:09.502300 32199 sgd_solver.cpp:106] Iteration 5050, lr = 5e-05
I0403 04:04:16.734205 32199 solver.cpp:228] Iteration 5060, loss = 0.0025925
I0403 04:04:16.734294 32199 solver.cpp:244]     Train net output #0: loss = 0.00259256 (* 1 = 0.00259256 loss)
I0403 04:04:16.911120 32199 sgd_solver.cpp:106] Iteration 5060, lr = 5e-05
I0403 04:04:23.913889 32199 solver.cpp:228] Iteration 5070, loss = 0.0100254
I0403 04:04:23.913980 32199 solver.cpp:244]     Train net output #0: loss = 0.0100254 (* 1 = 0.0100254 loss)
I0403 04:04:24.092574 32199 sgd_solver.cpp:106] Iteration 5070, lr = 5e-05
I0403 04:04:31.166086 32199 solver.cpp:228] Iteration 5080, loss = 0.0010731
I0403 04:04:31.166384 32199 solver.cpp:244]     Train net output #0: loss = 0.00107316 (* 1 = 0.00107316 loss)
I0403 04:04:31.340816 32199 sgd_solver.cpp:106] Iteration 5080, lr = 5e-05
I0403 04:04:38.600268 32199 solver.cpp:228] Iteration 5090, loss = 0.00781077
I0403 04:04:38.600365 32199 solver.cpp:244]     Train net output #0: loss = 0.00781083 (* 1 = 0.00781083 loss)
I0403 04:04:38.810588 32199 sgd_solver.cpp:106] Iteration 5090, lr = 5e-05
I0403 04:04:46.134165 32199 solver.cpp:228] Iteration 5100, loss = 0.0129178
I0403 04:04:46.134256 32199 solver.cpp:244]     Train net output #0: loss = 0.0129178 (* 1 = 0.0129178 loss)
I0403 04:04:46.301152 32199 sgd_solver.cpp:106] Iteration 5100, lr = 5e-05
I0403 04:04:53.446115 32199 solver.cpp:228] Iteration 5110, loss = 0.013304
I0403 04:04:53.446219 32199 solver.cpp:244]     Train net output #0: loss = 0.013304 (* 1 = 0.013304 loss)
I0403 04:04:53.647406 32199 sgd_solver.cpp:106] Iteration 5110, lr = 5e-05
I0403 04:05:00.917183 32199 solver.cpp:228] Iteration 5120, loss = 0.000424405
I0403 04:05:00.917274 32199 solver.cpp:244]     Train net output #0: loss = 0.000424464 (* 1 = 0.000424464 loss)
I0403 04:05:01.094090 32199 sgd_solver.cpp:106] Iteration 5120, lr = 5e-05
I0403 04:05:08.195318 32199 solver.cpp:228] Iteration 5130, loss = 0.00243765
I0403 04:05:08.195684 32199 solver.cpp:244]     Train net output #0: loss = 0.00243771 (* 1 = 0.00243771 loss)
I0403 04:05:08.375005 32199 sgd_solver.cpp:106] Iteration 5130, lr = 5e-05
I0403 04:05:15.472666 32199 solver.cpp:228] Iteration 5140, loss = 0.00836566
I0403 04:05:15.472756 32199 solver.cpp:244]     Train net output #0: loss = 0.00836573 (* 1 = 0.00836573 loss)
I0403 04:05:15.650959 32199 sgd_solver.cpp:106] Iteration 5140, lr = 5e-05
I0403 04:05:22.836011 32199 solver.cpp:228] Iteration 5150, loss = 0.0378745
I0403 04:05:22.836102 32199 solver.cpp:244]     Train net output #0: loss = 0.0378746 (* 1 = 0.0378746 loss)
I0403 04:05:22.992256 32199 sgd_solver.cpp:106] Iteration 5150, lr = 5e-05
I0403 04:05:30.281731 32199 solver.cpp:228] Iteration 5160, loss = 0.00221271
I0403 04:05:30.281822 32199 solver.cpp:244]     Train net output #0: loss = 0.00221277 (* 1 = 0.00221277 loss)
I0403 04:05:30.457370 32199 sgd_solver.cpp:106] Iteration 5160, lr = 5e-05
I0403 04:05:37.665782 32199 solver.cpp:228] Iteration 5170, loss = 0.0046937
I0403 04:05:37.665871 32199 solver.cpp:244]     Train net output #0: loss = 0.00469376 (* 1 = 0.00469376 loss)
I0403 04:05:37.843811 32199 sgd_solver.cpp:106] Iteration 5170, lr = 5e-05
I0403 04:05:45.041095 32199 solver.cpp:228] Iteration 5180, loss = 0.00620113
I0403 04:05:45.041420 32199 solver.cpp:244]     Train net output #0: loss = 0.0062012 (* 1 = 0.0062012 loss)
I0403 04:05:45.200737 32199 sgd_solver.cpp:106] Iteration 5180, lr = 5e-05
I0403 04:05:52.346463 32199 solver.cpp:228] Iteration 5190, loss = 0.00157219
I0403 04:05:52.346570 32199 solver.cpp:244]     Train net output #0: loss = 0.00157225 (* 1 = 0.00157225 loss)
I0403 04:05:52.531498 32199 sgd_solver.cpp:106] Iteration 5190, lr = 5e-05
I0403 04:05:59.763525 32199 solver.cpp:228] Iteration 5200, loss = 0.00996123
I0403 04:05:59.763613 32199 solver.cpp:244]     Train net output #0: loss = 0.0099613 (* 1 = 0.0099613 loss)
I0403 04:05:59.931532 32199 sgd_solver.cpp:106] Iteration 5200, lr = 5e-05
I0403 04:06:07.122577 32199 solver.cpp:228] Iteration 5210, loss = 0.00288462
I0403 04:06:07.122683 32199 solver.cpp:244]     Train net output #0: loss = 0.00288468 (* 1 = 0.00288468 loss)
I0403 04:06:07.328872 32199 sgd_solver.cpp:106] Iteration 5210, lr = 5e-05
I0403 04:06:14.618449 32199 solver.cpp:228] Iteration 5220, loss = 0.00135189
I0403 04:06:14.618561 32199 solver.cpp:244]     Train net output #0: loss = 0.00135196 (* 1 = 0.00135196 loss)
I0403 04:06:14.809665 32199 sgd_solver.cpp:106] Iteration 5220, lr = 5e-05
I0403 04:06:22.005578 32199 solver.cpp:228] Iteration 5230, loss = 0.00136758
I0403 04:06:22.005898 32199 solver.cpp:244]     Train net output #0: loss = 0.00136765 (* 1 = 0.00136765 loss)
I0403 04:06:22.189236 32199 sgd_solver.cpp:106] Iteration 5230, lr = 5e-05
I0403 04:06:29.269451 32199 solver.cpp:228] Iteration 5240, loss = 0.00132691
I0403 04:06:29.269534 32199 solver.cpp:244]     Train net output #0: loss = 0.00132698 (* 1 = 0.00132698 loss)
I0403 04:06:29.442637 32199 sgd_solver.cpp:106] Iteration 5240, lr = 5e-05
I0403 04:06:36.530177 32199 solver.cpp:228] Iteration 5250, loss = 0.00111249
I0403 04:06:36.530264 32199 solver.cpp:244]     Train net output #0: loss = 0.00111256 (* 1 = 0.00111256 loss)
I0403 04:06:36.707257 32199 sgd_solver.cpp:106] Iteration 5250, lr = 5e-05
I0403 04:06:40.344638 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5256.caffemodel
I0403 04:06:43.001214 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5256.solverstate
I0403 04:06:44.794886 32199 solver.cpp:337] Iteration 5256, Testing net (#0)
I0403 04:07:58.584460 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958081
I0403 04:07:58.584810 32199 solver.cpp:404]     Test net output #1: loss = 0.160204 (* 1 = 0.160204 loss)
I0403 04:08:02.061715 32199 solver.cpp:228] Iteration 5260, loss = 0.00649595
I0403 04:08:02.067251 32199 solver.cpp:244]     Train net output #0: loss = 0.00649602 (* 1 = 0.00649602 loss)
I0403 04:08:02.238081 32199 sgd_solver.cpp:106] Iteration 5260, lr = 5e-05
I0403 04:08:09.407052 32199 solver.cpp:228] Iteration 5270, loss = 0.000924649
I0403 04:08:09.407141 32199 solver.cpp:244]     Train net output #0: loss = 0.000924719 (* 1 = 0.000924719 loss)
I0403 04:08:09.583282 32199 sgd_solver.cpp:106] Iteration 5270, lr = 5e-05
I0403 04:08:16.743607 32199 solver.cpp:228] Iteration 5280, loss = 0.00658109
I0403 04:08:16.743697 32199 solver.cpp:244]     Train net output #0: loss = 0.00658116 (* 1 = 0.00658116 loss)
I0403 04:08:16.883046 32199 sgd_solver.cpp:106] Iteration 5280, lr = 5e-05
I0403 04:08:24.151235 32199 solver.cpp:228] Iteration 5290, loss = 0.00139577
I0403 04:08:24.151340 32199 solver.cpp:244]     Train net output #0: loss = 0.00139584 (* 1 = 0.00139584 loss)
I0403 04:08:24.394878 32199 sgd_solver.cpp:106] Iteration 5290, lr = 5e-05
I0403 04:08:31.602251 32199 solver.cpp:228] Iteration 5300, loss = 0.000981143
I0403 04:08:31.602588 32199 solver.cpp:244]     Train net output #0: loss = 0.000981213 (* 1 = 0.000981213 loss)
I0403 04:08:31.761114 32199 sgd_solver.cpp:106] Iteration 5300, lr = 5e-05
I0403 04:08:38.891721 32199 solver.cpp:228] Iteration 5310, loss = 0.00112822
I0403 04:08:38.891824 32199 solver.cpp:244]     Train net output #0: loss = 0.00112829 (* 1 = 0.00112829 loss)
I0403 04:08:39.075237 32199 sgd_solver.cpp:106] Iteration 5310, lr = 5e-05
I0403 04:08:46.397359 32199 solver.cpp:228] Iteration 5320, loss = 0.00523374
I0403 04:08:46.397446 32199 solver.cpp:244]     Train net output #0: loss = 0.00523381 (* 1 = 0.00523381 loss)
I0403 04:08:46.567948 32199 sgd_solver.cpp:106] Iteration 5320, lr = 5e-05
I0403 04:08:53.793488 32199 solver.cpp:228] Iteration 5330, loss = 0.00099664
I0403 04:08:53.793581 32199 solver.cpp:244]     Train net output #0: loss = 0.000996711 (* 1 = 0.000996711 loss)
I0403 04:08:53.962159 32199 sgd_solver.cpp:106] Iteration 5330, lr = 5e-05
I0403 04:09:01.151011 32199 solver.cpp:228] Iteration 5340, loss = 0.000805912
I0403 04:09:01.151113 32199 solver.cpp:244]     Train net output #0: loss = 0.000805982 (* 1 = 0.000805982 loss)
I0403 04:09:01.334964 32199 sgd_solver.cpp:106] Iteration 5340, lr = 5e-05
I0403 04:09:08.468686 32199 solver.cpp:228] Iteration 5350, loss = 0.0128692
I0403 04:09:08.469004 32199 solver.cpp:244]     Train net output #0: loss = 0.0128692 (* 1 = 0.0128692 loss)
I0403 04:09:08.650996 32199 sgd_solver.cpp:106] Iteration 5350, lr = 5e-05
I0403 04:09:15.829831 32199 solver.cpp:228] Iteration 5360, loss = 0.0194146
I0403 04:09:15.829921 32199 solver.cpp:244]     Train net output #0: loss = 0.0194147 (* 1 = 0.0194147 loss)
I0403 04:09:15.965078 32199 sgd_solver.cpp:106] Iteration 5360, lr = 5e-05
I0403 04:09:23.564653 32199 solver.cpp:228] Iteration 5370, loss = 0.0063867
I0403 04:09:23.564748 32199 solver.cpp:244]     Train net output #0: loss = 0.00638676 (* 1 = 0.00638676 loss)
I0403 04:09:23.732256 32199 sgd_solver.cpp:106] Iteration 5370, lr = 5e-05
I0403 04:09:31.044909 32199 solver.cpp:228] Iteration 5380, loss = 0.00156783
I0403 04:09:31.044997 32199 solver.cpp:244]     Train net output #0: loss = 0.00156789 (* 1 = 0.00156789 loss)
I0403 04:09:31.226043 32199 sgd_solver.cpp:106] Iteration 5380, lr = 5e-05
I0403 04:09:38.316648 32199 solver.cpp:228] Iteration 5390, loss = 0.00210159
I0403 04:09:38.316738 32199 solver.cpp:244]     Train net output #0: loss = 0.00210165 (* 1 = 0.00210165 loss)
I0403 04:09:38.491660 32199 sgd_solver.cpp:106] Iteration 5390, lr = 5e-05
I0403 04:09:45.690346 32199 solver.cpp:228] Iteration 5400, loss = 0.00266367
I0403 04:09:45.690457 32199 solver.cpp:244]     Train net output #0: loss = 0.00266373 (* 1 = 0.00266373 loss)
I0403 04:09:45.859158 32199 sgd_solver.cpp:106] Iteration 5400, lr = 5e-05
I0403 04:09:53.063941 32199 solver.cpp:228] Iteration 5410, loss = 0.00612547
I0403 04:09:53.064045 32199 solver.cpp:244]     Train net output #0: loss = 0.00612554 (* 1 = 0.00612554 loss)
I0403 04:09:53.264400 32199 sgd_solver.cpp:106] Iteration 5410, lr = 5e-05
I0403 04:10:00.450162 32199 solver.cpp:228] Iteration 5420, loss = 0.000908109
I0403 04:10:00.450268 32199 solver.cpp:244]     Train net output #0: loss = 0.000908173 (* 1 = 0.000908173 loss)
I0403 04:10:00.641973 32199 sgd_solver.cpp:106] Iteration 5420, lr = 5e-05
I0403 04:10:07.795466 32199 solver.cpp:228] Iteration 5430, loss = 0.00577966
I0403 04:10:07.795558 32199 solver.cpp:244]     Train net output #0: loss = 0.00577972 (* 1 = 0.00577972 loss)
I0403 04:10:07.971664 32199 sgd_solver.cpp:106] Iteration 5430, lr = 5e-05
I0403 04:10:15.115669 32199 solver.cpp:228] Iteration 5440, loss = 0.00213944
I0403 04:10:15.115983 32199 solver.cpp:244]     Train net output #0: loss = 0.00213951 (* 1 = 0.00213951 loss)
I0403 04:10:15.287065 32199 sgd_solver.cpp:106] Iteration 5440, lr = 5e-05
I0403 04:10:22.392424 32199 solver.cpp:228] Iteration 5450, loss = 0.0159176
I0403 04:10:22.392524 32199 solver.cpp:244]     Train net output #0: loss = 0.0159177 (* 1 = 0.0159177 loss)
I0403 04:10:22.568730 32199 sgd_solver.cpp:106] Iteration 5450, lr = 5e-05
I0403 04:10:29.760581 32199 solver.cpp:228] Iteration 5460, loss = 0.0224545
I0403 04:10:29.760670 32199 solver.cpp:244]     Train net output #0: loss = 0.0224546 (* 1 = 0.0224546 loss)
I0403 04:10:29.933163 32199 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 04:10:37.225455 32199 solver.cpp:228] Iteration 5470, loss = 0.00420208
I0403 04:10:37.225544 32199 solver.cpp:244]     Train net output #0: loss = 0.00420214 (* 1 = 0.00420214 loss)
I0403 04:10:37.380029 32199 sgd_solver.cpp:106] Iteration 5470, lr = 5e-05
I0403 04:10:40.333940 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5475.caffemodel
I0403 04:10:43.119690 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5475.solverstate
I0403 04:10:45.028266 32199 solver.cpp:337] Iteration 5475, Testing net (#0)
I0403 04:11:58.813812 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958236
I0403 04:11:58.814138 32199 solver.cpp:404]     Test net output #1: loss = 0.160214 (* 1 = 0.160214 loss)
I0403 04:12:03.056900 32199 solver.cpp:228] Iteration 5480, loss = 0.00276614
I0403 04:12:03.056998 32199 solver.cpp:244]     Train net output #0: loss = 0.0027662 (* 1 = 0.0027662 loss)
I0403 04:12:03.245079 32199 sgd_solver.cpp:106] Iteration 5480, lr = 5e-05
I0403 04:12:10.371544 32199 solver.cpp:228] Iteration 5490, loss = 0.00599598
I0403 04:12:10.371634 32199 solver.cpp:244]     Train net output #0: loss = 0.00599604 (* 1 = 0.00599604 loss)
I0403 04:12:10.520458 32199 sgd_solver.cpp:106] Iteration 5490, lr = 5e-05
I0403 04:12:18.027829 32199 solver.cpp:228] Iteration 5500, loss = 0.0111588
I0403 04:12:18.027920 32199 solver.cpp:244]     Train net output #0: loss = 0.0111589 (* 1 = 0.0111589 loss)
I0403 04:12:18.139370 32199 sgd_solver.cpp:106] Iteration 5500, lr = 5e-05
I0403 04:12:25.382513 32199 solver.cpp:228] Iteration 5510, loss = 0.000445794
I0403 04:12:25.382621 32199 solver.cpp:244]     Train net output #0: loss = 0.000445854 (* 1 = 0.000445854 loss)
I0403 04:12:25.599143 32199 sgd_solver.cpp:106] Iteration 5510, lr = 5e-05
I0403 04:12:32.695036 32199 solver.cpp:228] Iteration 5520, loss = 0.0105629
I0403 04:12:32.695371 32199 solver.cpp:244]     Train net output #0: loss = 0.0105629 (* 1 = 0.0105629 loss)
I0403 04:12:32.878655 32199 sgd_solver.cpp:106] Iteration 5520, lr = 5e-05
I0403 04:12:40.015638 32199 solver.cpp:228] Iteration 5530, loss = 0.00136056
I0403 04:12:40.015740 32199 solver.cpp:244]     Train net output #0: loss = 0.00136062 (* 1 = 0.00136062 loss)
I0403 04:12:40.237206 32199 sgd_solver.cpp:106] Iteration 5530, lr = 5e-05
I0403 04:12:47.379426 32199 solver.cpp:228] Iteration 5540, loss = 0.0187291
I0403 04:12:47.379528 32199 solver.cpp:244]     Train net output #0: loss = 0.0187292 (* 1 = 0.0187292 loss)
I0403 04:12:47.565079 32199 sgd_solver.cpp:106] Iteration 5540, lr = 5e-05
I0403 04:12:54.644448 32199 solver.cpp:228] Iteration 5550, loss = 0.00396746
I0403 04:12:54.654047 32199 solver.cpp:244]     Train net output #0: loss = 0.00396752 (* 1 = 0.00396752 loss)
I0403 04:12:54.817255 32199 sgd_solver.cpp:106] Iteration 5550, lr = 5e-05
I0403 04:13:01.993010 32199 solver.cpp:228] Iteration 5560, loss = 0.000777325
I0403 04:13:01.993099 32199 solver.cpp:244]     Train net output #0: loss = 0.000777383 (* 1 = 0.000777383 loss)
I0403 04:13:02.159499 32199 sgd_solver.cpp:106] Iteration 5560, lr = 5e-05
I0403 04:13:09.250293 32199 solver.cpp:228] Iteration 5570, loss = 0.00360699
I0403 04:13:09.250618 32199 solver.cpp:244]     Train net output #0: loss = 0.00360705 (* 1 = 0.00360705 loss)
I0403 04:13:09.419044 32199 sgd_solver.cpp:106] Iteration 5570, lr = 5e-05
I0403 04:13:16.634313 32199 solver.cpp:228] Iteration 5580, loss = 0.00512915
I0403 04:13:16.634408 32199 solver.cpp:244]     Train net output #0: loss = 0.00512921 (* 1 = 0.00512921 loss)
I0403 04:13:16.801157 32199 sgd_solver.cpp:106] Iteration 5580, lr = 5e-05
I0403 04:13:24.143455 32199 solver.cpp:228] Iteration 5590, loss = 0.00251727
I0403 04:13:24.143543 32199 solver.cpp:244]     Train net output #0: loss = 0.00251733 (* 1 = 0.00251733 loss)
I0403 04:13:24.322427 32199 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 04:13:31.557708 32199 solver.cpp:228] Iteration 5600, loss = 0.0236053
I0403 04:13:31.557796 32199 solver.cpp:244]     Train net output #0: loss = 0.0236053 (* 1 = 0.0236053 loss)
I0403 04:13:31.682014 32199 sgd_solver.cpp:106] Iteration 5600, lr = 5e-05
I0403 04:13:38.864675 32199 solver.cpp:228] Iteration 5610, loss = 0.0149643
I0403 04:13:38.864766 32199 solver.cpp:244]     Train net output #0: loss = 0.0149644 (* 1 = 0.0149644 loss)
I0403 04:13:39.037878 32199 sgd_solver.cpp:106] Iteration 5610, lr = 5e-05
I0403 04:13:46.246222 32199 solver.cpp:228] Iteration 5620, loss = 0.00212044
I0403 04:13:46.246538 32199 solver.cpp:244]     Train net output #0: loss = 0.0021205 (* 1 = 0.0021205 loss)
I0403 04:13:46.423940 32199 sgd_solver.cpp:106] Iteration 5620, lr = 5e-05
I0403 04:13:53.600620 32199 solver.cpp:228] Iteration 5630, loss = 0.0146033
I0403 04:13:53.600708 32199 solver.cpp:244]     Train net output #0: loss = 0.0146034 (* 1 = 0.0146034 loss)
I0403 04:13:53.778105 32199 sgd_solver.cpp:106] Iteration 5630, lr = 5e-05
I0403 04:14:00.915781 32199 solver.cpp:228] Iteration 5640, loss = 0.0010301
I0403 04:14:00.915884 32199 solver.cpp:244]     Train net output #0: loss = 0.00103016 (* 1 = 0.00103016 loss)
I0403 04:14:01.103597 32199 sgd_solver.cpp:106] Iteration 5640, lr = 5e-05
I0403 04:14:08.318850 32199 solver.cpp:228] Iteration 5650, loss = 0.00417334
I0403 04:14:08.318944 32199 solver.cpp:244]     Train net output #0: loss = 0.0041734 (* 1 = 0.0041734 loss)
I0403 04:14:08.473790 32199 sgd_solver.cpp:106] Iteration 5650, lr = 5e-05
I0403 04:14:15.805266 32199 solver.cpp:228] Iteration 5660, loss = 0.00205344
I0403 04:14:15.806488 32199 solver.cpp:244]     Train net output #0: loss = 0.0020535 (* 1 = 0.0020535 loss)
I0403 04:14:15.954983 32199 sgd_solver.cpp:106] Iteration 5660, lr = 5e-05
I0403 04:14:23.224098 32199 solver.cpp:228] Iteration 5670, loss = 0.00235058
I0403 04:14:23.228394 32199 solver.cpp:244]     Train net output #0: loss = 0.00235064 (* 1 = 0.00235064 loss)
I0403 04:14:23.400240 32199 sgd_solver.cpp:106] Iteration 5670, lr = 5e-05
I0403 04:14:30.530055 32199 solver.cpp:228] Iteration 5680, loss = 0.00384472
I0403 04:14:30.530158 32199 solver.cpp:244]     Train net output #0: loss = 0.00384478 (* 1 = 0.00384478 loss)
I0403 04:14:30.713645 32199 sgd_solver.cpp:106] Iteration 5680, lr = 5e-05
I0403 04:14:37.821737 32199 solver.cpp:228] Iteration 5690, loss = 0.00644343
I0403 04:14:37.821826 32199 solver.cpp:244]     Train net output #0: loss = 0.00644349 (* 1 = 0.00644349 loss)
I0403 04:14:37.990708 32199 sgd_solver.cpp:106] Iteration 5690, lr = 5e-05
I0403 04:14:40.323035 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5694.caffemodel
I0403 04:14:43.139281 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5694.solverstate
I0403 04:14:44.953016 32199 solver.cpp:337] Iteration 5694, Testing net (#0)
I0403 04:15:58.751648 32199 solver.cpp:404]     Test net output #0: accuracy = 0.95836
I0403 04:15:58.751991 32199 solver.cpp:404]     Test net output #1: loss = 0.15986 (* 1 = 0.15986 loss)
I0403 04:16:03.744048 32199 solver.cpp:228] Iteration 5700, loss = 0.00131015
I0403 04:16:03.744143 32199 solver.cpp:244]     Train net output #0: loss = 0.00131021 (* 1 = 0.00131021 loss)
I0403 04:16:03.920030 32199 sgd_solver.cpp:106] Iteration 5700, lr = 5e-05
I0403 04:16:11.075587 32199 solver.cpp:228] Iteration 5710, loss = 0.00290375
I0403 04:16:11.075682 32199 solver.cpp:244]     Train net output #0: loss = 0.00290381 (* 1 = 0.00290381 loss)
I0403 04:16:11.260149 32199 sgd_solver.cpp:106] Iteration 5710, lr = 5e-05
I0403 04:16:18.429637 32199 solver.cpp:228] Iteration 5720, loss = 0.00103687
I0403 04:16:18.429728 32199 solver.cpp:244]     Train net output #0: loss = 0.00103692 (* 1 = 0.00103692 loss)
I0403 04:16:18.597863 32199 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 04:16:25.785514 32199 solver.cpp:228] Iteration 5730, loss = 0.00268726
I0403 04:16:25.785609 32199 solver.cpp:244]     Train net output #0: loss = 0.00268732 (* 1 = 0.00268732 loss)
I0403 04:16:25.960290 32199 sgd_solver.cpp:106] Iteration 5730, lr = 5e-05
I0403 04:16:33.111927 32199 solver.cpp:228] Iteration 5740, loss = 0.00352555
I0403 04:16:33.112236 32199 solver.cpp:244]     Train net output #0: loss = 0.00352561 (* 1 = 0.00352561 loss)
I0403 04:16:33.306776 32199 sgd_solver.cpp:106] Iteration 5740, lr = 5e-05
I0403 04:16:40.475914 32199 solver.cpp:228] Iteration 5750, loss = 0.00223252
I0403 04:16:40.476018 32199 solver.cpp:244]     Train net output #0: loss = 0.00223257 (* 1 = 0.00223257 loss)
I0403 04:16:40.661387 32199 sgd_solver.cpp:106] Iteration 5750, lr = 5e-05
I0403 04:16:47.806506 32199 solver.cpp:228] Iteration 5760, loss = 0.00714107
I0403 04:16:47.806594 32199 solver.cpp:244]     Train net output #0: loss = 0.00714112 (* 1 = 0.00714112 loss)
I0403 04:16:47.980983 32199 sgd_solver.cpp:106] Iteration 5760, lr = 5e-05
I0403 04:16:55.095469 32199 solver.cpp:228] Iteration 5770, loss = 0.00211215
I0403 04:16:55.095561 32199 solver.cpp:244]     Train net output #0: loss = 0.00211221 (* 1 = 0.00211221 loss)
I0403 04:16:55.269800 32199 sgd_solver.cpp:106] Iteration 5770, lr = 5e-05
I0403 04:17:02.636232 32199 solver.cpp:228] Iteration 5780, loss = 0.0250869
I0403 04:17:02.636322 32199 solver.cpp:244]     Train net output #0: loss = 0.0250869 (* 1 = 0.0250869 loss)
I0403 04:17:02.810184 32199 sgd_solver.cpp:106] Iteration 5780, lr = 5e-05
I0403 04:17:09.925940 32199 solver.cpp:228] Iteration 5790, loss = 0.00510551
I0403 04:17:09.927291 32199 solver.cpp:244]     Train net output #0: loss = 0.00510556 (* 1 = 0.00510556 loss)
I0403 04:17:10.093089 32199 sgd_solver.cpp:106] Iteration 5790, lr = 5e-05
I0403 04:17:17.509202 32199 solver.cpp:228] Iteration 5800, loss = 0.00312797
I0403 04:17:17.509290 32199 solver.cpp:244]     Train net output #0: loss = 0.00312803 (* 1 = 0.00312803 loss)
I0403 04:17:17.687911 32199 sgd_solver.cpp:106] Iteration 5800, lr = 5e-05
I0403 04:17:24.983427 32199 solver.cpp:228] Iteration 5810, loss = 0.00893319
I0403 04:17:24.983536 32199 solver.cpp:244]     Train net output #0: loss = 0.00893325 (* 1 = 0.00893325 loss)
I0403 04:17:25.114224 32199 sgd_solver.cpp:106] Iteration 5810, lr = 5e-05
I0403 04:17:32.244735 32199 solver.cpp:228] Iteration 5820, loss = 0.0105115
I0403 04:17:32.244835 32199 solver.cpp:244]     Train net output #0: loss = 0.0105116 (* 1 = 0.0105116 loss)
I0403 04:17:32.441896 32199 sgd_solver.cpp:106] Iteration 5820, lr = 5e-05
I0403 04:17:39.561034 32199 solver.cpp:228] Iteration 5830, loss = 0.00268813
I0403 04:17:39.561128 32199 solver.cpp:244]     Train net output #0: loss = 0.00268819 (* 1 = 0.00268819 loss)
I0403 04:17:39.727906 32199 sgd_solver.cpp:106] Iteration 5830, lr = 5e-05
I0403 04:17:46.900023 32199 solver.cpp:228] Iteration 5840, loss = 0.00645124
I0403 04:17:46.900331 32199 solver.cpp:244]     Train net output #0: loss = 0.00645129 (* 1 = 0.00645129 loss)
I0403 04:17:47.068691 32199 sgd_solver.cpp:106] Iteration 5840, lr = 5e-05
I0403 04:17:54.209245 32199 solver.cpp:228] Iteration 5850, loss = 0.00136167
I0403 04:17:54.209337 32199 solver.cpp:244]     Train net output #0: loss = 0.00136173 (* 1 = 0.00136173 loss)
I0403 04:17:54.381507 32199 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 04:18:01.604331 32199 solver.cpp:228] Iteration 5860, loss = 0.00886073
I0403 04:18:01.604435 32199 solver.cpp:244]     Train net output #0: loss = 0.00886078 (* 1 = 0.00886078 loss)
I0403 04:18:01.802106 32199 sgd_solver.cpp:106] Iteration 5860, lr = 5e-05
I0403 04:18:08.964463 32199 solver.cpp:228] Iteration 5870, loss = 0.0247267
I0403 04:18:08.964553 32199 solver.cpp:244]     Train net output #0: loss = 0.0247267 (* 1 = 0.0247267 loss)
I0403 04:18:09.142395 32199 sgd_solver.cpp:106] Iteration 5870, lr = 5e-05
I0403 04:18:16.440974 32199 solver.cpp:228] Iteration 5880, loss = 0.00349854
I0403 04:18:16.441082 32199 solver.cpp:244]     Train net output #0: loss = 0.00349859 (* 1 = 0.00349859 loss)
I0403 04:18:16.654347 32199 sgd_solver.cpp:106] Iteration 5880, lr = 5e-05
I0403 04:18:23.753106 32199 solver.cpp:228] Iteration 5890, loss = 0.0167136
I0403 04:18:23.753391 32199 solver.cpp:244]     Train net output #0: loss = 0.0167137 (* 1 = 0.0167137 loss)
I0403 04:18:23.948164 32199 sgd_solver.cpp:106] Iteration 5890, lr = 5e-05
I0403 04:18:31.007083 32199 solver.cpp:228] Iteration 5900, loss = 0.0299815
I0403 04:18:31.007185 32199 solver.cpp:244]     Train net output #0: loss = 0.0299815 (* 1 = 0.0299815 loss)
I0403 04:18:31.201304 32199 sgd_solver.cpp:106] Iteration 5900, lr = 5e-05
I0403 04:18:38.698890 32199 solver.cpp:228] Iteration 5910, loss = 0.00228971
I0403 04:18:38.698978 32199 solver.cpp:244]     Train net output #0: loss = 0.00228976 (* 1 = 0.00228976 loss)
I0403 04:18:38.881996 32199 sgd_solver.cpp:106] Iteration 5910, lr = 5e-05
I0403 04:18:40.361306 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5913.caffemodel
I0403 04:18:42.989984 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_5913.solverstate
I0403 04:18:44.768129 32199 solver.cpp:337] Iteration 5913, Testing net (#0)
I0403 04:19:58.575379 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958112
I0403 04:19:58.575712 32199 solver.cpp:404]     Test net output #1: loss = 0.160545 (* 1 = 0.160545 loss)
I0403 04:20:04.438372 32199 solver.cpp:228] Iteration 5920, loss = 0.000676071
I0403 04:20:04.439535 32199 solver.cpp:244]     Train net output #0: loss = 0.000676121 (* 1 = 0.000676121 loss)
I0403 04:20:04.619665 32199 sgd_solver.cpp:106] Iteration 5920, lr = 5e-05
I0403 04:20:11.642308 32199 solver.cpp:228] Iteration 5930, loss = 0.00183584
I0403 04:20:11.642421 32199 solver.cpp:244]     Train net output #0: loss = 0.0018359 (* 1 = 0.0018359 loss)
I0403 04:20:11.843729 32199 sgd_solver.cpp:106] Iteration 5930, lr = 5e-05
I0403 04:20:19.120390 32199 solver.cpp:228] Iteration 5940, loss = 0.00536647
I0403 04:20:19.120483 32199 solver.cpp:244]     Train net output #0: loss = 0.00536653 (* 1 = 0.00536653 loss)
I0403 04:20:19.279124 32199 sgd_solver.cpp:106] Iteration 5940, lr = 5e-05
I0403 04:20:26.430318 32199 solver.cpp:228] Iteration 5950, loss = 0.00251374
I0403 04:20:26.430416 32199 solver.cpp:244]     Train net output #0: loss = 0.00251379 (* 1 = 0.00251379 loss)
I0403 04:20:26.674679 32199 sgd_solver.cpp:106] Iteration 5950, lr = 5e-05
I0403 04:20:33.841039 32199 solver.cpp:228] Iteration 5960, loss = 0.0267464
I0403 04:20:33.841348 32199 solver.cpp:244]     Train net output #0: loss = 0.0267464 (* 1 = 0.0267464 loss)
I0403 04:20:34.020221 32199 sgd_solver.cpp:106] Iteration 5960, lr = 5e-05
I0403 04:20:41.166844 32199 solver.cpp:228] Iteration 5970, loss = 0.000844314
I0403 04:20:41.166949 32199 solver.cpp:244]     Train net output #0: loss = 0.000844371 (* 1 = 0.000844371 loss)
I0403 04:20:41.394650 32199 sgd_solver.cpp:106] Iteration 5970, lr = 5e-05
I0403 04:20:48.521066 32199 solver.cpp:228] Iteration 5980, loss = 0.00422883
I0403 04:20:48.521155 32199 solver.cpp:244]     Train net output #0: loss = 0.00422889 (* 1 = 0.00422889 loss)
I0403 04:20:48.694618 32199 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 04:20:55.822655 32199 solver.cpp:228] Iteration 5990, loss = 0.00295447
I0403 04:20:55.822747 32199 solver.cpp:244]     Train net output #0: loss = 0.00295453 (* 1 = 0.00295453 loss)
I0403 04:20:55.993046 32199 sgd_solver.cpp:106] Iteration 5990, lr = 5e-05
I0403 04:21:03.153544 32199 solver.cpp:228] Iteration 6000, loss = 0.0134297
I0403 04:21:03.153645 32199 solver.cpp:244]     Train net output #0: loss = 0.0134298 (* 1 = 0.0134298 loss)
I0403 04:21:03.354677 32199 sgd_solver.cpp:106] Iteration 6000, lr = 5e-05
I0403 04:21:10.457999 32199 solver.cpp:228] Iteration 6010, loss = 0.00161055
I0403 04:21:10.458292 32199 solver.cpp:244]     Train net output #0: loss = 0.00161061 (* 1 = 0.00161061 loss)
I0403 04:21:10.619596 32199 sgd_solver.cpp:106] Iteration 6010, lr = 5e-05
I0403 04:21:17.760203 32199 solver.cpp:228] Iteration 6020, loss = 0.00817323
I0403 04:21:17.760306 32199 solver.cpp:244]     Train net output #0: loss = 0.00817329 (* 1 = 0.00817329 loss)
I0403 04:21:17.944926 32199 sgd_solver.cpp:106] Iteration 6020, lr = 5e-05
I0403 04:21:25.130254 32199 solver.cpp:228] Iteration 6030, loss = 0.012986
I0403 04:21:25.130354 32199 solver.cpp:244]     Train net output #0: loss = 0.012986 (* 1 = 0.012986 loss)
I0403 04:21:25.297482 32199 sgd_solver.cpp:106] Iteration 6030, lr = 5e-05
I0403 04:21:32.461412 32199 solver.cpp:228] Iteration 6040, loss = 0.00638686
I0403 04:21:32.461514 32199 solver.cpp:244]     Train net output #0: loss = 0.00638692 (* 1 = 0.00638692 loss)
I0403 04:21:32.648571 32199 sgd_solver.cpp:106] Iteration 6040, lr = 5e-05
I0403 04:21:39.862418 32199 solver.cpp:228] Iteration 6050, loss = 0.00477835
I0403 04:21:39.862519 32199 solver.cpp:244]     Train net output #0: loss = 0.00477841 (* 1 = 0.00477841 loss)
I0403 04:21:40.027570 32199 sgd_solver.cpp:106] Iteration 6050, lr = 5e-05
I0403 04:21:47.283918 32199 solver.cpp:228] Iteration 6060, loss = 0.010127
I0403 04:21:47.284235 32199 solver.cpp:244]     Train net output #0: loss = 0.010127 (* 1 = 0.010127 loss)
I0403 04:21:47.420425 32199 sgd_solver.cpp:106] Iteration 6060, lr = 5e-05
I0403 04:21:54.671049 32199 solver.cpp:228] Iteration 6070, loss = 0.00283479
I0403 04:21:54.671155 32199 solver.cpp:244]     Train net output #0: loss = 0.00283485 (* 1 = 0.00283485 loss)
I0403 04:21:54.854624 32199 sgd_solver.cpp:106] Iteration 6070, lr = 5e-05
I0403 04:22:01.970887 32199 solver.cpp:228] Iteration 6080, loss = 0.0122556
I0403 04:22:01.970979 32199 solver.cpp:244]     Train net output #0: loss = 0.0122556 (* 1 = 0.0122556 loss)
I0403 04:22:02.137662 32199 sgd_solver.cpp:106] Iteration 6080, lr = 5e-05
I0403 04:22:09.310598 32199 solver.cpp:228] Iteration 6090, loss = 0.00934899
I0403 04:22:09.310693 32199 solver.cpp:244]     Train net output #0: loss = 0.00934905 (* 1 = 0.00934905 loss)
I0403 04:22:09.485481 32199 sgd_solver.cpp:106] Iteration 6090, lr = 5e-05
I0403 04:22:16.824172 32199 solver.cpp:228] Iteration 6100, loss = 0.00212865
I0403 04:22:16.824264 32199 solver.cpp:244]     Train net output #0: loss = 0.0021287 (* 1 = 0.0021287 loss)
I0403 04:22:16.982954 32199 sgd_solver.cpp:106] Iteration 6100, lr = 5e-05
I0403 04:22:24.522025 32199 solver.cpp:228] Iteration 6110, loss = 0.00133062
I0403 04:22:24.522403 32199 solver.cpp:244]     Train net output #0: loss = 0.00133068 (* 1 = 0.00133068 loss)
I0403 04:22:24.707094 32199 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 04:22:31.819546 32199 solver.cpp:228] Iteration 6120, loss = 0.00204074
I0403 04:22:31.819638 32199 solver.cpp:244]     Train net output #0: loss = 0.0020408 (* 1 = 0.0020408 loss)
I0403 04:22:31.998618 32199 sgd_solver.cpp:106] Iteration 6120, lr = 5e-05
I0403 04:22:39.235584 32199 solver.cpp:228] Iteration 6130, loss = 0.0117903
I0403 04:22:39.238237 32199 solver.cpp:244]     Train net output #0: loss = 0.0117904 (* 1 = 0.0117904 loss)
I0403 04:22:39.407908 32199 sgd_solver.cpp:106] Iteration 6130, lr = 5e-05
I0403 04:22:40.133098 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6132.caffemodel
I0403 04:22:43.212697 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6132.solverstate
I0403 04:22:45.025981 32199 solver.cpp:337] Iteration 6132, Testing net (#0)
I0403 04:23:58.816149 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958174
I0403 04:23:58.816471 32199 solver.cpp:404]     Test net output #1: loss = 0.160764 (* 1 = 0.160764 loss)
I0403 04:24:05.160260 32199 solver.cpp:228] Iteration 6140, loss = 0.000235338
I0403 04:24:05.160364 32199 solver.cpp:244]     Train net output #0: loss = 0.000235395 (* 1 = 0.000235395 loss)
I0403 04:24:05.392043 32199 sgd_solver.cpp:106] Iteration 6140, lr = 5e-05
I0403 04:24:12.680385 32199 solver.cpp:228] Iteration 6150, loss = 0.00141909
I0403 04:24:12.680490 32199 solver.cpp:244]     Train net output #0: loss = 0.00141915 (* 1 = 0.00141915 loss)
I0403 04:24:12.874003 32199 sgd_solver.cpp:106] Iteration 6150, lr = 5e-05
I0403 04:24:20.000682 32199 solver.cpp:228] Iteration 6160, loss = 0.0113069
I0403 04:24:20.000777 32199 solver.cpp:244]     Train net output #0: loss = 0.011307 (* 1 = 0.011307 loss)
I0403 04:24:20.167048 32199 sgd_solver.cpp:106] Iteration 6160, lr = 5e-05
I0403 04:24:27.491739 32199 solver.cpp:228] Iteration 6170, loss = 0.00266724
I0403 04:24:27.491824 32199 solver.cpp:244]     Train net output #0: loss = 0.0026673 (* 1 = 0.0026673 loss)
I0403 04:24:27.666725 32199 sgd_solver.cpp:106] Iteration 6170, lr = 5e-05
I0403 04:24:34.930402 32199 solver.cpp:228] Iteration 6180, loss = 0.00393813
I0403 04:24:34.930714 32199 solver.cpp:244]     Train net output #0: loss = 0.0039382 (* 1 = 0.0039382 loss)
I0403 04:24:35.102639 32199 sgd_solver.cpp:106] Iteration 6180, lr = 5e-05
I0403 04:24:42.311758 32199 solver.cpp:228] Iteration 6190, loss = 0.0020208
I0403 04:24:42.311861 32199 solver.cpp:244]     Train net output #0: loss = 0.00202086 (* 1 = 0.00202086 loss)
I0403 04:24:42.509268 32199 sgd_solver.cpp:106] Iteration 6190, lr = 5e-05
I0403 04:24:49.540112 32199 solver.cpp:228] Iteration 6200, loss = 0.0230747
I0403 04:24:49.540215 32199 solver.cpp:244]     Train net output #0: loss = 0.0230748 (* 1 = 0.0230748 loss)
I0403 04:24:49.750000 32199 sgd_solver.cpp:106] Iteration 6200, lr = 5e-05
I0403 04:24:56.782331 32199 solver.cpp:228] Iteration 6210, loss = 0.00952455
I0403 04:24:56.782428 32199 solver.cpp:244]     Train net output #0: loss = 0.00952461 (* 1 = 0.00952461 loss)
I0403 04:24:56.951603 32199 sgd_solver.cpp:106] Iteration 6210, lr = 5e-05
I0403 04:25:04.065364 32199 solver.cpp:228] Iteration 6220, loss = 0.00737087
I0403 04:25:04.065460 32199 solver.cpp:244]     Train net output #0: loss = 0.00737093 (* 1 = 0.00737093 loss)
I0403 04:25:04.249006 32199 sgd_solver.cpp:106] Iteration 6220, lr = 5e-05
I0403 04:25:11.369583 32199 solver.cpp:228] Iteration 6230, loss = 0.00142049
I0403 04:25:11.369947 32199 solver.cpp:244]     Train net output #0: loss = 0.00142055 (* 1 = 0.00142055 loss)
I0403 04:25:11.559583 32199 sgd_solver.cpp:106] Iteration 6230, lr = 5e-05
I0403 04:25:18.787441 32199 solver.cpp:228] Iteration 6240, loss = 0.00091665
I0403 04:25:18.787530 32199 solver.cpp:244]     Train net output #0: loss = 0.000916714 (* 1 = 0.000916714 loss)
I0403 04:25:18.939134 32199 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 04:25:26.380852 32199 solver.cpp:228] Iteration 6250, loss = 0.0261337
I0403 04:25:26.380939 32199 solver.cpp:244]     Train net output #0: loss = 0.0261337 (* 1 = 0.0261337 loss)
I0403 04:25:26.381314 32199 sgd_solver.cpp:106] Iteration 6250, lr = 5e-05
I0403 04:25:33.680752 32199 solver.cpp:228] Iteration 6260, loss = 0.00232581
I0403 04:25:33.680838 32199 solver.cpp:244]     Train net output #0: loss = 0.00232587 (* 1 = 0.00232587 loss)
I0403 04:25:33.857265 32199 sgd_solver.cpp:106] Iteration 6260, lr = 5e-05
I0403 04:25:40.991513 32199 solver.cpp:228] Iteration 6270, loss = 0.000446323
I0403 04:25:40.991605 32199 solver.cpp:244]     Train net output #0: loss = 0.000446388 (* 1 = 0.000446388 loss)
I0403 04:25:41.155752 32199 sgd_solver.cpp:106] Iteration 6270, lr = 5e-05
I0403 04:25:48.338086 32199 solver.cpp:228] Iteration 6280, loss = 0.0212297
I0403 04:25:48.338383 32199 solver.cpp:244]     Train net output #0: loss = 0.0212297 (* 1 = 0.0212297 loss)
I0403 04:25:48.468107 32199 sgd_solver.cpp:106] Iteration 6280, lr = 5e-05
I0403 04:25:55.863430 32199 solver.cpp:228] Iteration 6290, loss = 0.0266254
I0403 04:25:55.863520 32199 solver.cpp:244]     Train net output #0: loss = 0.0266255 (* 1 = 0.0266255 loss)
I0403 04:25:56.023478 32199 sgd_solver.cpp:106] Iteration 6290, lr = 5e-05
I0403 04:26:03.354032 32199 solver.cpp:228] Iteration 6300, loss = 0.00181559
I0403 04:26:03.354123 32199 solver.cpp:244]     Train net output #0: loss = 0.00181566 (* 1 = 0.00181566 loss)
I0403 04:26:03.529408 32199 sgd_solver.cpp:106] Iteration 6300, lr = 5e-05
I0403 04:26:10.928350 32199 solver.cpp:228] Iteration 6310, loss = 0.00074655
I0403 04:26:10.928447 32199 solver.cpp:244]     Train net output #0: loss = 0.000746609 (* 1 = 0.000746609 loss)
I0403 04:26:11.105339 32199 sgd_solver.cpp:106] Iteration 6310, lr = 5e-05
I0403 04:26:18.226380 32199 solver.cpp:228] Iteration 6320, loss = 0.0039129
I0403 04:26:18.226469 32199 solver.cpp:244]     Train net output #0: loss = 0.00391296 (* 1 = 0.00391296 loss)
I0403 04:26:18.403844 32199 sgd_solver.cpp:106] Iteration 6320, lr = 5e-05
I0403 04:26:25.503741 32199 solver.cpp:228] Iteration 6330, loss = 0.0106458
I0403 04:26:25.503836 32199 solver.cpp:244]     Train net output #0: loss = 0.0106459 (* 1 = 0.0106459 loss)
I0403 04:26:25.674072 32199 sgd_solver.cpp:106] Iteration 6330, lr = 5e-05
I0403 04:26:32.951217 32199 solver.cpp:228] Iteration 6340, loss = 0.0012686
I0403 04:26:32.951316 32199 solver.cpp:244]     Train net output #0: loss = 0.00126866 (* 1 = 0.00126866 loss)
I0403 04:26:33.139683 32199 sgd_solver.cpp:106] Iteration 6340, lr = 5e-05
I0403 04:26:40.291595 32199 solver.cpp:228] Iteration 6350, loss = 0.0311983
I0403 04:26:40.291697 32199 solver.cpp:244]     Train net output #0: loss = 0.0311984 (* 1 = 0.0311984 loss)
I0403 04:26:40.492074 32199 sgd_solver.cpp:106] Iteration 6350, lr = 5e-05
I0403 04:26:40.492318 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6351.caffemodel
I0403 04:26:43.147330 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6351.solverstate
I0403 04:26:44.967728 32199 solver.cpp:337] Iteration 6351, Testing net (#0)
I0403 04:27:58.775317 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958762
I0403 04:27:58.782814 32199 solver.cpp:404]     Test net output #1: loss = 0.159165 (* 1 = 0.159165 loss)
I0403 04:28:05.972504 32199 solver.cpp:228] Iteration 6360, loss = 0.0221038
I0403 04:28:05.972595 32199 solver.cpp:244]     Train net output #0: loss = 0.0221039 (* 1 = 0.0221039 loss)
I0403 04:28:06.127337 32199 sgd_solver.cpp:106] Iteration 6360, lr = 5e-05
I0403 04:28:13.537088 32199 solver.cpp:228] Iteration 6370, loss = 0.00195339
I0403 04:28:13.537192 32199 solver.cpp:244]     Train net output #0: loss = 0.00195344 (* 1 = 0.00195344 loss)
I0403 04:28:13.720429 32199 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 04:28:21.011626 32199 solver.cpp:228] Iteration 6380, loss = 0.00846908
I0403 04:28:21.011715 32199 solver.cpp:244]     Train net output #0: loss = 0.00846914 (* 1 = 0.00846914 loss)
I0403 04:28:21.192489 32199 sgd_solver.cpp:106] Iteration 6380, lr = 5e-05
I0403 04:28:28.457629 32199 solver.cpp:228] Iteration 6390, loss = 0.0064548
I0403 04:28:28.457715 32199 solver.cpp:244]     Train net output #0: loss = 0.00645486 (* 1 = 0.00645486 loss)
I0403 04:28:28.604738 32199 sgd_solver.cpp:106] Iteration 6390, lr = 5e-05
I0403 04:28:35.835700 32199 solver.cpp:228] Iteration 6400, loss = 0.0043859
I0403 04:28:35.836019 32199 solver.cpp:244]     Train net output #0: loss = 0.00438595 (* 1 = 0.00438595 loss)
I0403 04:28:36.019220 32199 sgd_solver.cpp:106] Iteration 6400, lr = 5e-05
I0403 04:28:43.198166 32199 solver.cpp:228] Iteration 6410, loss = 0.000433233
I0403 04:28:43.198259 32199 solver.cpp:244]     Train net output #0: loss = 0.00043329 (* 1 = 0.00043329 loss)
I0403 04:28:43.380053 32199 sgd_solver.cpp:106] Iteration 6410, lr = 5e-05
I0403 04:28:50.496781 32199 solver.cpp:228] Iteration 6420, loss = 0.00479213
I0403 04:28:50.496871 32199 solver.cpp:244]     Train net output #0: loss = 0.00479219 (* 1 = 0.00479219 loss)
I0403 04:28:50.668340 32199 sgd_solver.cpp:106] Iteration 6420, lr = 5e-05
I0403 04:28:57.891968 32199 solver.cpp:228] Iteration 6430, loss = 0.0065516
I0403 04:28:57.892053 32199 solver.cpp:244]     Train net output #0: loss = 0.00655166 (* 1 = 0.00655166 loss)
I0403 04:28:58.055197 32199 sgd_solver.cpp:106] Iteration 6430, lr = 5e-05
I0403 04:29:05.155704 32199 solver.cpp:228] Iteration 6440, loss = 0.00212972
I0403 04:29:05.155797 32199 solver.cpp:244]     Train net output #0: loss = 0.00212978 (* 1 = 0.00212978 loss)
I0403 04:29:05.321887 32199 sgd_solver.cpp:106] Iteration 6440, lr = 5e-05
I0403 04:29:12.548384 32199 solver.cpp:228] Iteration 6450, loss = 0.00128031
I0403 04:29:12.548676 32199 solver.cpp:244]     Train net output #0: loss = 0.00128037 (* 1 = 0.00128037 loss)
I0403 04:29:12.680429 32199 sgd_solver.cpp:106] Iteration 6450, lr = 5e-05
I0403 04:29:20.087851 32199 solver.cpp:228] Iteration 6460, loss = 0.00528538
I0403 04:29:20.087942 32199 solver.cpp:244]     Train net output #0: loss = 0.00528544 (* 1 = 0.00528544 loss)
I0403 04:29:20.243233 32199 sgd_solver.cpp:106] Iteration 6460, lr = 5e-05
I0403 04:29:27.478535 32199 solver.cpp:228] Iteration 6470, loss = 0.00103772
I0403 04:29:27.478638 32199 solver.cpp:244]     Train net output #0: loss = 0.00103778 (* 1 = 0.00103778 loss)
I0403 04:29:27.704304 32199 sgd_solver.cpp:106] Iteration 6470, lr = 5e-05
I0403 04:29:34.866806 32199 solver.cpp:228] Iteration 6480, loss = 0.000309398
I0403 04:29:34.866919 32199 solver.cpp:244]     Train net output #0: loss = 0.000309453 (* 1 = 0.000309453 loss)
I0403 04:29:35.029184 32199 sgd_solver.cpp:106] Iteration 6480, lr = 5e-05
I0403 04:29:42.291128 32199 solver.cpp:228] Iteration 6490, loss = 0.0161517
I0403 04:29:42.291218 32199 solver.cpp:244]     Train net output #0: loss = 0.0161517 (* 1 = 0.0161517 loss)
I0403 04:29:42.470320 32199 sgd_solver.cpp:106] Iteration 6490, lr = 5e-05
I0403 04:29:49.677600 32199 solver.cpp:228] Iteration 6500, loss = 0.000692099
I0403 04:29:49.677947 32199 solver.cpp:244]     Train net output #0: loss = 0.000692155 (* 1 = 0.000692155 loss)
I0403 04:29:49.806632 32199 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 04:29:57.063973 32199 solver.cpp:228] Iteration 6510, loss = 0.00542799
I0403 04:29:57.064076 32199 solver.cpp:244]     Train net output #0: loss = 0.00542805 (* 1 = 0.00542805 loss)
I0403 04:29:57.247433 32199 sgd_solver.cpp:106] Iteration 6510, lr = 5e-05
I0403 04:30:04.486151 32199 solver.cpp:228] Iteration 6520, loss = 0.0241193
I0403 04:30:04.486255 32199 solver.cpp:244]     Train net output #0: loss = 0.0241194 (* 1 = 0.0241194 loss)
I0403 04:30:04.684564 32199 sgd_solver.cpp:106] Iteration 6520, lr = 5e-05
I0403 04:30:11.855669 32199 solver.cpp:228] Iteration 6530, loss = 0.00847269
I0403 04:30:11.855772 32199 solver.cpp:244]     Train net output #0: loss = 0.00847274 (* 1 = 0.00847274 loss)
I0403 04:30:12.050741 32199 sgd_solver.cpp:106] Iteration 6530, lr = 5e-05
I0403 04:30:19.340839 32199 solver.cpp:228] Iteration 6540, loss = 0.000880719
I0403 04:30:19.340936 32199 solver.cpp:244]     Train net output #0: loss = 0.000880775 (* 1 = 0.000880775 loss)
I0403 04:30:19.502933 32199 sgd_solver.cpp:106] Iteration 6540, lr = 5e-05
I0403 04:30:26.665652 32199 solver.cpp:228] Iteration 6550, loss = 0.00476409
I0403 04:30:26.665961 32199 solver.cpp:244]     Train net output #0: loss = 0.00476415 (* 1 = 0.00476415 loss)
I0403 04:30:26.849182 32199 sgd_solver.cpp:106] Iteration 6550, lr = 5e-05
I0403 04:30:34.221735 32199 solver.cpp:228] Iteration 6560, loss = 0.00308207
I0403 04:30:34.221827 32199 solver.cpp:244]     Train net output #0: loss = 0.00308213 (* 1 = 0.00308213 loss)
I0403 04:30:34.400032 32199 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 04:30:41.041795 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6570.caffemodel
I0403 04:30:43.789862 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6570.solverstate
I0403 04:30:45.685178 32199 solver.cpp:337] Iteration 6570, Testing net (#0)
I0403 04:31:59.480139 32199 solver.cpp:404]     Test net output #0: accuracy = 0.958825
I0403 04:31:59.480460 32199 solver.cpp:404]     Test net output #1: loss = 0.160024 (* 1 = 0.160024 loss)
I0403 04:32:00.000231 32199 solver.cpp:228] Iteration 6570, loss = 0.00697294
I0403 04:32:00.000319 32199 solver.cpp:244]     Train net output #0: loss = 0.006973 (* 1 = 0.006973 loss)
I0403 04:32:00.168166 32199 sgd_solver.cpp:106] Iteration 6570, lr = 5e-05
I0403 04:32:07.263325 32199 solver.cpp:228] Iteration 6580, loss = 0.00356283
I0403 04:32:07.263419 32199 solver.cpp:244]     Train net output #0: loss = 0.00356289 (* 1 = 0.00356289 loss)
I0403 04:32:07.420248 32199 sgd_solver.cpp:106] Iteration 6580, lr = 5e-05
I0403 04:32:13.298708 32199 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6589.caffemodel
I0403 04:32:15.962605 32199 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_finetune/snapshots__iter_6589.solverstate
I0403 04:32:17.758896 32199 solver.cpp:322] Optimization Done.
I0403 04:32:17.950214 32199 caffe.cpp:222] Optimization Done.
