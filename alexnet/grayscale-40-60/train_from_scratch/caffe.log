I0403 07:33:20.761468 24116 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 07:33:20.761878 24116 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 07:33:20.761907 24116 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 07:33:25.253231 24116 caffe.cpp:185] Using GPUs 0, 1
I0403 07:33:25.253737 24116 caffe.cpp:190] GPU 0: Tesla K40m
I0403 07:33:25.254175 24116 caffe.cpp:190] GPU 1: Tesla K40m
I0403 07:33:25.512182 24116 solver.cpp:48] Initializing solver from parameters: 
test_iter: 323
test_interval: 219
base_lr: 0.005
display: 10
max_iter: 6589
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2196
snapshot: 219
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 07:33:25.526432 24116 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 07:33:25.553004 24116 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 07:33:25.553066 24116 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 07:33:25.553894 24116 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 07:33:25.554450 24116 layer_factory.hpp:77] Creating layer data
I0403 07:33:25.555243 24116 net.cpp:91] Creating Layer data
I0403 07:33:25.556828 24116 net.cpp:399] data -> data
I0403 07:33:25.556895 24116 net.cpp:399] data -> label
I0403 07:33:25.556936 24116 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto
I0403 07:33:25.693534 24119 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/train_db
I0403 07:33:25.716369 24116 data_layer.cpp:41] output data size: 100,3,227,227
I0403 07:33:25.859091 24116 net.cpp:141] Setting up data
I0403 07:33:25.859191 24116 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 07:33:25.859218 24116 net.cpp:148] Top shape: 100 (100)
I0403 07:33:25.859237 24116 net.cpp:156] Memory required for data: 61835200
I0403 07:33:25.859273 24116 layer_factory.hpp:77] Creating layer conv1
I0403 07:33:25.859323 24116 net.cpp:91] Creating Layer conv1
I0403 07:33:25.859350 24116 net.cpp:425] conv1 <- data
I0403 07:33:25.859388 24116 net.cpp:399] conv1 -> conv1
I0403 07:33:25.862593 24116 net.cpp:141] Setting up conv1
I0403 07:33:25.862632 24116 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:33:25.862653 24116 net.cpp:156] Memory required for data: 177995200
I0403 07:33:25.862694 24116 layer_factory.hpp:77] Creating layer relu1
I0403 07:33:25.862728 24116 net.cpp:91] Creating Layer relu1
I0403 07:33:25.862756 24116 net.cpp:425] relu1 <- conv1
I0403 07:33:25.862788 24116 net.cpp:386] relu1 -> conv1 (in-place)
I0403 07:33:25.862819 24116 net.cpp:141] Setting up relu1
I0403 07:33:25.862843 24116 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:33:25.862862 24116 net.cpp:156] Memory required for data: 294155200
I0403 07:33:25.862880 24116 layer_factory.hpp:77] Creating layer norm1
I0403 07:33:25.862942 24116 net.cpp:91] Creating Layer norm1
I0403 07:33:25.862964 24116 net.cpp:425] norm1 <- conv1
I0403 07:33:25.862988 24116 net.cpp:399] norm1 -> norm1
I0403 07:33:25.868589 24116 net.cpp:141] Setting up norm1
I0403 07:33:25.868633 24116 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:33:25.868654 24116 net.cpp:156] Memory required for data: 410315200
I0403 07:33:25.868671 24116 layer_factory.hpp:77] Creating layer pool1
I0403 07:33:25.868698 24116 net.cpp:91] Creating Layer pool1
I0403 07:33:25.868721 24116 net.cpp:425] pool1 <- norm1
I0403 07:33:25.868749 24116 net.cpp:399] pool1 -> pool1
I0403 07:33:25.868839 24116 net.cpp:141] Setting up pool1
I0403 07:33:25.868870 24116 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 07:33:25.868890 24116 net.cpp:156] Memory required for data: 438308800
I0403 07:33:25.868908 24116 layer_factory.hpp:77] Creating layer conv2
I0403 07:33:25.868937 24116 net.cpp:91] Creating Layer conv2
I0403 07:33:25.868958 24116 net.cpp:425] conv2 <- pool1
I0403 07:33:25.868983 24116 net.cpp:399] conv2 -> conv2
I0403 07:33:25.870815 24121 blocking_queue.cpp:50] Waiting for data
I0403 07:33:25.888366 24116 net.cpp:141] Setting up conv2
I0403 07:33:25.888404 24116 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:33:25.888425 24116 net.cpp:156] Memory required for data: 512958400
I0403 07:33:25.888453 24116 layer_factory.hpp:77] Creating layer relu2
I0403 07:33:25.888478 24116 net.cpp:91] Creating Layer relu2
I0403 07:33:25.888499 24116 net.cpp:425] relu2 <- conv2
I0403 07:33:25.888520 24116 net.cpp:386] relu2 -> conv2 (in-place)
I0403 07:33:25.888545 24116 net.cpp:141] Setting up relu2
I0403 07:33:25.888566 24116 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:33:25.888583 24116 net.cpp:156] Memory required for data: 587608000
I0403 07:33:25.888602 24116 layer_factory.hpp:77] Creating layer norm2
I0403 07:33:25.888625 24116 net.cpp:91] Creating Layer norm2
I0403 07:33:25.888645 24116 net.cpp:425] norm2 <- conv2
I0403 07:33:25.888669 24116 net.cpp:399] norm2 -> norm2
I0403 07:33:25.888727 24116 net.cpp:141] Setting up norm2
I0403 07:33:25.888761 24116 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:33:25.888780 24116 net.cpp:156] Memory required for data: 662257600
I0403 07:33:25.888798 24116 layer_factory.hpp:77] Creating layer pool2
I0403 07:33:25.888824 24116 net.cpp:91] Creating Layer pool2
I0403 07:33:25.888844 24116 net.cpp:425] pool2 <- norm2
I0403 07:33:25.888865 24116 net.cpp:399] pool2 -> pool2
I0403 07:33:25.888922 24116 net.cpp:141] Setting up pool2
I0403 07:33:25.888950 24116 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:33:25.888969 24116 net.cpp:156] Memory required for data: 679563200
I0403 07:33:25.888988 24116 layer_factory.hpp:77] Creating layer conv3
I0403 07:33:25.889015 24116 net.cpp:91] Creating Layer conv3
I0403 07:33:25.889039 24116 net.cpp:425] conv3 <- pool2
I0403 07:33:25.889062 24116 net.cpp:399] conv3 -> conv3
I0403 07:33:25.930881 24116 net.cpp:141] Setting up conv3
I0403 07:33:25.930919 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:25.930940 24116 net.cpp:156] Memory required for data: 705521600
I0403 07:33:25.930968 24116 layer_factory.hpp:77] Creating layer relu3
I0403 07:33:25.930994 24116 net.cpp:91] Creating Layer relu3
I0403 07:33:25.931015 24116 net.cpp:425] relu3 <- conv3
I0403 07:33:25.931036 24116 net.cpp:386] relu3 -> conv3 (in-place)
I0403 07:33:25.931071 24116 net.cpp:141] Setting up relu3
I0403 07:33:25.931093 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:25.931113 24116 net.cpp:156] Memory required for data: 731480000
I0403 07:33:25.931130 24116 layer_factory.hpp:77] Creating layer conv4
I0403 07:33:25.931156 24116 net.cpp:91] Creating Layer conv4
I0403 07:33:25.931179 24116 net.cpp:425] conv4 <- conv3
I0403 07:33:25.931202 24116 net.cpp:399] conv4 -> conv4
I0403 07:33:25.962674 24116 net.cpp:141] Setting up conv4
I0403 07:33:25.962712 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:25.962733 24116 net.cpp:156] Memory required for data: 757438400
I0403 07:33:25.962781 24116 layer_factory.hpp:77] Creating layer relu4
I0403 07:33:25.962808 24116 net.cpp:91] Creating Layer relu4
I0403 07:33:25.962829 24116 net.cpp:425] relu4 <- conv4
I0403 07:33:25.962853 24116 net.cpp:386] relu4 -> conv4 (in-place)
I0403 07:33:25.962878 24116 net.cpp:141] Setting up relu4
I0403 07:33:25.962901 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:25.962920 24116 net.cpp:156] Memory required for data: 783396800
I0403 07:33:25.962937 24116 layer_factory.hpp:77] Creating layer conv5
I0403 07:33:25.962965 24116 net.cpp:91] Creating Layer conv5
I0403 07:33:25.962985 24116 net.cpp:425] conv5 <- conv4
I0403 07:33:25.963011 24116 net.cpp:399] conv5 -> conv5
I0403 07:33:25.984151 24116 net.cpp:141] Setting up conv5
I0403 07:33:25.984189 24116 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:33:25.984210 24116 net.cpp:156] Memory required for data: 800702400
I0403 07:33:25.984241 24116 layer_factory.hpp:77] Creating layer relu5
I0403 07:33:25.984266 24116 net.cpp:91] Creating Layer relu5
I0403 07:33:25.984287 24116 net.cpp:425] relu5 <- conv5
I0403 07:33:25.984310 24116 net.cpp:386] relu5 -> conv5 (in-place)
I0403 07:33:25.984335 24116 net.cpp:141] Setting up relu5
I0403 07:33:25.984357 24116 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:33:25.984376 24116 net.cpp:156] Memory required for data: 818008000
I0403 07:33:25.984395 24116 layer_factory.hpp:77] Creating layer pool5
I0403 07:33:25.984417 24116 net.cpp:91] Creating Layer pool5
I0403 07:33:25.984437 24116 net.cpp:425] pool5 <- conv5
I0403 07:33:25.984459 24116 net.cpp:399] pool5 -> pool5
I0403 07:33:25.984519 24116 net.cpp:141] Setting up pool5
I0403 07:33:25.984547 24116 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 07:33:25.984566 24116 net.cpp:156] Memory required for data: 821694400
I0403 07:33:25.984585 24116 layer_factory.hpp:77] Creating layer fc6
I0403 07:33:25.984621 24116 net.cpp:91] Creating Layer fc6
I0403 07:33:25.984643 24116 net.cpp:425] fc6 <- pool5
I0403 07:33:25.984668 24116 net.cpp:399] fc6 -> fc6
I0403 07:33:27.515008 24116 net.cpp:141] Setting up fc6
I0403 07:33:27.515090 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:27.515107 24116 net.cpp:156] Memory required for data: 823332800
I0403 07:33:27.515130 24116 layer_factory.hpp:77] Creating layer relu6
I0403 07:33:27.515153 24116 net.cpp:91] Creating Layer relu6
I0403 07:33:27.515172 24116 net.cpp:425] relu6 <- fc6
I0403 07:33:27.515192 24116 net.cpp:386] relu6 -> fc6 (in-place)
I0403 07:33:27.515216 24116 net.cpp:141] Setting up relu6
I0403 07:33:27.515234 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:27.515249 24116 net.cpp:156] Memory required for data: 824971200
I0403 07:33:27.515264 24116 layer_factory.hpp:77] Creating layer drop6
I0403 07:33:27.515288 24116 net.cpp:91] Creating Layer drop6
I0403 07:33:27.515305 24116 net.cpp:425] drop6 <- fc6
I0403 07:33:27.515323 24116 net.cpp:386] drop6 -> fc6 (in-place)
I0403 07:33:27.515369 24116 net.cpp:141] Setting up drop6
I0403 07:33:27.515391 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:27.515406 24116 net.cpp:156] Memory required for data: 826609600
I0403 07:33:27.515420 24116 layer_factory.hpp:77] Creating layer fc7
I0403 07:33:27.515442 24116 net.cpp:91] Creating Layer fc7
I0403 07:33:27.515460 24116 net.cpp:425] fc7 <- fc6
I0403 07:33:27.515480 24116 net.cpp:399] fc7 -> fc7
I0403 07:33:28.125238 24116 net.cpp:141] Setting up fc7
I0403 07:33:28.125319 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:28.125335 24116 net.cpp:156] Memory required for data: 828248000
I0403 07:33:28.125357 24116 layer_factory.hpp:77] Creating layer relu7
I0403 07:33:28.125381 24116 net.cpp:91] Creating Layer relu7
I0403 07:33:28.125398 24116 net.cpp:425] relu7 <- fc7
I0403 07:33:28.125422 24116 net.cpp:386] relu7 -> fc7 (in-place)
I0403 07:33:28.125445 24116 net.cpp:141] Setting up relu7
I0403 07:33:28.125463 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:28.125478 24116 net.cpp:156] Memory required for data: 829886400
I0403 07:33:28.125525 24116 layer_factory.hpp:77] Creating layer drop7
I0403 07:33:28.125547 24116 net.cpp:91] Creating Layer drop7
I0403 07:33:28.125562 24116 net.cpp:425] drop7 <- fc7
I0403 07:33:28.125579 24116 net.cpp:386] drop7 -> fc7 (in-place)
I0403 07:33:28.125619 24116 net.cpp:141] Setting up drop7
I0403 07:33:28.125640 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:28.125655 24116 net.cpp:156] Memory required for data: 831524800
I0403 07:33:28.125669 24116 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 07:33:28.125694 24116 net.cpp:91] Creating Layer fc8_plantvillage
I0403 07:33:28.125711 24116 net.cpp:425] fc8_plantvillage <- fc7
I0403 07:33:28.125730 24116 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 07:33:28.131784 24116 net.cpp:141] Setting up fc8_plantvillage
I0403 07:33:28.131813 24116 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:33:28.131829 24116 net.cpp:156] Memory required for data: 831540000
I0403 07:33:28.131847 24116 layer_factory.hpp:77] Creating layer loss
I0403 07:33:28.131873 24116 net.cpp:91] Creating Layer loss
I0403 07:33:28.131891 24116 net.cpp:425] loss <- fc8_plantvillage
I0403 07:33:28.131907 24116 net.cpp:425] loss <- label
I0403 07:33:28.131932 24116 net.cpp:399] loss -> loss
I0403 07:33:28.131961 24116 layer_factory.hpp:77] Creating layer loss
I0403 07:33:28.132061 24116 net.cpp:141] Setting up loss
I0403 07:33:28.132084 24116 net.cpp:148] Top shape: (1)
I0403 07:33:28.132099 24116 net.cpp:151]     with loss weight 1
I0403 07:33:28.132154 24116 net.cpp:156] Memory required for data: 831540004
I0403 07:33:28.132170 24116 net.cpp:217] loss needs backward computation.
I0403 07:33:28.132185 24116 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 07:33:28.132200 24116 net.cpp:217] drop7 needs backward computation.
I0403 07:33:28.132215 24116 net.cpp:217] relu7 needs backward computation.
I0403 07:33:28.132230 24116 net.cpp:217] fc7 needs backward computation.
I0403 07:33:28.132243 24116 net.cpp:217] drop6 needs backward computation.
I0403 07:33:28.132257 24116 net.cpp:217] relu6 needs backward computation.
I0403 07:33:28.132272 24116 net.cpp:217] fc6 needs backward computation.
I0403 07:33:28.132285 24116 net.cpp:217] pool5 needs backward computation.
I0403 07:33:28.132299 24116 net.cpp:217] relu5 needs backward computation.
I0403 07:33:28.132314 24116 net.cpp:217] conv5 needs backward computation.
I0403 07:33:28.132328 24116 net.cpp:217] relu4 needs backward computation.
I0403 07:33:28.132342 24116 net.cpp:217] conv4 needs backward computation.
I0403 07:33:28.132355 24116 net.cpp:217] relu3 needs backward computation.
I0403 07:33:28.132370 24116 net.cpp:217] conv3 needs backward computation.
I0403 07:33:28.132385 24116 net.cpp:217] pool2 needs backward computation.
I0403 07:33:28.132400 24116 net.cpp:217] norm2 needs backward computation.
I0403 07:33:28.132413 24116 net.cpp:217] relu2 needs backward computation.
I0403 07:33:28.132426 24116 net.cpp:217] conv2 needs backward computation.
I0403 07:33:28.132441 24116 net.cpp:217] pool1 needs backward computation.
I0403 07:33:28.132455 24116 net.cpp:217] norm1 needs backward computation.
I0403 07:33:28.132470 24116 net.cpp:217] relu1 needs backward computation.
I0403 07:33:28.132484 24116 net.cpp:217] conv1 needs backward computation.
I0403 07:33:28.132499 24116 net.cpp:219] data does not need backward computation.
I0403 07:33:28.132513 24116 net.cpp:261] This network produces output loss
I0403 07:33:28.132535 24116 net.cpp:274] Network initialization done.
I0403 07:33:28.133589 24116 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 07:33:28.133646 24116 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 07:33:28.134299 24116 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-40-60/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 07:33:28.134460 24116 layer_factory.hpp:77] Creating layer data
I0403 07:33:28.134625 24116 net.cpp:91] Creating Layer data
I0403 07:33:28.134652 24116 net.cpp:399] data -> data
I0403 07:33:28.134678 24116 net.cpp:399] data -> label
I0403 07:33:28.134701 24116 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/mean.binaryproto
I0403 07:33:28.222684 24124 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-40-60/test_db
I0403 07:33:28.260860 24116 data_layer.cpp:41] output data size: 100,3,227,227
I0403 07:33:28.445894 24116 net.cpp:141] Setting up data
I0403 07:33:28.445961 24116 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 07:33:28.445984 24116 net.cpp:148] Top shape: 100 (100)
I0403 07:33:28.446003 24116 net.cpp:156] Memory required for data: 61835200
I0403 07:33:28.446030 24116 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 07:33:28.446069 24116 net.cpp:91] Creating Layer label_data_1_split
I0403 07:33:28.446095 24116 net.cpp:425] label_data_1_split <- label
I0403 07:33:28.446120 24116 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 07:33:28.446154 24116 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 07:33:28.446238 24116 net.cpp:141] Setting up label_data_1_split
I0403 07:33:28.446269 24116 net.cpp:148] Top shape: 100 (100)
I0403 07:33:28.446293 24116 net.cpp:148] Top shape: 100 (100)
I0403 07:33:28.446310 24116 net.cpp:156] Memory required for data: 61836000
I0403 07:33:28.446333 24116 layer_factory.hpp:77] Creating layer conv1
I0403 07:33:28.446370 24116 net.cpp:91] Creating Layer conv1
I0403 07:33:28.446393 24116 net.cpp:425] conv1 <- data
I0403 07:33:28.446420 24116 net.cpp:399] conv1 -> conv1
I0403 07:33:28.448060 24116 net.cpp:141] Setting up conv1
I0403 07:33:28.448096 24116 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:33:28.448120 24116 net.cpp:156] Memory required for data: 177996000
I0403 07:33:28.448153 24116 layer_factory.hpp:77] Creating layer relu1
I0403 07:33:28.448176 24116 net.cpp:91] Creating Layer relu1
I0403 07:33:28.448204 24116 net.cpp:425] relu1 <- conv1
I0403 07:33:28.448230 24116 net.cpp:386] relu1 -> conv1 (in-place)
I0403 07:33:28.448258 24116 net.cpp:141] Setting up relu1
I0403 07:33:28.448278 24116 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:33:28.448302 24116 net.cpp:156] Memory required for data: 294156000
I0403 07:33:28.448325 24116 layer_factory.hpp:77] Creating layer norm1
I0403 07:33:28.448348 24116 net.cpp:91] Creating Layer norm1
I0403 07:33:28.448375 24116 net.cpp:425] norm1 <- conv1
I0403 07:33:28.448401 24116 net.cpp:399] norm1 -> norm1
I0403 07:33:28.448457 24116 net.cpp:141] Setting up norm1
I0403 07:33:28.448487 24116 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 07:33:28.448505 24116 net.cpp:156] Memory required for data: 410316000
I0403 07:33:28.448525 24116 layer_factory.hpp:77] Creating layer pool1
I0403 07:33:28.448551 24116 net.cpp:91] Creating Layer pool1
I0403 07:33:28.448568 24116 net.cpp:425] pool1 <- norm1
I0403 07:33:28.448596 24116 net.cpp:399] pool1 -> pool1
I0403 07:33:28.448654 24116 net.cpp:141] Setting up pool1
I0403 07:33:28.448679 24116 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 07:33:28.448696 24116 net.cpp:156] Memory required for data: 438309600
I0403 07:33:28.448734 24116 layer_factory.hpp:77] Creating layer conv2
I0403 07:33:28.448777 24116 net.cpp:91] Creating Layer conv2
I0403 07:33:28.448801 24116 net.cpp:425] conv2 <- pool1
I0403 07:33:28.448832 24116 net.cpp:399] conv2 -> conv2
I0403 07:33:28.461518 24116 net.cpp:141] Setting up conv2
I0403 07:33:28.487117 24116 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:33:28.487139 24116 net.cpp:156] Memory required for data: 512959200
I0403 07:33:28.487162 24116 layer_factory.hpp:77] Creating layer relu2
I0403 07:33:28.487185 24116 net.cpp:91] Creating Layer relu2
I0403 07:33:28.487201 24116 net.cpp:425] relu2 <- conv2
I0403 07:33:28.487221 24116 net.cpp:386] relu2 -> conv2 (in-place)
I0403 07:33:28.487242 24116 net.cpp:141] Setting up relu2
I0403 07:33:28.487260 24116 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:33:28.487275 24116 net.cpp:156] Memory required for data: 587608800
I0403 07:33:28.487290 24116 layer_factory.hpp:77] Creating layer norm2
I0403 07:33:28.487311 24116 net.cpp:91] Creating Layer norm2
I0403 07:33:28.487337 24116 net.cpp:425] norm2 <- conv2
I0403 07:33:28.487363 24116 net.cpp:399] norm2 -> norm2
I0403 07:33:28.487422 24116 net.cpp:141] Setting up norm2
I0403 07:33:28.487452 24116 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 07:33:28.487469 24116 net.cpp:156] Memory required for data: 662258400
I0403 07:33:28.487493 24116 layer_factory.hpp:77] Creating layer pool2
I0403 07:33:28.487519 24116 net.cpp:91] Creating Layer pool2
I0403 07:33:28.487537 24116 net.cpp:425] pool2 <- norm2
I0403 07:33:28.487563 24116 net.cpp:399] pool2 -> pool2
I0403 07:33:28.487623 24116 net.cpp:141] Setting up pool2
I0403 07:33:28.487653 24116 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:33:28.487674 24116 net.cpp:156] Memory required for data: 679564000
I0403 07:33:28.487695 24116 layer_factory.hpp:77] Creating layer conv3
I0403 07:33:28.487726 24116 net.cpp:91] Creating Layer conv3
I0403 07:33:28.487753 24116 net.cpp:425] conv3 <- pool2
I0403 07:33:28.487797 24116 net.cpp:399] conv3 -> conv3
I0403 07:33:28.524296 24116 net.cpp:141] Setting up conv3
I0403 07:33:28.524349 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:28.524368 24116 net.cpp:156] Memory required for data: 705522400
I0403 07:33:28.524394 24116 layer_factory.hpp:77] Creating layer relu3
I0403 07:33:28.524418 24116 net.cpp:91] Creating Layer relu3
I0403 07:33:28.524438 24116 net.cpp:425] relu3 <- conv3
I0403 07:33:28.524461 24116 net.cpp:386] relu3 -> conv3 (in-place)
I0403 07:33:28.524483 24116 net.cpp:141] Setting up relu3
I0403 07:33:28.524502 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:28.524518 24116 net.cpp:156] Memory required for data: 731480800
I0403 07:33:28.524533 24116 layer_factory.hpp:77] Creating layer conv4
I0403 07:33:28.524559 24116 net.cpp:91] Creating Layer conv4
I0403 07:33:28.524579 24116 net.cpp:425] conv4 <- conv3
I0403 07:33:28.524600 24116 net.cpp:399] conv4 -> conv4
I0403 07:33:28.552258 24116 net.cpp:141] Setting up conv4
I0403 07:33:28.552315 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:28.552335 24116 net.cpp:156] Memory required for data: 757439200
I0403 07:33:28.552356 24116 layer_factory.hpp:77] Creating layer relu4
I0403 07:33:28.552381 24116 net.cpp:91] Creating Layer relu4
I0403 07:33:28.552402 24116 net.cpp:425] relu4 <- conv4
I0403 07:33:28.552423 24116 net.cpp:386] relu4 -> conv4 (in-place)
I0403 07:33:28.552445 24116 net.cpp:141] Setting up relu4
I0403 07:33:28.552464 24116 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 07:33:28.552480 24116 net.cpp:156] Memory required for data: 783397600
I0403 07:33:28.552496 24116 layer_factory.hpp:77] Creating layer conv5
I0403 07:33:28.552521 24116 net.cpp:91] Creating Layer conv5
I0403 07:33:28.552539 24116 net.cpp:425] conv5 <- conv4
I0403 07:33:28.552561 24116 net.cpp:399] conv5 -> conv5
I0403 07:33:28.570895 24116 net.cpp:141] Setting up conv5
I0403 07:33:28.570930 24116 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:33:28.570969 24116 net.cpp:156] Memory required for data: 800703200
I0403 07:33:28.570996 24116 layer_factory.hpp:77] Creating layer relu5
I0403 07:33:28.571020 24116 net.cpp:91] Creating Layer relu5
I0403 07:33:28.571039 24116 net.cpp:425] relu5 <- conv5
I0403 07:33:28.571059 24116 net.cpp:386] relu5 -> conv5 (in-place)
I0403 07:33:28.571080 24116 net.cpp:141] Setting up relu5
I0403 07:33:28.571100 24116 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 07:33:28.571118 24116 net.cpp:156] Memory required for data: 818008800
I0403 07:33:28.571144 24116 layer_factory.hpp:77] Creating layer pool5
I0403 07:33:28.571177 24116 net.cpp:91] Creating Layer pool5
I0403 07:33:28.571197 24116 net.cpp:425] pool5 <- conv5
I0403 07:33:28.571224 24116 net.cpp:399] pool5 -> pool5
I0403 07:33:28.571283 24116 net.cpp:141] Setting up pool5
I0403 07:33:28.571308 24116 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 07:33:28.571324 24116 net.cpp:156] Memory required for data: 821695200
I0403 07:33:28.571341 24116 layer_factory.hpp:77] Creating layer fc6
I0403 07:33:28.571367 24116 net.cpp:91] Creating Layer fc6
I0403 07:33:28.571388 24116 net.cpp:425] fc6 <- pool5
I0403 07:33:28.571409 24116 net.cpp:399] fc6 -> fc6
I0403 07:33:29.965759 24116 net.cpp:141] Setting up fc6
I0403 07:33:29.965845 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:29.965863 24116 net.cpp:156] Memory required for data: 823333600
I0403 07:33:29.965885 24116 layer_factory.hpp:77] Creating layer relu6
I0403 07:33:29.965909 24116 net.cpp:91] Creating Layer relu6
I0403 07:33:29.965926 24116 net.cpp:425] relu6 <- fc6
I0403 07:33:29.965947 24116 net.cpp:386] relu6 -> fc6 (in-place)
I0403 07:33:29.965970 24116 net.cpp:141] Setting up relu6
I0403 07:33:29.965988 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:29.966002 24116 net.cpp:156] Memory required for data: 824972000
I0403 07:33:29.966017 24116 layer_factory.hpp:77] Creating layer drop6
I0403 07:33:29.966048 24116 net.cpp:91] Creating Layer drop6
I0403 07:33:29.966065 24116 net.cpp:425] drop6 <- fc6
I0403 07:33:29.966084 24116 net.cpp:386] drop6 -> fc6 (in-place)
I0403 07:33:29.966125 24116 net.cpp:141] Setting up drop6
I0403 07:33:29.966145 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:29.966161 24116 net.cpp:156] Memory required for data: 826610400
I0403 07:33:29.966176 24116 layer_factory.hpp:77] Creating layer fc7
I0403 07:33:29.966195 24116 net.cpp:91] Creating Layer fc7
I0403 07:33:29.966212 24116 net.cpp:425] fc7 <- fc6
I0403 07:33:29.966233 24116 net.cpp:399] fc7 -> fc7
I0403 07:33:30.572159 24116 net.cpp:141] Setting up fc7
I0403 07:33:30.572242 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:30.572260 24116 net.cpp:156] Memory required for data: 828248800
I0403 07:33:30.572283 24116 layer_factory.hpp:77] Creating layer relu7
I0403 07:33:30.572309 24116 net.cpp:91] Creating Layer relu7
I0403 07:33:30.572336 24116 net.cpp:425] relu7 <- fc7
I0403 07:33:30.572360 24116 net.cpp:386] relu7 -> fc7 (in-place)
I0403 07:33:30.572382 24116 net.cpp:141] Setting up relu7
I0403 07:33:30.572401 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:30.572415 24116 net.cpp:156] Memory required for data: 829887200
I0403 07:33:30.572429 24116 layer_factory.hpp:77] Creating layer drop7
I0403 07:33:30.572448 24116 net.cpp:91] Creating Layer drop7
I0403 07:33:30.572463 24116 net.cpp:425] drop7 <- fc7
I0403 07:33:30.572480 24116 net.cpp:386] drop7 -> fc7 (in-place)
I0403 07:33:30.572521 24116 net.cpp:141] Setting up drop7
I0403 07:33:30.572543 24116 net.cpp:148] Top shape: 100 4096 (409600)
I0403 07:33:30.572558 24116 net.cpp:156] Memory required for data: 831525600
I0403 07:33:30.572573 24116 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 07:33:30.572598 24116 net.cpp:91] Creating Layer fc8_plantvillage
I0403 07:33:30.572615 24116 net.cpp:425] fc8_plantvillage <- fc7
I0403 07:33:30.572633 24116 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 07:33:30.578615 24116 net.cpp:141] Setting up fc8_plantvillage
I0403 07:33:30.578644 24116 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:33:30.578706 24116 net.cpp:156] Memory required for data: 831540800
I0403 07:33:30.578727 24116 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 07:33:30.578758 24116 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 07:33:30.578779 24116 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 07:33:30.578800 24116 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 07:33:30.578824 24116 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 07:33:30.578874 24116 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 07:33:30.578901 24116 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:33:30.578917 24116 net.cpp:148] Top shape: 100 38 (3800)
I0403 07:33:30.578932 24116 net.cpp:156] Memory required for data: 831571200
I0403 07:33:30.578948 24116 layer_factory.hpp:77] Creating layer loss
I0403 07:33:30.578964 24116 net.cpp:91] Creating Layer loss
I0403 07:33:30.578981 24116 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 07:33:30.579000 24116 net.cpp:425] loss <- label_data_1_split_0
I0403 07:33:30.579018 24116 net.cpp:399] loss -> loss
I0403 07:33:30.579041 24116 layer_factory.hpp:77] Creating layer loss
I0403 07:33:30.579146 24116 net.cpp:141] Setting up loss
I0403 07:33:30.579170 24116 net.cpp:148] Top shape: (1)
I0403 07:33:30.579185 24116 net.cpp:151]     with loss weight 1
I0403 07:33:30.579211 24116 net.cpp:156] Memory required for data: 831571204
I0403 07:33:30.579226 24116 layer_factory.hpp:77] Creating layer accuracy
I0403 07:33:30.579244 24116 net.cpp:91] Creating Layer accuracy
I0403 07:33:30.579260 24116 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 07:33:30.579277 24116 net.cpp:425] accuracy <- label_data_1_split_1
I0403 07:33:30.579298 24116 net.cpp:399] accuracy -> accuracy
I0403 07:33:30.579327 24116 net.cpp:141] Setting up accuracy
I0403 07:33:30.579346 24116 net.cpp:148] Top shape: (1)
I0403 07:33:30.579360 24116 net.cpp:156] Memory required for data: 831571208
I0403 07:33:30.579375 24116 net.cpp:219] accuracy does not need backward computation.
I0403 07:33:30.579391 24116 net.cpp:217] loss needs backward computation.
I0403 07:33:30.579406 24116 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 07:33:30.579421 24116 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 07:33:30.579437 24116 net.cpp:217] drop7 needs backward computation.
I0403 07:33:30.579450 24116 net.cpp:217] relu7 needs backward computation.
I0403 07:33:30.579464 24116 net.cpp:217] fc7 needs backward computation.
I0403 07:33:30.579478 24116 net.cpp:217] drop6 needs backward computation.
I0403 07:33:30.579493 24116 net.cpp:217] relu6 needs backward computation.
I0403 07:33:30.579506 24116 net.cpp:217] fc6 needs backward computation.
I0403 07:33:30.579521 24116 net.cpp:217] pool5 needs backward computation.
I0403 07:33:30.579536 24116 net.cpp:217] relu5 needs backward computation.
I0403 07:33:30.579550 24116 net.cpp:217] conv5 needs backward computation.
I0403 07:33:30.579565 24116 net.cpp:217] relu4 needs backward computation.
I0403 07:33:30.579579 24116 net.cpp:217] conv4 needs backward computation.
I0403 07:33:30.579594 24116 net.cpp:217] relu3 needs backward computation.
I0403 07:33:30.579609 24116 net.cpp:217] conv3 needs backward computation.
I0403 07:33:30.579623 24116 net.cpp:217] pool2 needs backward computation.
I0403 07:33:30.579638 24116 net.cpp:217] norm2 needs backward computation.
I0403 07:33:30.579653 24116 net.cpp:217] relu2 needs backward computation.
I0403 07:33:30.579666 24116 net.cpp:217] conv2 needs backward computation.
I0403 07:33:30.579680 24116 net.cpp:217] pool1 needs backward computation.
I0403 07:33:30.579696 24116 net.cpp:217] norm1 needs backward computation.
I0403 07:33:30.579711 24116 net.cpp:217] relu1 needs backward computation.
I0403 07:33:30.579726 24116 net.cpp:217] conv1 needs backward computation.
I0403 07:33:30.582756 24116 net.cpp:219] label_data_1_split does not need backward computation.
I0403 07:33:30.582798 24116 net.cpp:219] data does not need backward computation.
I0403 07:33:30.582847 24116 net.cpp:261] This network produces output accuracy
I0403 07:33:30.582890 24116 net.cpp:261] This network produces output loss
I0403 07:33:30.582973 24116 net.cpp:274] Network initialization done.
I0403 07:33:30.583230 24116 solver.cpp:60] Solver scaffolding done.
I0403 07:33:30.607831 24116 parallel.cpp:392] GPUs pairs 0:1
I0403 07:33:30.855581 24116 data_layer.cpp:41] output data size: 100,3,227,227
I0403 07:33:33.325741 24116 parallel.cpp:425] Starting Optimization
I0403 07:33:33.325901 24116 solver.cpp:279] Solving 
I0403 07:33:33.325925 24116 solver.cpp:280] Learning Rate Policy: step
I0403 07:33:33.326118 24116 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 07:34:46.263998 24116 solver.cpp:404]     Test net output #0: accuracy = 0.0262849
I0403 07:34:46.264194 24116 solver.cpp:404]     Test net output #1: loss = 3.62466 (* 1 = 3.62466 loss)
I0403 07:34:46.841615 24116 solver.cpp:228] Iteration 0, loss = 3.59661
I0403 07:34:46.841686 24116 solver.cpp:244]     Train net output #0: loss = 3.59661 (* 1 = 3.59661 loss)
I0403 07:34:47.036494 24116 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 07:34:54.123976 24116 solver.cpp:228] Iteration 10, loss = 3.30047
I0403 07:34:54.124044 24116 solver.cpp:244]     Train net output #0: loss = 3.30047 (* 1 = 3.30047 loss)
I0403 07:34:54.303292 24116 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 07:35:01.449275 24116 solver.cpp:228] Iteration 20, loss = 3.25003
I0403 07:35:01.449344 24116 solver.cpp:244]     Train net output #0: loss = 3.25003 (* 1 = 3.25003 loss)
I0403 07:35:01.626538 24116 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 07:35:08.688376 24116 solver.cpp:228] Iteration 30, loss = 3.33931
I0403 07:35:08.688453 24116 solver.cpp:244]     Train net output #0: loss = 3.33931 (* 1 = 3.33931 loss)
I0403 07:35:08.871989 24116 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 07:35:15.873401 24116 solver.cpp:228] Iteration 40, loss = 3.28134
I0403 07:35:15.873482 24116 solver.cpp:244]     Train net output #0: loss = 3.28134 (* 1 = 3.28134 loss)
I0403 07:35:16.081815 24116 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 07:35:23.172544 24116 solver.cpp:228] Iteration 50, loss = 3.34083
I0403 07:35:23.172813 24116 solver.cpp:244]     Train net output #0: loss = 3.34083 (* 1 = 3.34083 loss)
I0403 07:35:23.354794 24116 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 07:35:30.377444 24116 solver.cpp:228] Iteration 60, loss = 3.04038
I0403 07:35:30.377512 24116 solver.cpp:244]     Train net output #0: loss = 3.04038 (* 1 = 3.04038 loss)
I0403 07:35:30.554455 24116 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 07:35:37.584144 24116 solver.cpp:228] Iteration 70, loss = 3.02473
I0403 07:35:37.584215 24116 solver.cpp:244]     Train net output #0: loss = 3.02473 (* 1 = 3.02473 loss)
I0403 07:35:37.756922 24116 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 07:35:44.792054 24116 solver.cpp:228] Iteration 80, loss = 3.16381
I0403 07:35:44.792132 24116 solver.cpp:244]     Train net output #0: loss = 3.16381 (* 1 = 3.16381 loss)
I0403 07:35:44.986238 24116 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 07:35:52.005070 24116 solver.cpp:228] Iteration 90, loss = 2.79667
I0403 07:35:52.005147 24116 solver.cpp:244]     Train net output #0: loss = 2.79667 (* 1 = 2.79667 loss)
I0403 07:35:52.188232 24116 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 07:35:59.198990 24116 solver.cpp:228] Iteration 100, loss = 2.78335
I0403 07:35:59.199259 24116 solver.cpp:244]     Train net output #0: loss = 2.78335 (* 1 = 2.78335 loss)
I0403 07:35:59.366812 24116 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 07:36:06.470218 24116 solver.cpp:228] Iteration 110, loss = 2.71792
I0403 07:36:06.470307 24116 solver.cpp:244]     Train net output #0: loss = 2.71792 (* 1 = 2.71792 loss)
I0403 07:36:06.647852 24116 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 07:36:13.783331 24116 solver.cpp:228] Iteration 120, loss = 3.47463
I0403 07:36:13.783416 24116 solver.cpp:244]     Train net output #0: loss = 3.47463 (* 1 = 3.47463 loss)
I0403 07:36:13.962251 24116 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 07:36:21.045827 24116 solver.cpp:228] Iteration 130, loss = 3.17341
I0403 07:36:21.045924 24116 solver.cpp:244]     Train net output #0: loss = 3.17341 (* 1 = 3.17341 loss)
I0403 07:36:21.238824 24116 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 07:36:28.373507 24116 solver.cpp:228] Iteration 140, loss = 3.08031
I0403 07:36:28.373600 24116 solver.cpp:244]     Train net output #0: loss = 3.08031 (* 1 = 3.08031 loss)
I0403 07:36:28.557126 24116 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 07:36:35.723529 24116 solver.cpp:228] Iteration 150, loss = 2.74894
I0403 07:36:35.723860 24116 solver.cpp:244]     Train net output #0: loss = 2.74894 (* 1 = 2.74894 loss)
I0403 07:36:35.905972 24116 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 07:36:43.010028 24116 solver.cpp:228] Iteration 160, loss = 3.07865
I0403 07:36:43.010126 24116 solver.cpp:244]     Train net output #0: loss = 3.07865 (* 1 = 3.07865 loss)
I0403 07:36:43.196512 24116 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 07:36:50.175642 24116 solver.cpp:228] Iteration 170, loss = 2.68266
I0403 07:36:50.175740 24116 solver.cpp:244]     Train net output #0: loss = 2.68266 (* 1 = 2.68266 loss)
I0403 07:36:50.392523 24116 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 07:36:57.405478 24116 solver.cpp:228] Iteration 180, loss = 2.72298
I0403 07:36:57.405572 24116 solver.cpp:244]     Train net output #0: loss = 2.72298 (* 1 = 2.72298 loss)
I0403 07:36:57.601517 24116 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 07:37:04.747617 24116 solver.cpp:228] Iteration 190, loss = 2.67577
I0403 07:37:04.747702 24116 solver.cpp:244]     Train net output #0: loss = 2.67577 (* 1 = 2.67577 loss)
I0403 07:37:04.918509 24116 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 07:37:12.091564 24116 solver.cpp:228] Iteration 200, loss = 2.50477
I0403 07:37:12.091871 24116 solver.cpp:244]     Train net output #0: loss = 2.50477 (* 1 = 2.50477 loss)
I0403 07:37:12.329979 24116 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 07:37:19.325049 24116 solver.cpp:228] Iteration 210, loss = 2.41753
I0403 07:37:19.325147 24116 solver.cpp:244]     Train net output #0: loss = 2.41753 (* 1 = 2.41753 loss)
I0403 07:37:19.531945 24116 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 07:37:25.310714 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_219.caffemodel
I0403 07:37:28.200040 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_219.solverstate
I0403 07:37:30.119201 24116 solver.cpp:337] Iteration 219, Testing net (#0)
I0403 07:38:42.620487 24116 solver.cpp:404]     Test net output #0: accuracy = 0.323127
I0403 07:38:42.620792 24116 solver.cpp:404]     Test net output #1: loss = 2.50212 (* 1 = 2.50212 loss)
I0403 07:38:43.845752 24116 solver.cpp:228] Iteration 220, loss = 2.67703
I0403 07:38:43.845855 24116 solver.cpp:244]     Train net output #0: loss = 2.67703 (* 1 = 2.67703 loss)
I0403 07:38:44.073118 24116 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 07:38:51.283139 24116 solver.cpp:228] Iteration 230, loss = 2.34284
I0403 07:38:51.283236 24116 solver.cpp:244]     Train net output #0: loss = 2.34284 (* 1 = 2.34284 loss)
I0403 07:38:51.466609 24116 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 07:38:58.469763 24116 solver.cpp:228] Iteration 240, loss = 2.29122
I0403 07:38:58.469859 24116 solver.cpp:244]     Train net output #0: loss = 2.29122 (* 1 = 2.29122 loss)
I0403 07:38:58.684145 24116 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 07:39:05.787178 24116 solver.cpp:228] Iteration 250, loss = 2.31938
I0403 07:39:05.787281 24116 solver.cpp:244]     Train net output #0: loss = 2.31938 (* 1 = 2.31938 loss)
I0403 07:39:06.016788 24116 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 07:39:13.144840 24116 solver.cpp:228] Iteration 260, loss = 2.06331
I0403 07:39:13.145155 24116 solver.cpp:244]     Train net output #0: loss = 2.06331 (* 1 = 2.06331 loss)
I0403 07:39:13.323659 24116 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 07:39:20.545320 24116 solver.cpp:228] Iteration 270, loss = 2.56055
I0403 07:39:20.545404 24116 solver.cpp:244]     Train net output #0: loss = 2.56055 (* 1 = 2.56055 loss)
I0403 07:39:20.721407 24116 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 07:39:27.921766 24116 solver.cpp:228] Iteration 280, loss = 2.01367
I0403 07:39:27.921866 24116 solver.cpp:244]     Train net output #0: loss = 2.01367 (* 1 = 2.01367 loss)
I0403 07:39:28.109027 24116 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 07:39:35.157237 24116 solver.cpp:228] Iteration 290, loss = 1.99751
I0403 07:39:35.157336 24116 solver.cpp:244]     Train net output #0: loss = 1.99751 (* 1 = 1.99751 loss)
I0403 07:39:35.341653 24116 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 07:39:42.349333 24116 solver.cpp:228] Iteration 300, loss = 2.26195
I0403 07:39:42.349426 24116 solver.cpp:244]     Train net output #0: loss = 2.26195 (* 1 = 2.26195 loss)
I0403 07:39:42.547129 24116 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 07:39:49.635529 24116 solver.cpp:228] Iteration 310, loss = 2.1604
I0403 07:39:49.635818 24116 solver.cpp:244]     Train net output #0: loss = 2.1604 (* 1 = 2.1604 loss)
I0403 07:39:49.817709 24116 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 07:39:56.917888 24116 solver.cpp:228] Iteration 320, loss = 1.87345
I0403 07:39:56.917996 24116 solver.cpp:244]     Train net output #0: loss = 1.87345 (* 1 = 1.87345 loss)
I0403 07:39:57.111400 24116 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 07:40:04.243968 24116 solver.cpp:228] Iteration 330, loss = 1.80746
I0403 07:40:04.244068 24116 solver.cpp:244]     Train net output #0: loss = 1.80746 (* 1 = 1.80746 loss)
I0403 07:40:04.482565 24116 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 07:40:11.760045 24116 solver.cpp:228] Iteration 340, loss = 2.24122
I0403 07:40:11.760130 24116 solver.cpp:244]     Train net output #0: loss = 2.24122 (* 1 = 2.24122 loss)
I0403 07:40:11.917492 24116 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 07:40:19.111771 24116 solver.cpp:228] Iteration 350, loss = 1.47811
I0403 07:40:19.111871 24116 solver.cpp:244]     Train net output #0: loss = 1.47811 (* 1 = 1.47811 loss)
I0403 07:40:19.307739 24116 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 07:40:26.292019 24116 solver.cpp:228] Iteration 360, loss = 1.5896
I0403 07:40:26.292299 24116 solver.cpp:244]     Train net output #0: loss = 1.5896 (* 1 = 1.5896 loss)
I0403 07:40:26.489228 24116 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 07:40:33.524273 24116 solver.cpp:228] Iteration 370, loss = 1.75909
I0403 07:40:33.524361 24116 solver.cpp:244]     Train net output #0: loss = 1.75909 (* 1 = 1.75909 loss)
I0403 07:40:33.682184 24116 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 07:40:40.867630 24116 solver.cpp:228] Iteration 380, loss = 1.89347
I0403 07:40:40.867727 24116 solver.cpp:244]     Train net output #0: loss = 1.89347 (* 1 = 1.89347 loss)
I0403 07:40:41.065675 24116 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 07:40:48.110519 24116 solver.cpp:228] Iteration 390, loss = 1.40792
I0403 07:40:48.110615 24116 solver.cpp:244]     Train net output #0: loss = 1.40792 (* 1 = 1.40792 loss)
I0403 07:40:48.316762 24116 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 07:40:55.479742 24116 solver.cpp:228] Iteration 400, loss = 1.31742
I0403 07:40:55.479835 24116 solver.cpp:244]     Train net output #0: loss = 1.31742 (* 1 = 1.31742 loss)
I0403 07:40:55.643409 24116 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 07:41:02.753937 24116 solver.cpp:228] Iteration 410, loss = 1.8308
I0403 07:41:02.754266 24116 solver.cpp:244]     Train net output #0: loss = 1.8308 (* 1 = 1.8308 loss)
I0403 07:41:02.963866 24116 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 07:41:10.051199 24116 solver.cpp:228] Iteration 420, loss = 1.35624
I0403 07:41:10.051285 24116 solver.cpp:244]     Train net output #0: loss = 1.35624 (* 1 = 1.35624 loss)
I0403 07:41:10.196797 24116 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 07:41:17.308042 24116 solver.cpp:228] Iteration 430, loss = 1.53674
I0403 07:41:17.308140 24116 solver.cpp:244]     Train net output #0: loss = 1.53674 (* 1 = 1.53674 loss)
I0403 07:41:17.552489 24116 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 07:41:22.669183 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_438.caffemodel
I0403 07:41:25.378813 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_438.solverstate
I0403 07:41:27.285711 24116 solver.cpp:337] Iteration 438, Testing net (#0)
I0403 07:42:39.785528 24116 solver.cpp:404]     Test net output #0: accuracy = 0.540558
I0403 07:42:39.785871 24116 solver.cpp:404]     Test net output #1: loss = 1.5507 (* 1 = 1.5507 loss)
I0403 07:42:41.736753 24116 solver.cpp:228] Iteration 440, loss = 1.47978
I0403 07:42:41.736848 24116 solver.cpp:244]     Train net output #0: loss = 1.47978 (* 1 = 1.47978 loss)
I0403 07:42:41.918845 24116 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 07:42:49.078249 24116 solver.cpp:228] Iteration 450, loss = 1.58631
I0403 07:42:49.078348 24116 solver.cpp:244]     Train net output #0: loss = 1.58631 (* 1 = 1.58631 loss)
I0403 07:42:49.260551 24116 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 07:42:56.394800 24116 solver.cpp:228] Iteration 460, loss = 1.20253
I0403 07:42:56.394887 24116 solver.cpp:244]     Train net output #0: loss = 1.20253 (* 1 = 1.20253 loss)
I0403 07:42:56.570937 24116 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 07:43:03.640879 24116 solver.cpp:228] Iteration 470, loss = 1.33539
I0403 07:43:03.640979 24116 solver.cpp:244]     Train net output #0: loss = 1.33539 (* 1 = 1.33539 loss)
I0403 07:43:03.826406 24116 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 07:43:10.878010 24116 solver.cpp:228] Iteration 480, loss = 1.32804
I0403 07:43:10.878294 24116 solver.cpp:244]     Train net output #0: loss = 1.32804 (* 1 = 1.32804 loss)
I0403 07:43:11.059422 24116 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 07:43:18.170760 24116 solver.cpp:228] Iteration 490, loss = 1.55336
I0403 07:43:18.170862 24116 solver.cpp:244]     Train net output #0: loss = 1.55336 (* 1 = 1.55336 loss)
I0403 07:43:18.366874 24116 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 07:43:25.620332 24116 solver.cpp:228] Iteration 500, loss = 1.13408
I0403 07:43:25.620416 24116 solver.cpp:244]     Train net output #0: loss = 1.13408 (* 1 = 1.13408 loss)
I0403 07:43:25.761844 24116 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 07:43:32.930634 24116 solver.cpp:228] Iteration 510, loss = 1.14376
I0403 07:43:32.930733 24116 solver.cpp:244]     Train net output #0: loss = 1.14376 (* 1 = 1.14376 loss)
I0403 07:43:33.133544 24116 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 07:43:40.219573 24116 solver.cpp:228] Iteration 520, loss = 1.33505
I0403 07:43:40.219671 24116 solver.cpp:244]     Train net output #0: loss = 1.33505 (* 1 = 1.33505 loss)
I0403 07:43:40.418977 24116 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 07:43:47.578034 24116 solver.cpp:228] Iteration 530, loss = 1.048
I0403 07:43:47.582108 24116 solver.cpp:244]     Train net output #0: loss = 1.048 (* 1 = 1.048 loss)
I0403 07:43:47.715068 24116 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 07:43:54.905923 24116 solver.cpp:228] Iteration 540, loss = 1.29189
I0403 07:43:54.906020 24116 solver.cpp:244]     Train net output #0: loss = 1.29189 (* 1 = 1.29189 loss)
I0403 07:43:55.139365 24116 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 07:44:02.278825 24116 solver.cpp:228] Iteration 550, loss = 1.14568
I0403 07:44:02.278910 24116 solver.cpp:244]     Train net output #0: loss = 1.14568 (* 1 = 1.14568 loss)
I0403 07:44:02.448215 24116 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 07:44:09.593816 24116 solver.cpp:228] Iteration 560, loss = 1.20277
I0403 07:44:09.593901 24116 solver.cpp:244]     Train net output #0: loss = 1.20277 (* 1 = 1.20277 loss)
I0403 07:44:09.775331 24116 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 07:44:16.893929 24116 solver.cpp:228] Iteration 570, loss = 1.04145
I0403 07:44:16.894026 24116 solver.cpp:244]     Train net output #0: loss = 1.04145 (* 1 = 1.04145 loss)
I0403 07:44:17.076458 24116 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 07:44:24.164405 24116 solver.cpp:228] Iteration 580, loss = 1.16188
I0403 07:44:24.164726 24116 solver.cpp:244]     Train net output #0: loss = 1.16188 (* 1 = 1.16188 loss)
I0403 07:44:24.366026 24116 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 07:44:31.444216 24116 solver.cpp:228] Iteration 590, loss = 1.17294
I0403 07:44:31.444314 24116 solver.cpp:244]     Train net output #0: loss = 1.17294 (* 1 = 1.17294 loss)
I0403 07:44:31.638969 24116 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 07:44:38.724192 24116 solver.cpp:228] Iteration 600, loss = 1.10912
I0403 07:44:38.724274 24116 solver.cpp:244]     Train net output #0: loss = 1.10912 (* 1 = 1.10912 loss)
I0403 07:44:38.853801 24116 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 07:44:46.037624 24116 solver.cpp:228] Iteration 610, loss = 0.954323
I0403 07:44:46.037721 24116 solver.cpp:244]     Train net output #0: loss = 0.954323 (* 1 = 0.954323 loss)
I0403 07:44:46.259429 24116 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 07:44:53.395741 24116 solver.cpp:228] Iteration 620, loss = 1.13082
I0403 07:44:53.395841 24116 solver.cpp:244]     Train net output #0: loss = 1.13082 (* 1 = 1.13082 loss)
I0403 07:44:53.587481 24116 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 07:45:00.681146 24116 solver.cpp:228] Iteration 630, loss = 1.12467
I0403 07:45:00.681445 24116 solver.cpp:244]     Train net output #0: loss = 1.12467 (* 1 = 1.12467 loss)
I0403 07:45:00.885943 24116 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 07:45:07.964103 24116 solver.cpp:228] Iteration 640, loss = 1.03838
I0403 07:45:07.964198 24116 solver.cpp:244]     Train net output #0: loss = 1.03838 (* 1 = 1.03838 loss)
I0403 07:45:08.159696 24116 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 07:45:15.303355 24116 solver.cpp:228] Iteration 650, loss = 0.97109
I0403 07:45:15.303452 24116 solver.cpp:244]     Train net output #0: loss = 0.97109 (* 1 = 0.97109 loss)
I0403 07:45:15.530513 24116 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 07:45:19.932950 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_657.caffemodel
I0403 07:45:22.684547 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_657.solverstate
I0403 07:45:24.531960 24116 solver.cpp:337] Iteration 657, Testing net (#0)
I0403 07:46:37.046535 24116 solver.cpp:404]     Test net output #0: accuracy = 0.688761
I0403 07:46:37.046860 24116 solver.cpp:404]     Test net output #1: loss = 1.01887 (* 1 = 1.01887 loss)
I0403 07:46:39.724828 24116 solver.cpp:228] Iteration 660, loss = 0.881859
I0403 07:46:39.724913 24116 solver.cpp:244]     Train net output #0: loss = 0.881859 (* 1 = 0.881859 loss)
I0403 07:46:39.891861 24116 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 07:46:46.934953 24116 solver.cpp:228] Iteration 670, loss = 1.11434
I0403 07:46:46.935040 24116 solver.cpp:244]     Train net output #0: loss = 1.11434 (* 1 = 1.11434 loss)
I0403 07:46:47.108090 24116 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 07:46:54.243197 24116 solver.cpp:228] Iteration 680, loss = 0.860779
I0403 07:46:54.243281 24116 solver.cpp:244]     Train net output #0: loss = 0.860779 (* 1 = 0.860779 loss)
I0403 07:46:54.393573 24116 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 07:47:01.544092 24116 solver.cpp:228] Iteration 690, loss = 1.09224
I0403 07:47:01.544186 24116 solver.cpp:244]     Train net output #0: loss = 1.09224 (* 1 = 1.09224 loss)
I0403 07:47:01.739588 24116 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 07:47:08.831827 24116 solver.cpp:228] Iteration 700, loss = 1.04033
I0403 07:47:08.832145 24116 solver.cpp:244]     Train net output #0: loss = 1.04033 (* 1 = 1.04033 loss)
I0403 07:47:09.031877 24116 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 07:47:16.290040 24116 solver.cpp:228] Iteration 710, loss = 0.800912
I0403 07:47:16.290138 24116 solver.cpp:244]     Train net output #0: loss = 0.800912 (* 1 = 0.800912 loss)
I0403 07:47:16.477291 24116 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 07:47:23.517349 24116 solver.cpp:228] Iteration 720, loss = 0.750789
I0403 07:47:23.517444 24116 solver.cpp:244]     Train net output #0: loss = 0.750789 (* 1 = 0.750789 loss)
I0403 07:47:23.699638 24116 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 07:47:30.889122 24116 solver.cpp:228] Iteration 730, loss = 0.881086
I0403 07:47:30.889219 24116 solver.cpp:244]     Train net output #0: loss = 0.881086 (* 1 = 0.881086 loss)
I0403 07:47:31.086398 24116 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 07:47:38.417882 24116 solver.cpp:228] Iteration 740, loss = 1.28129
I0403 07:47:38.417966 24116 solver.cpp:244]     Train net output #0: loss = 1.28129 (* 1 = 1.28129 loss)
I0403 07:47:38.587890 24116 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 07:47:45.613741 24116 solver.cpp:228] Iteration 750, loss = 0.991546
I0403 07:47:45.614048 24116 solver.cpp:244]     Train net output #0: loss = 0.991546 (* 1 = 0.991546 loss)
I0403 07:47:45.799075 24116 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 07:47:52.842844 24116 solver.cpp:228] Iteration 760, loss = 1.00933
I0403 07:47:52.842941 24116 solver.cpp:244]     Train net output #0: loss = 1.00933 (* 1 = 1.00933 loss)
I0403 07:47:53.027390 24116 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 07:48:00.014116 24116 solver.cpp:228] Iteration 770, loss = 0.906256
I0403 07:48:00.014215 24116 solver.cpp:244]     Train net output #0: loss = 0.906256 (* 1 = 0.906256 loss)
I0403 07:48:00.211652 24116 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 07:48:07.348163 24116 solver.cpp:228] Iteration 780, loss = 0.926446
I0403 07:48:07.348258 24116 solver.cpp:244]     Train net output #0: loss = 0.926446 (* 1 = 0.926446 loss)
I0403 07:48:07.538620 24116 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 07:48:14.598561 24116 solver.cpp:228] Iteration 790, loss = 0.896982
I0403 07:48:14.598660 24116 solver.cpp:244]     Train net output #0: loss = 0.896982 (* 1 = 0.896982 loss)
I0403 07:48:14.827627 24116 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 07:48:21.909368 24116 solver.cpp:228] Iteration 800, loss = 0.830242
I0403 07:48:21.909667 24116 solver.cpp:244]     Train net output #0: loss = 0.830242 (* 1 = 0.830242 loss)
I0403 07:48:22.096942 24116 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 07:48:29.195806 24116 solver.cpp:228] Iteration 810, loss = 0.939517
I0403 07:48:29.195901 24116 solver.cpp:244]     Train net output #0: loss = 0.939517 (* 1 = 0.939517 loss)
I0403 07:48:29.402843 24116 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 07:48:36.417346 24116 solver.cpp:228] Iteration 820, loss = 0.793838
I0403 07:48:36.417439 24116 solver.cpp:244]     Train net output #0: loss = 0.793838 (* 1 = 0.793838 loss)
I0403 07:48:36.600435 24116 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 07:48:43.652787 24116 solver.cpp:228] Iteration 830, loss = 0.646581
I0403 07:48:43.652886 24116 solver.cpp:244]     Train net output #0: loss = 0.646581 (* 1 = 0.646581 loss)
I0403 07:48:43.849934 24116 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 07:48:50.894227 24116 solver.cpp:228] Iteration 840, loss = 0.72941
I0403 07:48:50.894320 24116 solver.cpp:244]     Train net output #0: loss = 0.72941 (* 1 = 0.72941 loss)
I0403 07:48:51.078991 24116 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 07:48:58.068675 24116 solver.cpp:228] Iteration 850, loss = 0.993447
I0403 07:48:58.069015 24116 solver.cpp:244]     Train net output #0: loss = 0.993447 (* 1 = 0.993447 loss)
I0403 07:48:58.249028 24116 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 07:49:05.409713 24116 solver.cpp:228] Iteration 860, loss = 0.838324
I0403 07:49:05.409804 24116 solver.cpp:244]     Train net output #0: loss = 0.838324 (* 1 = 0.838324 loss)
I0403 07:49:05.571311 24116 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 07:49:12.720212 24116 solver.cpp:228] Iteration 870, loss = 0.907203
I0403 07:49:12.720299 24116 solver.cpp:244]     Train net output #0: loss = 0.907203 (* 1 = 0.907203 loss)
I0403 07:49:12.872315 24116 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 07:49:16.686874 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_876.caffemodel
I0403 07:49:19.567699 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_876.solverstate
I0403 07:49:21.467205 24116 solver.cpp:337] Iteration 876, Testing net (#0)
I0403 07:50:33.965811 24116 solver.cpp:404]     Test net output #0: accuracy = 0.762167
I0403 07:50:33.966112 24116 solver.cpp:404]     Test net output #1: loss = 0.768964 (* 1 = 0.768964 loss)
I0403 07:50:37.383081 24116 solver.cpp:228] Iteration 880, loss = 0.84277
I0403 07:50:37.383163 24116 solver.cpp:244]     Train net output #0: loss = 0.84277 (* 1 = 0.84277 loss)
I0403 07:50:37.555848 24116 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 07:50:44.623705 24116 solver.cpp:228] Iteration 890, loss = 0.713511
I0403 07:50:44.623795 24116 solver.cpp:244]     Train net output #0: loss = 0.713511 (* 1 = 0.713511 loss)
I0403 07:50:44.799711 24116 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 07:50:52.310672 24116 solver.cpp:228] Iteration 900, loss = 0.65574
I0403 07:50:52.310761 24116 solver.cpp:244]     Train net output #0: loss = 0.65574 (* 1 = 0.65574 loss)
I0403 07:50:52.490197 24116 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 07:50:59.568100 24116 solver.cpp:228] Iteration 910, loss = 0.579756
I0403 07:50:59.568186 24116 solver.cpp:244]     Train net output #0: loss = 0.579756 (* 1 = 0.579756 loss)
I0403 07:50:59.743144 24116 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 07:51:06.954653 24116 solver.cpp:228] Iteration 920, loss = 0.620403
I0403 07:51:06.954939 24116 solver.cpp:244]     Train net output #0: loss = 0.620403 (* 1 = 0.620403 loss)
I0403 07:51:07.145071 24116 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 07:51:14.199385 24116 solver.cpp:228] Iteration 930, loss = 0.63419
I0403 07:51:14.199482 24116 solver.cpp:244]     Train net output #0: loss = 0.63419 (* 1 = 0.63419 loss)
I0403 07:51:14.386651 24116 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 07:51:21.585790 24116 solver.cpp:228] Iteration 940, loss = 0.675259
I0403 07:51:21.585882 24116 solver.cpp:244]     Train net output #0: loss = 0.675259 (* 1 = 0.675259 loss)
I0403 07:51:21.776301 24116 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 07:51:28.844713 24116 solver.cpp:228] Iteration 950, loss = 0.692933
I0403 07:51:28.859513 24116 solver.cpp:244]     Train net output #0: loss = 0.692933 (* 1 = 0.692933 loss)
I0403 07:51:29.006325 24116 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 07:51:36.213913 24116 solver.cpp:228] Iteration 960, loss = 0.810874
I0403 07:51:36.214007 24116 solver.cpp:244]     Train net output #0: loss = 0.810874 (* 1 = 0.810874 loss)
I0403 07:51:36.417048 24116 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 07:51:43.457681 24116 solver.cpp:228] Iteration 970, loss = 0.627141
I0403 07:51:43.458005 24116 solver.cpp:244]     Train net output #0: loss = 0.627141 (* 1 = 0.627141 loss)
I0403 07:51:43.643478 24116 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 07:51:50.697804 24116 solver.cpp:228] Iteration 980, loss = 0.855293
I0403 07:51:50.697903 24116 solver.cpp:244]     Train net output #0: loss = 0.855293 (* 1 = 0.855293 loss)
I0403 07:51:50.887362 24116 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 07:51:57.953363 24116 solver.cpp:228] Iteration 990, loss = 0.764664
I0403 07:51:57.953451 24116 solver.cpp:244]     Train net output #0: loss = 0.764664 (* 1 = 0.764664 loss)
I0403 07:51:58.131058 24116 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 07:52:05.220158 24116 solver.cpp:228] Iteration 1000, loss = 0.753073
I0403 07:52:05.220254 24116 solver.cpp:244]     Train net output #0: loss = 0.753073 (* 1 = 0.753073 loss)
I0403 07:52:05.402101 24116 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 07:52:12.443372 24116 solver.cpp:228] Iteration 1010, loss = 0.649418
I0403 07:52:12.443470 24116 solver.cpp:244]     Train net output #0: loss = 0.649418 (* 1 = 0.649418 loss)
I0403 07:52:12.628094 24116 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 07:52:19.775909 24116 solver.cpp:228] Iteration 1020, loss = 0.522723
I0403 07:52:19.776211 24116 solver.cpp:244]     Train net output #0: loss = 0.522723 (* 1 = 0.522723 loss)
I0403 07:52:19.968871 24116 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 07:52:27.045711 24116 solver.cpp:228] Iteration 1030, loss = 0.498144
I0403 07:52:27.045816 24116 solver.cpp:244]     Train net output #0: loss = 0.498144 (* 1 = 0.498144 loss)
I0403 07:52:27.259987 24116 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 07:52:34.203578 24116 solver.cpp:228] Iteration 1040, loss = 0.624915
I0403 07:52:34.203677 24116 solver.cpp:244]     Train net output #0: loss = 0.624915 (* 1 = 0.624915 loss)
I0403 07:52:34.424043 24116 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 07:52:41.471282 24116 solver.cpp:228] Iteration 1050, loss = 0.586161
I0403 07:52:41.471379 24116 solver.cpp:244]     Train net output #0: loss = 0.586161 (* 1 = 0.586161 loss)
I0403 07:52:41.657970 24116 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 07:52:48.745959 24116 solver.cpp:228] Iteration 1060, loss = 0.546753
I0403 07:52:48.746055 24116 solver.cpp:244]     Train net output #0: loss = 0.546753 (* 1 = 0.546753 loss)
I0403 07:52:48.931759 24116 sgd_solver.cpp:106] Iteration 1060, lr = 0.005
I0403 07:52:56.174798 24116 solver.cpp:228] Iteration 1070, loss = 0.793598
I0403 07:52:56.175057 24116 solver.cpp:244]     Train net output #0: loss = 0.793598 (* 1 = 0.793598 loss)
I0403 07:52:56.354485 24116 sgd_solver.cpp:106] Iteration 1070, lr = 0.005
I0403 07:53:03.576922 24116 solver.cpp:228] Iteration 1080, loss = 0.648099
I0403 07:53:03.577013 24116 solver.cpp:244]     Train net output #0: loss = 0.648099 (* 1 = 0.648099 loss)
I0403 07:53:03.779767 24116 sgd_solver.cpp:106] Iteration 1080, lr = 0.005
I0403 07:53:10.963892 24116 solver.cpp:228] Iteration 1090, loss = 0.824932
I0403 07:53:10.963992 24116 solver.cpp:244]     Train net output #0: loss = 0.824932 (* 1 = 0.824932 loss)
I0403 07:53:11.149672 24116 sgd_solver.cpp:106] Iteration 1090, lr = 0.005
I0403 07:53:14.155485 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1095.caffemodel
I0403 07:53:16.956529 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1095.solverstate
I0403 07:53:18.817730 24116 solver.cpp:337] Iteration 1095, Testing net (#0)
I0403 07:54:31.340726 24116 solver.cpp:404]     Test net output #0: accuracy = 0.777833
I0403 07:54:31.340987 24116 solver.cpp:404]     Test net output #1: loss = 0.721557 (* 1 = 0.721557 loss)
I0403 07:54:35.435381 24116 solver.cpp:228] Iteration 1100, loss = 0.729582
I0403 07:54:35.435467 24116 solver.cpp:244]     Train net output #0: loss = 0.729582 (* 1 = 0.729582 loss)
I0403 07:54:35.616963 24116 sgd_solver.cpp:106] Iteration 1100, lr = 0.005
I0403 07:54:42.707175 24116 solver.cpp:228] Iteration 1110, loss = 0.612438
I0403 07:54:42.707274 24116 solver.cpp:244]     Train net output #0: loss = 0.612438 (* 1 = 0.612438 loss)
I0403 07:54:42.902933 24116 sgd_solver.cpp:106] Iteration 1110, lr = 0.005
I0403 07:54:50.003633 24116 solver.cpp:228] Iteration 1120, loss = 0.518475
I0403 07:54:50.003731 24116 solver.cpp:244]     Train net output #0: loss = 0.518475 (* 1 = 0.518475 loss)
I0403 07:54:50.197095 24116 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 07:54:57.212009 24116 solver.cpp:228] Iteration 1130, loss = 0.60169
I0403 07:54:57.212110 24116 solver.cpp:244]     Train net output #0: loss = 0.60169 (* 1 = 0.60169 loss)
I0403 07:54:57.400440 24116 sgd_solver.cpp:106] Iteration 1130, lr = 0.005
I0403 07:55:04.527112 24116 solver.cpp:228] Iteration 1140, loss = 0.633678
I0403 07:55:04.527439 24116 solver.cpp:244]     Train net output #0: loss = 0.633678 (* 1 = 0.633678 loss)
I0403 07:55:04.726807 24116 sgd_solver.cpp:106] Iteration 1140, lr = 0.005
I0403 07:55:11.838160 24116 solver.cpp:228] Iteration 1150, loss = 0.386038
I0403 07:55:11.838258 24116 solver.cpp:244]     Train net output #0: loss = 0.386038 (* 1 = 0.386038 loss)
I0403 07:55:12.037773 24116 sgd_solver.cpp:106] Iteration 1150, lr = 0.005
I0403 07:55:19.151700 24116 solver.cpp:228] Iteration 1160, loss = 0.434948
I0403 07:55:19.151804 24116 solver.cpp:244]     Train net output #0: loss = 0.434948 (* 1 = 0.434948 loss)
I0403 07:55:19.336482 24116 sgd_solver.cpp:106] Iteration 1160, lr = 0.005
I0403 07:55:26.403967 24116 solver.cpp:228] Iteration 1170, loss = 0.515218
I0403 07:55:26.404064 24116 solver.cpp:244]     Train net output #0: loss = 0.515218 (* 1 = 0.515218 loss)
I0403 07:55:26.621793 24116 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 07:55:33.628289 24116 solver.cpp:228] Iteration 1180, loss = 0.624397
I0403 07:55:33.628391 24116 solver.cpp:244]     Train net output #0: loss = 0.624397 (* 1 = 0.624397 loss)
I0403 07:55:33.882449 24116 sgd_solver.cpp:106] Iteration 1180, lr = 0.005
I0403 07:55:40.933138 24116 solver.cpp:228] Iteration 1190, loss = 0.40538
I0403 07:55:40.933447 24116 solver.cpp:244]     Train net output #0: loss = 0.40538 (* 1 = 0.40538 loss)
I0403 07:55:41.117398 24116 sgd_solver.cpp:106] Iteration 1190, lr = 0.005
I0403 07:55:48.193315 24116 solver.cpp:228] Iteration 1200, loss = 0.500532
I0403 07:55:48.193413 24116 solver.cpp:244]     Train net output #0: loss = 0.500532 (* 1 = 0.500532 loss)
I0403 07:55:48.379971 24116 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 07:55:55.473781 24116 solver.cpp:228] Iteration 1210, loss = 0.518028
I0403 07:55:55.473878 24116 solver.cpp:244]     Train net output #0: loss = 0.518028 (* 1 = 0.518028 loss)
I0403 07:55:55.657703 24116 sgd_solver.cpp:106] Iteration 1210, lr = 0.005
I0403 07:56:02.835892 24116 solver.cpp:228] Iteration 1220, loss = 0.4763
I0403 07:56:02.835991 24116 solver.cpp:244]     Train net output #0: loss = 0.4763 (* 1 = 0.4763 loss)
I0403 07:56:03.039518 24116 sgd_solver.cpp:106] Iteration 1220, lr = 0.005
I0403 07:56:10.074712 24116 solver.cpp:228] Iteration 1230, loss = 0.506171
I0403 07:56:10.074815 24116 solver.cpp:244]     Train net output #0: loss = 0.506171 (* 1 = 0.506171 loss)
I0403 07:56:10.313292 24116 sgd_solver.cpp:106] Iteration 1230, lr = 0.005
I0403 07:56:17.394058 24116 solver.cpp:228] Iteration 1240, loss = 0.476915
I0403 07:56:17.394366 24116 solver.cpp:244]     Train net output #0: loss = 0.476915 (* 1 = 0.476915 loss)
I0403 07:56:17.615972 24116 sgd_solver.cpp:106] Iteration 1240, lr = 0.005
I0403 07:56:24.652942 24116 solver.cpp:228] Iteration 1250, loss = 0.429744
I0403 07:56:24.653040 24116 solver.cpp:244]     Train net output #0: loss = 0.429744 (* 1 = 0.429744 loss)
I0403 07:56:24.886162 24116 sgd_solver.cpp:106] Iteration 1250, lr = 0.005
I0403 07:56:31.978938 24116 solver.cpp:228] Iteration 1260, loss = 0.333558
I0403 07:56:31.979037 24116 solver.cpp:244]     Train net output #0: loss = 0.333558 (* 1 = 0.333558 loss)
I0403 07:56:32.166267 24116 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 07:56:39.407800 24116 solver.cpp:228] Iteration 1270, loss = 0.468047
I0403 07:56:39.407897 24116 solver.cpp:244]     Train net output #0: loss = 0.468047 (* 1 = 0.468047 loss)
I0403 07:56:39.597735 24116 sgd_solver.cpp:106] Iteration 1270, lr = 0.005
I0403 07:56:46.766116 24116 solver.cpp:228] Iteration 1280, loss = 0.438876
I0403 07:56:46.766212 24116 solver.cpp:244]     Train net output #0: loss = 0.438876 (* 1 = 0.438876 loss)
I0403 07:56:46.954946 24116 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 07:56:53.967797 24116 solver.cpp:228] Iteration 1290, loss = 0.520788
I0403 07:56:53.968127 24116 solver.cpp:244]     Train net output #0: loss = 0.520788 (* 1 = 0.520788 loss)
I0403 07:56:54.162823 24116 sgd_solver.cpp:106] Iteration 1290, lr = 0.005
I0403 07:57:01.275315 24116 solver.cpp:228] Iteration 1300, loss = 0.379492
I0403 07:57:01.275413 24116 solver.cpp:244]     Train net output #0: loss = 0.379492 (* 1 = 0.379492 loss)
I0403 07:57:01.486507 24116 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 07:57:08.943351 24116 solver.cpp:228] Iteration 1310, loss = 0.470878
I0403 07:57:08.943449 24116 solver.cpp:244]     Train net output #0: loss = 0.470878 (* 1 = 0.470878 loss)
I0403 07:57:09.125419 24116 sgd_solver.cpp:106] Iteration 1310, lr = 0.005
I0403 07:57:11.373643 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1314.caffemodel
I0403 07:57:14.147271 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1314.solverstate
I0403 07:57:15.952313 24116 solver.cpp:337] Iteration 1314, Testing net (#0)
I0403 07:58:28.458832 24116 solver.cpp:404]     Test net output #0: accuracy = 0.815078
I0403 07:58:28.459095 24116 solver.cpp:404]     Test net output #1: loss = 0.580317 (* 1 = 0.580317 loss)
I0403 07:58:33.383702 24116 solver.cpp:228] Iteration 1320, loss = 0.570609
I0403 07:58:33.383793 24116 solver.cpp:244]     Train net output #0: loss = 0.570609 (* 1 = 0.570609 loss)
I0403 07:58:33.554435 24116 sgd_solver.cpp:106] Iteration 1320, lr = 0.005
I0403 07:58:40.931186 24116 solver.cpp:228] Iteration 1330, loss = 0.420954
I0403 07:58:40.931274 24116 solver.cpp:244]     Train net output #0: loss = 0.420954 (* 1 = 0.420954 loss)
I0403 07:58:41.088048 24116 sgd_solver.cpp:106] Iteration 1330, lr = 0.005
I0403 07:58:48.199302 24116 solver.cpp:228] Iteration 1340, loss = 0.456032
I0403 07:58:48.199400 24116 solver.cpp:244]     Train net output #0: loss = 0.456032 (* 1 = 0.456032 loss)
I0403 07:58:48.384791 24116 sgd_solver.cpp:106] Iteration 1340, lr = 0.005
I0403 07:58:55.560894 24116 solver.cpp:228] Iteration 1350, loss = 0.603274
I0403 07:58:55.560981 24116 solver.cpp:244]     Train net output #0: loss = 0.603274 (* 1 = 0.603274 loss)
I0403 07:58:55.658205 24116 sgd_solver.cpp:106] Iteration 1350, lr = 0.005
I0403 07:59:02.876075 24116 solver.cpp:228] Iteration 1360, loss = 0.347684
I0403 07:59:02.879112 24116 solver.cpp:244]     Train net output #0: loss = 0.347684 (* 1 = 0.347684 loss)
I0403 07:59:03.076851 24116 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 07:59:10.268592 24116 solver.cpp:228] Iteration 1370, loss = 0.353089
I0403 07:59:10.268690 24116 solver.cpp:244]     Train net output #0: loss = 0.353089 (* 1 = 0.353089 loss)
I0403 07:59:10.455921 24116 sgd_solver.cpp:106] Iteration 1370, lr = 0.005
I0403 07:59:17.582876 24116 solver.cpp:228] Iteration 1380, loss = 0.477235
I0403 07:59:17.582963 24116 solver.cpp:244]     Train net output #0: loss = 0.477235 (* 1 = 0.477235 loss)
I0403 07:59:17.735360 24116 sgd_solver.cpp:106] Iteration 1380, lr = 0.005
I0403 07:59:24.975250 24116 solver.cpp:228] Iteration 1390, loss = 0.676478
I0403 07:59:24.975335 24116 solver.cpp:244]     Train net output #0: loss = 0.676478 (* 1 = 0.676478 loss)
I0403 07:59:25.149763 24116 sgd_solver.cpp:106] Iteration 1390, lr = 0.005
I0403 07:59:32.183807 24116 solver.cpp:228] Iteration 1400, loss = 0.456043
I0403 07:59:32.183892 24116 solver.cpp:244]     Train net output #0: loss = 0.456043 (* 1 = 0.456043 loss)
I0403 07:59:32.347457 24116 sgd_solver.cpp:106] Iteration 1400, lr = 0.005
I0403 07:59:39.640750 24116 solver.cpp:228] Iteration 1410, loss = 0.41242
I0403 07:59:39.641006 24116 solver.cpp:244]     Train net output #0: loss = 0.41242 (* 1 = 0.41242 loss)
I0403 07:59:39.796257 24116 sgd_solver.cpp:106] Iteration 1410, lr = 0.005
I0403 07:59:46.924087 24116 solver.cpp:228] Iteration 1420, loss = 0.426153
I0403 07:59:46.924182 24116 solver.cpp:244]     Train net output #0: loss = 0.426153 (* 1 = 0.426153 loss)
I0403 07:59:47.128702 24116 sgd_solver.cpp:106] Iteration 1420, lr = 0.005
I0403 07:59:54.260898 24116 solver.cpp:228] Iteration 1430, loss = 0.490418
I0403 07:59:54.260999 24116 solver.cpp:244]     Train net output #0: loss = 0.490418 (* 1 = 0.490418 loss)
I0403 07:59:54.459974 24116 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 08:00:01.533486 24116 solver.cpp:228] Iteration 1440, loss = 0.54368
I0403 08:00:01.533576 24116 solver.cpp:244]     Train net output #0: loss = 0.54368 (* 1 = 0.54368 loss)
I0403 08:00:01.730078 24116 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 08:00:08.814927 24116 solver.cpp:228] Iteration 1450, loss = 0.356883
I0403 08:00:08.815026 24116 solver.cpp:244]     Train net output #0: loss = 0.356883 (* 1 = 0.356883 loss)
I0403 08:00:08.998461 24116 sgd_solver.cpp:106] Iteration 1450, lr = 0.005
I0403 08:00:16.291198 24116 solver.cpp:228] Iteration 1460, loss = 0.474497
I0403 08:00:16.291446 24116 solver.cpp:244]     Train net output #0: loss = 0.474497 (* 1 = 0.474497 loss)
I0403 08:00:16.502894 24116 sgd_solver.cpp:106] Iteration 1460, lr = 0.005
I0403 08:00:23.681046 24116 solver.cpp:228] Iteration 1470, loss = 0.312259
I0403 08:00:23.681143 24116 solver.cpp:244]     Train net output #0: loss = 0.312259 (* 1 = 0.312259 loss)
I0403 08:00:23.830656 24116 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 08:00:31.040470 24116 solver.cpp:228] Iteration 1480, loss = 0.363008
I0403 08:00:31.040570 24116 solver.cpp:244]     Train net output #0: loss = 0.363008 (* 1 = 0.363008 loss)
I0403 08:00:31.231794 24116 sgd_solver.cpp:106] Iteration 1480, lr = 0.005
I0403 08:00:38.506325 24116 solver.cpp:228] Iteration 1490, loss = 0.428242
I0403 08:00:38.506419 24116 solver.cpp:244]     Train net output #0: loss = 0.428242 (* 1 = 0.428242 loss)
I0403 08:00:38.701998 24116 sgd_solver.cpp:106] Iteration 1490, lr = 0.005
I0403 08:00:45.748329 24116 solver.cpp:228] Iteration 1500, loss = 0.434346
I0403 08:00:45.748416 24116 solver.cpp:244]     Train net output #0: loss = 0.434346 (* 1 = 0.434346 loss)
I0403 08:00:45.900180 24116 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0403 08:00:52.973122 24116 solver.cpp:228] Iteration 1510, loss = 0.312913
I0403 08:00:52.973402 24116 solver.cpp:244]     Train net output #0: loss = 0.312913 (* 1 = 0.312913 loss)
I0403 08:00:53.156494 24116 sgd_solver.cpp:106] Iteration 1510, lr = 0.005
I0403 08:01:00.221860 24116 solver.cpp:228] Iteration 1520, loss = 0.37555
I0403 08:01:00.221959 24116 solver.cpp:244]     Train net output #0: loss = 0.37555 (* 1 = 0.37555 loss)
I0403 08:01:00.416684 24116 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 08:01:07.497861 24116 solver.cpp:228] Iteration 1530, loss = 0.508682
I0403 08:01:07.497953 24116 solver.cpp:244]     Train net output #0: loss = 0.508682 (* 1 = 0.508682 loss)
I0403 08:01:07.706847 24116 sgd_solver.cpp:106] Iteration 1530, lr = 0.005
I0403 08:01:09.159324 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1533.caffemodel
I0403 08:01:11.931102 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1533.solverstate
I0403 08:01:13.811604 24116 solver.cpp:337] Iteration 1533, Testing net (#0)
I0403 08:02:26.344724 24116 solver.cpp:404]     Test net output #0: accuracy = 0.814644
I0403 08:02:26.345096 24116 solver.cpp:404]     Test net output #1: loss = 0.59628 (* 1 = 0.59628 loss)
I0403 08:02:31.913655 24116 solver.cpp:228] Iteration 1540, loss = 0.398535
I0403 08:02:31.913758 24116 solver.cpp:244]     Train net output #0: loss = 0.398535 (* 1 = 0.398535 loss)
I0403 08:02:32.100967 24116 sgd_solver.cpp:106] Iteration 1540, lr = 0.005
I0403 08:02:39.160738 24116 solver.cpp:228] Iteration 1550, loss = 0.363914
I0403 08:02:39.160830 24116 solver.cpp:244]     Train net output #0: loss = 0.363914 (* 1 = 0.363914 loss)
I0403 08:02:39.337363 24116 sgd_solver.cpp:106] Iteration 1550, lr = 0.005
I0403 08:02:46.838634 24116 solver.cpp:228] Iteration 1560, loss = 0.318248
I0403 08:02:46.838719 24116 solver.cpp:244]     Train net output #0: loss = 0.318248 (* 1 = 0.318248 loss)
I0403 08:02:47.020313 24116 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 08:02:54.075748 24116 solver.cpp:228] Iteration 1570, loss = 0.297133
I0403 08:02:54.075845 24116 solver.cpp:244]     Train net output #0: loss = 0.297133 (* 1 = 0.297133 loss)
I0403 08:02:54.264436 24116 sgd_solver.cpp:106] Iteration 1570, lr = 0.005
I0403 08:03:01.490916 24116 solver.cpp:228] Iteration 1580, loss = 0.310585
I0403 08:03:01.491255 24116 solver.cpp:244]     Train net output #0: loss = 0.310585 (* 1 = 0.310585 loss)
I0403 08:03:01.719393 24116 sgd_solver.cpp:106] Iteration 1580, lr = 0.005
I0403 08:03:08.755733 24116 solver.cpp:228] Iteration 1590, loss = 0.413661
I0403 08:03:08.755823 24116 solver.cpp:244]     Train net output #0: loss = 0.413661 (* 1 = 0.413661 loss)
I0403 08:03:08.916535 24116 sgd_solver.cpp:106] Iteration 1590, lr = 0.005
I0403 08:03:16.005065 24116 solver.cpp:228] Iteration 1600, loss = 0.439078
I0403 08:03:16.005152 24116 solver.cpp:244]     Train net output #0: loss = 0.439078 (* 1 = 0.439078 loss)
I0403 08:03:16.180086 24116 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 08:03:23.487748 24116 solver.cpp:228] Iteration 1610, loss = 0.402877
I0403 08:03:23.487850 24116 solver.cpp:244]     Train net output #0: loss = 0.402877 (* 1 = 0.402877 loss)
I0403 08:03:23.735580 24116 sgd_solver.cpp:106] Iteration 1610, lr = 0.005
I0403 08:03:30.900790 24116 solver.cpp:228] Iteration 1620, loss = 0.329139
I0403 08:03:30.900876 24116 solver.cpp:244]     Train net output #0: loss = 0.329139 (* 1 = 0.329139 loss)
I0403 08:03:31.058027 24116 sgd_solver.cpp:106] Iteration 1620, lr = 0.005
I0403 08:03:38.559165 24116 solver.cpp:228] Iteration 1630, loss = 0.230416
I0403 08:03:38.559465 24116 solver.cpp:244]     Train net output #0: loss = 0.230416 (* 1 = 0.230416 loss)
I0403 08:03:38.753159 24116 sgd_solver.cpp:106] Iteration 1630, lr = 0.005
I0403 08:03:45.806269 24116 solver.cpp:228] Iteration 1640, loss = 0.522698
I0403 08:03:45.806368 24116 solver.cpp:244]     Train net output #0: loss = 0.522698 (* 1 = 0.522698 loss)
I0403 08:03:46.034129 24116 sgd_solver.cpp:106] Iteration 1640, lr = 0.005
I0403 08:03:53.111205 24116 solver.cpp:228] Iteration 1650, loss = 0.468562
I0403 08:03:53.111291 24116 solver.cpp:244]     Train net output #0: loss = 0.468562 (* 1 = 0.468562 loss)
I0403 08:03:53.274734 24116 sgd_solver.cpp:106] Iteration 1650, lr = 0.005
I0403 08:04:00.410917 24116 solver.cpp:228] Iteration 1660, loss = 0.322734
I0403 08:04:00.411005 24116 solver.cpp:244]     Train net output #0: loss = 0.322734 (* 1 = 0.322734 loss)
I0403 08:04:00.581182 24116 sgd_solver.cpp:106] Iteration 1660, lr = 0.005
I0403 08:04:07.731834 24116 solver.cpp:228] Iteration 1670, loss = 0.380995
I0403 08:04:07.731932 24116 solver.cpp:244]     Train net output #0: loss = 0.380995 (* 1 = 0.380995 loss)
I0403 08:04:07.982509 24116 sgd_solver.cpp:106] Iteration 1670, lr = 0.005
I0403 08:04:14.955202 24116 solver.cpp:228] Iteration 1680, loss = 0.287081
I0403 08:04:14.955502 24116 solver.cpp:244]     Train net output #0: loss = 0.287081 (* 1 = 0.287081 loss)
I0403 08:04:15.159222 24116 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 08:04:22.468173 24116 solver.cpp:228] Iteration 1690, loss = 0.187697
I0403 08:04:22.468271 24116 solver.cpp:244]     Train net output #0: loss = 0.187697 (* 1 = 0.187697 loss)
I0403 08:04:22.683158 24116 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 08:04:29.798795 24116 solver.cpp:228] Iteration 1700, loss = 0.283576
I0403 08:04:29.798883 24116 solver.cpp:244]     Train net output #0: loss = 0.283576 (* 1 = 0.283576 loss)
I0403 08:04:29.969218 24116 sgd_solver.cpp:106] Iteration 1700, lr = 0.005
I0403 08:04:37.244530 24116 solver.cpp:228] Iteration 1710, loss = 0.262559
I0403 08:04:37.244626 24116 solver.cpp:244]     Train net output #0: loss = 0.262559 (* 1 = 0.262559 loss)
I0403 08:04:37.443583 24116 sgd_solver.cpp:106] Iteration 1710, lr = 0.005
I0403 08:04:44.514906 24116 solver.cpp:228] Iteration 1720, loss = 0.35662
I0403 08:04:44.515002 24116 solver.cpp:244]     Train net output #0: loss = 0.35662 (* 1 = 0.35662 loss)
I0403 08:04:44.696681 24116 sgd_solver.cpp:106] Iteration 1720, lr = 0.005
I0403 08:04:51.743870 24116 solver.cpp:228] Iteration 1730, loss = 0.466503
I0403 08:04:51.744163 24116 solver.cpp:244]     Train net output #0: loss = 0.466503 (* 1 = 0.466503 loss)
I0403 08:04:51.939968 24116 sgd_solver.cpp:106] Iteration 1730, lr = 0.005
I0403 08:04:59.233167 24116 solver.cpp:228] Iteration 1740, loss = 0.314956
I0403 08:04:59.233256 24116 solver.cpp:244]     Train net output #0: loss = 0.314956 (* 1 = 0.314956 loss)
I0403 08:04:59.388388 24116 sgd_solver.cpp:106] Iteration 1740, lr = 0.005
I0403 08:05:06.567932 24116 solver.cpp:228] Iteration 1750, loss = 0.311474
I0403 08:05:06.568032 24116 solver.cpp:244]     Train net output #0: loss = 0.311474 (* 1 = 0.311474 loss)
I0403 08:05:06.741250 24116 sgd_solver.cpp:106] Iteration 1750, lr = 0.005
I0403 08:05:07.470996 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1752.caffemodel
I0403 08:05:10.165205 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1752.solverstate
I0403 08:05:12.039873 24116 solver.cpp:337] Iteration 1752, Testing net (#0)
I0403 08:06:24.532343 24116 solver.cpp:404]     Test net output #0: accuracy = 0.851795
I0403 08:06:24.532654 24116 solver.cpp:404]     Test net output #1: loss = 0.468855 (* 1 = 0.468855 loss)
I0403 08:06:30.953270 24116 solver.cpp:228] Iteration 1760, loss = 0.419079
I0403 08:06:30.953369 24116 solver.cpp:244]     Train net output #0: loss = 0.419079 (* 1 = 0.419079 loss)
I0403 08:06:31.161911 24116 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 08:06:38.243854 24116 solver.cpp:228] Iteration 1770, loss = 0.385362
I0403 08:06:38.243948 24116 solver.cpp:244]     Train net output #0: loss = 0.385362 (* 1 = 0.385362 loss)
I0403 08:06:38.458720 24116 sgd_solver.cpp:106] Iteration 1770, lr = 0.005
I0403 08:06:45.575067 24116 solver.cpp:228] Iteration 1780, loss = 0.613252
I0403 08:06:45.575148 24116 solver.cpp:244]     Train net output #0: loss = 0.613252 (* 1 = 0.613252 loss)
I0403 08:06:45.730228 24116 sgd_solver.cpp:106] Iteration 1780, lr = 0.005
I0403 08:06:52.951584 24116 solver.cpp:228] Iteration 1790, loss = 0.277582
I0403 08:06:52.951675 24116 solver.cpp:244]     Train net output #0: loss = 0.277582 (* 1 = 0.277582 loss)
I0403 08:06:53.141131 24116 sgd_solver.cpp:106] Iteration 1790, lr = 0.005
I0403 08:07:00.268882 24116 solver.cpp:228] Iteration 1800, loss = 0.126851
I0403 08:07:00.269125 24116 solver.cpp:244]     Train net output #0: loss = 0.126851 (* 1 = 0.126851 loss)
I0403 08:07:00.452205 24116 sgd_solver.cpp:106] Iteration 1800, lr = 0.005
I0403 08:07:07.473199 24116 solver.cpp:228] Iteration 1810, loss = 0.418685
I0403 08:07:07.473296 24116 solver.cpp:244]     Train net output #0: loss = 0.418685 (* 1 = 0.418685 loss)
I0403 08:07:07.655325 24116 sgd_solver.cpp:106] Iteration 1810, lr = 0.005
I0403 08:07:14.691505 24116 solver.cpp:228] Iteration 1820, loss = 0.407218
I0403 08:07:14.691603 24116 solver.cpp:244]     Train net output #0: loss = 0.407218 (* 1 = 0.407218 loss)
I0403 08:07:14.903924 24116 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 08:07:21.944469 24116 solver.cpp:228] Iteration 1830, loss = 0.458281
I0403 08:07:21.944555 24116 solver.cpp:244]     Train net output #0: loss = 0.458281 (* 1 = 0.458281 loss)
I0403 08:07:22.119704 24116 sgd_solver.cpp:106] Iteration 1830, lr = 0.005
I0403 08:07:29.180912 24116 solver.cpp:228] Iteration 1840, loss = 0.428244
I0403 08:07:29.181021 24116 solver.cpp:244]     Train net output #0: loss = 0.428244 (* 1 = 0.428244 loss)
I0403 08:07:29.401935 24116 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 08:07:36.582527 24116 solver.cpp:228] Iteration 1850, loss = 0.175165
I0403 08:07:36.582864 24116 solver.cpp:244]     Train net output #0: loss = 0.175165 (* 1 = 0.175165 loss)
I0403 08:07:36.799054 24116 sgd_solver.cpp:106] Iteration 1850, lr = 0.005
I0403 08:07:44.012913 24116 solver.cpp:228] Iteration 1860, loss = 0.371247
I0403 08:07:44.013006 24116 solver.cpp:244]     Train net output #0: loss = 0.371246 (* 1 = 0.371246 loss)
I0403 08:07:44.225363 24116 sgd_solver.cpp:106] Iteration 1860, lr = 0.005
I0403 08:07:51.351531 24116 solver.cpp:228] Iteration 1870, loss = 0.298603
I0403 08:07:51.351618 24116 solver.cpp:244]     Train net output #0: loss = 0.298603 (* 1 = 0.298603 loss)
I0403 08:07:51.520570 24116 sgd_solver.cpp:106] Iteration 1870, lr = 0.005
I0403 08:07:58.615005 24116 solver.cpp:228] Iteration 1880, loss = 0.377269
I0403 08:07:58.615097 24116 solver.cpp:244]     Train net output #0: loss = 0.377269 (* 1 = 0.377269 loss)
I0403 08:07:58.804719 24116 sgd_solver.cpp:106] Iteration 1880, lr = 0.005
I0403 08:08:05.946811 24116 solver.cpp:228] Iteration 1890, loss = 0.381631
I0403 08:08:05.946909 24116 solver.cpp:244]     Train net output #0: loss = 0.381631 (* 1 = 0.381631 loss)
I0403 08:08:06.131592 24116 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 08:08:13.212126 24116 solver.cpp:228] Iteration 1900, loss = 0.361827
I0403 08:08:13.212426 24116 solver.cpp:244]     Train net output #0: loss = 0.361827 (* 1 = 0.361827 loss)
I0403 08:08:13.435281 24116 sgd_solver.cpp:106] Iteration 1900, lr = 0.005
I0403 08:08:20.635637 24116 solver.cpp:228] Iteration 1910, loss = 0.206138
I0403 08:08:20.635732 24116 solver.cpp:244]     Train net output #0: loss = 0.206138 (* 1 = 0.206138 loss)
I0403 08:08:20.826658 24116 sgd_solver.cpp:106] Iteration 1910, lr = 0.005
I0403 08:08:27.964851 24116 solver.cpp:228] Iteration 1920, loss = 0.429227
I0403 08:08:27.964957 24116 solver.cpp:244]     Train net output #0: loss = 0.429227 (* 1 = 0.429227 loss)
I0403 08:08:28.146523 24116 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 08:08:35.149435 24116 solver.cpp:228] Iteration 1930, loss = 0.304866
I0403 08:08:35.149531 24116 solver.cpp:244]     Train net output #0: loss = 0.304866 (* 1 = 0.304866 loss)
I0403 08:08:35.366605 24116 sgd_solver.cpp:106] Iteration 1930, lr = 0.005
I0403 08:08:42.593073 24116 solver.cpp:228] Iteration 1940, loss = 0.354156
I0403 08:08:42.593158 24116 solver.cpp:244]     Train net output #0: loss = 0.354156 (* 1 = 0.354156 loss)
I0403 08:08:42.768574 24116 sgd_solver.cpp:106] Iteration 1940, lr = 0.005
I0403 08:08:49.798804 24116 solver.cpp:228] Iteration 1950, loss = 0.415733
I0403 08:08:49.805364 24116 solver.cpp:244]     Train net output #0: loss = 0.415733 (* 1 = 0.415733 loss)
I0403 08:08:50.024410 24116 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 08:08:57.057458 24116 solver.cpp:228] Iteration 1960, loss = 0.258583
I0403 08:08:57.057555 24116 solver.cpp:244]     Train net output #0: loss = 0.258583 (* 1 = 0.258583 loss)
I0403 08:08:57.242787 24116 sgd_solver.cpp:106] Iteration 1960, lr = 0.005
I0403 08:09:04.399029 24116 solver.cpp:228] Iteration 1970, loss = 0.419098
I0403 08:09:04.399142 24116 solver.cpp:244]     Train net output #0: loss = 0.419098 (* 1 = 0.419098 loss)
I0403 08:09:04.583891 24116 sgd_solver.cpp:106] Iteration 1970, lr = 0.005
I0403 08:09:04.584121 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1971.caffemodel
I0403 08:09:07.347873 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_1971.solverstate
I0403 08:09:09.241142 24116 solver.cpp:337] Iteration 1971, Testing net (#0)
I0403 08:10:21.763101 24116 solver.cpp:404]     Test net output #0: accuracy = 0.857368
I0403 08:10:21.763414 24116 solver.cpp:404]     Test net output #1: loss = 0.452515 (* 1 = 0.452515 loss)
I0403 08:10:28.898447 24116 solver.cpp:228] Iteration 1980, loss = 0.318924
I0403 08:10:28.898545 24116 solver.cpp:244]     Train net output #0: loss = 0.318924 (* 1 = 0.318924 loss)
I0403 08:10:29.087637 24116 sgd_solver.cpp:106] Iteration 1980, lr = 0.005
I0403 08:10:36.156677 24116 solver.cpp:228] Iteration 1990, loss = 0.425721
I0403 08:10:36.156780 24116 solver.cpp:244]     Train net output #0: loss = 0.425721 (* 1 = 0.425721 loss)
I0403 08:10:36.356736 24116 sgd_solver.cpp:106] Iteration 1990, lr = 0.005
I0403 08:10:43.333106 24116 solver.cpp:228] Iteration 2000, loss = 0.35899
I0403 08:10:43.333201 24116 solver.cpp:244]     Train net output #0: loss = 0.35899 (* 1 = 0.35899 loss)
I0403 08:10:43.517454 24116 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 08:10:50.723685 24116 solver.cpp:228] Iteration 2010, loss = 0.363312
I0403 08:10:50.723788 24116 solver.cpp:244]     Train net output #0: loss = 0.363312 (* 1 = 0.363312 loss)
I0403 08:10:50.932637 24116 sgd_solver.cpp:106] Iteration 2010, lr = 0.005
I0403 08:10:58.084609 24116 solver.cpp:228] Iteration 2020, loss = 0.233945
I0403 08:10:58.084893 24116 solver.cpp:244]     Train net output #0: loss = 0.233945 (* 1 = 0.233945 loss)
I0403 08:10:58.279911 24116 sgd_solver.cpp:106] Iteration 2020, lr = 0.005
I0403 08:11:05.404842 24116 solver.cpp:228] Iteration 2030, loss = 0.306633
I0403 08:11:05.404938 24116 solver.cpp:244]     Train net output #0: loss = 0.306633 (* 1 = 0.306633 loss)
I0403 08:11:05.619256 24116 sgd_solver.cpp:106] Iteration 2030, lr = 0.005
I0403 08:11:12.652885 24116 solver.cpp:228] Iteration 2040, loss = 0.328204
I0403 08:11:12.652983 24116 solver.cpp:244]     Train net output #0: loss = 0.328204 (* 1 = 0.328204 loss)
I0403 08:11:12.862648 24116 sgd_solver.cpp:106] Iteration 2040, lr = 0.005
I0403 08:11:19.905510 24116 solver.cpp:228] Iteration 2050, loss = 0.372932
I0403 08:11:19.905591 24116 solver.cpp:244]     Train net output #0: loss = 0.372932 (* 1 = 0.372932 loss)
I0403 08:11:20.058816 24116 sgd_solver.cpp:106] Iteration 2050, lr = 0.005
I0403 08:11:27.174321 24116 solver.cpp:228] Iteration 2060, loss = 0.313611
I0403 08:11:27.174406 24116 solver.cpp:244]     Train net output #0: loss = 0.313611 (* 1 = 0.313611 loss)
I0403 08:11:27.354557 24116 sgd_solver.cpp:106] Iteration 2060, lr = 0.005
I0403 08:11:34.461968 24116 solver.cpp:228] Iteration 2070, loss = 0.392271
I0403 08:11:34.462271 24116 solver.cpp:244]     Train net output #0: loss = 0.392271 (* 1 = 0.392271 loss)
I0403 08:11:34.699566 24116 sgd_solver.cpp:106] Iteration 2070, lr = 0.005
I0403 08:11:41.717547 24116 solver.cpp:228] Iteration 2080, loss = 0.236041
I0403 08:11:41.717638 24116 solver.cpp:244]     Train net output #0: loss = 0.236041 (* 1 = 0.236041 loss)
I0403 08:11:41.883442 24116 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 08:11:48.999294 24116 solver.cpp:228] Iteration 2090, loss = 0.434916
I0403 08:11:48.999393 24116 solver.cpp:244]     Train net output #0: loss = 0.434916 (* 1 = 0.434916 loss)
I0403 08:11:49.192673 24116 sgd_solver.cpp:106] Iteration 2090, lr = 0.005
I0403 08:11:56.286176 24116 solver.cpp:228] Iteration 2100, loss = 0.24052
I0403 08:11:56.286269 24116 solver.cpp:244]     Train net output #0: loss = 0.24052 (* 1 = 0.24052 loss)
I0403 08:11:56.474794 24116 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 08:12:03.499090 24116 solver.cpp:228] Iteration 2110, loss = 0.397016
I0403 08:12:03.499189 24116 solver.cpp:244]     Train net output #0: loss = 0.397016 (* 1 = 0.397016 loss)
I0403 08:12:03.681730 24116 sgd_solver.cpp:106] Iteration 2110, lr = 0.005
I0403 08:12:10.698233 24116 solver.cpp:228] Iteration 2120, loss = 0.365674
I0403 08:12:10.698546 24116 solver.cpp:244]     Train net output #0: loss = 0.365674 (* 1 = 0.365674 loss)
I0403 08:12:10.914932 24116 sgd_solver.cpp:106] Iteration 2120, lr = 0.005
I0403 08:12:17.949064 24116 solver.cpp:228] Iteration 2130, loss = 0.263261
I0403 08:12:17.949159 24116 solver.cpp:244]     Train net output #0: loss = 0.26326 (* 1 = 0.26326 loss)
I0403 08:12:18.183882 24116 sgd_solver.cpp:106] Iteration 2130, lr = 0.005
I0403 08:12:25.390177 24116 solver.cpp:228] Iteration 2140, loss = 0.168874
I0403 08:12:25.390274 24116 solver.cpp:244]     Train net output #0: loss = 0.168874 (* 1 = 0.168874 loss)
I0403 08:12:25.663197 24116 sgd_solver.cpp:106] Iteration 2140, lr = 0.005
I0403 08:12:32.917649 24116 solver.cpp:228] Iteration 2150, loss = 0.336663
I0403 08:12:32.917750 24116 solver.cpp:244]     Train net output #0: loss = 0.336663 (* 1 = 0.336663 loss)
I0403 08:12:33.094322 24116 sgd_solver.cpp:106] Iteration 2150, lr = 0.005
I0403 08:12:40.418040 24116 solver.cpp:228] Iteration 2160, loss = 0.512739
I0403 08:12:40.418136 24116 solver.cpp:244]     Train net output #0: loss = 0.512739 (* 1 = 0.512739 loss)
I0403 08:12:40.607630 24116 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 08:12:47.755766 24116 solver.cpp:228] Iteration 2170, loss = 0.290489
I0403 08:12:47.756057 24116 solver.cpp:244]     Train net output #0: loss = 0.290489 (* 1 = 0.290489 loss)
I0403 08:12:47.990257 24116 sgd_solver.cpp:106] Iteration 2170, lr = 0.005
I0403 08:12:55.210950 24116 solver.cpp:228] Iteration 2180, loss = 0.417144
I0403 08:12:55.211037 24116 solver.cpp:244]     Train net output #0: loss = 0.417144 (* 1 = 0.417144 loss)
I0403 08:12:55.377403 24116 sgd_solver.cpp:106] Iteration 2180, lr = 0.005
I0403 08:13:01.946601 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2190.caffemodel
I0403 08:13:04.760184 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2190.solverstate
I0403 08:13:06.559007 24116 solver.cpp:337] Iteration 2190, Testing net (#0)
I0403 08:14:19.093300 24116 solver.cpp:404]     Test net output #0: accuracy = 0.868978
I0403 08:14:19.093621 24116 solver.cpp:404]     Test net output #1: loss = 0.41639 (* 1 = 0.41639 loss)
I0403 08:14:19.611148 24116 solver.cpp:228] Iteration 2190, loss = 0.19747
I0403 08:14:19.611228 24116 solver.cpp:244]     Train net output #0: loss = 0.197469 (* 1 = 0.197469 loss)
I0403 08:14:19.775949 24116 sgd_solver.cpp:106] Iteration 2190, lr = 0.005
I0403 08:14:26.925771 24116 solver.cpp:228] Iteration 2200, loss = 0.608139
I0403 08:14:26.925873 24116 solver.cpp:244]     Train net output #0: loss = 0.608139 (* 1 = 0.608139 loss)
I0403 08:14:27.112068 24116 sgd_solver.cpp:106] Iteration 2200, lr = 0.0005
I0403 08:14:34.256819 24116 solver.cpp:228] Iteration 2210, loss = 0.287544
I0403 08:14:34.256921 24116 solver.cpp:244]     Train net output #0: loss = 0.287544 (* 1 = 0.287544 loss)
I0403 08:14:34.439128 24116 sgd_solver.cpp:106] Iteration 2210, lr = 0.0005
I0403 08:14:41.406657 24116 solver.cpp:228] Iteration 2220, loss = 0.234163
I0403 08:14:41.406743 24116 solver.cpp:244]     Train net output #0: loss = 0.234163 (* 1 = 0.234163 loss)
I0403 08:14:41.584269 24116 sgd_solver.cpp:106] Iteration 2220, lr = 0.0005
I0403 08:14:48.663648 24116 solver.cpp:228] Iteration 2230, loss = 0.185602
I0403 08:14:48.663744 24116 solver.cpp:244]     Train net output #0: loss = 0.185602 (* 1 = 0.185602 loss)
I0403 08:14:48.859329 24116 sgd_solver.cpp:106] Iteration 2230, lr = 0.0005
I0403 08:14:55.928993 24116 solver.cpp:228] Iteration 2240, loss = 0.161209
I0403 08:14:55.929329 24116 solver.cpp:244]     Train net output #0: loss = 0.161209 (* 1 = 0.161209 loss)
I0403 08:14:56.139158 24116 sgd_solver.cpp:106] Iteration 2240, lr = 0.0005
I0403 08:15:03.264314 24116 solver.cpp:228] Iteration 2250, loss = 0.318068
I0403 08:15:03.264411 24116 solver.cpp:244]     Train net output #0: loss = 0.318068 (* 1 = 0.318068 loss)
I0403 08:15:03.465821 24116 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0403 08:15:10.495813 24116 solver.cpp:228] Iteration 2260, loss = 0.233695
I0403 08:15:10.495911 24116 solver.cpp:244]     Train net output #0: loss = 0.233695 (* 1 = 0.233695 loss)
I0403 08:15:10.679225 24116 sgd_solver.cpp:106] Iteration 2260, lr = 0.0005
I0403 08:15:17.704468 24116 solver.cpp:228] Iteration 2270, loss = 0.258157
I0403 08:15:17.704561 24116 solver.cpp:244]     Train net output #0: loss = 0.258157 (* 1 = 0.258157 loss)
I0403 08:15:17.918632 24116 sgd_solver.cpp:106] Iteration 2270, lr = 0.0005
I0403 08:15:24.940397 24116 solver.cpp:228] Iteration 2280, loss = 0.139584
I0403 08:15:24.940496 24116 solver.cpp:244]     Train net output #0: loss = 0.139584 (* 1 = 0.139584 loss)
I0403 08:15:25.128424 24116 sgd_solver.cpp:106] Iteration 2280, lr = 0.0005
I0403 08:15:32.344472 24116 solver.cpp:228] Iteration 2290, loss = 0.191089
I0403 08:15:32.344766 24116 solver.cpp:244]     Train net output #0: loss = 0.191089 (* 1 = 0.191089 loss)
I0403 08:15:32.514264 24116 sgd_solver.cpp:106] Iteration 2290, lr = 0.0005
I0403 08:15:39.654796 24116 solver.cpp:228] Iteration 2300, loss = 0.176787
I0403 08:15:39.654892 24116 solver.cpp:244]     Train net output #0: loss = 0.176787 (* 1 = 0.176787 loss)
I0403 08:15:39.869948 24116 sgd_solver.cpp:106] Iteration 2300, lr = 0.0005
I0403 08:15:46.850929 24116 solver.cpp:228] Iteration 2310, loss = 0.190518
I0403 08:15:46.851025 24116 solver.cpp:244]     Train net output #0: loss = 0.190517 (* 1 = 0.190517 loss)
I0403 08:15:47.084992 24116 sgd_solver.cpp:106] Iteration 2310, lr = 0.0005
I0403 08:15:54.298920 24116 solver.cpp:228] Iteration 2320, loss = 0.240613
I0403 08:15:54.299008 24116 solver.cpp:244]     Train net output #0: loss = 0.240613 (* 1 = 0.240613 loss)
I0403 08:15:54.470921 24116 sgd_solver.cpp:106] Iteration 2320, lr = 0.0005
I0403 08:16:01.641855 24116 solver.cpp:228] Iteration 2330, loss = 0.134419
I0403 08:16:01.641952 24116 solver.cpp:244]     Train net output #0: loss = 0.134419 (* 1 = 0.134419 loss)
I0403 08:16:01.826469 24116 sgd_solver.cpp:106] Iteration 2330, lr = 0.0005
I0403 08:16:08.921236 24116 solver.cpp:228] Iteration 2340, loss = 0.216125
I0403 08:16:08.921541 24116 solver.cpp:244]     Train net output #0: loss = 0.216125 (* 1 = 0.216125 loss)
I0403 08:16:09.133658 24116 sgd_solver.cpp:106] Iteration 2340, lr = 0.0005
I0403 08:16:16.134173 24116 solver.cpp:228] Iteration 2350, loss = 0.146218
I0403 08:16:16.134274 24116 solver.cpp:244]     Train net output #0: loss = 0.146218 (* 1 = 0.146218 loss)
I0403 08:16:16.319473 24116 sgd_solver.cpp:106] Iteration 2350, lr = 0.0005
I0403 08:16:23.631819 24116 solver.cpp:228] Iteration 2360, loss = 0.189077
I0403 08:16:23.631904 24116 solver.cpp:244]     Train net output #0: loss = 0.189077 (* 1 = 0.189077 loss)
I0403 08:16:23.805524 24116 sgd_solver.cpp:106] Iteration 2360, lr = 0.0005
I0403 08:16:30.872419 24116 solver.cpp:228] Iteration 2370, loss = 0.165738
I0403 08:16:30.872519 24116 solver.cpp:244]     Train net output #0: loss = 0.165738 (* 1 = 0.165738 loss)
I0403 08:16:31.054672 24116 sgd_solver.cpp:106] Iteration 2370, lr = 0.0005
I0403 08:16:38.124220 24116 solver.cpp:228] Iteration 2380, loss = 0.164981
I0403 08:16:38.124308 24116 solver.cpp:244]     Train net output #0: loss = 0.164981 (* 1 = 0.164981 loss)
I0403 08:16:38.272136 24116 sgd_solver.cpp:106] Iteration 2380, lr = 0.0005
I0403 08:16:45.579586 24116 solver.cpp:228] Iteration 2390, loss = 0.126959
I0403 08:16:45.579869 24116 solver.cpp:244]     Train net output #0: loss = 0.126958 (* 1 = 0.126958 loss)
I0403 08:16:45.785187 24116 sgd_solver.cpp:106] Iteration 2390, lr = 0.0005
I0403 08:16:52.949154 24116 solver.cpp:228] Iteration 2400, loss = 0.223393
I0403 08:16:52.949256 24116 solver.cpp:244]     Train net output #0: loss = 0.223393 (* 1 = 0.223393 loss)
I0403 08:16:53.180376 24116 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I0403 08:16:59.207821 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2409.caffemodel
I0403 08:17:02.027859 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2409.solverstate
I0403 08:17:03.931434 24116 solver.cpp:337] Iteration 2409, Testing net (#0)
I0403 08:18:16.434468 24116 solver.cpp:404]     Test net output #0: accuracy = 0.895201
I0403 08:18:16.434793 24116 solver.cpp:404]     Test net output #1: loss = 0.331372 (* 1 = 0.331372 loss)
I0403 08:18:17.681334 24116 solver.cpp:228] Iteration 2410, loss = 0.117808
I0403 08:18:17.681432 24116 solver.cpp:244]     Train net output #0: loss = 0.117808 (* 1 = 0.117808 loss)
I0403 08:18:17.915277 24116 sgd_solver.cpp:106] Iteration 2410, lr = 0.0005
I0403 08:18:25.104856 24116 solver.cpp:228] Iteration 2420, loss = 0.174178
I0403 08:18:25.104954 24116 solver.cpp:244]     Train net output #0: loss = 0.174178 (* 1 = 0.174178 loss)
I0403 08:18:25.302862 24116 sgd_solver.cpp:106] Iteration 2420, lr = 0.0005
I0403 08:18:32.318876 24116 solver.cpp:228] Iteration 2430, loss = 0.25202
I0403 08:18:32.318974 24116 solver.cpp:244]     Train net output #0: loss = 0.25202 (* 1 = 0.25202 loss)
I0403 08:18:32.501322 24116 sgd_solver.cpp:106] Iteration 2430, lr = 0.0005
I0403 08:18:39.536877 24116 solver.cpp:228] Iteration 2440, loss = 0.0677074
I0403 08:18:39.536974 24116 solver.cpp:244]     Train net output #0: loss = 0.0677073 (* 1 = 0.0677073 loss)
I0403 08:18:39.720010 24116 sgd_solver.cpp:106] Iteration 2440, lr = 0.0005
I0403 08:18:46.749285 24116 solver.cpp:228] Iteration 2450, loss = 0.10453
I0403 08:18:46.749523 24116 solver.cpp:244]     Train net output #0: loss = 0.104529 (* 1 = 0.104529 loss)
I0403 08:18:46.960224 24116 sgd_solver.cpp:106] Iteration 2450, lr = 0.0005
I0403 08:18:54.063390 24116 solver.cpp:228] Iteration 2460, loss = 0.150684
I0403 08:18:54.063482 24116 solver.cpp:244]     Train net output #0: loss = 0.150683 (* 1 = 0.150683 loss)
I0403 08:18:54.247979 24116 sgd_solver.cpp:106] Iteration 2460, lr = 0.0005
I0403 08:19:01.296039 24116 solver.cpp:228] Iteration 2470, loss = 0.157394
I0403 08:19:01.296138 24116 solver.cpp:244]     Train net output #0: loss = 0.157394 (* 1 = 0.157394 loss)
I0403 08:19:01.488658 24116 sgd_solver.cpp:106] Iteration 2470, lr = 0.0005
I0403 08:19:08.560200 24116 solver.cpp:228] Iteration 2480, loss = 0.10767
I0403 08:19:08.560297 24116 solver.cpp:244]     Train net output #0: loss = 0.10767 (* 1 = 0.10767 loss)
I0403 08:19:08.746176 24116 sgd_solver.cpp:106] Iteration 2480, lr = 0.0005
I0403 08:19:15.776360 24116 solver.cpp:228] Iteration 2490, loss = 0.333723
I0403 08:19:15.776456 24116 solver.cpp:244]     Train net output #0: loss = 0.333722 (* 1 = 0.333722 loss)
I0403 08:19:15.979267 24116 sgd_solver.cpp:106] Iteration 2490, lr = 0.0005
I0403 08:19:23.113483 24116 solver.cpp:228] Iteration 2500, loss = 0.122594
I0403 08:19:23.113760 24116 solver.cpp:244]     Train net output #0: loss = 0.122594 (* 1 = 0.122594 loss)
I0403 08:19:23.330660 24116 sgd_solver.cpp:106] Iteration 2500, lr = 0.0005
I0403 08:19:30.537631 24116 solver.cpp:228] Iteration 2510, loss = 0.140683
I0403 08:19:30.537719 24116 solver.cpp:244]     Train net output #0: loss = 0.140683 (* 1 = 0.140683 loss)
I0403 08:19:30.690184 24116 sgd_solver.cpp:106] Iteration 2510, lr = 0.0005
I0403 08:19:37.742035 24116 solver.cpp:228] Iteration 2520, loss = 0.112724
I0403 08:19:37.742121 24116 solver.cpp:244]     Train net output #0: loss = 0.112724 (* 1 = 0.112724 loss)
I0403 08:19:37.920187 24116 sgd_solver.cpp:106] Iteration 2520, lr = 0.0005
I0403 08:19:45.039759 24116 solver.cpp:228] Iteration 2530, loss = 0.173935
I0403 08:19:45.039860 24116 solver.cpp:244]     Train net output #0: loss = 0.173935 (* 1 = 0.173935 loss)
I0403 08:19:45.236081 24116 sgd_solver.cpp:106] Iteration 2530, lr = 0.0005
I0403 08:19:52.384709 24116 solver.cpp:228] Iteration 2540, loss = 0.16612
I0403 08:19:52.384800 24116 solver.cpp:244]     Train net output #0: loss = 0.16612 (* 1 = 0.16612 loss)
I0403 08:19:52.549630 24116 sgd_solver.cpp:106] Iteration 2540, lr = 0.0005
I0403 08:19:59.574316 24116 solver.cpp:228] Iteration 2550, loss = 0.124575
I0403 08:19:59.574633 24116 solver.cpp:244]     Train net output #0: loss = 0.124574 (* 1 = 0.124574 loss)
I0403 08:19:59.756088 24116 sgd_solver.cpp:106] Iteration 2550, lr = 0.0005
I0403 08:20:06.813787 24116 solver.cpp:228] Iteration 2560, loss = 0.131178
I0403 08:20:06.813868 24116 solver.cpp:244]     Train net output #0: loss = 0.131178 (* 1 = 0.131178 loss)
I0403 08:20:06.995463 24116 sgd_solver.cpp:106] Iteration 2560, lr = 0.0005
I0403 08:20:14.141273 24116 solver.cpp:228] Iteration 2570, loss = 0.0826947
I0403 08:20:14.141362 24116 solver.cpp:244]     Train net output #0: loss = 0.0826945 (* 1 = 0.0826945 loss)
I0403 08:20:14.308598 24116 sgd_solver.cpp:106] Iteration 2570, lr = 0.0005
I0403 08:20:21.426666 24116 solver.cpp:228] Iteration 2580, loss = 0.0801261
I0403 08:20:21.426760 24116 solver.cpp:244]     Train net output #0: loss = 0.0801259 (* 1 = 0.0801259 loss)
I0403 08:20:21.669556 24116 sgd_solver.cpp:106] Iteration 2580, lr = 0.0005
I0403 08:20:28.709506 24116 solver.cpp:228] Iteration 2590, loss = 0.163235
I0403 08:20:28.709601 24116 solver.cpp:244]     Train net output #0: loss = 0.163235 (* 1 = 0.163235 loss)
I0403 08:20:28.899971 24116 sgd_solver.cpp:106] Iteration 2590, lr = 0.0005
I0403 08:20:35.965797 24116 solver.cpp:228] Iteration 2600, loss = 0.15641
I0403 08:20:35.966080 24116 solver.cpp:244]     Train net output #0: loss = 0.15641 (* 1 = 0.15641 loss)
I0403 08:20:36.162539 24116 sgd_solver.cpp:106] Iteration 2600, lr = 0.0005
I0403 08:20:43.372262 24116 solver.cpp:228] Iteration 2610, loss = 0.133151
I0403 08:20:43.372359 24116 solver.cpp:244]     Train net output #0: loss = 0.13315 (* 1 = 0.13315 loss)
I0403 08:20:43.576602 24116 sgd_solver.cpp:106] Iteration 2610, lr = 0.0005
I0403 08:20:50.800335 24116 solver.cpp:228] Iteration 2620, loss = 0.146804
I0403 08:20:50.800420 24116 solver.cpp:244]     Train net output #0: loss = 0.146804 (* 1 = 0.146804 loss)
I0403 08:20:50.937553 24116 sgd_solver.cpp:106] Iteration 2620, lr = 0.0005
I0403 08:20:56.193698 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2628.caffemodel
I0403 08:20:58.950702 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2628.solverstate
I0403 08:21:00.834525 24116 solver.cpp:337] Iteration 2628, Testing net (#0)
I0403 08:22:13.339470 24116 solver.cpp:404]     Test net output #0: accuracy = 0.898328
I0403 08:22:13.339774 24116 solver.cpp:404]     Test net output #1: loss = 0.32392 (* 1 = 0.32392 loss)
I0403 08:22:15.401296 24116 solver.cpp:228] Iteration 2630, loss = 0.045725
I0403 08:22:15.401381 24116 solver.cpp:244]     Train net output #0: loss = 0.0457248 (* 1 = 0.0457248 loss)
I0403 08:22:15.527313 24116 sgd_solver.cpp:106] Iteration 2630, lr = 0.0005
I0403 08:22:22.843791 24116 solver.cpp:228] Iteration 2640, loss = 0.147765
I0403 08:22:22.843885 24116 solver.cpp:244]     Train net output #0: loss = 0.147765 (* 1 = 0.147765 loss)
I0403 08:22:23.028585 24116 sgd_solver.cpp:106] Iteration 2640, lr = 0.0005
I0403 08:22:30.263546 24116 solver.cpp:228] Iteration 2650, loss = 0.171371
I0403 08:22:30.263645 24116 solver.cpp:244]     Train net output #0: loss = 0.171371 (* 1 = 0.171371 loss)
I0403 08:22:30.459661 24116 sgd_solver.cpp:106] Iteration 2650, lr = 0.0005
I0403 08:22:37.528875 24116 solver.cpp:228] Iteration 2660, loss = 0.185742
I0403 08:22:37.528973 24116 solver.cpp:244]     Train net output #0: loss = 0.185742 (* 1 = 0.185742 loss)
I0403 08:22:37.717659 24116 sgd_solver.cpp:106] Iteration 2660, lr = 0.0005
I0403 08:22:44.865155 24116 solver.cpp:228] Iteration 2670, loss = 0.1528
I0403 08:22:44.865460 24116 solver.cpp:244]     Train net output #0: loss = 0.1528 (* 1 = 0.1528 loss)
I0403 08:22:45.070235 24116 sgd_solver.cpp:106] Iteration 2670, lr = 0.0005
I0403 08:22:52.177858 24116 solver.cpp:228] Iteration 2680, loss = 0.0956163
I0403 08:22:52.177953 24116 solver.cpp:244]     Train net output #0: loss = 0.0956162 (* 1 = 0.0956162 loss)
I0403 08:22:52.377507 24116 sgd_solver.cpp:106] Iteration 2680, lr = 0.0005
I0403 08:22:59.447491 24116 solver.cpp:228] Iteration 2690, loss = 0.158699
I0403 08:22:59.447582 24116 solver.cpp:244]     Train net output #0: loss = 0.158699 (* 1 = 0.158699 loss)
I0403 08:22:59.627043 24116 sgd_solver.cpp:106] Iteration 2690, lr = 0.0005
I0403 08:23:06.635170 24116 solver.cpp:228] Iteration 2700, loss = 0.16362
I0403 08:23:06.635260 24116 solver.cpp:244]     Train net output #0: loss = 0.16362 (* 1 = 0.16362 loss)
I0403 08:23:06.814076 24116 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I0403 08:23:13.823771 24116 solver.cpp:228] Iteration 2710, loss = 0.305101
I0403 08:23:13.823871 24116 solver.cpp:244]     Train net output #0: loss = 0.305101 (* 1 = 0.305101 loss)
I0403 08:23:14.007031 24116 sgd_solver.cpp:106] Iteration 2710, lr = 0.0005
I0403 08:23:21.020421 24116 solver.cpp:228] Iteration 2720, loss = 0.128418
I0403 08:23:21.020685 24116 solver.cpp:244]     Train net output #0: loss = 0.128418 (* 1 = 0.128418 loss)
I0403 08:23:21.195755 24116 sgd_solver.cpp:106] Iteration 2720, lr = 0.0005
I0403 08:23:28.271571 24116 solver.cpp:228] Iteration 2730, loss = 0.0914302
I0403 08:23:28.271663 24116 solver.cpp:244]     Train net output #0: loss = 0.0914301 (* 1 = 0.0914301 loss)
I0403 08:23:28.423622 24116 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 08:23:35.897094 24116 solver.cpp:228] Iteration 2740, loss = 0.077154
I0403 08:23:35.897192 24116 solver.cpp:244]     Train net output #0: loss = 0.0771539 (* 1 = 0.0771539 loss)
I0403 08:23:36.080420 24116 sgd_solver.cpp:106] Iteration 2740, lr = 0.0005
I0403 08:23:43.185297 24116 solver.cpp:228] Iteration 2750, loss = 0.085353
I0403 08:23:43.185397 24116 solver.cpp:244]     Train net output #0: loss = 0.0853529 (* 1 = 0.0853529 loss)
I0403 08:23:43.369839 24116 sgd_solver.cpp:106] Iteration 2750, lr = 0.0005
I0403 08:23:50.457608 24116 solver.cpp:228] Iteration 2760, loss = 0.04702
I0403 08:23:50.457695 24116 solver.cpp:244]     Train net output #0: loss = 0.0470199 (* 1 = 0.0470199 loss)
I0403 08:23:50.622735 24116 sgd_solver.cpp:106] Iteration 2760, lr = 0.0005
I0403 08:23:57.721304 24116 solver.cpp:228] Iteration 2770, loss = 0.160654
I0403 08:23:57.721581 24116 solver.cpp:244]     Train net output #0: loss = 0.160654 (* 1 = 0.160654 loss)
I0403 08:23:57.880192 24116 sgd_solver.cpp:106] Iteration 2770, lr = 0.0005
I0403 08:24:04.969128 24116 solver.cpp:228] Iteration 2780, loss = 0.133829
I0403 08:24:04.969228 24116 solver.cpp:244]     Train net output #0: loss = 0.133829 (* 1 = 0.133829 loss)
I0403 08:24:05.193264 24116 sgd_solver.cpp:106] Iteration 2780, lr = 0.0005
I0403 08:24:12.273593 24116 solver.cpp:228] Iteration 2790, loss = 0.0952202
I0403 08:24:12.273692 24116 solver.cpp:244]     Train net output #0: loss = 0.0952201 (* 1 = 0.0952201 loss)
I0403 08:24:12.458206 24116 sgd_solver.cpp:106] Iteration 2790, lr = 0.0005
I0403 08:24:19.589782 24116 solver.cpp:228] Iteration 2800, loss = 0.0743933
I0403 08:24:19.589870 24116 solver.cpp:244]     Train net output #0: loss = 0.0743932 (* 1 = 0.0743932 loss)
I0403 08:24:19.801913 24116 sgd_solver.cpp:106] Iteration 2800, lr = 0.0005
I0403 08:24:26.776069 24116 solver.cpp:228] Iteration 2810, loss = 0.11925
I0403 08:24:26.776168 24116 solver.cpp:244]     Train net output #0: loss = 0.11925 (* 1 = 0.11925 loss)
I0403 08:24:26.984607 24116 sgd_solver.cpp:106] Iteration 2810, lr = 0.0005
I0403 08:24:34.009398 24116 solver.cpp:228] Iteration 2820, loss = 0.196484
I0403 08:24:34.009706 24116 solver.cpp:244]     Train net output #0: loss = 0.196484 (* 1 = 0.196484 loss)
I0403 08:24:34.198566 24116 sgd_solver.cpp:106] Iteration 2820, lr = 0.0005
I0403 08:24:41.331146 24116 solver.cpp:228] Iteration 2830, loss = 0.127852
I0403 08:24:41.331244 24116 solver.cpp:244]     Train net output #0: loss = 0.127852 (* 1 = 0.127852 loss)
I0403 08:24:41.525594 24116 sgd_solver.cpp:106] Iteration 2830, lr = 0.0005
I0403 08:24:48.684908 24116 solver.cpp:228] Iteration 2840, loss = 0.123193
I0403 08:24:48.685008 24116 solver.cpp:244]     Train net output #0: loss = 0.123193 (* 1 = 0.123193 loss)
I0403 08:24:48.878725 24116 sgd_solver.cpp:106] Iteration 2840, lr = 0.0005
I0403 08:24:53.319802 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2847.caffemodel
I0403 08:24:56.092983 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_2847.solverstate
I0403 08:24:57.985215 24116 solver.cpp:337] Iteration 2847, Testing net (#0)
I0403 08:26:10.468154 24116 solver.cpp:404]     Test net output #0: accuracy = 0.899938
I0403 08:26:10.468498 24116 solver.cpp:404]     Test net output #1: loss = 0.324149 (* 1 = 0.324149 loss)
I0403 08:26:13.188705 24116 solver.cpp:228] Iteration 2850, loss = 0.104231
I0403 08:26:13.188813 24116 solver.cpp:244]     Train net output #0: loss = 0.104231 (* 1 = 0.104231 loss)
I0403 08:26:13.372865 24116 sgd_solver.cpp:106] Iteration 2850, lr = 0.0005
I0403 08:26:20.411509 24116 solver.cpp:228] Iteration 2860, loss = 0.166442
I0403 08:26:20.411599 24116 solver.cpp:244]     Train net output #0: loss = 0.166442 (* 1 = 0.166442 loss)
I0403 08:26:20.558310 24116 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 08:26:27.855146 24116 solver.cpp:228] Iteration 2870, loss = 0.0803054
I0403 08:26:27.855233 24116 solver.cpp:244]     Train net output #0: loss = 0.0803053 (* 1 = 0.0803053 loss)
I0403 08:26:28.025723 24116 sgd_solver.cpp:106] Iteration 2870, lr = 0.0005
I0403 08:26:35.219352 24116 solver.cpp:228] Iteration 2880, loss = 0.156397
I0403 08:26:35.219454 24116 solver.cpp:244]     Train net output #0: loss = 0.156397 (* 1 = 0.156397 loss)
I0403 08:26:35.443738 24116 sgd_solver.cpp:106] Iteration 2880, lr = 0.0005
I0403 08:26:42.509096 24116 solver.cpp:228] Iteration 2890, loss = 0.12454
I0403 08:26:42.509351 24116 solver.cpp:244]     Train net output #0: loss = 0.12454 (* 1 = 0.12454 loss)
I0403 08:26:42.706465 24116 sgd_solver.cpp:106] Iteration 2890, lr = 0.0005
I0403 08:26:49.737056 24116 solver.cpp:228] Iteration 2900, loss = 0.0628946
I0403 08:26:49.737146 24116 solver.cpp:244]     Train net output #0: loss = 0.0628945 (* 1 = 0.0628945 loss)
I0403 08:26:49.938710 24116 sgd_solver.cpp:106] Iteration 2900, lr = 0.0005
I0403 08:26:56.946955 24116 solver.cpp:228] Iteration 2910, loss = 0.199339
I0403 08:26:56.947063 24116 solver.cpp:244]     Train net output #0: loss = 0.199339 (* 1 = 0.199339 loss)
I0403 08:26:57.145946 24116 sgd_solver.cpp:106] Iteration 2910, lr = 0.0005
I0403 08:27:04.162436 24116 solver.cpp:228] Iteration 2920, loss = 0.116276
I0403 08:27:04.162535 24116 solver.cpp:244]     Train net output #0: loss = 0.116276 (* 1 = 0.116276 loss)
I0403 08:27:04.396404 24116 sgd_solver.cpp:106] Iteration 2920, lr = 0.0005
I0403 08:27:11.439065 24116 solver.cpp:228] Iteration 2930, loss = 0.142852
I0403 08:27:11.439162 24116 solver.cpp:244]     Train net output #0: loss = 0.142852 (* 1 = 0.142852 loss)
I0403 08:27:11.634582 24116 sgd_solver.cpp:106] Iteration 2930, lr = 0.0005
I0403 08:27:18.715348 24116 solver.cpp:228] Iteration 2940, loss = 0.106811
I0403 08:27:18.715620 24116 solver.cpp:244]     Train net output #0: loss = 0.106811 (* 1 = 0.106811 loss)
I0403 08:27:18.923604 24116 sgd_solver.cpp:106] Iteration 2940, lr = 0.0005
I0403 08:27:25.956742 24116 solver.cpp:228] Iteration 2950, loss = 0.0695315
I0403 08:27:25.956842 24116 solver.cpp:244]     Train net output #0: loss = 0.0695313 (* 1 = 0.0695313 loss)
I0403 08:27:26.173410 24116 sgd_solver.cpp:106] Iteration 2950, lr = 0.0005
I0403 08:27:33.230686 24116 solver.cpp:228] Iteration 2960, loss = 0.22083
I0403 08:27:33.230792 24116 solver.cpp:244]     Train net output #0: loss = 0.22083 (* 1 = 0.22083 loss)
I0403 08:27:33.475610 24116 sgd_solver.cpp:106] Iteration 2960, lr = 0.0005
I0403 08:27:40.473757 24116 solver.cpp:228] Iteration 2970, loss = 0.168006
I0403 08:27:40.473855 24116 solver.cpp:244]     Train net output #0: loss = 0.168006 (* 1 = 0.168006 loss)
I0403 08:27:40.657086 24116 sgd_solver.cpp:106] Iteration 2970, lr = 0.0005
I0403 08:27:47.719724 24116 solver.cpp:228] Iteration 2980, loss = 0.100777
I0403 08:27:47.719830 24116 solver.cpp:244]     Train net output #0: loss = 0.100777 (* 1 = 0.100777 loss)
I0403 08:27:47.904078 24116 sgd_solver.cpp:106] Iteration 2980, lr = 0.0005
I0403 08:27:54.900643 24116 solver.cpp:228] Iteration 2990, loss = 0.17344
I0403 08:27:54.900972 24116 solver.cpp:244]     Train net output #0: loss = 0.17344 (* 1 = 0.17344 loss)
I0403 08:27:55.093255 24116 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 08:28:02.236682 24116 solver.cpp:228] Iteration 3000, loss = 0.1142
I0403 08:28:02.236788 24116 solver.cpp:244]     Train net output #0: loss = 0.1142 (* 1 = 0.1142 loss)
I0403 08:28:02.436219 24116 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0403 08:28:09.620450 24116 solver.cpp:228] Iteration 3010, loss = 0.0589874
I0403 08:28:09.620537 24116 solver.cpp:244]     Train net output #0: loss = 0.0589872 (* 1 = 0.0589872 loss)
I0403 08:28:09.766963 24116 sgd_solver.cpp:106] Iteration 3010, lr = 0.0005
I0403 08:28:17.176719 24116 solver.cpp:228] Iteration 3020, loss = 0.124412
I0403 08:28:17.176826 24116 solver.cpp:244]     Train net output #0: loss = 0.124412 (* 1 = 0.124412 loss)
I0403 08:28:17.366185 24116 sgd_solver.cpp:106] Iteration 3020, lr = 0.0005
I0403 08:28:24.448318 24116 solver.cpp:228] Iteration 3030, loss = 0.107785
I0403 08:28:24.448405 24116 solver.cpp:244]     Train net output #0: loss = 0.107785 (* 1 = 0.107785 loss)
I0403 08:28:24.629940 24116 sgd_solver.cpp:106] Iteration 3030, lr = 0.0005
I0403 08:28:31.738505 24116 solver.cpp:228] Iteration 3040, loss = 0.114277
I0403 08:28:31.738787 24116 solver.cpp:244]     Train net output #0: loss = 0.114276 (* 1 = 0.114276 loss)
I0403 08:28:31.855056 24116 sgd_solver.cpp:106] Iteration 3040, lr = 0.0005
I0403 08:28:39.113642 24116 solver.cpp:228] Iteration 3050, loss = 0.102143
I0403 08:28:39.113741 24116 solver.cpp:244]     Train net output #0: loss = 0.102142 (* 1 = 0.102142 loss)
I0403 08:28:39.307301 24116 sgd_solver.cpp:106] Iteration 3050, lr = 0.0005
I0403 08:28:46.330163 24116 solver.cpp:228] Iteration 3060, loss = 0.0683494
I0403 08:28:46.330250 24116 solver.cpp:244]     Train net output #0: loss = 0.0683492 (* 1 = 0.0683492 loss)
I0403 08:28:46.510833 24116 sgd_solver.cpp:106] Iteration 3060, lr = 0.0005
I0403 08:28:50.130010 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3066.caffemodel
I0403 08:28:52.909137 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3066.solverstate
I0403 08:28:54.807363 24116 solver.cpp:337] Iteration 3066, Testing net (#0)
I0403 08:30:07.322815 24116 solver.cpp:404]     Test net output #0: accuracy = 0.903839
I0403 08:30:07.323150 24116 solver.cpp:404]     Test net output #1: loss = 0.316917 (* 1 = 0.316917 loss)
I0403 08:30:10.716847 24116 solver.cpp:228] Iteration 3070, loss = 0.134618
I0403 08:30:10.716939 24116 solver.cpp:244]     Train net output #0: loss = 0.134618 (* 1 = 0.134618 loss)
I0403 08:30:10.900346 24116 sgd_solver.cpp:106] Iteration 3070, lr = 0.0005
I0403 08:30:17.967190 24116 solver.cpp:228] Iteration 3080, loss = 0.152367
I0403 08:30:17.967277 24116 solver.cpp:244]     Train net output #0: loss = 0.152367 (* 1 = 0.152367 loss)
I0403 08:30:18.114537 24116 sgd_solver.cpp:106] Iteration 3080, lr = 0.0005
I0403 08:30:25.464939 24116 solver.cpp:228] Iteration 3090, loss = 0.108664
I0403 08:30:25.465049 24116 solver.cpp:244]     Train net output #0: loss = 0.108664 (* 1 = 0.108664 loss)
I0403 08:30:25.647081 24116 sgd_solver.cpp:106] Iteration 3090, lr = 0.0005
I0403 08:30:32.767906 24116 solver.cpp:228] Iteration 3100, loss = 0.104396
I0403 08:30:32.768005 24116 solver.cpp:244]     Train net output #0: loss = 0.104396 (* 1 = 0.104396 loss)
I0403 08:30:32.979034 24116 sgd_solver.cpp:106] Iteration 3100, lr = 0.0005
I0403 08:30:40.034196 24116 solver.cpp:228] Iteration 3110, loss = 0.0598624
I0403 08:30:40.034520 24116 solver.cpp:244]     Train net output #0: loss = 0.0598622 (* 1 = 0.0598622 loss)
I0403 08:30:40.212044 24116 sgd_solver.cpp:106] Iteration 3110, lr = 0.0005
I0403 08:30:47.341265 24116 solver.cpp:228] Iteration 3120, loss = 0.102687
I0403 08:30:47.341354 24116 solver.cpp:244]     Train net output #0: loss = 0.102687 (* 1 = 0.102687 loss)
I0403 08:30:47.498227 24116 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 08:30:54.621711 24116 solver.cpp:228] Iteration 3130, loss = 0.0826505
I0403 08:30:54.621816 24116 solver.cpp:244]     Train net output #0: loss = 0.0826503 (* 1 = 0.0826503 loss)
I0403 08:30:54.824139 24116 sgd_solver.cpp:106] Iteration 3130, lr = 0.0005
I0403 08:31:01.890173 24116 solver.cpp:228] Iteration 3140, loss = 0.136014
I0403 08:31:01.890278 24116 solver.cpp:244]     Train net output #0: loss = 0.136014 (* 1 = 0.136014 loss)
I0403 08:31:02.108906 24116 sgd_solver.cpp:106] Iteration 3140, lr = 0.0005
I0403 08:31:09.185062 24116 solver.cpp:228] Iteration 3150, loss = 0.083222
I0403 08:31:09.185159 24116 solver.cpp:244]     Train net output #0: loss = 0.0832219 (* 1 = 0.0832219 loss)
I0403 08:31:09.367972 24116 sgd_solver.cpp:106] Iteration 3150, lr = 0.0005
I0403 08:31:16.474141 24116 solver.cpp:228] Iteration 3160, loss = 0.0459022
I0403 08:31:16.474441 24116 solver.cpp:244]     Train net output #0: loss = 0.0459021 (* 1 = 0.0459021 loss)
I0403 08:31:16.673852 24116 sgd_solver.cpp:106] Iteration 3160, lr = 0.0005
I0403 08:31:23.815338 24116 solver.cpp:228] Iteration 3170, loss = 0.111226
I0403 08:31:23.815436 24116 solver.cpp:244]     Train net output #0: loss = 0.111226 (* 1 = 0.111226 loss)
I0403 08:31:24.007381 24116 sgd_solver.cpp:106] Iteration 3170, lr = 0.0005
I0403 08:31:31.222905 24116 solver.cpp:228] Iteration 3180, loss = 0.175744
I0403 08:31:31.223009 24116 solver.cpp:244]     Train net output #0: loss = 0.175744 (* 1 = 0.175744 loss)
I0403 08:31:31.426797 24116 sgd_solver.cpp:106] Iteration 3180, lr = 0.0005
I0403 08:31:38.537456 24116 solver.cpp:228] Iteration 3190, loss = 0.112225
I0403 08:31:38.537544 24116 solver.cpp:244]     Train net output #0: loss = 0.112225 (* 1 = 0.112225 loss)
I0403 08:31:38.698772 24116 sgd_solver.cpp:106] Iteration 3190, lr = 0.0005
I0403 08:31:45.948627 24116 solver.cpp:228] Iteration 3200, loss = 0.0745412
I0403 08:31:45.948729 24116 solver.cpp:244]     Train net output #0: loss = 0.0745411 (* 1 = 0.0745411 loss)
I0403 08:31:46.140033 24116 sgd_solver.cpp:106] Iteration 3200, lr = 0.0005
I0403 08:31:53.352435 24116 solver.cpp:228] Iteration 3210, loss = 0.0766504
I0403 08:31:53.352725 24116 solver.cpp:244]     Train net output #0: loss = 0.0766502 (* 1 = 0.0766502 loss)
I0403 08:31:53.572973 24116 sgd_solver.cpp:106] Iteration 3210, lr = 0.0005
I0403 08:32:00.688570 24116 solver.cpp:228] Iteration 3220, loss = 0.0540095
I0403 08:32:00.688658 24116 solver.cpp:244]     Train net output #0: loss = 0.0540094 (* 1 = 0.0540094 loss)
I0403 08:32:00.831331 24116 sgd_solver.cpp:106] Iteration 3220, lr = 0.0005
I0403 08:32:07.962596 24116 solver.cpp:228] Iteration 3230, loss = 0.107375
I0403 08:32:07.962684 24116 solver.cpp:244]     Train net output #0: loss = 0.107375 (* 1 = 0.107375 loss)
I0403 08:32:08.105451 24116 sgd_solver.cpp:106] Iteration 3230, lr = 0.0005
I0403 08:32:15.228732 24116 solver.cpp:228] Iteration 3240, loss = 0.0886734
I0403 08:32:15.228842 24116 solver.cpp:244]     Train net output #0: loss = 0.0886732 (* 1 = 0.0886732 loss)
I0403 08:32:15.463935 24116 sgd_solver.cpp:106] Iteration 3240, lr = 0.0005
I0403 08:32:22.483551 24116 solver.cpp:228] Iteration 3250, loss = 0.124364
I0403 08:32:22.483640 24116 solver.cpp:244]     Train net output #0: loss = 0.124364 (* 1 = 0.124364 loss)
I0403 08:32:22.665066 24116 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 08:32:29.673629 24116 solver.cpp:228] Iteration 3260, loss = 0.0503532
I0403 08:32:29.673954 24116 solver.cpp:244]     Train net output #0: loss = 0.0503531 (* 1 = 0.0503531 loss)
I0403 08:32:29.848018 24116 sgd_solver.cpp:106] Iteration 3260, lr = 0.0005
I0403 08:32:36.976265 24116 solver.cpp:228] Iteration 3270, loss = 0.166708
I0403 08:32:36.976363 24116 solver.cpp:244]     Train net output #0: loss = 0.166708 (* 1 = 0.166708 loss)
I0403 08:32:37.212931 24116 sgd_solver.cpp:106] Iteration 3270, lr = 0.0005
I0403 08:32:44.346547 24116 solver.cpp:228] Iteration 3280, loss = 0.101554
I0403 08:32:44.346645 24116 solver.cpp:244]     Train net output #0: loss = 0.101554 (* 1 = 0.101554 loss)
I0403 08:32:44.549568 24116 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 08:32:47.430707 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3285.caffemodel
I0403 08:32:50.238232 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3285.solverstate
I0403 08:32:52.127903 24116 solver.cpp:337] Iteration 3285, Testing net (#0)
I0403 08:34:04.625330 24116 solver.cpp:404]     Test net output #0: accuracy = 0.903962
I0403 08:34:04.625687 24116 solver.cpp:404]     Test net output #1: loss = 0.320342 (* 1 = 0.320342 loss)
I0403 08:34:08.843226 24116 solver.cpp:228] Iteration 3290, loss = 0.080398
I0403 08:34:08.843322 24116 solver.cpp:244]     Train net output #0: loss = 0.0803979 (* 1 = 0.0803979 loss)
I0403 08:34:09.026216 24116 sgd_solver.cpp:106] Iteration 3290, lr = 0.0005
I0403 08:34:16.094590 24116 solver.cpp:228] Iteration 3300, loss = 0.164675
I0403 08:34:16.094687 24116 solver.cpp:244]     Train net output #0: loss = 0.164675 (* 1 = 0.164675 loss)
I0403 08:34:16.313803 24116 sgd_solver.cpp:106] Iteration 3300, lr = 0.0005
I0403 08:34:23.414155 24116 solver.cpp:228] Iteration 3310, loss = 0.0529196
I0403 08:34:23.414242 24116 solver.cpp:244]     Train net output #0: loss = 0.0529194 (* 1 = 0.0529194 loss)
I0403 08:34:23.584532 24116 sgd_solver.cpp:106] Iteration 3310, lr = 0.0005
I0403 08:34:30.679339 24116 solver.cpp:228] Iteration 3320, loss = 0.127764
I0403 08:34:30.679440 24116 solver.cpp:244]     Train net output #0: loss = 0.127764 (* 1 = 0.127764 loss)
I0403 08:34:30.883251 24116 sgd_solver.cpp:106] Iteration 3320, lr = 0.0005
I0403 08:34:37.914633 24116 solver.cpp:228] Iteration 3330, loss = 0.0872364
I0403 08:34:37.914938 24116 solver.cpp:244]     Train net output #0: loss = 0.0872363 (* 1 = 0.0872363 loss)
I0403 08:34:38.135694 24116 sgd_solver.cpp:106] Iteration 3330, lr = 0.0005
I0403 08:34:45.109192 24116 solver.cpp:228] Iteration 3340, loss = 0.100719
I0403 08:34:45.109293 24116 solver.cpp:244]     Train net output #0: loss = 0.100719 (* 1 = 0.100719 loss)
I0403 08:34:45.294809 24116 sgd_solver.cpp:106] Iteration 3340, lr = 0.0005
I0403 08:34:52.404716 24116 solver.cpp:228] Iteration 3350, loss = 0.107482
I0403 08:34:52.404819 24116 solver.cpp:244]     Train net output #0: loss = 0.107481 (* 1 = 0.107481 loss)
I0403 08:34:52.614361 24116 sgd_solver.cpp:106] Iteration 3350, lr = 0.0005
I0403 08:34:59.860004 24116 solver.cpp:228] Iteration 3360, loss = 0.0864394
I0403 08:34:59.860091 24116 solver.cpp:244]     Train net output #0: loss = 0.0864392 (* 1 = 0.0864392 loss)
I0403 08:35:00.031517 24116 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 08:35:07.114740 24116 solver.cpp:228] Iteration 3370, loss = 0.0606639
I0403 08:35:07.114830 24116 solver.cpp:244]     Train net output #0: loss = 0.0606637 (* 1 = 0.0606637 loss)
I0403 08:35:07.289891 24116 sgd_solver.cpp:106] Iteration 3370, lr = 0.0005
I0403 08:35:14.615171 24116 solver.cpp:228] Iteration 3380, loss = 0.0994953
I0403 08:35:14.615510 24116 solver.cpp:244]     Train net output #0: loss = 0.0994952 (* 1 = 0.0994952 loss)
I0403 08:35:14.800688 24116 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 08:35:21.908119 24116 solver.cpp:228] Iteration 3390, loss = 0.120085
I0403 08:35:21.908218 24116 solver.cpp:244]     Train net output #0: loss = 0.120085 (* 1 = 0.120085 loss)
I0403 08:35:22.101372 24116 sgd_solver.cpp:106] Iteration 3390, lr = 0.0005
I0403 08:35:29.207188 24116 solver.cpp:228] Iteration 3400, loss = 0.0751783
I0403 08:35:29.207275 24116 solver.cpp:244]     Train net output #0: loss = 0.0751782 (* 1 = 0.0751782 loss)
I0403 08:35:29.378736 24116 sgd_solver.cpp:106] Iteration 3400, lr = 0.0005
I0403 08:35:36.491493 24116 solver.cpp:228] Iteration 3410, loss = 0.118814
I0403 08:35:36.491590 24116 solver.cpp:244]     Train net output #0: loss = 0.118814 (* 1 = 0.118814 loss)
I0403 08:35:36.692172 24116 sgd_solver.cpp:106] Iteration 3410, lr = 0.0005
I0403 08:35:43.953274 24116 solver.cpp:228] Iteration 3420, loss = 0.0609246
I0403 08:35:43.953377 24116 solver.cpp:244]     Train net output #0: loss = 0.0609244 (* 1 = 0.0609244 loss)
I0403 08:35:44.139510 24116 sgd_solver.cpp:106] Iteration 3420, lr = 0.0005
I0403 08:35:51.159191 24116 solver.cpp:228] Iteration 3430, loss = 0.0616219
I0403 08:35:51.165751 24116 solver.cpp:244]     Train net output #0: loss = 0.0616218 (* 1 = 0.0616218 loss)
I0403 08:35:51.382925 24116 sgd_solver.cpp:106] Iteration 3430, lr = 0.0005
I0403 08:35:58.454718 24116 solver.cpp:228] Iteration 3440, loss = 0.0300724
I0403 08:35:58.454810 24116 solver.cpp:244]     Train net output #0: loss = 0.0300722 (* 1 = 0.0300722 loss)
I0403 08:35:58.616957 24116 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 08:36:05.925853 24116 solver.cpp:228] Iteration 3450, loss = 0.103163
I0403 08:36:05.925940 24116 solver.cpp:244]     Train net output #0: loss = 0.103163 (* 1 = 0.103163 loss)
I0403 08:36:06.105590 24116 sgd_solver.cpp:106] Iteration 3450, lr = 0.0005
I0403 08:36:13.260778 24116 solver.cpp:228] Iteration 3460, loss = 0.0704094
I0403 08:36:13.260879 24116 solver.cpp:244]     Train net output #0: loss = 0.0704093 (* 1 = 0.0704093 loss)
I0403 08:36:13.496896 24116 sgd_solver.cpp:106] Iteration 3460, lr = 0.0005
I0403 08:36:20.620730 24116 solver.cpp:228] Iteration 3470, loss = 0.125226
I0403 08:36:20.620825 24116 solver.cpp:244]     Train net output #0: loss = 0.125226 (* 1 = 0.125226 loss)
I0403 08:36:20.801293 24116 sgd_solver.cpp:106] Iteration 3470, lr = 0.0005
I0403 08:36:27.803243 24116 solver.cpp:228] Iteration 3480, loss = 0.0680135
I0403 08:36:27.803539 24116 solver.cpp:244]     Train net output #0: loss = 0.0680133 (* 1 = 0.0680133 loss)
I0403 08:36:27.993707 24116 sgd_solver.cpp:106] Iteration 3480, lr = 0.0005
I0403 08:36:35.213615 24116 solver.cpp:228] Iteration 3490, loss = 0.11864
I0403 08:36:35.213716 24116 solver.cpp:244]     Train net output #0: loss = 0.11864 (* 1 = 0.11864 loss)
I0403 08:36:35.429698 24116 sgd_solver.cpp:106] Iteration 3490, lr = 0.0005
I0403 08:36:42.573199 24116 solver.cpp:228] Iteration 3500, loss = 0.114108
I0403 08:36:42.573303 24116 solver.cpp:244]     Train net output #0: loss = 0.114108 (* 1 = 0.114108 loss)
I0403 08:36:42.757158 24116 sgd_solver.cpp:106] Iteration 3500, lr = 0.0005
I0403 08:36:44.916697 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3504.caffemodel
I0403 08:36:47.700865 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3504.solverstate
I0403 08:36:49.582386 24116 solver.cpp:337] Iteration 3504, Testing net (#0)
I0403 08:38:02.094246 24116 solver.cpp:404]     Test net output #0: accuracy = 0.905356
I0403 08:38:02.094570 24116 solver.cpp:404]     Test net output #1: loss = 0.320124 (* 1 = 0.320124 loss)
I0403 08:38:07.187796 24116 solver.cpp:228] Iteration 3510, loss = 0.0326429
I0403 08:38:07.187896 24116 solver.cpp:244]     Train net output #0: loss = 0.0326428 (* 1 = 0.0326428 loss)
I0403 08:38:07.418182 24116 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 08:38:14.494187 24116 solver.cpp:228] Iteration 3520, loss = 0.0634088
I0403 08:38:14.494292 24116 solver.cpp:244]     Train net output #0: loss = 0.0634087 (* 1 = 0.0634087 loss)
I0403 08:38:14.676487 24116 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 08:38:21.936889 24116 solver.cpp:228] Iteration 3530, loss = 0.0523362
I0403 08:38:21.936990 24116 solver.cpp:244]     Train net output #0: loss = 0.0523361 (* 1 = 0.0523361 loss)
I0403 08:38:22.125166 24116 sgd_solver.cpp:106] Iteration 3530, lr = 0.0005
I0403 08:38:29.224597 24116 solver.cpp:228] Iteration 3540, loss = 0.119176
I0403 08:38:29.224684 24116 solver.cpp:244]     Train net output #0: loss = 0.119176 (* 1 = 0.119176 loss)
I0403 08:38:29.403468 24116 sgd_solver.cpp:106] Iteration 3540, lr = 0.0005
I0403 08:38:36.586344 24116 solver.cpp:228] Iteration 3550, loss = 0.0519882
I0403 08:38:36.586650 24116 solver.cpp:244]     Train net output #0: loss = 0.051988 (* 1 = 0.051988 loss)
I0403 08:38:36.792073 24116 sgd_solver.cpp:106] Iteration 3550, lr = 0.0005
I0403 08:38:43.921437 24116 solver.cpp:228] Iteration 3560, loss = 0.139744
I0403 08:38:43.921535 24116 solver.cpp:244]     Train net output #0: loss = 0.139744 (* 1 = 0.139744 loss)
I0403 08:38:44.149679 24116 sgd_solver.cpp:106] Iteration 3560, lr = 0.0005
I0403 08:38:51.314193 24116 solver.cpp:228] Iteration 3570, loss = 0.0709884
I0403 08:38:51.314292 24116 solver.cpp:244]     Train net output #0: loss = 0.0709882 (* 1 = 0.0709882 loss)
I0403 08:38:51.546253 24116 sgd_solver.cpp:106] Iteration 3570, lr = 0.0005
I0403 08:38:58.583149 24116 solver.cpp:228] Iteration 3580, loss = 0.0987262
I0403 08:38:58.583250 24116 solver.cpp:244]     Train net output #0: loss = 0.0987261 (* 1 = 0.0987261 loss)
I0403 08:38:58.794795 24116 sgd_solver.cpp:106] Iteration 3580, lr = 0.0005
I0403 08:39:05.789695 24116 solver.cpp:228] Iteration 3590, loss = 0.0458475
I0403 08:39:05.789795 24116 solver.cpp:244]     Train net output #0: loss = 0.0458474 (* 1 = 0.0458474 loss)
I0403 08:39:05.987802 24116 sgd_solver.cpp:106] Iteration 3590, lr = 0.0005
I0403 08:39:13.067613 24116 solver.cpp:228] Iteration 3600, loss = 0.0426778
I0403 08:39:13.067909 24116 solver.cpp:244]     Train net output #0: loss = 0.0426777 (* 1 = 0.0426777 loss)
I0403 08:39:13.292665 24116 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 08:39:20.384670 24116 solver.cpp:228] Iteration 3610, loss = 0.0786015
I0403 08:39:20.384757 24116 solver.cpp:244]     Train net output #0: loss = 0.0786013 (* 1 = 0.0786013 loss)
I0403 08:39:20.563119 24116 sgd_solver.cpp:106] Iteration 3610, lr = 0.0005
I0403 08:39:27.785800 24116 solver.cpp:228] Iteration 3620, loss = 0.0659569
I0403 08:39:27.785897 24116 solver.cpp:244]     Train net output #0: loss = 0.0659567 (* 1 = 0.0659567 loss)
I0403 08:39:27.979413 24116 sgd_solver.cpp:106] Iteration 3620, lr = 0.0005
I0403 08:39:35.114697 24116 solver.cpp:228] Iteration 3630, loss = 0.141266
I0403 08:39:35.114801 24116 solver.cpp:244]     Train net output #0: loss = 0.141266 (* 1 = 0.141266 loss)
I0403 08:39:35.316289 24116 sgd_solver.cpp:106] Iteration 3630, lr = 0.0005
I0403 08:39:42.585731 24116 solver.cpp:228] Iteration 3640, loss = 0.0850782
I0403 08:39:42.585827 24116 solver.cpp:244]     Train net output #0: loss = 0.085078 (* 1 = 0.085078 loss)
I0403 08:39:42.753109 24116 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 08:39:49.832931 24116 solver.cpp:228] Iteration 3650, loss = 0.124938
I0403 08:39:49.833184 24116 solver.cpp:244]     Train net output #0: loss = 0.124938 (* 1 = 0.124938 loss)
I0403 08:39:50.034314 24116 sgd_solver.cpp:106] Iteration 3650, lr = 0.0005
I0403 08:39:57.056573 24116 solver.cpp:228] Iteration 3660, loss = 0.0646475
I0403 08:39:57.056674 24116 solver.cpp:244]     Train net output #0: loss = 0.0646474 (* 1 = 0.0646474 loss)
I0403 08:39:57.229499 24116 sgd_solver.cpp:106] Iteration 3660, lr = 0.0005
I0403 08:40:04.534910 24116 solver.cpp:228] Iteration 3670, loss = 0.119358
I0403 08:40:04.535004 24116 solver.cpp:244]     Train net output #0: loss = 0.119358 (* 1 = 0.119358 loss)
I0403 08:40:04.721928 24116 sgd_solver.cpp:106] Iteration 3670, lr = 0.0005
I0403 08:40:11.708284 24116 solver.cpp:228] Iteration 3680, loss = 0.0457281
I0403 08:40:11.708384 24116 solver.cpp:244]     Train net output #0: loss = 0.0457279 (* 1 = 0.0457279 loss)
I0403 08:40:11.952668 24116 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 08:40:19.014933 24116 solver.cpp:228] Iteration 3690, loss = 0.154289
I0403 08:40:19.015033 24116 solver.cpp:244]     Train net output #0: loss = 0.154289 (* 1 = 0.154289 loss)
I0403 08:40:19.206670 24116 sgd_solver.cpp:106] Iteration 3690, lr = 0.0005
I0403 08:40:26.256019 24116 solver.cpp:228] Iteration 3700, loss = 0.0894061
I0403 08:40:26.256350 24116 solver.cpp:244]     Train net output #0: loss = 0.0894059 (* 1 = 0.0894059 loss)
I0403 08:40:26.455535 24116 sgd_solver.cpp:106] Iteration 3700, lr = 0.0005
I0403 08:40:33.456468 24116 solver.cpp:228] Iteration 3710, loss = 0.076103
I0403 08:40:33.456568 24116 solver.cpp:244]     Train net output #0: loss = 0.0761028 (* 1 = 0.0761028 loss)
I0403 08:40:33.650183 24116 sgd_solver.cpp:106] Iteration 3710, lr = 0.0005
I0403 08:40:40.703510 24116 solver.cpp:228] Iteration 3720, loss = 0.101086
I0403 08:40:40.703598 24116 solver.cpp:244]     Train net output #0: loss = 0.101086 (* 1 = 0.101086 loss)
I0403 08:40:40.876816 24116 sgd_solver.cpp:106] Iteration 3720, lr = 0.0005
I0403 08:40:42.332794 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3723.caffemodel
I0403 08:40:45.042619 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3723.solverstate
I0403 08:40:46.862025 24116 solver.cpp:337] Iteration 3723, Testing net (#0)
I0403 08:41:59.403460 24116 solver.cpp:404]     Test net output #0: accuracy = 0.903839
I0403 08:41:59.403764 24116 solver.cpp:404]     Test net output #1: loss = 0.329125 (* 1 = 0.329125 loss)
I0403 08:42:04.916908 24116 solver.cpp:228] Iteration 3730, loss = 0.0922139
I0403 08:42:04.917006 24116 solver.cpp:244]     Train net output #0: loss = 0.0922137 (* 1 = 0.0922137 loss)
I0403 08:42:05.132928 24116 sgd_solver.cpp:106] Iteration 3730, lr = 0.0005
I0403 08:42:12.217435 24116 solver.cpp:228] Iteration 3740, loss = 0.0743676
I0403 08:42:12.217535 24116 solver.cpp:244]     Train net output #0: loss = 0.0743674 (* 1 = 0.0743674 loss)
I0403 08:42:12.401648 24116 sgd_solver.cpp:106] Iteration 3740, lr = 0.0005
I0403 08:42:19.521698 24116 solver.cpp:228] Iteration 3750, loss = 0.0605469
I0403 08:42:19.521808 24116 solver.cpp:244]     Train net output #0: loss = 0.0605467 (* 1 = 0.0605467 loss)
I0403 08:42:19.703639 24116 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0403 08:42:26.741981 24116 solver.cpp:228] Iteration 3760, loss = 0.0814193
I0403 08:42:26.742079 24116 solver.cpp:244]     Train net output #0: loss = 0.0814191 (* 1 = 0.0814191 loss)
I0403 08:42:26.945523 24116 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 08:42:34.055661 24116 solver.cpp:228] Iteration 3770, loss = 0.0470063
I0403 08:42:34.055950 24116 solver.cpp:244]     Train net output #0: loss = 0.0470061 (* 1 = 0.0470061 loss)
I0403 08:42:34.235455 24116 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 08:42:41.403409 24116 solver.cpp:228] Iteration 3780, loss = 0.0887281
I0403 08:42:41.403509 24116 solver.cpp:244]     Train net output #0: loss = 0.0887279 (* 1 = 0.0887279 loss)
I0403 08:42:41.586756 24116 sgd_solver.cpp:106] Iteration 3780, lr = 0.0005
I0403 08:42:48.696070 24116 solver.cpp:228] Iteration 3790, loss = 0.110522
I0403 08:42:48.696167 24116 solver.cpp:244]     Train net output #0: loss = 0.110522 (* 1 = 0.110522 loss)
I0403 08:42:48.896684 24116 sgd_solver.cpp:106] Iteration 3790, lr = 0.0005
I0403 08:42:56.047269 24116 solver.cpp:228] Iteration 3800, loss = 0.0927085
I0403 08:42:56.047371 24116 solver.cpp:244]     Train net output #0: loss = 0.0927083 (* 1 = 0.0927083 loss)
I0403 08:42:56.270334 24116 sgd_solver.cpp:106] Iteration 3800, lr = 0.0005
I0403 08:43:03.336458 24116 solver.cpp:228] Iteration 3810, loss = 0.0528551
I0403 08:43:03.336557 24116 solver.cpp:244]     Train net output #0: loss = 0.0528549 (* 1 = 0.0528549 loss)
I0403 08:43:03.549947 24116 sgd_solver.cpp:106] Iteration 3810, lr = 0.0005
I0403 08:43:10.800941 24116 solver.cpp:228] Iteration 3820, loss = 0.133202
I0403 08:43:10.801273 24116 solver.cpp:244]     Train net output #0: loss = 0.133202 (* 1 = 0.133202 loss)
I0403 08:43:11.004945 24116 sgd_solver.cpp:106] Iteration 3820, lr = 0.0005
I0403 08:43:18.113399 24116 solver.cpp:228] Iteration 3830, loss = 0.11684
I0403 08:43:18.113482 24116 solver.cpp:244]     Train net output #0: loss = 0.11684 (* 1 = 0.11684 loss)
I0403 08:43:18.286007 24116 sgd_solver.cpp:106] Iteration 3830, lr = 0.0005
I0403 08:43:25.534950 24116 solver.cpp:228] Iteration 3840, loss = 0.104587
I0403 08:43:25.535049 24116 solver.cpp:244]     Train net output #0: loss = 0.104587 (* 1 = 0.104587 loss)
I0403 08:43:25.722043 24116 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 08:43:32.768177 24116 solver.cpp:228] Iteration 3850, loss = 0.05849
I0403 08:43:32.768272 24116 solver.cpp:244]     Train net output #0: loss = 0.0584898 (* 1 = 0.0584898 loss)
I0403 08:43:32.960420 24116 sgd_solver.cpp:106] Iteration 3850, lr = 0.0005
I0403 08:43:39.995887 24116 solver.cpp:228] Iteration 3860, loss = 0.0509724
I0403 08:43:39.995986 24116 solver.cpp:244]     Train net output #0: loss = 0.0509722 (* 1 = 0.0509722 loss)
I0403 08:43:40.203117 24116 sgd_solver.cpp:106] Iteration 3860, lr = 0.0005
I0403 08:43:47.215538 24116 solver.cpp:228] Iteration 3870, loss = 0.190068
I0403 08:43:47.215845 24116 solver.cpp:244]     Train net output #0: loss = 0.190068 (* 1 = 0.190068 loss)
I0403 08:43:47.399005 24116 sgd_solver.cpp:106] Iteration 3870, lr = 0.0005
I0403 08:43:54.627408 24116 solver.cpp:228] Iteration 3880, loss = 0.0766244
I0403 08:43:54.627504 24116 solver.cpp:244]     Train net output #0: loss = 0.0766242 (* 1 = 0.0766242 loss)
I0403 08:43:54.821529 24116 sgd_solver.cpp:106] Iteration 3880, lr = 0.0005
I0403 08:44:01.861696 24116 solver.cpp:228] Iteration 3890, loss = 0.138792
I0403 08:44:01.861804 24116 solver.cpp:244]     Train net output #0: loss = 0.138792 (* 1 = 0.138792 loss)
I0403 08:44:02.043301 24116 sgd_solver.cpp:106] Iteration 3890, lr = 0.0005
I0403 08:44:09.184942 24116 solver.cpp:228] Iteration 3900, loss = 0.0703018
I0403 08:44:09.185041 24116 solver.cpp:244]     Train net output #0: loss = 0.0703016 (* 1 = 0.0703016 loss)
I0403 08:44:09.375552 24116 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 08:44:16.453229 24116 solver.cpp:228] Iteration 3910, loss = 0.0726345
I0403 08:44:16.453328 24116 solver.cpp:244]     Train net output #0: loss = 0.0726343 (* 1 = 0.0726343 loss)
I0403 08:44:16.619077 24116 sgd_solver.cpp:106] Iteration 3910, lr = 0.0005
I0403 08:44:24.089972 24116 solver.cpp:228] Iteration 3920, loss = 0.0363953
I0403 08:44:24.090267 24116 solver.cpp:244]     Train net output #0: loss = 0.0363951 (* 1 = 0.0363951 loss)
I0403 08:44:24.279878 24116 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 08:44:31.340073 24116 solver.cpp:228] Iteration 3930, loss = 0.0502781
I0403 08:44:31.340162 24116 solver.cpp:244]     Train net output #0: loss = 0.0502779 (* 1 = 0.0502779 loss)
I0403 08:44:31.519521 24116 sgd_solver.cpp:106] Iteration 3930, lr = 0.0005
I0403 08:44:38.600312 24116 solver.cpp:228] Iteration 3940, loss = 0.0990191
I0403 08:44:38.600409 24116 solver.cpp:244]     Train net output #0: loss = 0.0990189 (* 1 = 0.0990189 loss)
I0403 08:44:38.786825 24116 sgd_solver.cpp:106] Iteration 3940, lr = 0.0005
I0403 08:44:39.500491 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3942.caffemodel
I0403 08:44:42.216655 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_3942.solverstate
I0403 08:44:44.115752 24116 solver.cpp:337] Iteration 3942, Testing net (#0)
I0403 08:45:56.639824 24116 solver.cpp:404]     Test net output #0: accuracy = 0.90613
I0403 08:45:56.640143 24116 solver.cpp:404]     Test net output #1: loss = 0.319545 (* 1 = 0.319545 loss)
I0403 08:46:03.039453 24116 solver.cpp:228] Iteration 3950, loss = 0.0784618
I0403 08:46:03.039552 24116 solver.cpp:244]     Train net output #0: loss = 0.0784616 (* 1 = 0.0784616 loss)
I0403 08:46:03.222029 24116 sgd_solver.cpp:106] Iteration 3950, lr = 0.0005
I0403 08:46:10.219257 24116 solver.cpp:228] Iteration 3960, loss = 0.0427094
I0403 08:46:10.219362 24116 solver.cpp:244]     Train net output #0: loss = 0.0427092 (* 1 = 0.0427092 loss)
I0403 08:46:10.466260 24116 sgd_solver.cpp:106] Iteration 3960, lr = 0.0005
I0403 08:46:17.656112 24116 solver.cpp:228] Iteration 3970, loss = 0.0370568
I0403 08:46:17.656213 24116 solver.cpp:244]     Train net output #0: loss = 0.0370566 (* 1 = 0.0370566 loss)
I0403 08:46:17.855583 24116 sgd_solver.cpp:106] Iteration 3970, lr = 0.0005
I0403 08:46:24.915562 24116 solver.cpp:228] Iteration 3980, loss = 0.130057
I0403 08:46:24.915663 24116 solver.cpp:244]     Train net output #0: loss = 0.130057 (* 1 = 0.130057 loss)
I0403 08:46:25.115356 24116 sgd_solver.cpp:106] Iteration 3980, lr = 0.0005
I0403 08:46:32.255575 24116 solver.cpp:228] Iteration 3990, loss = 0.104599
I0403 08:46:32.255884 24116 solver.cpp:244]     Train net output #0: loss = 0.104599 (* 1 = 0.104599 loss)
I0403 08:46:32.449141 24116 sgd_solver.cpp:106] Iteration 3990, lr = 0.0005
I0403 08:46:39.536321 24116 solver.cpp:228] Iteration 4000, loss = 0.0832319
I0403 08:46:39.536420 24116 solver.cpp:244]     Train net output #0: loss = 0.0832317 (* 1 = 0.0832317 loss)
I0403 08:46:39.722731 24116 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 08:46:46.781203 24116 solver.cpp:228] Iteration 4010, loss = 0.175713
I0403 08:46:46.781287 24116 solver.cpp:244]     Train net output #0: loss = 0.175713 (* 1 = 0.175713 loss)
I0403 08:46:46.962952 24116 sgd_solver.cpp:106] Iteration 4010, lr = 0.0005
I0403 08:46:53.992630 24116 solver.cpp:228] Iteration 4020, loss = 0.148091
I0403 08:46:53.992727 24116 solver.cpp:244]     Train net output #0: loss = 0.148091 (* 1 = 0.148091 loss)
I0403 08:46:54.190093 24116 sgd_solver.cpp:106] Iteration 4020, lr = 0.0005
I0403 08:47:01.178508 24116 solver.cpp:228] Iteration 4030, loss = 0.115014
I0403 08:47:01.178603 24116 solver.cpp:244]     Train net output #0: loss = 0.115014 (* 1 = 0.115014 loss)
I0403 08:47:01.362062 24116 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 08:47:08.406296 24116 solver.cpp:228] Iteration 4040, loss = 0.052739
I0403 08:47:08.406587 24116 solver.cpp:244]     Train net output #0: loss = 0.0527388 (* 1 = 0.0527388 loss)
I0403 08:47:08.562171 24116 sgd_solver.cpp:106] Iteration 4040, lr = 0.0005
I0403 08:47:15.801959 24116 solver.cpp:228] Iteration 4050, loss = 0.0619206
I0403 08:47:15.802055 24116 solver.cpp:244]     Train net output #0: loss = 0.0619204 (* 1 = 0.0619204 loss)
I0403 08:47:15.995815 24116 sgd_solver.cpp:106] Iteration 4050, lr = 0.0005
I0403 08:47:23.035598 24116 solver.cpp:228] Iteration 4060, loss = 0.137321
I0403 08:47:23.035686 24116 solver.cpp:244]     Train net output #0: loss = 0.13732 (* 1 = 0.13732 loss)
I0403 08:47:23.193783 24116 sgd_solver.cpp:106] Iteration 4060, lr = 0.0005
I0403 08:47:30.376147 24116 solver.cpp:228] Iteration 4070, loss = 0.014952
I0403 08:47:30.376233 24116 solver.cpp:244]     Train net output #0: loss = 0.0149518 (* 1 = 0.0149518 loss)
I0403 08:47:30.549505 24116 sgd_solver.cpp:106] Iteration 4070, lr = 0.0005
I0403 08:47:37.928613 24116 solver.cpp:228] Iteration 4080, loss = 0.0489682
I0403 08:47:37.928710 24116 solver.cpp:244]     Train net output #0: loss = 0.048968 (* 1 = 0.048968 loss)
I0403 08:47:38.119680 24116 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 08:47:45.460958 24116 solver.cpp:228] Iteration 4090, loss = 0.0484868
I0403 08:47:45.461282 24116 solver.cpp:244]     Train net output #0: loss = 0.0484866 (* 1 = 0.0484866 loss)
I0403 08:47:45.628311 24116 sgd_solver.cpp:106] Iteration 4090, lr = 0.0005
I0403 08:47:52.813158 24116 solver.cpp:228] Iteration 4100, loss = 0.0694486
I0403 08:47:52.813256 24116 solver.cpp:244]     Train net output #0: loss = 0.0694483 (* 1 = 0.0694483 loss)
I0403 08:47:53.009981 24116 sgd_solver.cpp:106] Iteration 4100, lr = 0.0005
I0403 08:48:00.132920 24116 solver.cpp:228] Iteration 4110, loss = 0.115568
I0403 08:48:00.133023 24116 solver.cpp:244]     Train net output #0: loss = 0.115568 (* 1 = 0.115568 loss)
I0403 08:48:00.342572 24116 sgd_solver.cpp:106] Iteration 4110, lr = 0.0005
I0403 08:48:07.364878 24116 solver.cpp:228] Iteration 4120, loss = 0.0603248
I0403 08:48:07.364979 24116 solver.cpp:244]     Train net output #0: loss = 0.0603245 (* 1 = 0.0603245 loss)
I0403 08:48:07.547432 24116 sgd_solver.cpp:106] Iteration 4120, lr = 0.0005
I0403 08:48:14.720532 24116 solver.cpp:228] Iteration 4130, loss = 0.0888651
I0403 08:48:14.720619 24116 solver.cpp:244]     Train net output #0: loss = 0.0888649 (* 1 = 0.0888649 loss)
I0403 08:48:14.886976 24116 sgd_solver.cpp:106] Iteration 4130, lr = 0.0005
I0403 08:48:22.113018 24116 solver.cpp:228] Iteration 4140, loss = 0.127555
I0403 08:48:22.113311 24116 solver.cpp:244]     Train net output #0: loss = 0.127555 (* 1 = 0.127555 loss)
I0403 08:48:22.298820 24116 sgd_solver.cpp:106] Iteration 4140, lr = 0.0005
I0403 08:48:29.433503 24116 solver.cpp:228] Iteration 4150, loss = 0.0320335
I0403 08:48:29.440899 24116 solver.cpp:244]     Train net output #0: loss = 0.0320332 (* 1 = 0.0320332 loss)
I0403 08:48:29.599488 24116 sgd_solver.cpp:106] Iteration 4150, lr = 0.0005
I0403 08:48:36.722488 24116 solver.cpp:228] Iteration 4160, loss = 0.0726781
I0403 08:48:36.722582 24116 solver.cpp:244]     Train net output #0: loss = 0.0726779 (* 1 = 0.0726779 loss)
I0403 08:48:36.944835 24116 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 08:48:36.945075 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4161.caffemodel
I0403 08:48:39.705101 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4161.solverstate
I0403 08:48:41.587669 24116 solver.cpp:337] Iteration 4161, Testing net (#0)
I0403 08:49:54.117069 24116 solver.cpp:404]     Test net output #0: accuracy = 0.90418
I0403 08:49:54.117336 24116 solver.cpp:404]     Test net output #1: loss = 0.325723 (* 1 = 0.325723 loss)
I0403 08:50:01.149762 24116 solver.cpp:228] Iteration 4170, loss = 0.087899
I0403 08:50:01.149866 24116 solver.cpp:244]     Train net output #0: loss = 0.0878988 (* 1 = 0.0878988 loss)
I0403 08:50:01.364024 24116 sgd_solver.cpp:106] Iteration 4170, lr = 0.0005
I0403 08:50:08.552160 24116 solver.cpp:228] Iteration 4180, loss = 0.0628061
I0403 08:50:08.552258 24116 solver.cpp:244]     Train net output #0: loss = 0.0628059 (* 1 = 0.0628059 loss)
I0403 08:50:08.756135 24116 sgd_solver.cpp:106] Iteration 4180, lr = 0.0005
I0403 08:50:16.111269 24116 solver.cpp:228] Iteration 4190, loss = 0.0820322
I0403 08:50:16.111368 24116 solver.cpp:244]     Train net output #0: loss = 0.082032 (* 1 = 0.082032 loss)
I0403 08:50:16.261744 24116 sgd_solver.cpp:106] Iteration 4190, lr = 0.0005
I0403 08:50:23.718543 24116 solver.cpp:228] Iteration 4200, loss = 0.0792222
I0403 08:50:23.718629 24116 solver.cpp:244]     Train net output #0: loss = 0.079222 (* 1 = 0.079222 loss)
I0403 08:50:23.900233 24116 sgd_solver.cpp:106] Iteration 4200, lr = 0.0005
I0403 08:50:30.917953 24116 solver.cpp:228] Iteration 4210, loss = 0.115851
I0403 08:50:30.918268 24116 solver.cpp:244]     Train net output #0: loss = 0.115851 (* 1 = 0.115851 loss)
I0403 08:50:31.081699 24116 sgd_solver.cpp:106] Iteration 4210, lr = 0.0005
I0403 08:50:38.200752 24116 solver.cpp:228] Iteration 4220, loss = 0.0905176
I0403 08:50:38.200860 24116 solver.cpp:244]     Train net output #0: loss = 0.0905174 (* 1 = 0.0905174 loss)
I0403 08:50:38.402873 24116 sgd_solver.cpp:106] Iteration 4220, lr = 0.0005
I0403 08:50:45.610062 24116 solver.cpp:228] Iteration 4230, loss = 0.0649196
I0403 08:50:45.610147 24116 solver.cpp:244]     Train net output #0: loss = 0.0649194 (* 1 = 0.0649194 loss)
I0403 08:50:45.732190 24116 sgd_solver.cpp:106] Iteration 4230, lr = 0.0005
I0403 08:50:52.935047 24116 solver.cpp:228] Iteration 4240, loss = 0.0636848
I0403 08:50:52.935135 24116 solver.cpp:244]     Train net output #0: loss = 0.0636846 (* 1 = 0.0636846 loss)
I0403 08:50:53.106974 24116 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 08:51:00.133759 24116 solver.cpp:228] Iteration 4250, loss = 0.148531
I0403 08:51:00.133862 24116 solver.cpp:244]     Train net output #0: loss = 0.14853 (* 1 = 0.14853 loss)
I0403 08:51:00.318126 24116 sgd_solver.cpp:106] Iteration 4250, lr = 0.0005
I0403 08:51:07.426664 24116 solver.cpp:228] Iteration 4260, loss = 0.0932919
I0403 08:51:07.426966 24116 solver.cpp:244]     Train net output #0: loss = 0.0932916 (* 1 = 0.0932916 loss)
I0403 08:51:07.617804 24116 sgd_solver.cpp:106] Iteration 4260, lr = 0.0005
I0403 08:51:14.749578 24116 solver.cpp:228] Iteration 4270, loss = 0.0702484
I0403 08:51:14.749676 24116 solver.cpp:244]     Train net output #0: loss = 0.0702481 (* 1 = 0.0702481 loss)
I0403 08:51:14.974740 24116 sgd_solver.cpp:106] Iteration 4270, lr = 0.0005
I0403 08:51:22.165863 24116 solver.cpp:228] Iteration 4280, loss = 0.109145
I0403 08:51:22.165966 24116 solver.cpp:244]     Train net output #0: loss = 0.109145 (* 1 = 0.109145 loss)
I0403 08:51:22.407409 24116 sgd_solver.cpp:106] Iteration 4280, lr = 0.0005
I0403 08:51:29.424670 24116 solver.cpp:228] Iteration 4290, loss = 0.0729033
I0403 08:51:29.424772 24116 solver.cpp:244]     Train net output #0: loss = 0.0729031 (* 1 = 0.0729031 loss)
I0403 08:51:29.611001 24116 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 08:51:36.797600 24116 solver.cpp:228] Iteration 4300, loss = 0.0708156
I0403 08:51:36.797686 24116 solver.cpp:244]     Train net output #0: loss = 0.0708154 (* 1 = 0.0708154 loss)
I0403 08:51:36.977797 24116 sgd_solver.cpp:106] Iteration 4300, lr = 0.0005
I0403 08:51:44.104605 24116 solver.cpp:228] Iteration 4310, loss = 0.0394555
I0403 08:51:44.104897 24116 solver.cpp:244]     Train net output #0: loss = 0.0394553 (* 1 = 0.0394553 loss)
I0403 08:51:44.276705 24116 sgd_solver.cpp:106] Iteration 4310, lr = 0.0005
I0403 08:51:51.458920 24116 solver.cpp:228] Iteration 4320, loss = 0.075129
I0403 08:51:51.459020 24116 solver.cpp:244]     Train net output #0: loss = 0.0751288 (* 1 = 0.0751288 loss)
I0403 08:51:51.645617 24116 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 08:51:58.790032 24116 solver.cpp:228] Iteration 4330, loss = 0.0430414
I0403 08:51:58.790118 24116 solver.cpp:244]     Train net output #0: loss = 0.0430412 (* 1 = 0.0430412 loss)
I0403 08:51:58.957870 24116 sgd_solver.cpp:106] Iteration 4330, lr = 0.0005
I0403 08:52:06.008198 24116 solver.cpp:228] Iteration 4340, loss = 0.0844221
I0403 08:52:06.008297 24116 solver.cpp:244]     Train net output #0: loss = 0.0844219 (* 1 = 0.0844219 loss)
I0403 08:52:06.258853 24116 sgd_solver.cpp:106] Iteration 4340, lr = 0.0005
I0403 08:52:13.308550 24116 solver.cpp:228] Iteration 4350, loss = 0.0899543
I0403 08:52:13.308651 24116 solver.cpp:244]     Train net output #0: loss = 0.0899541 (* 1 = 0.0899541 loss)
I0403 08:52:13.524382 24116 sgd_solver.cpp:106] Iteration 4350, lr = 0.0005
I0403 08:52:20.566138 24116 solver.cpp:228] Iteration 4360, loss = 0.120758
I0403 08:52:20.566464 24116 solver.cpp:244]     Train net output #0: loss = 0.120758 (* 1 = 0.120758 loss)
I0403 08:52:20.748065 24116 sgd_solver.cpp:106] Iteration 4360, lr = 0.0005
I0403 08:52:27.925367 24116 solver.cpp:228] Iteration 4370, loss = 0.0413524
I0403 08:52:27.925452 24116 solver.cpp:244]     Train net output #0: loss = 0.0413522 (* 1 = 0.0413522 loss)
I0403 08:52:28.105909 24116 sgd_solver.cpp:106] Iteration 4370, lr = 0.0005
I0403 08:52:34.742038 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4380.caffemodel
I0403 08:52:37.512104 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4380.solverstate
I0403 08:52:39.407012 24116 solver.cpp:337] Iteration 4380, Testing net (#0)
I0403 08:53:51.919469 24116 solver.cpp:404]     Test net output #0: accuracy = 0.906842
I0403 08:53:51.919752 24116 solver.cpp:404]     Test net output #1: loss = 0.326491 (* 1 = 0.326491 loss)
I0403 08:53:52.460649 24116 solver.cpp:228] Iteration 4380, loss = 0.107577
I0403 08:53:52.460731 24116 solver.cpp:244]     Train net output #0: loss = 0.107577 (* 1 = 0.107577 loss)
I0403 08:53:52.615903 24116 sgd_solver.cpp:106] Iteration 4380, lr = 0.0005
I0403 08:53:59.878080 24116 solver.cpp:228] Iteration 4390, loss = 0.0828819
I0403 08:53:59.878167 24116 solver.cpp:244]     Train net output #0: loss = 0.0828817 (* 1 = 0.0828817 loss)
I0403 08:54:00.025215 24116 sgd_solver.cpp:106] Iteration 4390, lr = 0.0005
I0403 08:54:07.095154 24116 solver.cpp:228] Iteration 4400, loss = 0.0713231
I0403 08:54:07.095255 24116 solver.cpp:244]     Train net output #0: loss = 0.0713229 (* 1 = 0.0713229 loss)
I0403 08:54:07.320638 24116 sgd_solver.cpp:106] Iteration 4400, lr = 5e-05
I0403 08:54:14.367050 24116 solver.cpp:228] Iteration 4410, loss = 0.0134951
I0403 08:54:14.367152 24116 solver.cpp:244]     Train net output #0: loss = 0.0134949 (* 1 = 0.0134949 loss)
I0403 08:54:14.567901 24116 sgd_solver.cpp:106] Iteration 4410, lr = 5e-05
I0403 08:54:21.619395 24116 solver.cpp:228] Iteration 4420, loss = 0.0588261
I0403 08:54:21.619493 24116 solver.cpp:244]     Train net output #0: loss = 0.0588259 (* 1 = 0.0588259 loss)
I0403 08:54:21.809928 24116 sgd_solver.cpp:106] Iteration 4420, lr = 5e-05
I0403 08:54:28.985942 24116 solver.cpp:228] Iteration 4430, loss = 0.0596118
I0403 08:54:28.986241 24116 solver.cpp:244]     Train net output #0: loss = 0.0596116 (* 1 = 0.0596116 loss)
I0403 08:54:29.201140 24116 sgd_solver.cpp:106] Iteration 4430, lr = 5e-05
I0403 08:54:36.241874 24116 solver.cpp:228] Iteration 4440, loss = 0.0767749
I0403 08:54:36.241973 24116 solver.cpp:244]     Train net output #0: loss = 0.0767747 (* 1 = 0.0767747 loss)
I0403 08:54:36.432741 24116 sgd_solver.cpp:106] Iteration 4440, lr = 5e-05
I0403 08:54:43.444222 24116 solver.cpp:228] Iteration 4450, loss = 0.0537505
I0403 08:54:43.444324 24116 solver.cpp:244]     Train net output #0: loss = 0.0537503 (* 1 = 0.0537503 loss)
I0403 08:54:43.627614 24116 sgd_solver.cpp:106] Iteration 4450, lr = 5e-05
I0403 08:54:50.670644 24116 solver.cpp:228] Iteration 4460, loss = 0.0961618
I0403 08:54:50.670742 24116 solver.cpp:244]     Train net output #0: loss = 0.0961616 (* 1 = 0.0961616 loss)
I0403 08:54:50.874322 24116 sgd_solver.cpp:106] Iteration 4460, lr = 5e-05
I0403 08:54:57.865911 24116 solver.cpp:228] Iteration 4470, loss = 0.0744979
I0403 08:54:57.866008 24116 solver.cpp:244]     Train net output #0: loss = 0.0744977 (* 1 = 0.0744977 loss)
I0403 08:54:58.049909 24116 sgd_solver.cpp:106] Iteration 4470, lr = 5e-05
I0403 08:55:05.092691 24116 solver.cpp:228] Iteration 4480, loss = 0.0170115
I0403 08:55:05.092996 24116 solver.cpp:244]     Train net output #0: loss = 0.0170113 (* 1 = 0.0170113 loss)
I0403 08:55:05.290470 24116 sgd_solver.cpp:106] Iteration 4480, lr = 5e-05
I0403 08:55:12.527436 24116 solver.cpp:228] Iteration 4490, loss = 0.048318
I0403 08:55:12.527524 24116 solver.cpp:244]     Train net output #0: loss = 0.0483178 (* 1 = 0.0483178 loss)
I0403 08:55:12.708384 24116 sgd_solver.cpp:106] Iteration 4490, lr = 5e-05
I0403 08:55:19.815762 24116 solver.cpp:228] Iteration 4500, loss = 0.0544775
I0403 08:55:19.815851 24116 solver.cpp:244]     Train net output #0: loss = 0.0544773 (* 1 = 0.0544773 loss)
I0403 08:55:19.998612 24116 sgd_solver.cpp:106] Iteration 4500, lr = 5e-05
I0403 08:55:27.178023 24116 solver.cpp:228] Iteration 4510, loss = 0.101352
I0403 08:55:27.178112 24116 solver.cpp:244]     Train net output #0: loss = 0.101352 (* 1 = 0.101352 loss)
I0403 08:55:27.359998 24116 sgd_solver.cpp:106] Iteration 4510, lr = 5e-05
I0403 08:55:34.418329 24116 solver.cpp:228] Iteration 4520, loss = 0.0612319
I0403 08:55:34.418431 24116 solver.cpp:244]     Train net output #0: loss = 0.0612317 (* 1 = 0.0612317 loss)
I0403 08:55:34.604321 24116 sgd_solver.cpp:106] Iteration 4520, lr = 5e-05
I0403 08:55:41.695647 24116 solver.cpp:228] Iteration 4530, loss = 0.113349
I0403 08:55:41.695961 24116 solver.cpp:244]     Train net output #0: loss = 0.113349 (* 1 = 0.113349 loss)
I0403 08:55:41.903683 24116 sgd_solver.cpp:106] Iteration 4530, lr = 5e-05
I0403 08:55:49.046736 24116 solver.cpp:228] Iteration 4540, loss = 0.0474757
I0403 08:55:49.046840 24116 solver.cpp:244]     Train net output #0: loss = 0.0474755 (* 1 = 0.0474755 loss)
I0403 08:55:49.275895 24116 sgd_solver.cpp:106] Iteration 4540, lr = 5e-05
I0403 08:55:56.266962 24116 solver.cpp:228] Iteration 4550, loss = 0.107693
I0403 08:55:56.267058 24116 solver.cpp:244]     Train net output #0: loss = 0.107693 (* 1 = 0.107693 loss)
I0403 08:55:56.449432 24116 sgd_solver.cpp:106] Iteration 4550, lr = 5e-05
I0403 08:56:03.633389 24116 solver.cpp:228] Iteration 4560, loss = 0.0370752
I0403 08:56:03.633477 24116 solver.cpp:244]     Train net output #0: loss = 0.0370749 (* 1 = 0.0370749 loss)
I0403 08:56:03.802034 24116 sgd_solver.cpp:106] Iteration 4560, lr = 5e-05
I0403 08:56:10.983973 24116 solver.cpp:228] Iteration 4570, loss = 0.0842198
I0403 08:56:10.984069 24116 solver.cpp:244]     Train net output #0: loss = 0.0842196 (* 1 = 0.0842196 loss)
I0403 08:56:11.137822 24116 sgd_solver.cpp:106] Iteration 4570, lr = 5e-05
I0403 08:56:18.240828 24116 solver.cpp:228] Iteration 4580, loss = 0.0951445
I0403 08:56:18.241065 24116 solver.cpp:244]     Train net output #0: loss = 0.0951443 (* 1 = 0.0951443 loss)
I0403 08:56:18.373682 24116 sgd_solver.cpp:106] Iteration 4580, lr = 5e-05
I0403 08:56:25.567420 24116 solver.cpp:228] Iteration 4590, loss = 0.0408265
I0403 08:56:25.567518 24116 solver.cpp:244]     Train net output #0: loss = 0.0408263 (* 1 = 0.0408263 loss)
I0403 08:56:25.756458 24116 sgd_solver.cpp:106] Iteration 4590, lr = 5e-05
I0403 08:56:31.568691 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4599.caffemodel
I0403 08:56:34.307142 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4599.solverstate
I0403 08:56:36.132552 24116 solver.cpp:337] Iteration 4599, Testing net (#0)
I0403 08:57:48.628502 24116 solver.cpp:404]     Test net output #0: accuracy = 0.909597
I0403 08:57:48.628808 24116 solver.cpp:404]     Test net output #1: loss = 0.3173 (* 1 = 0.3173 loss)
I0403 08:57:49.857950 24116 solver.cpp:228] Iteration 4600, loss = 0.0588022
I0403 08:57:49.858042 24116 solver.cpp:244]     Train net output #0: loss = 0.058802 (* 1 = 0.058802 loss)
I0403 08:57:50.047274 24116 sgd_solver.cpp:106] Iteration 4600, lr = 5e-05
I0403 08:57:57.130762 24116 solver.cpp:228] Iteration 4610, loss = 0.0509113
I0403 08:57:57.130862 24116 solver.cpp:244]     Train net output #0: loss = 0.0509111 (* 1 = 0.0509111 loss)
I0403 08:57:57.320508 24116 sgd_solver.cpp:106] Iteration 4610, lr = 5e-05
I0403 08:58:04.519141 24116 solver.cpp:228] Iteration 4620, loss = 0.06155
I0403 08:58:04.519240 24116 solver.cpp:244]     Train net output #0: loss = 0.0615497 (* 1 = 0.0615497 loss)
I0403 08:58:04.723629 24116 sgd_solver.cpp:106] Iteration 4620, lr = 5e-05
I0403 08:58:11.709262 24116 solver.cpp:228] Iteration 4630, loss = 0.11892
I0403 08:58:11.709362 24116 solver.cpp:244]     Train net output #0: loss = 0.11892 (* 1 = 0.11892 loss)
I0403 08:58:11.909296 24116 sgd_solver.cpp:106] Iteration 4630, lr = 5e-05
I0403 08:58:18.960716 24116 solver.cpp:228] Iteration 4640, loss = 0.0793765
I0403 08:58:18.961027 24116 solver.cpp:244]     Train net output #0: loss = 0.0793763 (* 1 = 0.0793763 loss)
I0403 08:58:19.158946 24116 sgd_solver.cpp:106] Iteration 4640, lr = 5e-05
I0403 08:58:26.217136 24116 solver.cpp:228] Iteration 4650, loss = 0.0374114
I0403 08:58:26.217237 24116 solver.cpp:244]     Train net output #0: loss = 0.0374112 (* 1 = 0.0374112 loss)
I0403 08:58:26.400286 24116 sgd_solver.cpp:106] Iteration 4650, lr = 5e-05
I0403 08:58:33.492331 24116 solver.cpp:228] Iteration 4660, loss = 0.0741886
I0403 08:58:33.492431 24116 solver.cpp:244]     Train net output #0: loss = 0.0741884 (* 1 = 0.0741884 loss)
I0403 08:58:33.701167 24116 sgd_solver.cpp:106] Iteration 4660, lr = 5e-05
I0403 08:58:40.800289 24116 solver.cpp:228] Iteration 4670, loss = 0.022725
I0403 08:58:40.800379 24116 solver.cpp:244]     Train net output #0: loss = 0.0227248 (* 1 = 0.0227248 loss)
I0403 08:58:40.979140 24116 sgd_solver.cpp:106] Iteration 4670, lr = 5e-05
I0403 08:58:47.997759 24116 solver.cpp:228] Iteration 4680, loss = 0.0278614
I0403 08:58:47.997859 24116 solver.cpp:244]     Train net output #0: loss = 0.0278612 (* 1 = 0.0278612 loss)
I0403 08:58:48.221722 24116 sgd_solver.cpp:106] Iteration 4680, lr = 5e-05
I0403 08:58:55.307694 24116 solver.cpp:228] Iteration 4690, loss = 0.0523894
I0403 08:58:55.308007 24116 solver.cpp:244]     Train net output #0: loss = 0.0523892 (* 1 = 0.0523892 loss)
I0403 08:58:55.490718 24116 sgd_solver.cpp:106] Iteration 4690, lr = 5e-05
I0403 08:59:02.561975 24116 solver.cpp:228] Iteration 4700, loss = 0.0573315
I0403 08:59:02.562060 24116 solver.cpp:244]     Train net output #0: loss = 0.0573313 (* 1 = 0.0573313 loss)
I0403 08:59:02.737114 24116 sgd_solver.cpp:106] Iteration 4700, lr = 5e-05
I0403 08:59:09.903522 24116 solver.cpp:228] Iteration 4710, loss = 0.0438205
I0403 08:59:09.903616 24116 solver.cpp:244]     Train net output #0: loss = 0.0438203 (* 1 = 0.0438203 loss)
I0403 08:59:10.104818 24116 sgd_solver.cpp:106] Iteration 4710, lr = 5e-05
I0403 08:59:17.207350 24116 solver.cpp:228] Iteration 4720, loss = 0.0792324
I0403 08:59:17.207443 24116 solver.cpp:244]     Train net output #0: loss = 0.0792322 (* 1 = 0.0792322 loss)
I0403 08:59:17.387776 24116 sgd_solver.cpp:106] Iteration 4720, lr = 5e-05
I0403 08:59:24.563102 24116 solver.cpp:228] Iteration 4730, loss = 0.104124
I0403 08:59:24.563185 24116 solver.cpp:244]     Train net output #0: loss = 0.104124 (* 1 = 0.104124 loss)
I0403 08:59:24.727393 24116 sgd_solver.cpp:106] Iteration 4730, lr = 5e-05
I0403 08:59:32.003087 24116 solver.cpp:228] Iteration 4740, loss = 0.0336923
I0403 08:59:32.003373 24116 solver.cpp:244]     Train net output #0: loss = 0.0336921 (* 1 = 0.0336921 loss)
I0403 08:59:32.231356 24116 sgd_solver.cpp:106] Iteration 4740, lr = 5e-05
I0403 08:59:39.255031 24116 solver.cpp:228] Iteration 4750, loss = 0.103393
I0403 08:59:39.255131 24116 solver.cpp:244]     Train net output #0: loss = 0.103392 (* 1 = 0.103392 loss)
I0403 08:59:39.465896 24116 sgd_solver.cpp:106] Iteration 4750, lr = 5e-05
I0403 08:59:46.560910 24116 solver.cpp:228] Iteration 4760, loss = 0.0465102
I0403 08:59:46.561008 24116 solver.cpp:244]     Train net output #0: loss = 0.04651 (* 1 = 0.04651 loss)
I0403 08:59:46.751781 24116 sgd_solver.cpp:106] Iteration 4760, lr = 5e-05
I0403 08:59:53.813570 24116 solver.cpp:228] Iteration 4770, loss = 0.0729678
I0403 08:59:53.813657 24116 solver.cpp:244]     Train net output #0: loss = 0.0729676 (* 1 = 0.0729676 loss)
I0403 08:59:53.989586 24116 sgd_solver.cpp:106] Iteration 4770, lr = 5e-05
I0403 09:00:01.124163 24116 solver.cpp:228] Iteration 4780, loss = 0.0259592
I0403 09:00:01.124251 24116 solver.cpp:244]     Train net output #0: loss = 0.025959 (* 1 = 0.025959 loss)
I0403 09:00:01.305737 24116 sgd_solver.cpp:106] Iteration 4780, lr = 5e-05
I0403 09:00:08.336899 24116 solver.cpp:228] Iteration 4790, loss = 0.141555
I0403 09:00:08.337213 24116 solver.cpp:244]     Train net output #0: loss = 0.141555 (* 1 = 0.141555 loss)
I0403 09:00:08.522161 24116 sgd_solver.cpp:106] Iteration 4790, lr = 5e-05
I0403 09:00:15.643975 24116 solver.cpp:228] Iteration 4800, loss = 0.0676799
I0403 09:00:15.644088 24116 solver.cpp:244]     Train net output #0: loss = 0.0676797 (* 1 = 0.0676797 loss)
I0403 09:00:15.857790 24116 sgd_solver.cpp:106] Iteration 4800, lr = 5e-05
I0403 09:00:22.991421 24116 solver.cpp:228] Iteration 4810, loss = 0.0865313
I0403 09:00:22.991508 24116 solver.cpp:244]     Train net output #0: loss = 0.0865311 (* 1 = 0.0865311 loss)
I0403 09:00:23.168848 24116 sgd_solver.cpp:106] Iteration 4810, lr = 5e-05
I0403 09:00:28.240515 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4818.caffemodel
I0403 09:00:30.992602 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_4818.solverstate
I0403 09:00:32.886831 24116 solver.cpp:337] Iteration 4818, Testing net (#0)
I0403 09:01:45.396452 24116 solver.cpp:404]     Test net output #0: accuracy = 0.910309
I0403 09:01:45.396755 24116 solver.cpp:404]     Test net output #1: loss = 0.316996 (* 1 = 0.316996 loss)
I0403 09:01:47.455198 24116 solver.cpp:228] Iteration 4820, loss = 0.0478931
I0403 09:01:47.455293 24116 solver.cpp:244]     Train net output #0: loss = 0.0478929 (* 1 = 0.0478929 loss)
I0403 09:01:47.650550 24116 sgd_solver.cpp:106] Iteration 4820, lr = 5e-05
I0403 09:01:54.711037 24116 solver.cpp:228] Iteration 4830, loss = 0.0506009
I0403 09:01:54.711132 24116 solver.cpp:244]     Train net output #0: loss = 0.0506007 (* 1 = 0.0506007 loss)
I0403 09:01:54.897696 24116 sgd_solver.cpp:106] Iteration 4830, lr = 5e-05
I0403 09:02:02.161905 24116 solver.cpp:228] Iteration 4840, loss = 0.0469686
I0403 09:02:02.161991 24116 solver.cpp:244]     Train net output #0: loss = 0.0469684 (* 1 = 0.0469684 loss)
I0403 09:02:02.338160 24116 sgd_solver.cpp:106] Iteration 4840, lr = 5e-05
I0403 09:02:09.412410 24116 solver.cpp:228] Iteration 4850, loss = 0.0468137
I0403 09:02:09.412533 24116 solver.cpp:244]     Train net output #0: loss = 0.0468135 (* 1 = 0.0468135 loss)
I0403 09:02:09.668375 24116 sgd_solver.cpp:106] Iteration 4850, lr = 5e-05
I0403 09:02:16.832983 24116 solver.cpp:228] Iteration 4860, loss = 0.0916813
I0403 09:02:16.836933 24116 solver.cpp:244]     Train net output #0: loss = 0.0916811 (* 1 = 0.0916811 loss)
I0403 09:02:17.063175 24116 sgd_solver.cpp:106] Iteration 4860, lr = 5e-05
I0403 09:02:24.131582 24116 solver.cpp:228] Iteration 4870, loss = 0.114855
I0403 09:02:24.131675 24116 solver.cpp:244]     Train net output #0: loss = 0.114855 (* 1 = 0.114855 loss)
I0403 09:02:24.329819 24116 sgd_solver.cpp:106] Iteration 4870, lr = 5e-05
I0403 09:02:31.474485 24116 solver.cpp:228] Iteration 4880, loss = 0.0310711
I0403 09:02:31.474572 24116 solver.cpp:244]     Train net output #0: loss = 0.0310709 (* 1 = 0.0310709 loss)
I0403 09:02:31.653151 24116 sgd_solver.cpp:106] Iteration 4880, lr = 5e-05
I0403 09:02:38.791892 24116 solver.cpp:228] Iteration 4890, loss = 0.0216425
I0403 09:02:38.791991 24116 solver.cpp:244]     Train net output #0: loss = 0.0216423 (* 1 = 0.0216423 loss)
I0403 09:02:39.017829 24116 sgd_solver.cpp:106] Iteration 4890, lr = 5e-05
I0403 09:02:46.166440 24116 solver.cpp:228] Iteration 4900, loss = 0.0756665
I0403 09:02:46.166538 24116 solver.cpp:244]     Train net output #0: loss = 0.0756663 (* 1 = 0.0756663 loss)
I0403 09:02:46.360435 24116 sgd_solver.cpp:106] Iteration 4900, lr = 5e-05
I0403 09:02:53.373309 24116 solver.cpp:228] Iteration 4910, loss = 0.0566293
I0403 09:02:53.373641 24116 solver.cpp:244]     Train net output #0: loss = 0.0566291 (* 1 = 0.0566291 loss)
I0403 09:02:53.556133 24116 sgd_solver.cpp:106] Iteration 4910, lr = 5e-05
I0403 09:03:00.585373 24116 solver.cpp:228] Iteration 4920, loss = 0.0663471
I0403 09:03:00.585472 24116 solver.cpp:244]     Train net output #0: loss = 0.0663469 (* 1 = 0.0663469 loss)
I0403 09:03:00.794977 24116 sgd_solver.cpp:106] Iteration 4920, lr = 5e-05
I0403 09:03:07.814826 24116 solver.cpp:228] Iteration 4930, loss = 0.146284
I0403 09:03:07.814924 24116 solver.cpp:244]     Train net output #0: loss = 0.146284 (* 1 = 0.146284 loss)
I0403 09:03:08.006904 24116 sgd_solver.cpp:106] Iteration 4930, lr = 5e-05
I0403 09:03:15.087882 24116 solver.cpp:228] Iteration 4940, loss = 0.141028
I0403 09:03:15.087980 24116 solver.cpp:244]     Train net output #0: loss = 0.141028 (* 1 = 0.141028 loss)
I0403 09:03:15.277941 24116 sgd_solver.cpp:106] Iteration 4940, lr = 5e-05
I0403 09:03:22.268798 24116 solver.cpp:228] Iteration 4950, loss = 0.119153
I0403 09:03:22.268895 24116 solver.cpp:244]     Train net output #0: loss = 0.119153 (* 1 = 0.119153 loss)
I0403 09:03:22.466473 24116 sgd_solver.cpp:106] Iteration 4950, lr = 5e-05
I0403 09:03:29.738936 24116 solver.cpp:228] Iteration 4960, loss = 0.0533509
I0403 09:03:29.739243 24116 solver.cpp:244]     Train net output #0: loss = 0.0533507 (* 1 = 0.0533507 loss)
I0403 09:03:29.992705 24116 sgd_solver.cpp:106] Iteration 4960, lr = 5e-05
I0403 09:03:36.997071 24116 solver.cpp:228] Iteration 4970, loss = 0.0901055
I0403 09:03:36.997167 24116 solver.cpp:244]     Train net output #0: loss = 0.0901053 (* 1 = 0.0901053 loss)
I0403 09:03:37.196894 24116 sgd_solver.cpp:106] Iteration 4970, lr = 5e-05
I0403 09:03:44.338338 24116 solver.cpp:228] Iteration 4980, loss = 0.0355841
I0403 09:03:44.338435 24116 solver.cpp:244]     Train net output #0: loss = 0.0355839 (* 1 = 0.0355839 loss)
I0403 09:03:44.532791 24116 sgd_solver.cpp:106] Iteration 4980, lr = 5e-05
I0403 09:03:51.737273 24116 solver.cpp:228] Iteration 4990, loss = 0.0434787
I0403 09:03:51.737370 24116 solver.cpp:244]     Train net output #0: loss = 0.0434785 (* 1 = 0.0434785 loss)
I0403 09:03:51.949460 24116 sgd_solver.cpp:106] Iteration 4990, lr = 5e-05
I0403 09:03:59.058214 24116 solver.cpp:228] Iteration 5000, loss = 0.0697442
I0403 09:03:59.058311 24116 solver.cpp:244]     Train net output #0: loss = 0.0697439 (* 1 = 0.0697439 loss)
I0403 09:03:59.203770 24116 sgd_solver.cpp:106] Iteration 5000, lr = 5e-05
I0403 09:04:06.420835 24116 solver.cpp:228] Iteration 5010, loss = 0.0584521
I0403 09:04:06.421121 24116 solver.cpp:244]     Train net output #0: loss = 0.0584519 (* 1 = 0.0584519 loss)
I0403 09:04:06.600657 24116 sgd_solver.cpp:106] Iteration 5010, lr = 5e-05
I0403 09:04:13.769553 24116 solver.cpp:228] Iteration 5020, loss = 0.0521819
I0403 09:04:13.769641 24116 solver.cpp:244]     Train net output #0: loss = 0.0521817 (* 1 = 0.0521817 loss)
I0403 09:04:13.951198 24116 sgd_solver.cpp:106] Iteration 5020, lr = 5e-05
I0403 09:04:21.200115 24116 solver.cpp:228] Iteration 5030, loss = 0.0716116
I0403 09:04:21.200201 24116 solver.cpp:244]     Train net output #0: loss = 0.0716114 (* 1 = 0.0716114 loss)
I0403 09:04:21.380094 24116 sgd_solver.cpp:106] Iteration 5030, lr = 5e-05
I0403 09:04:25.912494 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5037.caffemodel
I0403 09:04:28.673914 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5037.solverstate
I0403 09:04:30.570428 24116 solver.cpp:337] Iteration 5037, Testing net (#0)
I0403 09:05:43.073540 24116 solver.cpp:404]     Test net output #0: accuracy = 0.909721
I0403 09:05:43.073781 24116 solver.cpp:404]     Test net output #1: loss = 0.316592 (* 1 = 0.316592 loss)
I0403 09:05:45.837803 24116 solver.cpp:228] Iteration 5040, loss = 0.0401079
I0403 09:05:45.837898 24116 solver.cpp:244]     Train net output #0: loss = 0.0401077 (* 1 = 0.0401077 loss)
I0403 09:05:46.022183 24116 sgd_solver.cpp:106] Iteration 5040, lr = 5e-05
I0403 09:05:53.076635 24116 solver.cpp:228] Iteration 5050, loss = 0.0370515
I0403 09:05:53.076735 24116 solver.cpp:244]     Train net output #0: loss = 0.0370513 (* 1 = 0.0370513 loss)
I0403 09:05:53.289697 24116 sgd_solver.cpp:106] Iteration 5050, lr = 5e-05
I0403 09:06:00.261020 24116 solver.cpp:228] Iteration 5060, loss = 0.0564968
I0403 09:06:00.261111 24116 solver.cpp:244]     Train net output #0: loss = 0.0564966 (* 1 = 0.0564966 loss)
I0403 09:06:00.439365 24116 sgd_solver.cpp:106] Iteration 5060, lr = 5e-05
I0403 09:06:07.458897 24116 solver.cpp:228] Iteration 5070, loss = 0.115417
I0403 09:06:07.458997 24116 solver.cpp:244]     Train net output #0: loss = 0.115417 (* 1 = 0.115417 loss)
I0403 09:06:07.642366 24116 sgd_solver.cpp:106] Iteration 5070, lr = 5e-05
I0403 09:06:14.743703 24116 solver.cpp:228] Iteration 5080, loss = 0.0660659
I0403 09:06:14.744021 24116 solver.cpp:244]     Train net output #0: loss = 0.0660657 (* 1 = 0.0660657 loss)
I0403 09:06:14.921069 24116 sgd_solver.cpp:106] Iteration 5080, lr = 5e-05
I0403 09:06:21.979100 24116 solver.cpp:228] Iteration 5090, loss = 0.0687503
I0403 09:06:21.979202 24116 solver.cpp:244]     Train net output #0: loss = 0.0687501 (* 1 = 0.0687501 loss)
I0403 09:06:22.213078 24116 sgd_solver.cpp:106] Iteration 5090, lr = 5e-05
I0403 09:06:29.376734 24116 solver.cpp:228] Iteration 5100, loss = 0.0275706
I0403 09:06:29.376837 24116 solver.cpp:244]     Train net output #0: loss = 0.0275704 (* 1 = 0.0275704 loss)
I0403 09:06:29.569978 24116 sgd_solver.cpp:106] Iteration 5100, lr = 5e-05
I0403 09:06:36.548584 24116 solver.cpp:228] Iteration 5110, loss = 0.0546279
I0403 09:06:36.548683 24116 solver.cpp:244]     Train net output #0: loss = 0.0546276 (* 1 = 0.0546276 loss)
I0403 09:06:36.772869 24116 sgd_solver.cpp:106] Iteration 5110, lr = 5e-05
I0403 09:06:43.859225 24116 solver.cpp:228] Iteration 5120, loss = 0.0460367
I0403 09:06:43.859325 24116 solver.cpp:244]     Train net output #0: loss = 0.0460365 (* 1 = 0.0460365 loss)
I0403 09:06:44.096410 24116 sgd_solver.cpp:106] Iteration 5120, lr = 5e-05
I0403 09:06:51.284252 24116 solver.cpp:228] Iteration 5130, loss = 0.0638705
I0403 09:06:51.284566 24116 solver.cpp:244]     Train net output #0: loss = 0.0638703 (* 1 = 0.0638703 loss)
I0403 09:06:51.522351 24116 sgd_solver.cpp:106] Iteration 5130, lr = 5e-05
I0403 09:06:58.580384 24116 solver.cpp:228] Iteration 5140, loss = 0.137294
I0403 09:06:58.580471 24116 solver.cpp:244]     Train net output #0: loss = 0.137294 (* 1 = 0.137294 loss)
I0403 09:06:58.737773 24116 sgd_solver.cpp:106] Iteration 5140, lr = 5e-05
I0403 09:07:05.815125 24116 solver.cpp:228] Iteration 5150, loss = 0.0774572
I0403 09:07:05.815224 24116 solver.cpp:244]     Train net output #0: loss = 0.077457 (* 1 = 0.077457 loss)
I0403 09:07:06.048259 24116 sgd_solver.cpp:106] Iteration 5150, lr = 5e-05
I0403 09:07:13.131510 24116 solver.cpp:228] Iteration 5160, loss = 0.0539539
I0403 09:07:13.131609 24116 solver.cpp:244]     Train net output #0: loss = 0.0539537 (* 1 = 0.0539537 loss)
I0403 09:07:13.352841 24116 sgd_solver.cpp:106] Iteration 5160, lr = 5e-05
I0403 09:07:20.536604 24116 solver.cpp:228] Iteration 5170, loss = 0.0790437
I0403 09:07:20.536703 24116 solver.cpp:244]     Train net output #0: loss = 0.0790435 (* 1 = 0.0790435 loss)
I0403 09:07:20.739045 24116 sgd_solver.cpp:106] Iteration 5170, lr = 5e-05
I0403 09:07:27.816900 24116 solver.cpp:228] Iteration 5180, loss = 0.0876252
I0403 09:07:27.817193 24116 solver.cpp:244]     Train net output #0: loss = 0.087625 (* 1 = 0.087625 loss)
I0403 09:07:28.007850 24116 sgd_solver.cpp:106] Iteration 5180, lr = 5e-05
I0403 09:07:35.115535 24116 solver.cpp:228] Iteration 5190, loss = 0.0433859
I0403 09:07:35.115635 24116 solver.cpp:244]     Train net output #0: loss = 0.0433857 (* 1 = 0.0433857 loss)
I0403 09:07:35.305620 24116 sgd_solver.cpp:106] Iteration 5190, lr = 5e-05
I0403 09:07:42.363857 24116 solver.cpp:228] Iteration 5200, loss = 0.12015
I0403 09:07:42.363955 24116 solver.cpp:244]     Train net output #0: loss = 0.12015 (* 1 = 0.12015 loss)
I0403 09:07:42.558400 24116 sgd_solver.cpp:106] Iteration 5200, lr = 5e-05
I0403 09:07:49.701701 24116 solver.cpp:228] Iteration 5210, loss = 0.0194635
I0403 09:07:49.701793 24116 solver.cpp:244]     Train net output #0: loss = 0.0194633 (* 1 = 0.0194633 loss)
I0403 09:07:49.879501 24116 sgd_solver.cpp:106] Iteration 5210, lr = 5e-05
I0403 09:07:57.091366 24116 solver.cpp:228] Iteration 5220, loss = 0.118321
I0403 09:07:57.091469 24116 solver.cpp:244]     Train net output #0: loss = 0.118321 (* 1 = 0.118321 loss)
I0403 09:07:57.336464 24116 sgd_solver.cpp:106] Iteration 5220, lr = 5e-05
I0403 09:08:04.398591 24116 solver.cpp:228] Iteration 5230, loss = 0.0262027
I0403 09:08:04.398922 24116 solver.cpp:244]     Train net output #0: loss = 0.0262025 (* 1 = 0.0262025 loss)
I0403 09:08:04.604714 24116 sgd_solver.cpp:106] Iteration 5230, lr = 5e-05
I0403 09:08:11.730345 24116 solver.cpp:228] Iteration 5240, loss = 0.023678
I0403 09:08:11.730428 24116 solver.cpp:244]     Train net output #0: loss = 0.0236778 (* 1 = 0.0236778 loss)
I0403 09:08:11.910081 24116 sgd_solver.cpp:106] Iteration 5240, lr = 5e-05
I0403 09:08:18.916059 24116 solver.cpp:228] Iteration 5250, loss = 0.116021
I0403 09:08:18.916155 24116 solver.cpp:244]     Train net output #0: loss = 0.116021 (* 1 = 0.116021 loss)
I0403 09:08:19.107563 24116 sgd_solver.cpp:106] Iteration 5250, lr = 5e-05
I0403 09:08:22.740353 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5256.caffemodel
I0403 09:08:25.556936 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5256.solverstate
I0403 09:08:27.435353 24116 solver.cpp:337] Iteration 5256, Testing net (#0)
I0403 09:09:39.965719 24116 solver.cpp:404]     Test net output #0: accuracy = 0.909567
I0403 09:09:39.966006 24116 solver.cpp:404]     Test net output #1: loss = 0.317393 (* 1 = 0.317393 loss)
I0403 09:09:43.375134 24116 solver.cpp:228] Iteration 5260, loss = 0.0193036
I0403 09:09:43.375229 24116 solver.cpp:244]     Train net output #0: loss = 0.0193034 (* 1 = 0.0193034 loss)
I0403 09:09:43.571544 24116 sgd_solver.cpp:106] Iteration 5260, lr = 5e-05
I0403 09:09:50.642216 24116 solver.cpp:228] Iteration 5270, loss = 0.041612
I0403 09:09:50.642303 24116 solver.cpp:244]     Train net output #0: loss = 0.0416118 (* 1 = 0.0416118 loss)
I0403 09:09:50.805083 24116 sgd_solver.cpp:106] Iteration 5270, lr = 5e-05
I0403 09:09:57.958205 24116 solver.cpp:228] Iteration 5280, loss = 0.0662924
I0403 09:09:57.958304 24116 solver.cpp:244]     Train net output #0: loss = 0.0662922 (* 1 = 0.0662922 loss)
I0403 09:09:58.163646 24116 sgd_solver.cpp:106] Iteration 5280, lr = 5e-05
I0403 09:10:05.255851 24116 solver.cpp:228] Iteration 5290, loss = 0.0990365
I0403 09:10:05.255949 24116 solver.cpp:244]     Train net output #0: loss = 0.0990363 (* 1 = 0.0990363 loss)
I0403 09:10:05.456583 24116 sgd_solver.cpp:106] Iteration 5290, lr = 5e-05
I0403 09:10:12.520243 24116 solver.cpp:228] Iteration 5300, loss = 0.0341965
I0403 09:10:12.520537 24116 solver.cpp:244]     Train net output #0: loss = 0.0341963 (* 1 = 0.0341963 loss)
I0403 09:10:12.656576 24116 sgd_solver.cpp:106] Iteration 5300, lr = 5e-05
I0403 09:10:19.837225 24116 solver.cpp:228] Iteration 5310, loss = 0.0572573
I0403 09:10:19.837312 24116 solver.cpp:244]     Train net output #0: loss = 0.0572571 (* 1 = 0.0572571 loss)
I0403 09:10:20.011451 24116 sgd_solver.cpp:106] Iteration 5310, lr = 5e-05
I0403 09:10:27.037925 24116 solver.cpp:228] Iteration 5320, loss = 0.139051
I0403 09:10:27.038022 24116 solver.cpp:244]     Train net output #0: loss = 0.139051 (* 1 = 0.139051 loss)
I0403 09:10:27.230720 24116 sgd_solver.cpp:106] Iteration 5320, lr = 5e-05
I0403 09:10:34.265827 24116 solver.cpp:228] Iteration 5330, loss = 0.0245568
I0403 09:10:34.265928 24116 solver.cpp:244]     Train net output #0: loss = 0.0245566 (* 1 = 0.0245566 loss)
I0403 09:10:34.465155 24116 sgd_solver.cpp:106] Iteration 5330, lr = 5e-05
I0403 09:10:41.580884 24116 solver.cpp:228] Iteration 5340, loss = 0.0552721
I0403 09:10:41.580971 24116 solver.cpp:244]     Train net output #0: loss = 0.0552719 (* 1 = 0.0552719 loss)
I0403 09:10:41.753538 24116 sgd_solver.cpp:106] Iteration 5340, lr = 5e-05
I0403 09:10:48.876864 24116 solver.cpp:228] Iteration 5350, loss = 0.129478
I0403 09:10:48.877180 24116 solver.cpp:244]     Train net output #0: loss = 0.129478 (* 1 = 0.129478 loss)
I0403 09:10:49.084022 24116 sgd_solver.cpp:106] Iteration 5350, lr = 5e-05
I0403 09:10:56.237365 24116 solver.cpp:228] Iteration 5360, loss = 0.0720202
I0403 09:10:56.237452 24116 solver.cpp:244]     Train net output #0: loss = 0.0720199 (* 1 = 0.0720199 loss)
I0403 09:10:56.409113 24116 sgd_solver.cpp:106] Iteration 5360, lr = 5e-05
I0403 09:11:03.430865 24116 solver.cpp:228] Iteration 5370, loss = 0.0840677
I0403 09:11:03.430966 24116 solver.cpp:244]     Train net output #0: loss = 0.0840675 (* 1 = 0.0840675 loss)
I0403 09:11:03.626155 24116 sgd_solver.cpp:106] Iteration 5370, lr = 5e-05
I0403 09:11:10.588953 24116 solver.cpp:228] Iteration 5380, loss = 0.113417
I0403 09:11:10.589056 24116 solver.cpp:244]     Train net output #0: loss = 0.113417 (* 1 = 0.113417 loss)
I0403 09:11:10.802218 24116 sgd_solver.cpp:106] Iteration 5380, lr = 5e-05
I0403 09:11:17.908463 24116 solver.cpp:228] Iteration 5390, loss = 0.0966035
I0403 09:11:17.908558 24116 solver.cpp:244]     Train net output #0: loss = 0.0966033 (* 1 = 0.0966033 loss)
I0403 09:11:18.112179 24116 sgd_solver.cpp:106] Iteration 5390, lr = 5e-05
I0403 09:11:25.365916 24116 solver.cpp:228] Iteration 5400, loss = 0.0455997
I0403 09:11:25.366205 24116 solver.cpp:244]     Train net output #0: loss = 0.0455994 (* 1 = 0.0455994 loss)
I0403 09:11:25.567145 24116 sgd_solver.cpp:106] Iteration 5400, lr = 5e-05
I0403 09:11:32.750002 24116 solver.cpp:228] Iteration 5410, loss = 0.073971
I0403 09:11:32.750089 24116 solver.cpp:244]     Train net output #0: loss = 0.0739708 (* 1 = 0.0739708 loss)
I0403 09:11:32.930577 24116 sgd_solver.cpp:106] Iteration 5410, lr = 5e-05
I0403 09:11:40.016419 24116 solver.cpp:228] Iteration 5420, loss = 0.0439694
I0403 09:11:40.016520 24116 solver.cpp:244]     Train net output #0: loss = 0.0439692 (* 1 = 0.0439692 loss)
I0403 09:11:40.253003 24116 sgd_solver.cpp:106] Iteration 5420, lr = 5e-05
I0403 09:11:47.442044 24116 solver.cpp:228] Iteration 5430, loss = 0.0763669
I0403 09:11:47.442131 24116 solver.cpp:244]     Train net output #0: loss = 0.0763667 (* 1 = 0.0763667 loss)
I0403 09:11:47.610044 24116 sgd_solver.cpp:106] Iteration 5430, lr = 5e-05
I0403 09:11:54.981000 24116 solver.cpp:228] Iteration 5440, loss = 0.0227045
I0403 09:11:54.981083 24116 solver.cpp:244]     Train net output #0: loss = 0.0227043 (* 1 = 0.0227043 loss)
I0403 09:11:55.155205 24116 sgd_solver.cpp:106] Iteration 5440, lr = 5e-05
I0403 09:12:02.271652 24116 solver.cpp:228] Iteration 5450, loss = 0.0415625
I0403 09:12:02.271924 24116 solver.cpp:244]     Train net output #0: loss = 0.0415622 (* 1 = 0.0415622 loss)
I0403 09:12:02.438575 24116 sgd_solver.cpp:106] Iteration 5450, lr = 5e-05
I0403 09:12:09.653090 24116 solver.cpp:228] Iteration 5460, loss = 0.0559141
I0403 09:12:09.653188 24116 solver.cpp:244]     Train net output #0: loss = 0.0559139 (* 1 = 0.0559139 loss)
I0403 09:12:09.851788 24116 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 09:12:16.984885 24116 solver.cpp:228] Iteration 5470, loss = 0.0546828
I0403 09:12:16.984972 24116 solver.cpp:244]     Train net output #0: loss = 0.0546825 (* 1 = 0.0546825 loss)
I0403 09:12:17.137087 24116 sgd_solver.cpp:106] Iteration 5470, lr = 5e-05
I0403 09:12:20.235914 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5475.caffemodel
I0403 09:12:22.920331 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5475.solverstate
I0403 09:12:24.741260 24116 solver.cpp:337] Iteration 5475, Testing net (#0)
I0403 09:13:37.259613 24116 solver.cpp:404]     Test net output #0: accuracy = 0.909876
I0403 09:13:37.259982 24116 solver.cpp:404]     Test net output #1: loss = 0.316906 (* 1 = 0.316906 loss)
I0403 09:13:41.443660 24116 solver.cpp:228] Iteration 5480, loss = 0.11544
I0403 09:13:41.443753 24116 solver.cpp:244]     Train net output #0: loss = 0.115439 (* 1 = 0.115439 loss)
I0403 09:13:41.618998 24116 sgd_solver.cpp:106] Iteration 5480, lr = 5e-05
I0403 09:13:48.663058 24116 solver.cpp:228] Iteration 5490, loss = 0.102777
I0403 09:13:48.663158 24116 solver.cpp:244]     Train net output #0: loss = 0.102777 (* 1 = 0.102777 loss)
I0403 09:13:48.825081 24116 sgd_solver.cpp:106] Iteration 5490, lr = 5e-05
I0403 09:13:55.896327 24116 solver.cpp:228] Iteration 5500, loss = 0.0286409
I0403 09:13:55.896426 24116 solver.cpp:244]     Train net output #0: loss = 0.0286406 (* 1 = 0.0286406 loss)
I0403 09:13:56.111795 24116 sgd_solver.cpp:106] Iteration 5500, lr = 5e-05
I0403 09:14:03.208668 24116 solver.cpp:228] Iteration 5510, loss = 0.0869946
I0403 09:14:03.208788 24116 solver.cpp:244]     Train net output #0: loss = 0.0869944 (* 1 = 0.0869944 loss)
I0403 09:14:03.392076 24116 sgd_solver.cpp:106] Iteration 5510, lr = 5e-05
I0403 09:14:10.577003 24116 solver.cpp:228] Iteration 5520, loss = 0.0906382
I0403 09:14:10.577301 24116 solver.cpp:244]     Train net output #0: loss = 0.090638 (* 1 = 0.090638 loss)
I0403 09:14:10.781203 24116 sgd_solver.cpp:106] Iteration 5520, lr = 5e-05
I0403 09:14:17.833500 24116 solver.cpp:228] Iteration 5530, loss = 0.055053
I0403 09:14:17.833601 24116 solver.cpp:244]     Train net output #0: loss = 0.0550528 (* 1 = 0.0550528 loss)
I0403 09:14:18.043521 24116 sgd_solver.cpp:106] Iteration 5530, lr = 5e-05
I0403 09:14:25.098465 24116 solver.cpp:228] Iteration 5540, loss = 0.0402096
I0403 09:14:25.098562 24116 solver.cpp:244]     Train net output #0: loss = 0.0402093 (* 1 = 0.0402093 loss)
I0403 09:14:25.289702 24116 sgd_solver.cpp:106] Iteration 5540, lr = 5e-05
I0403 09:14:32.279117 24116 solver.cpp:228] Iteration 5550, loss = 0.104227
I0403 09:14:32.279217 24116 solver.cpp:244]     Train net output #0: loss = 0.104227 (* 1 = 0.104227 loss)
I0403 09:14:32.515583 24116 sgd_solver.cpp:106] Iteration 5550, lr = 5e-05
I0403 09:14:39.757565 24116 solver.cpp:228] Iteration 5560, loss = 0.0185498
I0403 09:14:39.757653 24116 solver.cpp:244]     Train net output #0: loss = 0.0185495 (* 1 = 0.0185495 loss)
I0403 09:14:39.935742 24116 sgd_solver.cpp:106] Iteration 5560, lr = 5e-05
I0403 09:14:47.300650 24116 solver.cpp:228] Iteration 5570, loss = 0.0422385
I0403 09:14:47.300942 24116 solver.cpp:244]     Train net output #0: loss = 0.0422382 (* 1 = 0.0422382 loss)
I0403 09:14:47.413467 24116 sgd_solver.cpp:106] Iteration 5570, lr = 5e-05
I0403 09:14:54.828310 24116 solver.cpp:228] Iteration 5580, loss = 0.0460708
I0403 09:14:54.828397 24116 solver.cpp:244]     Train net output #0: loss = 0.0460705 (* 1 = 0.0460705 loss)
I0403 09:14:54.943337 24116 sgd_solver.cpp:106] Iteration 5580, lr = 5e-05
I0403 09:15:02.186856 24116 solver.cpp:228] Iteration 5590, loss = 0.0743203
I0403 09:15:02.186954 24116 solver.cpp:244]     Train net output #0: loss = 0.07432 (* 1 = 0.07432 loss)
I0403 09:15:02.405907 24116 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 09:15:09.650710 24116 solver.cpp:228] Iteration 5600, loss = 0.0657159
I0403 09:15:09.650801 24116 solver.cpp:244]     Train net output #0: loss = 0.0657157 (* 1 = 0.0657157 loss)
I0403 09:15:09.785349 24116 sgd_solver.cpp:106] Iteration 5600, lr = 5e-05
I0403 09:15:16.978631 24116 solver.cpp:228] Iteration 5610, loss = 0.0316014
I0403 09:15:16.978718 24116 solver.cpp:244]     Train net output #0: loss = 0.0316011 (* 1 = 0.0316011 loss)
I0403 09:15:17.159852 24116 sgd_solver.cpp:106] Iteration 5610, lr = 5e-05
I0403 09:15:24.254801 24116 solver.cpp:228] Iteration 5620, loss = 0.105186
I0403 09:15:24.255069 24116 solver.cpp:244]     Train net output #0: loss = 0.105186 (* 1 = 0.105186 loss)
I0403 09:15:24.455564 24116 sgd_solver.cpp:106] Iteration 5620, lr = 5e-05
I0403 09:15:31.466931 24116 solver.cpp:228] Iteration 5630, loss = 0.0633173
I0403 09:15:31.467031 24116 solver.cpp:244]     Train net output #0: loss = 0.0633171 (* 1 = 0.0633171 loss)
I0403 09:15:31.659310 24116 sgd_solver.cpp:106] Iteration 5630, lr = 5e-05
I0403 09:15:38.800940 24116 solver.cpp:228] Iteration 5640, loss = 0.0859394
I0403 09:15:38.801029 24116 solver.cpp:244]     Train net output #0: loss = 0.0859392 (* 1 = 0.0859392 loss)
I0403 09:15:38.957669 24116 sgd_solver.cpp:106] Iteration 5640, lr = 5e-05
I0403 09:15:46.083680 24116 solver.cpp:228] Iteration 5650, loss = 0.0980297
I0403 09:15:46.083782 24116 solver.cpp:244]     Train net output #0: loss = 0.0980294 (* 1 = 0.0980294 loss)
I0403 09:15:46.266947 24116 sgd_solver.cpp:106] Iteration 5650, lr = 5e-05
I0403 09:15:53.374723 24116 solver.cpp:228] Iteration 5660, loss = 0.0643709
I0403 09:15:53.374825 24116 solver.cpp:244]     Train net output #0: loss = 0.0643706 (* 1 = 0.0643706 loss)
I0403 09:15:53.586392 24116 sgd_solver.cpp:106] Iteration 5660, lr = 5e-05
I0403 09:16:00.584686 24116 solver.cpp:228] Iteration 5670, loss = 0.0422139
I0403 09:16:00.584985 24116 solver.cpp:244]     Train net output #0: loss = 0.0422137 (* 1 = 0.0422137 loss)
I0403 09:16:00.753187 24116 sgd_solver.cpp:106] Iteration 5670, lr = 5e-05
I0403 09:16:07.898422 24116 solver.cpp:228] Iteration 5680, loss = 0.0482883
I0403 09:16:07.898519 24116 solver.cpp:244]     Train net output #0: loss = 0.048288 (* 1 = 0.048288 loss)
I0403 09:16:08.106554 24116 sgd_solver.cpp:106] Iteration 5680, lr = 5e-05
I0403 09:16:15.197280 24116 solver.cpp:228] Iteration 5690, loss = 0.0446014
I0403 09:16:15.197367 24116 solver.cpp:244]     Train net output #0: loss = 0.0446011 (* 1 = 0.0446011 loss)
I0403 09:16:15.370023 24116 sgd_solver.cpp:106] Iteration 5690, lr = 5e-05
I0403 09:16:17.554391 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5694.caffemodel
I0403 09:16:20.354264 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5694.solverstate
I0403 09:16:22.205001 24116 solver.cpp:337] Iteration 5694, Testing net (#0)
I0403 09:17:34.720860 24116 solver.cpp:404]     Test net output #0: accuracy = 0.909784
I0403 09:17:34.721130 24116 solver.cpp:404]     Test net output #1: loss = 0.31735 (* 1 = 0.31735 loss)
I0403 09:17:39.559909 24116 solver.cpp:228] Iteration 5700, loss = 0.131383
I0403 09:17:39.560008 24116 solver.cpp:244]     Train net output #0: loss = 0.131383 (* 1 = 0.131383 loss)
I0403 09:17:39.743470 24116 sgd_solver.cpp:106] Iteration 5700, lr = 5e-05
I0403 09:17:46.798614 24116 solver.cpp:228] Iteration 5710, loss = 0.0376108
I0403 09:17:46.798707 24116 solver.cpp:244]     Train net output #0: loss = 0.0376105 (* 1 = 0.0376105 loss)
I0403 09:17:46.996824 24116 sgd_solver.cpp:106] Iteration 5710, lr = 5e-05
I0403 09:17:54.199246 24116 solver.cpp:228] Iteration 5720, loss = 0.0465884
I0403 09:17:54.199331 24116 solver.cpp:244]     Train net output #0: loss = 0.0465881 (* 1 = 0.0465881 loss)
I0403 09:17:54.380278 24116 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 09:18:01.593732 24116 solver.cpp:228] Iteration 5730, loss = 0.0801892
I0403 09:18:01.593837 24116 solver.cpp:244]     Train net output #0: loss = 0.0801889 (* 1 = 0.0801889 loss)
I0403 09:18:01.833684 24116 sgd_solver.cpp:106] Iteration 5730, lr = 5e-05
I0403 09:18:08.935458 24116 solver.cpp:228] Iteration 5740, loss = 0.0915625
I0403 09:18:08.935731 24116 solver.cpp:244]     Train net output #0: loss = 0.0915622 (* 1 = 0.0915622 loss)
I0403 09:18:09.142998 24116 sgd_solver.cpp:106] Iteration 5740, lr = 5e-05
I0403 09:18:16.314677 24116 solver.cpp:228] Iteration 5750, loss = 0.0829269
I0403 09:18:16.314781 24116 solver.cpp:244]     Train net output #0: loss = 0.0829266 (* 1 = 0.0829266 loss)
I0403 09:18:16.553022 24116 sgd_solver.cpp:106] Iteration 5750, lr = 5e-05
I0403 09:18:23.746479 24116 solver.cpp:228] Iteration 5760, loss = 0.100099
I0403 09:18:23.746578 24116 solver.cpp:244]     Train net output #0: loss = 0.100099 (* 1 = 0.100099 loss)
I0403 09:18:23.930007 24116 sgd_solver.cpp:106] Iteration 5760, lr = 5e-05
I0403 09:18:30.987704 24116 solver.cpp:228] Iteration 5770, loss = 0.101311
I0403 09:18:30.987797 24116 solver.cpp:244]     Train net output #0: loss = 0.101311 (* 1 = 0.101311 loss)
I0403 09:18:31.167276 24116 sgd_solver.cpp:106] Iteration 5770, lr = 5e-05
I0403 09:18:38.347452 24116 solver.cpp:228] Iteration 5780, loss = 0.0596168
I0403 09:18:38.347551 24116 solver.cpp:244]     Train net output #0: loss = 0.0596165 (* 1 = 0.0596165 loss)
I0403 09:18:38.539193 24116 sgd_solver.cpp:106] Iteration 5780, lr = 5e-05
I0403 09:18:45.596542 24116 solver.cpp:228] Iteration 5790, loss = 0.0508455
I0403 09:18:45.596891 24116 solver.cpp:244]     Train net output #0: loss = 0.0508453 (* 1 = 0.0508453 loss)
I0403 09:18:45.769647 24116 sgd_solver.cpp:106] Iteration 5790, lr = 5e-05
I0403 09:18:52.925009 24116 solver.cpp:228] Iteration 5800, loss = 0.0229244
I0403 09:18:52.925107 24116 solver.cpp:244]     Train net output #0: loss = 0.0229242 (* 1 = 0.0229242 loss)
I0403 09:18:53.110077 24116 sgd_solver.cpp:106] Iteration 5800, lr = 5e-05
I0403 09:19:00.347654 24116 solver.cpp:228] Iteration 5810, loss = 0.0423767
I0403 09:19:00.347762 24116 solver.cpp:244]     Train net output #0: loss = 0.0423765 (* 1 = 0.0423765 loss)
I0403 09:19:00.535857 24116 sgd_solver.cpp:106] Iteration 5810, lr = 5e-05
I0403 09:19:07.628664 24116 solver.cpp:228] Iteration 5820, loss = 0.0862422
I0403 09:19:07.628778 24116 solver.cpp:244]     Train net output #0: loss = 0.0862419 (* 1 = 0.0862419 loss)
I0403 09:19:07.812309 24116 sgd_solver.cpp:106] Iteration 5820, lr = 5e-05
I0403 09:19:14.827486 24116 solver.cpp:228] Iteration 5830, loss = 0.0251049
I0403 09:19:14.827584 24116 solver.cpp:244]     Train net output #0: loss = 0.0251046 (* 1 = 0.0251046 loss)
I0403 09:19:15.011219 24116 sgd_solver.cpp:106] Iteration 5830, lr = 5e-05
I0403 09:19:22.106775 24116 solver.cpp:228] Iteration 5840, loss = 0.100563
I0403 09:19:22.107075 24116 solver.cpp:244]     Train net output #0: loss = 0.100563 (* 1 = 0.100563 loss)
I0403 09:19:22.295662 24116 sgd_solver.cpp:106] Iteration 5840, lr = 5e-05
I0403 09:19:29.485864 24116 solver.cpp:228] Iteration 5850, loss = 0.0695607
I0403 09:19:29.485967 24116 solver.cpp:244]     Train net output #0: loss = 0.0695605 (* 1 = 0.0695605 loss)
I0403 09:19:29.675451 24116 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 09:19:36.836705 24116 solver.cpp:228] Iteration 5860, loss = 0.0318235
I0403 09:19:36.836807 24116 solver.cpp:244]     Train net output #0: loss = 0.0318233 (* 1 = 0.0318233 loss)
I0403 09:19:37.014647 24116 sgd_solver.cpp:106] Iteration 5860, lr = 5e-05
I0403 09:19:44.110657 24116 solver.cpp:228] Iteration 5870, loss = 0.0358813
I0403 09:19:44.110756 24116 solver.cpp:244]     Train net output #0: loss = 0.035881 (* 1 = 0.035881 loss)
I0403 09:19:44.333811 24116 sgd_solver.cpp:106] Iteration 5870, lr = 5e-05
I0403 09:19:51.406708 24116 solver.cpp:228] Iteration 5880, loss = 0.0332663
I0403 09:19:51.406810 24116 solver.cpp:244]     Train net output #0: loss = 0.033266 (* 1 = 0.033266 loss)
I0403 09:19:51.589258 24116 sgd_solver.cpp:106] Iteration 5880, lr = 5e-05
I0403 09:19:58.673437 24116 solver.cpp:228] Iteration 5890, loss = 0.0859429
I0403 09:19:58.673733 24116 solver.cpp:244]     Train net output #0: loss = 0.0859426 (* 1 = 0.0859426 loss)
I0403 09:19:58.879506 24116 sgd_solver.cpp:106] Iteration 5890, lr = 5e-05
I0403 09:20:05.885078 24116 solver.cpp:228] Iteration 5900, loss = 0.0335301
I0403 09:20:05.885179 24116 solver.cpp:244]     Train net output #0: loss = 0.0335298 (* 1 = 0.0335298 loss)
I0403 09:20:06.070076 24116 sgd_solver.cpp:106] Iteration 5900, lr = 5e-05
I0403 09:20:13.187666 24116 solver.cpp:228] Iteration 5910, loss = 0.0311448
I0403 09:20:13.187767 24116 solver.cpp:244]     Train net output #0: loss = 0.0311445 (* 1 = 0.0311445 loss)
I0403 09:20:13.411396 24116 sgd_solver.cpp:106] Iteration 5910, lr = 5e-05
I0403 09:20:14.850981 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5913.caffemodel
I0403 09:20:17.659318 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_5913.solverstate
I0403 09:20:19.510571 24116 solver.cpp:337] Iteration 5913, Testing net (#0)
I0403 09:21:32.025759 24116 solver.cpp:404]     Test net output #0: accuracy = 0.909381
I0403 09:21:32.026082 24116 solver.cpp:404]     Test net output #1: loss = 0.319112 (* 1 = 0.319112 loss)
I0403 09:21:37.711812 24116 solver.cpp:228] Iteration 5920, loss = 0.110413
I0403 09:21:37.711896 24116 solver.cpp:244]     Train net output #0: loss = 0.110413 (* 1 = 0.110413 loss)
I0403 09:21:37.792008 24116 sgd_solver.cpp:106] Iteration 5920, lr = 5e-05
I0403 09:21:45.106122 24116 solver.cpp:228] Iteration 5930, loss = 0.0375915
I0403 09:21:45.106220 24116 solver.cpp:244]     Train net output #0: loss = 0.0375912 (* 1 = 0.0375912 loss)
I0403 09:21:45.288338 24116 sgd_solver.cpp:106] Iteration 5930, lr = 5e-05
I0403 09:21:52.324627 24116 solver.cpp:228] Iteration 5940, loss = 0.0289456
I0403 09:21:52.324725 24116 solver.cpp:244]     Train net output #0: loss = 0.0289453 (* 1 = 0.0289453 loss)
I0403 09:21:52.521559 24116 sgd_solver.cpp:106] Iteration 5940, lr = 5e-05
I0403 09:21:59.619813 24116 solver.cpp:228] Iteration 5950, loss = 0.102504
I0403 09:21:59.619901 24116 solver.cpp:244]     Train net output #0: loss = 0.102504 (* 1 = 0.102504 loss)
I0403 09:21:59.789723 24116 sgd_solver.cpp:106] Iteration 5950, lr = 5e-05
I0403 09:22:06.873950 24116 solver.cpp:228] Iteration 5960, loss = 0.0471915
I0403 09:22:06.874264 24116 solver.cpp:244]     Train net output #0: loss = 0.0471912 (* 1 = 0.0471912 loss)
I0403 09:22:07.047152 24116 sgd_solver.cpp:106] Iteration 5960, lr = 5e-05
I0403 09:22:14.260875 24116 solver.cpp:228] Iteration 5970, loss = 0.0358025
I0403 09:22:14.260977 24116 solver.cpp:244]     Train net output #0: loss = 0.0358022 (* 1 = 0.0358022 loss)
I0403 09:22:14.456506 24116 sgd_solver.cpp:106] Iteration 5970, lr = 5e-05
I0403 09:22:21.679666 24116 solver.cpp:228] Iteration 5980, loss = 0.0700103
I0403 09:22:21.679759 24116 solver.cpp:244]     Train net output #0: loss = 0.07001 (* 1 = 0.07001 loss)
I0403 09:22:21.849707 24116 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 09:22:28.903795 24116 solver.cpp:228] Iteration 5990, loss = 0.0731217
I0403 09:22:28.903887 24116 solver.cpp:244]     Train net output #0: loss = 0.0731214 (* 1 = 0.0731214 loss)
I0403 09:22:29.085384 24116 sgd_solver.cpp:106] Iteration 5990, lr = 5e-05
I0403 09:22:36.186163 24116 solver.cpp:228] Iteration 6000, loss = 0.0295632
I0403 09:22:36.186264 24116 solver.cpp:244]     Train net output #0: loss = 0.029563 (* 1 = 0.029563 loss)
I0403 09:22:36.451907 24116 sgd_solver.cpp:106] Iteration 6000, lr = 5e-05
I0403 09:22:43.746678 24116 solver.cpp:228] Iteration 6010, loss = 0.038595
I0403 09:22:43.746954 24116 solver.cpp:244]     Train net output #0: loss = 0.0385947 (* 1 = 0.0385947 loss)
I0403 09:22:43.939376 24116 sgd_solver.cpp:106] Iteration 6010, lr = 5e-05
I0403 09:22:51.143584 24116 solver.cpp:228] Iteration 6020, loss = 0.110911
I0403 09:22:51.143684 24116 solver.cpp:244]     Train net output #0: loss = 0.110911 (* 1 = 0.110911 loss)
I0403 09:22:51.342820 24116 sgd_solver.cpp:106] Iteration 6020, lr = 5e-05
I0403 09:22:58.325098 24116 solver.cpp:228] Iteration 6030, loss = 0.0351464
I0403 09:22:58.325196 24116 solver.cpp:244]     Train net output #0: loss = 0.0351462 (* 1 = 0.0351462 loss)
I0403 09:22:58.526610 24116 sgd_solver.cpp:106] Iteration 6030, lr = 5e-05
I0403 09:23:05.644563 24116 solver.cpp:228] Iteration 6040, loss = 0.0666024
I0403 09:23:05.644660 24116 solver.cpp:244]     Train net output #0: loss = 0.0666021 (* 1 = 0.0666021 loss)
I0403 09:23:05.834208 24116 sgd_solver.cpp:106] Iteration 6040, lr = 5e-05
I0403 09:23:12.963565 24116 solver.cpp:228] Iteration 6050, loss = 0.0356382
I0403 09:23:12.963654 24116 solver.cpp:244]     Train net output #0: loss = 0.0356379 (* 1 = 0.0356379 loss)
I0403 09:23:13.113927 24116 sgd_solver.cpp:106] Iteration 6050, lr = 5e-05
I0403 09:23:20.343825 24116 solver.cpp:228] Iteration 6060, loss = 0.130472
I0403 09:23:20.344161 24116 solver.cpp:244]     Train net output #0: loss = 0.130472 (* 1 = 0.130472 loss)
I0403 09:23:20.551421 24116 sgd_solver.cpp:106] Iteration 6060, lr = 5e-05
I0403 09:23:27.721384 24116 solver.cpp:228] Iteration 6070, loss = 0.107759
I0403 09:23:27.721483 24116 solver.cpp:244]     Train net output #0: loss = 0.107758 (* 1 = 0.107758 loss)
I0403 09:23:27.914446 24116 sgd_solver.cpp:106] Iteration 6070, lr = 5e-05
I0403 09:23:34.908808 24116 solver.cpp:228] Iteration 6080, loss = 0.0354603
I0403 09:23:34.908908 24116 solver.cpp:244]     Train net output #0: loss = 0.03546 (* 1 = 0.03546 loss)
I0403 09:23:35.152490 24116 sgd_solver.cpp:106] Iteration 6080, lr = 5e-05
I0403 09:23:42.139437 24116 solver.cpp:228] Iteration 6090, loss = 0.0715611
I0403 09:23:42.139534 24116 solver.cpp:244]     Train net output #0: loss = 0.0715609 (* 1 = 0.0715609 loss)
I0403 09:23:42.346498 24116 sgd_solver.cpp:106] Iteration 6090, lr = 5e-05
I0403 09:23:49.422163 24116 solver.cpp:228] Iteration 6100, loss = 0.172865
I0403 09:23:49.422250 24116 solver.cpp:244]     Train net output #0: loss = 0.172864 (* 1 = 0.172864 loss)
I0403 09:23:49.576459 24116 sgd_solver.cpp:106] Iteration 6100, lr = 5e-05
I0403 09:23:56.924846 24116 solver.cpp:228] Iteration 6110, loss = 0.0514897
I0403 09:23:56.925132 24116 solver.cpp:244]     Train net output #0: loss = 0.0514895 (* 1 = 0.0514895 loss)
I0403 09:23:57.100608 24116 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 09:24:04.132237 24116 solver.cpp:228] Iteration 6120, loss = 0.0313466
I0403 09:24:04.132330 24116 solver.cpp:244]     Train net output #0: loss = 0.0313464 (* 1 = 0.0313464 loss)
I0403 09:24:04.331773 24116 sgd_solver.cpp:106] Iteration 6120, lr = 5e-05
I0403 09:24:11.335315 24116 solver.cpp:228] Iteration 6130, loss = 0.0345541
I0403 09:24:11.335417 24116 solver.cpp:244]     Train net output #0: loss = 0.0345539 (* 1 = 0.0345539 loss)
I0403 09:24:11.544864 24116 sgd_solver.cpp:106] Iteration 6130, lr = 5e-05
I0403 09:24:12.261206 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6132.caffemodel
I0403 09:24:15.064419 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6132.solverstate
I0403 09:24:16.955420 24116 solver.cpp:337] Iteration 6132, Testing net (#0)
I0403 09:25:29.487241 24116 solver.cpp:404]     Test net output #0: accuracy = 0.90935
I0403 09:25:29.487514 24116 solver.cpp:404]     Test net output #1: loss = 0.319391 (* 1 = 0.319391 loss)
I0403 09:25:35.878276 24116 solver.cpp:228] Iteration 6140, loss = 0.0799578
I0403 09:25:35.878373 24116 solver.cpp:244]     Train net output #0: loss = 0.0799575 (* 1 = 0.0799575 loss)
I0403 09:25:36.112161 24116 sgd_solver.cpp:106] Iteration 6140, lr = 5e-05
I0403 09:25:43.211102 24116 solver.cpp:228] Iteration 6150, loss = 0.0361952
I0403 09:25:43.211192 24116 solver.cpp:244]     Train net output #0: loss = 0.036195 (* 1 = 0.036195 loss)
I0403 09:25:43.320142 24116 sgd_solver.cpp:106] Iteration 6150, lr = 5e-05
I0403 09:25:50.655972 24116 solver.cpp:228] Iteration 6160, loss = 0.0956177
I0403 09:25:50.656075 24116 solver.cpp:244]     Train net output #0: loss = 0.0956174 (* 1 = 0.0956174 loss)
I0403 09:25:50.846163 24116 sgd_solver.cpp:106] Iteration 6160, lr = 5e-05
I0403 09:25:58.016921 24116 solver.cpp:228] Iteration 6170, loss = 0.129588
I0403 09:25:58.017017 24116 solver.cpp:244]     Train net output #0: loss = 0.129588 (* 1 = 0.129588 loss)
I0403 09:25:58.202585 24116 sgd_solver.cpp:106] Iteration 6170, lr = 5e-05
I0403 09:26:05.422612 24116 solver.cpp:228] Iteration 6180, loss = 0.0852006
I0403 09:26:05.422935 24116 solver.cpp:244]     Train net output #0: loss = 0.0852003 (* 1 = 0.0852003 loss)
I0403 09:26:05.578557 24116 sgd_solver.cpp:106] Iteration 6180, lr = 5e-05
I0403 09:26:12.809264 24116 solver.cpp:228] Iteration 6190, loss = 0.0432952
I0403 09:26:12.809361 24116 solver.cpp:244]     Train net output #0: loss = 0.0432949 (* 1 = 0.0432949 loss)
I0403 09:26:12.997644 24116 sgd_solver.cpp:106] Iteration 6190, lr = 5e-05
I0403 09:26:20.200306 24116 solver.cpp:228] Iteration 6200, loss = 0.110771
I0403 09:26:20.200395 24116 solver.cpp:244]     Train net output #0: loss = 0.110771 (* 1 = 0.110771 loss)
I0403 09:26:20.346360 24116 sgd_solver.cpp:106] Iteration 6200, lr = 5e-05
I0403 09:26:27.514917 24116 solver.cpp:228] Iteration 6210, loss = 0.07488
I0403 09:26:27.515018 24116 solver.cpp:244]     Train net output #0: loss = 0.0748797 (* 1 = 0.0748797 loss)
I0403 09:26:27.701088 24116 sgd_solver.cpp:106] Iteration 6210, lr = 5e-05
I0403 09:26:34.772209 24116 solver.cpp:228] Iteration 6220, loss = 0.0602525
I0403 09:26:34.772307 24116 solver.cpp:244]     Train net output #0: loss = 0.0602522 (* 1 = 0.0602522 loss)
I0403 09:26:34.953894 24116 sgd_solver.cpp:106] Iteration 6220, lr = 5e-05
I0403 09:26:42.074587 24116 solver.cpp:228] Iteration 6230, loss = 0.084248
I0403 09:26:42.074868 24116 solver.cpp:244]     Train net output #0: loss = 0.0842477 (* 1 = 0.0842477 loss)
I0403 09:26:42.280143 24116 sgd_solver.cpp:106] Iteration 6230, lr = 5e-05
I0403 09:26:49.337996 24116 solver.cpp:228] Iteration 6240, loss = 0.0727378
I0403 09:26:49.338098 24116 solver.cpp:244]     Train net output #0: loss = 0.0727375 (* 1 = 0.0727375 loss)
I0403 09:26:49.526177 24116 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 09:26:56.706271 24116 solver.cpp:228] Iteration 6250, loss = 0.0568829
I0403 09:26:56.706368 24116 solver.cpp:244]     Train net output #0: loss = 0.0568826 (* 1 = 0.0568826 loss)
I0403 09:26:56.921119 24116 sgd_solver.cpp:106] Iteration 6250, lr = 5e-05
I0403 09:27:04.043436 24116 solver.cpp:228] Iteration 6260, loss = 0.0600502
I0403 09:27:04.043530 24116 solver.cpp:244]     Train net output #0: loss = 0.06005 (* 1 = 0.06005 loss)
I0403 09:27:04.255623 24116 sgd_solver.cpp:106] Iteration 6260, lr = 5e-05
I0403 09:27:11.233254 24116 solver.cpp:228] Iteration 6270, loss = 0.019907
I0403 09:27:11.233352 24116 solver.cpp:244]     Train net output #0: loss = 0.0199067 (* 1 = 0.0199067 loss)
I0403 09:27:11.431752 24116 sgd_solver.cpp:106] Iteration 6270, lr = 5e-05
I0403 09:27:18.464357 24116 solver.cpp:228] Iteration 6280, loss = 0.141659
I0403 09:27:18.464630 24116 solver.cpp:244]     Train net output #0: loss = 0.141659 (* 1 = 0.141659 loss)
I0403 09:27:18.626809 24116 sgd_solver.cpp:106] Iteration 6280, lr = 5e-05
I0403 09:27:25.664383 24116 solver.cpp:228] Iteration 6290, loss = 0.14287
I0403 09:27:25.664469 24116 solver.cpp:244]     Train net output #0: loss = 0.14287 (* 1 = 0.14287 loss)
I0403 09:27:25.845456 24116 sgd_solver.cpp:106] Iteration 6290, lr = 5e-05
I0403 09:27:32.870075 24116 solver.cpp:228] Iteration 6300, loss = 0.0487375
I0403 09:27:32.870173 24116 solver.cpp:244]     Train net output #0: loss = 0.0487373 (* 1 = 0.0487373 loss)
I0403 09:27:33.063607 24116 sgd_solver.cpp:106] Iteration 6300, lr = 5e-05
I0403 09:27:40.109294 24116 solver.cpp:228] Iteration 6310, loss = 0.0607044
I0403 09:27:40.109391 24116 solver.cpp:244]     Train net output #0: loss = 0.0607041 (* 1 = 0.0607041 loss)
I0403 09:27:40.297777 24116 sgd_solver.cpp:106] Iteration 6310, lr = 5e-05
I0403 09:27:47.453649 24116 solver.cpp:228] Iteration 6320, loss = 0.0627405
I0403 09:27:47.453754 24116 solver.cpp:244]     Train net output #0: loss = 0.0627402 (* 1 = 0.0627402 loss)
I0403 09:27:47.638283 24116 sgd_solver.cpp:106] Iteration 6320, lr = 5e-05
I0403 09:27:54.643865 24116 solver.cpp:228] Iteration 6330, loss = 0.0743805
I0403 09:27:54.648130 24116 solver.cpp:244]     Train net output #0: loss = 0.0743802 (* 1 = 0.0743802 loss)
I0403 09:27:54.854094 24116 sgd_solver.cpp:106] Iteration 6330, lr = 5e-05
I0403 09:28:01.896530 24116 solver.cpp:228] Iteration 6340, loss = 0.0562201
I0403 09:28:01.896631 24116 solver.cpp:244]     Train net output #0: loss = 0.0562198 (* 1 = 0.0562198 loss)
I0403 09:28:02.093528 24116 sgd_solver.cpp:106] Iteration 6340, lr = 5e-05
I0403 09:28:09.367385 24116 solver.cpp:228] Iteration 6350, loss = 0.0959552
I0403 09:28:09.367476 24116 solver.cpp:244]     Train net output #0: loss = 0.095955 (* 1 = 0.095955 loss)
I0403 09:28:09.540446 24116 sgd_solver.cpp:106] Iteration 6350, lr = 5e-05
I0403 09:28:09.540673 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6351.caffemodel
I0403 09:28:12.326380 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6351.solverstate
I0403 09:28:14.224417 24116 solver.cpp:337] Iteration 6351, Testing net (#0)
I0403 09:29:26.749795 24116 solver.cpp:404]     Test net output #0: accuracy = 0.909783
I0403 09:29:26.750066 24116 solver.cpp:404]     Test net output #1: loss = 0.318562 (* 1 = 0.318562 loss)
I0403 09:29:33.772634 24116 solver.cpp:228] Iteration 6360, loss = 0.0200101
I0403 09:29:33.772719 24116 solver.cpp:244]     Train net output #0: loss = 0.0200098 (* 1 = 0.0200098 loss)
I0403 09:29:33.936380 24116 sgd_solver.cpp:106] Iteration 6360, lr = 5e-05
I0403 09:29:41.107900 24116 solver.cpp:228] Iteration 6370, loss = 0.0410398
I0403 09:29:41.107996 24116 solver.cpp:244]     Train net output #0: loss = 0.0410396 (* 1 = 0.0410396 loss)
I0403 09:29:41.300178 24116 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 09:29:48.319490 24116 solver.cpp:228] Iteration 6380, loss = 0.037136
I0403 09:29:48.319591 24116 solver.cpp:244]     Train net output #0: loss = 0.0371358 (* 1 = 0.0371358 loss)
I0403 09:29:48.545306 24116 sgd_solver.cpp:106] Iteration 6380, lr = 5e-05
I0403 09:29:55.570513 24116 solver.cpp:228] Iteration 6390, loss = 0.108927
I0403 09:29:55.570612 24116 solver.cpp:244]     Train net output #0: loss = 0.108927 (* 1 = 0.108927 loss)
I0403 09:29:55.759563 24116 sgd_solver.cpp:106] Iteration 6390, lr = 5e-05
I0403 09:30:02.847756 24116 solver.cpp:228] Iteration 6400, loss = 0.133785
I0403 09:30:02.848044 24116 solver.cpp:244]     Train net output #0: loss = 0.133785 (* 1 = 0.133785 loss)
I0403 09:30:03.008292 24116 sgd_solver.cpp:106] Iteration 6400, lr = 5e-05
I0403 09:30:10.059262 24116 solver.cpp:228] Iteration 6410, loss = 0.128703
I0403 09:30:10.059360 24116 solver.cpp:244]     Train net output #0: loss = 0.128703 (* 1 = 0.128703 loss)
I0403 09:30:10.259670 24116 sgd_solver.cpp:106] Iteration 6410, lr = 5e-05
I0403 09:30:17.380306 24116 solver.cpp:228] Iteration 6420, loss = 0.02892
I0403 09:30:17.380393 24116 solver.cpp:244]     Train net output #0: loss = 0.0289198 (* 1 = 0.0289198 loss)
I0403 09:30:17.560741 24116 sgd_solver.cpp:106] Iteration 6420, lr = 5e-05
I0403 09:30:24.921361 24116 solver.cpp:228] Iteration 6430, loss = 0.0510352
I0403 09:30:24.921449 24116 solver.cpp:244]     Train net output #0: loss = 0.051035 (* 1 = 0.051035 loss)
I0403 09:30:25.089790 24116 sgd_solver.cpp:106] Iteration 6430, lr = 5e-05
I0403 09:30:32.197448 24116 solver.cpp:228] Iteration 6440, loss = 0.0993641
I0403 09:30:32.197551 24116 solver.cpp:244]     Train net output #0: loss = 0.0993638 (* 1 = 0.0993638 loss)
I0403 09:30:32.420434 24116 sgd_solver.cpp:106] Iteration 6440, lr = 5e-05
I0403 09:30:39.574203 24116 solver.cpp:228] Iteration 6450, loss = 0.0483747
I0403 09:30:39.574532 24116 solver.cpp:244]     Train net output #0: loss = 0.0483744 (* 1 = 0.0483744 loss)
I0403 09:30:39.781100 24116 sgd_solver.cpp:106] Iteration 6450, lr = 5e-05
I0403 09:30:46.806520 24116 solver.cpp:228] Iteration 6460, loss = 0.0370844
I0403 09:30:46.806617 24116 solver.cpp:244]     Train net output #0: loss = 0.0370841 (* 1 = 0.0370841 loss)
I0403 09:30:47.011306 24116 sgd_solver.cpp:106] Iteration 6460, lr = 5e-05
I0403 09:30:54.073884 24116 solver.cpp:228] Iteration 6470, loss = 0.0698147
I0403 09:30:54.073982 24116 solver.cpp:244]     Train net output #0: loss = 0.0698144 (* 1 = 0.0698144 loss)
I0403 09:30:54.284521 24116 sgd_solver.cpp:106] Iteration 6470, lr = 5e-05
I0403 09:31:01.306499 24116 solver.cpp:228] Iteration 6480, loss = 0.0941442
I0403 09:31:01.306586 24116 solver.cpp:244]     Train net output #0: loss = 0.0941439 (* 1 = 0.0941439 loss)
I0403 09:31:01.481242 24116 sgd_solver.cpp:106] Iteration 6480, lr = 5e-05
I0403 09:31:08.688071 24116 solver.cpp:228] Iteration 6490, loss = 0.0465157
I0403 09:31:08.688171 24116 solver.cpp:244]     Train net output #0: loss = 0.0465154 (* 1 = 0.0465154 loss)
I0403 09:31:08.853409 24116 sgd_solver.cpp:106] Iteration 6490, lr = 5e-05
I0403 09:31:16.047967 24116 solver.cpp:228] Iteration 6500, loss = 0.0618586
I0403 09:31:16.048297 24116 solver.cpp:244]     Train net output #0: loss = 0.0618583 (* 1 = 0.0618583 loss)
I0403 09:31:16.230845 24116 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 09:31:23.499933 24116 solver.cpp:228] Iteration 6510, loss = 0.168963
I0403 09:31:23.500018 24116 solver.cpp:244]     Train net output #0: loss = 0.168963 (* 1 = 0.168963 loss)
I0403 09:31:23.662889 24116 sgd_solver.cpp:106] Iteration 6510, lr = 5e-05
I0403 09:31:30.923243 24116 solver.cpp:228] Iteration 6520, loss = 0.157779
I0403 09:31:30.923342 24116 solver.cpp:244]     Train net output #0: loss = 0.157779 (* 1 = 0.157779 loss)
I0403 09:31:31.108016 24116 sgd_solver.cpp:106] Iteration 6520, lr = 5e-05
I0403 09:31:38.265650 24116 solver.cpp:228] Iteration 6530, loss = 0.0645045
I0403 09:31:38.265741 24116 solver.cpp:244]     Train net output #0: loss = 0.0645043 (* 1 = 0.0645043 loss)
I0403 09:31:38.436035 24116 sgd_solver.cpp:106] Iteration 6530, lr = 5e-05
I0403 09:31:45.489936 24116 solver.cpp:228] Iteration 6540, loss = 0.070079
I0403 09:31:45.490036 24116 solver.cpp:244]     Train net output #0: loss = 0.0700787 (* 1 = 0.0700787 loss)
I0403 09:31:45.692131 24116 sgd_solver.cpp:106] Iteration 6540, lr = 5e-05
I0403 09:31:52.829818 24116 solver.cpp:228] Iteration 6550, loss = 0.0523703
I0403 09:31:52.830123 24116 solver.cpp:244]     Train net output #0: loss = 0.05237 (* 1 = 0.05237 loss)
I0403 09:31:53.048197 24116 sgd_solver.cpp:106] Iteration 6550, lr = 5e-05
I0403 09:32:00.068694 24116 solver.cpp:228] Iteration 6560, loss = 0.0357867
I0403 09:32:00.068792 24116 solver.cpp:244]     Train net output #0: loss = 0.0357865 (* 1 = 0.0357865 loss)
I0403 09:32:00.250243 24116 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 09:32:06.815955 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6570.caffemodel
I0403 09:32:09.875782 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6570.solverstate
I0403 09:32:11.767012 24116 solver.cpp:337] Iteration 6570, Testing net (#0)
I0403 09:33:24.284222 24116 solver.cpp:404]     Test net output #0: accuracy = 0.91003
I0403 09:33:24.284803 24116 solver.cpp:404]     Test net output #1: loss = 0.317961 (* 1 = 0.317961 loss)
I0403 09:33:24.788519 24116 solver.cpp:228] Iteration 6570, loss = 0.0761509
I0403 09:33:24.788614 24116 solver.cpp:244]     Train net output #0: loss = 0.0761506 (* 1 = 0.0761506 loss)
I0403 09:33:24.975785 24116 sgd_solver.cpp:106] Iteration 6570, lr = 5e-05
I0403 09:33:32.014544 24116 solver.cpp:228] Iteration 6580, loss = 0.107591
I0403 09:33:32.014643 24116 solver.cpp:244]     Train net output #0: loss = 0.107591 (* 1 = 0.107591 loss)
I0403 09:33:32.206660 24116 sgd_solver.cpp:106] Iteration 6580, lr = 5e-05
I0403 09:33:38.078837 24116 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6589.caffemodel
I0403 09:33:40.876675 24116 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-40-60_train_from_scratch/snapshots__iter_6589.solverstate
I0403 09:33:42.755659 24116 solver.cpp:322] Optimization Done.
I0403 09:33:42.838829 24116 caffe.cpp:222] Optimization Done.
