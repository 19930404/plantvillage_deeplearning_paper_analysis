I0403 02:30:27.993399  4270 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:27.994297  4270 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:27.994346  4270 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:35.896270  4270 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:35.897805  4270 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:35.899260  4270 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.007813  4270 solver.cpp:48] Initializing solver from parameters: 
test_iter: 273
test_interval: 269
base_lr: 0.005
display: 13
max_iter: 8075
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2691
snapshot: 269
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.048403  4270 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.060003  4270 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.060163  4270 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.062019  4270 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-50-50/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.063099  4270 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.064739  4270 net.cpp:91] Creating Layer data
I0403 02:30:37.064836  4270 net.cpp:399] data -> data
I0403 02:30:37.064963  4270 net.cpp:399] data -> label
I0403 02:30:37.065062  4270 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-50-50/mean.binaryproto
I0403 02:30:37.091559  4276 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-50-50/train_db
I0403 02:30:37.114472  4270 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.266521  4270 net.cpp:141] Setting up data
I0403 02:30:37.266638  4270 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.266664  4270 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.266681  4270 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.266718  4270 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.266775  4270 net.cpp:91] Creating Layer conv1
I0403 02:30:37.266803  4270 net.cpp:425] conv1 <- data
I0403 02:30:37.266841  4270 net.cpp:399] conv1 -> conv1
I0403 02:30:37.270079  4270 net.cpp:141] Setting up conv1
I0403 02:30:37.270118  4270 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.270138  4270 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.270181  4270 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.270212  4270 net.cpp:91] Creating Layer relu1
I0403 02:30:37.270236  4270 net.cpp:425] relu1 <- conv1
I0403 02:30:37.270257  4270 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.270285  4270 net.cpp:141] Setting up relu1
I0403 02:30:37.270308  4270 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.270325  4270 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.270342  4270 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.270365  4270 net.cpp:91] Creating Layer norm1
I0403 02:30:37.270419  4270 net.cpp:425] norm1 <- conv1
I0403 02:30:37.270442  4270 net.cpp:399] norm1 -> norm1
I0403 02:30:37.279510  4270 net.cpp:141] Setting up norm1
I0403 02:30:37.279541  4270 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.279559  4270 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.279577  4270 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.279603  4270 net.cpp:91] Creating Layer pool1
I0403 02:30:37.279623  4270 net.cpp:425] pool1 <- norm1
I0403 02:30:37.279645  4270 net.cpp:399] pool1 -> pool1
I0403 02:30:37.279719  4270 net.cpp:141] Setting up pool1
I0403 02:30:37.279750  4270 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.279768  4270 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.279788  4270 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.279815  4270 net.cpp:91] Creating Layer conv2
I0403 02:30:37.279835  4270 net.cpp:425] conv2 <- pool1
I0403 02:30:37.279860  4270 net.cpp:399] conv2 -> conv2
I0403 02:30:37.281450  4278 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.298228  4270 net.cpp:141] Setting up conv2
I0403 02:30:37.298264  4270 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.298285  4270 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.298311  4270 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.298336  4270 net.cpp:91] Creating Layer relu2
I0403 02:30:37.298355  4270 net.cpp:425] relu2 <- conv2
I0403 02:30:37.298377  4270 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.298400  4270 net.cpp:141] Setting up relu2
I0403 02:30:37.298421  4270 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.298439  4270 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.298459  4270 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.298481  4270 net.cpp:91] Creating Layer norm2
I0403 02:30:37.298499  4270 net.cpp:425] norm2 <- conv2
I0403 02:30:37.298521  4270 net.cpp:399] norm2 -> norm2
I0403 02:30:37.298578  4270 net.cpp:141] Setting up norm2
I0403 02:30:37.298605  4270 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.298624  4270 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.298641  4270 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.298666  4270 net.cpp:91] Creating Layer pool2
I0403 02:30:37.298686  4270 net.cpp:425] pool2 <- norm2
I0403 02:30:37.298707  4270 net.cpp:399] pool2 -> pool2
I0403 02:30:37.298761  4270 net.cpp:141] Setting up pool2
I0403 02:30:37.298789  4270 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.298807  4270 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.298825  4270 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.298853  4270 net.cpp:91] Creating Layer conv3
I0403 02:30:37.298873  4270 net.cpp:425] conv3 <- pool2
I0403 02:30:37.298897  4270 net.cpp:399] conv3 -> conv3
I0403 02:30:37.340764  4270 net.cpp:141] Setting up conv3
I0403 02:30:37.340804  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.340824  4270 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.340850  4270 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.340874  4270 net.cpp:91] Creating Layer relu3
I0403 02:30:37.340893  4270 net.cpp:425] relu3 <- conv3
I0403 02:30:37.340916  4270 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.340939  4270 net.cpp:141] Setting up relu3
I0403 02:30:37.340960  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.340977  4270 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.341004  4270 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.341033  4270 net.cpp:91] Creating Layer conv4
I0403 02:30:37.341053  4270 net.cpp:425] conv4 <- conv3
I0403 02:30:37.341078  4270 net.cpp:399] conv4 -> conv4
I0403 02:30:37.372627  4270 net.cpp:141] Setting up conv4
I0403 02:30:37.372666  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.372687  4270 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.372711  4270 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.372756  4270 net.cpp:91] Creating Layer relu4
I0403 02:30:37.372779  4270 net.cpp:425] relu4 <- conv4
I0403 02:30:37.372803  4270 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.372828  4270 net.cpp:141] Setting up relu4
I0403 02:30:37.372848  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.372870  4270 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.372906  4270 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.372958  4270 net.cpp:91] Creating Layer conv5
I0403 02:30:37.373008  4270 net.cpp:425] conv5 <- conv4
I0403 02:30:37.373057  4270 net.cpp:399] conv5 -> conv5
I0403 02:30:37.394219  4270 net.cpp:141] Setting up conv5
I0403 02:30:37.394259  4270 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.394279  4270 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.394305  4270 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.394330  4270 net.cpp:91] Creating Layer relu5
I0403 02:30:37.394350  4270 net.cpp:425] relu5 <- conv5
I0403 02:30:37.394371  4270 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.394395  4270 net.cpp:141] Setting up relu5
I0403 02:30:37.394418  4270 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.394434  4270 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.394453  4270 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.394474  4270 net.cpp:91] Creating Layer pool5
I0403 02:30:37.394493  4270 net.cpp:425] pool5 <- conv5
I0403 02:30:37.394513  4270 net.cpp:399] pool5 -> pool5
I0403 02:30:37.394575  4270 net.cpp:141] Setting up pool5
I0403 02:30:37.394603  4270 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.394621  4270 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.394639  4270 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.394672  4270 net.cpp:91] Creating Layer fc6
I0403 02:30:37.394695  4270 net.cpp:425] fc6 <- pool5
I0403 02:30:37.394722  4270 net.cpp:399] fc6 -> fc6
I0403 02:30:38.967111  4270 net.cpp:141] Setting up fc6
I0403 02:30:38.967211  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.967226  4270 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.967248  4270 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.967272  4270 net.cpp:91] Creating Layer relu6
I0403 02:30:38.967288  4270 net.cpp:425] relu6 <- fc6
I0403 02:30:38.967311  4270 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.967334  4270 net.cpp:141] Setting up relu6
I0403 02:30:38.967350  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.967363  4270 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.967376  4270 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.967401  4270 net.cpp:91] Creating Layer drop6
I0403 02:30:38.967417  4270 net.cpp:425] drop6 <- fc6
I0403 02:30:38.967435  4270 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.967481  4270 net.cpp:141] Setting up drop6
I0403 02:30:38.967501  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.967514  4270 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.967528  4270 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.967550  4270 net.cpp:91] Creating Layer fc7
I0403 02:30:38.967567  4270 net.cpp:425] fc7 <- fc6
I0403 02:30:38.967584  4270 net.cpp:399] fc7 -> fc7
I0403 02:30:39.589915  4270 net.cpp:141] Setting up fc7
I0403 02:30:39.590020  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.590039  4270 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.590064  4270 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.590088  4270 net.cpp:91] Creating Layer relu7
I0403 02:30:39.590106  4270 net.cpp:425] relu7 <- fc7
I0403 02:30:39.590127  4270 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.590152  4270 net.cpp:141] Setting up relu7
I0403 02:30:39.590169  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.590183  4270 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.590198  4270 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.590250  4270 net.cpp:91] Creating Layer drop7
I0403 02:30:39.590267  4270 net.cpp:425] drop7 <- fc7
I0403 02:30:39.590287  4270 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.590330  4270 net.cpp:141] Setting up drop7
I0403 02:30:39.590354  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.590369  4270 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.590384  4270 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.590406  4270 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.590421  4270 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.590442  4270 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.597216  4270 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.597245  4270 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.597261  4270 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.597280  4270 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.597306  4270 net.cpp:91] Creating Layer loss
I0403 02:30:39.597323  4270 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.597340  4270 net.cpp:425] loss <- label
I0403 02:30:39.597365  4270 net.cpp:399] loss -> loss
I0403 02:30:39.597395  4270 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.597506  4270 net.cpp:141] Setting up loss
I0403 02:30:39.597530  4270 net.cpp:148] Top shape: (1)
I0403 02:30:39.597546  4270 net.cpp:151]     with loss weight 1
I0403 02:30:39.597604  4270 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.597620  4270 net.cpp:217] loss needs backward computation.
I0403 02:30:39.597636  4270 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.597651  4270 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.597666  4270 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.597678  4270 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.597693  4270 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.597707  4270 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.597720  4270 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.597735  4270 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.597750  4270 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.597764  4270 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.597779  4270 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.597793  4270 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.597807  4270 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.597821  4270 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.597836  4270 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.597851  4270 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.597865  4270 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.597879  4270 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.597893  4270 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.597909  4270 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.597923  4270 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.597937  4270 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.597952  4270 net.cpp:219] data does not need backward computation.
I0403 02:30:39.597966  4270 net.cpp:261] This network produces output loss
I0403 02:30:39.598007  4270 net.cpp:274] Network initialization done.
I0403 02:30:39.599202  4270 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.599267  4270 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.599952  4270 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-50-50/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.600128  4270 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.600275  4270 net.cpp:91] Creating Layer data
I0403 02:30:39.600301  4270 net.cpp:399] data -> data
I0403 02:30:39.600330  4270 net.cpp:399] data -> label
I0403 02:30:39.600355  4270 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-50-50/mean.binaryproto
I0403 02:30:39.677801  4281 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-50-50/test_db
I0403 02:30:39.684823  4270 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.843122  4270 net.cpp:141] Setting up data
I0403 02:30:39.856637  4270 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.856715  4270 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.856777  4270 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.856802  4270 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.856837  4270 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.856856  4270 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.856878  4270 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.856904  4270 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.856967  4270 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.857007  4270 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.857024  4270 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.857038  4270 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.857053  4270 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.857082  4270 net.cpp:91] Creating Layer conv1
I0403 02:30:39.857098  4270 net.cpp:425] conv1 <- data
I0403 02:30:39.857117  4270 net.cpp:399] conv1 -> conv1
I0403 02:30:39.858678  4270 net.cpp:141] Setting up conv1
I0403 02:30:39.858705  4270 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.858719  4270 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.858743  4270 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.858763  4270 net.cpp:91] Creating Layer relu1
I0403 02:30:39.858779  4270 net.cpp:425] relu1 <- conv1
I0403 02:30:39.858796  4270 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.858816  4270 net.cpp:141] Setting up relu1
I0403 02:30:39.858834  4270 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.858846  4270 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.858860  4270 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.858880  4270 net.cpp:91] Creating Layer norm1
I0403 02:30:39.858896  4270 net.cpp:425] norm1 <- conv1
I0403 02:30:39.858913  4270 net.cpp:399] norm1 -> norm1
I0403 02:30:39.858963  4270 net.cpp:141] Setting up norm1
I0403 02:30:39.858995  4270 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.859014  4270 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.859028  4270 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.859047  4270 net.cpp:91] Creating Layer pool1
I0403 02:30:39.859063  4270 net.cpp:425] pool1 <- norm1
I0403 02:30:39.859081  4270 net.cpp:399] pool1 -> pool1
I0403 02:30:39.859130  4270 net.cpp:141] Setting up pool1
I0403 02:30:39.859151  4270 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.859165  4270 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.859211  4270 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.859236  4270 net.cpp:91] Creating Layer conv2
I0403 02:30:39.859251  4270 net.cpp:425] conv2 <- pool1
I0403 02:30:39.859269  4270 net.cpp:399] conv2 -> conv2
I0403 02:30:39.871522  4270 net.cpp:141] Setting up conv2
I0403 02:30:39.871554  4270 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.871572  4270 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.871592  4270 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.871613  4270 net.cpp:91] Creating Layer relu2
I0403 02:30:39.871628  4270 net.cpp:425] relu2 <- conv2
I0403 02:30:39.871645  4270 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.871666  4270 net.cpp:141] Setting up relu2
I0403 02:30:39.871687  4270 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.871709  4270 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.871734  4270 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.871762  4270 net.cpp:91] Creating Layer norm2
I0403 02:30:39.871784  4270 net.cpp:425] norm2 <- conv2
I0403 02:30:39.871804  4270 net.cpp:399] norm2 -> norm2
I0403 02:30:39.871861  4270 net.cpp:141] Setting up norm2
I0403 02:30:39.871883  4270 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.871897  4270 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.871912  4270 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.871929  4270 net.cpp:91] Creating Layer pool2
I0403 02:30:39.871944  4270 net.cpp:425] pool2 <- norm2
I0403 02:30:39.871963  4270 net.cpp:399] pool2 -> pool2
I0403 02:30:39.872014  4270 net.cpp:141] Setting up pool2
I0403 02:30:39.872035  4270 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.872050  4270 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.872063  4270 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.872087  4270 net.cpp:91] Creating Layer conv3
I0403 02:30:39.872102  4270 net.cpp:425] conv3 <- pool2
I0403 02:30:39.872120  4270 net.cpp:399] conv3 -> conv3
I0403 02:30:39.907089  4270 net.cpp:141] Setting up conv3
I0403 02:30:39.907145  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.907160  4270 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.907183  4270 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.907207  4270 net.cpp:91] Creating Layer relu3
I0403 02:30:39.907224  4270 net.cpp:425] relu3 <- conv3
I0403 02:30:39.907243  4270 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.907274  4270 net.cpp:141] Setting up relu3
I0403 02:30:39.907291  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.907305  4270 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.907326  4270 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.907351  4270 net.cpp:91] Creating Layer conv4
I0403 02:30:39.907366  4270 net.cpp:425] conv4 <- conv3
I0403 02:30:39.907385  4270 net.cpp:399] conv4 -> conv4
I0403 02:30:39.932677  4270 net.cpp:141] Setting up conv4
I0403 02:30:39.932713  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.932728  4270 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.932746  4270 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.932765  4270 net.cpp:91] Creating Layer relu4
I0403 02:30:39.932780  4270 net.cpp:425] relu4 <- conv4
I0403 02:30:39.932798  4270 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.932819  4270 net.cpp:141] Setting up relu4
I0403 02:30:39.932835  4270 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.932850  4270 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.932863  4270 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.932885  4270 net.cpp:91] Creating Layer conv5
I0403 02:30:39.932900  4270 net.cpp:425] conv5 <- conv4
I0403 02:30:39.932919  4270 net.cpp:399] conv5 -> conv5
I0403 02:30:39.949627  4270 net.cpp:141] Setting up conv5
I0403 02:30:39.949658  4270 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.949673  4270 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.949725  4270 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.949746  4270 net.cpp:91] Creating Layer relu5
I0403 02:30:39.949762  4270 net.cpp:425] relu5 <- conv5
I0403 02:30:39.949779  4270 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.949798  4270 net.cpp:141] Setting up relu5
I0403 02:30:39.949815  4270 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.949829  4270 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.949846  4270 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.949873  4270 net.cpp:91] Creating Layer pool5
I0403 02:30:39.949899  4270 net.cpp:425] pool5 <- conv5
I0403 02:30:39.949928  4270 net.cpp:399] pool5 -> pool5
I0403 02:30:39.949992  4270 net.cpp:141] Setting up pool5
I0403 02:30:39.950016  4270 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.950031  4270 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.950044  4270 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.950067  4270 net.cpp:91] Creating Layer fc6
I0403 02:30:39.950084  4270 net.cpp:425] fc6 <- pool5
I0403 02:30:39.950103  4270 net.cpp:399] fc6 -> fc6
I0403 02:30:41.376214  4270 net.cpp:141] Setting up fc6
I0403 02:30:41.376324  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.376340  4270 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.376363  4270 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.376387  4270 net.cpp:91] Creating Layer relu6
I0403 02:30:41.376405  4270 net.cpp:425] relu6 <- fc6
I0403 02:30:41.376426  4270 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.376451  4270 net.cpp:141] Setting up relu6
I0403 02:30:41.376467  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.376480  4270 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.376493  4270 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.376512  4270 net.cpp:91] Creating Layer drop6
I0403 02:30:41.376526  4270 net.cpp:425] drop6 <- fc6
I0403 02:30:41.376544  4270 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.376584  4270 net.cpp:141] Setting up drop6
I0403 02:30:41.376603  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.376616  4270 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.376631  4270 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.376652  4270 net.cpp:91] Creating Layer fc7
I0403 02:30:41.376668  4270 net.cpp:425] fc7 <- fc6
I0403 02:30:41.376685  4270 net.cpp:399] fc7 -> fc7
I0403 02:30:42.005437  4270 net.cpp:141] Setting up fc7
I0403 02:30:42.005529  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.005548  4270 net.cpp:156] Memory required for data: 828248800
I0403 02:30:42.005573  4270 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:42.005599  4270 net.cpp:91] Creating Layer relu7
I0403 02:30:42.005620  4270 net.cpp:425] relu7 <- fc7
I0403 02:30:42.005643  4270 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:42.005669  4270 net.cpp:141] Setting up relu7
I0403 02:30:42.005687  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.005702  4270 net.cpp:156] Memory required for data: 829887200
I0403 02:30:42.005717  4270 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:42.005738  4270 net.cpp:91] Creating Layer drop7
I0403 02:30:42.005756  4270 net.cpp:425] drop7 <- fc7
I0403 02:30:42.005777  4270 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:42.005820  4270 net.cpp:141] Setting up drop7
I0403 02:30:42.005846  4270 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.005863  4270 net.cpp:156] Memory required for data: 831525600
I0403 02:30:42.005879  4270 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:42.005903  4270 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:42.005918  4270 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:42.005941  4270 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:42.012786  4270 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:42.012820  4270 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.012835  4270 net.cpp:156] Memory required for data: 831540800
I0403 02:30:42.012886  4270 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.012908  4270 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.012931  4270 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:42.012951  4270 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.012974  4270 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.013034  4270 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.013059  4270 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.013075  4270 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.013090  4270 net.cpp:156] Memory required for data: 831571200
I0403 02:30:42.013105  4270 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.013124  4270 net.cpp:91] Creating Layer loss
I0403 02:30:42.013141  4270 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.013159  4270 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:42.013177  4270 net.cpp:399] loss -> loss
I0403 02:30:42.013205  4270 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.013308  4270 net.cpp:141] Setting up loss
I0403 02:30:42.013331  4270 net.cpp:148] Top shape: (1)
I0403 02:30:42.013347  4270 net.cpp:151]     with loss weight 1
I0403 02:30:42.013373  4270 net.cpp:156] Memory required for data: 831571204
I0403 02:30:42.013389  4270 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:42.013411  4270 net.cpp:91] Creating Layer accuracy
I0403 02:30:42.013427  4270 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.013447  4270 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:42.013468  4270 net.cpp:399] accuracy -> accuracy
I0403 02:30:42.013500  4270 net.cpp:141] Setting up accuracy
I0403 02:30:42.013523  4270 net.cpp:148] Top shape: (1)
I0403 02:30:42.013548  4270 net.cpp:156] Memory required for data: 831571208
I0403 02:30:42.013566  4270 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:42.013586  4270 net.cpp:217] loss needs backward computation.
I0403 02:30:42.013602  4270 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:42.013617  4270 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:42.013633  4270 net.cpp:217] drop7 needs backward computation.
I0403 02:30:42.013648  4270 net.cpp:217] relu7 needs backward computation.
I0403 02:30:42.013662  4270 net.cpp:217] fc7 needs backward computation.
I0403 02:30:42.013677  4270 net.cpp:217] drop6 needs backward computation.
I0403 02:30:42.013691  4270 net.cpp:217] relu6 needs backward computation.
I0403 02:30:42.013707  4270 net.cpp:217] fc6 needs backward computation.
I0403 02:30:42.013726  4270 net.cpp:217] pool5 needs backward computation.
I0403 02:30:42.013741  4270 net.cpp:217] relu5 needs backward computation.
I0403 02:30:42.013756  4270 net.cpp:217] conv5 needs backward computation.
I0403 02:30:42.013770  4270 net.cpp:217] relu4 needs backward computation.
I0403 02:30:42.013785  4270 net.cpp:217] conv4 needs backward computation.
I0403 02:30:42.013800  4270 net.cpp:217] relu3 needs backward computation.
I0403 02:30:42.013824  4270 net.cpp:217] conv3 needs backward computation.
I0403 02:30:42.013840  4270 net.cpp:217] pool2 needs backward computation.
I0403 02:30:42.013856  4270 net.cpp:217] norm2 needs backward computation.
I0403 02:30:42.013871  4270 net.cpp:217] relu2 needs backward computation.
I0403 02:30:42.013893  4270 net.cpp:217] conv2 needs backward computation.
I0403 02:30:42.013909  4270 net.cpp:217] pool1 needs backward computation.
I0403 02:30:42.013924  4270 net.cpp:217] norm1 needs backward computation.
I0403 02:30:42.013939  4270 net.cpp:217] relu1 needs backward computation.
I0403 02:30:42.013959  4270 net.cpp:217] conv1 needs backward computation.
I0403 02:30:42.013996  4270 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:42.014015  4270 net.cpp:219] data does not need backward computation.
I0403 02:30:42.014031  4270 net.cpp:261] This network produces output accuracy
I0403 02:30:42.014047  4270 net.cpp:261] This network produces output loss
I0403 02:30:42.014084  4270 net.cpp:274] Network initialization done.
I0403 02:30:42.014219  4270 solver.cpp:60] Solver scaffolding done.
I0403 02:30:42.014742  4270 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.222179  4270 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.222316  4270 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.222358  4270 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.222445  4270 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.661062  4270 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.704144  4270 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.820534  4270 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.820618  4270 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.820637  4270 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.820683  4270 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.291499  4270 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.333079  4270 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.375360  4270 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.656618  4270 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.368491  4270 parallel.cpp:425] Starting Optimization
I0403 02:30:48.369021  4270 solver.cpp:279] Solving 
I0403 02:30:48.369055  4270 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.369202  4270 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:51.059602  4270 solver.cpp:404]     Test net output #0: accuracy = 0.0203297
I0403 02:31:51.066357  4270 solver.cpp:404]     Test net output #1: loss = 3.85556 (* 1 = 3.85556 loss)
I0403 02:31:51.668480  4270 solver.cpp:228] Iteration 0, loss = 4.29572
I0403 02:31:51.674559  4270 solver.cpp:244]     Train net output #0: loss = 4.29572 (* 1 = 4.29572 loss)
I0403 02:31:51.869343  4270 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:01.516814  4270 solver.cpp:228] Iteration 13, loss = 1.6115
I0403 02:32:01.522749  4270 solver.cpp:244]     Train net output #0: loss = 1.6115 (* 1 = 1.6115 loss)
I0403 02:32:01.731310  4270 sgd_solver.cpp:106] Iteration 13, lr = 0.005
I0403 02:32:11.256458  4270 solver.cpp:228] Iteration 26, loss = 0.786727
I0403 02:32:11.263391  4270 solver.cpp:244]     Train net output #0: loss = 0.786727 (* 1 = 0.786727 loss)
I0403 02:32:11.485780  4270 sgd_solver.cpp:106] Iteration 26, lr = 0.005
I0403 02:32:21.091887  4270 solver.cpp:228] Iteration 39, loss = 0.499649
I0403 02:32:21.099460  4270 solver.cpp:244]     Train net output #0: loss = 0.499649 (* 1 = 0.499649 loss)
I0403 02:32:21.293308  4270 sgd_solver.cpp:106] Iteration 39, lr = 0.005
I0403 02:32:30.917932  4270 solver.cpp:228] Iteration 52, loss = 0.490768
I0403 02:32:30.923665  4270 solver.cpp:244]     Train net output #0: loss = 0.490768 (* 1 = 0.490768 loss)
I0403 02:32:31.146337  4270 sgd_solver.cpp:106] Iteration 52, lr = 0.005
I0403 02:32:40.756013  4270 solver.cpp:228] Iteration 65, loss = 0.483754
I0403 02:32:40.763077  4270 solver.cpp:244]     Train net output #0: loss = 0.483754 (* 1 = 0.483754 loss)
I0403 02:32:40.953533  4270 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 02:32:50.628106  4270 solver.cpp:228] Iteration 78, loss = 0.291387
I0403 02:32:50.633782  4270 solver.cpp:244]     Train net output #0: loss = 0.291387 (* 1 = 0.291387 loss)
I0403 02:32:50.846894  4270 sgd_solver.cpp:106] Iteration 78, lr = 0.005
I0403 02:33:00.475052  4270 solver.cpp:228] Iteration 91, loss = 0.264859
I0403 02:33:00.480713  4270 solver.cpp:244]     Train net output #0: loss = 0.264859 (* 1 = 0.264859 loss)
I0403 02:33:00.678091  4270 sgd_solver.cpp:106] Iteration 91, lr = 0.005
I0403 02:33:10.288043  4270 solver.cpp:228] Iteration 104, loss = 0.288142
I0403 02:33:10.293613  4270 solver.cpp:244]     Train net output #0: loss = 0.288142 (* 1 = 0.288142 loss)
I0403 02:33:10.500911  4270 sgd_solver.cpp:106] Iteration 104, lr = 0.005
I0403 02:33:20.262049  4270 solver.cpp:228] Iteration 117, loss = 0.175309
I0403 02:33:20.270246  4270 solver.cpp:244]     Train net output #0: loss = 0.175309 (* 1 = 0.175309 loss)
I0403 02:33:20.464886  4270 sgd_solver.cpp:106] Iteration 117, lr = 0.005
I0403 02:33:30.072777  4270 solver.cpp:228] Iteration 130, loss = 0.500407
I0403 02:33:30.072880  4270 solver.cpp:244]     Train net output #0: loss = 0.500407 (* 1 = 0.500407 loss)
I0403 02:33:30.284478  4270 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:33:40.070416  4270 solver.cpp:228] Iteration 143, loss = 0.147594
I0403 02:33:40.077143  4270 solver.cpp:244]     Train net output #0: loss = 0.147594 (* 1 = 0.147594 loss)
I0403 02:33:40.270508  4270 sgd_solver.cpp:106] Iteration 143, lr = 0.005
I0403 02:33:50.121567  4270 solver.cpp:228] Iteration 156, loss = 0.206244
I0403 02:33:50.126685  4270 solver.cpp:244]     Train net output #0: loss = 0.206244 (* 1 = 0.206244 loss)
I0403 02:33:50.354215  4270 sgd_solver.cpp:106] Iteration 156, lr = 0.005
I0403 02:34:00.190183  4270 solver.cpp:228] Iteration 169, loss = 0.140287
I0403 02:34:00.195804  4270 solver.cpp:244]     Train net output #0: loss = 0.140287 (* 1 = 0.140287 loss)
I0403 02:34:00.399085  4270 sgd_solver.cpp:106] Iteration 169, lr = 0.005
I0403 02:34:10.111429  4270 solver.cpp:228] Iteration 182, loss = 0.284365
I0403 02:34:10.118013  4270 solver.cpp:244]     Train net output #0: loss = 0.284365 (* 1 = 0.284365 loss)
I0403 02:34:10.360129  4270 sgd_solver.cpp:106] Iteration 182, lr = 0.005
I0403 02:34:19.956573  4270 solver.cpp:228] Iteration 195, loss = 0.170622
I0403 02:34:19.962600  4270 solver.cpp:244]     Train net output #0: loss = 0.170622 (* 1 = 0.170622 loss)
I0403 02:34:20.168326  4270 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 02:34:30.045610  4270 solver.cpp:228] Iteration 208, loss = 0.223692
I0403 02:34:30.051014  4270 solver.cpp:244]     Train net output #0: loss = 0.223692 (* 1 = 0.223692 loss)
I0403 02:34:30.249469  4270 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 02:34:40.018954  4270 solver.cpp:228] Iteration 221, loss = 0.168712
I0403 02:34:40.025059  4270 solver.cpp:244]     Train net output #0: loss = 0.168712 (* 1 = 0.168712 loss)
I0403 02:34:40.223637  4270 sgd_solver.cpp:106] Iteration 221, lr = 0.005
I0403 02:34:49.976415  4270 solver.cpp:228] Iteration 234, loss = 0.0575914
I0403 02:34:49.982292  4270 solver.cpp:244]     Train net output #0: loss = 0.0575913 (* 1 = 0.0575913 loss)
I0403 02:34:50.230115  4270 sgd_solver.cpp:106] Iteration 234, lr = 0.005
I0403 02:34:59.989586  4270 solver.cpp:228] Iteration 247, loss = 0.0458367
I0403 02:34:59.994947  4270 solver.cpp:244]     Train net output #0: loss = 0.0458366 (* 1 = 0.0458366 loss)
I0403 02:35:00.205826  4270 sgd_solver.cpp:106] Iteration 247, lr = 0.005
I0403 02:35:09.914152  4270 solver.cpp:228] Iteration 260, loss = 0.104269
I0403 02:35:09.920419  4270 solver.cpp:244]     Train net output #0: loss = 0.104269 (* 1 = 0.104269 loss)
I0403 02:35:10.114068  4270 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:35:16.352248  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_269.caffemodel
I0403 02:35:19.266767  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_269.solverstate
I0403 02:35:21.149716  4270 solver.cpp:337] Iteration 269, Testing net (#0)
I0403 02:36:22.290339  4270 solver.cpp:404]     Test net output #0: accuracy = 0.949743
I0403 02:36:22.296788  4270 solver.cpp:404]     Test net output #1: loss = 0.148092 (* 1 = 0.148092 loss)
I0403 02:36:25.842650  4270 solver.cpp:228] Iteration 273, loss = 0.117625
I0403 02:36:25.848675  4270 solver.cpp:244]     Train net output #0: loss = 0.117625 (* 1 = 0.117625 loss)
I0403 02:36:26.047377  4270 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 02:36:35.749269  4270 solver.cpp:228] Iteration 286, loss = 0.194391
I0403 02:36:35.754328  4270 solver.cpp:244]     Train net output #0: loss = 0.194391 (* 1 = 0.194391 loss)
I0403 02:36:35.958809  4270 sgd_solver.cpp:106] Iteration 286, lr = 0.005
I0403 02:36:45.512878  4270 solver.cpp:228] Iteration 299, loss = 0.0671082
I0403 02:36:45.522948  4270 solver.cpp:244]     Train net output #0: loss = 0.0671081 (* 1 = 0.0671081 loss)
I0403 02:36:45.709799  4270 sgd_solver.cpp:106] Iteration 299, lr = 0.005
I0403 02:36:55.559770  4270 solver.cpp:228] Iteration 312, loss = 0.101449
I0403 02:36:55.566798  4270 solver.cpp:244]     Train net output #0: loss = 0.101448 (* 1 = 0.101448 loss)
I0403 02:36:55.791999  4270 sgd_solver.cpp:106] Iteration 312, lr = 0.005
I0403 02:37:05.446348  4270 solver.cpp:228] Iteration 325, loss = 0.0429216
I0403 02:37:05.452400  4270 solver.cpp:244]     Train net output #0: loss = 0.0429215 (* 1 = 0.0429215 loss)
I0403 02:37:05.673132  4270 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 02:37:15.556135  4270 solver.cpp:228] Iteration 338, loss = 0.0922033
I0403 02:37:15.562590  4270 solver.cpp:244]     Train net output #0: loss = 0.0922033 (* 1 = 0.0922033 loss)
I0403 02:37:15.800222  4270 sgd_solver.cpp:106] Iteration 338, lr = 0.005
I0403 02:37:25.707092  4270 solver.cpp:228] Iteration 351, loss = 0.318568
I0403 02:37:25.712855  4270 solver.cpp:244]     Train net output #0: loss = 0.318567 (* 1 = 0.318567 loss)
I0403 02:37:25.881686  4270 sgd_solver.cpp:106] Iteration 351, lr = 0.005
I0403 02:37:35.534533  4270 solver.cpp:228] Iteration 364, loss = 0.0975862
I0403 02:37:35.541275  4270 solver.cpp:244]     Train net output #0: loss = 0.0975861 (* 1 = 0.0975861 loss)
I0403 02:37:35.784358  4270 sgd_solver.cpp:106] Iteration 364, lr = 0.005
I0403 02:37:45.430866  4270 solver.cpp:228] Iteration 377, loss = 0.0641901
I0403 02:37:45.436731  4270 solver.cpp:244]     Train net output #0: loss = 0.06419 (* 1 = 0.06419 loss)
I0403 02:37:45.714045  4270 sgd_solver.cpp:106] Iteration 377, lr = 0.005
I0403 02:37:55.548384  4270 solver.cpp:228] Iteration 390, loss = 0.0936634
I0403 02:37:55.548501  4270 solver.cpp:244]     Train net output #0: loss = 0.0936633 (* 1 = 0.0936633 loss)
I0403 02:37:55.758970  4270 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:38:05.646265  4270 solver.cpp:228] Iteration 403, loss = 0.122707
I0403 02:38:05.646381  4270 solver.cpp:244]     Train net output #0: loss = 0.122707 (* 1 = 0.122707 loss)
I0403 02:38:05.852716  4270 sgd_solver.cpp:106] Iteration 403, lr = 0.005
I0403 02:38:15.730456  4270 solver.cpp:228] Iteration 416, loss = 0.0546696
I0403 02:38:15.735625  4270 solver.cpp:244]     Train net output #0: loss = 0.0546695 (* 1 = 0.0546695 loss)
I0403 02:38:15.902073  4270 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 02:38:25.745337  4270 solver.cpp:228] Iteration 429, loss = 0.0315997
I0403 02:38:25.751422  4270 solver.cpp:244]     Train net output #0: loss = 0.0315996 (* 1 = 0.0315996 loss)
I0403 02:38:25.966800  4270 sgd_solver.cpp:106] Iteration 429, lr = 0.005
I0403 02:38:35.639531  4270 solver.cpp:228] Iteration 442, loss = 0.100599
I0403 02:38:35.645558  4270 solver.cpp:244]     Train net output #0: loss = 0.100599 (* 1 = 0.100599 loss)
I0403 02:38:35.934940  4270 sgd_solver.cpp:106] Iteration 442, lr = 0.005
I0403 02:38:45.551573  4270 solver.cpp:228] Iteration 455, loss = 0.141489
I0403 02:38:45.551687  4270 solver.cpp:244]     Train net output #0: loss = 0.141489 (* 1 = 0.141489 loss)
I0403 02:38:45.835026  4270 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 02:38:55.525173  4270 solver.cpp:228] Iteration 468, loss = 0.108648
I0403 02:38:55.525285  4270 solver.cpp:244]     Train net output #0: loss = 0.108648 (* 1 = 0.108648 loss)
I0403 02:38:55.731812  4270 sgd_solver.cpp:106] Iteration 468, lr = 0.005
I0403 02:39:05.537212  4270 solver.cpp:228] Iteration 481, loss = 0.0304204
I0403 02:39:05.537528  4270 solver.cpp:244]     Train net output #0: loss = 0.0304203 (* 1 = 0.0304203 loss)
I0403 02:39:05.779728  4270 sgd_solver.cpp:106] Iteration 481, lr = 0.005
I0403 02:39:15.341541  4270 solver.cpp:228] Iteration 494, loss = 0.163459
I0403 02:39:15.341652  4270 solver.cpp:244]     Train net output #0: loss = 0.163459 (* 1 = 0.163459 loss)
I0403 02:39:15.546741  4270 sgd_solver.cpp:106] Iteration 494, lr = 0.005
I0403 02:39:25.165784  4270 solver.cpp:228] Iteration 507, loss = 0.179819
I0403 02:39:25.165902  4270 solver.cpp:244]     Train net output #0: loss = 0.179819 (* 1 = 0.179819 loss)
I0403 02:39:25.390570  4270 sgd_solver.cpp:106] Iteration 507, lr = 0.005
I0403 02:39:35.115341  4270 solver.cpp:228] Iteration 520, loss = 0.120801
I0403 02:39:35.115458  4270 solver.cpp:244]     Train net output #0: loss = 0.1208 (* 1 = 0.1208 loss)
I0403 02:39:35.352787  4270 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:39:45.103454  4270 solver.cpp:228] Iteration 533, loss = 0.0536694
I0403 02:39:45.103763  4270 solver.cpp:244]     Train net output #0: loss = 0.0536694 (* 1 = 0.0536694 loss)
I0403 02:39:45.289186  4270 sgd_solver.cpp:106] Iteration 533, lr = 0.005
I0403 02:39:48.369817  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_538.caffemodel
I0403 02:39:51.153170  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_538.solverstate
I0403 02:39:53.037327  4270 solver.cpp:337] Iteration 538, Testing net (#0)
I0403 02:40:54.123072  4270 solver.cpp:404]     Test net output #0: accuracy = 0.969158
I0403 02:40:54.133935  4270 solver.cpp:404]     Test net output #1: loss = 0.100134 (* 1 = 0.100134 loss)
I0403 02:41:00.862818  4270 solver.cpp:228] Iteration 546, loss = 0.124758
I0403 02:41:00.869648  4270 solver.cpp:244]     Train net output #0: loss = 0.124758 (* 1 = 0.124758 loss)
I0403 02:41:01.084355  4270 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 02:41:10.904491  4270 solver.cpp:228] Iteration 559, loss = 0.0489977
I0403 02:41:10.911314  4270 solver.cpp:244]     Train net output #0: loss = 0.0489976 (* 1 = 0.0489976 loss)
I0403 02:41:11.112906  4270 sgd_solver.cpp:106] Iteration 559, lr = 0.005
I0403 02:41:21.048251  4270 solver.cpp:228] Iteration 572, loss = 0.0389916
I0403 02:41:21.054210  4270 solver.cpp:244]     Train net output #0: loss = 0.0389916 (* 1 = 0.0389916 loss)
I0403 02:41:21.252691  4270 sgd_solver.cpp:106] Iteration 572, lr = 0.005
I0403 02:41:30.778573  4270 solver.cpp:228] Iteration 585, loss = 0.0336792
I0403 02:41:30.784888  4270 solver.cpp:244]     Train net output #0: loss = 0.0336791 (* 1 = 0.0336791 loss)
I0403 02:41:30.996773  4270 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 02:41:40.617844  4270 solver.cpp:228] Iteration 598, loss = 0.0505544
I0403 02:41:40.624158  4270 solver.cpp:244]     Train net output #0: loss = 0.0505543 (* 1 = 0.0505543 loss)
I0403 02:41:40.824051  4270 sgd_solver.cpp:106] Iteration 598, lr = 0.005
I0403 02:41:50.496212  4270 solver.cpp:228] Iteration 611, loss = 0.0298617
I0403 02:41:50.502667  4270 solver.cpp:244]     Train net output #0: loss = 0.0298616 (* 1 = 0.0298616 loss)
I0403 02:41:50.748109  4270 sgd_solver.cpp:106] Iteration 611, lr = 0.005
I0403 02:42:00.718021  4270 solver.cpp:228] Iteration 624, loss = 0.0920131
I0403 02:42:00.723924  4270 solver.cpp:244]     Train net output #0: loss = 0.092013 (* 1 = 0.092013 loss)
I0403 02:42:00.936921  4270 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 02:42:10.597390  4270 solver.cpp:228] Iteration 637, loss = 0.0736481
I0403 02:42:10.601789  4270 solver.cpp:244]     Train net output #0: loss = 0.0736479 (* 1 = 0.0736479 loss)
I0403 02:42:10.814347  4270 sgd_solver.cpp:106] Iteration 637, lr = 0.005
I0403 02:42:20.477946  4270 solver.cpp:228] Iteration 650, loss = 0.0680998
I0403 02:42:20.482887  4270 solver.cpp:244]     Train net output #0: loss = 0.0680997 (* 1 = 0.0680997 loss)
I0403 02:42:20.691303  4270 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:42:30.454990  4270 solver.cpp:228] Iteration 663, loss = 0.0464209
I0403 02:42:30.461143  4270 solver.cpp:244]     Train net output #0: loss = 0.0464207 (* 1 = 0.0464207 loss)
I0403 02:42:30.677310  4270 sgd_solver.cpp:106] Iteration 663, lr = 0.005
I0403 02:42:40.306071  4270 solver.cpp:228] Iteration 676, loss = 0.0242914
I0403 02:42:40.312579  4270 solver.cpp:244]     Train net output #0: loss = 0.0242913 (* 1 = 0.0242913 loss)
I0403 02:42:40.532028  4270 sgd_solver.cpp:106] Iteration 676, lr = 0.005
I0403 02:42:50.178231  4270 solver.cpp:228] Iteration 689, loss = 0.0735774
I0403 02:42:50.184551  4270 solver.cpp:244]     Train net output #0: loss = 0.0735772 (* 1 = 0.0735772 loss)
I0403 02:42:50.437064  4270 sgd_solver.cpp:106] Iteration 689, lr = 0.005
I0403 02:43:00.056618  4270 solver.cpp:228] Iteration 702, loss = 0.00270593
I0403 02:43:00.062333  4270 solver.cpp:244]     Train net output #0: loss = 0.00270581 (* 1 = 0.00270581 loss)
I0403 02:43:00.270900  4270 sgd_solver.cpp:106] Iteration 702, lr = 0.005
I0403 02:43:09.903070  4270 solver.cpp:228] Iteration 715, loss = 0.04661
I0403 02:43:09.909775  4270 solver.cpp:244]     Train net output #0: loss = 0.0466098 (* 1 = 0.0466098 loss)
I0403 02:43:10.113358  4270 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 02:43:20.018573  4270 solver.cpp:228] Iteration 728, loss = 0.0670653
I0403 02:43:20.025746  4270 solver.cpp:244]     Train net output #0: loss = 0.0670652 (* 1 = 0.0670652 loss)
I0403 02:43:20.247434  4270 sgd_solver.cpp:106] Iteration 728, lr = 0.005
I0403 02:43:30.072854  4270 solver.cpp:228] Iteration 741, loss = 0.101876
I0403 02:43:30.078901  4270 solver.cpp:244]     Train net output #0: loss = 0.101876 (* 1 = 0.101876 loss)
I0403 02:43:30.318605  4270 sgd_solver.cpp:106] Iteration 741, lr = 0.005
I0403 02:43:39.953266  4270 solver.cpp:228] Iteration 754, loss = 0.120325
I0403 02:43:39.960049  4270 solver.cpp:244]     Train net output #0: loss = 0.120325 (* 1 = 0.120325 loss)
I0403 02:43:40.190930  4270 sgd_solver.cpp:106] Iteration 754, lr = 0.005
I0403 02:43:49.901793  4270 solver.cpp:228] Iteration 767, loss = 0.0505399
I0403 02:43:49.908346  4270 solver.cpp:244]     Train net output #0: loss = 0.0505398 (* 1 = 0.0505398 loss)
I0403 02:43:50.108235  4270 sgd_solver.cpp:106] Iteration 767, lr = 0.005
I0403 02:43:59.815292  4270 solver.cpp:228] Iteration 780, loss = 0.012565
I0403 02:43:59.822522  4270 solver.cpp:244]     Train net output #0: loss = 0.0125649 (* 1 = 0.0125649 loss)
I0403 02:44:00.028175  4270 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:44:09.797770  4270 solver.cpp:228] Iteration 793, loss = 0.123981
I0403 02:44:09.812053  4270 solver.cpp:244]     Train net output #0: loss = 0.123981 (* 1 = 0.123981 loss)
I0403 02:44:09.981748  4270 sgd_solver.cpp:106] Iteration 793, lr = 0.005
I0403 02:44:19.698966  4270 solver.cpp:228] Iteration 806, loss = 0.0175957
I0403 02:44:19.705314  4270 solver.cpp:244]     Train net output #0: loss = 0.0175956 (* 1 = 0.0175956 loss)
I0403 02:44:19.911218  4270 sgd_solver.cpp:106] Iteration 806, lr = 0.005
I0403 02:44:19.911453  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_807.caffemodel
I0403 02:44:22.756294  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_807.solverstate
I0403 02:44:24.575855  4270 solver.cpp:337] Iteration 807, Testing net (#0)
I0403 02:45:25.510092  4270 solver.cpp:404]     Test net output #0: accuracy = 0.971576
I0403 02:45:25.516511  4270 solver.cpp:404]     Test net output #1: loss = 0.0894687 (* 1 = 0.0894687 loss)
I0403 02:45:35.169795  4270 solver.cpp:228] Iteration 819, loss = 0.103956
I0403 02:45:35.176353  4270 solver.cpp:244]     Train net output #0: loss = 0.103956 (* 1 = 0.103956 loss)
I0403 02:45:35.397490  4270 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 02:45:45.025089  4270 solver.cpp:228] Iteration 832, loss = 0.0478193
I0403 02:45:45.032052  4270 solver.cpp:244]     Train net output #0: loss = 0.0478192 (* 1 = 0.0478192 loss)
I0403 02:45:45.258445  4270 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 02:45:55.059638  4270 solver.cpp:228] Iteration 845, loss = 0.00557102
I0403 02:45:55.066274  4270 solver.cpp:244]     Train net output #0: loss = 0.00557091 (* 1 = 0.00557091 loss)
I0403 02:45:55.201213  4270 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 02:46:04.998045  4270 solver.cpp:228] Iteration 858, loss = 0.0533081
I0403 02:46:05.003744  4270 solver.cpp:244]     Train net output #0: loss = 0.053308 (* 1 = 0.053308 loss)
I0403 02:46:05.190526  4270 sgd_solver.cpp:106] Iteration 858, lr = 0.005
I0403 02:46:14.768738  4270 solver.cpp:228] Iteration 871, loss = 0.0380396
I0403 02:46:14.774320  4270 solver.cpp:244]     Train net output #0: loss = 0.0380395 (* 1 = 0.0380395 loss)
I0403 02:46:14.984030  4270 sgd_solver.cpp:106] Iteration 871, lr = 0.005
I0403 02:46:24.914098  4270 solver.cpp:228] Iteration 884, loss = 0.0301987
I0403 02:46:24.919560  4270 solver.cpp:244]     Train net output #0: loss = 0.0301986 (* 1 = 0.0301986 loss)
I0403 02:46:25.089407  4270 sgd_solver.cpp:106] Iteration 884, lr = 0.005
I0403 02:46:34.950719  4270 solver.cpp:228] Iteration 897, loss = 0.0245791
I0403 02:46:34.956888  4270 solver.cpp:244]     Train net output #0: loss = 0.024579 (* 1 = 0.024579 loss)
I0403 02:46:35.126466  4270 sgd_solver.cpp:106] Iteration 897, lr = 0.005
I0403 02:46:44.846058  4270 solver.cpp:228] Iteration 910, loss = 0.0616684
I0403 02:46:44.851686  4270 solver.cpp:244]     Train net output #0: loss = 0.0616683 (* 1 = 0.0616683 loss)
I0403 02:46:45.090623  4270 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:46:55.043058  4270 solver.cpp:228] Iteration 923, loss = 0.0168916
I0403 02:46:55.049305  4270 solver.cpp:244]     Train net output #0: loss = 0.0168915 (* 1 = 0.0168915 loss)
I0403 02:46:55.262642  4270 sgd_solver.cpp:106] Iteration 923, lr = 0.005
I0403 02:47:04.944766  4270 solver.cpp:228] Iteration 936, loss = 0.0328606
I0403 02:47:04.950803  4270 solver.cpp:244]     Train net output #0: loss = 0.0328605 (* 1 = 0.0328605 loss)
I0403 02:47:05.167495  4270 sgd_solver.cpp:106] Iteration 936, lr = 0.005
I0403 02:47:14.832952  4270 solver.cpp:228] Iteration 949, loss = 0.00762111
I0403 02:47:14.838800  4270 solver.cpp:244]     Train net output #0: loss = 0.007621 (* 1 = 0.007621 loss)
I0403 02:47:15.046651  4270 sgd_solver.cpp:106] Iteration 949, lr = 0.005
I0403 02:47:24.776756  4270 solver.cpp:228] Iteration 962, loss = 0.0111726
I0403 02:47:24.783212  4270 solver.cpp:244]     Train net output #0: loss = 0.0111725 (* 1 = 0.0111725 loss)
I0403 02:47:25.005066  4270 sgd_solver.cpp:106] Iteration 962, lr = 0.005
I0403 02:47:34.870019  4270 solver.cpp:228] Iteration 975, loss = 0.0802581
I0403 02:47:34.875720  4270 solver.cpp:244]     Train net output #0: loss = 0.080258 (* 1 = 0.080258 loss)
I0403 02:47:35.067018  4270 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 02:47:44.777350  4270 solver.cpp:228] Iteration 988, loss = 0.0460254
I0403 02:47:44.783040  4270 solver.cpp:244]     Train net output #0: loss = 0.0460253 (* 1 = 0.0460253 loss)
I0403 02:47:44.983902  4270 sgd_solver.cpp:106] Iteration 988, lr = 0.005
I0403 02:47:54.748461  4270 solver.cpp:228] Iteration 1001, loss = 0.0500474
I0403 02:47:54.755162  4270 solver.cpp:244]     Train net output #0: loss = 0.0500473 (* 1 = 0.0500473 loss)
I0403 02:47:54.896034  4270 sgd_solver.cpp:106] Iteration 1001, lr = 0.005
I0403 02:48:04.686187  4270 solver.cpp:228] Iteration 1014, loss = 0.0142279
I0403 02:48:04.690835  4270 solver.cpp:244]     Train net output #0: loss = 0.0142278 (* 1 = 0.0142278 loss)
I0403 02:48:04.913185  4270 sgd_solver.cpp:106] Iteration 1014, lr = 0.005
I0403 02:48:14.616379  4270 solver.cpp:228] Iteration 1027, loss = 0.019521
I0403 02:48:14.621493  4270 solver.cpp:244]     Train net output #0: loss = 0.0195209 (* 1 = 0.0195209 loss)
I0403 02:48:14.837944  4270 sgd_solver.cpp:106] Iteration 1027, lr = 0.005
I0403 02:48:24.570247  4270 solver.cpp:228] Iteration 1040, loss = 0.00814243
I0403 02:48:24.576633  4270 solver.cpp:244]     Train net output #0: loss = 0.00814235 (* 1 = 0.00814235 loss)
I0403 02:48:24.790479  4270 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:48:34.506996  4270 solver.cpp:228] Iteration 1053, loss = 0.0973435
I0403 02:48:34.513254  4270 solver.cpp:244]     Train net output #0: loss = 0.0973434 (* 1 = 0.0973434 loss)
I0403 02:48:34.723135  4270 sgd_solver.cpp:106] Iteration 1053, lr = 0.005
I0403 02:48:44.400944  4270 solver.cpp:228] Iteration 1066, loss = 0.0242562
I0403 02:48:44.406527  4270 solver.cpp:244]     Train net output #0: loss = 0.0242561 (* 1 = 0.0242561 loss)
I0403 02:48:44.684608  4270 sgd_solver.cpp:106] Iteration 1066, lr = 0.005
I0403 02:48:51.537721  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1076.caffemodel
I0403 02:48:54.338711  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1076.solverstate
I0403 02:48:56.239580  4270 solver.cpp:337] Iteration 1076, Testing net (#0)
I0403 02:49:57.355586  4270 solver.cpp:404]     Test net output #0: accuracy = 0.976484
I0403 02:49:57.363131  4270 solver.cpp:404]     Test net output #1: loss = 0.0739688 (* 1 = 0.0739688 loss)
I0403 02:50:00.322005  4270 solver.cpp:228] Iteration 1079, loss = 0.0840796
I0403 02:50:00.328492  4270 solver.cpp:244]     Train net output #0: loss = 0.0840795 (* 1 = 0.0840795 loss)
I0403 02:50:00.484472  4270 sgd_solver.cpp:106] Iteration 1079, lr = 0.005
I0403 02:50:10.249313  4270 solver.cpp:228] Iteration 1092, loss = 0.0161112
I0403 02:50:10.256028  4270 solver.cpp:244]     Train net output #0: loss = 0.0161112 (* 1 = 0.0161112 loss)
I0403 02:50:10.511967  4270 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 02:50:20.246840  4270 solver.cpp:228] Iteration 1105, loss = 0.0129337
I0403 02:50:20.260231  4270 solver.cpp:244]     Train net output #0: loss = 0.0129336 (* 1 = 0.0129336 loss)
I0403 02:50:20.450165  4270 sgd_solver.cpp:106] Iteration 1105, lr = 0.005
I0403 02:50:30.132047  4270 solver.cpp:228] Iteration 1118, loss = 0.00591005
I0403 02:50:30.141998  4270 solver.cpp:244]     Train net output #0: loss = 0.00590996 (* 1 = 0.00590996 loss)
I0403 02:50:30.349524  4270 sgd_solver.cpp:106] Iteration 1118, lr = 0.005
I0403 02:50:39.969913  4270 solver.cpp:228] Iteration 1131, loss = 0.035024
I0403 02:50:39.975394  4270 solver.cpp:244]     Train net output #0: loss = 0.0350239 (* 1 = 0.0350239 loss)
I0403 02:50:40.202190  4270 sgd_solver.cpp:106] Iteration 1131, lr = 0.005
I0403 02:50:49.913800  4270 solver.cpp:228] Iteration 1144, loss = 0.0677595
I0403 02:50:49.920790  4270 solver.cpp:244]     Train net output #0: loss = 0.0677594 (* 1 = 0.0677594 loss)
I0403 02:50:50.153879  4270 sgd_solver.cpp:106] Iteration 1144, lr = 0.005
I0403 02:50:59.862072  4270 solver.cpp:228] Iteration 1157, loss = 0.0167738
I0403 02:50:59.869143  4270 solver.cpp:244]     Train net output #0: loss = 0.0167738 (* 1 = 0.0167738 loss)
I0403 02:51:00.042644  4270 sgd_solver.cpp:106] Iteration 1157, lr = 0.005
I0403 02:51:09.779556  4270 solver.cpp:228] Iteration 1170, loss = 0.0145619
I0403 02:51:09.785792  4270 solver.cpp:244]     Train net output #0: loss = 0.0145619 (* 1 = 0.0145619 loss)
I0403 02:51:10.001479  4270 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 02:51:19.581895  4270 solver.cpp:228] Iteration 1183, loss = 0.0107487
I0403 02:51:19.588146  4270 solver.cpp:244]     Train net output #0: loss = 0.0107486 (* 1 = 0.0107486 loss)
I0403 02:51:19.827782  4270 sgd_solver.cpp:106] Iteration 1183, lr = 0.005
I0403 02:51:29.374487  4270 solver.cpp:228] Iteration 1196, loss = 0.0343472
I0403 02:51:29.380988  4270 solver.cpp:244]     Train net output #0: loss = 0.0343471 (* 1 = 0.0343471 loss)
I0403 02:51:29.582556  4270 sgd_solver.cpp:106] Iteration 1196, lr = 0.005
I0403 02:51:39.204792  4270 solver.cpp:228] Iteration 1209, loss = 0.0329664
I0403 02:51:39.211596  4270 solver.cpp:244]     Train net output #0: loss = 0.0329664 (* 1 = 0.0329664 loss)
I0403 02:51:39.476042  4270 sgd_solver.cpp:106] Iteration 1209, lr = 0.005
I0403 02:51:49.263553  4270 solver.cpp:228] Iteration 1222, loss = 0.0359623
I0403 02:51:49.270488  4270 solver.cpp:244]     Train net output #0: loss = 0.0359622 (* 1 = 0.0359622 loss)
I0403 02:51:49.471874  4270 sgd_solver.cpp:106] Iteration 1222, lr = 0.005
I0403 02:51:59.318027  4270 solver.cpp:228] Iteration 1235, loss = 0.0266693
I0403 02:51:59.324352  4270 solver.cpp:244]     Train net output #0: loss = 0.0266692 (* 1 = 0.0266692 loss)
I0403 02:51:59.552573  4270 sgd_solver.cpp:106] Iteration 1235, lr = 0.005
I0403 02:52:09.278447  4270 solver.cpp:228] Iteration 1248, loss = 0.0843527
I0403 02:52:09.285151  4270 solver.cpp:244]     Train net output #0: loss = 0.0843526 (* 1 = 0.0843526 loss)
I0403 02:52:09.489975  4270 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 02:52:19.176937  4270 solver.cpp:228] Iteration 1261, loss = 0.0709087
I0403 02:52:19.182965  4270 solver.cpp:244]     Train net output #0: loss = 0.0709086 (* 1 = 0.0709086 loss)
I0403 02:52:19.398916  4270 sgd_solver.cpp:106] Iteration 1261, lr = 0.005
I0403 02:52:28.975359  4270 solver.cpp:228] Iteration 1274, loss = 0.021668
I0403 02:52:28.981535  4270 solver.cpp:244]     Train net output #0: loss = 0.0216679 (* 1 = 0.0216679 loss)
I0403 02:52:29.178257  4270 sgd_solver.cpp:106] Iteration 1274, lr = 0.005
I0403 02:52:39.219756  4270 solver.cpp:228] Iteration 1287, loss = 0.0243786
I0403 02:52:39.226444  4270 solver.cpp:244]     Train net output #0: loss = 0.0243785 (* 1 = 0.0243785 loss)
I0403 02:52:39.446583  4270 sgd_solver.cpp:106] Iteration 1287, lr = 0.005
I0403 02:52:49.024096  4270 solver.cpp:228] Iteration 1300, loss = 0.0271497
I0403 02:52:49.030524  4270 solver.cpp:244]     Train net output #0: loss = 0.0271496 (* 1 = 0.0271496 loss)
I0403 02:52:49.264282  4270 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 02:52:59.016569  4270 solver.cpp:228] Iteration 1313, loss = 0.0197958
I0403 02:52:59.023531  4270 solver.cpp:244]     Train net output #0: loss = 0.0197958 (* 1 = 0.0197958 loss)
I0403 02:52:59.229236  4270 sgd_solver.cpp:106] Iteration 1313, lr = 0.005
I0403 02:53:08.831483  4270 solver.cpp:228] Iteration 1326, loss = 0.0168577
I0403 02:53:08.837363  4270 solver.cpp:244]     Train net output #0: loss = 0.0168576 (* 1 = 0.0168576 loss)
I0403 02:53:09.064877  4270 sgd_solver.cpp:106] Iteration 1326, lr = 0.005
I0403 02:53:18.786905  4270 solver.cpp:228] Iteration 1339, loss = 0.0990431
I0403 02:53:18.793118  4270 solver.cpp:244]     Train net output #0: loss = 0.0990431 (* 1 = 0.0990431 loss)
I0403 02:53:18.992422  4270 sgd_solver.cpp:106] Iteration 1339, lr = 0.005
I0403 02:53:22.841120  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1345.caffemodel
I0403 02:53:25.665657  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1345.solverstate
I0403 02:53:27.555233  4270 solver.cpp:337] Iteration 1345, Testing net (#0)
I0403 02:54:28.808096  4270 solver.cpp:404]     Test net output #0: accuracy = 0.982088
I0403 02:54:28.815397  4270 solver.cpp:404]     Test net output #1: loss = 0.0548999 (* 1 = 0.0548999 loss)
I0403 02:54:34.635069  4270 solver.cpp:228] Iteration 1352, loss = 0.0183751
I0403 02:54:34.641144  4270 solver.cpp:244]     Train net output #0: loss = 0.018375 (* 1 = 0.018375 loss)
I0403 02:54:34.841168  4270 sgd_solver.cpp:106] Iteration 1352, lr = 0.005
I0403 02:54:44.454035  4270 solver.cpp:228] Iteration 1365, loss = 0.0383696
I0403 02:54:44.460047  4270 solver.cpp:244]     Train net output #0: loss = 0.0383696 (* 1 = 0.0383696 loss)
I0403 02:54:44.658296  4270 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 02:54:54.606235  4270 solver.cpp:228] Iteration 1378, loss = 0.0102285
I0403 02:54:54.612257  4270 solver.cpp:244]     Train net output #0: loss = 0.0102285 (* 1 = 0.0102285 loss)
I0403 02:54:54.795686  4270 sgd_solver.cpp:106] Iteration 1378, lr = 0.005
I0403 02:55:04.512676  4270 solver.cpp:228] Iteration 1391, loss = 0.00836765
I0403 02:55:04.517338  4270 solver.cpp:244]     Train net output #0: loss = 0.00836759 (* 1 = 0.00836759 loss)
I0403 02:55:04.751811  4270 sgd_solver.cpp:106] Iteration 1391, lr = 0.005
I0403 02:55:14.533723  4270 solver.cpp:228] Iteration 1404, loss = 0.00286913
I0403 02:55:14.539733  4270 solver.cpp:244]     Train net output #0: loss = 0.00286908 (* 1 = 0.00286908 loss)
I0403 02:55:14.757644  4270 sgd_solver.cpp:106] Iteration 1404, lr = 0.005
I0403 02:55:24.486538  4270 solver.cpp:228] Iteration 1417, loss = 0.0418628
I0403 02:55:24.492590  4270 solver.cpp:244]     Train net output #0: loss = 0.0418627 (* 1 = 0.0418627 loss)
I0403 02:55:24.714998  4270 sgd_solver.cpp:106] Iteration 1417, lr = 0.005
I0403 02:55:34.278923  4270 solver.cpp:228] Iteration 1430, loss = 0.0368296
I0403 02:55:34.286252  4270 solver.cpp:244]     Train net output #0: loss = 0.0368295 (* 1 = 0.0368295 loss)
I0403 02:55:34.492033  4270 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 02:55:44.066066  4270 solver.cpp:228] Iteration 1443, loss = 0.012458
I0403 02:55:44.072455  4270 solver.cpp:244]     Train net output #0: loss = 0.0124579 (* 1 = 0.0124579 loss)
I0403 02:55:44.279217  4270 sgd_solver.cpp:106] Iteration 1443, lr = 0.005
I0403 02:55:53.951901  4270 solver.cpp:228] Iteration 1456, loss = 0.00971092
I0403 02:55:53.958482  4270 solver.cpp:244]     Train net output #0: loss = 0.00971087 (* 1 = 0.00971087 loss)
I0403 02:55:54.170203  4270 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 02:56:03.943440  4270 solver.cpp:228] Iteration 1469, loss = 0.024921
I0403 02:56:03.949861  4270 solver.cpp:244]     Train net output #0: loss = 0.0249209 (* 1 = 0.0249209 loss)
I0403 02:56:04.190907  4270 sgd_solver.cpp:106] Iteration 1469, lr = 0.005
I0403 02:56:13.824103  4270 solver.cpp:228] Iteration 1482, loss = 0.00224599
I0403 02:56:13.829871  4270 solver.cpp:244]     Train net output #0: loss = 0.00224594 (* 1 = 0.00224594 loss)
I0403 02:56:14.027923  4270 sgd_solver.cpp:106] Iteration 1482, lr = 0.005
I0403 02:56:24.034464  4270 solver.cpp:228] Iteration 1495, loss = 0.00254235
I0403 02:56:24.046663  4270 solver.cpp:244]     Train net output #0: loss = 0.0025423 (* 1 = 0.0025423 loss)
I0403 02:56:24.249845  4270 sgd_solver.cpp:106] Iteration 1495, lr = 0.005
I0403 02:56:33.872640  4270 solver.cpp:228] Iteration 1508, loss = 0.00418911
I0403 02:56:33.879429  4270 solver.cpp:244]     Train net output #0: loss = 0.00418905 (* 1 = 0.00418905 loss)
I0403 02:56:34.087477  4270 sgd_solver.cpp:106] Iteration 1508, lr = 0.005
I0403 02:56:43.803347  4270 solver.cpp:228] Iteration 1521, loss = 0.00507453
I0403 02:56:43.809309  4270 solver.cpp:244]     Train net output #0: loss = 0.00507448 (* 1 = 0.00507448 loss)
I0403 02:56:44.020575  4270 sgd_solver.cpp:106] Iteration 1521, lr = 0.005
I0403 02:56:53.720731  4270 solver.cpp:228] Iteration 1534, loss = 0.0358996
I0403 02:56:53.726364  4270 solver.cpp:244]     Train net output #0: loss = 0.0358996 (* 1 = 0.0358996 loss)
I0403 02:56:53.932893  4270 sgd_solver.cpp:106] Iteration 1534, lr = 0.005
I0403 02:57:03.642657  4270 solver.cpp:228] Iteration 1547, loss = 0.00558714
I0403 02:57:03.648952  4270 solver.cpp:244]     Train net output #0: loss = 0.00558709 (* 1 = 0.00558709 loss)
I0403 02:57:03.868048  4270 sgd_solver.cpp:106] Iteration 1547, lr = 0.005
I0403 02:57:13.702543  4270 solver.cpp:228] Iteration 1560, loss = 0.00693057
I0403 02:57:13.707758  4270 solver.cpp:244]     Train net output #0: loss = 0.00693052 (* 1 = 0.00693052 loss)
I0403 02:57:13.908344  4270 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 02:57:23.682512  4270 solver.cpp:228] Iteration 1573, loss = 0.0198092
I0403 02:57:23.688349  4270 solver.cpp:244]     Train net output #0: loss = 0.0198092 (* 1 = 0.0198092 loss)
I0403 02:57:23.890732  4270 sgd_solver.cpp:106] Iteration 1573, lr = 0.005
I0403 02:57:33.578739  4270 solver.cpp:228] Iteration 1586, loss = 0.00743342
I0403 02:57:33.584995  4270 solver.cpp:244]     Train net output #0: loss = 0.00743337 (* 1 = 0.00743337 loss)
I0403 02:57:33.799046  4270 sgd_solver.cpp:106] Iteration 1586, lr = 0.005
I0403 02:57:43.718749  4270 solver.cpp:228] Iteration 1599, loss = 0.00256043
I0403 02:57:43.724557  4270 solver.cpp:244]     Train net output #0: loss = 0.00256038 (* 1 = 0.00256038 loss)
I0403 02:57:43.948439  4270 sgd_solver.cpp:106] Iteration 1599, lr = 0.005
I0403 02:57:53.766492  4270 solver.cpp:228] Iteration 1612, loss = 0.00307093
I0403 02:57:53.771723  4270 solver.cpp:244]     Train net output #0: loss = 0.00307087 (* 1 = 0.00307087 loss)
I0403 02:57:53.991618  4270 sgd_solver.cpp:106] Iteration 1612, lr = 0.005
I0403 02:57:54.758128  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1614.caffemodel
I0403 02:57:57.539991  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1614.solverstate
I0403 02:57:59.386404  4270 solver.cpp:337] Iteration 1614, Testing net (#0)
I0403 02:59:00.522769  4270 solver.cpp:404]     Test net output #0: accuracy = 0.984176
I0403 02:59:00.530002  4270 solver.cpp:404]     Test net output #1: loss = 0.0500041 (* 1 = 0.0500041 loss)
I0403 02:59:09.411262  4270 solver.cpp:228] Iteration 1625, loss = 0.0129724
I0403 02:59:09.417395  4270 solver.cpp:244]     Train net output #0: loss = 0.0129723 (* 1 = 0.0129723 loss)
I0403 02:59:09.684706  4270 sgd_solver.cpp:106] Iteration 1625, lr = 0.005
I0403 02:59:19.535653  4270 solver.cpp:228] Iteration 1638, loss = 0.129205
I0403 02:59:19.541658  4270 solver.cpp:244]     Train net output #0: loss = 0.129205 (* 1 = 0.129205 loss)
I0403 02:59:19.741469  4270 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 02:59:29.576143  4270 solver.cpp:228] Iteration 1651, loss = 0.0138298
I0403 02:59:29.582597  4270 solver.cpp:244]     Train net output #0: loss = 0.0138298 (* 1 = 0.0138298 loss)
I0403 02:59:29.792366  4270 sgd_solver.cpp:106] Iteration 1651, lr = 0.005
I0403 02:59:39.642232  4270 solver.cpp:228] Iteration 1664, loss = 0.0197396
I0403 02:59:39.657812  4270 solver.cpp:244]     Train net output #0: loss = 0.0197396 (* 1 = 0.0197396 loss)
I0403 02:59:39.857266  4270 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 02:59:49.643592  4270 solver.cpp:228] Iteration 1677, loss = 0.000436424
I0403 02:59:49.649778  4270 solver.cpp:244]     Train net output #0: loss = 0.000436381 (* 1 = 0.000436381 loss)
I0403 02:59:49.823132  4270 sgd_solver.cpp:106] Iteration 1677, lr = 0.005
I0403 02:59:59.543207  4270 solver.cpp:228] Iteration 1690, loss = 0.0353385
I0403 02:59:59.549633  4270 solver.cpp:244]     Train net output #0: loss = 0.0353385 (* 1 = 0.0353385 loss)
I0403 02:59:59.758599  4270 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 03:00:09.479497  4270 solver.cpp:228] Iteration 1703, loss = 0.0104568
I0403 03:00:09.485642  4270 solver.cpp:244]     Train net output #0: loss = 0.0104568 (* 1 = 0.0104568 loss)
I0403 03:00:09.692942  4270 sgd_solver.cpp:106] Iteration 1703, lr = 0.005
I0403 03:00:19.334040  4270 solver.cpp:228] Iteration 1716, loss = 0.00301208
I0403 03:00:19.340900  4270 solver.cpp:244]     Train net output #0: loss = 0.00301204 (* 1 = 0.00301204 loss)
I0403 03:00:19.539983  4270 sgd_solver.cpp:106] Iteration 1716, lr = 0.005
I0403 03:00:29.196830  4270 solver.cpp:228] Iteration 1729, loss = 0.00393702
I0403 03:00:29.202440  4270 solver.cpp:244]     Train net output #0: loss = 0.00393698 (* 1 = 0.00393698 loss)
I0403 03:00:29.402134  4270 sgd_solver.cpp:106] Iteration 1729, lr = 0.005
I0403 03:00:38.998993  4270 solver.cpp:228] Iteration 1742, loss = 0.00803231
I0403 03:00:39.004593  4270 solver.cpp:244]     Train net output #0: loss = 0.00803226 (* 1 = 0.00803226 loss)
I0403 03:00:39.226629  4270 sgd_solver.cpp:106] Iteration 1742, lr = 0.005
I0403 03:00:48.942572  4270 solver.cpp:228] Iteration 1755, loss = 0.00940556
I0403 03:00:48.948827  4270 solver.cpp:244]     Train net output #0: loss = 0.00940551 (* 1 = 0.00940551 loss)
I0403 03:00:49.161912  4270 sgd_solver.cpp:106] Iteration 1755, lr = 0.005
I0403 03:00:58.887243  4270 solver.cpp:228] Iteration 1768, loss = 0.0182628
I0403 03:00:58.893685  4270 solver.cpp:244]     Train net output #0: loss = 0.0182627 (* 1 = 0.0182627 loss)
I0403 03:00:59.106835  4270 sgd_solver.cpp:106] Iteration 1768, lr = 0.005
I0403 03:01:08.903832  4270 solver.cpp:228] Iteration 1781, loss = 0.0975949
I0403 03:01:08.910014  4270 solver.cpp:244]     Train net output #0: loss = 0.0975949 (* 1 = 0.0975949 loss)
I0403 03:01:09.112715  4270 sgd_solver.cpp:106] Iteration 1781, lr = 0.005
I0403 03:01:18.868068  4270 solver.cpp:228] Iteration 1794, loss = 0.000906006
I0403 03:01:18.874441  4270 solver.cpp:244]     Train net output #0: loss = 0.000905953 (* 1 = 0.000905953 loss)
I0403 03:01:19.104421  4270 sgd_solver.cpp:106] Iteration 1794, lr = 0.005
I0403 03:01:28.763867  4270 solver.cpp:228] Iteration 1807, loss = 0.000364812
I0403 03:01:28.769183  4270 solver.cpp:244]     Train net output #0: loss = 0.000364758 (* 1 = 0.000364758 loss)
I0403 03:01:28.960701  4270 sgd_solver.cpp:106] Iteration 1807, lr = 0.005
I0403 03:01:38.643323  4270 solver.cpp:228] Iteration 1820, loss = 0.012553
I0403 03:01:38.649600  4270 solver.cpp:244]     Train net output #0: loss = 0.0125529 (* 1 = 0.0125529 loss)
I0403 03:01:38.841640  4270 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 03:01:48.567309  4270 solver.cpp:228] Iteration 1833, loss = 0.0150923
I0403 03:01:48.573652  4270 solver.cpp:244]     Train net output #0: loss = 0.0150922 (* 1 = 0.0150922 loss)
I0403 03:01:48.783357  4270 sgd_solver.cpp:106] Iteration 1833, lr = 0.005
I0403 03:01:58.444500  4270 solver.cpp:228] Iteration 1846, loss = 0.00561356
I0403 03:01:58.449430  4270 solver.cpp:244]     Train net output #0: loss = 0.00561351 (* 1 = 0.00561351 loss)
I0403 03:01:58.630919  4270 sgd_solver.cpp:106] Iteration 1846, lr = 0.005
I0403 03:02:08.415137  4270 solver.cpp:228] Iteration 1859, loss = 0.00333771
I0403 03:02:08.420846  4270 solver.cpp:244]     Train net output #0: loss = 0.00333766 (* 1 = 0.00333766 loss)
I0403 03:02:08.672256  4270 sgd_solver.cpp:106] Iteration 1859, lr = 0.005
I0403 03:02:18.334573  4270 solver.cpp:228] Iteration 1872, loss = 0.0104817
I0403 03:02:18.340361  4270 solver.cpp:244]     Train net output #0: loss = 0.0104816 (* 1 = 0.0104816 loss)
I0403 03:02:18.556255  4270 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 03:02:26.397236  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1883.caffemodel
I0403 03:02:29.240857  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_1883.solverstate
I0403 03:02:31.163966  4270 solver.cpp:337] Iteration 1883, Testing net (#0)
I0403 03:03:32.268805  4270 solver.cpp:404]     Test net output #0: accuracy = 0.980293
I0403 03:03:32.279278  4270 solver.cpp:404]     Test net output #1: loss = 0.0689906 (* 1 = 0.0689906 loss)
I0403 03:03:34.391095  4270 solver.cpp:228] Iteration 1885, loss = 0.00930319
I0403 03:03:34.397477  4270 solver.cpp:244]     Train net output #0: loss = 0.00930313 (* 1 = 0.00930313 loss)
I0403 03:03:34.593673  4270 sgd_solver.cpp:106] Iteration 1885, lr = 0.005
I0403 03:03:44.258186  4270 solver.cpp:228] Iteration 1898, loss = 0.00944029
I0403 03:03:44.263934  4270 solver.cpp:244]     Train net output #0: loss = 0.00944023 (* 1 = 0.00944023 loss)
I0403 03:03:44.440793  4270 sgd_solver.cpp:106] Iteration 1898, lr = 0.005
I0403 03:03:54.335650  4270 solver.cpp:228] Iteration 1911, loss = 0.00402933
I0403 03:03:54.342375  4270 solver.cpp:244]     Train net output #0: loss = 0.00402927 (* 1 = 0.00402927 loss)
I0403 03:03:54.509433  4270 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 03:04:04.329181  4270 solver.cpp:228] Iteration 1924, loss = 0.00297318
I0403 03:04:04.334538  4270 solver.cpp:244]     Train net output #0: loss = 0.00297312 (* 1 = 0.00297312 loss)
I0403 03:04:04.544737  4270 sgd_solver.cpp:106] Iteration 1924, lr = 0.005
I0403 03:04:14.226213  4270 solver.cpp:228] Iteration 1937, loss = 0.00639021
I0403 03:04:14.232832  4270 solver.cpp:244]     Train net output #0: loss = 0.00639015 (* 1 = 0.00639015 loss)
I0403 03:04:14.412470  4270 sgd_solver.cpp:106] Iteration 1937, lr = 0.005
I0403 03:04:24.188403  4270 solver.cpp:228] Iteration 1950, loss = 0.0088574
I0403 03:04:24.193630  4270 solver.cpp:244]     Train net output #0: loss = 0.00885734 (* 1 = 0.00885734 loss)
I0403 03:04:24.403072  4270 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 03:04:34.219149  4270 solver.cpp:228] Iteration 1963, loss = 0.000732154
I0403 03:04:34.225776  4270 solver.cpp:244]     Train net output #0: loss = 0.000732096 (* 1 = 0.000732096 loss)
I0403 03:04:34.423754  4270 sgd_solver.cpp:106] Iteration 1963, lr = 0.005
I0403 03:04:44.174901  4270 solver.cpp:228] Iteration 1976, loss = 0.0198113
I0403 03:04:44.181598  4270 solver.cpp:244]     Train net output #0: loss = 0.0198113 (* 1 = 0.0198113 loss)
I0403 03:04:44.399220  4270 sgd_solver.cpp:106] Iteration 1976, lr = 0.005
I0403 03:04:53.930565  4270 solver.cpp:228] Iteration 1989, loss = 0.024333
I0403 03:04:53.941918  4270 solver.cpp:244]     Train net output #0: loss = 0.024333 (* 1 = 0.024333 loss)
I0403 03:04:54.186785  4270 sgd_solver.cpp:106] Iteration 1989, lr = 0.005
I0403 03:05:03.816769  4270 solver.cpp:228] Iteration 2002, loss = 0.0121351
I0403 03:05:03.823441  4270 solver.cpp:244]     Train net output #0: loss = 0.012135 (* 1 = 0.012135 loss)
I0403 03:05:04.095083  4270 sgd_solver.cpp:106] Iteration 2002, lr = 0.005
I0403 03:05:13.797351  4270 solver.cpp:228] Iteration 2015, loss = 0.00954701
I0403 03:05:13.803015  4270 solver.cpp:244]     Train net output #0: loss = 0.00954696 (* 1 = 0.00954696 loss)
I0403 03:05:14.009090  4270 sgd_solver.cpp:106] Iteration 2015, lr = 0.005
I0403 03:05:23.971303  4270 solver.cpp:228] Iteration 2028, loss = 0.018014
I0403 03:05:23.976923  4270 solver.cpp:244]     Train net output #0: loss = 0.018014 (* 1 = 0.018014 loss)
I0403 03:05:24.135607  4270 sgd_solver.cpp:106] Iteration 2028, lr = 0.005
I0403 03:05:33.882462  4270 solver.cpp:228] Iteration 2041, loss = 0.0532255
I0403 03:05:33.889416  4270 solver.cpp:244]     Train net output #0: loss = 0.0532255 (* 1 = 0.0532255 loss)
I0403 03:05:34.105904  4270 sgd_solver.cpp:106] Iteration 2041, lr = 0.005
I0403 03:05:43.803869  4270 solver.cpp:228] Iteration 2054, loss = 0.0381273
I0403 03:05:43.809916  4270 solver.cpp:244]     Train net output #0: loss = 0.0381272 (* 1 = 0.0381272 loss)
I0403 03:05:44.023696  4270 sgd_solver.cpp:106] Iteration 2054, lr = 0.005
I0403 03:05:53.934609  4270 solver.cpp:228] Iteration 2067, loss = 0.0204047
I0403 03:05:53.940646  4270 solver.cpp:244]     Train net output #0: loss = 0.0204046 (* 1 = 0.0204046 loss)
I0403 03:05:54.111014  4270 sgd_solver.cpp:106] Iteration 2067, lr = 0.005
I0403 03:06:03.919728  4270 solver.cpp:228] Iteration 2080, loss = 0.00143141
I0403 03:06:03.924715  4270 solver.cpp:244]     Train net output #0: loss = 0.00143136 (* 1 = 0.00143136 loss)
I0403 03:06:04.121099  4270 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:06:13.938237  4270 solver.cpp:228] Iteration 2093, loss = 0.0106829
I0403 03:06:13.944686  4270 solver.cpp:244]     Train net output #0: loss = 0.0106828 (* 1 = 0.0106828 loss)
I0403 03:06:14.127648  4270 sgd_solver.cpp:106] Iteration 2093, lr = 0.005
I0403 03:06:23.812984  4270 solver.cpp:228] Iteration 2106, loss = 0.00243568
I0403 03:06:23.818529  4270 solver.cpp:244]     Train net output #0: loss = 0.00243563 (* 1 = 0.00243563 loss)
I0403 03:06:24.034838  4270 sgd_solver.cpp:106] Iteration 2106, lr = 0.005
I0403 03:06:33.763905  4270 solver.cpp:228] Iteration 2119, loss = 0.00143415
I0403 03:06:33.770164  4270 solver.cpp:244]     Train net output #0: loss = 0.0014341 (* 1 = 0.0014341 loss)
I0403 03:06:33.956861  4270 sgd_solver.cpp:106] Iteration 2119, lr = 0.005
I0403 03:06:43.783185  4270 solver.cpp:228] Iteration 2132, loss = 0.00521562
I0403 03:06:43.788586  4270 solver.cpp:244]     Train net output #0: loss = 0.00521557 (* 1 = 0.00521557 loss)
I0403 03:06:43.990924  4270 sgd_solver.cpp:106] Iteration 2132, lr = 0.005
I0403 03:06:53.651932  4270 solver.cpp:228] Iteration 2145, loss = 0.00658587
I0403 03:06:53.657649  4270 solver.cpp:244]     Train net output #0: loss = 0.00658581 (* 1 = 0.00658581 loss)
I0403 03:06:53.918660  4270 sgd_solver.cpp:106] Iteration 2145, lr = 0.005
I0403 03:06:58.591110  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2152.caffemodel
I0403 03:07:01.417558  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2152.solverstate
I0403 03:07:03.334342  4270 solver.cpp:337] Iteration 2152, Testing net (#0)
I0403 03:08:04.441256  4270 solver.cpp:404]     Test net output #0: accuracy = 0.981466
I0403 03:08:04.449473  4270 solver.cpp:404]     Test net output #1: loss = 0.0669664 (* 1 = 0.0669664 loss)
I0403 03:08:09.503409  4270 solver.cpp:228] Iteration 2158, loss = 0.0461854
I0403 03:08:09.508947  4270 solver.cpp:244]     Train net output #0: loss = 0.0461854 (* 1 = 0.0461854 loss)
I0403 03:08:09.711027  4270 sgd_solver.cpp:106] Iteration 2158, lr = 0.005
I0403 03:08:19.454823  4270 solver.cpp:228] Iteration 2171, loss = 0.0133869
I0403 03:08:19.461424  4270 solver.cpp:244]     Train net output #0: loss = 0.0133869 (* 1 = 0.0133869 loss)
I0403 03:08:19.693529  4270 sgd_solver.cpp:106] Iteration 2171, lr = 0.005
I0403 03:08:29.279654  4270 solver.cpp:228] Iteration 2184, loss = 0.0392099
I0403 03:08:29.285352  4270 solver.cpp:244]     Train net output #0: loss = 0.0392099 (* 1 = 0.0392099 loss)
I0403 03:08:29.482436  4270 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 03:08:39.113071  4270 solver.cpp:228] Iteration 2197, loss = 0.00576167
I0403 03:08:39.119165  4270 solver.cpp:244]     Train net output #0: loss = 0.00576162 (* 1 = 0.00576162 loss)
I0403 03:08:39.292611  4270 sgd_solver.cpp:106] Iteration 2197, lr = 0.005
I0403 03:08:49.152243  4270 solver.cpp:228] Iteration 2210, loss = 0.00508676
I0403 03:08:49.158419  4270 solver.cpp:244]     Train net output #0: loss = 0.00508671 (* 1 = 0.00508671 loss)
I0403 03:08:49.356806  4270 sgd_solver.cpp:106] Iteration 2210, lr = 0.005
I0403 03:08:59.154752  4270 solver.cpp:228] Iteration 2223, loss = 0.00019253
I0403 03:08:59.160387  4270 solver.cpp:244]     Train net output #0: loss = 0.000192478 (* 1 = 0.000192478 loss)
I0403 03:08:59.372799  4270 sgd_solver.cpp:106] Iteration 2223, lr = 0.005
I0403 03:09:08.998505  4270 solver.cpp:228] Iteration 2236, loss = 0.00264724
I0403 03:09:09.004600  4270 solver.cpp:244]     Train net output #0: loss = 0.00264719 (* 1 = 0.00264719 loss)
I0403 03:09:09.237320  4270 sgd_solver.cpp:106] Iteration 2236, lr = 0.005
I0403 03:09:18.966722  4270 solver.cpp:228] Iteration 2249, loss = 0.000218163
I0403 03:09:18.972723  4270 solver.cpp:244]     Train net output #0: loss = 0.000218112 (* 1 = 0.000218112 loss)
I0403 03:09:19.197989  4270 sgd_solver.cpp:106] Iteration 2249, lr = 0.005
I0403 03:09:29.078249  4270 solver.cpp:228] Iteration 2262, loss = 0.0261866
I0403 03:09:29.082821  4270 solver.cpp:244]     Train net output #0: loss = 0.0261865 (* 1 = 0.0261865 loss)
I0403 03:09:29.273298  4270 sgd_solver.cpp:106] Iteration 2262, lr = 0.005
I0403 03:09:39.174022  4270 solver.cpp:228] Iteration 2275, loss = 0.046323
I0403 03:09:39.179249  4270 solver.cpp:244]     Train net output #0: loss = 0.046323 (* 1 = 0.046323 loss)
I0403 03:09:39.373658  4270 sgd_solver.cpp:106] Iteration 2275, lr = 0.005
I0403 03:09:48.983974  4270 solver.cpp:228] Iteration 2288, loss = 0.00203456
I0403 03:09:48.990391  4270 solver.cpp:244]     Train net output #0: loss = 0.00203451 (* 1 = 0.00203451 loss)
I0403 03:09:49.231295  4270 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 03:09:58.856928  4270 solver.cpp:228] Iteration 2301, loss = 0.00102496
I0403 03:09:58.863545  4270 solver.cpp:244]     Train net output #0: loss = 0.0010249 (* 1 = 0.0010249 loss)
I0403 03:09:59.081331  4270 sgd_solver.cpp:106] Iteration 2301, lr = 0.005
I0403 03:10:09.027441  4270 solver.cpp:228] Iteration 2314, loss = 0.00399945
I0403 03:10:09.033884  4270 solver.cpp:244]     Train net output #0: loss = 0.0039994 (* 1 = 0.0039994 loss)
I0403 03:10:09.231256  4270 sgd_solver.cpp:106] Iteration 2314, lr = 0.005
I0403 03:10:18.863608  4270 solver.cpp:228] Iteration 2327, loss = 0.0338432
I0403 03:10:18.869560  4270 solver.cpp:244]     Train net output #0: loss = 0.0338432 (* 1 = 0.0338432 loss)
I0403 03:10:19.111153  4270 sgd_solver.cpp:106] Iteration 2327, lr = 0.005
I0403 03:10:28.943328  4270 solver.cpp:228] Iteration 2340, loss = 0.0026043
I0403 03:10:28.949977  4270 solver.cpp:244]     Train net output #0: loss = 0.00260425 (* 1 = 0.00260425 loss)
I0403 03:10:29.118615  4270 sgd_solver.cpp:106] Iteration 2340, lr = 0.005
I0403 03:10:38.878271  4270 solver.cpp:228] Iteration 2353, loss = 0.0133682
I0403 03:10:38.884769  4270 solver.cpp:244]     Train net output #0: loss = 0.0133682 (* 1 = 0.0133682 loss)
I0403 03:10:39.075806  4270 sgd_solver.cpp:106] Iteration 2353, lr = 0.005
I0403 03:10:48.869474  4270 solver.cpp:228] Iteration 2366, loss = 0.00398402
I0403 03:10:48.875924  4270 solver.cpp:244]     Train net output #0: loss = 0.00398395 (* 1 = 0.00398395 loss)
I0403 03:10:49.077020  4270 sgd_solver.cpp:106] Iteration 2366, lr = 0.005
I0403 03:10:58.827713  4270 solver.cpp:228] Iteration 2379, loss = 0.00598212
I0403 03:10:58.832798  4270 solver.cpp:244]     Train net output #0: loss = 0.00598206 (* 1 = 0.00598206 loss)
I0403 03:10:59.026051  4270 sgd_solver.cpp:106] Iteration 2379, lr = 0.005
I0403 03:11:08.759090  4270 solver.cpp:228] Iteration 2392, loss = 0.0271476
I0403 03:11:08.765393  4270 solver.cpp:244]     Train net output #0: loss = 0.0271475 (* 1 = 0.0271475 loss)
I0403 03:11:08.923205  4270 sgd_solver.cpp:106] Iteration 2392, lr = 0.005
I0403 03:11:18.710809  4270 solver.cpp:228] Iteration 2405, loss = 0.000577359
I0403 03:11:18.716272  4270 solver.cpp:244]     Train net output #0: loss = 0.000577298 (* 1 = 0.000577298 loss)
I0403 03:11:18.922088  4270 sgd_solver.cpp:106] Iteration 2405, lr = 0.005
I0403 03:11:28.472982  4270 solver.cpp:228] Iteration 2418, loss = 0.000517012
I0403 03:11:28.479202  4270 solver.cpp:244]     Train net output #0: loss = 0.000516955 (* 1 = 0.000516955 loss)
I0403 03:11:28.696354  4270 sgd_solver.cpp:106] Iteration 2418, lr = 0.005
I0403 03:11:30.212537  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2421.caffemodel
I0403 03:11:32.981096  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2421.solverstate
I0403 03:11:34.893441  4270 solver.cpp:337] Iteration 2421, Testing net (#0)
I0403 03:12:35.970340  4270 solver.cpp:404]     Test net output #0: accuracy = 0.982309
I0403 03:12:35.977830  4270 solver.cpp:404]     Test net output #1: loss = 0.0634717 (* 1 = 0.0634717 loss)
I0403 03:12:44.303472  4270 solver.cpp:228] Iteration 2431, loss = 0.000421789
I0403 03:12:44.309901  4270 solver.cpp:244]     Train net output #0: loss = 0.000421732 (* 1 = 0.000421732 loss)
I0403 03:12:44.528369  4270 sgd_solver.cpp:106] Iteration 2431, lr = 0.005
I0403 03:12:54.276566  4270 solver.cpp:228] Iteration 2444, loss = 0.000688184
I0403 03:12:54.282749  4270 solver.cpp:244]     Train net output #0: loss = 0.000688129 (* 1 = 0.000688129 loss)
I0403 03:12:54.492605  4270 sgd_solver.cpp:106] Iteration 2444, lr = 0.005
I0403 03:13:04.244081  4270 solver.cpp:228] Iteration 2457, loss = 0.0924924
I0403 03:13:04.249583  4270 solver.cpp:244]     Train net output #0: loss = 0.0924923 (* 1 = 0.0924923 loss)
I0403 03:13:04.449749  4270 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 03:13:14.077114  4270 solver.cpp:228] Iteration 2470, loss = 0.00202529
I0403 03:13:14.083642  4270 solver.cpp:244]     Train net output #0: loss = 0.00202525 (* 1 = 0.00202525 loss)
I0403 03:13:14.292371  4270 sgd_solver.cpp:106] Iteration 2470, lr = 0.005
I0403 03:13:23.957994  4270 solver.cpp:228] Iteration 2483, loss = 0.0355776
I0403 03:13:23.964097  4270 solver.cpp:244]     Train net output #0: loss = 0.0355776 (* 1 = 0.0355776 loss)
I0403 03:13:24.233662  4270 sgd_solver.cpp:106] Iteration 2483, lr = 0.005
I0403 03:13:34.068621  4270 solver.cpp:228] Iteration 2496, loss = 0.0536187
I0403 03:13:34.079604  4270 solver.cpp:244]     Train net output #0: loss = 0.0536186 (* 1 = 0.0536186 loss)
I0403 03:13:34.268882  4270 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 03:13:44.017205  4270 solver.cpp:228] Iteration 2509, loss = 0.0485928
I0403 03:13:44.023347  4270 solver.cpp:244]     Train net output #0: loss = 0.0485928 (* 1 = 0.0485928 loss)
I0403 03:13:44.227561  4270 sgd_solver.cpp:106] Iteration 2509, lr = 0.005
I0403 03:13:53.998620  4270 solver.cpp:228] Iteration 2522, loss = 0.000909403
I0403 03:13:54.005005  4270 solver.cpp:244]     Train net output #0: loss = 0.000909363 (* 1 = 0.000909363 loss)
I0403 03:13:54.254454  4270 sgd_solver.cpp:106] Iteration 2522, lr = 0.005
I0403 03:14:03.933373  4270 solver.cpp:228] Iteration 2535, loss = 0.00448027
I0403 03:14:03.942364  4270 solver.cpp:244]     Train net output #0: loss = 0.00448023 (* 1 = 0.00448023 loss)
I0403 03:14:04.195374  4270 sgd_solver.cpp:106] Iteration 2535, lr = 0.005
I0403 03:14:13.946887  4270 solver.cpp:228] Iteration 2548, loss = 0.0024042
I0403 03:14:13.952034  4270 solver.cpp:244]     Train net output #0: loss = 0.00240416 (* 1 = 0.00240416 loss)
I0403 03:14:14.177790  4270 sgd_solver.cpp:106] Iteration 2548, lr = 0.005
I0403 03:14:23.969784  4270 solver.cpp:228] Iteration 2561, loss = 0.00467977
I0403 03:14:23.975880  4270 solver.cpp:244]     Train net output #0: loss = 0.00467973 (* 1 = 0.00467973 loss)
I0403 03:14:24.171577  4270 sgd_solver.cpp:106] Iteration 2561, lr = 0.005
I0403 03:14:33.852367  4270 solver.cpp:228] Iteration 2574, loss = 7.22967e-05
I0403 03:14:33.858779  4270 solver.cpp:244]     Train net output #0: loss = 7.2259e-05 (* 1 = 7.2259e-05 loss)
I0403 03:14:34.133446  4270 sgd_solver.cpp:106] Iteration 2574, lr = 0.005
I0403 03:14:43.812909  4270 solver.cpp:228] Iteration 2587, loss = 0.0182015
I0403 03:14:43.818783  4270 solver.cpp:244]     Train net output #0: loss = 0.0182014 (* 1 = 0.0182014 loss)
I0403 03:14:44.027961  4270 sgd_solver.cpp:106] Iteration 2587, lr = 0.005
I0403 03:14:53.701047  4270 solver.cpp:228] Iteration 2600, loss = 0.00697143
I0403 03:14:53.706914  4270 solver.cpp:244]     Train net output #0: loss = 0.00697139 (* 1 = 0.00697139 loss)
I0403 03:14:53.899479  4270 sgd_solver.cpp:106] Iteration 2600, lr = 0.005
I0403 03:15:03.723829  4270 solver.cpp:228] Iteration 2613, loss = 0.0042034
I0403 03:15:03.730270  4270 solver.cpp:244]     Train net output #0: loss = 0.00420336 (* 1 = 0.00420336 loss)
I0403 03:15:03.921105  4270 sgd_solver.cpp:106] Iteration 2613, lr = 0.005
I0403 03:15:13.675575  4270 solver.cpp:228] Iteration 2626, loss = 0.00354314
I0403 03:15:13.681512  4270 solver.cpp:244]     Train net output #0: loss = 0.0035431 (* 1 = 0.0035431 loss)
I0403 03:15:13.898244  4270 sgd_solver.cpp:106] Iteration 2626, lr = 0.005
I0403 03:15:23.553288  4270 solver.cpp:228] Iteration 2639, loss = 0.0214022
I0403 03:15:23.558862  4270 solver.cpp:244]     Train net output #0: loss = 0.0214021 (* 1 = 0.0214021 loss)
I0403 03:15:23.796545  4270 sgd_solver.cpp:106] Iteration 2639, lr = 0.005
I0403 03:15:33.472697  4270 solver.cpp:228] Iteration 2652, loss = 0.00171868
I0403 03:15:33.478164  4270 solver.cpp:244]     Train net output #0: loss = 0.00171865 (* 1 = 0.00171865 loss)
I0403 03:15:33.650810  4270 sgd_solver.cpp:106] Iteration 2652, lr = 0.005
I0403 03:15:43.557914  4270 solver.cpp:228] Iteration 2665, loss = 0.0100096
I0403 03:15:43.563894  4270 solver.cpp:244]     Train net output #0: loss = 0.0100095 (* 1 = 0.0100095 loss)
I0403 03:15:43.797632  4270 sgd_solver.cpp:106] Iteration 2665, lr = 0.005
I0403 03:15:53.523612  4270 solver.cpp:228] Iteration 2678, loss = 0.00862455
I0403 03:15:53.529881  4270 solver.cpp:244]     Train net output #0: loss = 0.00862452 (* 1 = 0.00862452 loss)
I0403 03:15:53.737242  4270 sgd_solver.cpp:106] Iteration 2678, lr = 0.005
I0403 03:16:02.194757  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2690.caffemodel
I0403 03:16:05.024477  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2690.solverstate
I0403 03:16:06.926697  4270 solver.cpp:337] Iteration 2690, Testing net (#0)
I0403 03:17:08.163875  4270 solver.cpp:404]     Test net output #0: accuracy = 0.983371
I0403 03:17:08.169401  4270 solver.cpp:404]     Test net output #1: loss = 0.0580424 (* 1 = 0.0580424 loss)
I0403 03:17:09.437902  4270 solver.cpp:228] Iteration 2691, loss = 0.000387894
I0403 03:17:09.442876  4270 solver.cpp:244]     Train net output #0: loss = 0.00038786 (* 1 = 0.00038786 loss)
I0403 03:17:09.660580  4270 sgd_solver.cpp:106] Iteration 2691, lr = 0.0005
I0403 03:17:19.236600  4270 solver.cpp:228] Iteration 2704, loss = 0.0023817
I0403 03:17:19.242561  4270 solver.cpp:244]     Train net output #0: loss = 0.00238166 (* 1 = 0.00238166 loss)
I0403 03:17:19.475780  4270 sgd_solver.cpp:106] Iteration 2704, lr = 0.0005
I0403 03:17:29.093963  4270 solver.cpp:228] Iteration 2717, loss = 0.00707416
I0403 03:17:29.099129  4270 solver.cpp:244]     Train net output #0: loss = 0.00707413 (* 1 = 0.00707413 loss)
I0403 03:17:29.290467  4270 sgd_solver.cpp:106] Iteration 2717, lr = 0.0005
I0403 03:17:38.873078  4270 solver.cpp:228] Iteration 2730, loss = 0.00433162
I0403 03:17:38.881074  4270 solver.cpp:244]     Train net output #0: loss = 0.00433158 (* 1 = 0.00433158 loss)
I0403 03:17:39.090807  4270 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 03:17:48.762730  4270 solver.cpp:228] Iteration 2743, loss = 0.0216316
I0403 03:17:48.768488  4270 solver.cpp:244]     Train net output #0: loss = 0.0216316 (* 1 = 0.0216316 loss)
I0403 03:17:48.999338  4270 sgd_solver.cpp:106] Iteration 2743, lr = 0.0005
I0403 03:17:58.859904  4270 solver.cpp:228] Iteration 2756, loss = 0.00195924
I0403 03:17:58.865839  4270 solver.cpp:244]     Train net output #0: loss = 0.00195921 (* 1 = 0.00195921 loss)
I0403 03:17:59.094806  4270 sgd_solver.cpp:106] Iteration 2756, lr = 0.0005
I0403 03:18:08.785418  4270 solver.cpp:228] Iteration 2769, loss = 0.0111803
I0403 03:18:08.790792  4270 solver.cpp:244]     Train net output #0: loss = 0.0111803 (* 1 = 0.0111803 loss)
I0403 03:18:09.007597  4270 sgd_solver.cpp:106] Iteration 2769, lr = 0.0005
I0403 03:18:18.647182  4270 solver.cpp:228] Iteration 2782, loss = 0.00141055
I0403 03:18:18.658797  4270 solver.cpp:244]     Train net output #0: loss = 0.00141052 (* 1 = 0.00141052 loss)
I0403 03:18:18.853726  4270 sgd_solver.cpp:106] Iteration 2782, lr = 0.0005
I0403 03:18:28.609329  4270 solver.cpp:228] Iteration 2795, loss = 0.000163131
I0403 03:18:28.614375  4270 solver.cpp:244]     Train net output #0: loss = 0.000163097 (* 1 = 0.000163097 loss)
I0403 03:18:28.823840  4270 sgd_solver.cpp:106] Iteration 2795, lr = 0.0005
I0403 03:18:38.648586  4270 solver.cpp:228] Iteration 2808, loss = 0.00542201
I0403 03:18:38.654188  4270 solver.cpp:244]     Train net output #0: loss = 0.00542197 (* 1 = 0.00542197 loss)
I0403 03:18:38.864228  4270 sgd_solver.cpp:106] Iteration 2808, lr = 0.0005
I0403 03:18:48.653635  4270 solver.cpp:228] Iteration 2821, loss = 0.00962851
I0403 03:18:48.658942  4270 solver.cpp:244]     Train net output #0: loss = 0.00962847 (* 1 = 0.00962847 loss)
I0403 03:18:48.850525  4270 sgd_solver.cpp:106] Iteration 2821, lr = 0.0005
I0403 03:18:58.754359  4270 solver.cpp:228] Iteration 2834, loss = 0.000742346
I0403 03:18:58.760593  4270 solver.cpp:244]     Train net output #0: loss = 0.000742313 (* 1 = 0.000742313 loss)
I0403 03:18:58.903776  4270 sgd_solver.cpp:106] Iteration 2834, lr = 0.0005
I0403 03:19:08.732823  4270 solver.cpp:228] Iteration 2847, loss = 0.0346847
I0403 03:19:08.739737  4270 solver.cpp:244]     Train net output #0: loss = 0.0346847 (* 1 = 0.0346847 loss)
I0403 03:19:08.916916  4270 sgd_solver.cpp:106] Iteration 2847, lr = 0.0005
I0403 03:19:18.755919  4270 solver.cpp:228] Iteration 2860, loss = 0.000538711
I0403 03:19:18.762513  4270 solver.cpp:244]     Train net output #0: loss = 0.000538678 (* 1 = 0.000538678 loss)
I0403 03:19:18.940599  4270 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 03:19:28.971983  4270 solver.cpp:228] Iteration 2873, loss = 0.00190264
I0403 03:19:28.978091  4270 solver.cpp:244]     Train net output #0: loss = 0.00190261 (* 1 = 0.00190261 loss)
I0403 03:19:29.157457  4270 sgd_solver.cpp:106] Iteration 2873, lr = 0.0005
I0403 03:19:39.018446  4270 solver.cpp:228] Iteration 2886, loss = 0.000545354
I0403 03:19:39.025164  4270 solver.cpp:244]     Train net output #0: loss = 0.000545321 (* 1 = 0.000545321 loss)
I0403 03:19:39.232934  4270 sgd_solver.cpp:106] Iteration 2886, lr = 0.0005
I0403 03:19:49.133613  4270 solver.cpp:228] Iteration 2899, loss = 0.00116601
I0403 03:19:49.141156  4270 solver.cpp:244]     Train net output #0: loss = 0.00116597 (* 1 = 0.00116597 loss)
I0403 03:19:49.346462  4270 sgd_solver.cpp:106] Iteration 2899, lr = 0.0005
I0403 03:19:59.203793  4270 solver.cpp:228] Iteration 2912, loss = 0.00378935
I0403 03:19:59.208847  4270 solver.cpp:244]     Train net output #0: loss = 0.00378931 (* 1 = 0.00378931 loss)
I0403 03:19:59.407827  4270 sgd_solver.cpp:106] Iteration 2912, lr = 0.0005
I0403 03:20:08.983754  4270 solver.cpp:228] Iteration 2925, loss = 0.0205664
I0403 03:20:08.990368  4270 solver.cpp:244]     Train net output #0: loss = 0.0205664 (* 1 = 0.0205664 loss)
I0403 03:20:09.185432  4270 sgd_solver.cpp:106] Iteration 2925, lr = 0.0005
I0403 03:20:18.915467  4270 solver.cpp:228] Iteration 2938, loss = 0.0036677
I0403 03:20:18.921505  4270 solver.cpp:244]     Train net output #0: loss = 0.00366767 (* 1 = 0.00366767 loss)
I0403 03:20:19.130488  4270 sgd_solver.cpp:106] Iteration 2938, lr = 0.0005
I0403 03:20:28.953022  4270 solver.cpp:228] Iteration 2951, loss = 0.00260746
I0403 03:20:28.958557  4270 solver.cpp:244]     Train net output #0: loss = 0.00260743 (* 1 = 0.00260743 loss)
I0403 03:20:29.156648  4270 sgd_solver.cpp:106] Iteration 2951, lr = 0.0005
I0403 03:20:34.493785  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2959.caffemodel
I0403 03:20:37.295411  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_2959.solverstate
I0403 03:20:39.188789  4270 solver.cpp:337] Iteration 2959, Testing net (#0)
I0403 03:21:40.336484  4270 solver.cpp:404]     Test net output #0: accuracy = 0.9874
I0403 03:21:40.342360  4270 solver.cpp:404]     Test net output #1: loss = 0.0425982 (* 1 = 0.0425982 loss)
I0403 03:21:44.681615  4270 solver.cpp:228] Iteration 2964, loss = 0.000122638
I0403 03:21:44.687222  4270 solver.cpp:244]     Train net output #0: loss = 0.000122608 (* 1 = 0.000122608 loss)
I0403 03:21:44.908383  4270 sgd_solver.cpp:106] Iteration 2964, lr = 0.0005
I0403 03:21:54.530787  4270 solver.cpp:228] Iteration 2977, loss = 0.000289178
I0403 03:21:54.539820  4270 solver.cpp:244]     Train net output #0: loss = 0.000289148 (* 1 = 0.000289148 loss)
I0403 03:21:54.740896  4270 sgd_solver.cpp:106] Iteration 2977, lr = 0.0005
I0403 03:22:04.327859  4270 solver.cpp:228] Iteration 2990, loss = 0.00225222
I0403 03:22:04.334450  4270 solver.cpp:244]     Train net output #0: loss = 0.00225219 (* 1 = 0.00225219 loss)
I0403 03:22:04.529322  4270 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 03:22:14.249714  4270 solver.cpp:228] Iteration 3003, loss = 0.00184789
I0403 03:22:14.254191  4270 solver.cpp:244]     Train net output #0: loss = 0.00184786 (* 1 = 0.00184786 loss)
I0403 03:22:14.529168  4270 sgd_solver.cpp:106] Iteration 3003, lr = 0.0005
I0403 03:22:24.211784  4270 solver.cpp:228] Iteration 3016, loss = 0.00372807
I0403 03:22:24.218569  4270 solver.cpp:244]     Train net output #0: loss = 0.00372804 (* 1 = 0.00372804 loss)
I0403 03:22:24.446271  4270 sgd_solver.cpp:106] Iteration 3016, lr = 0.0005
I0403 03:22:34.153811  4270 solver.cpp:228] Iteration 3029, loss = 0.000172958
I0403 03:22:34.159883  4270 solver.cpp:244]     Train net output #0: loss = 0.000172928 (* 1 = 0.000172928 loss)
I0403 03:22:34.387892  4270 sgd_solver.cpp:106] Iteration 3029, lr = 0.0005
I0403 03:22:44.101717  4270 solver.cpp:228] Iteration 3042, loss = 0.0025977
I0403 03:22:44.108049  4270 solver.cpp:244]     Train net output #0: loss = 0.00259767 (* 1 = 0.00259767 loss)
I0403 03:22:44.347369  4270 sgd_solver.cpp:106] Iteration 3042, lr = 0.0005
I0403 03:22:54.050675  4270 solver.cpp:228] Iteration 3055, loss = 0.000245544
I0403 03:22:54.055713  4270 solver.cpp:244]     Train net output #0: loss = 0.000245514 (* 1 = 0.000245514 loss)
I0403 03:22:54.236466  4270 sgd_solver.cpp:106] Iteration 3055, lr = 0.0005
I0403 03:23:03.941025  4270 solver.cpp:228] Iteration 3068, loss = 0.000822915
I0403 03:23:03.946413  4270 solver.cpp:244]     Train net output #0: loss = 0.000822886 (* 1 = 0.000822886 loss)
I0403 03:23:04.180256  4270 sgd_solver.cpp:106] Iteration 3068, lr = 0.0005
I0403 03:23:13.908380  4270 solver.cpp:228] Iteration 3081, loss = 0.00164192
I0403 03:23:13.915181  4270 solver.cpp:244]     Train net output #0: loss = 0.00164189 (* 1 = 0.00164189 loss)
I0403 03:23:14.126241  4270 sgd_solver.cpp:106] Iteration 3081, lr = 0.0005
I0403 03:23:23.821862  4270 solver.cpp:228] Iteration 3094, loss = 0.00591781
I0403 03:23:23.828717  4270 solver.cpp:244]     Train net output #0: loss = 0.00591778 (* 1 = 0.00591778 loss)
I0403 03:23:24.047104  4270 sgd_solver.cpp:106] Iteration 3094, lr = 0.0005
I0403 03:23:33.696360  4270 solver.cpp:228] Iteration 3107, loss = 0.00225256
I0403 03:23:33.702296  4270 solver.cpp:244]     Train net output #0: loss = 0.00225253 (* 1 = 0.00225253 loss)
I0403 03:23:33.912587  4270 sgd_solver.cpp:106] Iteration 3107, lr = 0.0005
I0403 03:23:43.533432  4270 solver.cpp:228] Iteration 3120, loss = 0.00492184
I0403 03:23:43.539593  4270 solver.cpp:244]     Train net output #0: loss = 0.00492181 (* 1 = 0.00492181 loss)
I0403 03:23:43.777875  4270 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 03:23:53.561115  4270 solver.cpp:228] Iteration 3133, loss = 0.000482036
I0403 03:23:53.569772  4270 solver.cpp:244]     Train net output #0: loss = 0.000482005 (* 1 = 0.000482005 loss)
I0403 03:23:53.818367  4270 sgd_solver.cpp:106] Iteration 3133, lr = 0.0005
I0403 03:24:03.449537  4270 solver.cpp:228] Iteration 3146, loss = 0.00195046
I0403 03:24:03.455749  4270 solver.cpp:244]     Train net output #0: loss = 0.00195043 (* 1 = 0.00195043 loss)
I0403 03:24:03.713812  4270 sgd_solver.cpp:106] Iteration 3146, lr = 0.0005
I0403 03:24:13.931570  4270 solver.cpp:228] Iteration 3159, loss = 0.00530725
I0403 03:24:13.939164  4270 solver.cpp:244]     Train net output #0: loss = 0.00530722 (* 1 = 0.00530722 loss)
I0403 03:24:14.107152  4270 sgd_solver.cpp:106] Iteration 3159, lr = 0.0005
I0403 03:24:24.026424  4270 solver.cpp:228] Iteration 3172, loss = 0.00157566
I0403 03:24:24.032003  4270 solver.cpp:244]     Train net output #0: loss = 0.00157563 (* 1 = 0.00157563 loss)
I0403 03:24:24.229846  4270 sgd_solver.cpp:106] Iteration 3172, lr = 0.0005
I0403 03:24:33.969681  4270 solver.cpp:228] Iteration 3185, loss = 0.00341919
I0403 03:24:33.976822  4270 solver.cpp:244]     Train net output #0: loss = 0.00341916 (* 1 = 0.00341916 loss)
I0403 03:24:34.187701  4270 sgd_solver.cpp:106] Iteration 3185, lr = 0.0005
I0403 03:24:44.065541  4270 solver.cpp:228] Iteration 3198, loss = 0.000119449
I0403 03:24:44.072763  4270 solver.cpp:244]     Train net output #0: loss = 0.000119417 (* 1 = 0.000119417 loss)
I0403 03:24:44.260957  4270 sgd_solver.cpp:106] Iteration 3198, lr = 0.0005
I0403 03:24:53.938869  4270 solver.cpp:228] Iteration 3211, loss = 0.000179346
I0403 03:24:53.944468  4270 solver.cpp:244]     Train net output #0: loss = 0.000179314 (* 1 = 0.000179314 loss)
I0403 03:24:54.139997  4270 sgd_solver.cpp:106] Iteration 3211, lr = 0.0005
I0403 03:25:03.756160  4270 solver.cpp:228] Iteration 3224, loss = 0.000279882
I0403 03:25:03.761620  4270 solver.cpp:244]     Train net output #0: loss = 0.00027985 (* 1 = 0.00027985 loss)
I0403 03:25:03.976693  4270 sgd_solver.cpp:106] Iteration 3224, lr = 0.0005
I0403 03:25:06.266723  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_3228.caffemodel
I0403 03:25:09.065457  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_3228.solverstate
I0403 03:25:10.971271  4270 solver.cpp:337] Iteration 3228, Testing net (#0)
I0403 03:26:12.107842  4270 solver.cpp:404]     Test net output #0: accuracy = 0.988023
I0403 03:26:12.115100  4270 solver.cpp:404]     Test net output #1: loss = 0.0409424 (* 1 = 0.0409424 loss)
I0403 03:26:19.495823  4270 solver.cpp:228] Iteration 3237, loss = 0.0047532
I0403 03:26:19.501653  4270 solver.cpp:244]     Train net output #0: loss = 0.00475317 (* 1 = 0.00475317 loss)
I0403 03:26:19.702239  4270 sgd_solver.cpp:106] Iteration 3237, lr = 0.0005
I0403 03:26:29.372890  4270 solver.cpp:228] Iteration 3250, loss = 0.00345396
I0403 03:26:29.391243  4270 solver.cpp:244]     Train net output #0: loss = 0.00345393 (* 1 = 0.00345393 loss)
I0403 03:26:29.571739  4270 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 03:26:39.304393  4270 solver.cpp:228] Iteration 3263, loss = 0.000218844
I0403 03:26:39.309623  4270 solver.cpp:244]     Train net output #0: loss = 0.000218817 (* 1 = 0.000218817 loss)
I0403 03:26:39.526504  4270 sgd_solver.cpp:106] Iteration 3263, lr = 0.0005
I0403 03:26:49.252099  4270 solver.cpp:228] Iteration 3276, loss = 0.0019432
I0403 03:26:49.259268  4270 solver.cpp:244]     Train net output #0: loss = 0.00194317 (* 1 = 0.00194317 loss)
I0403 03:26:49.544083  4270 sgd_solver.cpp:106] Iteration 3276, lr = 0.0005
I0403 03:26:59.192961  4270 solver.cpp:228] Iteration 3289, loss = 0.00116666
I0403 03:26:59.199820  4270 solver.cpp:244]     Train net output #0: loss = 0.00116663 (* 1 = 0.00116663 loss)
I0403 03:26:59.389978  4270 sgd_solver.cpp:106] Iteration 3289, lr = 0.0005
I0403 03:27:09.089606  4270 solver.cpp:228] Iteration 3302, loss = 0.000681473
I0403 03:27:09.094841  4270 solver.cpp:244]     Train net output #0: loss = 0.000681445 (* 1 = 0.000681445 loss)
I0403 03:27:09.291836  4270 sgd_solver.cpp:106] Iteration 3302, lr = 0.0005
I0403 03:27:18.979501  4270 solver.cpp:228] Iteration 3315, loss = 0.0210875
I0403 03:27:18.986871  4270 solver.cpp:244]     Train net output #0: loss = 0.0210875 (* 1 = 0.0210875 loss)
I0403 03:27:19.221652  4270 sgd_solver.cpp:106] Iteration 3315, lr = 0.0005
I0403 03:27:28.962337  4270 solver.cpp:228] Iteration 3328, loss = 0.000606934
I0403 03:27:28.979284  4270 solver.cpp:244]     Train net output #0: loss = 0.000606906 (* 1 = 0.000606906 loss)
I0403 03:27:29.231433  4270 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 03:27:38.913128  4270 solver.cpp:228] Iteration 3341, loss = 0.000168562
I0403 03:27:38.919890  4270 solver.cpp:244]     Train net output #0: loss = 0.000168533 (* 1 = 0.000168533 loss)
I0403 03:27:39.172272  4270 sgd_solver.cpp:106] Iteration 3341, lr = 0.0005
I0403 03:27:48.867270  4270 solver.cpp:228] Iteration 3354, loss = 0.00137487
I0403 03:27:48.872392  4270 solver.cpp:244]     Train net output #0: loss = 0.00137484 (* 1 = 0.00137484 loss)
I0403 03:27:49.046555  4270 sgd_solver.cpp:106] Iteration 3354, lr = 0.0005
I0403 03:27:58.986624  4270 solver.cpp:228] Iteration 3367, loss = 0.00396901
I0403 03:27:58.993640  4270 solver.cpp:244]     Train net output #0: loss = 0.00396898 (* 1 = 0.00396898 loss)
I0403 03:27:59.226547  4270 sgd_solver.cpp:106] Iteration 3367, lr = 0.0005
I0403 03:28:08.953099  4270 solver.cpp:228] Iteration 3380, loss = 0.00153581
I0403 03:28:08.959265  4270 solver.cpp:244]     Train net output #0: loss = 0.00153579 (* 1 = 0.00153579 loss)
I0403 03:28:09.191656  4270 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 03:28:18.837571  4270 solver.cpp:228] Iteration 3393, loss = 0.000317101
I0403 03:28:18.843787  4270 solver.cpp:244]     Train net output #0: loss = 0.000317072 (* 1 = 0.000317072 loss)
I0403 03:28:19.052153  4270 sgd_solver.cpp:106] Iteration 3393, lr = 0.0005
I0403 03:28:28.855804  4270 solver.cpp:228] Iteration 3406, loss = 0.000400019
I0403 03:28:28.861827  4270 solver.cpp:244]     Train net output #0: loss = 0.00039999 (* 1 = 0.00039999 loss)
I0403 03:28:29.051491  4270 sgd_solver.cpp:106] Iteration 3406, lr = 0.0005
I0403 03:28:38.897714  4270 solver.cpp:228] Iteration 3419, loss = 0.00110372
I0403 03:28:38.902945  4270 solver.cpp:244]     Train net output #0: loss = 0.00110369 (* 1 = 0.00110369 loss)
I0403 03:28:39.113982  4270 sgd_solver.cpp:106] Iteration 3419, lr = 0.0005
I0403 03:28:49.014996  4270 solver.cpp:228] Iteration 3432, loss = 0.000486845
I0403 03:28:49.021278  4270 solver.cpp:244]     Train net output #0: loss = 0.000486816 (* 1 = 0.000486816 loss)
I0403 03:28:49.207026  4270 sgd_solver.cpp:106] Iteration 3432, lr = 0.0005
I0403 03:28:58.975718  4270 solver.cpp:228] Iteration 3445, loss = 0.00924886
I0403 03:28:58.982069  4270 solver.cpp:244]     Train net output #0: loss = 0.00924883 (* 1 = 0.00924883 loss)
I0403 03:28:59.183012  4270 sgd_solver.cpp:106] Iteration 3445, lr = 0.0005
I0403 03:29:09.057988  4270 solver.cpp:228] Iteration 3458, loss = 0.00095959
I0403 03:29:09.063336  4270 solver.cpp:244]     Train net output #0: loss = 0.00095956 (* 1 = 0.00095956 loss)
I0403 03:29:09.263365  4270 sgd_solver.cpp:106] Iteration 3458, lr = 0.0005
I0403 03:29:19.023756  4270 solver.cpp:228] Iteration 3471, loss = 0.000242321
I0403 03:29:19.028941  4270 solver.cpp:244]     Train net output #0: loss = 0.000242291 (* 1 = 0.000242291 loss)
I0403 03:29:19.242720  4270 sgd_solver.cpp:106] Iteration 3471, lr = 0.0005
I0403 03:29:28.970178  4270 solver.cpp:228] Iteration 3484, loss = 0.00444233
I0403 03:29:28.976296  4270 solver.cpp:244]     Train net output #0: loss = 0.0044423 (* 1 = 0.0044423 loss)
I0403 03:29:29.172920  4270 sgd_solver.cpp:106] Iteration 3484, lr = 0.0005
I0403 03:29:38.285604  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_3497.caffemodel
I0403 03:29:41.100972  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_3497.solverstate
I0403 03:29:43.007714  4270 solver.cpp:337] Iteration 3497, Testing net (#0)
I0403 03:30:44.118557  4270 solver.cpp:404]     Test net output #0: accuracy = 0.988865
I0403 03:30:44.125944  4270 solver.cpp:404]     Test net output #1: loss = 0.0392558 (* 1 = 0.0392558 loss)
I0403 03:30:44.647796  4270 solver.cpp:228] Iteration 3497, loss = 0.00420779
I0403 03:30:44.654186  4270 solver.cpp:244]     Train net output #0: loss = 0.00420776 (* 1 = 0.00420776 loss)
I0403 03:30:44.861979  4270 sgd_solver.cpp:106] Iteration 3497, lr = 0.0005
I0403 03:30:54.612540  4270 solver.cpp:228] Iteration 3510, loss = 0.00132886
I0403 03:30:54.618754  4270 solver.cpp:244]     Train net output #0: loss = 0.00132883 (* 1 = 0.00132883 loss)
I0403 03:30:54.865612  4270 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 03:31:04.549368  4270 solver.cpp:228] Iteration 3523, loss = 0.000492222
I0403 03:31:04.556223  4270 solver.cpp:244]     Train net output #0: loss = 0.000492191 (* 1 = 0.000492191 loss)
I0403 03:31:04.764130  4270 sgd_solver.cpp:106] Iteration 3523, lr = 0.0005
I0403 03:31:14.465831  4270 solver.cpp:228] Iteration 3536, loss = 0.000146225
I0403 03:31:14.472477  4270 solver.cpp:244]     Train net output #0: loss = 0.000146194 (* 1 = 0.000146194 loss)
I0403 03:31:14.669208  4270 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 03:31:24.503793  4270 solver.cpp:228] Iteration 3549, loss = 0.000645957
I0403 03:31:24.511608  4270 solver.cpp:244]     Train net output #0: loss = 0.000645928 (* 1 = 0.000645928 loss)
I0403 03:31:24.721976  4270 sgd_solver.cpp:106] Iteration 3549, lr = 0.0005
I0403 03:31:34.295722  4270 solver.cpp:228] Iteration 3562, loss = 0.000521656
I0403 03:31:34.303481  4270 solver.cpp:244]     Train net output #0: loss = 0.000521627 (* 1 = 0.000521627 loss)
I0403 03:31:34.511154  4270 sgd_solver.cpp:106] Iteration 3562, lr = 0.0005
I0403 03:31:44.264716  4270 solver.cpp:228] Iteration 3575, loss = 0.00412382
I0403 03:31:44.269878  4270 solver.cpp:244]     Train net output #0: loss = 0.00412379 (* 1 = 0.00412379 loss)
I0403 03:31:44.484820  4270 sgd_solver.cpp:106] Iteration 3575, lr = 0.0005
I0403 03:31:54.139660  4270 solver.cpp:228] Iteration 3588, loss = 0.00106988
I0403 03:31:54.147743  4270 solver.cpp:244]     Train net output #0: loss = 0.00106985 (* 1 = 0.00106985 loss)
I0403 03:31:54.342151  4270 sgd_solver.cpp:106] Iteration 3588, lr = 0.0005
I0403 03:32:03.984449  4270 solver.cpp:228] Iteration 3601, loss = 0.00338679
I0403 03:32:03.990401  4270 solver.cpp:244]     Train net output #0: loss = 0.00338676 (* 1 = 0.00338676 loss)
I0403 03:32:04.203614  4270 sgd_solver.cpp:106] Iteration 3601, lr = 0.0005
I0403 03:32:13.911123  4270 solver.cpp:228] Iteration 3614, loss = 0.000561799
I0403 03:32:13.916275  4270 solver.cpp:244]     Train net output #0: loss = 0.000561769 (* 1 = 0.000561769 loss)
I0403 03:32:14.150298  4270 sgd_solver.cpp:106] Iteration 3614, lr = 0.0005
I0403 03:32:23.836190  4270 solver.cpp:228] Iteration 3627, loss = 0.000293787
I0403 03:32:23.842548  4270 solver.cpp:244]     Train net output #0: loss = 0.000293758 (* 1 = 0.000293758 loss)
I0403 03:32:24.041779  4270 sgd_solver.cpp:106] Iteration 3627, lr = 0.0005
I0403 03:32:33.657301  4270 solver.cpp:228] Iteration 3640, loss = 0.000265744
I0403 03:32:33.662868  4270 solver.cpp:244]     Train net output #0: loss = 0.000265715 (* 1 = 0.000265715 loss)
I0403 03:32:33.862464  4270 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 03:32:43.544795  4270 solver.cpp:228] Iteration 3653, loss = 0.00197135
I0403 03:32:43.551071  4270 solver.cpp:244]     Train net output #0: loss = 0.00197132 (* 1 = 0.00197132 loss)
I0403 03:32:43.760792  4270 sgd_solver.cpp:106] Iteration 3653, lr = 0.0005
I0403 03:32:53.482724  4270 solver.cpp:228] Iteration 3666, loss = 0.000162813
I0403 03:32:53.488540  4270 solver.cpp:244]     Train net output #0: loss = 0.000162783 (* 1 = 0.000162783 loss)
I0403 03:32:53.744848  4270 sgd_solver.cpp:106] Iteration 3666, lr = 0.0005
I0403 03:33:03.636462  4270 solver.cpp:228] Iteration 3679, loss = 0.00227988
I0403 03:33:03.641878  4270 solver.cpp:244]     Train net output #0: loss = 0.00227985 (* 1 = 0.00227985 loss)
I0403 03:33:03.852622  4270 sgd_solver.cpp:106] Iteration 3679, lr = 0.0005
I0403 03:33:13.693923  4270 solver.cpp:228] Iteration 3692, loss = 9.55278e-05
I0403 03:33:13.700923  4270 solver.cpp:244]     Train net output #0: loss = 9.54978e-05 (* 1 = 9.54978e-05 loss)
I0403 03:33:13.933526  4270 sgd_solver.cpp:106] Iteration 3692, lr = 0.0005
I0403 03:33:23.622128  4270 solver.cpp:228] Iteration 3705, loss = 0.00276263
I0403 03:33:23.628218  4270 solver.cpp:244]     Train net output #0: loss = 0.0027626 (* 1 = 0.0027626 loss)
I0403 03:33:23.833729  4270 sgd_solver.cpp:106] Iteration 3705, lr = 0.0005
I0403 03:33:33.612577  4270 solver.cpp:228] Iteration 3718, loss = 2.70171e-05
I0403 03:33:33.619765  4270 solver.cpp:244]     Train net output #0: loss = 2.69873e-05 (* 1 = 2.69873e-05 loss)
I0403 03:33:33.834138  4270 sgd_solver.cpp:106] Iteration 3718, lr = 0.0005
I0403 03:33:43.427211  4270 solver.cpp:228] Iteration 3731, loss = 0.00139812
I0403 03:33:43.434116  4270 solver.cpp:244]     Train net output #0: loss = 0.00139809 (* 1 = 0.00139809 loss)
I0403 03:33:43.637012  4270 sgd_solver.cpp:106] Iteration 3731, lr = 0.0005
I0403 03:33:53.491080  4270 solver.cpp:228] Iteration 3744, loss = 0.00329478
I0403 03:33:53.497480  4270 solver.cpp:244]     Train net output #0: loss = 0.00329475 (* 1 = 0.00329475 loss)
I0403 03:33:53.681022  4270 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 03:34:03.595306  4270 solver.cpp:228] Iteration 3757, loss = 0.00149055
I0403 03:34:03.595422  4270 solver.cpp:244]     Train net output #0: loss = 0.00149052 (* 1 = 0.00149052 loss)
I0403 03:34:03.813289  4270 sgd_solver.cpp:106] Iteration 3757, lr = 0.0005
I0403 03:34:09.884840  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_3766.caffemodel
I0403 03:34:12.691071  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_3766.solverstate
I0403 03:34:14.580826  4270 solver.cpp:337] Iteration 3766, Testing net (#0)
I0403 03:35:15.803230  4270 solver.cpp:404]     Test net output #0: accuracy = 0.988791
I0403 03:35:15.803542  4270 solver.cpp:404]     Test net output #1: loss = 0.0398602 (* 1 = 0.0398602 loss)
I0403 03:35:19.480350  4270 solver.cpp:228] Iteration 3770, loss = 0.000460931
I0403 03:35:19.480455  4270 solver.cpp:244]     Train net output #0: loss = 0.000460902 (* 1 = 0.000460902 loss)
I0403 03:35:19.657105  4270 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 03:35:29.473912  4270 solver.cpp:228] Iteration 3783, loss = 0.000413862
I0403 03:35:29.474030  4270 solver.cpp:244]     Train net output #0: loss = 0.000413833 (* 1 = 0.000413833 loss)
I0403 03:35:29.687752  4270 sgd_solver.cpp:106] Iteration 3783, lr = 0.0005
I0403 03:35:39.469251  4270 solver.cpp:228] Iteration 3796, loss = 0.000798332
I0403 03:35:39.469367  4270 solver.cpp:244]     Train net output #0: loss = 0.000798302 (* 1 = 0.000798302 loss)
I0403 03:35:39.676010  4270 sgd_solver.cpp:106] Iteration 3796, lr = 0.0005
I0403 03:35:49.267282  4270 solver.cpp:228] Iteration 3809, loss = 0.000242908
I0403 03:35:49.267634  4270 solver.cpp:244]     Train net output #0: loss = 0.000242878 (* 1 = 0.000242878 loss)
I0403 03:35:49.472805  4270 sgd_solver.cpp:106] Iteration 3809, lr = 0.0005
I0403 03:35:59.063396  4270 solver.cpp:228] Iteration 3822, loss = 0.000300295
I0403 03:35:59.063503  4270 solver.cpp:244]     Train net output #0: loss = 0.000300265 (* 1 = 0.000300265 loss)
I0403 03:35:59.279605  4270 sgd_solver.cpp:106] Iteration 3822, lr = 0.0005
I0403 03:36:09.014291  4270 solver.cpp:228] Iteration 3835, loss = 0.000443694
I0403 03:36:09.014403  4270 solver.cpp:244]     Train net output #0: loss = 0.000443664 (* 1 = 0.000443664 loss)
I0403 03:36:09.238036  4270 sgd_solver.cpp:106] Iteration 3835, lr = 0.0005
I0403 03:36:19.048032  4270 solver.cpp:228] Iteration 3848, loss = 0.000301857
I0403 03:36:19.048135  4270 solver.cpp:244]     Train net output #0: loss = 0.000301825 (* 1 = 0.000301825 loss)
I0403 03:36:19.231035  4270 sgd_solver.cpp:106] Iteration 3848, lr = 0.0005
I0403 03:36:29.046880  4270 solver.cpp:228] Iteration 3861, loss = 0.000177036
I0403 03:36:29.047258  4270 solver.cpp:244]     Train net output #0: loss = 0.000177009 (* 1 = 0.000177009 loss)
I0403 03:36:29.331341  4270 sgd_solver.cpp:106] Iteration 3861, lr = 0.0005
I0403 03:36:39.167418  4270 solver.cpp:228] Iteration 3874, loss = 0.000146039
I0403 03:36:39.167521  4270 solver.cpp:244]     Train net output #0: loss = 0.000146011 (* 1 = 0.000146011 loss)
I0403 03:36:39.349397  4270 sgd_solver.cpp:106] Iteration 3874, lr = 0.0005
I0403 03:36:49.150679  4270 solver.cpp:228] Iteration 3887, loss = 6.05613e-05
I0403 03:36:49.150796  4270 solver.cpp:244]     Train net output #0: loss = 6.05336e-05 (* 1 = 6.05336e-05 loss)
I0403 03:36:49.385002  4270 sgd_solver.cpp:106] Iteration 3887, lr = 0.0005
I0403 03:36:59.112450  4270 solver.cpp:228] Iteration 3900, loss = 3.94675e-05
I0403 03:36:59.112766  4270 solver.cpp:244]     Train net output #0: loss = 3.94397e-05 (* 1 = 3.94397e-05 loss)
I0403 03:36:59.297688  4270 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 03:37:09.112797  4270 solver.cpp:228] Iteration 3913, loss = 0.0465269
I0403 03:37:09.112885  4270 solver.cpp:244]     Train net output #0: loss = 0.0465269 (* 1 = 0.0465269 loss)
I0403 03:37:09.371351  4270 sgd_solver.cpp:106] Iteration 3913, lr = 0.0005
I0403 03:37:19.079334  4270 solver.cpp:228] Iteration 3926, loss = 0.00173394
I0403 03:37:19.079455  4270 solver.cpp:244]     Train net output #0: loss = 0.00173391 (* 1 = 0.00173391 loss)
I0403 03:37:19.363644  4270 sgd_solver.cpp:106] Iteration 3926, lr = 0.0005
I0403 03:37:29.122676  4270 solver.cpp:228] Iteration 3939, loss = 0.000660806
I0403 03:37:29.123004  4270 solver.cpp:244]     Train net output #0: loss = 0.00066078 (* 1 = 0.00066078 loss)
I0403 03:37:29.331148  4270 sgd_solver.cpp:106] Iteration 3939, lr = 0.0005
I0403 03:37:38.999418  4270 solver.cpp:228] Iteration 3952, loss = 0.00141107
I0403 03:37:38.999529  4270 solver.cpp:244]     Train net output #0: loss = 0.00141105 (* 1 = 0.00141105 loss)
I0403 03:37:39.209012  4270 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 03:37:48.910332  4270 solver.cpp:228] Iteration 3965, loss = 0.00041933
I0403 03:37:48.910434  4270 solver.cpp:244]     Train net output #0: loss = 0.000419304 (* 1 = 0.000419304 loss)
I0403 03:37:49.102114  4270 sgd_solver.cpp:106] Iteration 3965, lr = 0.0005
I0403 03:37:58.914134  4270 solver.cpp:228] Iteration 3978, loss = 0.000208686
I0403 03:37:58.914239  4270 solver.cpp:244]     Train net output #0: loss = 0.00020866 (* 1 = 0.00020866 loss)
I0403 03:37:59.117854  4270 sgd_solver.cpp:106] Iteration 3978, lr = 0.0005
I0403 03:38:08.925997  4270 solver.cpp:228] Iteration 3991, loss = 0.000626154
I0403 03:38:08.926296  4270 solver.cpp:244]     Train net output #0: loss = 0.000626129 (* 1 = 0.000626129 loss)
I0403 03:38:09.142271  4270 sgd_solver.cpp:106] Iteration 3991, lr = 0.0005
I0403 03:38:18.809574  4270 solver.cpp:228] Iteration 4004, loss = 0.000297486
I0403 03:38:18.809689  4270 solver.cpp:244]     Train net output #0: loss = 0.000297461 (* 1 = 0.000297461 loss)
I0403 03:38:19.039404  4270 sgd_solver.cpp:106] Iteration 4004, lr = 0.0005
I0403 03:38:28.808913  4270 solver.cpp:228] Iteration 4017, loss = 0.00207492
I0403 03:38:28.809037  4270 solver.cpp:244]     Train net output #0: loss = 0.0020749 (* 1 = 0.0020749 loss)
I0403 03:38:29.075214  4270 sgd_solver.cpp:106] Iteration 4017, lr = 0.0005
I0403 03:38:39.107242  4270 solver.cpp:228] Iteration 4030, loss = 0.00376123
I0403 03:38:39.107574  4270 solver.cpp:244]     Train net output #0: loss = 0.0037612 (* 1 = 0.0037612 loss)
I0403 03:38:39.372901  4270 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 03:38:42.401011  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4035.caffemodel
I0403 03:38:45.213989  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4035.solverstate
I0403 03:38:47.102090  4270 solver.cpp:337] Iteration 4035, Testing net (#0)
I0403 03:39:48.199834  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989305
I0403 03:39:48.201524  4270 solver.cpp:404]     Test net output #1: loss = 0.0383767 (* 1 = 0.0383767 loss)
I0403 03:39:54.994771  4270 solver.cpp:228] Iteration 4043, loss = 4.02161e-05
I0403 03:39:54.994887  4270 solver.cpp:244]     Train net output #0: loss = 4.0189e-05 (* 1 = 4.0189e-05 loss)
I0403 03:39:55.228207  4270 sgd_solver.cpp:106] Iteration 4043, lr = 0.0005
I0403 03:40:04.856711  4270 solver.cpp:228] Iteration 4056, loss = 0.00191215
I0403 03:40:04.856809  4270 solver.cpp:244]     Train net output #0: loss = 0.00191212 (* 1 = 0.00191212 loss)
I0403 03:40:05.052774  4270 sgd_solver.cpp:106] Iteration 4056, lr = 0.0005
I0403 03:40:14.991570  4270 solver.cpp:228] Iteration 4069, loss = 0.000547167
I0403 03:40:14.991685  4270 solver.cpp:244]     Train net output #0: loss = 0.000547141 (* 1 = 0.000547141 loss)
I0403 03:40:15.236906  4270 sgd_solver.cpp:106] Iteration 4069, lr = 0.0005
I0403 03:40:24.936122  4270 solver.cpp:228] Iteration 4082, loss = 0.00016345
I0403 03:40:24.936449  4270 solver.cpp:244]     Train net output #0: loss = 0.000163424 (* 1 = 0.000163424 loss)
I0403 03:40:25.160881  4270 sgd_solver.cpp:106] Iteration 4082, lr = 0.0005
I0403 03:40:34.893138  4270 solver.cpp:228] Iteration 4095, loss = 7.0391e-05
I0403 03:40:34.893254  4270 solver.cpp:244]     Train net output #0: loss = 7.03645e-05 (* 1 = 7.03645e-05 loss)
I0403 03:40:35.098085  4270 sgd_solver.cpp:106] Iteration 4095, lr = 0.0005
I0403 03:40:44.936426  4270 solver.cpp:228] Iteration 4108, loss = 0.00150482
I0403 03:40:44.936530  4270 solver.cpp:244]     Train net output #0: loss = 0.00150479 (* 1 = 0.00150479 loss)
I0403 03:40:45.130095  4270 sgd_solver.cpp:106] Iteration 4108, lr = 0.0005
I0403 03:40:54.972667  4270 solver.cpp:228] Iteration 4121, loss = 0.000236153
I0403 03:40:54.972945  4270 solver.cpp:244]     Train net output #0: loss = 0.000236127 (* 1 = 0.000236127 loss)
I0403 03:40:55.169384  4270 sgd_solver.cpp:106] Iteration 4121, lr = 0.0005
I0403 03:41:04.847460  4270 solver.cpp:228] Iteration 4134, loss = 0.000911801
I0403 03:41:04.847574  4270 solver.cpp:244]     Train net output #0: loss = 0.000911775 (* 1 = 0.000911775 loss)
I0403 03:41:05.118365  4270 sgd_solver.cpp:106] Iteration 4134, lr = 0.0005
I0403 03:41:14.722848  4270 solver.cpp:228] Iteration 4147, loss = 0.000353123
I0403 03:41:14.722941  4270 solver.cpp:244]     Train net output #0: loss = 0.000353097 (* 1 = 0.000353097 loss)
I0403 03:41:14.944736  4270 sgd_solver.cpp:106] Iteration 4147, lr = 0.0005
I0403 03:41:24.702730  4270 solver.cpp:228] Iteration 4160, loss = 0.000716576
I0403 03:41:24.702832  4270 solver.cpp:244]     Train net output #0: loss = 0.00071655 (* 1 = 0.00071655 loss)
I0403 03:41:24.890223  4270 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:41:34.760975  4270 solver.cpp:228] Iteration 4173, loss = 0.00553123
I0403 03:41:34.768075  4270 solver.cpp:244]     Train net output #0: loss = 0.00553121 (* 1 = 0.00553121 loss)
I0403 03:41:34.942661  4270 sgd_solver.cpp:106] Iteration 4173, lr = 0.0005
I0403 03:41:44.841076  4270 solver.cpp:228] Iteration 4186, loss = 0.00161177
I0403 03:41:44.841192  4270 solver.cpp:244]     Train net output #0: loss = 0.00161174 (* 1 = 0.00161174 loss)
I0403 03:41:45.050170  4270 sgd_solver.cpp:106] Iteration 4186, lr = 0.0005
I0403 03:41:54.705535  4270 solver.cpp:228] Iteration 4199, loss = 0.00166628
I0403 03:41:54.705651  4270 solver.cpp:244]     Train net output #0: loss = 0.00166626 (* 1 = 0.00166626 loss)
I0403 03:41:54.983268  4270 sgd_solver.cpp:106] Iteration 4199, lr = 0.0005
I0403 03:42:04.557293  4270 solver.cpp:228] Iteration 4212, loss = 0.000371971
I0403 03:42:04.557413  4270 solver.cpp:244]     Train net output #0: loss = 0.000371946 (* 1 = 0.000371946 loss)
I0403 03:42:04.764677  4270 sgd_solver.cpp:106] Iteration 4212, lr = 0.0005
I0403 03:42:14.508544  4270 solver.cpp:228] Iteration 4225, loss = 0.00018803
I0403 03:42:14.508661  4270 solver.cpp:244]     Train net output #0: loss = 0.000188005 (* 1 = 0.000188005 loss)
I0403 03:42:14.712116  4270 sgd_solver.cpp:106] Iteration 4225, lr = 0.0005
I0403 03:42:24.384603  4270 solver.cpp:228] Iteration 4238, loss = 3.64054e-05
I0403 03:42:24.384704  4270 solver.cpp:244]     Train net output #0: loss = 3.63796e-05 (* 1 = 3.63796e-05 loss)
I0403 03:42:24.554368  4270 sgd_solver.cpp:106] Iteration 4238, lr = 0.0005
I0403 03:42:34.319948  4270 solver.cpp:228] Iteration 4251, loss = 0.00140186
I0403 03:42:34.320075  4270 solver.cpp:244]     Train net output #0: loss = 0.00140184 (* 1 = 0.00140184 loss)
I0403 03:42:34.576174  4270 sgd_solver.cpp:106] Iteration 4251, lr = 0.0005
I0403 03:42:44.232815  4270 solver.cpp:228] Iteration 4264, loss = 0.000586066
I0403 03:42:44.233124  4270 solver.cpp:244]     Train net output #0: loss = 0.00058604 (* 1 = 0.00058604 loss)
I0403 03:42:44.433425  4270 sgd_solver.cpp:106] Iteration 4264, lr = 0.0005
I0403 03:42:54.035315  4270 solver.cpp:228] Iteration 4277, loss = 6.35453e-05
I0403 03:42:54.035419  4270 solver.cpp:244]     Train net output #0: loss = 6.35188e-05 (* 1 = 6.35188e-05 loss)
I0403 03:42:54.233094  4270 sgd_solver.cpp:106] Iteration 4277, lr = 0.0005
I0403 03:43:03.925827  4270 solver.cpp:228] Iteration 4290, loss = 0.000796109
I0403 03:43:03.925967  4270 solver.cpp:244]     Train net output #0: loss = 0.000796083 (* 1 = 0.000796083 loss)
I0403 03:43:04.130826  4270 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 03:43:13.889578  4270 solver.cpp:228] Iteration 4303, loss = 0.000368455
I0403 03:43:13.889686  4270 solver.cpp:244]     Train net output #0: loss = 0.000368429 (* 1 = 0.000368429 loss)
I0403 03:43:14.145820  4270 sgd_solver.cpp:106] Iteration 4303, lr = 0.0005
I0403 03:43:14.146067  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4304.caffemodel
I0403 03:43:16.950259  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4304.solverstate
I0403 03:43:18.823444  4270 solver.cpp:337] Iteration 4304, Testing net (#0)
I0403 03:44:19.919518  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989341
I0403 03:44:19.919824  4270 solver.cpp:404]     Test net output #1: loss = 0.0383808 (* 1 = 0.0383808 loss)
I0403 03:44:29.584744  4270 solver.cpp:228] Iteration 4316, loss = 0.00118441
I0403 03:44:29.584858  4270 solver.cpp:244]     Train net output #0: loss = 0.00118438 (* 1 = 0.00118438 loss)
I0403 03:44:29.806689  4270 sgd_solver.cpp:106] Iteration 4316, lr = 0.0005
I0403 03:44:39.422691  4270 solver.cpp:228] Iteration 4329, loss = 0.00178633
I0403 03:44:39.422806  4270 solver.cpp:244]     Train net output #0: loss = 0.00178631 (* 1 = 0.00178631 loss)
I0403 03:44:39.627540  4270 sgd_solver.cpp:106] Iteration 4329, lr = 0.0005
I0403 03:44:49.380491  4270 solver.cpp:228] Iteration 4342, loss = 0.000974192
I0403 03:44:49.380606  4270 solver.cpp:244]     Train net output #0: loss = 0.000974165 (* 1 = 0.000974165 loss)
I0403 03:44:49.583866  4270 sgd_solver.cpp:106] Iteration 4342, lr = 0.0005
I0403 03:44:59.561381  4270 solver.cpp:228] Iteration 4355, loss = 0.00750071
I0403 03:44:59.561691  4270 solver.cpp:244]     Train net output #0: loss = 0.00750068 (* 1 = 0.00750068 loss)
I0403 03:44:59.735076  4270 sgd_solver.cpp:106] Iteration 4355, lr = 0.0005
I0403 03:45:10.005970  4270 solver.cpp:228] Iteration 4368, loss = 0.000361434
I0403 03:45:10.006093  4270 solver.cpp:244]     Train net output #0: loss = 0.000361404 (* 1 = 0.000361404 loss)
I0403 03:45:10.267174  4270 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:45:19.992442  4270 solver.cpp:228] Iteration 4381, loss = 0.000890241
I0403 03:45:19.992557  4270 solver.cpp:244]     Train net output #0: loss = 0.000890211 (* 1 = 0.000890211 loss)
I0403 03:45:20.224839  4270 sgd_solver.cpp:106] Iteration 4381, lr = 0.0005
I0403 03:45:29.967234  4270 solver.cpp:228] Iteration 4394, loss = 9.46072e-05
I0403 03:45:29.967573  4270 solver.cpp:244]     Train net output #0: loss = 9.45772e-05 (* 1 = 9.45772e-05 loss)
I0403 03:45:30.187073  4270 sgd_solver.cpp:106] Iteration 4394, lr = 0.0005
I0403 03:45:39.943778  4270 solver.cpp:228] Iteration 4407, loss = 0.000524789
I0403 03:45:39.943891  4270 solver.cpp:244]     Train net output #0: loss = 0.000524759 (* 1 = 0.000524759 loss)
I0403 03:45:40.166895  4270 sgd_solver.cpp:106] Iteration 4407, lr = 0.0005
I0403 03:45:49.788406  4270 solver.cpp:228] Iteration 4420, loss = 0.000486781
I0403 03:45:49.788522  4270 solver.cpp:244]     Train net output #0: loss = 0.00048675 (* 1 = 0.00048675 loss)
I0403 03:45:50.007133  4270 sgd_solver.cpp:106] Iteration 4420, lr = 0.0005
I0403 03:45:59.663851  4270 solver.cpp:228] Iteration 4433, loss = 0.000185064
I0403 03:45:59.663970  4270 solver.cpp:244]     Train net output #0: loss = 0.000185035 (* 1 = 0.000185035 loss)
I0403 03:45:59.944317  4270 sgd_solver.cpp:106] Iteration 4433, lr = 0.0005
I0403 03:46:09.627954  4270 solver.cpp:228] Iteration 4446, loss = 0.00141254
I0403 03:46:09.628294  4270 solver.cpp:244]     Train net output #0: loss = 0.00141251 (* 1 = 0.00141251 loss)
I0403 03:46:09.867555  4270 sgd_solver.cpp:106] Iteration 4446, lr = 0.0005
I0403 03:46:19.827898  4270 solver.cpp:228] Iteration 4459, loss = 0.000142817
I0403 03:46:19.828016  4270 solver.cpp:244]     Train net output #0: loss = 0.000142786 (* 1 = 0.000142786 loss)
I0403 03:46:19.998443  4270 sgd_solver.cpp:106] Iteration 4459, lr = 0.0005
I0403 03:46:29.762306  4270 solver.cpp:228] Iteration 4472, loss = 0.00345182
I0403 03:46:29.762409  4270 solver.cpp:244]     Train net output #0: loss = 0.00345179 (* 1 = 0.00345179 loss)
I0403 03:46:29.963775  4270 sgd_solver.cpp:106] Iteration 4472, lr = 0.0005
I0403 03:46:39.871356  4270 solver.cpp:228] Iteration 4485, loss = 0.000507363
I0403 03:46:39.871656  4270 solver.cpp:244]     Train net output #0: loss = 0.000507333 (* 1 = 0.000507333 loss)
I0403 03:46:40.075741  4270 sgd_solver.cpp:106] Iteration 4485, lr = 0.0005
I0403 03:46:49.740353  4270 solver.cpp:228] Iteration 4498, loss = 8.73095e-05
I0403 03:46:49.740466  4270 solver.cpp:244]     Train net output #0: loss = 8.72789e-05 (* 1 = 8.72789e-05 loss)
I0403 03:46:49.970180  4270 sgd_solver.cpp:106] Iteration 4498, lr = 0.0005
I0403 03:46:59.760143  4270 solver.cpp:228] Iteration 4511, loss = 0.000212876
I0403 03:46:59.760256  4270 solver.cpp:244]     Train net output #0: loss = 0.000212845 (* 1 = 0.000212845 loss)
I0403 03:46:59.963894  4270 sgd_solver.cpp:106] Iteration 4511, lr = 0.0005
I0403 03:47:09.762603  4270 solver.cpp:228] Iteration 4524, loss = 0.00150724
I0403 03:47:09.762717  4270 solver.cpp:244]     Train net output #0: loss = 0.00150721 (* 1 = 0.00150721 loss)
I0403 03:47:09.968700  4270 sgd_solver.cpp:106] Iteration 4524, lr = 0.0005
I0403 03:47:19.613888  4270 solver.cpp:228] Iteration 4537, loss = 0.000151633
I0403 03:47:19.614008  4270 solver.cpp:244]     Train net output #0: loss = 0.000151603 (* 1 = 0.000151603 loss)
I0403 03:47:19.819787  4270 sgd_solver.cpp:106] Iteration 4537, lr = 0.0005
I0403 03:47:29.693366  4270 solver.cpp:228] Iteration 4550, loss = 0.000154222
I0403 03:47:29.693466  4270 solver.cpp:244]     Train net output #0: loss = 0.000154191 (* 1 = 0.000154191 loss)
I0403 03:47:29.896747  4270 sgd_solver.cpp:106] Iteration 4550, lr = 0.0005
I0403 03:47:39.834004  4270 solver.cpp:228] Iteration 4563, loss = 9.30039e-05
I0403 03:47:39.834113  4270 solver.cpp:244]     Train net output #0: loss = 9.29734e-05 (* 1 = 9.29734e-05 loss)
I0403 03:47:40.037005  4270 sgd_solver.cpp:106] Iteration 4563, lr = 0.0005
I0403 03:47:46.828449  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4573.caffemodel
I0403 03:47:49.587877  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4573.solverstate
I0403 03:47:51.409562  4270 solver.cpp:337] Iteration 4573, Testing net (#0)
I0403 03:48:52.641425  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989964
I0403 03:48:52.641763  4270 solver.cpp:404]     Test net output #1: loss = 0.0372313 (* 1 = 0.0372313 loss)
I0403 03:48:55.508442  4270 solver.cpp:228] Iteration 4576, loss = 0.00143896
I0403 03:48:55.508551  4270 solver.cpp:244]     Train net output #0: loss = 0.00143893 (* 1 = 0.00143893 loss)
I0403 03:48:55.720616  4270 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 03:49:05.339758  4270 solver.cpp:228] Iteration 4589, loss = 0.00015969
I0403 03:49:05.339879  4270 solver.cpp:244]     Train net output #0: loss = 0.000159659 (* 1 = 0.000159659 loss)
I0403 03:49:05.568333  4270 sgd_solver.cpp:106] Iteration 4589, lr = 0.0005
I0403 03:49:15.287369  4270 solver.cpp:228] Iteration 4602, loss = 0.0010054
I0403 03:49:15.287520  4270 solver.cpp:244]     Train net output #0: loss = 0.00100537 (* 1 = 0.00100537 loss)
I0403 03:49:15.584302  4270 sgd_solver.cpp:106] Iteration 4602, lr = 0.0005
I0403 03:49:25.359778  4270 solver.cpp:228] Iteration 4615, loss = 0.000881355
I0403 03:49:25.360061  4270 solver.cpp:244]     Train net output #0: loss = 0.000881325 (* 1 = 0.000881325 loss)
I0403 03:49:25.521080  4270 sgd_solver.cpp:106] Iteration 4615, lr = 0.0005
I0403 03:49:35.416182  4270 solver.cpp:228] Iteration 4628, loss = 8.42139e-05
I0403 03:49:35.416298  4270 solver.cpp:244]     Train net output #0: loss = 8.4184e-05 (* 1 = 8.4184e-05 loss)
I0403 03:49:35.637928  4270 sgd_solver.cpp:106] Iteration 4628, lr = 0.0005
I0403 03:49:45.263393  4270 solver.cpp:228] Iteration 4641, loss = 0.00490371
I0403 03:49:45.263509  4270 solver.cpp:244]     Train net output #0: loss = 0.00490368 (* 1 = 0.00490368 loss)
I0403 03:49:45.488894  4270 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 03:49:55.248147  4270 solver.cpp:228] Iteration 4654, loss = 0.000527679
I0403 03:49:55.248266  4270 solver.cpp:244]     Train net output #0: loss = 0.000527649 (* 1 = 0.000527649 loss)
I0403 03:49:55.467708  4270 sgd_solver.cpp:106] Iteration 4654, lr = 0.0005
I0403 03:50:05.103472  4270 solver.cpp:228] Iteration 4667, loss = 0.000397239
I0403 03:50:05.103591  4270 solver.cpp:244]     Train net output #0: loss = 0.00039721 (* 1 = 0.00039721 loss)
I0403 03:50:05.321441  4270 sgd_solver.cpp:106] Iteration 4667, lr = 0.0005
I0403 03:50:15.008841  4270 solver.cpp:228] Iteration 4680, loss = 0.000132002
I0403 03:50:15.008944  4270 solver.cpp:244]     Train net output #0: loss = 0.000131972 (* 1 = 0.000131972 loss)
I0403 03:50:15.180532  4270 sgd_solver.cpp:106] Iteration 4680, lr = 0.0005
I0403 03:50:24.972064  4270 solver.cpp:228] Iteration 4693, loss = 7.4537e-05
I0403 03:50:24.972180  4270 solver.cpp:244]     Train net output #0: loss = 7.45071e-05 (* 1 = 7.45071e-05 loss)
I0403 03:50:25.182934  4270 sgd_solver.cpp:106] Iteration 4693, lr = 0.0005
I0403 03:50:34.690198  4270 solver.cpp:228] Iteration 4706, loss = 0.000153365
I0403 03:50:34.690524  4270 solver.cpp:244]     Train net output #0: loss = 0.000153334 (* 1 = 0.000153334 loss)
I0403 03:50:34.941679  4270 sgd_solver.cpp:106] Iteration 4706, lr = 0.0005
I0403 03:50:44.679678  4270 solver.cpp:228] Iteration 4719, loss = 0.00146231
I0403 03:50:44.679798  4270 solver.cpp:244]     Train net output #0: loss = 0.00146227 (* 1 = 0.00146227 loss)
I0403 03:50:44.893141  4270 sgd_solver.cpp:106] Iteration 4719, lr = 0.0005
I0403 03:50:54.475385  4270 solver.cpp:228] Iteration 4732, loss = 0.000581005
I0403 03:50:54.475504  4270 solver.cpp:244]     Train net output #0: loss = 0.000580973 (* 1 = 0.000580973 loss)
I0403 03:50:54.679872  4270 sgd_solver.cpp:106] Iteration 4732, lr = 0.0005
I0403 03:51:04.500651  4270 solver.cpp:228] Iteration 4745, loss = 0.000193471
I0403 03:51:04.500769  4270 solver.cpp:244]     Train net output #0: loss = 0.00019344 (* 1 = 0.00019344 loss)
I0403 03:51:04.724655  4270 sgd_solver.cpp:106] Iteration 4745, lr = 0.0005
I0403 03:51:14.407207  4270 solver.cpp:228] Iteration 4758, loss = 0.000571754
I0403 03:51:14.407323  4270 solver.cpp:244]     Train net output #0: loss = 0.000571723 (* 1 = 0.000571723 loss)
I0403 03:51:14.614392  4270 sgd_solver.cpp:106] Iteration 4758, lr = 0.0005
I0403 03:51:24.469269  4270 solver.cpp:228] Iteration 4771, loss = 0.00397336
I0403 03:51:24.469388  4270 solver.cpp:244]     Train net output #0: loss = 0.00397332 (* 1 = 0.00397332 loss)
I0403 03:51:24.684391  4270 sgd_solver.cpp:106] Iteration 4771, lr = 0.0005
I0403 03:51:34.367879  4270 solver.cpp:228] Iteration 4784, loss = 0.00233227
I0403 03:51:34.368007  4270 solver.cpp:244]     Train net output #0: loss = 0.00233224 (* 1 = 0.00233224 loss)
I0403 03:51:34.572387  4270 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 03:51:44.196012  4270 solver.cpp:228] Iteration 4797, loss = 0.00113602
I0403 03:51:44.196341  4270 solver.cpp:244]     Train net output #0: loss = 0.00113599 (* 1 = 0.00113599 loss)
I0403 03:51:44.411289  4270 sgd_solver.cpp:106] Iteration 4797, lr = 0.0005
I0403 03:51:54.192749  4270 solver.cpp:228] Iteration 4810, loss = 5.75336e-05
I0403 03:51:54.192873  4270 solver.cpp:244]     Train net output #0: loss = 5.75032e-05 (* 1 = 5.75032e-05 loss)
I0403 03:51:54.474048  4270 sgd_solver.cpp:106] Iteration 4810, lr = 0.0005
I0403 03:52:04.073894  4270 solver.cpp:228] Iteration 4823, loss = 0.000605181
I0403 03:52:04.074017  4270 solver.cpp:244]     Train net output #0: loss = 0.00060515 (* 1 = 0.00060515 loss)
I0403 03:52:04.282675  4270 sgd_solver.cpp:106] Iteration 4823, lr = 0.0005
I0403 03:52:14.265308  4270 solver.cpp:228] Iteration 4836, loss = 0.00422701
I0403 03:52:14.265622  4270 solver.cpp:244]     Train net output #0: loss = 0.00422698 (* 1 = 0.00422698 loss)
I0403 03:52:14.482815  4270 sgd_solver.cpp:106] Iteration 4836, lr = 0.0005
I0403 03:52:18.311513  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4842.caffemodel
I0403 03:52:21.095901  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_4842.solverstate
I0403 03:52:22.912657  4270 solver.cpp:337] Iteration 4842, Testing net (#0)
I0403 03:53:23.861819  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989708
I0403 03:53:23.862156  4270 solver.cpp:404]     Test net output #1: loss = 0.0387376 (* 1 = 0.0387376 loss)
I0403 03:53:29.723618  4270 solver.cpp:228] Iteration 4849, loss = 0.00163063
I0403 03:53:29.723732  4270 solver.cpp:244]     Train net output #0: loss = 0.0016306 (* 1 = 0.0016306 loss)
I0403 03:53:29.962720  4270 sgd_solver.cpp:106] Iteration 4849, lr = 0.0005
I0403 03:53:39.676506  4270 solver.cpp:228] Iteration 4862, loss = 0.000940008
I0403 03:53:39.676610  4270 solver.cpp:244]     Train net output #0: loss = 0.000939977 (* 1 = 0.000939977 loss)
I0403 03:53:39.878022  4270 sgd_solver.cpp:106] Iteration 4862, lr = 0.0005
I0403 03:53:49.586479  4270 solver.cpp:228] Iteration 4875, loss = 3.10561e-05
I0403 03:53:49.586598  4270 solver.cpp:244]     Train net output #0: loss = 3.10257e-05 (* 1 = 3.10257e-05 loss)
I0403 03:53:49.834760  4270 sgd_solver.cpp:106] Iteration 4875, lr = 0.0005
I0403 03:53:59.467483  4270 solver.cpp:228] Iteration 4888, loss = 0.00122477
I0403 03:53:59.467793  4270 solver.cpp:244]     Train net output #0: loss = 0.00122474 (* 1 = 0.00122474 loss)
I0403 03:53:59.702927  4270 sgd_solver.cpp:106] Iteration 4888, lr = 0.0005
I0403 03:54:09.330888  4270 solver.cpp:228] Iteration 4901, loss = 5.37693e-05
I0403 03:54:09.331010  4270 solver.cpp:244]     Train net output #0: loss = 5.37391e-05 (* 1 = 5.37391e-05 loss)
I0403 03:54:09.557680  4270 sgd_solver.cpp:106] Iteration 4901, lr = 0.0005
I0403 03:54:19.199272  4270 solver.cpp:228] Iteration 4914, loss = 9.41373e-05
I0403 03:54:19.199388  4270 solver.cpp:244]     Train net output #0: loss = 9.41075e-05 (* 1 = 9.41075e-05 loss)
I0403 03:54:19.410332  4270 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 03:54:29.178158  4270 solver.cpp:228] Iteration 4927, loss = 0.00193212
I0403 03:54:29.178277  4270 solver.cpp:244]     Train net output #0: loss = 0.00193209 (* 1 = 0.00193209 loss)
I0403 03:54:29.397891  4270 sgd_solver.cpp:106] Iteration 4927, lr = 0.0005
I0403 03:54:38.965571  4270 solver.cpp:228] Iteration 4940, loss = 0.000353052
I0403 03:54:38.965906  4270 solver.cpp:244]     Train net output #0: loss = 0.000353022 (* 1 = 0.000353022 loss)
I0403 03:54:39.171356  4270 sgd_solver.cpp:106] Iteration 4940, lr = 0.0005
I0403 03:54:48.787490  4270 solver.cpp:228] Iteration 4953, loss = 0.00015942
I0403 03:54:48.787606  4270 solver.cpp:244]     Train net output #0: loss = 0.00015939 (* 1 = 0.00015939 loss)
I0403 03:54:49.003829  4270 sgd_solver.cpp:106] Iteration 4953, lr = 0.0005
I0403 03:54:58.698673  4270 solver.cpp:228] Iteration 4966, loss = 0.000427892
I0403 03:54:58.698775  4270 solver.cpp:244]     Train net output #0: loss = 0.000427863 (* 1 = 0.000427863 loss)
I0403 03:54:58.899605  4270 sgd_solver.cpp:106] Iteration 4966, lr = 0.0005
I0403 03:55:08.575696  4270 solver.cpp:228] Iteration 4979, loss = 2.59565e-05
I0403 03:55:08.582121  4270 solver.cpp:244]     Train net output #0: loss = 2.59274e-05 (* 1 = 2.59274e-05 loss)
I0403 03:55:08.790109  4270 sgd_solver.cpp:106] Iteration 4979, lr = 0.0005
I0403 03:55:18.486915  4270 solver.cpp:228] Iteration 4992, loss = 0.00012171
I0403 03:55:18.487232  4270 solver.cpp:244]     Train net output #0: loss = 0.000121681 (* 1 = 0.000121681 loss)
I0403 03:55:18.683619  4270 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 03:55:28.316598  4270 solver.cpp:228] Iteration 5005, loss = 0.000361179
I0403 03:55:28.322957  4270 solver.cpp:244]     Train net output #0: loss = 0.00036115 (* 1 = 0.00036115 loss)
I0403 03:55:28.589231  4270 sgd_solver.cpp:106] Iteration 5005, lr = 0.0005
I0403 03:55:38.381804  4270 solver.cpp:228] Iteration 5018, loss = 0.000116274
I0403 03:55:38.388434  4270 solver.cpp:244]     Train net output #0: loss = 0.000116245 (* 1 = 0.000116245 loss)
I0403 03:55:38.638813  4270 sgd_solver.cpp:106] Iteration 5018, lr = 0.0005
I0403 03:55:48.438617  4270 solver.cpp:228] Iteration 5031, loss = 0.0116909
I0403 03:55:48.438732  4270 solver.cpp:244]     Train net output #0: loss = 0.0116909 (* 1 = 0.0116909 loss)
I0403 03:55:48.643275  4270 sgd_solver.cpp:106] Iteration 5031, lr = 0.0005
I0403 03:55:58.283253  4270 solver.cpp:228] Iteration 5044, loss = 0.000279902
I0403 03:55:58.283356  4270 solver.cpp:244]     Train net output #0: loss = 0.000279873 (* 1 = 0.000279873 loss)
I0403 03:55:58.481124  4270 sgd_solver.cpp:106] Iteration 5044, lr = 0.0005
I0403 03:56:08.393573  4270 solver.cpp:228] Iteration 5057, loss = 0.000621876
I0403 03:56:08.393687  4270 solver.cpp:244]     Train net output #0: loss = 0.000621847 (* 1 = 0.000621847 loss)
I0403 03:56:08.601402  4270 sgd_solver.cpp:106] Iteration 5057, lr = 0.0005
I0403 03:56:18.352900  4270 solver.cpp:228] Iteration 5070, loss = 0.00438938
I0403 03:56:18.353021  4270 solver.cpp:244]     Train net output #0: loss = 0.00438935 (* 1 = 0.00438935 loss)
I0403 03:56:18.560480  4270 sgd_solver.cpp:106] Iteration 5070, lr = 0.0005
I0403 03:56:28.382741  4270 solver.cpp:228] Iteration 5083, loss = 0.000586489
I0403 03:56:28.383065  4270 solver.cpp:244]     Train net output #0: loss = 0.00058646 (* 1 = 0.00058646 loss)
I0403 03:56:28.588732  4270 sgd_solver.cpp:106] Iteration 5083, lr = 0.0005
I0403 03:56:38.486829  4270 solver.cpp:228] Iteration 5096, loss = 0.000729197
I0403 03:56:38.486929  4270 solver.cpp:244]     Train net output #0: loss = 0.000729168 (* 1 = 0.000729168 loss)
I0403 03:56:38.688998  4270 sgd_solver.cpp:106] Iteration 5096, lr = 0.0005
I0403 03:56:48.244545  4270 solver.cpp:228] Iteration 5109, loss = 0.000897394
I0403 03:56:48.244664  4270 solver.cpp:244]     Train net output #0: loss = 0.000897364 (* 1 = 0.000897364 loss)
I0403 03:56:48.495136  4270 sgd_solver.cpp:106] Iteration 5109, lr = 0.0005
I0403 03:56:49.264978  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5111.caffemodel
I0403 03:56:52.074939  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5111.solverstate
I0403 03:56:53.959034  4270 solver.cpp:337] Iteration 5111, Testing net (#0)
I0403 03:57:55.177005  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989341
I0403 03:57:55.177330  4270 solver.cpp:404]     Test net output #1: loss = 0.0388775 (* 1 = 0.0388775 loss)
I0403 03:58:04.031729  4270 solver.cpp:228] Iteration 5122, loss = 9.77498e-05
I0403 03:58:04.031848  4270 solver.cpp:244]     Train net output #0: loss = 9.77201e-05 (* 1 = 9.77201e-05 loss)
I0403 03:58:04.249872  4270 sgd_solver.cpp:106] Iteration 5122, lr = 0.0005
I0403 03:58:14.059947  4270 solver.cpp:228] Iteration 5135, loss = 0.000366536
I0403 03:58:14.060056  4270 solver.cpp:244]     Train net output #0: loss = 0.000366506 (* 1 = 0.000366506 loss)
I0403 03:58:14.237056  4270 sgd_solver.cpp:106] Iteration 5135, lr = 0.0005
I0403 03:58:24.199232  4270 solver.cpp:228] Iteration 5148, loss = 0.000432144
I0403 03:58:24.199347  4270 solver.cpp:244]     Train net output #0: loss = 0.000432114 (* 1 = 0.000432114 loss)
I0403 03:58:24.464066  4270 sgd_solver.cpp:106] Iteration 5148, lr = 0.0005
I0403 03:58:34.373008  4270 solver.cpp:228] Iteration 5161, loss = 6.14187e-05
I0403 03:58:34.373317  4270 solver.cpp:244]     Train net output #0: loss = 6.13891e-05 (* 1 = 6.13891e-05 loss)
I0403 03:58:34.563581  4270 sgd_solver.cpp:106] Iteration 5161, lr = 0.0005
I0403 03:58:44.222832  4270 solver.cpp:228] Iteration 5174, loss = 0.000355985
I0403 03:58:44.222950  4270 solver.cpp:244]     Train net output #0: loss = 0.000355955 (* 1 = 0.000355955 loss)
I0403 03:58:44.442688  4270 sgd_solver.cpp:106] Iteration 5174, lr = 0.0005
I0403 03:58:54.073748  4270 solver.cpp:228] Iteration 5187, loss = 0.000388983
I0403 03:58:54.073863  4270 solver.cpp:244]     Train net output #0: loss = 0.000388953 (* 1 = 0.000388953 loss)
I0403 03:58:54.292332  4270 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 03:59:03.965173  4270 solver.cpp:228] Iteration 5200, loss = 0.000939977
I0403 03:59:03.965286  4270 solver.cpp:244]     Train net output #0: loss = 0.000939948 (* 1 = 0.000939948 loss)
I0403 03:59:04.187131  4270 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 03:59:13.802922  4270 solver.cpp:228] Iteration 5213, loss = 0.000212996
I0403 03:59:13.803243  4270 solver.cpp:244]     Train net output #0: loss = 0.000212968 (* 1 = 0.000212968 loss)
I0403 03:59:14.065392  4270 sgd_solver.cpp:106] Iteration 5213, lr = 0.0005
I0403 03:59:23.754899  4270 solver.cpp:228] Iteration 5226, loss = 0.00210892
I0403 03:59:23.755017  4270 solver.cpp:244]     Train net output #0: loss = 0.00210889 (* 1 = 0.00210889 loss)
I0403 03:59:23.983494  4270 sgd_solver.cpp:106] Iteration 5226, lr = 0.0005
I0403 03:59:33.749984  4270 solver.cpp:228] Iteration 5239, loss = 0.000112522
I0403 03:59:33.750108  4270 solver.cpp:244]     Train net output #0: loss = 0.000112492 (* 1 = 0.000112492 loss)
I0403 03:59:33.929044  4270 sgd_solver.cpp:106] Iteration 5239, lr = 0.0005
I0403 03:59:43.785095  4270 solver.cpp:228] Iteration 5252, loss = 0.000136388
I0403 03:59:43.785208  4270 solver.cpp:244]     Train net output #0: loss = 0.000136358 (* 1 = 0.000136358 loss)
I0403 03:59:44.002269  4270 sgd_solver.cpp:106] Iteration 5252, lr = 0.0005
I0403 03:59:53.737196  4270 solver.cpp:228] Iteration 5265, loss = 0.00846229
I0403 03:59:53.737313  4270 solver.cpp:244]     Train net output #0: loss = 0.00846226 (* 1 = 0.00846226 loss)
I0403 03:59:53.954221  4270 sgd_solver.cpp:106] Iteration 5265, lr = 0.0005
I0403 04:00:03.613128  4270 solver.cpp:228] Iteration 5278, loss = 0.000101592
I0403 04:00:03.613246  4270 solver.cpp:244]     Train net output #0: loss = 0.000101562 (* 1 = 0.000101562 loss)
I0403 04:00:03.844848  4270 sgd_solver.cpp:106] Iteration 5278, lr = 0.0005
I0403 04:00:13.520115  4270 solver.cpp:228] Iteration 5291, loss = 0.00013164
I0403 04:00:13.520234  4270 solver.cpp:244]     Train net output #0: loss = 0.00013161 (* 1 = 0.00013161 loss)
I0403 04:00:13.753844  4270 sgd_solver.cpp:106] Iteration 5291, lr = 0.0005
I0403 04:00:23.428225  4270 solver.cpp:228] Iteration 5304, loss = 5.05694e-05
I0403 04:00:23.428567  4270 solver.cpp:244]     Train net output #0: loss = 5.054e-05 (* 1 = 5.054e-05 loss)
I0403 04:00:23.637727  4270 sgd_solver.cpp:106] Iteration 5304, lr = 0.0005
I0403 04:00:33.207237  4270 solver.cpp:228] Iteration 5317, loss = 0.000149613
I0403 04:00:33.207337  4270 solver.cpp:244]     Train net output #0: loss = 0.000149584 (* 1 = 0.000149584 loss)
I0403 04:00:33.403066  4270 sgd_solver.cpp:106] Iteration 5317, lr = 0.0005
I0403 04:00:43.076055  4270 solver.cpp:228] Iteration 5330, loss = 0.000803789
I0403 04:00:43.076171  4270 solver.cpp:244]     Train net output #0: loss = 0.00080376 (* 1 = 0.00080376 loss)
I0403 04:00:43.288735  4270 sgd_solver.cpp:106] Iteration 5330, lr = 0.0005
I0403 04:00:53.122995  4270 solver.cpp:228] Iteration 5343, loss = 0.000160719
I0403 04:00:53.123111  4270 solver.cpp:244]     Train net output #0: loss = 0.00016069 (* 1 = 0.00016069 loss)
I0403 04:00:53.353065  4270 sgd_solver.cpp:106] Iteration 5343, lr = 0.0005
I0403 04:01:03.073462  4270 solver.cpp:228] Iteration 5356, loss = 0.000678438
I0403 04:01:03.079350  4270 solver.cpp:244]     Train net output #0: loss = 0.000678409 (* 1 = 0.000678409 loss)
I0403 04:01:03.283013  4270 sgd_solver.cpp:106] Iteration 5356, lr = 0.0005
I0403 04:01:12.966157  4270 solver.cpp:228] Iteration 5369, loss = 0.00143486
I0403 04:01:12.966271  4270 solver.cpp:244]     Train net output #0: loss = 0.00143483 (* 1 = 0.00143483 loss)
I0403 04:01:13.190033  4270 sgd_solver.cpp:106] Iteration 5369, lr = 0.0005
I0403 04:01:20.894596  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5380.caffemodel
I0403 04:01:23.670047  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5380.solverstate
I0403 04:01:25.556226  4270 solver.cpp:337] Iteration 5380, Testing net (#0)
I0403 04:02:26.624037  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989341
I0403 04:02:26.624384  4270 solver.cpp:404]     Test net output #1: loss = 0.0404762 (* 1 = 0.0404762 loss)
I0403 04:02:28.671388  4270 solver.cpp:228] Iteration 5382, loss = 0.00263127
I0403 04:02:28.671501  4270 solver.cpp:244]     Train net output #0: loss = 0.00263124 (* 1 = 0.00263124 loss)
I0403 04:02:28.883029  4270 sgd_solver.cpp:106] Iteration 5382, lr = 5e-05
I0403 04:02:38.597055  4270 solver.cpp:228] Iteration 5395, loss = 0.000221242
I0403 04:02:38.597169  4270 solver.cpp:244]     Train net output #0: loss = 0.000221212 (* 1 = 0.000221212 loss)
I0403 04:02:38.837869  4270 sgd_solver.cpp:106] Iteration 5395, lr = 5e-05
I0403 04:02:48.581315  4270 solver.cpp:228] Iteration 5408, loss = 0.000182801
I0403 04:02:48.581431  4270 solver.cpp:244]     Train net output #0: loss = 0.000182771 (* 1 = 0.000182771 loss)
I0403 04:02:48.810560  4270 sgd_solver.cpp:106] Iteration 5408, lr = 5e-05
I0403 04:02:58.634687  4270 solver.cpp:228] Iteration 5421, loss = 0.00712625
I0403 04:02:58.634991  4270 solver.cpp:244]     Train net output #0: loss = 0.00712622 (* 1 = 0.00712622 loss)
I0403 04:02:58.836653  4270 sgd_solver.cpp:106] Iteration 5421, lr = 5e-05
I0403 04:03:08.452035  4270 solver.cpp:228] Iteration 5434, loss = 0.000543375
I0403 04:03:08.452152  4270 solver.cpp:244]     Train net output #0: loss = 0.000543344 (* 1 = 0.000543344 loss)
I0403 04:03:08.677677  4270 sgd_solver.cpp:106] Iteration 5434, lr = 5e-05
I0403 04:03:18.289896  4270 solver.cpp:228] Iteration 5447, loss = 0.000967304
I0403 04:03:18.290007  4270 solver.cpp:244]     Train net output #0: loss = 0.000967274 (* 1 = 0.000967274 loss)
I0403 04:03:18.507143  4270 sgd_solver.cpp:106] Iteration 5447, lr = 5e-05
I0403 04:03:28.193869  4270 solver.cpp:228] Iteration 5460, loss = 0.000227615
I0403 04:03:28.193992  4270 solver.cpp:244]     Train net output #0: loss = 0.000227585 (* 1 = 0.000227585 loss)
I0403 04:03:28.415364  4270 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 04:03:38.189785  4270 solver.cpp:228] Iteration 5473, loss = 0.000982452
I0403 04:03:38.190129  4270 solver.cpp:244]     Train net output #0: loss = 0.000982422 (* 1 = 0.000982422 loss)
I0403 04:03:38.393926  4270 sgd_solver.cpp:106] Iteration 5473, lr = 5e-05
I0403 04:03:48.076674  4270 solver.cpp:228] Iteration 5486, loss = 7.4652e-05
I0403 04:03:48.076789  4270 solver.cpp:244]     Train net output #0: loss = 7.46227e-05 (* 1 = 7.46227e-05 loss)
I0403 04:03:48.290576  4270 sgd_solver.cpp:106] Iteration 5486, lr = 5e-05
I0403 04:03:58.071409  4270 solver.cpp:228] Iteration 5499, loss = 0.000235837
I0403 04:03:58.071517  4270 solver.cpp:244]     Train net output #0: loss = 0.000235807 (* 1 = 0.000235807 loss)
I0403 04:03:58.245157  4270 sgd_solver.cpp:106] Iteration 5499, lr = 5e-05
I0403 04:04:08.239192  4270 solver.cpp:228] Iteration 5512, loss = 0.000542202
I0403 04:04:08.239508  4270 solver.cpp:244]     Train net output #0: loss = 0.000542173 (* 1 = 0.000542173 loss)
I0403 04:04:08.458992  4270 sgd_solver.cpp:106] Iteration 5512, lr = 5e-05
I0403 04:04:18.155644  4270 solver.cpp:228] Iteration 5525, loss = 0.00253161
I0403 04:04:18.155758  4270 solver.cpp:244]     Train net output #0: loss = 0.00253159 (* 1 = 0.00253159 loss)
I0403 04:04:18.366281  4270 sgd_solver.cpp:106] Iteration 5525, lr = 5e-05
I0403 04:04:28.049968  4270 solver.cpp:228] Iteration 5538, loss = 0.00532154
I0403 04:04:28.050076  4270 solver.cpp:244]     Train net output #0: loss = 0.00532151 (* 1 = 0.00532151 loss)
I0403 04:04:28.232767  4270 sgd_solver.cpp:106] Iteration 5538, lr = 5e-05
I0403 04:04:37.985659  4270 solver.cpp:228] Iteration 5551, loss = 7.29125e-05
I0403 04:04:37.985762  4270 solver.cpp:244]     Train net output #0: loss = 7.28836e-05 (* 1 = 7.28836e-05 loss)
I0403 04:04:38.179067  4270 sgd_solver.cpp:106] Iteration 5551, lr = 5e-05
I0403 04:04:47.936310  4270 solver.cpp:228] Iteration 5564, loss = 0.00385362
I0403 04:04:47.936594  4270 solver.cpp:244]     Train net output #0: loss = 0.0038536 (* 1 = 0.0038536 loss)
I0403 04:04:48.150629  4270 sgd_solver.cpp:106] Iteration 5564, lr = 5e-05
I0403 04:04:57.872851  4270 solver.cpp:228] Iteration 5577, loss = 0.000130005
I0403 04:04:57.872962  4270 solver.cpp:244]     Train net output #0: loss = 0.000129977 (* 1 = 0.000129977 loss)
I0403 04:04:58.077211  4270 sgd_solver.cpp:106] Iteration 5577, lr = 5e-05
I0403 04:05:07.957216  4270 solver.cpp:228] Iteration 5590, loss = 0.000557631
I0403 04:05:07.957329  4270 solver.cpp:244]     Train net output #0: loss = 0.000557604 (* 1 = 0.000557604 loss)
I0403 04:05:08.163146  4270 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 04:05:17.785107  4270 solver.cpp:228] Iteration 5603, loss = 0.00188119
I0403 04:05:17.785226  4270 solver.cpp:244]     Train net output #0: loss = 0.00188117 (* 1 = 0.00188117 loss)
I0403 04:05:18.000623  4270 sgd_solver.cpp:106] Iteration 5603, lr = 5e-05
I0403 04:05:27.709300  4270 solver.cpp:228] Iteration 5616, loss = 0.000467678
I0403 04:05:27.709414  4270 solver.cpp:244]     Train net output #0: loss = 0.00046765 (* 1 = 0.00046765 loss)
I0403 04:05:27.930898  4270 sgd_solver.cpp:106] Iteration 5616, lr = 5e-05
I0403 04:05:37.799103  4270 solver.cpp:228] Iteration 5629, loss = 0.000917482
I0403 04:05:37.799221  4270 solver.cpp:244]     Train net output #0: loss = 0.000917455 (* 1 = 0.000917455 loss)
I0403 04:05:37.978423  4270 sgd_solver.cpp:106] Iteration 5629, lr = 5e-05
I0403 04:05:47.733137  4270 solver.cpp:228] Iteration 5642, loss = 9.97355e-05
I0403 04:05:47.733256  4270 solver.cpp:244]     Train net output #0: loss = 9.97083e-05 (* 1 = 9.97083e-05 loss)
I0403 04:05:47.939075  4270 sgd_solver.cpp:106] Iteration 5642, lr = 5e-05
I0403 04:05:52.503563  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5649.caffemodel
I0403 04:05:55.328300  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5649.solverstate
I0403 04:05:57.147369  4270 solver.cpp:337] Iteration 5649, Testing net (#0)
I0403 04:06:58.255798  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989231
I0403 04:06:58.256105  4270 solver.cpp:404]     Test net output #1: loss = 0.0401632 (* 1 = 0.0401632 loss)
I0403 04:07:03.419498  4270 solver.cpp:228] Iteration 5655, loss = 0.000164376
I0403 04:07:03.419612  4270 solver.cpp:244]     Train net output #0: loss = 0.000164349 (* 1 = 0.000164349 loss)
I0403 04:07:03.687351  4270 sgd_solver.cpp:106] Iteration 5655, lr = 5e-05
I0403 04:07:13.502809  4270 solver.cpp:228] Iteration 5668, loss = 0.000344011
I0403 04:07:13.502923  4270 solver.cpp:244]     Train net output #0: loss = 0.000343984 (* 1 = 0.000343984 loss)
I0403 04:07:13.722051  4270 sgd_solver.cpp:106] Iteration 5668, lr = 5e-05
I0403 04:07:23.477280  4270 solver.cpp:228] Iteration 5681, loss = 0.00182836
I0403 04:07:23.477382  4270 solver.cpp:244]     Train net output #0: loss = 0.00182833 (* 1 = 0.00182833 loss)
I0403 04:07:23.676223  4270 sgd_solver.cpp:106] Iteration 5681, lr = 5e-05
I0403 04:07:33.415012  4270 solver.cpp:228] Iteration 5694, loss = 0.000244449
I0403 04:07:33.415326  4270 solver.cpp:244]     Train net output #0: loss = 0.000244422 (* 1 = 0.000244422 loss)
I0403 04:07:33.628115  4270 sgd_solver.cpp:106] Iteration 5694, lr = 5e-05
I0403 04:07:43.226420  4270 solver.cpp:228] Iteration 5707, loss = 0.00111463
I0403 04:07:43.226536  4270 solver.cpp:244]     Train net output #0: loss = 0.0011146 (* 1 = 0.0011146 loss)
I0403 04:07:43.468868  4270 sgd_solver.cpp:106] Iteration 5707, lr = 5e-05
I0403 04:07:53.517063  4270 solver.cpp:228] Iteration 5720, loss = 0.00074024
I0403 04:07:53.517182  4270 solver.cpp:244]     Train net output #0: loss = 0.000740213 (* 1 = 0.000740213 loss)
I0403 04:07:53.733068  4270 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 04:08:03.544210  4270 solver.cpp:228] Iteration 5733, loss = 0.000285028
I0403 04:08:03.544523  4270 solver.cpp:244]     Train net output #0: loss = 0.000285001 (* 1 = 0.000285001 loss)
I0403 04:08:03.767820  4270 sgd_solver.cpp:106] Iteration 5733, lr = 5e-05
I0403 04:08:13.602133  4270 solver.cpp:228] Iteration 5746, loss = 0.000916191
I0403 04:08:13.602247  4270 solver.cpp:244]     Train net output #0: loss = 0.000916164 (* 1 = 0.000916164 loss)
I0403 04:08:13.817651  4270 sgd_solver.cpp:106] Iteration 5746, lr = 5e-05
I0403 04:08:23.428037  4270 solver.cpp:228] Iteration 5759, loss = 0.000685454
I0403 04:08:23.428148  4270 solver.cpp:244]     Train net output #0: loss = 0.000685428 (* 1 = 0.000685428 loss)
I0403 04:08:23.640636  4270 sgd_solver.cpp:106] Iteration 5759, lr = 5e-05
I0403 04:08:33.242897  4270 solver.cpp:228] Iteration 5772, loss = 0.00157921
I0403 04:08:33.243022  4270 solver.cpp:244]     Train net output #0: loss = 0.00157918 (* 1 = 0.00157918 loss)
I0403 04:08:33.447937  4270 sgd_solver.cpp:106] Iteration 5772, lr = 5e-05
I0403 04:08:43.167681  4270 solver.cpp:228] Iteration 5785, loss = 0.000459726
I0403 04:08:43.167980  4270 solver.cpp:244]     Train net output #0: loss = 0.000459699 (* 1 = 0.000459699 loss)
I0403 04:08:43.376772  4270 sgd_solver.cpp:106] Iteration 5785, lr = 5e-05
I0403 04:08:53.024921  4270 solver.cpp:228] Iteration 5798, loss = 0.000190132
I0403 04:08:53.025041  4270 solver.cpp:244]     Train net output #0: loss = 0.000190106 (* 1 = 0.000190106 loss)
I0403 04:08:53.248175  4270 sgd_solver.cpp:106] Iteration 5798, lr = 5e-05
I0403 04:09:03.021618  4270 solver.cpp:228] Iteration 5811, loss = 0.000220659
I0403 04:09:03.021733  4270 solver.cpp:244]     Train net output #0: loss = 0.000220633 (* 1 = 0.000220633 loss)
I0403 04:09:03.231691  4270 sgd_solver.cpp:106] Iteration 5811, lr = 5e-05
I0403 04:09:12.967855  4270 solver.cpp:228] Iteration 5824, loss = 0.000187334
I0403 04:09:12.968763  4270 solver.cpp:244]     Train net output #0: loss = 0.000187308 (* 1 = 0.000187308 loss)
I0403 04:09:13.172057  4270 sgd_solver.cpp:106] Iteration 5824, lr = 5e-05
I0403 04:09:23.024535  4270 solver.cpp:228] Iteration 5837, loss = 0.00179149
I0403 04:09:23.024651  4270 solver.cpp:244]     Train net output #0: loss = 0.00179147 (* 1 = 0.00179147 loss)
I0403 04:09:23.239711  4270 sgd_solver.cpp:106] Iteration 5837, lr = 5e-05
I0403 04:09:32.880656  4270 solver.cpp:228] Iteration 5850, loss = 0.00173198
I0403 04:09:32.880771  4270 solver.cpp:244]     Train net output #0: loss = 0.00173196 (* 1 = 0.00173196 loss)
I0403 04:09:33.142276  4270 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 04:09:42.922818  4270 solver.cpp:228] Iteration 5863, loss = 0.000346204
I0403 04:09:42.922930  4270 solver.cpp:244]     Train net output #0: loss = 0.000346179 (* 1 = 0.000346179 loss)
I0403 04:09:43.168424  4270 sgd_solver.cpp:106] Iteration 5863, lr = 5e-05
I0403 04:09:52.828738  4270 solver.cpp:228] Iteration 5876, loss = 0.00121543
I0403 04:09:52.832736  4270 solver.cpp:244]     Train net output #0: loss = 0.00121541 (* 1 = 0.00121541 loss)
I0403 04:09:53.052080  4270 sgd_solver.cpp:106] Iteration 5876, lr = 5e-05
I0403 04:10:02.813284  4270 solver.cpp:228] Iteration 5889, loss = 0.000285608
I0403 04:10:02.813386  4270 solver.cpp:244]     Train net output #0: loss = 0.000285583 (* 1 = 0.000285583 loss)
I0403 04:10:02.999954  4270 sgd_solver.cpp:106] Iteration 5889, lr = 5e-05
I0403 04:10:12.900341  4270 solver.cpp:228] Iteration 5902, loss = 0.0145511
I0403 04:10:12.900444  4270 solver.cpp:244]     Train net output #0: loss = 0.0145511 (* 1 = 0.0145511 loss)
I0403 04:10:13.061712  4270 sgd_solver.cpp:106] Iteration 5902, lr = 5e-05
I0403 04:10:23.255455  4270 solver.cpp:228] Iteration 5915, loss = 0.0150855
I0403 04:10:23.255769  4270 solver.cpp:244]     Train net output #0: loss = 0.0150855 (* 1 = 0.0150855 loss)
I0403 04:10:23.473923  4270 sgd_solver.cpp:106] Iteration 5915, lr = 5e-05
I0403 04:10:24.984397  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5918.caffemodel
I0403 04:10:27.792999  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_5918.solverstate
I0403 04:10:29.617636  4270 solver.cpp:337] Iteration 5918, Testing net (#0)
I0403 04:11:30.727330  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989304
I0403 04:11:30.727637  4270 solver.cpp:404]     Test net output #1: loss = 0.0405111 (* 1 = 0.0405111 loss)
I0403 04:11:38.852062  4270 solver.cpp:228] Iteration 5928, loss = 0.0179592
I0403 04:11:38.852179  4270 solver.cpp:244]     Train net output #0: loss = 0.0179592 (* 1 = 0.0179592 loss)
I0403 04:11:39.059120  4270 sgd_solver.cpp:106] Iteration 5928, lr = 5e-05
I0403 04:11:48.856137  4270 solver.cpp:228] Iteration 5941, loss = 0.000645468
I0403 04:11:48.856251  4270 solver.cpp:244]     Train net output #0: loss = 0.000645442 (* 1 = 0.000645442 loss)
I0403 04:11:49.073429  4270 sgd_solver.cpp:106] Iteration 5941, lr = 5e-05
I0403 04:11:58.719332  4270 solver.cpp:228] Iteration 5954, loss = 0.00865184
I0403 04:11:58.719434  4270 solver.cpp:244]     Train net output #0: loss = 0.00865182 (* 1 = 0.00865182 loss)
I0403 04:11:58.912236  4270 sgd_solver.cpp:106] Iteration 5954, lr = 5e-05
I0403 04:12:08.719580  4270 solver.cpp:228] Iteration 5967, loss = 0.000458025
I0403 04:12:08.719905  4270 solver.cpp:244]     Train net output #0: loss = 0.000458 (* 1 = 0.000458 loss)
I0403 04:12:08.936908  4270 sgd_solver.cpp:106] Iteration 5967, lr = 5e-05
I0403 04:12:18.938159  4270 solver.cpp:228] Iteration 5980, loss = 0.00552488
I0403 04:12:18.938273  4270 solver.cpp:244]     Train net output #0: loss = 0.00552486 (* 1 = 0.00552486 loss)
I0403 04:12:19.142279  4270 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 04:12:29.290715  4270 solver.cpp:228] Iteration 5993, loss = 9.68464e-05
I0403 04:12:29.292042  4270 solver.cpp:244]     Train net output #0: loss = 9.68192e-05 (* 1 = 9.68192e-05 loss)
I0403 04:12:29.465827  4270 sgd_solver.cpp:106] Iteration 5993, lr = 5e-05
I0403 04:12:39.428212  4270 solver.cpp:228] Iteration 6006, loss = 0.000560095
I0403 04:12:39.428565  4270 solver.cpp:244]     Train net output #0: loss = 0.000560067 (* 1 = 0.000560067 loss)
I0403 04:12:39.633117  4270 sgd_solver.cpp:106] Iteration 6006, lr = 5e-05
I0403 04:12:49.346755  4270 solver.cpp:228] Iteration 6019, loss = 0.00105154
I0403 04:12:49.346879  4270 solver.cpp:244]     Train net output #0: loss = 0.00105151 (* 1 = 0.00105151 loss)
I0403 04:12:49.554067  4270 sgd_solver.cpp:106] Iteration 6019, lr = 5e-05
I0403 04:12:59.175514  4270 solver.cpp:228] Iteration 6032, loss = 0.000155121
I0403 04:12:59.175627  4270 solver.cpp:244]     Train net output #0: loss = 0.000155093 (* 1 = 0.000155093 loss)
I0403 04:12:59.397737  4270 sgd_solver.cpp:106] Iteration 6032, lr = 5e-05
I0403 04:13:09.047632  4270 solver.cpp:228] Iteration 6045, loss = 0.000225549
I0403 04:13:09.047750  4270 solver.cpp:244]     Train net output #0: loss = 0.000225522 (* 1 = 0.000225522 loss)
I0403 04:13:09.268414  4270 sgd_solver.cpp:106] Iteration 6045, lr = 5e-05
I0403 04:13:19.052726  4270 solver.cpp:228] Iteration 6058, loss = 0.00463851
I0403 04:13:19.053047  4270 solver.cpp:244]     Train net output #0: loss = 0.00463848 (* 1 = 0.00463848 loss)
I0403 04:13:19.260496  4270 sgd_solver.cpp:106] Iteration 6058, lr = 5e-05
I0403 04:13:29.107100  4270 solver.cpp:228] Iteration 6071, loss = 0.00654424
I0403 04:13:29.107203  4270 solver.cpp:244]     Train net output #0: loss = 0.00654421 (* 1 = 0.00654421 loss)
I0403 04:13:29.300537  4270 sgd_solver.cpp:106] Iteration 6071, lr = 5e-05
I0403 04:13:39.135435  4270 solver.cpp:228] Iteration 6084, loss = 0.000735223
I0403 04:13:39.135552  4270 solver.cpp:244]     Train net output #0: loss = 0.000735195 (* 1 = 0.000735195 loss)
I0403 04:13:39.371095  4270 sgd_solver.cpp:106] Iteration 6084, lr = 5e-05
I0403 04:13:49.025836  4270 solver.cpp:228] Iteration 6097, loss = 6.69952e-05
I0403 04:13:49.025960  4270 solver.cpp:244]     Train net output #0: loss = 6.69676e-05 (* 1 = 6.69676e-05 loss)
I0403 04:13:49.313803  4270 sgd_solver.cpp:106] Iteration 6097, lr = 5e-05
I0403 04:13:58.985218  4270 solver.cpp:228] Iteration 6110, loss = 0.00134961
I0403 04:13:58.985330  4270 solver.cpp:244]     Train net output #0: loss = 0.00134958 (* 1 = 0.00134958 loss)
I0403 04:13:59.193178  4270 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 04:14:08.889942  4270 solver.cpp:228] Iteration 6123, loss = 0.000103533
I0403 04:14:08.890050  4270 solver.cpp:244]     Train net output #0: loss = 0.000103505 (* 1 = 0.000103505 loss)
I0403 04:14:09.084513  4270 sgd_solver.cpp:106] Iteration 6123, lr = 5e-05
I0403 04:14:18.864321  4270 solver.cpp:228] Iteration 6136, loss = 0.00260509
I0403 04:14:18.864441  4270 solver.cpp:244]     Train net output #0: loss = 0.00260507 (* 1 = 0.00260507 loss)
I0403 04:14:19.070659  4270 sgd_solver.cpp:106] Iteration 6136, lr = 5e-05
I0403 04:14:28.671074  4270 solver.cpp:228] Iteration 6149, loss = 0.000153908
I0403 04:14:28.671435  4270 solver.cpp:244]     Train net output #0: loss = 0.00015388 (* 1 = 0.00015388 loss)
I0403 04:14:28.960175  4270 sgd_solver.cpp:106] Iteration 6149, lr = 5e-05
I0403 04:14:38.770615  4270 solver.cpp:228] Iteration 6162, loss = 0.000424254
I0403 04:14:38.770726  4270 solver.cpp:244]     Train net output #0: loss = 0.000424226 (* 1 = 0.000424226 loss)
I0403 04:14:38.933133  4270 sgd_solver.cpp:106] Iteration 6162, lr = 5e-05
I0403 04:14:48.623252  4270 solver.cpp:228] Iteration 6175, loss = 0.000398304
I0403 04:14:48.623371  4270 solver.cpp:244]     Train net output #0: loss = 0.000398279 (* 1 = 0.000398279 loss)
I0403 04:14:48.833009  4270 sgd_solver.cpp:106] Iteration 6175, lr = 5e-05
I0403 04:14:57.108032  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6187.caffemodel
I0403 04:15:01.854234  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6187.solverstate
I0403 04:15:04.061174  4270 solver.cpp:337] Iteration 6187, Testing net (#0)
I0403 04:16:05.131125  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989378
I0403 04:16:05.131441  4270 solver.cpp:404]     Test net output #1: loss = 0.0403962 (* 1 = 0.0403962 loss)
I0403 04:16:06.411764  4270 solver.cpp:228] Iteration 6188, loss = 0.000227266
I0403 04:16:06.411864  4270 solver.cpp:244]     Train net output #0: loss = 0.000227239 (* 1 = 0.000227239 loss)
I0403 04:16:06.611650  4270 sgd_solver.cpp:106] Iteration 6188, lr = 5e-05
I0403 04:16:16.377535  4270 solver.cpp:228] Iteration 6201, loss = 0.000359699
I0403 04:16:16.377650  4270 solver.cpp:244]     Train net output #0: loss = 0.000359672 (* 1 = 0.000359672 loss)
I0403 04:16:16.597287  4270 sgd_solver.cpp:106] Iteration 6201, lr = 5e-05
I0403 04:16:26.280033  4270 solver.cpp:228] Iteration 6214, loss = 4.34052e-05
I0403 04:16:26.280148  4270 solver.cpp:244]     Train net output #0: loss = 4.33792e-05 (* 1 = 4.33792e-05 loss)
I0403 04:16:26.504477  4270 sgd_solver.cpp:106] Iteration 6214, lr = 5e-05
I0403 04:16:36.169589  4270 solver.cpp:228] Iteration 6227, loss = 0.000767701
I0403 04:16:36.169895  4270 solver.cpp:244]     Train net output #0: loss = 0.000767675 (* 1 = 0.000767675 loss)
I0403 04:16:36.353065  4270 sgd_solver.cpp:106] Iteration 6227, lr = 5e-05
I0403 04:16:46.431567  4270 solver.cpp:228] Iteration 6240, loss = 0.000532906
I0403 04:16:46.431675  4270 solver.cpp:244]     Train net output #0: loss = 0.00053288 (* 1 = 0.00053288 loss)
I0403 04:16:46.596261  4270 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 04:16:56.497356  4270 solver.cpp:228] Iteration 6253, loss = 1.1994e-05
I0403 04:16:56.497474  4270 solver.cpp:244]     Train net output #0: loss = 1.19679e-05 (* 1 = 1.19679e-05 loss)
I0403 04:16:56.704944  4270 sgd_solver.cpp:106] Iteration 6253, lr = 5e-05
I0403 04:17:06.409163  4270 solver.cpp:228] Iteration 6266, loss = 0.00890427
I0403 04:17:06.409489  4270 solver.cpp:244]     Train net output #0: loss = 0.00890425 (* 1 = 0.00890425 loss)
I0403 04:17:06.640396  4270 sgd_solver.cpp:106] Iteration 6266, lr = 5e-05
I0403 04:17:16.278188  4270 solver.cpp:228] Iteration 6279, loss = 0.000302974
I0403 04:17:16.278306  4270 solver.cpp:244]     Train net output #0: loss = 0.000302946 (* 1 = 0.000302946 loss)
I0403 04:17:16.483608  4270 sgd_solver.cpp:106] Iteration 6279, lr = 5e-05
I0403 04:17:26.370964  4270 solver.cpp:228] Iteration 6292, loss = 0.00776867
I0403 04:17:26.371070  4270 solver.cpp:244]     Train net output #0: loss = 0.00776864 (* 1 = 0.00776864 loss)
I0403 04:17:26.532367  4270 sgd_solver.cpp:106] Iteration 6292, lr = 5e-05
I0403 04:17:36.565156  4270 solver.cpp:228] Iteration 6305, loss = 0.00219677
I0403 04:17:36.565477  4270 solver.cpp:244]     Train net output #0: loss = 0.00219674 (* 1 = 0.00219674 loss)
I0403 04:17:36.782968  4270 sgd_solver.cpp:106] Iteration 6305, lr = 5e-05
I0403 04:17:46.702914  4270 solver.cpp:228] Iteration 6318, loss = 3.70417e-05
I0403 04:17:46.703040  4270 solver.cpp:244]     Train net output #0: loss = 3.70139e-05 (* 1 = 3.70139e-05 loss)
I0403 04:17:46.920876  4270 sgd_solver.cpp:106] Iteration 6318, lr = 5e-05
I0403 04:17:56.648313  4270 solver.cpp:228] Iteration 6331, loss = 0.000299489
I0403 04:17:56.648433  4270 solver.cpp:244]     Train net output #0: loss = 0.00029946 (* 1 = 0.00029946 loss)
I0403 04:17:56.856894  4270 sgd_solver.cpp:106] Iteration 6331, lr = 5e-05
I0403 04:18:06.937769  4270 solver.cpp:228] Iteration 6344, loss = 3.15142e-05
I0403 04:18:06.938081  4270 solver.cpp:244]     Train net output #0: loss = 3.14844e-05 (* 1 = 3.14844e-05 loss)
I0403 04:18:07.145031  4270 sgd_solver.cpp:106] Iteration 6344, lr = 5e-05
I0403 04:18:16.886535  4270 solver.cpp:228] Iteration 6357, loss = 0.000467675
I0403 04:18:16.886644  4270 solver.cpp:244]     Train net output #0: loss = 0.000467645 (* 1 = 0.000467645 loss)
I0403 04:18:17.098598  4270 sgd_solver.cpp:106] Iteration 6357, lr = 5e-05
I0403 04:18:27.015311  4270 solver.cpp:228] Iteration 6370, loss = 0.000489484
I0403 04:18:27.015419  4270 solver.cpp:244]     Train net output #0: loss = 0.000489454 (* 1 = 0.000489454 loss)
I0403 04:18:27.229822  4270 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 04:18:36.865643  4270 solver.cpp:228] Iteration 6383, loss = 0.000331237
I0403 04:18:36.865756  4270 solver.cpp:244]     Train net output #0: loss = 0.000331207 (* 1 = 0.000331207 loss)
I0403 04:18:37.079830  4270 sgd_solver.cpp:106] Iteration 6383, lr = 5e-05
I0403 04:18:46.713030  4270 solver.cpp:228] Iteration 6396, loss = 0.000334563
I0403 04:18:46.713146  4270 solver.cpp:244]     Train net output #0: loss = 0.000334535 (* 1 = 0.000334535 loss)
I0403 04:18:46.994158  4270 sgd_solver.cpp:106] Iteration 6396, lr = 5e-05
I0403 04:18:56.646795  4270 solver.cpp:228] Iteration 6409, loss = 0.000534732
I0403 04:18:56.646914  4270 solver.cpp:244]     Train net output #0: loss = 0.000534705 (* 1 = 0.000534705 loss)
I0403 04:18:56.852444  4270 sgd_solver.cpp:106] Iteration 6409, lr = 5e-05
I0403 04:19:06.418439  4270 solver.cpp:228] Iteration 6422, loss = 0.00179184
I0403 04:19:06.418558  4270 solver.cpp:244]     Train net output #0: loss = 0.00179182 (* 1 = 0.00179182 loss)
I0403 04:19:06.674520  4270 sgd_solver.cpp:106] Iteration 6422, lr = 5e-05
I0403 04:19:16.761462  4270 solver.cpp:228] Iteration 6435, loss = 6.18337e-05
I0403 04:19:16.761786  4270 solver.cpp:244]     Train net output #0: loss = 6.18066e-05 (* 1 = 6.18066e-05 loss)
I0403 04:19:16.976461  4270 sgd_solver.cpp:106] Iteration 6435, lr = 5e-05
I0403 04:19:26.689280  4270 solver.cpp:228] Iteration 6448, loss = 0.000992134
I0403 04:19:26.689401  4270 solver.cpp:244]     Train net output #0: loss = 0.000992106 (* 1 = 0.000992106 loss)
I0403 04:19:26.897748  4270 sgd_solver.cpp:106] Iteration 6448, lr = 5e-05
I0403 04:19:32.277668  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6456.caffemodel
I0403 04:19:35.010131  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6456.solverstate
I0403 04:19:36.853152  4270 solver.cpp:337] Iteration 6456, Testing net (#0)
I0403 04:20:37.986383  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989598
I0403 04:20:37.986706  4270 solver.cpp:404]     Test net output #1: loss = 0.0398343 (* 1 = 0.0398343 loss)
I0403 04:20:42.304052  4270 solver.cpp:228] Iteration 6461, loss = 0.000459212
I0403 04:20:42.304173  4270 solver.cpp:244]     Train net output #0: loss = 0.000459184 (* 1 = 0.000459184 loss)
I0403 04:20:42.571492  4270 sgd_solver.cpp:106] Iteration 6461, lr = 5e-05
I0403 04:20:52.265353  4270 solver.cpp:228] Iteration 6474, loss = 0.000457256
I0403 04:20:52.265470  4270 solver.cpp:244]     Train net output #0: loss = 0.000457228 (* 1 = 0.000457228 loss)
I0403 04:20:52.486786  4270 sgd_solver.cpp:106] Iteration 6474, lr = 5e-05
I0403 04:21:02.281028  4270 solver.cpp:228] Iteration 6487, loss = 0.00031952
I0403 04:21:02.281127  4270 solver.cpp:244]     Train net output #0: loss = 0.000319493 (* 1 = 0.000319493 loss)
I0403 04:21:02.463217  4270 sgd_solver.cpp:106] Iteration 6487, lr = 5e-05
I0403 04:21:12.378692  4270 solver.cpp:228] Iteration 6500, loss = 7.24292e-05
I0403 04:21:12.379015  4270 solver.cpp:244]     Train net output #0: loss = 7.24025e-05 (* 1 = 7.24025e-05 loss)
I0403 04:21:12.579814  4270 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 04:21:22.272591  4270 solver.cpp:228] Iteration 6513, loss = 0.000179287
I0403 04:21:22.272711  4270 solver.cpp:244]     Train net output #0: loss = 0.000179261 (* 1 = 0.000179261 loss)
I0403 04:21:22.479972  4270 sgd_solver.cpp:106] Iteration 6513, lr = 5e-05
I0403 04:21:32.286396  4270 solver.cpp:228] Iteration 6526, loss = 0.00151053
I0403 04:21:32.287468  4270 solver.cpp:244]     Train net output #0: loss = 0.0015105 (* 1 = 0.0015105 loss)
I0403 04:21:32.502820  4270 sgd_solver.cpp:106] Iteration 6526, lr = 5e-05
I0403 04:21:42.335623  4270 solver.cpp:228] Iteration 6539, loss = 0.000663587
I0403 04:21:42.335739  4270 solver.cpp:244]     Train net output #0: loss = 0.00066356 (* 1 = 0.00066356 loss)
I0403 04:21:42.557029  4270 sgd_solver.cpp:106] Iteration 6539, lr = 5e-05
I0403 04:21:52.251874  4270 solver.cpp:228] Iteration 6552, loss = 0.000171009
I0403 04:21:52.252008  4270 solver.cpp:244]     Train net output #0: loss = 0.000170982 (* 1 = 0.000170982 loss)
I0403 04:21:52.470306  4270 sgd_solver.cpp:106] Iteration 6552, lr = 5e-05
I0403 04:22:02.309764  4270 solver.cpp:228] Iteration 6565, loss = 0.000966798
I0403 04:22:02.309876  4270 solver.cpp:244]     Train net output #0: loss = 0.000966771 (* 1 = 0.000966771 loss)
I0403 04:22:02.523527  4270 sgd_solver.cpp:106] Iteration 6565, lr = 5e-05
I0403 04:22:12.327500  4270 solver.cpp:228] Iteration 6578, loss = 0.00646675
I0403 04:22:12.327607  4270 solver.cpp:244]     Train net output #0: loss = 0.00646672 (* 1 = 0.00646672 loss)
I0403 04:22:12.519855  4270 sgd_solver.cpp:106] Iteration 6578, lr = 5e-05
I0403 04:22:22.347234  4270 solver.cpp:228] Iteration 6591, loss = 0.000122567
I0403 04:22:22.347545  4270 solver.cpp:244]     Train net output #0: loss = 0.000122539 (* 1 = 0.000122539 loss)
I0403 04:22:22.539654  4270 sgd_solver.cpp:106] Iteration 6591, lr = 5e-05
I0403 04:22:32.495939  4270 solver.cpp:228] Iteration 6604, loss = 0.000960316
I0403 04:22:32.496062  4270 solver.cpp:244]     Train net output #0: loss = 0.000960287 (* 1 = 0.000960287 loss)
I0403 04:22:32.727955  4270 sgd_solver.cpp:106] Iteration 6604, lr = 5e-05
I0403 04:22:42.445411  4270 solver.cpp:228] Iteration 6617, loss = 0.00330224
I0403 04:22:42.445528  4270 solver.cpp:244]     Train net output #0: loss = 0.00330221 (* 1 = 0.00330221 loss)
I0403 04:22:42.671133  4270 sgd_solver.cpp:106] Iteration 6617, lr = 5e-05
I0403 04:22:52.651057  4270 solver.cpp:228] Iteration 6630, loss = 0.00158014
I0403 04:22:52.651387  4270 solver.cpp:244]     Train net output #0: loss = 0.00158011 (* 1 = 0.00158011 loss)
I0403 04:22:52.829576  4270 sgd_solver.cpp:106] Iteration 6630, lr = 5e-05
I0403 04:23:02.702980  4270 solver.cpp:228] Iteration 6643, loss = 5.11316e-05
I0403 04:23:02.703088  4270 solver.cpp:244]     Train net output #0: loss = 5.11026e-05 (* 1 = 5.11026e-05 loss)
I0403 04:23:02.891371  4270 sgd_solver.cpp:106] Iteration 6643, lr = 5e-05
I0403 04:23:12.784031  4270 solver.cpp:228] Iteration 6656, loss = 0.000131598
I0403 04:23:12.784147  4270 solver.cpp:244]     Train net output #0: loss = 0.000131569 (* 1 = 0.000131569 loss)
I0403 04:23:12.995733  4270 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 04:23:22.778898  4270 solver.cpp:228] Iteration 6669, loss = 0.00142547
I0403 04:23:22.779172  4270 solver.cpp:244]     Train net output #0: loss = 0.00142544 (* 1 = 0.00142544 loss)
I0403 04:23:22.981432  4270 sgd_solver.cpp:106] Iteration 6669, lr = 5e-05
I0403 04:23:32.592839  4270 solver.cpp:228] Iteration 6682, loss = 0.00594304
I0403 04:23:32.592962  4270 solver.cpp:244]     Train net output #0: loss = 0.00594301 (* 1 = 0.00594301 loss)
I0403 04:23:32.821429  4270 sgd_solver.cpp:106] Iteration 6682, lr = 5e-05
I0403 04:23:42.518107  4270 solver.cpp:228] Iteration 6695, loss = 0.000190126
I0403 04:23:42.518218  4270 solver.cpp:244]     Train net output #0: loss = 0.000190096 (* 1 = 0.000190096 loss)
I0403 04:23:42.670019  4270 sgd_solver.cpp:106] Iteration 6695, lr = 5e-05
I0403 04:23:52.596406  4270 solver.cpp:228] Iteration 6708, loss = 0.000467183
I0403 04:23:52.596523  4270 solver.cpp:244]     Train net output #0: loss = 0.000467154 (* 1 = 0.000467154 loss)
I0403 04:23:52.812902  4270 sgd_solver.cpp:106] Iteration 6708, lr = 5e-05
I0403 04:24:02.545079  4270 solver.cpp:228] Iteration 6721, loss = 0.0032574
I0403 04:24:02.545194  4270 solver.cpp:244]     Train net output #0: loss = 0.00325737 (* 1 = 0.00325737 loss)
I0403 04:24:02.769843  4270 sgd_solver.cpp:106] Iteration 6721, lr = 5e-05
I0403 04:24:05.041940  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6725.caffemodel
I0403 04:24:07.817548  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6725.solverstate
I0403 04:24:09.609967  4270 solver.cpp:337] Iteration 6725, Testing net (#0)
I0403 04:25:10.740090  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989561
I0403 04:25:10.740442  4270 solver.cpp:404]     Test net output #1: loss = 0.0396873 (* 1 = 0.0396873 loss)
I0403 04:25:18.197046  4270 solver.cpp:228] Iteration 6734, loss = 0.000571408
I0403 04:25:18.197149  4270 solver.cpp:244]     Train net output #0: loss = 0.000571378 (* 1 = 0.000571378 loss)
I0403 04:25:18.388234  4270 sgd_solver.cpp:106] Iteration 6734, lr = 5e-05
I0403 04:25:28.175909  4270 solver.cpp:228] Iteration 6747, loss = 0.000250008
I0403 04:25:28.176033  4270 solver.cpp:244]     Train net output #0: loss = 0.000249977 (* 1 = 0.000249977 loss)
I0403 04:25:28.423481  4270 sgd_solver.cpp:106] Iteration 6747, lr = 5e-05
I0403 04:25:37.982175  4270 solver.cpp:228] Iteration 6760, loss = 0.00219931
I0403 04:25:37.982298  4270 solver.cpp:244]     Train net output #0: loss = 0.00219928 (* 1 = 0.00219928 loss)
I0403 04:25:38.213893  4270 sgd_solver.cpp:106] Iteration 6760, lr = 5e-05
I0403 04:25:48.056582  4270 solver.cpp:228] Iteration 6773, loss = 0.000496585
I0403 04:25:48.056913  4270 solver.cpp:244]     Train net output #0: loss = 0.000496553 (* 1 = 0.000496553 loss)
I0403 04:25:48.309168  4270 sgd_solver.cpp:106] Iteration 6773, lr = 5e-05
I0403 04:25:57.876581  4270 solver.cpp:228] Iteration 6786, loss = 0.000219389
I0403 04:25:57.876680  4270 solver.cpp:244]     Train net output #0: loss = 0.000219355 (* 1 = 0.000219355 loss)
I0403 04:25:58.079619  4270 sgd_solver.cpp:106] Iteration 6786, lr = 5e-05
I0403 04:26:07.655369  4270 solver.cpp:228] Iteration 6799, loss = 0.00245978
I0403 04:26:07.655490  4270 solver.cpp:244]     Train net output #0: loss = 0.00245975 (* 1 = 0.00245975 loss)
I0403 04:26:07.900979  4270 sgd_solver.cpp:106] Iteration 6799, lr = 5e-05
I0403 04:26:17.930099  4270 solver.cpp:228] Iteration 6812, loss = 0.00170615
I0403 04:26:17.930207  4270 solver.cpp:244]     Train net output #0: loss = 0.00170611 (* 1 = 0.00170611 loss)
I0403 04:26:18.117223  4270 sgd_solver.cpp:106] Iteration 6812, lr = 5e-05
I0403 04:26:27.833662  4270 solver.cpp:228] Iteration 6825, loss = 0.000304014
I0403 04:26:27.833781  4270 solver.cpp:244]     Train net output #0: loss = 0.000303981 (* 1 = 0.000303981 loss)
I0403 04:26:28.054741  4270 sgd_solver.cpp:106] Iteration 6825, lr = 5e-05
I0403 04:26:37.739598  4270 solver.cpp:228] Iteration 6838, loss = 3.26985e-05
I0403 04:26:37.739717  4270 solver.cpp:244]     Train net output #0: loss = 3.26653e-05 (* 1 = 3.26653e-05 loss)
I0403 04:26:37.947237  4270 sgd_solver.cpp:106] Iteration 6838, lr = 5e-05
I0403 04:26:47.622877  4270 solver.cpp:228] Iteration 6851, loss = 0.00254659
I0403 04:26:47.622999  4270 solver.cpp:244]     Train net output #0: loss = 0.00254656 (* 1 = 0.00254656 loss)
I0403 04:26:47.840901  4270 sgd_solver.cpp:106] Iteration 6851, lr = 5e-05
I0403 04:26:57.461886  4270 solver.cpp:228] Iteration 6864, loss = 0.0012705
I0403 04:26:57.462209  4270 solver.cpp:244]     Train net output #0: loss = 0.00127046 (* 1 = 0.00127046 loss)
I0403 04:26:57.679339  4270 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 04:27:07.418998  4270 solver.cpp:228] Iteration 6877, loss = 0.00019544
I0403 04:27:07.419116  4270 solver.cpp:244]     Train net output #0: loss = 0.000195407 (* 1 = 0.000195407 loss)
I0403 04:27:07.626399  4270 sgd_solver.cpp:106] Iteration 6877, lr = 5e-05
I0403 04:27:17.230077  4270 solver.cpp:228] Iteration 6890, loss = 0.000478626
I0403 04:27:17.230192  4270 solver.cpp:244]     Train net output #0: loss = 0.000478593 (* 1 = 0.000478593 loss)
I0403 04:27:17.513798  4270 sgd_solver.cpp:106] Iteration 6890, lr = 5e-05
I0403 04:27:27.146097  4270 solver.cpp:228] Iteration 6903, loss = 0.00134102
I0403 04:27:27.151100  4270 solver.cpp:244]     Train net output #0: loss = 0.00134099 (* 1 = 0.00134099 loss)
I0403 04:27:27.364238  4270 sgd_solver.cpp:106] Iteration 6903, lr = 5e-05
I0403 04:27:37.146281  4270 solver.cpp:228] Iteration 6916, loss = 0.000691026
I0403 04:27:37.146620  4270 solver.cpp:244]     Train net output #0: loss = 0.000690994 (* 1 = 0.000690994 loss)
I0403 04:27:37.372339  4270 sgd_solver.cpp:106] Iteration 6916, lr = 5e-05
I0403 04:27:47.152483  4270 solver.cpp:228] Iteration 6929, loss = 0.000320605
I0403 04:27:47.152587  4270 solver.cpp:244]     Train net output #0: loss = 0.000320572 (* 1 = 0.000320572 loss)
I0403 04:27:47.338711  4270 sgd_solver.cpp:106] Iteration 6929, lr = 5e-05
I0403 04:27:57.184676  4270 solver.cpp:228] Iteration 6942, loss = 0.00158738
I0403 04:27:57.184792  4270 solver.cpp:244]     Train net output #0: loss = 0.00158735 (* 1 = 0.00158735 loss)
I0403 04:27:57.401232  4270 sgd_solver.cpp:106] Iteration 6942, lr = 5e-05
I0403 04:28:07.088577  4270 solver.cpp:228] Iteration 6955, loss = 0.00047968
I0403 04:28:07.088688  4270 solver.cpp:244]     Train net output #0: loss = 0.000479648 (* 1 = 0.000479648 loss)
I0403 04:28:07.297876  4270 sgd_solver.cpp:106] Iteration 6955, lr = 5e-05
I0403 04:28:16.997762  4270 solver.cpp:228] Iteration 6968, loss = 0.00261165
I0403 04:28:16.997881  4270 solver.cpp:244]     Train net output #0: loss = 0.00261161 (* 1 = 0.00261161 loss)
I0403 04:28:17.223711  4270 sgd_solver.cpp:106] Iteration 6968, lr = 5e-05
I0403 04:28:27.004173  4270 solver.cpp:228] Iteration 6981, loss = 0.00774829
I0403 04:28:27.004292  4270 solver.cpp:244]     Train net output #0: loss = 0.00774826 (* 1 = 0.00774826 loss)
I0403 04:28:27.210136  4270 sgd_solver.cpp:106] Iteration 6981, lr = 5e-05
I0403 04:28:36.269937  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6994.caffemodel
I0403 04:28:39.057337  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_6994.solverstate
I0403 04:28:40.822938  4270 solver.cpp:337] Iteration 6994, Testing net (#0)
I0403 04:29:41.939936  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989671
I0403 04:29:41.940295  4270 solver.cpp:404]     Test net output #1: loss = 0.0393183 (* 1 = 0.0393183 loss)
I0403 04:29:42.465193  4270 solver.cpp:228] Iteration 6994, loss = 0.000246662
I0403 04:29:42.465291  4270 solver.cpp:244]     Train net output #0: loss = 0.000246629 (* 1 = 0.000246629 loss)
I0403 04:29:42.659660  4270 sgd_solver.cpp:106] Iteration 6994, lr = 5e-05
I0403 04:29:52.375754  4270 solver.cpp:228] Iteration 7007, loss = 0.000597704
I0403 04:29:52.375869  4270 solver.cpp:244]     Train net output #0: loss = 0.000597671 (* 1 = 0.000597671 loss)
I0403 04:29:52.580888  4270 sgd_solver.cpp:106] Iteration 7007, lr = 5e-05
I0403 04:30:02.383978  4270 solver.cpp:228] Iteration 7020, loss = 0.0049536
I0403 04:30:02.384109  4270 solver.cpp:244]     Train net output #0: loss = 0.00495356 (* 1 = 0.00495356 loss)
I0403 04:30:02.604787  4270 sgd_solver.cpp:106] Iteration 7020, lr = 5e-05
I0403 04:30:12.396466  4270 solver.cpp:228] Iteration 7033, loss = 0.000327142
I0403 04:30:12.396764  4270 solver.cpp:244]     Train net output #0: loss = 0.000327109 (* 1 = 0.000327109 loss)
I0403 04:30:12.599236  4270 sgd_solver.cpp:106] Iteration 7033, lr = 5e-05
I0403 04:30:22.216446  4270 solver.cpp:228] Iteration 7046, loss = 0.000645098
I0403 04:30:22.216562  4270 solver.cpp:244]     Train net output #0: loss = 0.000645064 (* 1 = 0.000645064 loss)
I0403 04:30:22.436188  4270 sgd_solver.cpp:106] Iteration 7046, lr = 5e-05
I0403 04:30:32.048074  4270 solver.cpp:228] Iteration 7059, loss = 0.000132024
I0403 04:30:32.048184  4270 solver.cpp:244]     Train net output #0: loss = 0.000131991 (* 1 = 0.000131991 loss)
I0403 04:30:32.304934  4270 sgd_solver.cpp:106] Iteration 7059, lr = 5e-05
I0403 04:30:41.946112  4270 solver.cpp:228] Iteration 7072, loss = 0.000848017
I0403 04:30:41.946213  4270 solver.cpp:244]     Train net output #0: loss = 0.000847983 (* 1 = 0.000847983 loss)
I0403 04:30:42.127627  4270 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 04:30:51.895967  4270 solver.cpp:228] Iteration 7085, loss = 3.73386e-05
I0403 04:30:51.896296  4270 solver.cpp:244]     Train net output #0: loss = 3.73051e-05 (* 1 = 3.73051e-05 loss)
I0403 04:30:52.108371  4270 sgd_solver.cpp:106] Iteration 7085, lr = 5e-05
I0403 04:31:01.826519  4270 solver.cpp:228] Iteration 7098, loss = 0.000449424
I0403 04:31:01.826624  4270 solver.cpp:244]     Train net output #0: loss = 0.00044939 (* 1 = 0.00044939 loss)
I0403 04:31:02.022608  4270 sgd_solver.cpp:106] Iteration 7098, lr = 5e-05
I0403 04:31:11.793705  4270 solver.cpp:228] Iteration 7111, loss = 0.000141194
I0403 04:31:11.793823  4270 solver.cpp:244]     Train net output #0: loss = 0.000141161 (* 1 = 0.000141161 loss)
I0403 04:31:12.030570  4270 sgd_solver.cpp:106] Iteration 7111, lr = 5e-05
I0403 04:31:21.614279  4270 solver.cpp:228] Iteration 7124, loss = 0.000233581
I0403 04:31:21.614395  4270 solver.cpp:244]     Train net output #0: loss = 0.000233547 (* 1 = 0.000233547 loss)
I0403 04:31:21.837867  4270 sgd_solver.cpp:106] Iteration 7124, lr = 5e-05
I0403 04:31:31.590032  4270 solver.cpp:228] Iteration 7137, loss = 0.00111148
I0403 04:31:31.590327  4270 solver.cpp:244]     Train net output #0: loss = 0.00111145 (* 1 = 0.00111145 loss)
I0403 04:31:31.737836  4270 sgd_solver.cpp:106] Iteration 7137, lr = 5e-05
I0403 04:31:41.532491  4270 solver.cpp:228] Iteration 7150, loss = 2.84665e-06
I0403 04:31:41.532608  4270 solver.cpp:244]     Train net output #0: loss = 2.81219e-06 (* 1 = 2.81219e-06 loss)
I0403 04:31:41.757217  4270 sgd_solver.cpp:106] Iteration 7150, lr = 5e-05
I0403 04:31:51.614153  4270 solver.cpp:228] Iteration 7163, loss = 6.2453e-05
I0403 04:31:51.614274  4270 solver.cpp:244]     Train net output #0: loss = 6.24188e-05 (* 1 = 6.24188e-05 loss)
I0403 04:31:51.819260  4270 sgd_solver.cpp:106] Iteration 7163, lr = 5e-05
I0403 04:32:01.415649  4270 solver.cpp:228] Iteration 7176, loss = 0.000329552
I0403 04:32:01.415766  4270 solver.cpp:244]     Train net output #0: loss = 0.000329517 (* 1 = 0.000329517 loss)
I0403 04:32:01.644420  4270 sgd_solver.cpp:106] Iteration 7176, lr = 5e-05
I0403 04:32:11.338452  4270 solver.cpp:228] Iteration 7189, loss = 0.000349317
I0403 04:32:11.338557  4270 solver.cpp:244]     Train net output #0: loss = 0.000349282 (* 1 = 0.000349282 loss)
I0403 04:32:11.525717  4270 sgd_solver.cpp:106] Iteration 7189, lr = 5e-05
I0403 04:32:21.365847  4270 solver.cpp:228] Iteration 7202, loss = 0.000166079
I0403 04:32:21.365968  4270 solver.cpp:244]     Train net output #0: loss = 0.000166044 (* 1 = 0.000166044 loss)
I0403 04:32:21.599850  4270 sgd_solver.cpp:106] Iteration 7202, lr = 5e-05
I0403 04:32:31.397497  4270 solver.cpp:228] Iteration 7215, loss = 0.000318644
I0403 04:32:31.397617  4270 solver.cpp:244]     Train net output #0: loss = 0.000318609 (* 1 = 0.000318609 loss)
I0403 04:32:31.623940  4270 sgd_solver.cpp:106] Iteration 7215, lr = 5e-05
I0403 04:32:41.336046  4270 solver.cpp:228] Iteration 7228, loss = 0.000386907
I0403 04:32:41.336372  4270 solver.cpp:244]     Train net output #0: loss = 0.000386872 (* 1 = 0.000386872 loss)
I0403 04:32:41.559686  4270 sgd_solver.cpp:106] Iteration 7228, lr = 5e-05
I0403 04:32:51.140033  4270 solver.cpp:228] Iteration 7241, loss = 0.000742799
I0403 04:32:51.140136  4270 solver.cpp:244]     Train net output #0: loss = 0.000742763 (* 1 = 0.000742763 loss)
I0403 04:32:51.315846  4270 sgd_solver.cpp:106] Iteration 7241, lr = 5e-05
I0403 04:33:01.107136  4270 solver.cpp:228] Iteration 7254, loss = 0.000150474
I0403 04:33:01.107247  4270 solver.cpp:244]     Train net output #0: loss = 0.000150439 (* 1 = 0.000150439 loss)
I0403 04:33:01.317109  4270 sgd_solver.cpp:106] Iteration 7254, lr = 5e-05
I0403 04:33:07.464751  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_7263.caffemodel
I0403 04:33:10.327446  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_7263.solverstate
I0403 04:33:12.228409  4270 solver.cpp:337] Iteration 7263, Testing net (#0)
I0403 04:34:13.302104  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989744
I0403 04:34:13.302434  4270 solver.cpp:404]     Test net output #1: loss = 0.0387337 (* 1 = 0.0387337 loss)
I0403 04:34:16.856919  4270 solver.cpp:228] Iteration 7267, loss = 1.55638e-05
I0403 04:34:16.857038  4270 solver.cpp:244]     Train net output #0: loss = 1.55285e-05 (* 1 = 1.55285e-05 loss)
I0403 04:34:17.089787  4270 sgd_solver.cpp:106] Iteration 7267, lr = 5e-05
I0403 04:34:26.885263  4270 solver.cpp:228] Iteration 7280, loss = 0.000128307
I0403 04:34:26.885380  4270 solver.cpp:244]     Train net output #0: loss = 0.000128271 (* 1 = 0.000128271 loss)
I0403 04:34:27.117480  4270 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 04:34:36.924183  4270 solver.cpp:228] Iteration 7293, loss = 0.000183268
I0403 04:34:36.924293  4270 solver.cpp:244]     Train net output #0: loss = 0.000183232 (* 1 = 0.000183232 loss)
I0403 04:34:37.111560  4270 sgd_solver.cpp:106] Iteration 7293, lr = 5e-05
I0403 04:34:47.005502  4270 solver.cpp:228] Iteration 7306, loss = 0.0107846
I0403 04:34:47.005784  4270 solver.cpp:244]     Train net output #0: loss = 0.0107845 (* 1 = 0.0107845 loss)
I0403 04:34:47.208952  4270 sgd_solver.cpp:106] Iteration 7306, lr = 5e-05
I0403 04:34:56.848145  4270 solver.cpp:228] Iteration 7319, loss = 8.19186e-05
I0403 04:34:56.848264  4270 solver.cpp:244]     Train net output #0: loss = 8.18842e-05 (* 1 = 8.18842e-05 loss)
I0403 04:34:57.063645  4270 sgd_solver.cpp:106] Iteration 7319, lr = 5e-05
I0403 04:35:06.664710  4270 solver.cpp:228] Iteration 7332, loss = 0.0120533
I0403 04:35:06.664822  4270 solver.cpp:244]     Train net output #0: loss = 0.0120533 (* 1 = 0.0120533 loss)
I0403 04:35:06.871898  4270 sgd_solver.cpp:106] Iteration 7332, lr = 5e-05
I0403 04:35:16.492835  4270 solver.cpp:228] Iteration 7345, loss = 0.000311178
I0403 04:35:16.492940  4270 solver.cpp:244]     Train net output #0: loss = 0.000311144 (* 1 = 0.000311144 loss)
I0403 04:35:16.692086  4270 sgd_solver.cpp:106] Iteration 7345, lr = 5e-05
I0403 04:35:26.638820  4270 solver.cpp:228] Iteration 7358, loss = 0.000124507
I0403 04:35:26.639138  4270 solver.cpp:244]     Train net output #0: loss = 0.000124473 (* 1 = 0.000124473 loss)
I0403 04:35:26.850867  4270 sgd_solver.cpp:106] Iteration 7358, lr = 5e-05
I0403 04:35:36.483167  4270 solver.cpp:228] Iteration 7371, loss = 0.000436707
I0403 04:35:36.483284  4270 solver.cpp:244]     Train net output #0: loss = 0.000436673 (* 1 = 0.000436673 loss)
I0403 04:35:36.700968  4270 sgd_solver.cpp:106] Iteration 7371, lr = 5e-05
I0403 04:35:46.323240  4270 solver.cpp:228] Iteration 7384, loss = 6.4699e-05
I0403 04:35:46.323359  4270 solver.cpp:244]     Train net output #0: loss = 6.46646e-05 (* 1 = 6.46646e-05 loss)
I0403 04:35:46.564685  4270 sgd_solver.cpp:106] Iteration 7384, lr = 5e-05
I0403 04:35:56.342286  4270 solver.cpp:228] Iteration 7397, loss = 0.000697121
I0403 04:35:56.342397  4270 solver.cpp:244]     Train net output #0: loss = 0.000697087 (* 1 = 0.000697087 loss)
I0403 04:35:56.525046  4270 sgd_solver.cpp:106] Iteration 7397, lr = 5e-05
I0403 04:36:06.369192  4270 solver.cpp:228] Iteration 7410, loss = 0.000282716
I0403 04:36:06.369452  4270 solver.cpp:244]     Train net output #0: loss = 0.000282682 (* 1 = 0.000282682 loss)
I0403 04:36:06.592938  4270 sgd_solver.cpp:106] Iteration 7410, lr = 5e-05
I0403 04:36:16.283049  4270 solver.cpp:228] Iteration 7423, loss = 0.000619529
I0403 04:36:16.283175  4270 solver.cpp:244]     Train net output #0: loss = 0.000619494 (* 1 = 0.000619494 loss)
I0403 04:36:16.493094  4270 sgd_solver.cpp:106] Iteration 7423, lr = 5e-05
I0403 04:36:26.133258  4270 solver.cpp:228] Iteration 7436, loss = 0.000386084
I0403 04:36:26.133368  4270 solver.cpp:244]     Train net output #0: loss = 0.00038605 (* 1 = 0.00038605 loss)
I0403 04:36:26.345432  4270 sgd_solver.cpp:106] Iteration 7436, lr = 5e-05
I0403 04:36:36.142132  4270 solver.cpp:228] Iteration 7449, loss = 0.000146848
I0403 04:36:36.142246  4270 solver.cpp:244]     Train net output #0: loss = 0.000146813 (* 1 = 0.000146813 loss)
I0403 04:36:36.348399  4270 sgd_solver.cpp:106] Iteration 7449, lr = 5e-05
I0403 04:36:46.038447  4270 solver.cpp:228] Iteration 7462, loss = 0.000336315
I0403 04:36:46.038794  4270 solver.cpp:244]     Train net output #0: loss = 0.00033628 (* 1 = 0.00033628 loss)
I0403 04:36:46.277472  4270 sgd_solver.cpp:106] Iteration 7462, lr = 5e-05
I0403 04:36:55.921605  4270 solver.cpp:228] Iteration 7475, loss = 0.00110828
I0403 04:36:55.921728  4270 solver.cpp:244]     Train net output #0: loss = 0.00110825 (* 1 = 0.00110825 loss)
I0403 04:36:56.160060  4270 sgd_solver.cpp:106] Iteration 7475, lr = 5e-05
I0403 04:37:06.126726  4270 solver.cpp:228] Iteration 7488, loss = 0.000311053
I0403 04:37:06.126832  4270 solver.cpp:244]     Train net output #0: loss = 0.000311019 (* 1 = 0.000311019 loss)
I0403 04:37:06.327080  4270 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 04:37:16.076714  4270 solver.cpp:228] Iteration 7501, loss = 0.000284225
I0403 04:37:16.077055  4270 solver.cpp:244]     Train net output #0: loss = 0.00028419 (* 1 = 0.00028419 loss)
I0403 04:37:16.299798  4270 sgd_solver.cpp:106] Iteration 7501, lr = 5e-05
I0403 04:37:26.141340  4270 solver.cpp:228] Iteration 7514, loss = 0.000977676
I0403 04:37:26.141443  4270 solver.cpp:244]     Train net output #0: loss = 0.000977641 (* 1 = 0.000977641 loss)
I0403 04:37:26.315073  4270 sgd_solver.cpp:106] Iteration 7514, lr = 5e-05
I0403 04:37:36.019881  4270 solver.cpp:228] Iteration 7527, loss = 0.000104389
I0403 04:37:36.020004  4270 solver.cpp:244]     Train net output #0: loss = 0.000104354 (* 1 = 0.000104354 loss)
I0403 04:37:36.228029  4270 sgd_solver.cpp:106] Iteration 7527, lr = 5e-05
I0403 04:37:39.326881  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_7532.caffemodel
I0403 04:37:42.153537  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_7532.solverstate
I0403 04:37:44.060243  4270 solver.cpp:337] Iteration 7532, Testing net (#0)
I0403 04:38:45.264858  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989817
I0403 04:38:45.265218  4270 solver.cpp:404]     Test net output #1: loss = 0.0392072 (* 1 = 0.0392072 loss)
I0403 04:38:51.963099  4270 solver.cpp:228] Iteration 7540, loss = 2.58966e-05
I0403 04:38:51.963213  4270 solver.cpp:244]     Train net output #0: loss = 2.58608e-05 (* 1 = 2.58608e-05 loss)
I0403 04:38:52.167484  4270 sgd_solver.cpp:106] Iteration 7540, lr = 5e-05
I0403 04:39:01.881254  4270 solver.cpp:228] Iteration 7553, loss = 0.000230297
I0403 04:39:01.881371  4270 solver.cpp:244]     Train net output #0: loss = 0.000230261 (* 1 = 0.000230261 loss)
I0403 04:39:02.163725  4270 sgd_solver.cpp:106] Iteration 7553, lr = 5e-05
I0403 04:39:11.893667  4270 solver.cpp:228] Iteration 7566, loss = 0.000501474
I0403 04:39:11.893754  4270 solver.cpp:244]     Train net output #0: loss = 0.000501438 (* 1 = 0.000501438 loss)
I0403 04:39:12.129933  4270 sgd_solver.cpp:106] Iteration 7566, lr = 5e-05
I0403 04:39:21.809649  4270 solver.cpp:228] Iteration 7579, loss = 0.000322962
I0403 04:39:21.809978  4270 solver.cpp:244]     Train net output #0: loss = 0.000322926 (* 1 = 0.000322926 loss)
I0403 04:39:22.017251  4270 sgd_solver.cpp:106] Iteration 7579, lr = 5e-05
I0403 04:39:31.776849  4270 solver.cpp:228] Iteration 7592, loss = 0.00340837
I0403 04:39:31.776971  4270 solver.cpp:244]     Train net output #0: loss = 0.00340833 (* 1 = 0.00340833 loss)
I0403 04:39:32.000849  4270 sgd_solver.cpp:106] Iteration 7592, lr = 5e-05
I0403 04:39:41.642464  4270 solver.cpp:228] Iteration 7605, loss = 4.20445e-05
I0403 04:39:41.642581  4270 solver.cpp:244]     Train net output #0: loss = 4.20075e-05 (* 1 = 4.20075e-05 loss)
I0403 04:39:41.865038  4270 sgd_solver.cpp:106] Iteration 7605, lr = 5e-05
I0403 04:39:51.565335  4270 solver.cpp:228] Iteration 7618, loss = 0.00408018
I0403 04:39:51.565450  4270 solver.cpp:244]     Train net output #0: loss = 0.00408014 (* 1 = 0.00408014 loss)
I0403 04:39:51.786963  4270 sgd_solver.cpp:106] Iteration 7618, lr = 5e-05
I0403 04:40:01.504628  4270 solver.cpp:228] Iteration 7631, loss = 3.37609e-05
I0403 04:40:01.515364  4270 solver.cpp:244]     Train net output #0: loss = 3.37235e-05 (* 1 = 3.37235e-05 loss)
I0403 04:40:01.731274  4270 sgd_solver.cpp:106] Iteration 7631, lr = 5e-05
I0403 04:40:11.440599  4270 solver.cpp:228] Iteration 7644, loss = 3.19705e-05
I0403 04:40:11.440718  4270 solver.cpp:244]     Train net output #0: loss = 3.1933e-05 (* 1 = 3.1933e-05 loss)
I0403 04:40:11.709342  4270 sgd_solver.cpp:106] Iteration 7644, lr = 5e-05
I0403 04:40:21.384750  4270 solver.cpp:228] Iteration 7657, loss = 0.000438621
I0403 04:40:21.384868  4270 solver.cpp:244]     Train net output #0: loss = 0.000438584 (* 1 = 0.000438584 loss)
I0403 04:40:21.598167  4270 sgd_solver.cpp:106] Iteration 7657, lr = 5e-05
I0403 04:40:31.246381  4270 solver.cpp:228] Iteration 7670, loss = 0.000959091
I0403 04:40:31.246493  4270 solver.cpp:244]     Train net output #0: loss = 0.000959054 (* 1 = 0.000959054 loss)
I0403 04:40:31.477058  4270 sgd_solver.cpp:106] Iteration 7670, lr = 5e-05
I0403 04:40:41.140616  4270 solver.cpp:228] Iteration 7683, loss = 0.000783982
I0403 04:40:41.140934  4270 solver.cpp:244]     Train net output #0: loss = 0.000783945 (* 1 = 0.000783945 loss)
I0403 04:40:41.355417  4270 sgd_solver.cpp:106] Iteration 7683, lr = 5e-05
I0403 04:40:51.003942  4270 solver.cpp:228] Iteration 7696, loss = 0.000424596
I0403 04:40:51.004052  4270 solver.cpp:244]     Train net output #0: loss = 0.000424561 (* 1 = 0.000424561 loss)
I0403 04:40:51.201210  4270 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 04:41:00.931764  4270 solver.cpp:228] Iteration 7709, loss = 0.000416874
I0403 04:41:00.931881  4270 solver.cpp:244]     Train net output #0: loss = 0.000416839 (* 1 = 0.000416839 loss)
I0403 04:41:01.214668  4270 sgd_solver.cpp:106] Iteration 7709, lr = 5e-05
I0403 04:41:10.934543  4270 solver.cpp:228] Iteration 7722, loss = 0.000813291
I0403 04:41:10.934659  4270 solver.cpp:244]     Train net output #0: loss = 0.000813256 (* 1 = 0.000813256 loss)
I0403 04:41:11.141556  4270 sgd_solver.cpp:106] Iteration 7722, lr = 5e-05
I0403 04:41:20.934190  4270 solver.cpp:228] Iteration 7735, loss = 6.17068e-05
I0403 04:41:20.934308  4270 solver.cpp:244]     Train net output #0: loss = 6.1671e-05 (* 1 = 6.1671e-05 loss)
I0403 04:41:21.160643  4270 sgd_solver.cpp:106] Iteration 7735, lr = 5e-05
I0403 04:41:30.828043  4270 solver.cpp:228] Iteration 7748, loss = 0.00151118
I0403 04:41:30.828160  4270 solver.cpp:244]     Train net output #0: loss = 0.00151115 (* 1 = 0.00151115 loss)
I0403 04:41:31.032938  4270 sgd_solver.cpp:106] Iteration 7748, lr = 5e-05
I0403 04:41:40.671335  4270 solver.cpp:228] Iteration 7761, loss = 0.000286367
I0403 04:41:40.671440  4270 solver.cpp:244]     Train net output #0: loss = 0.000286332 (* 1 = 0.000286332 loss)
I0403 04:41:40.862964  4270 sgd_solver.cpp:106] Iteration 7761, lr = 5e-05
I0403 04:41:50.703022  4270 solver.cpp:228] Iteration 7774, loss = 0.00130765
I0403 04:41:50.703337  4270 solver.cpp:244]     Train net output #0: loss = 0.00130761 (* 1 = 0.00130761 loss)
I0403 04:41:50.943675  4270 sgd_solver.cpp:106] Iteration 7774, lr = 5e-05
I0403 04:42:00.589360  4270 solver.cpp:228] Iteration 7787, loss = 2.38596e-05
I0403 04:42:00.589459  4270 solver.cpp:244]     Train net output #0: loss = 2.3825e-05 (* 1 = 2.3825e-05 loss)
I0403 04:42:00.771548  4270 sgd_solver.cpp:106] Iteration 7787, lr = 5e-05
I0403 04:42:10.455035  4270 solver.cpp:228] Iteration 7800, loss = 0.00113956
I0403 04:42:10.456094  4270 solver.cpp:244]     Train net output #0: loss = 0.00113953 (* 1 = 0.00113953 loss)
I0403 04:42:10.696501  4270 sgd_solver.cpp:106] Iteration 7800, lr = 5e-05
I0403 04:42:10.696737  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_7801.caffemodel
I0403 04:42:13.478842  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_7801.solverstate
I0403 04:42:15.386399  4270 solver.cpp:337] Iteration 7801, Testing net (#0)
I0403 04:43:16.478224  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989707
I0403 04:43:16.478564  4270 solver.cpp:404]     Test net output #1: loss = 0.0392764 (* 1 = 0.0392764 loss)
I0403 04:43:26.108948  4270 solver.cpp:228] Iteration 7813, loss = 0.000826151
I0403 04:43:26.109051  4270 solver.cpp:244]     Train net output #0: loss = 0.000826118 (* 1 = 0.000826118 loss)
I0403 04:43:26.284829  4270 sgd_solver.cpp:106] Iteration 7813, lr = 5e-05
I0403 04:43:36.051246  4270 solver.cpp:228] Iteration 7826, loss = 0.000552707
I0403 04:43:36.051359  4270 solver.cpp:244]     Train net output #0: loss = 0.000552673 (* 1 = 0.000552673 loss)
I0403 04:43:36.233415  4270 sgd_solver.cpp:106] Iteration 7826, lr = 5e-05
I0403 04:43:46.142968  4270 solver.cpp:228] Iteration 7839, loss = 6.77684e-05
I0403 04:43:46.143086  4270 solver.cpp:244]     Train net output #0: loss = 6.77315e-05 (* 1 = 6.77315e-05 loss)
I0403 04:43:46.348186  4270 sgd_solver.cpp:106] Iteration 7839, lr = 5e-05
I0403 04:43:56.032606  4270 solver.cpp:228] Iteration 7852, loss = 0.00080519
I0403 04:43:56.032912  4270 solver.cpp:244]     Train net output #0: loss = 0.000805153 (* 1 = 0.000805153 loss)
I0403 04:43:56.257124  4270 sgd_solver.cpp:106] Iteration 7852, lr = 5e-05
I0403 04:44:05.920111  4270 solver.cpp:228] Iteration 7865, loss = 0.00162343
I0403 04:44:05.920217  4270 solver.cpp:244]     Train net output #0: loss = 0.00162339 (* 1 = 0.00162339 loss)
I0403 04:44:06.174345  4270 sgd_solver.cpp:106] Iteration 7865, lr = 5e-05
I0403 04:44:15.826565  4270 solver.cpp:228] Iteration 7878, loss = 0.000940425
I0403 04:44:15.826679  4270 solver.cpp:244]     Train net output #0: loss = 0.000940389 (* 1 = 0.000940389 loss)
I0403 04:44:16.037559  4270 sgd_solver.cpp:106] Iteration 7878, lr = 5e-05
I0403 04:44:25.713665  4270 solver.cpp:228] Iteration 7891, loss = 0.000709907
I0403 04:44:25.713778  4270 solver.cpp:244]     Train net output #0: loss = 0.00070987 (* 1 = 0.00070987 loss)
I0403 04:44:25.932806  4270 sgd_solver.cpp:106] Iteration 7891, lr = 5e-05
I0403 04:44:35.733916  4270 solver.cpp:228] Iteration 7904, loss = 3.87513e-05
I0403 04:44:35.734237  4270 solver.cpp:244]     Train net output #0: loss = 3.87145e-05 (* 1 = 3.87145e-05 loss)
I0403 04:44:35.946008  4270 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 04:44:45.689301  4270 solver.cpp:228] Iteration 7917, loss = 0.00587293
I0403 04:44:45.689411  4270 solver.cpp:244]     Train net output #0: loss = 0.00587289 (* 1 = 0.00587289 loss)
I0403 04:44:45.937958  4270 sgd_solver.cpp:106] Iteration 7917, lr = 5e-05
I0403 04:44:55.607502  4270 solver.cpp:228] Iteration 7930, loss = 0.000281746
I0403 04:44:55.607617  4270 solver.cpp:244]     Train net output #0: loss = 0.000281709 (* 1 = 0.000281709 loss)
I0403 04:44:55.830317  4270 sgd_solver.cpp:106] Iteration 7930, lr = 5e-05
I0403 04:45:05.733855  4270 solver.cpp:228] Iteration 7943, loss = 0.000469179
I0403 04:45:05.733957  4270 solver.cpp:244]     Train net output #0: loss = 0.000469143 (* 1 = 0.000469143 loss)
I0403 04:45:05.909950  4270 sgd_solver.cpp:106] Iteration 7943, lr = 5e-05
I0403 04:45:15.685504  4270 solver.cpp:228] Iteration 7956, loss = 0.00155463
I0403 04:45:15.685621  4270 solver.cpp:244]     Train net output #0: loss = 0.00155459 (* 1 = 0.00155459 loss)
I0403 04:45:15.891425  4270 sgd_solver.cpp:106] Iteration 7956, lr = 5e-05
I0403 04:45:25.609603  4270 solver.cpp:228] Iteration 7969, loss = 2.61847e-05
I0403 04:45:25.609720  4270 solver.cpp:244]     Train net output #0: loss = 2.61479e-05 (* 1 = 2.61479e-05 loss)
I0403 04:45:25.833727  4270 sgd_solver.cpp:106] Iteration 7969, lr = 5e-05
I0403 04:45:35.513882  4270 solver.cpp:228] Iteration 7982, loss = 0.00028576
I0403 04:45:35.514013  4270 solver.cpp:244]     Train net output #0: loss = 0.000285723 (* 1 = 0.000285723 loss)
I0403 04:45:35.733610  4270 sgd_solver.cpp:106] Iteration 7982, lr = 5e-05
I0403 04:45:45.488634  4270 solver.cpp:228] Iteration 7995, loss = 3.44422e-05
I0403 04:45:45.488986  4270 solver.cpp:244]     Train net output #0: loss = 3.44044e-05 (* 1 = 3.44044e-05 loss)
I0403 04:45:45.696811  4270 sgd_solver.cpp:106] Iteration 7995, lr = 5e-05
I0403 04:45:55.462553  4270 solver.cpp:228] Iteration 8008, loss = 0.00182789
I0403 04:45:55.462677  4270 solver.cpp:244]     Train net output #0: loss = 0.00182785 (* 1 = 0.00182785 loss)
I0403 04:45:55.724465  4270 sgd_solver.cpp:106] Iteration 8008, lr = 5e-05
I0403 04:46:05.522997  4270 solver.cpp:228] Iteration 8021, loss = 0.00198676
I0403 04:46:05.523113  4270 solver.cpp:244]     Train net output #0: loss = 0.00198672 (* 1 = 0.00198672 loss)
I0403 04:46:05.730361  4270 sgd_solver.cpp:106] Iteration 8021, lr = 5e-05
I0403 04:46:15.477608  4270 solver.cpp:228] Iteration 8034, loss = 0.000212378
I0403 04:46:15.477715  4270 solver.cpp:244]     Train net output #0: loss = 0.00021234 (* 1 = 0.00021234 loss)
I0403 04:46:15.678638  4270 sgd_solver.cpp:106] Iteration 8034, lr = 5e-05
I0403 04:46:25.443791  4270 solver.cpp:228] Iteration 8047, loss = 5.74198e-05
I0403 04:46:25.443894  4270 solver.cpp:244]     Train net output #0: loss = 5.73813e-05 (* 1 = 5.73813e-05 loss)
I0403 04:46:25.642765  4270 sgd_solver.cpp:106] Iteration 8047, lr = 5e-05
I0403 04:46:35.314132  4270 solver.cpp:228] Iteration 8060, loss = 0.000491706
I0403 04:46:35.314249  4270 solver.cpp:244]     Train net output #0: loss = 0.000491668 (* 1 = 0.000491668 loss)
I0403 04:46:35.537164  4270 sgd_solver.cpp:106] Iteration 8060, lr = 5e-05
I0403 04:46:42.299239  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_8070.caffemodel
I0403 04:46:45.046418  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_8070.solverstate
I0403 04:46:46.895002  4270 solver.cpp:337] Iteration 8070, Testing net (#0)
I0403 04:47:47.963510  4270 solver.cpp:404]     Test net output #0: accuracy = 0.989708
I0403 04:47:47.963868  4270 solver.cpp:404]     Test net output #1: loss = 0.038962 (* 1 = 0.038962 loss)
I0403 04:47:50.774577  4270 solver.cpp:228] Iteration 8073, loss = 6.18425e-05
I0403 04:47:50.774690  4270 solver.cpp:244]     Train net output #0: loss = 6.18042e-05 (* 1 = 6.18042e-05 loss)
I0403 04:47:50.980217  4270 sgd_solver.cpp:106] Iteration 8073, lr = 5e-06
I0403 04:47:51.721981  4270 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_8075.caffemodel
I0403 04:47:54.490031  4270 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-50-50_finetune/snapshots__iter_8075.solverstate
I0403 04:47:56.376557  4270 solver.cpp:322] Optimization Done.
I0403 04:47:56.481374  4270 caffe.cpp:222] Optimization Done.
