I0403 05:23:30.109654  2705 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 05:23:30.110296  2705 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 05:23:30.110342  2705 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 05:23:34.140524  2705 caffe.cpp:185] Using GPUs 0, 1
I0403 05:23:34.140990  2705 caffe.cpp:190] GPU 0: Tesla K40m
I0403 05:23:34.141384  2705 caffe.cpp:190] GPU 1: Tesla K40m
I0403 05:23:34.354372  2705 solver.cpp:48] Initializing solver from parameters: 
test_iter: 217
test_interval: 325
base_lr: 0.005
display: 16
max_iter: 9758
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3252
snapshot: 325
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 05:23:34.370826  2705 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 05:23:34.533213  2705 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 05:23:34.533341  2705 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 05:23:34.534978  2705 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 05:23:34.556051  2705 layer_factory.hpp:77] Creating layer data
I0403 05:23:34.557772  2705 net.cpp:91] Creating Layer data
I0403 05:23:34.557869  2705 net.cpp:399] data -> data
I0403 05:23:34.557988  2705 net.cpp:399] data -> label
I0403 05:23:34.558069  2705 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto
I0403 05:23:34.614886  2709 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/train_db
I0403 05:23:34.666079  2705 data_layer.cpp:41] output data size: 100,3,227,227
I0403 05:23:34.792299  2705 net.cpp:141] Setting up data
I0403 05:23:34.792418  2705 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 05:23:34.792443  2705 net.cpp:148] Top shape: 100 (100)
I0403 05:23:34.792459  2705 net.cpp:156] Memory required for data: 61835200
I0403 05:23:34.792491  2705 layer_factory.hpp:77] Creating layer conv1
I0403 05:23:34.792538  2705 net.cpp:91] Creating Layer conv1
I0403 05:23:34.792562  2705 net.cpp:425] conv1 <- data
I0403 05:23:34.792593  2705 net.cpp:399] conv1 -> conv1
I0403 05:23:34.795341  2705 net.cpp:141] Setting up conv1
I0403 05:23:34.795378  2705 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 05:23:34.795395  2705 net.cpp:156] Memory required for data: 177995200
I0403 05:23:34.795433  2705 layer_factory.hpp:77] Creating layer relu1
I0403 05:23:34.795461  2705 net.cpp:91] Creating Layer relu1
I0403 05:23:34.795480  2705 net.cpp:425] relu1 <- conv1
I0403 05:23:34.795497  2705 net.cpp:386] relu1 -> conv1 (in-place)
I0403 05:23:34.795521  2705 net.cpp:141] Setting up relu1
I0403 05:23:34.795542  2705 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 05:23:34.795557  2705 net.cpp:156] Memory required for data: 294155200
I0403 05:23:34.795572  2705 layer_factory.hpp:77] Creating layer norm1
I0403 05:23:34.795624  2705 net.cpp:91] Creating Layer norm1
I0403 05:23:34.795642  2705 net.cpp:425] norm1 <- conv1
I0403 05:23:34.795660  2705 net.cpp:399] norm1 -> norm1
I0403 05:23:34.801297  2705 net.cpp:141] Setting up norm1
I0403 05:23:34.801337  2705 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 05:23:34.801362  2705 net.cpp:156] Memory required for data: 410315200
I0403 05:23:34.801379  2705 layer_factory.hpp:77] Creating layer pool1
I0403 05:23:34.801401  2705 net.cpp:91] Creating Layer pool1
I0403 05:23:34.801419  2705 net.cpp:425] pool1 <- norm1
I0403 05:23:34.801437  2705 net.cpp:399] pool1 -> pool1
I0403 05:23:34.801501  2705 net.cpp:141] Setting up pool1
I0403 05:23:34.801528  2705 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 05:23:34.801544  2705 net.cpp:156] Memory required for data: 438308800
I0403 05:23:34.801559  2705 layer_factory.hpp:77] Creating layer conv2
I0403 05:23:34.801583  2705 net.cpp:91] Creating Layer conv2
I0403 05:23:34.801599  2705 net.cpp:425] conv2 <- pool1
I0403 05:23:34.801620  2705 net.cpp:399] conv2 -> conv2
I0403 05:23:34.803073  2710 blocking_queue.cpp:50] Waiting for data
I0403 05:23:34.818804  2705 net.cpp:141] Setting up conv2
I0403 05:23:34.818835  2705 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 05:23:34.818851  2705 net.cpp:156] Memory required for data: 512958400
I0403 05:23:34.818874  2705 layer_factory.hpp:77] Creating layer relu2
I0403 05:23:34.818894  2705 net.cpp:91] Creating Layer relu2
I0403 05:23:34.818910  2705 net.cpp:425] relu2 <- conv2
I0403 05:23:34.818928  2705 net.cpp:386] relu2 -> conv2 (in-place)
I0403 05:23:34.818946  2705 net.cpp:141] Setting up relu2
I0403 05:23:34.818964  2705 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 05:23:34.818979  2705 net.cpp:156] Memory required for data: 587608000
I0403 05:23:34.818992  2705 layer_factory.hpp:77] Creating layer norm2
I0403 05:23:34.819010  2705 net.cpp:91] Creating Layer norm2
I0403 05:23:34.819025  2705 net.cpp:425] norm2 <- conv2
I0403 05:23:34.819043  2705 net.cpp:399] norm2 -> norm2
I0403 05:23:34.819089  2705 net.cpp:141] Setting up norm2
I0403 05:23:34.819113  2705 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 05:23:34.819126  2705 net.cpp:156] Memory required for data: 662257600
I0403 05:23:34.819140  2705 layer_factory.hpp:77] Creating layer pool2
I0403 05:23:34.819160  2705 net.cpp:91] Creating Layer pool2
I0403 05:23:34.819176  2705 net.cpp:425] pool2 <- norm2
I0403 05:23:34.819195  2705 net.cpp:399] pool2 -> pool2
I0403 05:23:34.819238  2705 net.cpp:141] Setting up pool2
I0403 05:23:34.819260  2705 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 05:23:34.819275  2705 net.cpp:156] Memory required for data: 679563200
I0403 05:23:34.819289  2705 layer_factory.hpp:77] Creating layer conv3
I0403 05:23:34.819316  2705 net.cpp:91] Creating Layer conv3
I0403 05:23:34.819332  2705 net.cpp:425] conv3 <- pool2
I0403 05:23:34.819360  2705 net.cpp:399] conv3 -> conv3
I0403 05:23:34.853493  2705 net.cpp:141] Setting up conv3
I0403 05:23:34.853534  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:34.853550  2705 net.cpp:156] Memory required for data: 705521600
I0403 05:23:34.853569  2705 layer_factory.hpp:77] Creating layer relu3
I0403 05:23:34.853588  2705 net.cpp:91] Creating Layer relu3
I0403 05:23:34.853605  2705 net.cpp:425] relu3 <- conv3
I0403 05:23:34.853621  2705 net.cpp:386] relu3 -> conv3 (in-place)
I0403 05:23:34.853638  2705 net.cpp:141] Setting up relu3
I0403 05:23:34.853654  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:34.853668  2705 net.cpp:156] Memory required for data: 731480000
I0403 05:23:34.853682  2705 layer_factory.hpp:77] Creating layer conv4
I0403 05:23:34.853703  2705 net.cpp:91] Creating Layer conv4
I0403 05:23:34.853718  2705 net.cpp:425] conv4 <- conv3
I0403 05:23:34.853736  2705 net.cpp:399] conv4 -> conv4
I0403 05:23:34.878628  2705 net.cpp:141] Setting up conv4
I0403 05:23:34.878659  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:34.878675  2705 net.cpp:156] Memory required for data: 757438400
I0403 05:23:34.878708  2705 layer_factory.hpp:77] Creating layer relu4
I0403 05:23:34.878728  2705 net.cpp:91] Creating Layer relu4
I0403 05:23:34.878743  2705 net.cpp:425] relu4 <- conv4
I0403 05:23:34.878761  2705 net.cpp:386] relu4 -> conv4 (in-place)
I0403 05:23:34.878777  2705 net.cpp:141] Setting up relu4
I0403 05:23:34.878793  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:34.878808  2705 net.cpp:156] Memory required for data: 783396800
I0403 05:23:34.878820  2705 layer_factory.hpp:77] Creating layer conv5
I0403 05:23:34.878850  2705 net.cpp:91] Creating Layer conv5
I0403 05:23:34.878866  2705 net.cpp:425] conv5 <- conv4
I0403 05:23:34.878885  2705 net.cpp:399] conv5 -> conv5
I0403 05:23:34.895726  2705 net.cpp:141] Setting up conv5
I0403 05:23:34.895757  2705 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 05:23:34.895771  2705 net.cpp:156] Memory required for data: 800702400
I0403 05:23:34.895792  2705 layer_factory.hpp:77] Creating layer relu5
I0403 05:23:34.895812  2705 net.cpp:91] Creating Layer relu5
I0403 05:23:34.895826  2705 net.cpp:425] relu5 <- conv5
I0403 05:23:34.895843  2705 net.cpp:386] relu5 -> conv5 (in-place)
I0403 05:23:34.895861  2705 net.cpp:141] Setting up relu5
I0403 05:23:34.895877  2705 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 05:23:34.895891  2705 net.cpp:156] Memory required for data: 818008000
I0403 05:23:34.895905  2705 layer_factory.hpp:77] Creating layer pool5
I0403 05:23:34.895921  2705 net.cpp:91] Creating Layer pool5
I0403 05:23:34.895936  2705 net.cpp:425] pool5 <- conv5
I0403 05:23:34.895952  2705 net.cpp:399] pool5 -> pool5
I0403 05:23:34.896003  2705 net.cpp:141] Setting up pool5
I0403 05:23:34.896024  2705 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 05:23:34.896039  2705 net.cpp:156] Memory required for data: 821694400
I0403 05:23:34.896052  2705 layer_factory.hpp:77] Creating layer fc6
I0403 05:23:34.896078  2705 net.cpp:91] Creating Layer fc6
I0403 05:23:34.896095  2705 net.cpp:425] fc6 <- pool5
I0403 05:23:34.896113  2705 net.cpp:399] fc6 -> fc6
I0403 05:23:36.325562  2705 net.cpp:141] Setting up fc6
I0403 05:23:36.325659  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:36.325675  2705 net.cpp:156] Memory required for data: 823332800
I0403 05:23:36.325697  2705 layer_factory.hpp:77] Creating layer relu6
I0403 05:23:36.325721  2705 net.cpp:91] Creating Layer relu6
I0403 05:23:36.325736  2705 net.cpp:425] relu6 <- fc6
I0403 05:23:36.325757  2705 net.cpp:386] relu6 -> fc6 (in-place)
I0403 05:23:36.325779  2705 net.cpp:141] Setting up relu6
I0403 05:23:36.325795  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:36.325809  2705 net.cpp:156] Memory required for data: 824971200
I0403 05:23:36.325822  2705 layer_factory.hpp:77] Creating layer drop6
I0403 05:23:36.325847  2705 net.cpp:91] Creating Layer drop6
I0403 05:23:36.325863  2705 net.cpp:425] drop6 <- fc6
I0403 05:23:36.325880  2705 net.cpp:386] drop6 -> fc6 (in-place)
I0403 05:23:36.325924  2705 net.cpp:141] Setting up drop6
I0403 05:23:36.325945  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:36.325960  2705 net.cpp:156] Memory required for data: 826609600
I0403 05:23:36.325974  2705 layer_factory.hpp:77] Creating layer fc7
I0403 05:23:36.325997  2705 net.cpp:91] Creating Layer fc7
I0403 05:23:36.326014  2705 net.cpp:425] fc7 <- fc6
I0403 05:23:36.326031  2705 net.cpp:399] fc7 -> fc7
I0403 05:23:36.956950  2705 net.cpp:141] Setting up fc7
I0403 05:23:36.957046  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:36.957062  2705 net.cpp:156] Memory required for data: 828248000
I0403 05:23:36.957084  2705 layer_factory.hpp:77] Creating layer relu7
I0403 05:23:36.957110  2705 net.cpp:91] Creating Layer relu7
I0403 05:23:36.957129  2705 net.cpp:425] relu7 <- fc7
I0403 05:23:36.957147  2705 net.cpp:386] relu7 -> fc7 (in-place)
I0403 05:23:36.957168  2705 net.cpp:141] Setting up relu7
I0403 05:23:36.957203  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:36.957239  2705 net.cpp:156] Memory required for data: 829886400
I0403 05:23:36.957288  2705 layer_factory.hpp:77] Creating layer drop7
I0403 05:23:36.957325  2705 net.cpp:91] Creating Layer drop7
I0403 05:23:36.957342  2705 net.cpp:425] drop7 <- fc7
I0403 05:23:36.957362  2705 net.cpp:386] drop7 -> fc7 (in-place)
I0403 05:23:36.957401  2705 net.cpp:141] Setting up drop7
I0403 05:23:36.957434  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:36.957453  2705 net.cpp:156] Memory required for data: 831524800
I0403 05:23:36.957468  2705 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 05:23:36.957489  2705 net.cpp:91] Creating Layer fc8_plantvillage
I0403 05:23:36.957504  2705 net.cpp:425] fc8_plantvillage <- fc7
I0403 05:23:36.957535  2705 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 05:23:36.963871  2705 net.cpp:141] Setting up fc8_plantvillage
I0403 05:23:36.963901  2705 net.cpp:148] Top shape: 100 38 (3800)
I0403 05:23:36.963917  2705 net.cpp:156] Memory required for data: 831540000
I0403 05:23:36.963933  2705 layer_factory.hpp:77] Creating layer loss
I0403 05:23:36.963958  2705 net.cpp:91] Creating Layer loss
I0403 05:23:36.963974  2705 net.cpp:425] loss <- fc8_plantvillage
I0403 05:23:36.964002  2705 net.cpp:425] loss <- label
I0403 05:23:36.964025  2705 net.cpp:399] loss -> loss
I0403 05:23:36.964051  2705 layer_factory.hpp:77] Creating layer loss
I0403 05:23:36.964151  2705 net.cpp:141] Setting up loss
I0403 05:23:36.964174  2705 net.cpp:148] Top shape: (1)
I0403 05:23:36.964200  2705 net.cpp:151]     with loss weight 1
I0403 05:23:36.964257  2705 net.cpp:156] Memory required for data: 831540004
I0403 05:23:36.964272  2705 net.cpp:217] loss needs backward computation.
I0403 05:23:36.964287  2705 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 05:23:36.964301  2705 net.cpp:217] drop7 needs backward computation.
I0403 05:23:36.964315  2705 net.cpp:217] relu7 needs backward computation.
I0403 05:23:36.964335  2705 net.cpp:217] fc7 needs backward computation.
I0403 05:23:36.964349  2705 net.cpp:217] drop6 needs backward computation.
I0403 05:23:36.964364  2705 net.cpp:217] relu6 needs backward computation.
I0403 05:23:36.964377  2705 net.cpp:217] fc6 needs backward computation.
I0403 05:23:36.964391  2705 net.cpp:217] pool5 needs backward computation.
I0403 05:23:36.964406  2705 net.cpp:217] relu5 needs backward computation.
I0403 05:23:36.964419  2705 net.cpp:217] conv5 needs backward computation.
I0403 05:23:36.964433  2705 net.cpp:217] relu4 needs backward computation.
I0403 05:23:36.964447  2705 net.cpp:217] conv4 needs backward computation.
I0403 05:23:36.964462  2705 net.cpp:217] relu3 needs backward computation.
I0403 05:23:36.964474  2705 net.cpp:217] conv3 needs backward computation.
I0403 05:23:36.964500  2705 net.cpp:217] pool2 needs backward computation.
I0403 05:23:36.964514  2705 net.cpp:217] norm2 needs backward computation.
I0403 05:23:36.964527  2705 net.cpp:217] relu2 needs backward computation.
I0403 05:23:36.964540  2705 net.cpp:217] conv2 needs backward computation.
I0403 05:23:36.964555  2705 net.cpp:217] pool1 needs backward computation.
I0403 05:23:36.964567  2705 net.cpp:217] norm1 needs backward computation.
I0403 05:23:36.964581  2705 net.cpp:217] relu1 needs backward computation.
I0403 05:23:36.964594  2705 net.cpp:217] conv1 needs backward computation.
I0403 05:23:36.964608  2705 net.cpp:219] data does not need backward computation.
I0403 05:23:36.964622  2705 net.cpp:261] This network produces output loss
I0403 05:23:36.964650  2705 net.cpp:274] Network initialization done.
I0403 05:23:36.965752  2705 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 05:23:36.965823  2705 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 05:23:36.966469  2705 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 05:23:36.966624  2705 layer_factory.hpp:77] Creating layer data
I0403 05:23:36.966786  2705 net.cpp:91] Creating Layer data
I0403 05:23:36.966814  2705 net.cpp:399] data -> data
I0403 05:23:36.966836  2705 net.cpp:399] data -> label
I0403 05:23:36.966862  2705 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto
I0403 05:23:37.033236  2711 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/test_db
I0403 05:23:37.076092  2705 data_layer.cpp:41] output data size: 100,3,227,227
I0403 05:23:37.238639  2705 net.cpp:141] Setting up data
I0403 05:23:37.238714  2705 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 05:23:37.238734  2705 net.cpp:148] Top shape: 100 (100)
I0403 05:23:37.238749  2705 net.cpp:156] Memory required for data: 61835200
I0403 05:23:37.238767  2705 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 05:23:37.238795  2705 net.cpp:91] Creating Layer label_data_1_split
I0403 05:23:37.238811  2705 net.cpp:425] label_data_1_split <- label
I0403 05:23:37.238831  2705 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 05:23:37.238854  2705 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 05:23:37.238910  2705 net.cpp:141] Setting up label_data_1_split
I0403 05:23:37.238932  2705 net.cpp:148] Top shape: 100 (100)
I0403 05:23:37.238950  2705 net.cpp:148] Top shape: 100 (100)
I0403 05:23:37.238963  2705 net.cpp:156] Memory required for data: 61836000
I0403 05:23:37.238977  2705 layer_factory.hpp:77] Creating layer conv1
I0403 05:23:37.239003  2705 net.cpp:91] Creating Layer conv1
I0403 05:23:37.239019  2705 net.cpp:425] conv1 <- data
I0403 05:23:37.239037  2705 net.cpp:399] conv1 -> conv1
I0403 05:23:37.240586  2705 net.cpp:141] Setting up conv1
I0403 05:23:37.240614  2705 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 05:23:37.240629  2705 net.cpp:156] Memory required for data: 177996000
I0403 05:23:37.240653  2705 layer_factory.hpp:77] Creating layer relu1
I0403 05:23:37.240671  2705 net.cpp:91] Creating Layer relu1
I0403 05:23:37.240686  2705 net.cpp:425] relu1 <- conv1
I0403 05:23:37.240702  2705 net.cpp:386] relu1 -> conv1 (in-place)
I0403 05:23:37.240720  2705 net.cpp:141] Setting up relu1
I0403 05:23:37.240737  2705 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 05:23:37.240752  2705 net.cpp:156] Memory required for data: 294156000
I0403 05:23:37.240767  2705 layer_factory.hpp:77] Creating layer norm1
I0403 05:23:37.240785  2705 net.cpp:91] Creating Layer norm1
I0403 05:23:37.240802  2705 net.cpp:425] norm1 <- conv1
I0403 05:23:37.240818  2705 net.cpp:399] norm1 -> norm1
I0403 05:23:37.240866  2705 net.cpp:141] Setting up norm1
I0403 05:23:37.240888  2705 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 05:23:37.240902  2705 net.cpp:156] Memory required for data: 410316000
I0403 05:23:37.240916  2705 layer_factory.hpp:77] Creating layer pool1
I0403 05:23:37.240936  2705 net.cpp:91] Creating Layer pool1
I0403 05:23:37.240950  2705 net.cpp:425] pool1 <- norm1
I0403 05:23:37.240968  2705 net.cpp:399] pool1 -> pool1
I0403 05:23:37.241017  2705 net.cpp:141] Setting up pool1
I0403 05:23:37.241039  2705 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 05:23:37.241053  2705 net.cpp:156] Memory required for data: 438309600
I0403 05:23:37.241091  2705 layer_factory.hpp:77] Creating layer conv2
I0403 05:23:37.241113  2705 net.cpp:91] Creating Layer conv2
I0403 05:23:37.241130  2705 net.cpp:425] conv2 <- pool1
I0403 05:23:37.241149  2705 net.cpp:399] conv2 -> conv2
I0403 05:23:37.259929  2705 net.cpp:141] Setting up conv2
I0403 05:23:37.259969  2705 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 05:23:37.259989  2705 net.cpp:156] Memory required for data: 512959200
I0403 05:23:37.260010  2705 layer_factory.hpp:77] Creating layer relu2
I0403 05:23:37.260030  2705 net.cpp:91] Creating Layer relu2
I0403 05:23:37.260046  2705 net.cpp:425] relu2 <- conv2
I0403 05:23:37.260063  2705 net.cpp:386] relu2 -> conv2 (in-place)
I0403 05:23:37.260082  2705 net.cpp:141] Setting up relu2
I0403 05:23:37.260099  2705 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 05:23:37.260113  2705 net.cpp:156] Memory required for data: 587608800
I0403 05:23:37.260128  2705 layer_factory.hpp:77] Creating layer norm2
I0403 05:23:37.260148  2705 net.cpp:91] Creating Layer norm2
I0403 05:23:37.260162  2705 net.cpp:425] norm2 <- conv2
I0403 05:23:37.260179  2705 net.cpp:399] norm2 -> norm2
I0403 05:23:37.260228  2705 net.cpp:141] Setting up norm2
I0403 05:23:37.260251  2705 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 05:23:37.260267  2705 net.cpp:156] Memory required for data: 662258400
I0403 05:23:37.260282  2705 layer_factory.hpp:77] Creating layer pool2
I0403 05:23:37.260299  2705 net.cpp:91] Creating Layer pool2
I0403 05:23:37.260314  2705 net.cpp:425] pool2 <- norm2
I0403 05:23:37.260335  2705 net.cpp:399] pool2 -> pool2
I0403 05:23:37.260396  2705 net.cpp:141] Setting up pool2
I0403 05:23:37.260421  2705 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 05:23:37.260437  2705 net.cpp:156] Memory required for data: 679564000
I0403 05:23:37.260452  2705 layer_factory.hpp:77] Creating layer conv3
I0403 05:23:37.260473  2705 net.cpp:91] Creating Layer conv3
I0403 05:23:37.260489  2705 net.cpp:425] conv3 <- pool2
I0403 05:23:37.260507  2705 net.cpp:399] conv3 -> conv3
I0403 05:23:37.296665  2705 net.cpp:141] Setting up conv3
I0403 05:23:37.296732  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:37.296759  2705 net.cpp:156] Memory required for data: 705522400
I0403 05:23:37.296787  2705 layer_factory.hpp:77] Creating layer relu3
I0403 05:23:37.296814  2705 net.cpp:91] Creating Layer relu3
I0403 05:23:37.296833  2705 net.cpp:425] relu3 <- conv3
I0403 05:23:37.296851  2705 net.cpp:386] relu3 -> conv3 (in-place)
I0403 05:23:37.296872  2705 net.cpp:141] Setting up relu3
I0403 05:23:37.296890  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:37.296905  2705 net.cpp:156] Memory required for data: 731480800
I0403 05:23:37.296921  2705 layer_factory.hpp:77] Creating layer conv4
I0403 05:23:37.296944  2705 net.cpp:91] Creating Layer conv4
I0403 05:23:37.296960  2705 net.cpp:425] conv4 <- conv3
I0403 05:23:37.296980  2705 net.cpp:399] conv4 -> conv4
I0403 05:23:37.324067  2705 net.cpp:141] Setting up conv4
I0403 05:23:37.324102  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:37.324118  2705 net.cpp:156] Memory required for data: 757439200
I0403 05:23:37.324139  2705 layer_factory.hpp:77] Creating layer relu4
I0403 05:23:37.324159  2705 net.cpp:91] Creating Layer relu4
I0403 05:23:37.324177  2705 net.cpp:425] relu4 <- conv4
I0403 05:23:37.324194  2705 net.cpp:386] relu4 -> conv4 (in-place)
I0403 05:23:37.324215  2705 net.cpp:141] Setting up relu4
I0403 05:23:37.324234  2705 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 05:23:37.324249  2705 net.cpp:156] Memory required for data: 783397600
I0403 05:23:37.324262  2705 layer_factory.hpp:77] Creating layer conv5
I0403 05:23:37.324285  2705 net.cpp:91] Creating Layer conv5
I0403 05:23:37.324302  2705 net.cpp:425] conv5 <- conv4
I0403 05:23:37.324322  2705 net.cpp:399] conv5 -> conv5
I0403 05:23:37.342170  2705 net.cpp:141] Setting up conv5
I0403 05:23:37.342206  2705 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 05:23:37.342252  2705 net.cpp:156] Memory required for data: 800703200
I0403 05:23:37.342277  2705 layer_factory.hpp:77] Creating layer relu5
I0403 05:23:37.342298  2705 net.cpp:91] Creating Layer relu5
I0403 05:23:37.342314  2705 net.cpp:425] relu5 <- conv5
I0403 05:23:37.342334  2705 net.cpp:386] relu5 -> conv5 (in-place)
I0403 05:23:37.342361  2705 net.cpp:141] Setting up relu5
I0403 05:23:37.342381  2705 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 05:23:37.342396  2705 net.cpp:156] Memory required for data: 818008800
I0403 05:23:37.342411  2705 layer_factory.hpp:77] Creating layer pool5
I0403 05:23:37.342432  2705 net.cpp:91] Creating Layer pool5
I0403 05:23:37.342448  2705 net.cpp:425] pool5 <- conv5
I0403 05:23:37.342470  2705 net.cpp:399] pool5 -> pool5
I0403 05:23:37.342524  2705 net.cpp:141] Setting up pool5
I0403 05:23:37.342546  2705 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 05:23:37.342561  2705 net.cpp:156] Memory required for data: 821695200
I0403 05:23:37.342576  2705 layer_factory.hpp:77] Creating layer fc6
I0403 05:23:37.342599  2705 net.cpp:91] Creating Layer fc6
I0403 05:23:37.342617  2705 net.cpp:425] fc6 <- pool5
I0403 05:23:37.342634  2705 net.cpp:399] fc6 -> fc6
I0403 05:23:38.775977  2705 net.cpp:141] Setting up fc6
I0403 05:23:38.776070  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:38.776087  2705 net.cpp:156] Memory required for data: 823333600
I0403 05:23:38.776108  2705 layer_factory.hpp:77] Creating layer relu6
I0403 05:23:38.776130  2705 net.cpp:91] Creating Layer relu6
I0403 05:23:38.776146  2705 net.cpp:425] relu6 <- fc6
I0403 05:23:38.776167  2705 net.cpp:386] relu6 -> fc6 (in-place)
I0403 05:23:38.776188  2705 net.cpp:141] Setting up relu6
I0403 05:23:38.776204  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:38.776217  2705 net.cpp:156] Memory required for data: 824972000
I0403 05:23:38.776232  2705 layer_factory.hpp:77] Creating layer drop6
I0403 05:23:38.776249  2705 net.cpp:91] Creating Layer drop6
I0403 05:23:38.776264  2705 net.cpp:425] drop6 <- fc6
I0403 05:23:38.776279  2705 net.cpp:386] drop6 -> fc6 (in-place)
I0403 05:23:38.776319  2705 net.cpp:141] Setting up drop6
I0403 05:23:38.776340  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:38.776361  2705 net.cpp:156] Memory required for data: 826610400
I0403 05:23:38.776376  2705 layer_factory.hpp:77] Creating layer fc7
I0403 05:23:38.776398  2705 net.cpp:91] Creating Layer fc7
I0403 05:23:38.776414  2705 net.cpp:425] fc7 <- fc6
I0403 05:23:38.776432  2705 net.cpp:399] fc7 -> fc7
I0403 05:23:39.406361  2705 net.cpp:141] Setting up fc7
I0403 05:23:39.406461  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:39.406477  2705 net.cpp:156] Memory required for data: 828248800
I0403 05:23:39.406499  2705 layer_factory.hpp:77] Creating layer relu7
I0403 05:23:39.406525  2705 net.cpp:91] Creating Layer relu7
I0403 05:23:39.406543  2705 net.cpp:425] relu7 <- fc7
I0403 05:23:39.406561  2705 net.cpp:386] relu7 -> fc7 (in-place)
I0403 05:23:39.406581  2705 net.cpp:141] Setting up relu7
I0403 05:23:39.406597  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:39.406610  2705 net.cpp:156] Memory required for data: 829887200
I0403 05:23:39.406625  2705 layer_factory.hpp:77] Creating layer drop7
I0403 05:23:39.406642  2705 net.cpp:91] Creating Layer drop7
I0403 05:23:39.406656  2705 net.cpp:425] drop7 <- fc7
I0403 05:23:39.406674  2705 net.cpp:386] drop7 -> fc7 (in-place)
I0403 05:23:39.406711  2705 net.cpp:141] Setting up drop7
I0403 05:23:39.406733  2705 net.cpp:148] Top shape: 100 4096 (409600)
I0403 05:23:39.406745  2705 net.cpp:156] Memory required for data: 831525600
I0403 05:23:39.406759  2705 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 05:23:39.406785  2705 net.cpp:91] Creating Layer fc8_plantvillage
I0403 05:23:39.406801  2705 net.cpp:425] fc8_plantvillage <- fc7
I0403 05:23:39.406818  2705 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 05:23:39.412989  2705 net.cpp:141] Setting up fc8_plantvillage
I0403 05:23:39.413017  2705 net.cpp:148] Top shape: 100 38 (3800)
I0403 05:23:39.413075  2705 net.cpp:156] Memory required for data: 831540800
I0403 05:23:39.413094  2705 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 05:23:39.413112  2705 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 05:23:39.413126  2705 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 05:23:39.413146  2705 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 05:23:39.413166  2705 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 05:23:39.413211  2705 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 05:23:39.413234  2705 net.cpp:148] Top shape: 100 38 (3800)
I0403 05:23:39.413250  2705 net.cpp:148] Top shape: 100 38 (3800)
I0403 05:23:39.413264  2705 net.cpp:156] Memory required for data: 831571200
I0403 05:23:39.413277  2705 layer_factory.hpp:77] Creating layer loss
I0403 05:23:39.413293  2705 net.cpp:91] Creating Layer loss
I0403 05:23:39.413310  2705 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 05:23:39.413331  2705 net.cpp:425] loss <- label_data_1_split_0
I0403 05:23:39.413347  2705 net.cpp:399] loss -> loss
I0403 05:23:39.413368  2705 layer_factory.hpp:77] Creating layer loss
I0403 05:23:39.413467  2705 net.cpp:141] Setting up loss
I0403 05:23:39.413489  2705 net.cpp:148] Top shape: (1)
I0403 05:23:39.413503  2705 net.cpp:151]     with loss weight 1
I0403 05:23:39.413528  2705 net.cpp:156] Memory required for data: 831571204
I0403 05:23:39.413542  2705 layer_factory.hpp:77] Creating layer accuracy
I0403 05:23:39.413559  2705 net.cpp:91] Creating Layer accuracy
I0403 05:23:39.413574  2705 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 05:23:39.413589  2705 net.cpp:425] accuracy <- label_data_1_split_1
I0403 05:23:39.413607  2705 net.cpp:399] accuracy -> accuracy
I0403 05:23:39.413635  2705 net.cpp:141] Setting up accuracy
I0403 05:23:39.413652  2705 net.cpp:148] Top shape: (1)
I0403 05:23:39.413666  2705 net.cpp:156] Memory required for data: 831571208
I0403 05:23:39.413681  2705 net.cpp:219] accuracy does not need backward computation.
I0403 05:23:39.413693  2705 net.cpp:217] loss needs backward computation.
I0403 05:23:39.413707  2705 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 05:23:39.413722  2705 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 05:23:39.413734  2705 net.cpp:217] drop7 needs backward computation.
I0403 05:23:39.413748  2705 net.cpp:217] relu7 needs backward computation.
I0403 05:23:39.413760  2705 net.cpp:217] fc7 needs backward computation.
I0403 05:23:39.413774  2705 net.cpp:217] drop6 needs backward computation.
I0403 05:23:39.413786  2705 net.cpp:217] relu6 needs backward computation.
I0403 05:23:39.413799  2705 net.cpp:217] fc6 needs backward computation.
I0403 05:23:39.413812  2705 net.cpp:217] pool5 needs backward computation.
I0403 05:23:39.413825  2705 net.cpp:217] relu5 needs backward computation.
I0403 05:23:39.413838  2705 net.cpp:217] conv5 needs backward computation.
I0403 05:23:39.413851  2705 net.cpp:217] relu4 needs backward computation.
I0403 05:23:39.413864  2705 net.cpp:217] conv4 needs backward computation.
I0403 05:23:39.413877  2705 net.cpp:217] relu3 needs backward computation.
I0403 05:23:39.413892  2705 net.cpp:217] conv3 needs backward computation.
I0403 05:23:39.413904  2705 net.cpp:217] pool2 needs backward computation.
I0403 05:23:39.413918  2705 net.cpp:217] norm2 needs backward computation.
I0403 05:23:39.413931  2705 net.cpp:217] relu2 needs backward computation.
I0403 05:23:39.413944  2705 net.cpp:217] conv2 needs backward computation.
I0403 05:23:39.413957  2705 net.cpp:217] pool1 needs backward computation.
I0403 05:23:39.413971  2705 net.cpp:217] norm1 needs backward computation.
I0403 05:23:39.413985  2705 net.cpp:217] relu1 needs backward computation.
I0403 05:23:39.413997  2705 net.cpp:217] conv1 needs backward computation.
I0403 05:23:39.418792  2705 net.cpp:219] label_data_1_split does not need backward computation.
I0403 05:23:39.418812  2705 net.cpp:219] data does not need backward computation.
I0403 05:23:39.418825  2705 net.cpp:261] This network produces output accuracy
I0403 05:23:39.418840  2705 net.cpp:261] This network produces output loss
I0403 05:23:39.418869  2705 net.cpp:274] Network initialization done.
I0403 05:23:39.418973  2705 solver.cpp:60] Solver scaffolding done.
I0403 05:23:39.442926  2705 parallel.cpp:392] GPUs pairs 0:1
I0403 05:23:39.703668  2705 data_layer.cpp:41] output data size: 100,3,227,227
I0403 05:23:42.150235  2705 parallel.cpp:425] Starting Optimization
I0403 05:23:42.150385  2705 solver.cpp:279] Solving 
I0403 05:23:42.150409  2705 solver.cpp:280] Learning Rate Policy: step
I0403 05:23:42.150557  2705 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 05:24:31.396819  2705 solver.cpp:404]     Test net output #0: accuracy = 0.0240553
I0403 05:24:31.397002  2705 solver.cpp:404]     Test net output #1: loss = 3.6357 (* 1 = 3.6357 loss)
I0403 05:24:32.002041  2705 solver.cpp:228] Iteration 0, loss = 3.61644
I0403 05:24:32.002115  2705 solver.cpp:244]     Train net output #0: loss = 3.61644 (* 1 = 3.61644 loss)
I0403 05:24:32.127040  2705 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 05:24:43.486716  2705 solver.cpp:228] Iteration 16, loss = 3.35131
I0403 05:24:43.486800  2705 solver.cpp:244]     Train net output #0: loss = 3.35131 (* 1 = 3.35131 loss)
I0403 05:24:43.670111  2705 sgd_solver.cpp:106] Iteration 16, lr = 0.005
I0403 05:24:54.979364  2705 solver.cpp:228] Iteration 32, loss = 3.34503
I0403 05:24:54.979454  2705 solver.cpp:244]     Train net output #0: loss = 3.34503 (* 1 = 3.34503 loss)
I0403 05:24:55.163630  2705 sgd_solver.cpp:106] Iteration 32, lr = 0.005
I0403 05:25:06.432337  2705 solver.cpp:228] Iteration 48, loss = 3.33599
I0403 05:25:06.432616  2705 solver.cpp:244]     Train net output #0: loss = 3.33599 (* 1 = 3.33599 loss)
I0403 05:25:06.614336  2705 sgd_solver.cpp:106] Iteration 48, lr = 0.005
I0403 05:25:17.832029  2705 solver.cpp:228] Iteration 64, loss = 2.97869
I0403 05:25:17.832113  2705 solver.cpp:244]     Train net output #0: loss = 2.97869 (* 1 = 2.97869 loss)
I0403 05:25:18.046890  2705 sgd_solver.cpp:106] Iteration 64, lr = 0.005
I0403 05:25:29.400571  2705 solver.cpp:228] Iteration 80, loss = 3.26629
I0403 05:25:29.400650  2705 solver.cpp:244]     Train net output #0: loss = 3.26629 (* 1 = 3.26629 loss)
I0403 05:25:29.577672  2705 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 05:25:40.821913  2705 solver.cpp:228] Iteration 96, loss = 2.96672
I0403 05:25:40.822175  2705 solver.cpp:244]     Train net output #0: loss = 2.96672 (* 1 = 2.96672 loss)
I0403 05:25:41.011373  2705 sgd_solver.cpp:106] Iteration 96, lr = 0.005
I0403 05:25:52.369261  2705 solver.cpp:228] Iteration 112, loss = 2.99551
I0403 05:25:52.369338  2705 solver.cpp:244]     Train net output #0: loss = 2.99551 (* 1 = 2.99551 loss)
I0403 05:25:52.546105  2705 sgd_solver.cpp:106] Iteration 112, lr = 0.005
I0403 05:26:03.779589  2705 solver.cpp:228] Iteration 128, loss = 2.62278
I0403 05:26:03.779669  2705 solver.cpp:244]     Train net output #0: loss = 2.62278 (* 1 = 2.62278 loss)
I0403 05:26:03.958415  2705 sgd_solver.cpp:106] Iteration 128, lr = 0.005
I0403 05:26:15.221843  2705 solver.cpp:228] Iteration 144, loss = 2.37563
I0403 05:26:15.222132  2705 solver.cpp:244]     Train net output #0: loss = 2.37563 (* 1 = 2.37563 loss)
I0403 05:26:15.416908  2705 sgd_solver.cpp:106] Iteration 144, lr = 0.005
I0403 05:26:26.727622  2705 solver.cpp:228] Iteration 160, loss = 2.64079
I0403 05:26:26.727725  2705 solver.cpp:244]     Train net output #0: loss = 2.64079 (* 1 = 2.64079 loss)
I0403 05:26:26.900264  2705 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 05:26:38.661609  2705 solver.cpp:228] Iteration 176, loss = 2.29965
I0403 05:26:38.661707  2705 solver.cpp:244]     Train net output #0: loss = 2.29965 (* 1 = 2.29965 loss)
I0403 05:26:38.828474  2705 sgd_solver.cpp:106] Iteration 176, lr = 0.005
I0403 05:26:50.244211  2705 solver.cpp:228] Iteration 192, loss = 2.03569
I0403 05:26:50.244544  2705 solver.cpp:244]     Train net output #0: loss = 2.03569 (* 1 = 2.03569 loss)
I0403 05:26:50.398857  2705 sgd_solver.cpp:106] Iteration 192, lr = 0.005
I0403 05:27:02.184926  2705 solver.cpp:228] Iteration 208, loss = 2.28964
I0403 05:27:02.185034  2705 solver.cpp:244]     Train net output #0: loss = 2.28964 (* 1 = 2.28964 loss)
I0403 05:27:02.366207  2705 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 05:27:13.844645  2705 solver.cpp:228] Iteration 224, loss = 2.22901
I0403 05:27:13.844750  2705 solver.cpp:244]     Train net output #0: loss = 2.22901 (* 1 = 2.22901 loss)
I0403 05:27:14.026304  2705 sgd_solver.cpp:106] Iteration 224, lr = 0.005
I0403 05:27:25.461946  2705 solver.cpp:228] Iteration 240, loss = 1.78825
I0403 05:27:25.462266  2705 solver.cpp:244]     Train net output #0: loss = 1.78825 (* 1 = 1.78825 loss)
I0403 05:27:25.664034  2705 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 05:27:37.102530  2705 solver.cpp:228] Iteration 256, loss = 2.00019
I0403 05:27:37.102641  2705 solver.cpp:244]     Train net output #0: loss = 2.00019 (* 1 = 2.00019 loss)
I0403 05:27:37.276077  2705 sgd_solver.cpp:106] Iteration 256, lr = 0.005
I0403 05:27:48.558604  2705 solver.cpp:228] Iteration 272, loss = 1.75241
I0403 05:27:48.558713  2705 solver.cpp:244]     Train net output #0: loss = 1.75241 (* 1 = 1.75241 loss)
I0403 05:27:48.772030  2705 sgd_solver.cpp:106] Iteration 272, lr = 0.005
I0403 05:28:00.086282  2705 solver.cpp:228] Iteration 288, loss = 1.62341
I0403 05:28:00.086596  2705 solver.cpp:244]     Train net output #0: loss = 1.62341 (* 1 = 1.62341 loss)
I0403 05:28:00.285871  2705 sgd_solver.cpp:106] Iteration 288, lr = 0.005
I0403 05:28:11.752619  2705 solver.cpp:228] Iteration 304, loss = 1.73078
I0403 05:28:11.752730  2705 solver.cpp:244]     Train net output #0: loss = 1.73078 (* 1 = 1.73078 loss)
I0403 05:28:11.963378  2705 sgd_solver.cpp:106] Iteration 304, lr = 0.005
I0403 05:28:23.415386  2705 solver.cpp:228] Iteration 320, loss = 1.61879
I0403 05:28:23.415484  2705 solver.cpp:244]     Train net output #0: loss = 1.61879 (* 1 = 1.61879 loss)
I0403 05:28:23.540112  2705 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 05:28:26.537792  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_325.caffemodel
I0403 05:28:29.398219  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_325.solverstate
I0403 05:28:31.355623  2705 solver.cpp:337] Iteration 325, Testing net (#0)
I0403 05:29:19.794227  2705 solver.cpp:404]     Test net output #0: accuracy = 0.575069
I0403 05:29:19.794534  2705 solver.cpp:404]     Test net output #1: loss = 1.43767 (* 1 = 1.43767 loss)
I0403 05:29:28.399826  2705 solver.cpp:228] Iteration 336, loss = 1.10282
I0403 05:29:28.399922  2705 solver.cpp:244]     Train net output #0: loss = 1.10282 (* 1 = 1.10282 loss)
I0403 05:29:28.557696  2705 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 05:29:39.935340  2705 solver.cpp:228] Iteration 352, loss = 1.36285
I0403 05:29:39.935452  2705 solver.cpp:244]     Train net output #0: loss = 1.36285 (* 1 = 1.36285 loss)
I0403 05:29:40.122447  2705 sgd_solver.cpp:106] Iteration 352, lr = 0.005
I0403 05:29:51.520607  2705 solver.cpp:228] Iteration 368, loss = 1.22095
I0403 05:29:51.520903  2705 solver.cpp:244]     Train net output #0: loss = 1.22095 (* 1 = 1.22095 loss)
I0403 05:29:51.670665  2705 sgd_solver.cpp:106] Iteration 368, lr = 0.005
I0403 05:30:03.109266  2705 solver.cpp:228] Iteration 384, loss = 1.296
I0403 05:30:03.109380  2705 solver.cpp:244]     Train net output #0: loss = 1.296 (* 1 = 1.296 loss)
I0403 05:30:03.321542  2705 sgd_solver.cpp:106] Iteration 384, lr = 0.005
I0403 05:30:14.550976  2705 solver.cpp:228] Iteration 400, loss = 1.30125
I0403 05:30:14.551086  2705 solver.cpp:244]     Train net output #0: loss = 1.30125 (* 1 = 1.30125 loss)
I0403 05:30:14.791576  2705 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 05:30:26.392513  2705 solver.cpp:228] Iteration 416, loss = 1.08053
I0403 05:30:26.392860  2705 solver.cpp:244]     Train net output #0: loss = 1.08053 (* 1 = 1.08053 loss)
I0403 05:30:26.517393  2705 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 05:30:38.087793  2705 solver.cpp:228] Iteration 432, loss = 1.10062
I0403 05:30:38.087904  2705 solver.cpp:244]     Train net output #0: loss = 1.10062 (* 1 = 1.10062 loss)
I0403 05:30:38.317891  2705 sgd_solver.cpp:106] Iteration 432, lr = 0.005
I0403 05:30:49.654064  2705 solver.cpp:228] Iteration 448, loss = 1.15044
I0403 05:30:49.654173  2705 solver.cpp:244]     Train net output #0: loss = 1.15044 (* 1 = 1.15044 loss)
I0403 05:30:49.841578  2705 sgd_solver.cpp:106] Iteration 448, lr = 0.005
I0403 05:31:01.465379  2705 solver.cpp:228] Iteration 464, loss = 1.0016
I0403 05:31:01.465665  2705 solver.cpp:244]     Train net output #0: loss = 1.0016 (* 1 = 1.0016 loss)
I0403 05:31:01.704499  2705 sgd_solver.cpp:106] Iteration 464, lr = 0.005
I0403 05:31:12.995622  2705 solver.cpp:228] Iteration 480, loss = 1.13271
I0403 05:31:12.995733  2705 solver.cpp:244]     Train net output #0: loss = 1.13271 (* 1 = 1.13271 loss)
I0403 05:31:13.178093  2705 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 05:31:24.470685  2705 solver.cpp:228] Iteration 496, loss = 1.14504
I0403 05:31:24.470793  2705 solver.cpp:244]     Train net output #0: loss = 1.14504 (* 1 = 1.14504 loss)
I0403 05:31:24.664731  2705 sgd_solver.cpp:106] Iteration 496, lr = 0.005
I0403 05:31:36.007493  2705 solver.cpp:228] Iteration 512, loss = 1.13059
I0403 05:31:36.007884  2705 solver.cpp:244]     Train net output #0: loss = 1.13059 (* 1 = 1.13059 loss)
I0403 05:31:36.157755  2705 sgd_solver.cpp:106] Iteration 512, lr = 0.005
I0403 05:31:47.893106  2705 solver.cpp:228] Iteration 528, loss = 1.03356
I0403 05:31:47.893211  2705 solver.cpp:244]     Train net output #0: loss = 1.03356 (* 1 = 1.03356 loss)
I0403 05:31:48.122580  2705 sgd_solver.cpp:106] Iteration 528, lr = 0.005
I0403 05:31:59.366780  2705 solver.cpp:228] Iteration 544, loss = 1.01088
I0403 05:31:59.366890  2705 solver.cpp:244]     Train net output #0: loss = 1.01088 (* 1 = 1.01088 loss)
I0403 05:31:59.594277  2705 sgd_solver.cpp:106] Iteration 544, lr = 0.005
I0403 05:32:11.164882  2705 solver.cpp:228] Iteration 560, loss = 1.17368
I0403 05:32:11.165185  2705 solver.cpp:244]     Train net output #0: loss = 1.17368 (* 1 = 1.17368 loss)
I0403 05:32:11.333000  2705 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 05:32:22.814512  2705 solver.cpp:228] Iteration 576, loss = 0.991617
I0403 05:32:22.814625  2705 solver.cpp:244]     Train net output #0: loss = 0.991617 (* 1 = 0.991617 loss)
I0403 05:32:22.987582  2705 sgd_solver.cpp:106] Iteration 576, lr = 0.005
I0403 05:32:34.378399  2705 solver.cpp:228] Iteration 592, loss = 0.981891
I0403 05:32:34.378507  2705 solver.cpp:244]     Train net output #0: loss = 0.981891 (* 1 = 0.981891 loss)
I0403 05:32:34.584342  2705 sgd_solver.cpp:106] Iteration 592, lr = 0.005
I0403 05:32:45.930963  2705 solver.cpp:228] Iteration 608, loss = 0.990727
I0403 05:32:45.931267  2705 solver.cpp:244]     Train net output #0: loss = 0.990727 (* 1 = 0.990727 loss)
I0403 05:32:46.124495  2705 sgd_solver.cpp:106] Iteration 608, lr = 0.005
I0403 05:32:57.514639  2705 solver.cpp:228] Iteration 624, loss = 0.746574
I0403 05:32:57.514750  2705 solver.cpp:244]     Train net output #0: loss = 0.746574 (* 1 = 0.746574 loss)
I0403 05:32:57.688181  2705 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 05:33:09.106356  2705 solver.cpp:228] Iteration 640, loss = 0.847116
I0403 05:33:09.106456  2705 solver.cpp:244]     Train net output #0: loss = 0.847116 (* 1 = 0.847116 loss)
I0403 05:33:09.284744  2705 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 05:33:15.856256  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_650.caffemodel
I0403 05:33:18.671994  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_650.solverstate
I0403 05:33:20.507962  2705 solver.cpp:337] Iteration 650, Testing net (#0)
I0403 05:34:08.958293  2705 solver.cpp:404]     Test net output #0: accuracy = 0.744009
I0403 05:34:08.958602  2705 solver.cpp:404]     Test net output #1: loss = 0.803423 (* 1 = 0.803423 loss)
I0403 05:34:13.869108  2705 solver.cpp:228] Iteration 656, loss = 0.974008
I0403 05:34:13.869213  2705 solver.cpp:244]     Train net output #0: loss = 0.974008 (* 1 = 0.974008 loss)
I0403 05:34:14.051249  2705 sgd_solver.cpp:106] Iteration 656, lr = 0.005
I0403 05:34:25.618305  2705 solver.cpp:228] Iteration 672, loss = 0.666637
I0403 05:34:25.618422  2705 solver.cpp:244]     Train net output #0: loss = 0.666637 (* 1 = 0.666637 loss)
I0403 05:34:25.804697  2705 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 05:34:37.151165  2705 solver.cpp:228] Iteration 688, loss = 0.901266
I0403 05:34:37.151265  2705 solver.cpp:244]     Train net output #0: loss = 0.901266 (* 1 = 0.901266 loss)
I0403 05:34:37.321709  2705 sgd_solver.cpp:106] Iteration 688, lr = 0.005
I0403 05:34:48.637800  2705 solver.cpp:228] Iteration 704, loss = 1.05356
I0403 05:34:48.638113  2705 solver.cpp:244]     Train net output #0: loss = 1.05356 (* 1 = 1.05356 loss)
I0403 05:34:48.818126  2705 sgd_solver.cpp:106] Iteration 704, lr = 0.005
I0403 05:35:00.154774  2705 solver.cpp:228] Iteration 720, loss = 0.670859
I0403 05:35:00.154873  2705 solver.cpp:244]     Train net output #0: loss = 0.670859 (* 1 = 0.670859 loss)
I0403 05:35:00.329192  2705 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 05:35:11.719233  2705 solver.cpp:228] Iteration 736, loss = 0.846424
I0403 05:35:11.719346  2705 solver.cpp:244]     Train net output #0: loss = 0.846424 (* 1 = 0.846424 loss)
I0403 05:35:11.906046  2705 sgd_solver.cpp:106] Iteration 736, lr = 0.005
I0403 05:35:23.266510  2705 solver.cpp:228] Iteration 752, loss = 0.745276
I0403 05:35:23.266822  2705 solver.cpp:244]     Train net output #0: loss = 0.745276 (* 1 = 0.745276 loss)
I0403 05:35:23.446476  2705 sgd_solver.cpp:106] Iteration 752, lr = 0.005
I0403 05:35:34.841418  2705 solver.cpp:228] Iteration 768, loss = 0.683914
I0403 05:35:34.841516  2705 solver.cpp:244]     Train net output #0: loss = 0.683914 (* 1 = 0.683914 loss)
I0403 05:35:35.019193  2705 sgd_solver.cpp:106] Iteration 768, lr = 0.005
I0403 05:35:46.576987  2705 solver.cpp:228] Iteration 784, loss = 0.971326
I0403 05:35:46.577096  2705 solver.cpp:244]     Train net output #0: loss = 0.971326 (* 1 = 0.971326 loss)
I0403 05:35:46.771188  2705 sgd_solver.cpp:106] Iteration 784, lr = 0.005
I0403 05:35:58.263335  2705 solver.cpp:228] Iteration 800, loss = 0.663886
I0403 05:35:58.263672  2705 solver.cpp:244]     Train net output #0: loss = 0.663886 (* 1 = 0.663886 loss)
I0403 05:35:58.456646  2705 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 05:36:09.848223  2705 solver.cpp:228] Iteration 816, loss = 0.776235
I0403 05:36:09.848337  2705 solver.cpp:244]     Train net output #0: loss = 0.776235 (* 1 = 0.776235 loss)
I0403 05:36:10.043138  2705 sgd_solver.cpp:106] Iteration 816, lr = 0.005
I0403 05:36:21.229056  2705 solver.cpp:228] Iteration 832, loss = 0.858193
I0403 05:36:21.229164  2705 solver.cpp:244]     Train net output #0: loss = 0.858193 (* 1 = 0.858193 loss)
I0403 05:36:21.419755  2705 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 05:36:32.768774  2705 solver.cpp:228] Iteration 848, loss = 0.81426
I0403 05:36:32.769081  2705 solver.cpp:244]     Train net output #0: loss = 0.81426 (* 1 = 0.81426 loss)
I0403 05:36:32.950012  2705 sgd_solver.cpp:106] Iteration 848, lr = 0.005
I0403 05:36:44.582428  2705 solver.cpp:228] Iteration 864, loss = 0.719128
I0403 05:36:44.582538  2705 solver.cpp:244]     Train net output #0: loss = 0.719128 (* 1 = 0.719128 loss)
I0403 05:36:44.805536  2705 sgd_solver.cpp:106] Iteration 864, lr = 0.005
I0403 05:36:56.179191  2705 solver.cpp:228] Iteration 880, loss = 0.616529
I0403 05:36:56.179301  2705 solver.cpp:244]     Train net output #0: loss = 0.616529 (* 1 = 0.616529 loss)
I0403 05:36:56.368993  2705 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 05:37:07.620864  2705 solver.cpp:228] Iteration 896, loss = 0.696124
I0403 05:37:07.621196  2705 solver.cpp:244]     Train net output #0: loss = 0.696124 (* 1 = 0.696124 loss)
I0403 05:37:07.775787  2705 sgd_solver.cpp:106] Iteration 896, lr = 0.005
I0403 05:37:19.299737  2705 solver.cpp:228] Iteration 912, loss = 0.857941
I0403 05:37:19.299837  2705 solver.cpp:244]     Train net output #0: loss = 0.857941 (* 1 = 0.857941 loss)
I0403 05:37:19.485702  2705 sgd_solver.cpp:106] Iteration 912, lr = 0.005
I0403 05:37:30.838452  2705 solver.cpp:228] Iteration 928, loss = 0.632039
I0403 05:37:30.838562  2705 solver.cpp:244]     Train net output #0: loss = 0.632039 (* 1 = 0.632039 loss)
I0403 05:37:31.025324  2705 sgd_solver.cpp:106] Iteration 928, lr = 0.005
I0403 05:37:42.498827  2705 solver.cpp:228] Iteration 944, loss = 0.581962
I0403 05:37:42.499074  2705 solver.cpp:244]     Train net output #0: loss = 0.581962 (* 1 = 0.581962 loss)
I0403 05:37:42.677649  2705 sgd_solver.cpp:106] Iteration 944, lr = 0.005
I0403 05:37:54.066251  2705 solver.cpp:228] Iteration 960, loss = 0.416464
I0403 05:37:54.066352  2705 solver.cpp:244]     Train net output #0: loss = 0.416464 (* 1 = 0.416464 loss)
I0403 05:37:54.224658  2705 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 05:38:04.249924  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_975.caffemodel
I0403 05:38:07.046520  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_975.solverstate
I0403 05:38:08.873702  2705 solver.cpp:337] Iteration 975, Testing net (#0)
I0403 05:38:57.313006  2705 solver.cpp:404]     Test net output #0: accuracy = 0.797328
I0403 05:38:57.313262  2705 solver.cpp:404]     Test net output #1: loss = 0.627687 (* 1 = 0.627687 loss)
I0403 05:38:58.527264  2705 solver.cpp:228] Iteration 976, loss = 0.68465
I0403 05:38:58.527374  2705 solver.cpp:244]     Train net output #0: loss = 0.68465 (* 1 = 0.68465 loss)
I0403 05:38:58.708371  2705 sgd_solver.cpp:106] Iteration 976, lr = 0.005
I0403 05:39:10.052534  2705 solver.cpp:228] Iteration 992, loss = 0.412195
I0403 05:39:10.052633  2705 solver.cpp:244]     Train net output #0: loss = 0.412195 (* 1 = 0.412195 loss)
I0403 05:39:10.210722  2705 sgd_solver.cpp:106] Iteration 992, lr = 0.005
I0403 05:39:21.756935  2705 solver.cpp:228] Iteration 1008, loss = 0.624955
I0403 05:39:21.757033  2705 solver.cpp:244]     Train net output #0: loss = 0.624955 (* 1 = 0.624955 loss)
I0403 05:39:21.935205  2705 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 05:39:33.358028  2705 solver.cpp:228] Iteration 1024, loss = 0.725737
I0403 05:39:33.358280  2705 solver.cpp:244]     Train net output #0: loss = 0.725737 (* 1 = 0.725737 loss)
I0403 05:39:33.553232  2705 sgd_solver.cpp:106] Iteration 1024, lr = 0.005
I0403 05:39:44.933423  2705 solver.cpp:228] Iteration 1040, loss = 0.550688
I0403 05:39:44.933521  2705 solver.cpp:244]     Train net output #0: loss = 0.550688 (* 1 = 0.550688 loss)
I0403 05:39:45.107188  2705 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 05:39:56.588788  2705 solver.cpp:228] Iteration 1056, loss = 0.704757
I0403 05:39:56.588898  2705 solver.cpp:244]     Train net output #0: loss = 0.704757 (* 1 = 0.704757 loss)
I0403 05:39:56.805389  2705 sgd_solver.cpp:106] Iteration 1056, lr = 0.005
I0403 05:40:08.269800  2705 solver.cpp:228] Iteration 1072, loss = 0.490672
I0403 05:40:08.270074  2705 solver.cpp:244]     Train net output #0: loss = 0.490672 (* 1 = 0.490672 loss)
I0403 05:40:08.362282  2705 sgd_solver.cpp:106] Iteration 1072, lr = 0.005
I0403 05:40:20.079960  2705 solver.cpp:228] Iteration 1088, loss = 0.425302
I0403 05:40:20.080065  2705 solver.cpp:244]     Train net output #0: loss = 0.425302 (* 1 = 0.425302 loss)
I0403 05:40:20.254370  2705 sgd_solver.cpp:106] Iteration 1088, lr = 0.005
I0403 05:40:31.508667  2705 solver.cpp:228] Iteration 1104, loss = 0.636476
I0403 05:40:31.508772  2705 solver.cpp:244]     Train net output #0: loss = 0.636476 (* 1 = 0.636476 loss)
I0403 05:40:31.717284  2705 sgd_solver.cpp:106] Iteration 1104, lr = 0.005
I0403 05:40:42.894846  2705 solver.cpp:228] Iteration 1120, loss = 0.580561
I0403 05:40:42.895160  2705 solver.cpp:244]     Train net output #0: loss = 0.580561 (* 1 = 0.580561 loss)
I0403 05:40:43.058325  2705 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 05:40:54.319183  2705 solver.cpp:228] Iteration 1136, loss = 0.674654
I0403 05:40:54.319293  2705 solver.cpp:244]     Train net output #0: loss = 0.674654 (* 1 = 0.674654 loss)
I0403 05:40:54.501639  2705 sgd_solver.cpp:106] Iteration 1136, lr = 0.005
I0403 05:41:05.846112  2705 solver.cpp:228] Iteration 1152, loss = 0.625716
I0403 05:41:05.846221  2705 solver.cpp:244]     Train net output #0: loss = 0.625716 (* 1 = 0.625716 loss)
I0403 05:41:06.082056  2705 sgd_solver.cpp:106] Iteration 1152, lr = 0.005
I0403 05:41:17.457805  2705 solver.cpp:228] Iteration 1168, loss = 0.393792
I0403 05:41:17.458106  2705 solver.cpp:244]     Train net output #0: loss = 0.393792 (* 1 = 0.393792 loss)
I0403 05:41:17.716583  2705 sgd_solver.cpp:106] Iteration 1168, lr = 0.005
I0403 05:41:29.318366  2705 solver.cpp:228] Iteration 1184, loss = 0.42535
I0403 05:41:29.318480  2705 solver.cpp:244]     Train net output #0: loss = 0.42535 (* 1 = 0.42535 loss)
I0403 05:41:29.522598  2705 sgd_solver.cpp:106] Iteration 1184, lr = 0.005
I0403 05:41:40.995306  2705 solver.cpp:228] Iteration 1200, loss = 0.59257
I0403 05:41:40.995409  2705 solver.cpp:244]     Train net output #0: loss = 0.59257 (* 1 = 0.59257 loss)
I0403 05:41:41.145290  2705 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 05:41:52.526779  2705 solver.cpp:228] Iteration 1216, loss = 0.543004
I0403 05:41:52.527082  2705 solver.cpp:244]     Train net output #0: loss = 0.543004 (* 1 = 0.543004 loss)
I0403 05:41:52.704396  2705 sgd_solver.cpp:106] Iteration 1216, lr = 0.005
I0403 05:42:04.077014  2705 solver.cpp:228] Iteration 1232, loss = 0.813857
I0403 05:42:04.077127  2705 solver.cpp:244]     Train net output #0: loss = 0.813857 (* 1 = 0.813857 loss)
I0403 05:42:04.283212  2705 sgd_solver.cpp:106] Iteration 1232, lr = 0.005
I0403 05:42:15.686458  2705 solver.cpp:228] Iteration 1248, loss = 0.470591
I0403 05:42:15.686568  2705 solver.cpp:244]     Train net output #0: loss = 0.470591 (* 1 = 0.470591 loss)
I0403 05:42:15.885067  2705 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 05:42:27.353602  2705 solver.cpp:228] Iteration 1264, loss = 0.425021
I0403 05:42:27.353837  2705 solver.cpp:244]     Train net output #0: loss = 0.425021 (* 1 = 0.425021 loss)
I0403 05:42:27.525949  2705 sgd_solver.cpp:106] Iteration 1264, lr = 0.005
I0403 05:42:39.036654  2705 solver.cpp:228] Iteration 1280, loss = 0.29042
I0403 05:42:39.036768  2705 solver.cpp:244]     Train net output #0: loss = 0.29042 (* 1 = 0.29042 loss)
I0403 05:42:39.229470  2705 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 05:42:50.577260  2705 solver.cpp:228] Iteration 1296, loss = 0.484525
I0403 05:42:50.577376  2705 solver.cpp:244]     Train net output #0: loss = 0.484525 (* 1 = 0.484525 loss)
I0403 05:42:50.760715  2705 sgd_solver.cpp:106] Iteration 1296, lr = 0.005
I0403 05:42:52.924726  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_1300.caffemodel
I0403 05:42:55.766409  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_1300.solverstate
I0403 05:42:57.595393  2705 solver.cpp:337] Iteration 1300, Testing net (#0)
I0403 05:43:46.025369  2705 solver.cpp:404]     Test net output #0: accuracy = 0.854516
I0403 05:43:46.025662  2705 solver.cpp:404]     Test net output #1: loss = 0.441577 (* 1 = 0.441577 loss)
I0403 05:43:55.093153  2705 solver.cpp:228] Iteration 1312, loss = 0.28621
I0403 05:43:55.093264  2705 solver.cpp:244]     Train net output #0: loss = 0.28621 (* 1 = 0.28621 loss)
I0403 05:43:55.290487  2705 sgd_solver.cpp:106] Iteration 1312, lr = 0.005
I0403 05:44:06.550500  2705 solver.cpp:228] Iteration 1328, loss = 0.602752
I0403 05:44:06.550611  2705 solver.cpp:244]     Train net output #0: loss = 0.602752 (* 1 = 0.602752 loss)
I0403 05:44:06.754490  2705 sgd_solver.cpp:106] Iteration 1328, lr = 0.005
I0403 05:44:18.009587  2705 solver.cpp:228] Iteration 1344, loss = 0.501819
I0403 05:44:18.009866  2705 solver.cpp:244]     Train net output #0: loss = 0.501819 (* 1 = 0.501819 loss)
I0403 05:44:18.168043  2705 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 05:44:29.853487  2705 solver.cpp:228] Iteration 1360, loss = 0.647144
I0403 05:44:29.853590  2705 solver.cpp:244]     Train net output #0: loss = 0.647144 (* 1 = 0.647144 loss)
I0403 05:44:30.003726  2705 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 05:44:41.417735  2705 solver.cpp:228] Iteration 1376, loss = 0.466969
I0403 05:44:41.417847  2705 solver.cpp:244]     Train net output #0: loss = 0.466969 (* 1 = 0.466969 loss)
I0403 05:44:41.633604  2705 sgd_solver.cpp:106] Iteration 1376, lr = 0.005
I0403 05:44:53.402509  2705 solver.cpp:228] Iteration 1392, loss = 0.360593
I0403 05:44:53.402823  2705 solver.cpp:244]     Train net output #0: loss = 0.360593 (* 1 = 0.360593 loss)
I0403 05:44:53.628166  2705 sgd_solver.cpp:106] Iteration 1392, lr = 0.005
I0403 05:45:04.987577  2705 solver.cpp:228] Iteration 1408, loss = 0.452941
I0403 05:45:04.987684  2705 solver.cpp:244]     Train net output #0: loss = 0.452941 (* 1 = 0.452941 loss)
I0403 05:45:05.174785  2705 sgd_solver.cpp:106] Iteration 1408, lr = 0.005
I0403 05:45:16.607708  2705 solver.cpp:228] Iteration 1424, loss = 0.482342
I0403 05:45:16.607821  2705 solver.cpp:244]     Train net output #0: loss = 0.482342 (* 1 = 0.482342 loss)
I0403 05:45:16.807790  2705 sgd_solver.cpp:106] Iteration 1424, lr = 0.005
I0403 05:45:28.310039  2705 solver.cpp:228] Iteration 1440, loss = 0.381438
I0403 05:45:28.310371  2705 solver.cpp:244]     Train net output #0: loss = 0.381438 (* 1 = 0.381438 loss)
I0403 05:45:28.521788  2705 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 05:45:39.841845  2705 solver.cpp:228] Iteration 1456, loss = 0.410434
I0403 05:45:39.841959  2705 solver.cpp:244]     Train net output #0: loss = 0.410434 (* 1 = 0.410434 loss)
I0403 05:45:40.036756  2705 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 05:45:51.480911  2705 solver.cpp:228] Iteration 1472, loss = 0.393384
I0403 05:45:51.481019  2705 solver.cpp:244]     Train net output #0: loss = 0.393384 (* 1 = 0.393384 loss)
I0403 05:45:51.681859  2705 sgd_solver.cpp:106] Iteration 1472, lr = 0.005
I0403 05:46:02.939951  2705 solver.cpp:228] Iteration 1488, loss = 0.640444
I0403 05:46:02.940242  2705 solver.cpp:244]     Train net output #0: loss = 0.640444 (* 1 = 0.640444 loss)
I0403 05:46:03.136119  2705 sgd_solver.cpp:106] Iteration 1488, lr = 0.005
I0403 05:46:14.321492  2705 solver.cpp:228] Iteration 1504, loss = 0.390871
I0403 05:46:14.321614  2705 solver.cpp:244]     Train net output #0: loss = 0.390871 (* 1 = 0.390871 loss)
I0403 05:46:14.542395  2705 sgd_solver.cpp:106] Iteration 1504, lr = 0.005
I0403 05:46:26.043999  2705 solver.cpp:228] Iteration 1520, loss = 0.294043
I0403 05:46:26.044108  2705 solver.cpp:244]     Train net output #0: loss = 0.294043 (* 1 = 0.294043 loss)
I0403 05:46:26.226528  2705 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 05:46:37.618314  2705 solver.cpp:228] Iteration 1536, loss = 0.531235
I0403 05:46:37.618604  2705 solver.cpp:244]     Train net output #0: loss = 0.531235 (* 1 = 0.531235 loss)
I0403 05:46:37.810771  2705 sgd_solver.cpp:106] Iteration 1536, lr = 0.005
I0403 05:46:49.178961  2705 solver.cpp:228] Iteration 1552, loss = 0.462349
I0403 05:46:49.179080  2705 solver.cpp:244]     Train net output #0: loss = 0.462349 (* 1 = 0.462349 loss)
I0403 05:46:49.369546  2705 sgd_solver.cpp:106] Iteration 1552, lr = 0.005
I0403 05:47:00.738729  2705 solver.cpp:228] Iteration 1568, loss = 0.309289
I0403 05:47:00.738840  2705 solver.cpp:244]     Train net output #0: loss = 0.309289 (* 1 = 0.309289 loss)
I0403 05:47:00.925781  2705 sgd_solver.cpp:106] Iteration 1568, lr = 0.005
I0403 05:47:12.194141  2705 solver.cpp:228] Iteration 1584, loss = 0.37121
I0403 05:47:12.194458  2705 solver.cpp:244]     Train net output #0: loss = 0.37121 (* 1 = 0.37121 loss)
I0403 05:47:12.373904  2705 sgd_solver.cpp:106] Iteration 1584, lr = 0.005
I0403 05:47:24.045593  2705 solver.cpp:228] Iteration 1600, loss = 0.525572
I0403 05:47:24.045701  2705 solver.cpp:244]     Train net output #0: loss = 0.525572 (* 1 = 0.525572 loss)
I0403 05:47:24.234679  2705 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 05:47:35.613710  2705 solver.cpp:228] Iteration 1616, loss = 0.318248
I0403 05:47:35.613819  2705 solver.cpp:244]     Train net output #0: loss = 0.318248 (* 1 = 0.318248 loss)
I0403 05:47:35.794075  2705 sgd_solver.cpp:106] Iteration 1616, lr = 0.005
I0403 05:47:41.611945  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_1625.caffemodel
I0403 05:47:44.365046  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_1625.solverstate
I0403 05:47:46.227386  2705 solver.cpp:337] Iteration 1625, Testing net (#0)
I0403 05:48:34.650598  2705 solver.cpp:404]     Test net output #0: accuracy = 0.872811
I0403 05:48:34.650950  2705 solver.cpp:404]     Test net output #1: loss = 0.388373 (* 1 = 0.388373 loss)
I0403 05:48:40.211108  2705 solver.cpp:228] Iteration 1632, loss = 0.358754
I0403 05:48:40.211205  2705 solver.cpp:244]     Train net output #0: loss = 0.358754 (* 1 = 0.358754 loss)
I0403 05:48:40.387975  2705 sgd_solver.cpp:106] Iteration 1632, lr = 0.005
I0403 05:48:51.726645  2705 solver.cpp:228] Iteration 1648, loss = 0.321937
I0403 05:48:51.726745  2705 solver.cpp:244]     Train net output #0: loss = 0.321937 (* 1 = 0.321937 loss)
I0403 05:48:51.900537  2705 sgd_solver.cpp:106] Iteration 1648, lr = 0.005
I0403 05:49:03.481194  2705 solver.cpp:228] Iteration 1664, loss = 0.316774
I0403 05:49:03.481300  2705 solver.cpp:244]     Train net output #0: loss = 0.316774 (* 1 = 0.316774 loss)
I0403 05:49:03.671447  2705 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 05:49:15.198555  2705 solver.cpp:228] Iteration 1680, loss = 0.451247
I0403 05:49:15.198859  2705 solver.cpp:244]     Train net output #0: loss = 0.451247 (* 1 = 0.451247 loss)
I0403 05:49:15.367733  2705 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 05:49:26.754652  2705 solver.cpp:228] Iteration 1696, loss = 0.371859
I0403 05:49:26.754763  2705 solver.cpp:244]     Train net output #0: loss = 0.371859 (* 1 = 0.371859 loss)
I0403 05:49:26.953812  2705 sgd_solver.cpp:106] Iteration 1696, lr = 0.005
I0403 05:49:38.396700  2705 solver.cpp:228] Iteration 1712, loss = 0.329586
I0403 05:49:38.396802  2705 solver.cpp:244]     Train net output #0: loss = 0.329586 (* 1 = 0.329586 loss)
I0403 05:49:38.575332  2705 sgd_solver.cpp:106] Iteration 1712, lr = 0.005
I0403 05:49:50.380781  2705 solver.cpp:228] Iteration 1728, loss = 0.232833
I0403 05:49:50.381068  2705 solver.cpp:244]     Train net output #0: loss = 0.232833 (* 1 = 0.232833 loss)
I0403 05:49:50.555820  2705 sgd_solver.cpp:106] Iteration 1728, lr = 0.005
I0403 05:50:01.912879  2705 solver.cpp:228] Iteration 1744, loss = 0.351731
I0403 05:50:01.912988  2705 solver.cpp:244]     Train net output #0: loss = 0.351731 (* 1 = 0.351731 loss)
I0403 05:50:02.119422  2705 sgd_solver.cpp:106] Iteration 1744, lr = 0.005
I0403 05:50:13.467957  2705 solver.cpp:228] Iteration 1760, loss = 0.32669
I0403 05:50:13.468070  2705 solver.cpp:244]     Train net output #0: loss = 0.32669 (* 1 = 0.32669 loss)
I0403 05:50:13.681241  2705 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 05:50:25.019248  2705 solver.cpp:228] Iteration 1776, loss = 0.330166
I0403 05:50:25.019567  2705 solver.cpp:244]     Train net output #0: loss = 0.330166 (* 1 = 0.330166 loss)
I0403 05:50:25.216852  2705 sgd_solver.cpp:106] Iteration 1776, lr = 0.005
I0403 05:50:36.660879  2705 solver.cpp:228] Iteration 1792, loss = 0.426831
I0403 05:50:36.660990  2705 solver.cpp:244]     Train net output #0: loss = 0.426831 (* 1 = 0.426831 loss)
I0403 05:50:36.840884  2705 sgd_solver.cpp:106] Iteration 1792, lr = 0.005
I0403 05:50:48.206383  2705 solver.cpp:228] Iteration 1808, loss = 0.332922
I0403 05:50:48.206496  2705 solver.cpp:244]     Train net output #0: loss = 0.332922 (* 1 = 0.332922 loss)
I0403 05:50:48.410789  2705 sgd_solver.cpp:106] Iteration 1808, lr = 0.005
I0403 05:50:59.798266  2705 solver.cpp:228] Iteration 1824, loss = 0.271447
I0403 05:50:59.798614  2705 solver.cpp:244]     Train net output #0: loss = 0.271447 (* 1 = 0.271447 loss)
I0403 05:50:59.994272  2705 sgd_solver.cpp:106] Iteration 1824, lr = 0.005
I0403 05:51:11.230190  2705 solver.cpp:228] Iteration 1840, loss = 0.271489
I0403 05:51:11.230291  2705 solver.cpp:244]     Train net output #0: loss = 0.271489 (* 1 = 0.271489 loss)
I0403 05:51:11.405386  2705 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 05:51:22.870928  2705 solver.cpp:228] Iteration 1856, loss = 0.468768
I0403 05:51:22.871024  2705 solver.cpp:244]     Train net output #0: loss = 0.468768 (* 1 = 0.468768 loss)
I0403 05:51:23.048005  2705 sgd_solver.cpp:106] Iteration 1856, lr = 0.005
I0403 05:51:34.407268  2705 solver.cpp:228] Iteration 1872, loss = 0.393617
I0403 05:51:34.407580  2705 solver.cpp:244]     Train net output #0: loss = 0.393617 (* 1 = 0.393617 loss)
I0403 05:51:34.592056  2705 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 05:51:45.985625  2705 solver.cpp:228] Iteration 1888, loss = 0.572374
I0403 05:51:45.985734  2705 solver.cpp:244]     Train net output #0: loss = 0.572374 (* 1 = 0.572374 loss)
I0403 05:51:46.166522  2705 sgd_solver.cpp:106] Iteration 1888, lr = 0.005
I0403 05:51:57.579524  2705 solver.cpp:228] Iteration 1904, loss = 0.549513
I0403 05:51:57.579632  2705 solver.cpp:244]     Train net output #0: loss = 0.549513 (* 1 = 0.549513 loss)
I0403 05:51:57.759620  2705 sgd_solver.cpp:106] Iteration 1904, lr = 0.005
I0403 05:52:09.238301  2705 solver.cpp:228] Iteration 1920, loss = 0.319066
I0403 05:52:09.238631  2705 solver.cpp:244]     Train net output #0: loss = 0.319066 (* 1 = 0.319066 loss)
I0403 05:52:09.461239  2705 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 05:52:20.796210  2705 solver.cpp:228] Iteration 1936, loss = 0.389502
I0403 05:52:20.796335  2705 solver.cpp:244]     Train net output #0: loss = 0.389502 (* 1 = 0.389502 loss)
I0403 05:52:21.002817  2705 sgd_solver.cpp:106] Iteration 1936, lr = 0.005
I0403 05:52:30.378301  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_1950.caffemodel
I0403 05:52:33.187996  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_1950.solverstate
I0403 05:52:35.074548  2705 solver.cpp:337] Iteration 1950, Testing net (#0)
I0403 05:53:23.505283  2705 solver.cpp:404]     Test net output #0: accuracy = 0.887788
I0403 05:53:23.505600  2705 solver.cpp:404]     Test net output #1: loss = 0.345295 (* 1 = 0.345295 loss)
I0403 05:53:25.443440  2705 solver.cpp:228] Iteration 1952, loss = 0.358465
I0403 05:53:25.443549  2705 solver.cpp:244]     Train net output #0: loss = 0.358465 (* 1 = 0.358465 loss)
I0403 05:53:25.624259  2705 sgd_solver.cpp:106] Iteration 1952, lr = 0.005
I0403 05:53:36.961709  2705 solver.cpp:228] Iteration 1968, loss = 0.320911
I0403 05:53:36.961809  2705 solver.cpp:244]     Train net output #0: loss = 0.320911 (* 1 = 0.320911 loss)
I0403 05:53:37.136503  2705 sgd_solver.cpp:106] Iteration 1968, lr = 0.005
I0403 05:53:48.508332  2705 solver.cpp:228] Iteration 1984, loss = 0.187477
I0403 05:53:48.508435  2705 solver.cpp:244]     Train net output #0: loss = 0.187477 (* 1 = 0.187477 loss)
I0403 05:53:48.676996  2705 sgd_solver.cpp:106] Iteration 1984, lr = 0.005
I0403 05:54:00.097210  2705 solver.cpp:228] Iteration 2000, loss = 0.222741
I0403 05:54:00.097548  2705 solver.cpp:244]     Train net output #0: loss = 0.222741 (* 1 = 0.222741 loss)
I0403 05:54:00.305397  2705 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 05:54:11.713083  2705 solver.cpp:228] Iteration 2016, loss = 0.26534
I0403 05:54:11.713194  2705 solver.cpp:244]     Train net output #0: loss = 0.26534 (* 1 = 0.26534 loss)
I0403 05:54:11.938885  2705 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 05:54:23.205582  2705 solver.cpp:228] Iteration 2032, loss = 0.287637
I0403 05:54:23.205679  2705 solver.cpp:244]     Train net output #0: loss = 0.287637 (* 1 = 0.287637 loss)
I0403 05:54:23.384400  2705 sgd_solver.cpp:106] Iteration 2032, lr = 0.005
I0403 05:54:34.610594  2705 solver.cpp:228] Iteration 2048, loss = 0.176134
I0403 05:54:34.610846  2705 solver.cpp:244]     Train net output #0: loss = 0.176134 (* 1 = 0.176134 loss)
I0403 05:54:34.796224  2705 sgd_solver.cpp:106] Iteration 2048, lr = 0.005
I0403 05:54:46.083226  2705 solver.cpp:228] Iteration 2064, loss = 0.200345
I0403 05:54:46.083326  2705 solver.cpp:244]     Train net output #0: loss = 0.200345 (* 1 = 0.200345 loss)
I0403 05:54:46.260902  2705 sgd_solver.cpp:106] Iteration 2064, lr = 0.005
I0403 05:54:57.637017  2705 solver.cpp:228] Iteration 2080, loss = 0.232657
I0403 05:54:57.637116  2705 solver.cpp:244]     Train net output #0: loss = 0.232657 (* 1 = 0.232657 loss)
I0403 05:54:57.785095  2705 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 05:55:09.428091  2705 solver.cpp:228] Iteration 2096, loss = 0.232282
I0403 05:55:09.428400  2705 solver.cpp:244]     Train net output #0: loss = 0.232282 (* 1 = 0.232282 loss)
I0403 05:55:09.636510  2705 sgd_solver.cpp:106] Iteration 2096, lr = 0.005
I0403 05:55:21.033644  2705 solver.cpp:228] Iteration 2112, loss = 0.304387
I0403 05:55:21.033746  2705 solver.cpp:244]     Train net output #0: loss = 0.304387 (* 1 = 0.304387 loss)
I0403 05:55:21.168551  2705 sgd_solver.cpp:106] Iteration 2112, lr = 0.005
I0403 05:55:32.541607  2705 solver.cpp:228] Iteration 2128, loss = 0.1865
I0403 05:55:32.541715  2705 solver.cpp:244]     Train net output #0: loss = 0.1865 (* 1 = 0.1865 loss)
I0403 05:55:32.745580  2705 sgd_solver.cpp:106] Iteration 2128, lr = 0.005
I0403 05:55:44.091246  2705 solver.cpp:228] Iteration 2144, loss = 0.253257
I0403 05:55:44.091569  2705 solver.cpp:244]     Train net output #0: loss = 0.253257 (* 1 = 0.253257 loss)
I0403 05:55:44.319167  2705 sgd_solver.cpp:106] Iteration 2144, lr = 0.005
I0403 05:55:55.712388  2705 solver.cpp:228] Iteration 2160, loss = 0.219131
I0403 05:55:55.712501  2705 solver.cpp:244]     Train net output #0: loss = 0.219131 (* 1 = 0.219131 loss)
I0403 05:55:55.952868  2705 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 05:56:07.198016  2705 solver.cpp:228] Iteration 2176, loss = 0.315048
I0403 05:56:07.198125  2705 solver.cpp:244]     Train net output #0: loss = 0.315048 (* 1 = 0.315048 loss)
I0403 05:56:07.433204  2705 sgd_solver.cpp:106] Iteration 2176, lr = 0.005
I0403 05:56:18.845819  2705 solver.cpp:228] Iteration 2192, loss = 0.294022
I0403 05:56:18.846109  2705 solver.cpp:244]     Train net output #0: loss = 0.294022 (* 1 = 0.294022 loss)
I0403 05:56:19.025329  2705 sgd_solver.cpp:106] Iteration 2192, lr = 0.005
I0403 05:56:30.391394  2705 solver.cpp:228] Iteration 2208, loss = 0.215318
I0403 05:56:30.391505  2705 solver.cpp:244]     Train net output #0: loss = 0.215318 (* 1 = 0.215318 loss)
I0403 05:56:30.602815  2705 sgd_solver.cpp:106] Iteration 2208, lr = 0.005
I0403 05:56:41.923321  2705 solver.cpp:228] Iteration 2224, loss = 0.285475
I0403 05:56:41.923429  2705 solver.cpp:244]     Train net output #0: loss = 0.285475 (* 1 = 0.285475 loss)
I0403 05:56:42.171228  2705 sgd_solver.cpp:106] Iteration 2224, lr = 0.005
I0403 05:56:53.855731  2705 solver.cpp:228] Iteration 2240, loss = 0.211398
I0403 05:56:53.856032  2705 solver.cpp:244]     Train net output #0: loss = 0.211398 (* 1 = 0.211398 loss)
I0403 05:56:53.983438  2705 sgd_solver.cpp:106] Iteration 2240, lr = 0.005
I0403 05:57:05.382122  2705 solver.cpp:228] Iteration 2256, loss = 0.192581
I0403 05:57:05.382231  2705 solver.cpp:244]     Train net output #0: loss = 0.192581 (* 1 = 0.192581 loss)
I0403 05:57:05.584673  2705 sgd_solver.cpp:106] Iteration 2256, lr = 0.005
I0403 05:57:17.035400  2705 solver.cpp:228] Iteration 2272, loss = 0.262405
I0403 05:57:17.035512  2705 solver.cpp:244]     Train net output #0: loss = 0.262405 (* 1 = 0.262405 loss)
I0403 05:57:17.237658  2705 sgd_solver.cpp:106] Iteration 2272, lr = 0.005
I0403 05:57:18.672966  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_2275.caffemodel
I0403 05:57:21.407086  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_2275.solverstate
I0403 05:57:23.259423  2705 solver.cpp:337] Iteration 2275, Testing net (#0)
I0403 05:58:11.691479  2705 solver.cpp:404]     Test net output #0: accuracy = 0.891521
I0403 05:58:11.691787  2705 solver.cpp:404]     Test net output #1: loss = 0.319427 (* 1 = 0.319427 loss)
I0403 05:58:21.637599  2705 solver.cpp:228] Iteration 2288, loss = 0.300212
I0403 05:58:21.637708  2705 solver.cpp:244]     Train net output #0: loss = 0.300212 (* 1 = 0.300212 loss)
I0403 05:58:21.844362  2705 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 05:58:33.292789  2705 solver.cpp:228] Iteration 2304, loss = 0.153745
I0403 05:58:33.292901  2705 solver.cpp:244]     Train net output #0: loss = 0.153745 (* 1 = 0.153745 loss)
I0403 05:58:33.475621  2705 sgd_solver.cpp:106] Iteration 2304, lr = 0.005
I0403 05:58:44.885807  2705 solver.cpp:228] Iteration 2320, loss = 0.192305
I0403 05:58:44.886114  2705 solver.cpp:244]     Train net output #0: loss = 0.192305 (* 1 = 0.192305 loss)
I0403 05:58:45.076997  2705 sgd_solver.cpp:106] Iteration 2320, lr = 0.005
I0403 05:58:56.406520  2705 solver.cpp:228] Iteration 2336, loss = 0.144625
I0403 05:58:56.406627  2705 solver.cpp:244]     Train net output #0: loss = 0.144625 (* 1 = 0.144625 loss)
I0403 05:58:56.587226  2705 sgd_solver.cpp:106] Iteration 2336, lr = 0.005
I0403 05:59:08.068599  2705 solver.cpp:228] Iteration 2352, loss = 0.346427
I0403 05:59:08.068707  2705 solver.cpp:244]     Train net output #0: loss = 0.346427 (* 1 = 0.346427 loss)
I0403 05:59:08.258824  2705 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 05:59:19.651809  2705 solver.cpp:228] Iteration 2368, loss = 0.13512
I0403 05:59:19.652112  2705 solver.cpp:244]     Train net output #0: loss = 0.13512 (* 1 = 0.13512 loss)
I0403 05:59:19.826225  2705 sgd_solver.cpp:106] Iteration 2368, lr = 0.005
I0403 05:59:31.035840  2705 solver.cpp:228] Iteration 2384, loss = 0.258145
I0403 05:59:31.035953  2705 solver.cpp:244]     Train net output #0: loss = 0.258145 (* 1 = 0.258145 loss)
I0403 05:59:31.236174  2705 sgd_solver.cpp:106] Iteration 2384, lr = 0.005
I0403 05:59:42.577553  2705 solver.cpp:228] Iteration 2400, loss = 0.321506
I0403 05:59:42.577663  2705 solver.cpp:244]     Train net output #0: loss = 0.321506 (* 1 = 0.321506 loss)
I0403 05:59:42.758932  2705 sgd_solver.cpp:106] Iteration 2400, lr = 0.005
I0403 05:59:54.443562  2705 solver.cpp:228] Iteration 2416, loss = 0.256881
I0403 05:59:54.443804  2705 solver.cpp:244]     Train net output #0: loss = 0.256881 (* 1 = 0.256881 loss)
I0403 05:59:54.622335  2705 sgd_solver.cpp:106] Iteration 2416, lr = 0.005
I0403 06:00:06.151692  2705 solver.cpp:228] Iteration 2432, loss = 0.259388
I0403 06:00:06.151803  2705 solver.cpp:244]     Train net output #0: loss = 0.259388 (* 1 = 0.259388 loss)
I0403 06:00:06.334995  2705 sgd_solver.cpp:106] Iteration 2432, lr = 0.005
I0403 06:00:17.635260  2705 solver.cpp:228] Iteration 2448, loss = 0.213689
I0403 06:00:17.635367  2705 solver.cpp:244]     Train net output #0: loss = 0.213689 (* 1 = 0.213689 loss)
I0403 06:00:17.813887  2705 sgd_solver.cpp:106] Iteration 2448, lr = 0.005
I0403 06:00:29.255389  2705 solver.cpp:228] Iteration 2464, loss = 0.253731
I0403 06:00:29.255738  2705 solver.cpp:244]     Train net output #0: loss = 0.253731 (* 1 = 0.253731 loss)
I0403 06:00:29.465463  2705 sgd_solver.cpp:106] Iteration 2464, lr = 0.005
I0403 06:00:40.924244  2705 solver.cpp:228] Iteration 2480, loss = 0.232816
I0403 06:00:40.924360  2705 solver.cpp:244]     Train net output #0: loss = 0.232816 (* 1 = 0.232816 loss)
I0403 06:00:41.105733  2705 sgd_solver.cpp:106] Iteration 2480, lr = 0.005
I0403 06:00:52.379565  2705 solver.cpp:228] Iteration 2496, loss = 0.263065
I0403 06:00:52.379676  2705 solver.cpp:244]     Train net output #0: loss = 0.263065 (* 1 = 0.263065 loss)
I0403 06:00:52.592042  2705 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 06:01:03.880132  2705 solver.cpp:228] Iteration 2512, loss = 0.21541
I0403 06:01:03.880450  2705 solver.cpp:244]     Train net output #0: loss = 0.21541 (* 1 = 0.21541 loss)
I0403 06:01:04.097761  2705 sgd_solver.cpp:106] Iteration 2512, lr = 0.005
I0403 06:01:15.623467  2705 solver.cpp:228] Iteration 2528, loss = 0.298036
I0403 06:01:15.623577  2705 solver.cpp:244]     Train net output #0: loss = 0.298036 (* 1 = 0.298036 loss)
I0403 06:01:15.819619  2705 sgd_solver.cpp:106] Iteration 2528, lr = 0.005
I0403 06:01:27.178962  2705 solver.cpp:228] Iteration 2544, loss = 0.255711
I0403 06:01:27.179059  2705 solver.cpp:244]     Train net output #0: loss = 0.255711 (* 1 = 0.255711 loss)
I0403 06:01:27.348935  2705 sgd_solver.cpp:106] Iteration 2544, lr = 0.005
I0403 06:01:38.809813  2705 solver.cpp:228] Iteration 2560, loss = 0.276387
I0403 06:01:38.810109  2705 solver.cpp:244]     Train net output #0: loss = 0.276387 (* 1 = 0.276387 loss)
I0403 06:01:38.978091  2705 sgd_solver.cpp:106] Iteration 2560, lr = 0.005
I0403 06:01:50.346459  2705 solver.cpp:228] Iteration 2576, loss = 0.231746
I0403 06:01:50.346556  2705 solver.cpp:244]     Train net output #0: loss = 0.231746 (* 1 = 0.231746 loss)
I0403 06:01:50.516681  2705 sgd_solver.cpp:106] Iteration 2576, lr = 0.005
I0403 06:02:02.035454  2705 solver.cpp:228] Iteration 2592, loss = 0.175904
I0403 06:02:02.035554  2705 solver.cpp:244]     Train net output #0: loss = 0.175904 (* 1 = 0.175904 loss)
I0403 06:02:02.186357  2705 sgd_solver.cpp:106] Iteration 2592, lr = 0.005
I0403 06:02:07.284133  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_2600.caffemodel
I0403 06:02:09.983219  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_2600.solverstate
I0403 06:02:11.773638  2705 solver.cpp:337] Iteration 2600, Testing net (#0)
I0403 06:03:00.210373  2705 solver.cpp:404]     Test net output #0: accuracy = 0.896589
I0403 06:03:00.210672  2705 solver.cpp:404]     Test net output #1: loss = 0.319395 (* 1 = 0.319395 loss)
I0403 06:03:06.650929  2705 solver.cpp:228] Iteration 2608, loss = 0.142722
I0403 06:03:06.651039  2705 solver.cpp:244]     Train net output #0: loss = 0.142722 (* 1 = 0.142722 loss)
I0403 06:03:06.835525  2705 sgd_solver.cpp:106] Iteration 2608, lr = 0.005
I0403 06:03:18.315762  2705 solver.cpp:228] Iteration 2624, loss = 0.180346
I0403 06:03:18.315873  2705 solver.cpp:244]     Train net output #0: loss = 0.180346 (* 1 = 0.180346 loss)
I0403 06:03:18.501998  2705 sgd_solver.cpp:106] Iteration 2624, lr = 0.005
I0403 06:03:30.156993  2705 solver.cpp:228] Iteration 2640, loss = 0.187118
I0403 06:03:30.157096  2705 solver.cpp:244]     Train net output #0: loss = 0.187118 (* 1 = 0.187118 loss)
I0403 06:03:30.317965  2705 sgd_solver.cpp:106] Iteration 2640, lr = 0.005
I0403 06:03:41.661397  2705 solver.cpp:228] Iteration 2656, loss = 0.292594
I0403 06:03:41.661514  2705 solver.cpp:244]     Train net output #0: loss = 0.292594 (* 1 = 0.292594 loss)
I0403 06:03:41.872889  2705 sgd_solver.cpp:106] Iteration 2656, lr = 0.005
I0403 06:03:53.238090  2705 solver.cpp:228] Iteration 2672, loss = 0.148841
I0403 06:03:53.238188  2705 solver.cpp:244]     Train net output #0: loss = 0.148841 (* 1 = 0.148841 loss)
I0403 06:03:53.417999  2705 sgd_solver.cpp:106] Iteration 2672, lr = 0.005
I0403 06:04:04.618366  2705 solver.cpp:228] Iteration 2688, loss = 0.167597
I0403 06:04:04.618679  2705 solver.cpp:244]     Train net output #0: loss = 0.167597 (* 1 = 0.167597 loss)
I0403 06:04:04.816289  2705 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 06:04:16.446123  2705 solver.cpp:228] Iteration 2704, loss = 0.270254
I0403 06:04:16.446221  2705 solver.cpp:244]     Train net output #0: loss = 0.270254 (* 1 = 0.270254 loss)
I0403 06:04:16.624971  2705 sgd_solver.cpp:106] Iteration 2704, lr = 0.005
I0403 06:04:27.968863  2705 solver.cpp:228] Iteration 2720, loss = 0.280075
I0403 06:04:27.968971  2705 solver.cpp:244]     Train net output #0: loss = 0.280075 (* 1 = 0.280075 loss)
I0403 06:04:28.162466  2705 sgd_solver.cpp:106] Iteration 2720, lr = 0.005
I0403 06:04:39.567605  2705 solver.cpp:228] Iteration 2736, loss = 0.261604
I0403 06:04:39.567857  2705 solver.cpp:244]     Train net output #0: loss = 0.261604 (* 1 = 0.261604 loss)
I0403 06:04:39.785504  2705 sgd_solver.cpp:106] Iteration 2736, lr = 0.005
I0403 06:04:51.386270  2705 solver.cpp:228] Iteration 2752, loss = 0.239443
I0403 06:04:51.386373  2705 solver.cpp:244]     Train net output #0: loss = 0.239443 (* 1 = 0.239443 loss)
I0403 06:04:51.548133  2705 sgd_solver.cpp:106] Iteration 2752, lr = 0.005
I0403 06:05:02.953259  2705 solver.cpp:228] Iteration 2768, loss = 0.219453
I0403 06:05:02.953359  2705 solver.cpp:244]     Train net output #0: loss = 0.219453 (* 1 = 0.219453 loss)
I0403 06:05:03.132485  2705 sgd_solver.cpp:106] Iteration 2768, lr = 0.005
I0403 06:05:14.447726  2705 solver.cpp:228] Iteration 2784, loss = 0.124697
I0403 06:05:14.448038  2705 solver.cpp:244]     Train net output #0: loss = 0.124697 (* 1 = 0.124697 loss)
I0403 06:05:14.652577  2705 sgd_solver.cpp:106] Iteration 2784, lr = 0.005
I0403 06:05:25.889039  2705 solver.cpp:228] Iteration 2800, loss = 0.274432
I0403 06:05:25.889149  2705 solver.cpp:244]     Train net output #0: loss = 0.274432 (* 1 = 0.274432 loss)
I0403 06:05:26.083178  2705 sgd_solver.cpp:106] Iteration 2800, lr = 0.005
I0403 06:05:37.398533  2705 solver.cpp:228] Iteration 2816, loss = 0.111756
I0403 06:05:37.398632  2705 solver.cpp:244]     Train net output #0: loss = 0.111756 (* 1 = 0.111756 loss)
I0403 06:05:37.577421  2705 sgd_solver.cpp:106] Iteration 2816, lr = 0.005
I0403 06:05:49.085976  2705 solver.cpp:228] Iteration 2832, loss = 0.351334
I0403 06:05:49.086292  2705 solver.cpp:244]     Train net output #0: loss = 0.351334 (* 1 = 0.351334 loss)
I0403 06:05:49.270992  2705 sgd_solver.cpp:106] Iteration 2832, lr = 0.005
I0403 06:06:00.887662  2705 solver.cpp:228] Iteration 2848, loss = 0.232864
I0403 06:06:00.887760  2705 solver.cpp:244]     Train net output #0: loss = 0.232864 (* 1 = 0.232864 loss)
I0403 06:06:01.055969  2705 sgd_solver.cpp:106] Iteration 2848, lr = 0.005
I0403 06:06:12.443665  2705 solver.cpp:228] Iteration 2864, loss = 0.311124
I0403 06:06:12.443766  2705 solver.cpp:244]     Train net output #0: loss = 0.311124 (* 1 = 0.311124 loss)
I0403 06:06:12.604622  2705 sgd_solver.cpp:106] Iteration 2864, lr = 0.005
I0403 06:06:23.998786  2705 solver.cpp:228] Iteration 2880, loss = 0.257362
I0403 06:06:23.999078  2705 solver.cpp:244]     Train net output #0: loss = 0.257362 (* 1 = 0.257362 loss)
I0403 06:06:24.177393  2705 sgd_solver.cpp:106] Iteration 2880, lr = 0.005
I0403 06:06:35.472192  2705 solver.cpp:228] Iteration 2896, loss = 0.110331
I0403 06:06:35.472301  2705 solver.cpp:244]     Train net output #0: loss = 0.110331 (* 1 = 0.110331 loss)
I0403 06:06:35.658594  2705 sgd_solver.cpp:106] Iteration 2896, lr = 0.005
I0403 06:06:47.085551  2705 solver.cpp:228] Iteration 2912, loss = 0.110913
I0403 06:06:47.085649  2705 solver.cpp:244]     Train net output #0: loss = 0.110913 (* 1 = 0.110913 loss)
I0403 06:06:47.258072  2705 sgd_solver.cpp:106] Iteration 2912, lr = 0.005
I0403 06:06:55.941751  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_2925.caffemodel
I0403 06:06:58.737244  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_2925.solverstate
I0403 06:07:00.555336  2705 solver.cpp:337] Iteration 2925, Testing net (#0)
I0403 06:07:48.993801  2705 solver.cpp:404]     Test net output #0: accuracy = 0.910875
I0403 06:07:48.994112  2705 solver.cpp:404]     Test net output #1: loss = 0.272456 (* 1 = 0.272456 loss)
I0403 06:07:51.682838  2705 solver.cpp:228] Iteration 2928, loss = 0.173277
I0403 06:07:51.682947  2705 solver.cpp:244]     Train net output #0: loss = 0.173277 (* 1 = 0.173277 loss)
I0403 06:07:51.865679  2705 sgd_solver.cpp:106] Iteration 2928, lr = 0.005
I0403 06:08:03.311455  2705 solver.cpp:228] Iteration 2944, loss = 0.131568
I0403 06:08:03.311550  2705 solver.cpp:244]     Train net output #0: loss = 0.131568 (* 1 = 0.131568 loss)
I0403 06:08:03.486194  2705 sgd_solver.cpp:106] Iteration 2944, lr = 0.005
I0403 06:08:14.991212  2705 solver.cpp:228] Iteration 2960, loss = 0.0841346
I0403 06:08:14.991310  2705 solver.cpp:244]     Train net output #0: loss = 0.0841346 (* 1 = 0.0841346 loss)
I0403 06:08:15.159453  2705 sgd_solver.cpp:106] Iteration 2960, lr = 0.005
I0403 06:08:26.553094  2705 solver.cpp:228] Iteration 2976, loss = 0.307712
I0403 06:08:26.553416  2705 solver.cpp:244]     Train net output #0: loss = 0.307712 (* 1 = 0.307712 loss)
I0403 06:08:26.731910  2705 sgd_solver.cpp:106] Iteration 2976, lr = 0.005
I0403 06:08:38.154827  2705 solver.cpp:228] Iteration 2992, loss = 0.156499
I0403 06:08:38.154939  2705 solver.cpp:244]     Train net output #0: loss = 0.156499 (* 1 = 0.156499 loss)
I0403 06:08:38.358280  2705 sgd_solver.cpp:106] Iteration 2992, lr = 0.005
I0403 06:08:50.202669  2705 solver.cpp:228] Iteration 3008, loss = 0.214541
I0403 06:08:50.202787  2705 solver.cpp:244]     Train net output #0: loss = 0.214541 (* 1 = 0.214541 loss)
I0403 06:08:50.386191  2705 sgd_solver.cpp:106] Iteration 3008, lr = 0.005
I0403 06:09:01.849251  2705 solver.cpp:228] Iteration 3024, loss = 0.266374
I0403 06:09:01.849556  2705 solver.cpp:244]     Train net output #0: loss = 0.266374 (* 1 = 0.266374 loss)
I0403 06:09:01.977449  2705 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 06:09:13.627846  2705 solver.cpp:228] Iteration 3040, loss = 0.224086
I0403 06:09:13.627956  2705 solver.cpp:244]     Train net output #0: loss = 0.224086 (* 1 = 0.224086 loss)
I0403 06:09:13.827493  2705 sgd_solver.cpp:106] Iteration 3040, lr = 0.005
I0403 06:09:25.265509  2705 solver.cpp:228] Iteration 3056, loss = 0.173001
I0403 06:09:25.265619  2705 solver.cpp:244]     Train net output #0: loss = 0.173001 (* 1 = 0.173001 loss)
I0403 06:09:25.445754  2705 sgd_solver.cpp:106] Iteration 3056, lr = 0.005
I0403 06:09:36.693294  2705 solver.cpp:228] Iteration 3072, loss = 0.11328
I0403 06:09:36.693609  2705 solver.cpp:244]     Train net output #0: loss = 0.11328 (* 1 = 0.11328 loss)
I0403 06:09:36.932847  2705 sgd_solver.cpp:106] Iteration 3072, lr = 0.005
I0403 06:09:48.378537  2705 solver.cpp:228] Iteration 3088, loss = 0.257718
I0403 06:09:48.378634  2705 solver.cpp:244]     Train net output #0: loss = 0.257718 (* 1 = 0.257718 loss)
I0403 06:09:48.545194  2705 sgd_solver.cpp:106] Iteration 3088, lr = 0.005
I0403 06:10:00.014581  2705 solver.cpp:228] Iteration 3104, loss = 0.181087
I0403 06:10:00.014678  2705 solver.cpp:244]     Train net output #0: loss = 0.181087 (* 1 = 0.181087 loss)
I0403 06:10:00.187649  2705 sgd_solver.cpp:106] Iteration 3104, lr = 0.005
I0403 06:10:11.709064  2705 solver.cpp:228] Iteration 3120, loss = 0.2475
I0403 06:10:11.709401  2705 solver.cpp:244]     Train net output #0: loss = 0.2475 (* 1 = 0.2475 loss)
I0403 06:10:11.873744  2705 sgd_solver.cpp:106] Iteration 3120, lr = 0.005
I0403 06:10:23.433323  2705 solver.cpp:228] Iteration 3136, loss = 0.186001
I0403 06:10:23.433430  2705 solver.cpp:244]     Train net output #0: loss = 0.186001 (* 1 = 0.186001 loss)
I0403 06:10:23.583716  2705 sgd_solver.cpp:106] Iteration 3136, lr = 0.005
I0403 06:10:35.236147  2705 solver.cpp:228] Iteration 3152, loss = 0.269102
I0403 06:10:35.236258  2705 solver.cpp:244]     Train net output #0: loss = 0.269102 (* 1 = 0.269102 loss)
I0403 06:10:35.456300  2705 sgd_solver.cpp:106] Iteration 3152, lr = 0.005
I0403 06:10:46.805280  2705 solver.cpp:228] Iteration 3168, loss = 0.213487
I0403 06:10:46.805603  2705 solver.cpp:244]     Train net output #0: loss = 0.213487 (* 1 = 0.213487 loss)
I0403 06:10:47.032255  2705 sgd_solver.cpp:106] Iteration 3168, lr = 0.005
I0403 06:10:58.694560  2705 solver.cpp:228] Iteration 3184, loss = 0.239912
I0403 06:10:58.694671  2705 solver.cpp:244]     Train net output #0: loss = 0.239912 (* 1 = 0.239912 loss)
I0403 06:10:58.924685  2705 sgd_solver.cpp:106] Iteration 3184, lr = 0.005
I0403 06:11:10.587591  2705 solver.cpp:228] Iteration 3200, loss = 0.124177
I0403 06:11:10.587702  2705 solver.cpp:244]     Train net output #0: loss = 0.124177 (* 1 = 0.124177 loss)
I0403 06:11:10.772094  2705 sgd_solver.cpp:106] Iteration 3200, lr = 0.005
I0403 06:11:22.155747  2705 solver.cpp:228] Iteration 3216, loss = 0.126715
I0403 06:11:22.156008  2705 solver.cpp:244]     Train net output #0: loss = 0.126715 (* 1 = 0.126715 loss)
I0403 06:11:22.371206  2705 sgd_solver.cpp:106] Iteration 3216, lr = 0.005
I0403 06:11:33.986189  2705 solver.cpp:228] Iteration 3232, loss = 0.216358
I0403 06:11:33.986287  2705 solver.cpp:244]     Train net output #0: loss = 0.216358 (* 1 = 0.216358 loss)
I0403 06:11:34.142379  2705 sgd_solver.cpp:106] Iteration 3232, lr = 0.005
I0403 06:11:45.656754  2705 solver.cpp:228] Iteration 3248, loss = 0.170356
I0403 06:11:45.662207  2705 solver.cpp:244]     Train net output #0: loss = 0.170356 (* 1 = 0.170356 loss)
I0403 06:11:45.874267  2705 sgd_solver.cpp:106] Iteration 3248, lr = 0.005
I0403 06:11:46.595264  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_3250.caffemodel
I0403 06:11:49.385669  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_3250.solverstate
I0403 06:11:51.304222  2705 solver.cpp:337] Iteration 3250, Testing net (#0)
I0403 06:12:39.734289  2705 solver.cpp:404]     Test net output #0: accuracy = 0.908525
I0403 06:12:39.734599  2705 solver.cpp:404]     Test net output #1: loss = 0.290615 (* 1 = 0.290615 loss)
I0403 06:12:50.265962  2705 solver.cpp:228] Iteration 3264, loss = 0.170981
I0403 06:12:50.266069  2705 solver.cpp:244]     Train net output #0: loss = 0.170981 (* 1 = 0.170981 loss)
I0403 06:12:50.447919  2705 sgd_solver.cpp:106] Iteration 3264, lr = 0.0005
I0403 06:13:01.851773  2705 solver.cpp:228] Iteration 3280, loss = 0.115256
I0403 06:13:01.851888  2705 solver.cpp:244]     Train net output #0: loss = 0.115256 (* 1 = 0.115256 loss)
I0403 06:13:02.036640  2705 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 06:13:13.328819  2705 solver.cpp:228] Iteration 3296, loss = 0.0799674
I0403 06:13:13.329119  2705 solver.cpp:244]     Train net output #0: loss = 0.0799674 (* 1 = 0.0799674 loss)
I0403 06:13:13.506691  2705 sgd_solver.cpp:106] Iteration 3296, lr = 0.0005
I0403 06:13:24.935472  2705 solver.cpp:228] Iteration 3312, loss = 0.127196
I0403 06:13:24.935585  2705 solver.cpp:244]     Train net output #0: loss = 0.127196 (* 1 = 0.127196 loss)
I0403 06:13:25.161808  2705 sgd_solver.cpp:106] Iteration 3312, lr = 0.0005
I0403 06:13:36.538019  2705 solver.cpp:228] Iteration 3328, loss = 0.0901967
I0403 06:13:36.538123  2705 solver.cpp:244]     Train net output #0: loss = 0.0901967 (* 1 = 0.0901967 loss)
I0403 06:13:36.718053  2705 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 06:13:48.077594  2705 solver.cpp:228] Iteration 3344, loss = 0.118887
I0403 06:13:48.077926  2705 solver.cpp:244]     Train net output #0: loss = 0.118887 (* 1 = 0.118887 loss)
I0403 06:13:48.301141  2705 sgd_solver.cpp:106] Iteration 3344, lr = 0.0005
I0403 06:13:59.557600  2705 solver.cpp:228] Iteration 3360, loss = 0.0684206
I0403 06:13:59.557705  2705 solver.cpp:244]     Train net output #0: loss = 0.0684206 (* 1 = 0.0684206 loss)
I0403 06:13:59.754573  2705 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 06:14:11.025533  2705 solver.cpp:228] Iteration 3376, loss = 0.124493
I0403 06:14:11.025642  2705 solver.cpp:244]     Train net output #0: loss = 0.124493 (* 1 = 0.124493 loss)
I0403 06:14:11.249075  2705 sgd_solver.cpp:106] Iteration 3376, lr = 0.0005
I0403 06:14:22.878855  2705 solver.cpp:228] Iteration 3392, loss = 0.0751987
I0403 06:14:22.879159  2705 solver.cpp:244]     Train net output #0: loss = 0.0751987 (* 1 = 0.0751987 loss)
I0403 06:14:23.061822  2705 sgd_solver.cpp:106] Iteration 3392, lr = 0.0005
I0403 06:14:34.461452  2705 solver.cpp:228] Iteration 3408, loss = 0.102816
I0403 06:14:34.461565  2705 solver.cpp:244]     Train net output #0: loss = 0.102816 (* 1 = 0.102816 loss)
I0403 06:14:34.696797  2705 sgd_solver.cpp:106] Iteration 3408, lr = 0.0005
I0403 06:14:46.236357  2705 solver.cpp:228] Iteration 3424, loss = 0.139593
I0403 06:14:46.236454  2705 solver.cpp:244]     Train net output #0: loss = 0.139593 (* 1 = 0.139593 loss)
I0403 06:14:46.413764  2705 sgd_solver.cpp:106] Iteration 3424, lr = 0.0005
I0403 06:14:57.844863  2705 solver.cpp:228] Iteration 3440, loss = 0.141184
I0403 06:14:57.845176  2705 solver.cpp:244]     Train net output #0: loss = 0.141184 (* 1 = 0.141184 loss)
I0403 06:14:58.025941  2705 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 06:15:09.322897  2705 solver.cpp:228] Iteration 3456, loss = 0.0644002
I0403 06:15:09.323014  2705 solver.cpp:244]     Train net output #0: loss = 0.0644002 (* 1 = 0.0644002 loss)
I0403 06:15:09.516532  2705 sgd_solver.cpp:106] Iteration 3456, lr = 0.0005
I0403 06:15:21.256499  2705 solver.cpp:228] Iteration 3472, loss = 0.198279
I0403 06:15:21.256598  2705 solver.cpp:244]     Train net output #0: loss = 0.198279 (* 1 = 0.198279 loss)
I0403 06:15:21.413813  2705 sgd_solver.cpp:106] Iteration 3472, lr = 0.0005
I0403 06:15:32.843055  2705 solver.cpp:228] Iteration 3488, loss = 0.103501
I0403 06:15:32.843338  2705 solver.cpp:244]     Train net output #0: loss = 0.103501 (* 1 = 0.103501 loss)
I0403 06:15:33.021921  2705 sgd_solver.cpp:106] Iteration 3488, lr = 0.0005
I0403 06:15:44.397100  2705 solver.cpp:228] Iteration 3504, loss = 0.0365561
I0403 06:15:44.397215  2705 solver.cpp:244]     Train net output #0: loss = 0.0365561 (* 1 = 0.0365561 loss)
I0403 06:15:44.587558  2705 sgd_solver.cpp:106] Iteration 3504, lr = 0.0005
I0403 06:15:55.907536  2705 solver.cpp:228] Iteration 3520, loss = 0.0631866
I0403 06:15:55.907647  2705 solver.cpp:244]     Train net output #0: loss = 0.0631866 (* 1 = 0.0631866 loss)
I0403 06:15:56.092084  2705 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 06:16:07.437000  2705 solver.cpp:228] Iteration 3536, loss = 0.0337635
I0403 06:16:07.437312  2705 solver.cpp:244]     Train net output #0: loss = 0.0337635 (* 1 = 0.0337635 loss)
I0403 06:16:07.637065  2705 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 06:16:19.092389  2705 solver.cpp:228] Iteration 3552, loss = 0.14264
I0403 06:16:19.092489  2705 solver.cpp:244]     Train net output #0: loss = 0.14264 (* 1 = 0.14264 loss)
I0403 06:16:19.262508  2705 sgd_solver.cpp:106] Iteration 3552, lr = 0.0005
I0403 06:16:30.779978  2705 solver.cpp:228] Iteration 3568, loss = 0.0540369
I0403 06:16:30.780089  2705 solver.cpp:244]     Train net output #0: loss = 0.0540368 (* 1 = 0.0540368 loss)
I0403 06:16:30.962019  2705 sgd_solver.cpp:106] Iteration 3568, lr = 0.0005
I0403 06:16:35.395726  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_3575.caffemodel
I0403 06:16:38.172186  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_3575.solverstate
I0403 06:16:40.041813  2705 solver.cpp:337] Iteration 3575, Testing net (#0)
I0403 06:17:28.463579  2705 solver.cpp:404]     Test net output #0: accuracy = 0.931981
I0403 06:17:28.463899  2705 solver.cpp:404]     Test net output #1: loss = 0.216342 (* 1 = 0.216342 loss)
I0403 06:17:35.558215  2705 solver.cpp:228] Iteration 3584, loss = 0.0464171
I0403 06:17:35.558328  2705 solver.cpp:244]     Train net output #0: loss = 0.046417 (* 1 = 0.046417 loss)
I0403 06:17:35.756947  2705 sgd_solver.cpp:106] Iteration 3584, lr = 0.0005
I0403 06:17:47.106834  2705 solver.cpp:228] Iteration 3600, loss = 0.110184
I0403 06:17:47.106969  2705 solver.cpp:244]     Train net output #0: loss = 0.110184 (* 1 = 0.110184 loss)
I0403 06:17:47.296690  2705 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 06:17:58.820130  2705 solver.cpp:228] Iteration 3616, loss = 0.0671531
I0403 06:17:58.820420  2705 solver.cpp:244]     Train net output #0: loss = 0.0671531 (* 1 = 0.0671531 loss)
I0403 06:17:59.001142  2705 sgd_solver.cpp:106] Iteration 3616, lr = 0.0005
I0403 06:18:10.368700  2705 solver.cpp:228] Iteration 3632, loss = 0.0633616
I0403 06:18:10.368798  2705 solver.cpp:244]     Train net output #0: loss = 0.0633616 (* 1 = 0.0633616 loss)
I0403 06:18:10.517246  2705 sgd_solver.cpp:106] Iteration 3632, lr = 0.0005
I0403 06:18:22.213265  2705 solver.cpp:228] Iteration 3648, loss = 0.0904694
I0403 06:18:22.213387  2705 solver.cpp:244]     Train net output #0: loss = 0.0904693 (* 1 = 0.0904693 loss)
I0403 06:18:22.339049  2705 sgd_solver.cpp:106] Iteration 3648, lr = 0.0005
I0403 06:18:33.875247  2705 solver.cpp:228] Iteration 3664, loss = 0.064673
I0403 06:18:33.875557  2705 solver.cpp:244]     Train net output #0: loss = 0.064673 (* 1 = 0.064673 loss)
I0403 06:18:34.034215  2705 sgd_solver.cpp:106] Iteration 3664, lr = 0.0005
I0403 06:18:45.363175  2705 solver.cpp:228] Iteration 3680, loss = 0.0551359
I0403 06:18:45.363284  2705 solver.cpp:244]     Train net output #0: loss = 0.0551359 (* 1 = 0.0551359 loss)
I0403 06:18:45.582870  2705 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 06:18:56.871002  2705 solver.cpp:228] Iteration 3696, loss = 0.0737051
I0403 06:18:56.871115  2705 solver.cpp:244]     Train net output #0: loss = 0.073705 (* 1 = 0.073705 loss)
I0403 06:18:57.055251  2705 sgd_solver.cpp:106] Iteration 3696, lr = 0.0005
I0403 06:19:08.584542  2705 solver.cpp:228] Iteration 3712, loss = 0.0441809
I0403 06:19:08.589246  2705 solver.cpp:244]     Train net output #0: loss = 0.0441808 (* 1 = 0.0441808 loss)
I0403 06:19:08.731957  2705 sgd_solver.cpp:106] Iteration 3712, lr = 0.0005
I0403 06:19:20.278225  2705 solver.cpp:228] Iteration 3728, loss = 0.101438
I0403 06:19:20.278344  2705 solver.cpp:244]     Train net output #0: loss = 0.101438 (* 1 = 0.101438 loss)
I0403 06:19:20.491703  2705 sgd_solver.cpp:106] Iteration 3728, lr = 0.0005
I0403 06:19:32.037526  2705 solver.cpp:228] Iteration 3744, loss = 0.0637501
I0403 06:19:32.037652  2705 solver.cpp:244]     Train net output #0: loss = 0.0637501 (* 1 = 0.0637501 loss)
I0403 06:19:32.242197  2705 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 06:19:43.557935  2705 solver.cpp:228] Iteration 3760, loss = 0.0885126
I0403 06:19:43.558246  2705 solver.cpp:244]     Train net output #0: loss = 0.0885125 (* 1 = 0.0885125 loss)
I0403 06:19:43.745462  2705 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 06:19:55.016181  2705 solver.cpp:228] Iteration 3776, loss = 0.0685633
I0403 06:19:55.016290  2705 solver.cpp:244]     Train net output #0: loss = 0.0685633 (* 1 = 0.0685633 loss)
I0403 06:19:55.214126  2705 sgd_solver.cpp:106] Iteration 3776, lr = 0.0005
I0403 06:20:06.611179  2705 solver.cpp:228] Iteration 3792, loss = 0.0278776
I0403 06:20:06.611290  2705 solver.cpp:244]     Train net output #0: loss = 0.0278776 (* 1 = 0.0278776 loss)
I0403 06:20:06.854540  2705 sgd_solver.cpp:106] Iteration 3792, lr = 0.0005
I0403 06:20:18.545584  2705 solver.cpp:228] Iteration 3808, loss = 0.0605469
I0403 06:20:18.545918  2705 solver.cpp:244]     Train net output #0: loss = 0.0605468 (* 1 = 0.0605468 loss)
I0403 06:20:18.725371  2705 sgd_solver.cpp:106] Iteration 3808, lr = 0.0005
I0403 06:20:30.166983  2705 solver.cpp:228] Iteration 3824, loss = 0.116373
I0403 06:20:30.167079  2705 solver.cpp:244]     Train net output #0: loss = 0.116373 (* 1 = 0.116373 loss)
I0403 06:20:30.346305  2705 sgd_solver.cpp:106] Iteration 3824, lr = 0.0005
I0403 06:20:41.689960  2705 solver.cpp:228] Iteration 3840, loss = 0.0923237
I0403 06:20:41.690070  2705 solver.cpp:244]     Train net output #0: loss = 0.0923237 (* 1 = 0.0923237 loss)
I0403 06:20:41.881736  2705 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 06:20:53.366518  2705 solver.cpp:228] Iteration 3856, loss = 0.018413
I0403 06:20:53.366839  2705 solver.cpp:244]     Train net output #0: loss = 0.018413 (* 1 = 0.018413 loss)
I0403 06:20:53.555819  2705 sgd_solver.cpp:106] Iteration 3856, lr = 0.0005
I0403 06:21:04.881026  2705 solver.cpp:228] Iteration 3872, loss = 0.0634096
I0403 06:21:04.881137  2705 solver.cpp:244]     Train net output #0: loss = 0.0634096 (* 1 = 0.0634096 loss)
I0403 06:21:05.062680  2705 sgd_solver.cpp:106] Iteration 3872, lr = 0.0005
I0403 06:21:16.476532  2705 solver.cpp:228] Iteration 3888, loss = 0.0671747
I0403 06:21:16.476631  2705 solver.cpp:244]     Train net output #0: loss = 0.0671747 (* 1 = 0.0671747 loss)
I0403 06:21:16.653878  2705 sgd_solver.cpp:106] Iteration 3888, lr = 0.0005
I0403 06:21:24.519676  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_3900.caffemodel
I0403 06:21:27.359920  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_3900.solverstate
I0403 06:21:29.643465  2705 solver.cpp:337] Iteration 3900, Testing net (#0)
I0403 06:22:18.091408  2705 solver.cpp:404]     Test net output #0: accuracy = 0.934332
I0403 06:22:18.091717  2705 solver.cpp:404]     Test net output #1: loss = 0.212698 (* 1 = 0.212698 loss)
I0403 06:22:21.638434  2705 solver.cpp:228] Iteration 3904, loss = 0.0618821
I0403 06:22:21.638543  2705 solver.cpp:244]     Train net output #0: loss = 0.0618821 (* 1 = 0.0618821 loss)
I0403 06:22:21.825726  2705 sgd_solver.cpp:106] Iteration 3904, lr = 0.0005
I0403 06:22:33.156925  2705 solver.cpp:228] Iteration 3920, loss = 0.0779117
I0403 06:22:33.157022  2705 solver.cpp:244]     Train net output #0: loss = 0.0779117 (* 1 = 0.0779117 loss)
I0403 06:22:33.318421  2705 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 06:22:44.793114  2705 solver.cpp:228] Iteration 3936, loss = 0.180781
I0403 06:22:44.793223  2705 solver.cpp:244]     Train net output #0: loss = 0.180781 (* 1 = 0.180781 loss)
I0403 06:22:44.974346  2705 sgd_solver.cpp:106] Iteration 3936, lr = 0.0005
I0403 06:22:56.423658  2705 solver.cpp:228] Iteration 3952, loss = 0.0325788
I0403 06:22:56.423948  2705 solver.cpp:244]     Train net output #0: loss = 0.0325788 (* 1 = 0.0325788 loss)
I0403 06:22:56.582692  2705 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 06:23:08.197286  2705 solver.cpp:228] Iteration 3968, loss = 0.0129626
I0403 06:23:08.197389  2705 solver.cpp:244]     Train net output #0: loss = 0.0129626 (* 1 = 0.0129626 loss)
I0403 06:23:08.368474  2705 sgd_solver.cpp:106] Iteration 3968, lr = 0.0005
I0403 06:23:19.773458  2705 solver.cpp:228] Iteration 3984, loss = 0.0505662
I0403 06:23:19.773571  2705 solver.cpp:244]     Train net output #0: loss = 0.0505662 (* 1 = 0.0505662 loss)
I0403 06:23:19.985234  2705 sgd_solver.cpp:106] Iteration 3984, lr = 0.0005
I0403 06:23:31.386631  2705 solver.cpp:228] Iteration 4000, loss = 0.0684703
I0403 06:23:31.386937  2705 solver.cpp:244]     Train net output #0: loss = 0.0684703 (* 1 = 0.0684703 loss)
I0403 06:23:31.556949  2705 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 06:23:43.026355  2705 solver.cpp:228] Iteration 4016, loss = 0.070536
I0403 06:23:43.026454  2705 solver.cpp:244]     Train net output #0: loss = 0.070536 (* 1 = 0.070536 loss)
I0403 06:23:43.204099  2705 sgd_solver.cpp:106] Iteration 4016, lr = 0.0005
I0403 06:23:54.586688  2705 solver.cpp:228] Iteration 4032, loss = 0.062511
I0403 06:23:54.586801  2705 solver.cpp:244]     Train net output #0: loss = 0.062511 (* 1 = 0.062511 loss)
I0403 06:23:54.775547  2705 sgd_solver.cpp:106] Iteration 4032, lr = 0.0005
I0403 06:24:06.100711  2705 solver.cpp:228] Iteration 4048, loss = 0.0267119
I0403 06:24:06.101008  2705 solver.cpp:244]     Train net output #0: loss = 0.0267119 (* 1 = 0.0267119 loss)
I0403 06:24:06.278306  2705 sgd_solver.cpp:106] Iteration 4048, lr = 0.0005
I0403 06:24:17.620324  2705 solver.cpp:228] Iteration 4064, loss = 0.0317754
I0403 06:24:17.620434  2705 solver.cpp:244]     Train net output #0: loss = 0.0317754 (* 1 = 0.0317754 loss)
I0403 06:24:17.816584  2705 sgd_solver.cpp:106] Iteration 4064, lr = 0.0005
I0403 06:24:29.420465  2705 solver.cpp:228] Iteration 4080, loss = 0.126145
I0403 06:24:29.420562  2705 solver.cpp:244]     Train net output #0: loss = 0.126145 (* 1 = 0.126145 loss)
I0403 06:24:29.592567  2705 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 06:24:40.939647  2705 solver.cpp:228] Iteration 4096, loss = 0.0691231
I0403 06:24:40.939927  2705 solver.cpp:244]     Train net output #0: loss = 0.0691231 (* 1 = 0.0691231 loss)
I0403 06:24:41.117362  2705 sgd_solver.cpp:106] Iteration 4096, lr = 0.0005
I0403 06:24:52.615670  2705 solver.cpp:228] Iteration 4112, loss = 0.0434217
I0403 06:24:52.615768  2705 solver.cpp:244]     Train net output #0: loss = 0.0434217 (* 1 = 0.0434217 loss)
I0403 06:24:52.793030  2705 sgd_solver.cpp:106] Iteration 4112, lr = 0.0005
I0403 06:25:04.341517  2705 solver.cpp:228] Iteration 4128, loss = 0.0960879
I0403 06:25:04.341625  2705 solver.cpp:244]     Train net output #0: loss = 0.0960879 (* 1 = 0.0960879 loss)
I0403 06:25:04.535533  2705 sgd_solver.cpp:106] Iteration 4128, lr = 0.0005
I0403 06:25:15.939230  2705 solver.cpp:228] Iteration 4144, loss = 0.0894082
I0403 06:25:15.939615  2705 solver.cpp:244]     Train net output #0: loss = 0.0894082 (* 1 = 0.0894082 loss)
I0403 06:25:16.106894  2705 sgd_solver.cpp:106] Iteration 4144, lr = 0.0005
I0403 06:25:27.535879  2705 solver.cpp:228] Iteration 4160, loss = 0.138891
I0403 06:25:27.535987  2705 solver.cpp:244]     Train net output #0: loss = 0.138891 (* 1 = 0.138891 loss)
I0403 06:25:27.738360  2705 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 06:25:39.139581  2705 solver.cpp:228] Iteration 4176, loss = 0.0485324
I0403 06:25:39.139700  2705 solver.cpp:244]     Train net output #0: loss = 0.0485324 (* 1 = 0.0485324 loss)
I0403 06:25:39.327810  2705 sgd_solver.cpp:106] Iteration 4176, lr = 0.0005
I0403 06:25:50.594313  2705 solver.cpp:228] Iteration 4192, loss = 0.114315
I0403 06:25:50.594624  2705 solver.cpp:244]     Train net output #0: loss = 0.114315 (* 1 = 0.114315 loss)
I0403 06:25:50.773176  2705 sgd_solver.cpp:106] Iteration 4192, lr = 0.0005
I0403 06:26:02.296622  2705 solver.cpp:228] Iteration 4208, loss = 0.0837977
I0403 06:26:02.296720  2705 solver.cpp:244]     Train net output #0: loss = 0.0837977 (* 1 = 0.0837977 loss)
I0403 06:26:02.466436  2705 sgd_solver.cpp:106] Iteration 4208, lr = 0.0005
I0403 06:26:13.922777  2705 solver.cpp:228] Iteration 4224, loss = 0.0189978
I0403 06:26:13.922883  2705 solver.cpp:244]     Train net output #0: loss = 0.0189978 (* 1 = 0.0189978 loss)
I0403 06:26:14.097607  2705 sgd_solver.cpp:106] Iteration 4224, lr = 0.0005
I0403 06:26:14.097843  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_4225.caffemodel
I0403 06:26:16.866727  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_4225.solverstate
I0403 06:26:18.793222  2705 solver.cpp:337] Iteration 4225, Testing net (#0)
I0403 06:27:07.227418  2705 solver.cpp:404]     Test net output #0: accuracy = 0.93659
I0403 06:27:07.231652  2705 solver.cpp:404]     Test net output #1: loss = 0.212461 (* 1 = 0.212461 loss)
I0403 06:27:18.523083  2705 solver.cpp:228] Iteration 4240, loss = 0.0279798
I0403 06:27:18.523195  2705 solver.cpp:244]     Train net output #0: loss = 0.0279798 (* 1 = 0.0279798 loss)
I0403 06:27:18.789330  2705 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 06:27:30.410241  2705 solver.cpp:228] Iteration 4256, loss = 0.0275558
I0403 06:27:30.410356  2705 solver.cpp:244]     Train net output #0: loss = 0.0275559 (* 1 = 0.0275559 loss)
I0403 06:27:30.611263  2705 sgd_solver.cpp:106] Iteration 4256, lr = 0.0005
I0403 06:27:41.906566  2705 solver.cpp:228] Iteration 4272, loss = 0.0344629
I0403 06:27:41.906868  2705 solver.cpp:244]     Train net output #0: loss = 0.0344629 (* 1 = 0.0344629 loss)
I0403 06:27:42.037333  2705 sgd_solver.cpp:106] Iteration 4272, lr = 0.0005
I0403 06:27:53.504878  2705 solver.cpp:228] Iteration 4288, loss = 0.0478512
I0403 06:27:53.504973  2705 solver.cpp:244]     Train net output #0: loss = 0.0478513 (* 1 = 0.0478513 loss)
I0403 06:27:53.658339  2705 sgd_solver.cpp:106] Iteration 4288, lr = 0.0005
I0403 06:28:05.007974  2705 solver.cpp:228] Iteration 4304, loss = 0.101767
I0403 06:28:05.008072  2705 solver.cpp:244]     Train net output #0: loss = 0.101767 (* 1 = 0.101767 loss)
I0403 06:28:05.186936  2705 sgd_solver.cpp:106] Iteration 4304, lr = 0.0005
I0403 06:28:16.597607  2705 solver.cpp:228] Iteration 4320, loss = 0.036245
I0403 06:28:16.597890  2705 solver.cpp:244]     Train net output #0: loss = 0.0362451 (* 1 = 0.0362451 loss)
I0403 06:28:16.785447  2705 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 06:28:28.153591  2705 solver.cpp:228] Iteration 4336, loss = 0.050489
I0403 06:28:28.153690  2705 solver.cpp:244]     Train net output #0: loss = 0.050489 (* 1 = 0.050489 loss)
I0403 06:28:28.244391  2705 sgd_solver.cpp:106] Iteration 4336, lr = 0.0005
I0403 06:28:39.851022  2705 solver.cpp:228] Iteration 4352, loss = 0.0820271
I0403 06:28:39.851130  2705 solver.cpp:244]     Train net output #0: loss = 0.0820272 (* 1 = 0.0820272 loss)
I0403 06:28:40.055737  2705 sgd_solver.cpp:106] Iteration 4352, lr = 0.0005
I0403 06:28:51.457641  2705 solver.cpp:228] Iteration 4368, loss = 0.0788424
I0403 06:28:51.457962  2705 solver.cpp:244]     Train net output #0: loss = 0.0788424 (* 1 = 0.0788424 loss)
I0403 06:28:51.657295  2705 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 06:29:02.999950  2705 solver.cpp:228] Iteration 4384, loss = 0.0293801
I0403 06:29:03.000061  2705 solver.cpp:244]     Train net output #0: loss = 0.0293801 (* 1 = 0.0293801 loss)
I0403 06:29:03.181043  2705 sgd_solver.cpp:106] Iteration 4384, lr = 0.0005
I0403 06:29:14.550879  2705 solver.cpp:228] Iteration 4400, loss = 0.052715
I0403 06:29:14.550977  2705 solver.cpp:244]     Train net output #0: loss = 0.0527151 (* 1 = 0.0527151 loss)
I0403 06:29:14.727764  2705 sgd_solver.cpp:106] Iteration 4400, lr = 0.0005
I0403 06:29:25.969550  2705 solver.cpp:228] Iteration 4416, loss = 0.0822564
I0403 06:29:25.969828  2705 solver.cpp:244]     Train net output #0: loss = 0.0822565 (* 1 = 0.0822565 loss)
I0403 06:29:26.157722  2705 sgd_solver.cpp:106] Iteration 4416, lr = 0.0005
I0403 06:29:37.446341  2705 solver.cpp:228] Iteration 4432, loss = 0.0553139
I0403 06:29:37.446458  2705 solver.cpp:244]     Train net output #0: loss = 0.0553139 (* 1 = 0.0553139 loss)
I0403 06:29:37.639444  2705 sgd_solver.cpp:106] Iteration 4432, lr = 0.0005
I0403 06:29:49.019850  2705 solver.cpp:228] Iteration 4448, loss = 0.132191
I0403 06:29:49.019960  2705 solver.cpp:244]     Train net output #0: loss = 0.132191 (* 1 = 0.132191 loss)
I0403 06:29:49.215431  2705 sgd_solver.cpp:106] Iteration 4448, lr = 0.0005
I0403 06:30:00.728505  2705 solver.cpp:228] Iteration 4464, loss = 0.0405676
I0403 06:30:00.728847  2705 solver.cpp:244]     Train net output #0: loss = 0.0405677 (* 1 = 0.0405677 loss)
I0403 06:30:00.927291  2705 sgd_solver.cpp:106] Iteration 4464, lr = 0.0005
I0403 06:30:12.451745  2705 solver.cpp:228] Iteration 4480, loss = 0.0700148
I0403 06:30:12.451863  2705 solver.cpp:244]     Train net output #0: loss = 0.0700149 (* 1 = 0.0700149 loss)
I0403 06:30:12.661710  2705 sgd_solver.cpp:106] Iteration 4480, lr = 0.0005
I0403 06:30:23.937636  2705 solver.cpp:228] Iteration 4496, loss = 0.0139365
I0403 06:30:23.937750  2705 solver.cpp:244]     Train net output #0: loss = 0.0139366 (* 1 = 0.0139366 loss)
I0403 06:30:24.157323  2705 sgd_solver.cpp:106] Iteration 4496, lr = 0.0005
I0403 06:30:35.430037  2705 solver.cpp:228] Iteration 4512, loss = 0.0609871
I0403 06:30:35.430332  2705 solver.cpp:244]     Train net output #0: loss = 0.0609872 (* 1 = 0.0609872 loss)
I0403 06:30:35.615399  2705 sgd_solver.cpp:106] Iteration 4512, lr = 0.0005
I0403 06:30:47.227290  2705 solver.cpp:228] Iteration 4528, loss = 0.0635278
I0403 06:30:47.227397  2705 solver.cpp:244]     Train net output #0: loss = 0.0635278 (* 1 = 0.0635278 loss)
I0403 06:30:47.358372  2705 sgd_solver.cpp:106] Iteration 4528, lr = 0.0005
I0403 06:30:58.819828  2705 solver.cpp:228] Iteration 4544, loss = 0.0305791
I0403 06:30:58.819938  2705 solver.cpp:244]     Train net output #0: loss = 0.0305791 (* 1 = 0.0305791 loss)
I0403 06:30:59.008239  2705 sgd_solver.cpp:106] Iteration 4544, lr = 0.0005
I0403 06:31:02.705023  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_4550.caffemodel
I0403 06:31:05.474340  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_4550.solverstate
I0403 06:31:07.382763  2705 solver.cpp:337] Iteration 4550, Testing net (#0)
I0403 06:31:55.799921  2705 solver.cpp:404]     Test net output #0: accuracy = 0.937234
I0403 06:31:55.800276  2705 solver.cpp:404]     Test net output #1: loss = 0.212348 (* 1 = 0.212348 loss)
I0403 06:32:03.588598  2705 solver.cpp:228] Iteration 4560, loss = 0.125824
I0403 06:32:03.588707  2705 solver.cpp:244]     Train net output #0: loss = 0.125824 (* 1 = 0.125824 loss)
I0403 06:32:03.777485  2705 sgd_solver.cpp:106] Iteration 4560, lr = 0.0005
I0403 06:32:15.180758  2705 solver.cpp:228] Iteration 4576, loss = 0.0335799
I0403 06:32:15.180866  2705 solver.cpp:244]     Train net output #0: loss = 0.0335799 (* 1 = 0.0335799 loss)
I0403 06:32:15.378099  2705 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 06:32:26.646618  2705 solver.cpp:228] Iteration 4592, loss = 0.0270084
I0403 06:32:26.646960  2705 solver.cpp:244]     Train net output #0: loss = 0.0270085 (* 1 = 0.0270085 loss)
I0403 06:32:26.837116  2705 sgd_solver.cpp:106] Iteration 4592, lr = 0.0005
I0403 06:32:38.157488  2705 solver.cpp:228] Iteration 4608, loss = 0.0706166
I0403 06:32:38.157588  2705 solver.cpp:244]     Train net output #0: loss = 0.0706167 (* 1 = 0.0706167 loss)
I0403 06:32:38.327692  2705 sgd_solver.cpp:106] Iteration 4608, lr = 0.0005
I0403 06:32:49.829311  2705 solver.cpp:228] Iteration 4624, loss = 0.0395938
I0403 06:32:49.829416  2705 solver.cpp:244]     Train net output #0: loss = 0.0395939 (* 1 = 0.0395939 loss)
I0403 06:32:49.997814  2705 sgd_solver.cpp:106] Iteration 4624, lr = 0.0005
I0403 06:33:01.269809  2705 solver.cpp:228] Iteration 4640, loss = 0.110629
I0403 06:33:01.270105  2705 solver.cpp:244]     Train net output #0: loss = 0.110629 (* 1 = 0.110629 loss)
I0403 06:33:01.422966  2705 sgd_solver.cpp:106] Iteration 4640, lr = 0.0005
I0403 06:33:12.880424  2705 solver.cpp:228] Iteration 4656, loss = 0.110632
I0403 06:33:12.880532  2705 solver.cpp:244]     Train net output #0: loss = 0.110632 (* 1 = 0.110632 loss)
I0403 06:33:13.063874  2705 sgd_solver.cpp:106] Iteration 4656, lr = 0.0005
I0403 06:33:24.464198  2705 solver.cpp:228] Iteration 4672, loss = 0.0569207
I0403 06:33:24.464298  2705 solver.cpp:244]     Train net output #0: loss = 0.0569208 (* 1 = 0.0569208 loss)
I0403 06:33:24.628182  2705 sgd_solver.cpp:106] Iteration 4672, lr = 0.0005
I0403 06:33:36.171339  2705 solver.cpp:228] Iteration 4688, loss = 0.0522721
I0403 06:33:36.171687  2705 solver.cpp:244]     Train net output #0: loss = 0.0522722 (* 1 = 0.0522722 loss)
I0403 06:33:36.364405  2705 sgd_solver.cpp:106] Iteration 4688, lr = 0.0005
I0403 06:33:47.744846  2705 solver.cpp:228] Iteration 4704, loss = 0.035435
I0403 06:33:47.744954  2705 solver.cpp:244]     Train net output #0: loss = 0.0354351 (* 1 = 0.0354351 loss)
I0403 06:33:47.951761  2705 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 06:33:59.492557  2705 solver.cpp:228] Iteration 4720, loss = 0.0443116
I0403 06:33:59.492647  2705 solver.cpp:244]     Train net output #0: loss = 0.0443117 (* 1 = 0.0443117 loss)
I0403 06:33:59.642074  2705 sgd_solver.cpp:106] Iteration 4720, lr = 0.0005
I0403 06:34:11.097193  2705 solver.cpp:228] Iteration 4736, loss = 0.105535
I0403 06:34:11.097453  2705 solver.cpp:244]     Train net output #0: loss = 0.105535 (* 1 = 0.105535 loss)
I0403 06:34:11.284934  2705 sgd_solver.cpp:106] Iteration 4736, lr = 0.0005
I0403 06:34:22.778421  2705 solver.cpp:228] Iteration 4752, loss = 0.134577
I0403 06:34:22.778520  2705 solver.cpp:244]     Train net output #0: loss = 0.134577 (* 1 = 0.134577 loss)
I0403 06:34:22.949431  2705 sgd_solver.cpp:106] Iteration 4752, lr = 0.0005
I0403 06:34:34.447149  2705 solver.cpp:228] Iteration 4768, loss = 0.0192848
I0403 06:34:34.447258  2705 solver.cpp:244]     Train net output #0: loss = 0.0192849 (* 1 = 0.0192849 loss)
I0403 06:34:34.634121  2705 sgd_solver.cpp:106] Iteration 4768, lr = 0.0005
I0403 06:34:45.863159  2705 solver.cpp:228] Iteration 4784, loss = 0.0346899
I0403 06:34:45.863471  2705 solver.cpp:244]     Train net output #0: loss = 0.03469 (* 1 = 0.03469 loss)
I0403 06:34:46.052331  2705 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 06:34:57.428354  2705 solver.cpp:228] Iteration 4800, loss = 0.0358729
I0403 06:34:57.428465  2705 solver.cpp:244]     Train net output #0: loss = 0.035873 (* 1 = 0.035873 loss)
I0403 06:34:57.610309  2705 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0403 06:35:09.002650  2705 solver.cpp:228] Iteration 4816, loss = 0.0878977
I0403 06:35:09.002763  2705 solver.cpp:244]     Train net output #0: loss = 0.0878978 (* 1 = 0.0878978 loss)
I0403 06:35:09.232894  2705 sgd_solver.cpp:106] Iteration 4816, lr = 0.0005
I0403 06:35:20.579887  2705 solver.cpp:228] Iteration 4832, loss = 0.0499185
I0403 06:35:20.580399  2705 solver.cpp:244]     Train net output #0: loss = 0.0499186 (* 1 = 0.0499186 loss)
I0403 06:35:20.749572  2705 sgd_solver.cpp:106] Iteration 4832, lr = 0.0005
I0403 06:35:32.147112  2705 solver.cpp:228] Iteration 4848, loss = 0.0497639
I0403 06:35:32.147218  2705 solver.cpp:244]     Train net output #0: loss = 0.049764 (* 1 = 0.049764 loss)
I0403 06:35:32.343189  2705 sgd_solver.cpp:106] Iteration 4848, lr = 0.0005
I0403 06:35:43.639343  2705 solver.cpp:228] Iteration 4864, loss = 0.0109506
I0403 06:35:43.639441  2705 solver.cpp:244]     Train net output #0: loss = 0.0109507 (* 1 = 0.0109507 loss)
I0403 06:35:43.808708  2705 sgd_solver.cpp:106] Iteration 4864, lr = 0.0005
I0403 06:35:51.052373  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_4875.caffemodel
I0403 06:35:53.799885  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_4875.solverstate
I0403 06:35:55.677804  2705 solver.cpp:337] Iteration 4875, Testing net (#0)
I0403 06:36:44.092597  2705 solver.cpp:404]     Test net output #0: accuracy = 0.938203
I0403 06:36:44.092948  2705 solver.cpp:404]     Test net output #1: loss = 0.213445 (* 1 = 0.213445 loss)
I0403 06:36:48.232383  2705 solver.cpp:228] Iteration 4880, loss = 0.0248796
I0403 06:36:48.232488  2705 solver.cpp:244]     Train net output #0: loss = 0.0248797 (* 1 = 0.0248797 loss)
I0403 06:36:48.424999  2705 sgd_solver.cpp:106] Iteration 4880, lr = 0.0005
I0403 06:36:59.739152  2705 solver.cpp:228] Iteration 4896, loss = 0.0238852
I0403 06:36:59.739251  2705 solver.cpp:244]     Train net output #0: loss = 0.0238852 (* 1 = 0.0238852 loss)
I0403 06:36:59.908473  2705 sgd_solver.cpp:106] Iteration 4896, lr = 0.0005
I0403 06:37:11.341372  2705 solver.cpp:228] Iteration 4912, loss = 0.0224485
I0403 06:37:11.341483  2705 solver.cpp:244]     Train net output #0: loss = 0.0224485 (* 1 = 0.0224485 loss)
I0403 06:37:11.537477  2705 sgd_solver.cpp:106] Iteration 4912, lr = 0.0005
I0403 06:37:23.021126  2705 solver.cpp:228] Iteration 4928, loss = 0.019838
I0403 06:37:23.021432  2705 solver.cpp:244]     Train net output #0: loss = 0.0198381 (* 1 = 0.0198381 loss)
I0403 06:37:23.145406  2705 sgd_solver.cpp:106] Iteration 4928, lr = 0.0005
I0403 06:37:34.793668  2705 solver.cpp:228] Iteration 4944, loss = 0.0387684
I0403 06:37:34.793766  2705 solver.cpp:244]     Train net output #0: loss = 0.0387685 (* 1 = 0.0387685 loss)
I0403 06:37:34.969015  2705 sgd_solver.cpp:106] Iteration 4944, lr = 0.0005
I0403 06:37:46.378407  2705 solver.cpp:228] Iteration 4960, loss = 0.0198581
I0403 06:37:46.378520  2705 solver.cpp:244]     Train net output #0: loss = 0.0198582 (* 1 = 0.0198582 loss)
I0403 06:37:46.578742  2705 sgd_solver.cpp:106] Iteration 4960, lr = 0.0005
I0403 06:37:57.996893  2705 solver.cpp:228] Iteration 4976, loss = 0.0400566
I0403 06:37:57.997159  2705 solver.cpp:244]     Train net output #0: loss = 0.0400566 (* 1 = 0.0400566 loss)
I0403 06:37:58.185312  2705 sgd_solver.cpp:106] Iteration 4976, lr = 0.0005
I0403 06:38:09.609463  2705 solver.cpp:228] Iteration 4992, loss = 0.0287221
I0403 06:38:09.609565  2705 solver.cpp:244]     Train net output #0: loss = 0.0287222 (* 1 = 0.0287222 loss)
I0403 06:38:09.772297  2705 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 06:38:21.319453  2705 solver.cpp:228] Iteration 5008, loss = 0.0506442
I0403 06:38:21.319552  2705 solver.cpp:244]     Train net output #0: loss = 0.0506442 (* 1 = 0.0506442 loss)
I0403 06:38:21.498514  2705 sgd_solver.cpp:106] Iteration 5008, lr = 0.0005
I0403 06:38:32.849735  2705 solver.cpp:228] Iteration 5024, loss = 0.0170165
I0403 06:38:32.850021  2705 solver.cpp:244]     Train net output #0: loss = 0.0170165 (* 1 = 0.0170165 loss)
I0403 06:38:33.017331  2705 sgd_solver.cpp:106] Iteration 5024, lr = 0.0005
I0403 06:38:44.481932  2705 solver.cpp:228] Iteration 5040, loss = 0.0371075
I0403 06:38:44.482041  2705 solver.cpp:244]     Train net output #0: loss = 0.0371075 (* 1 = 0.0371075 loss)
I0403 06:38:44.668769  2705 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 06:38:56.210278  2705 solver.cpp:228] Iteration 5056, loss = 0.0638011
I0403 06:38:56.210391  2705 solver.cpp:244]     Train net output #0: loss = 0.0638011 (* 1 = 0.0638011 loss)
I0403 06:38:56.393944  2705 sgd_solver.cpp:106] Iteration 5056, lr = 0.0005
I0403 06:39:07.789587  2705 solver.cpp:228] Iteration 5072, loss = 0.119699
I0403 06:39:07.789924  2705 solver.cpp:244]     Train net output #0: loss = 0.119699 (* 1 = 0.119699 loss)
I0403 06:39:07.991643  2705 sgd_solver.cpp:106] Iteration 5072, lr = 0.0005
I0403 06:39:19.312901  2705 solver.cpp:228] Iteration 5088, loss = 0.0711437
I0403 06:39:19.313000  2705 solver.cpp:244]     Train net output #0: loss = 0.0711437 (* 1 = 0.0711437 loss)
I0403 06:39:19.464093  2705 sgd_solver.cpp:106] Iteration 5088, lr = 0.0005
I0403 06:39:31.110508  2705 solver.cpp:228] Iteration 5104, loss = 0.0697672
I0403 06:39:31.110622  2705 solver.cpp:244]     Train net output #0: loss = 0.0697673 (* 1 = 0.0697673 loss)
I0403 06:39:31.312499  2705 sgd_solver.cpp:106] Iteration 5104, lr = 0.0005
I0403 06:39:42.662485  2705 solver.cpp:228] Iteration 5120, loss = 0.0391406
I0403 06:39:42.662791  2705 solver.cpp:244]     Train net output #0: loss = 0.0391406 (* 1 = 0.0391406 loss)
I0403 06:39:42.840801  2705 sgd_solver.cpp:106] Iteration 5120, lr = 0.0005
I0403 06:39:54.194288  2705 solver.cpp:228] Iteration 5136, loss = 0.0499606
I0403 06:39:54.194443  2705 solver.cpp:244]     Train net output #0: loss = 0.0499607 (* 1 = 0.0499607 loss)
I0403 06:39:54.416858  2705 sgd_solver.cpp:106] Iteration 5136, lr = 0.0005
I0403 06:40:05.924969  2705 solver.cpp:228] Iteration 5152, loss = 0.0467617
I0403 06:40:05.925079  2705 solver.cpp:244]     Train net output #0: loss = 0.0467617 (* 1 = 0.0467617 loss)
I0403 06:40:06.106043  2705 sgd_solver.cpp:106] Iteration 5152, lr = 0.0005
I0403 06:40:17.323282  2705 solver.cpp:228] Iteration 5168, loss = 0.0586021
I0403 06:40:17.323622  2705 solver.cpp:244]     Train net output #0: loss = 0.0586022 (* 1 = 0.0586022 loss)
I0403 06:40:17.505573  2705 sgd_solver.cpp:106] Iteration 5168, lr = 0.0005
I0403 06:40:28.708394  2705 solver.cpp:228] Iteration 5184, loss = 0.0166294
I0403 06:40:28.708506  2705 solver.cpp:244]     Train net output #0: loss = 0.0166294 (* 1 = 0.0166294 loss)
I0403 06:40:28.932632  2705 sgd_solver.cpp:106] Iteration 5184, lr = 0.0005
I0403 06:40:39.774636  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_5200.caffemodel
I0403 06:40:42.528700  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_5200.solverstate
I0403 06:40:44.421722  2705 solver.cpp:337] Iteration 5200, Testing net (#0)
I0403 06:41:32.823318  2705 solver.cpp:404]     Test net output #0: accuracy = 0.937604
I0403 06:41:32.823665  2705 solver.cpp:404]     Test net output #1: loss = 0.215141 (* 1 = 0.215141 loss)
I0403 06:41:33.336652  2705 solver.cpp:228] Iteration 5200, loss = 0.0254432
I0403 06:41:33.336745  2705 solver.cpp:244]     Train net output #0: loss = 0.0254432 (* 1 = 0.0254432 loss)
I0403 06:41:33.496176  2705 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 06:41:45.038043  2705 solver.cpp:228] Iteration 5216, loss = 0.0219075
I0403 06:41:45.038156  2705 solver.cpp:244]     Train net output #0: loss = 0.0219076 (* 1 = 0.0219076 loss)
I0403 06:41:45.263980  2705 sgd_solver.cpp:106] Iteration 5216, lr = 0.0005
I0403 06:41:56.641098  2705 solver.cpp:228] Iteration 5232, loss = 0.0772445
I0403 06:41:56.641197  2705 solver.cpp:244]     Train net output #0: loss = 0.0772445 (* 1 = 0.0772445 loss)
I0403 06:41:56.818816  2705 sgd_solver.cpp:106] Iteration 5232, lr = 0.0005
I0403 06:42:08.180425  2705 solver.cpp:228] Iteration 5248, loss = 0.0460768
I0403 06:42:08.180732  2705 solver.cpp:244]     Train net output #0: loss = 0.0460769 (* 1 = 0.0460769 loss)
I0403 06:42:08.368592  2705 sgd_solver.cpp:106] Iteration 5248, lr = 0.0005
I0403 06:42:19.775928  2705 solver.cpp:228] Iteration 5264, loss = 0.0364756
I0403 06:42:19.776044  2705 solver.cpp:244]     Train net output #0: loss = 0.0364756 (* 1 = 0.0364756 loss)
I0403 06:42:19.956569  2705 sgd_solver.cpp:106] Iteration 5264, lr = 0.0005
I0403 06:42:31.352200  2705 solver.cpp:228] Iteration 5280, loss = 0.0397368
I0403 06:42:31.352309  2705 solver.cpp:244]     Train net output #0: loss = 0.0397369 (* 1 = 0.0397369 loss)
I0403 06:42:31.557435  2705 sgd_solver.cpp:106] Iteration 5280, lr = 0.0005
I0403 06:42:43.270555  2705 solver.cpp:228] Iteration 5296, loss = 0.0911914
I0403 06:42:43.270867  2705 solver.cpp:244]     Train net output #0: loss = 0.0911915 (* 1 = 0.0911915 loss)
I0403 06:42:43.488421  2705 sgd_solver.cpp:106] Iteration 5296, lr = 0.0005
I0403 06:42:54.848613  2705 solver.cpp:228] Iteration 5312, loss = 0.0704727
I0403 06:42:54.848722  2705 solver.cpp:244]     Train net output #0: loss = 0.0704727 (* 1 = 0.0704727 loss)
I0403 06:42:55.060434  2705 sgd_solver.cpp:106] Iteration 5312, lr = 0.0005
I0403 06:43:06.683290  2705 solver.cpp:228] Iteration 5328, loss = 0.0554943
I0403 06:43:06.683403  2705 solver.cpp:244]     Train net output #0: loss = 0.0554944 (* 1 = 0.0554944 loss)
I0403 06:43:06.865666  2705 sgd_solver.cpp:106] Iteration 5328, lr = 0.0005
I0403 06:43:18.202790  2705 solver.cpp:228] Iteration 5344, loss = 0.041891
I0403 06:43:18.203119  2705 solver.cpp:244]     Train net output #0: loss = 0.0418911 (* 1 = 0.0418911 loss)
I0403 06:43:18.371726  2705 sgd_solver.cpp:106] Iteration 5344, lr = 0.0005
I0403 06:43:29.712455  2705 solver.cpp:228] Iteration 5360, loss = 0.0802016
I0403 06:43:29.712556  2705 solver.cpp:244]     Train net output #0: loss = 0.0802017 (* 1 = 0.0802017 loss)
I0403 06:43:29.891981  2705 sgd_solver.cpp:106] Iteration 5360, lr = 0.0005
I0403 06:43:41.440418  2705 solver.cpp:228] Iteration 5376, loss = 0.0288896
I0403 06:43:41.440527  2705 solver.cpp:244]     Train net output #0: loss = 0.0288896 (* 1 = 0.0288896 loss)
I0403 06:43:41.635046  2705 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 06:43:53.150429  2705 solver.cpp:228] Iteration 5392, loss = 0.0776318
I0403 06:43:53.150719  2705 solver.cpp:244]     Train net output #0: loss = 0.0776319 (* 1 = 0.0776319 loss)
I0403 06:43:53.329602  2705 sgd_solver.cpp:106] Iteration 5392, lr = 0.0005
I0403 06:44:04.749788  2705 solver.cpp:228] Iteration 5408, loss = 0.024722
I0403 06:44:04.749886  2705 solver.cpp:244]     Train net output #0: loss = 0.024722 (* 1 = 0.024722 loss)
I0403 06:44:04.904197  2705 sgd_solver.cpp:106] Iteration 5408, lr = 0.0005
I0403 06:44:16.416996  2705 solver.cpp:228] Iteration 5424, loss = 0.0498598
I0403 06:44:16.417098  2705 solver.cpp:244]     Train net output #0: loss = 0.0498598 (* 1 = 0.0498598 loss)
I0403 06:44:16.585000  2705 sgd_solver.cpp:106] Iteration 5424, lr = 0.0005
I0403 06:44:28.122422  2705 solver.cpp:228] Iteration 5440, loss = 0.0811823
I0403 06:44:28.122728  2705 solver.cpp:244]     Train net output #0: loss = 0.0811824 (* 1 = 0.0811824 loss)
I0403 06:44:28.295912  2705 sgd_solver.cpp:106] Iteration 5440, lr = 0.0005
I0403 06:44:39.755880  2705 solver.cpp:228] Iteration 5456, loss = 0.0581285
I0403 06:44:39.755993  2705 solver.cpp:244]     Train net output #0: loss = 0.0581286 (* 1 = 0.0581286 loss)
I0403 06:44:39.971503  2705 sgd_solver.cpp:106] Iteration 5456, lr = 0.0005
I0403 06:44:51.340490  2705 solver.cpp:228] Iteration 5472, loss = 0.0245139
I0403 06:44:51.340605  2705 solver.cpp:244]     Train net output #0: loss = 0.024514 (* 1 = 0.024514 loss)
I0403 06:44:51.528093  2705 sgd_solver.cpp:106] Iteration 5472, lr = 0.0005
I0403 06:45:02.879341  2705 solver.cpp:228] Iteration 5488, loss = 0.00778916
I0403 06:45:02.879649  2705 solver.cpp:244]     Train net output #0: loss = 0.00778924 (* 1 = 0.00778924 loss)
I0403 06:45:03.077087  2705 sgd_solver.cpp:106] Iteration 5488, lr = 0.0005
I0403 06:45:14.548774  2705 solver.cpp:228] Iteration 5504, loss = 0.0670123
I0403 06:45:14.548887  2705 solver.cpp:244]     Train net output #0: loss = 0.0670124 (* 1 = 0.0670124 loss)
I0403 06:45:14.749275  2705 sgd_solver.cpp:106] Iteration 5504, lr = 0.0005
I0403 06:45:26.268391  2705 solver.cpp:228] Iteration 5520, loss = 0.030912
I0403 06:45:26.268501  2705 solver.cpp:244]     Train net output #0: loss = 0.0309121 (* 1 = 0.0309121 loss)
I0403 06:45:26.461148  2705 sgd_solver.cpp:106] Iteration 5520, lr = 0.0005
I0403 06:45:29.344960  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_5525.caffemodel
I0403 06:45:32.112431  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_5525.solverstate
I0403 06:45:33.993701  2705 solver.cpp:337] Iteration 5525, Testing net (#0)
I0403 06:46:22.406878  2705 solver.cpp:404]     Test net output #0: accuracy = 0.938064
I0403 06:46:22.407256  2705 solver.cpp:404]     Test net output #1: loss = 0.217763 (* 1 = 0.217763 loss)
I0403 06:46:30.844945  2705 solver.cpp:228] Iteration 5536, loss = 0.0449348
I0403 06:46:30.845052  2705 solver.cpp:244]     Train net output #0: loss = 0.0449349 (* 1 = 0.0449349 loss)
I0403 06:46:31.038451  2705 sgd_solver.cpp:106] Iteration 5536, lr = 0.0005
I0403 06:46:42.426609  2705 solver.cpp:228] Iteration 5552, loss = 0.0679161
I0403 06:46:42.426709  2705 solver.cpp:244]     Train net output #0: loss = 0.0679162 (* 1 = 0.0679162 loss)
I0403 06:46:42.604804  2705 sgd_solver.cpp:106] Iteration 5552, lr = 0.0005
I0403 06:46:53.945134  2705 solver.cpp:228] Iteration 5568, loss = 0.0543836
I0403 06:46:53.945446  2705 solver.cpp:244]     Train net output #0: loss = 0.0543836 (* 1 = 0.0543836 loss)
I0403 06:46:54.078737  2705 sgd_solver.cpp:106] Iteration 5568, lr = 0.0005
I0403 06:47:05.606402  2705 solver.cpp:228] Iteration 5584, loss = 0.0255524
I0403 06:47:05.606500  2705 solver.cpp:244]     Train net output #0: loss = 0.0255524 (* 1 = 0.0255524 loss)
I0403 06:47:05.777209  2705 sgd_solver.cpp:106] Iteration 5584, lr = 0.0005
I0403 06:47:17.365663  2705 solver.cpp:228] Iteration 5600, loss = 0.0491739
I0403 06:47:17.365762  2705 solver.cpp:244]     Train net output #0: loss = 0.049174 (* 1 = 0.049174 loss)
I0403 06:47:17.510968  2705 sgd_solver.cpp:106] Iteration 5600, lr = 0.0005
I0403 06:47:29.033040  2705 solver.cpp:228] Iteration 5616, loss = 0.0979733
I0403 06:47:29.033346  2705 solver.cpp:244]     Train net output #0: loss = 0.0979734 (* 1 = 0.0979734 loss)
I0403 06:47:29.171377  2705 sgd_solver.cpp:106] Iteration 5616, lr = 0.0005
I0403 06:47:40.579337  2705 solver.cpp:228] Iteration 5632, loss = 0.0536974
I0403 06:47:40.579437  2705 solver.cpp:244]     Train net output #0: loss = 0.0536974 (* 1 = 0.0536974 loss)
I0403 06:47:40.754801  2705 sgd_solver.cpp:106] Iteration 5632, lr = 0.0005
I0403 06:47:52.079030  2705 solver.cpp:228] Iteration 5648, loss = 0.0729594
I0403 06:47:52.079139  2705 solver.cpp:244]     Train net output #0: loss = 0.0729595 (* 1 = 0.0729595 loss)
I0403 06:47:52.264294  2705 sgd_solver.cpp:106] Iteration 5648, lr = 0.0005
I0403 06:48:03.913179  2705 solver.cpp:228] Iteration 5664, loss = 0.0155385
I0403 06:48:03.913475  2705 solver.cpp:244]     Train net output #0: loss = 0.0155386 (* 1 = 0.0155386 loss)
I0403 06:48:04.015244  2705 sgd_solver.cpp:106] Iteration 5664, lr = 0.0005
I0403 06:48:15.367355  2705 solver.cpp:228] Iteration 5680, loss = 0.0460032
I0403 06:48:15.367463  2705 solver.cpp:244]     Train net output #0: loss = 0.0460033 (* 1 = 0.0460033 loss)
I0403 06:48:15.585000  2705 sgd_solver.cpp:106] Iteration 5680, lr = 0.0005
I0403 06:48:26.783860  2705 solver.cpp:228] Iteration 5696, loss = 0.0259566
I0403 06:48:26.783970  2705 solver.cpp:244]     Train net output #0: loss = 0.0259567 (* 1 = 0.0259567 loss)
I0403 06:48:27.016865  2705 sgd_solver.cpp:106] Iteration 5696, lr = 0.0005
I0403 06:48:38.267487  2705 solver.cpp:228] Iteration 5712, loss = 0.0497357
I0403 06:48:38.267802  2705 solver.cpp:244]     Train net output #0: loss = 0.0497357 (* 1 = 0.0497357 loss)
I0403 06:48:38.467650  2705 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 06:48:50.142343  2705 solver.cpp:228] Iteration 5728, loss = 0.0205638
I0403 06:48:50.142464  2705 solver.cpp:244]     Train net output #0: loss = 0.0205639 (* 1 = 0.0205639 loss)
I0403 06:48:50.336244  2705 sgd_solver.cpp:106] Iteration 5728, lr = 0.0005
I0403 06:49:01.777400  2705 solver.cpp:228] Iteration 5744, loss = 0.0466872
I0403 06:49:01.777510  2705 solver.cpp:244]     Train net output #0: loss = 0.0466873 (* 1 = 0.0466873 loss)
I0403 06:49:01.965118  2705 sgd_solver.cpp:106] Iteration 5744, lr = 0.0005
I0403 06:49:13.330479  2705 solver.cpp:228] Iteration 5760, loss = 0.0312946
I0403 06:49:13.330780  2705 solver.cpp:244]     Train net output #0: loss = 0.0312946 (* 1 = 0.0312946 loss)
I0403 06:49:13.509196  2705 sgd_solver.cpp:106] Iteration 5760, lr = 0.0005
I0403 06:49:24.897485  2705 solver.cpp:228] Iteration 5776, loss = 0.0397079
I0403 06:49:24.897594  2705 solver.cpp:244]     Train net output #0: loss = 0.039708 (* 1 = 0.039708 loss)
I0403 06:49:25.097017  2705 sgd_solver.cpp:106] Iteration 5776, lr = 0.0005
I0403 06:49:36.394942  2705 solver.cpp:228] Iteration 5792, loss = 0.0936698
I0403 06:49:36.395051  2705 solver.cpp:244]     Train net output #0: loss = 0.0936699 (* 1 = 0.0936699 loss)
I0403 06:49:36.583876  2705 sgd_solver.cpp:106] Iteration 5792, lr = 0.0005
I0403 06:49:47.796330  2705 solver.cpp:228] Iteration 5808, loss = 0.0657323
I0403 06:49:47.800608  2705 solver.cpp:244]     Train net output #0: loss = 0.0657324 (* 1 = 0.0657324 loss)
I0403 06:49:47.981719  2705 sgd_solver.cpp:106] Iteration 5808, lr = 0.0005
I0403 06:49:59.684820  2705 solver.cpp:228] Iteration 5824, loss = 0.0214667
I0403 06:49:59.684917  2705 solver.cpp:244]     Train net output #0: loss = 0.0214668 (* 1 = 0.0214668 loss)
I0403 06:49:59.829687  2705 sgd_solver.cpp:106] Iteration 5824, lr = 0.0005
I0403 06:50:11.496229  2705 solver.cpp:228] Iteration 5840, loss = 0.0122226
I0403 06:50:11.496336  2705 solver.cpp:244]     Train net output #0: loss = 0.0122227 (* 1 = 0.0122227 loss)
I0403 06:50:11.664402  2705 sgd_solver.cpp:106] Iteration 5840, lr = 0.0005
I0403 06:50:18.250507  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_5850.caffemodel
I0403 06:50:20.966789  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_5850.solverstate
I0403 06:50:22.782924  2705 solver.cpp:337] Iteration 5850, Testing net (#0)
I0403 06:51:11.189734  2705 solver.cpp:404]     Test net output #0: accuracy = 0.93811
I0403 06:51:11.190045  2705 solver.cpp:404]     Test net output #1: loss = 0.222284 (* 1 = 0.222284 loss)
I0403 06:51:16.055713  2705 solver.cpp:228] Iteration 5856, loss = 0.0432973
I0403 06:51:16.055814  2705 solver.cpp:244]     Train net output #0: loss = 0.0432974 (* 1 = 0.0432974 loss)
I0403 06:51:16.205160  2705 sgd_solver.cpp:106] Iteration 5856, lr = 0.0005
I0403 06:51:27.730312  2705 solver.cpp:228] Iteration 5872, loss = 0.031068
I0403 06:51:27.730413  2705 solver.cpp:244]     Train net output #0: loss = 0.0310681 (* 1 = 0.0310681 loss)
I0403 06:51:27.905964  2705 sgd_solver.cpp:106] Iteration 5872, lr = 0.0005
I0403 06:51:39.364030  2705 solver.cpp:228] Iteration 5888, loss = 0.0464515
I0403 06:51:39.364147  2705 solver.cpp:244]     Train net output #0: loss = 0.0464516 (* 1 = 0.0464516 loss)
I0403 06:51:39.577214  2705 sgd_solver.cpp:106] Iteration 5888, lr = 0.0005
I0403 06:51:50.951748  2705 solver.cpp:228] Iteration 5904, loss = 0.0542353
I0403 06:51:50.952044  2705 solver.cpp:244]     Train net output #0: loss = 0.0542354 (* 1 = 0.0542354 loss)
I0403 06:51:51.138586  2705 sgd_solver.cpp:106] Iteration 5904, lr = 0.0005
I0403 06:52:02.432495  2705 solver.cpp:228] Iteration 5920, loss = 0.0338677
I0403 06:52:02.432592  2705 solver.cpp:244]     Train net output #0: loss = 0.0338678 (* 1 = 0.0338678 loss)
I0403 06:52:02.610195  2705 sgd_solver.cpp:106] Iteration 5920, lr = 0.0005
I0403 06:52:14.003592  2705 solver.cpp:228] Iteration 5936, loss = 0.0253791
I0403 06:52:14.003715  2705 solver.cpp:244]     Train net output #0: loss = 0.0253792 (* 1 = 0.0253792 loss)
I0403 06:52:14.183959  2705 sgd_solver.cpp:106] Iteration 5936, lr = 0.0005
I0403 06:52:25.587422  2705 solver.cpp:228] Iteration 5952, loss = 0.0131597
I0403 06:52:25.587733  2705 solver.cpp:244]     Train net output #0: loss = 0.0131599 (* 1 = 0.0131599 loss)
I0403 06:52:25.781633  2705 sgd_solver.cpp:106] Iteration 5952, lr = 0.0005
I0403 06:52:37.079471  2705 solver.cpp:228] Iteration 5968, loss = 0.0779412
I0403 06:52:37.079569  2705 solver.cpp:244]     Train net output #0: loss = 0.0779414 (* 1 = 0.0779414 loss)
I0403 06:52:37.258034  2705 sgd_solver.cpp:106] Iteration 5968, lr = 0.0005
I0403 06:52:48.546797  2705 solver.cpp:228] Iteration 5984, loss = 0.0239981
I0403 06:52:48.546906  2705 solver.cpp:244]     Train net output #0: loss = 0.0239982 (* 1 = 0.0239982 loss)
I0403 06:52:48.762315  2705 sgd_solver.cpp:106] Iteration 5984, lr = 0.0005
I0403 06:53:00.139081  2705 solver.cpp:228] Iteration 6000, loss = 0.0339569
I0403 06:53:00.139412  2705 solver.cpp:244]     Train net output #0: loss = 0.0339571 (* 1 = 0.0339571 loss)
I0403 06:53:00.317497  2705 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0403 06:53:11.670519  2705 solver.cpp:228] Iteration 6016, loss = 0.0266794
I0403 06:53:11.670632  2705 solver.cpp:244]     Train net output #0: loss = 0.0266796 (* 1 = 0.0266796 loss)
I0403 06:53:11.852783  2705 sgd_solver.cpp:106] Iteration 6016, lr = 0.0005
I0403 06:53:23.159940  2705 solver.cpp:228] Iteration 6032, loss = 0.0954063
I0403 06:53:23.160038  2705 solver.cpp:244]     Train net output #0: loss = 0.0954064 (* 1 = 0.0954064 loss)
I0403 06:53:23.338268  2705 sgd_solver.cpp:106] Iteration 6032, lr = 0.0005
I0403 06:53:34.788380  2705 solver.cpp:228] Iteration 6048, loss = 0.108499
I0403 06:53:34.788673  2705 solver.cpp:244]     Train net output #0: loss = 0.108499 (* 1 = 0.108499 loss)
I0403 06:53:34.990512  2705 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 06:53:46.456790  2705 solver.cpp:228] Iteration 6064, loss = 0.0412823
I0403 06:53:46.456889  2705 solver.cpp:244]     Train net output #0: loss = 0.0412824 (* 1 = 0.0412824 loss)
I0403 06:53:46.635262  2705 sgd_solver.cpp:106] Iteration 6064, lr = 0.0005
I0403 06:53:57.941923  2705 solver.cpp:228] Iteration 6080, loss = 0.0578534
I0403 06:53:57.942036  2705 solver.cpp:244]     Train net output #0: loss = 0.0578535 (* 1 = 0.0578535 loss)
I0403 06:53:58.177594  2705 sgd_solver.cpp:106] Iteration 6080, lr = 0.0005
I0403 06:54:09.700927  2705 solver.cpp:228] Iteration 6096, loss = 0.0482023
I0403 06:54:09.701241  2705 solver.cpp:244]     Train net output #0: loss = 0.0482025 (* 1 = 0.0482025 loss)
I0403 06:54:09.896625  2705 sgd_solver.cpp:106] Iteration 6096, lr = 0.0005
I0403 06:54:21.438776  2705 solver.cpp:228] Iteration 6112, loss = 0.0385621
I0403 06:54:21.438885  2705 solver.cpp:244]     Train net output #0: loss = 0.0385622 (* 1 = 0.0385622 loss)
I0403 06:54:21.618536  2705 sgd_solver.cpp:106] Iteration 6112, lr = 0.0005
I0403 06:54:33.151764  2705 solver.cpp:228] Iteration 6128, loss = 0.044793
I0403 06:54:33.151864  2705 solver.cpp:244]     Train net output #0: loss = 0.0447931 (* 1 = 0.0447931 loss)
I0403 06:54:33.329553  2705 sgd_solver.cpp:106] Iteration 6128, lr = 0.0005
I0403 06:54:44.694833  2705 solver.cpp:228] Iteration 6144, loss = 0.0252068
I0403 06:54:44.695122  2705 solver.cpp:244]     Train net output #0: loss = 0.0252069 (* 1 = 0.0252069 loss)
I0403 06:54:44.912273  2705 sgd_solver.cpp:106] Iteration 6144, lr = 0.0005
I0403 06:54:56.483526  2705 solver.cpp:228] Iteration 6160, loss = 0.0483745
I0403 06:54:56.483625  2705 solver.cpp:244]     Train net output #0: loss = 0.0483746 (* 1 = 0.0483746 loss)
I0403 06:54:56.615285  2705 sgd_solver.cpp:106] Iteration 6160, lr = 0.0005
I0403 06:55:06.936512  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_6175.caffemodel
I0403 06:55:09.631852  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_6175.solverstate
I0403 06:55:11.464382  2705 solver.cpp:337] Iteration 6175, Testing net (#0)
I0403 06:55:59.891304  2705 solver.cpp:404]     Test net output #0: accuracy = 0.938709
I0403 06:55:59.891641  2705 solver.cpp:404]     Test net output #1: loss = 0.219235 (* 1 = 0.219235 loss)
I0403 06:56:01.152499  2705 solver.cpp:228] Iteration 6176, loss = 0.0237481
I0403 06:56:01.152593  2705 solver.cpp:244]     Train net output #0: loss = 0.0237482 (* 1 = 0.0237482 loss)
I0403 06:56:01.327846  2705 sgd_solver.cpp:106] Iteration 6176, lr = 0.0005
I0403 06:56:12.688850  2705 solver.cpp:228] Iteration 6192, loss = 0.0547765
I0403 06:56:12.688947  2705 solver.cpp:244]     Train net output #0: loss = 0.0547766 (* 1 = 0.0547766 loss)
I0403 06:56:12.858876  2705 sgd_solver.cpp:106] Iteration 6192, lr = 0.0005
I0403 06:56:24.225906  2705 solver.cpp:228] Iteration 6208, loss = 0.0190538
I0403 06:56:24.226017  2705 solver.cpp:244]     Train net output #0: loss = 0.0190539 (* 1 = 0.0190539 loss)
I0403 06:56:24.420197  2705 sgd_solver.cpp:106] Iteration 6208, lr = 0.0005
I0403 06:56:35.927428  2705 solver.cpp:228] Iteration 6224, loss = 0.0708747
I0403 06:56:35.927752  2705 solver.cpp:244]     Train net output #0: loss = 0.0708748 (* 1 = 0.0708748 loss)
I0403 06:56:36.127326  2705 sgd_solver.cpp:106] Iteration 6224, lr = 0.0005
I0403 06:56:47.489430  2705 solver.cpp:228] Iteration 6240, loss = 0.0438796
I0403 06:56:47.489544  2705 solver.cpp:244]     Train net output #0: loss = 0.0438797 (* 1 = 0.0438797 loss)
I0403 06:56:47.702152  2705 sgd_solver.cpp:106] Iteration 6240, lr = 0.0005
I0403 06:56:59.181572  2705 solver.cpp:228] Iteration 6256, loss = 0.0229839
I0403 06:56:59.181684  2705 solver.cpp:244]     Train net output #0: loss = 0.022984 (* 1 = 0.022984 loss)
I0403 06:56:59.372453  2705 sgd_solver.cpp:106] Iteration 6256, lr = 0.0005
I0403 06:57:10.626554  2705 solver.cpp:228] Iteration 6272, loss = 0.0343859
I0403 06:57:10.626878  2705 solver.cpp:244]     Train net output #0: loss = 0.034386 (* 1 = 0.034386 loss)
I0403 06:57:10.808012  2705 sgd_solver.cpp:106] Iteration 6272, lr = 0.0005
I0403 06:57:22.502578  2705 solver.cpp:228] Iteration 6288, loss = 0.0526953
I0403 06:57:22.502689  2705 solver.cpp:244]     Train net output #0: loss = 0.0526954 (* 1 = 0.0526954 loss)
I0403 06:57:22.694309  2705 sgd_solver.cpp:106] Iteration 6288, lr = 0.0005
I0403 06:57:34.236687  2705 solver.cpp:228] Iteration 6304, loss = 0.0821588
I0403 06:57:34.236785  2705 solver.cpp:244]     Train net output #0: loss = 0.0821589 (* 1 = 0.0821589 loss)
I0403 06:57:34.398735  2705 sgd_solver.cpp:106] Iteration 6304, lr = 0.0005
I0403 06:57:45.826344  2705 solver.cpp:228] Iteration 6320, loss = 0.0399022
I0403 06:57:45.826653  2705 solver.cpp:244]     Train net output #0: loss = 0.0399023 (* 1 = 0.0399023 loss)
I0403 06:57:45.979936  2705 sgd_solver.cpp:106] Iteration 6320, lr = 0.0005
I0403 06:57:57.286463  2705 solver.cpp:228] Iteration 6336, loss = 0.0181166
I0403 06:57:57.286577  2705 solver.cpp:244]     Train net output #0: loss = 0.0181168 (* 1 = 0.0181168 loss)
I0403 06:57:57.512053  2705 sgd_solver.cpp:106] Iteration 6336, lr = 0.0005
I0403 06:58:08.800932  2705 solver.cpp:228] Iteration 6352, loss = 0.0229874
I0403 06:58:08.801030  2705 solver.cpp:244]     Train net output #0: loss = 0.0229875 (* 1 = 0.0229875 loss)
I0403 06:58:08.978927  2705 sgd_solver.cpp:106] Iteration 6352, lr = 0.0005
I0403 06:58:20.246975  2705 solver.cpp:228] Iteration 6368, loss = 0.0224886
I0403 06:58:20.250944  2705 solver.cpp:244]     Train net output #0: loss = 0.0224887 (* 1 = 0.0224887 loss)
I0403 06:58:20.434422  2705 sgd_solver.cpp:106] Iteration 6368, lr = 0.0005
I0403 06:58:31.716117  2705 solver.cpp:228] Iteration 6384, loss = 0.0311029
I0403 06:58:31.716231  2705 solver.cpp:244]     Train net output #0: loss = 0.031103 (* 1 = 0.031103 loss)
I0403 06:58:31.924739  2705 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 06:58:43.449007  2705 solver.cpp:228] Iteration 6400, loss = 0.0165225
I0403 06:58:43.449102  2705 solver.cpp:244]     Train net output #0: loss = 0.0165226 (* 1 = 0.0165226 loss)
I0403 06:58:43.628108  2705 sgd_solver.cpp:106] Iteration 6400, lr = 0.0005
I0403 06:58:55.171525  2705 solver.cpp:228] Iteration 6416, loss = 0.0164152
I0403 06:58:55.171836  2705 solver.cpp:244]     Train net output #0: loss = 0.0164153 (* 1 = 0.0164153 loss)
I0403 06:58:55.376473  2705 sgd_solver.cpp:106] Iteration 6416, lr = 0.0005
I0403 06:59:06.607434  2705 solver.cpp:228] Iteration 6432, loss = 0.0238716
I0403 06:59:06.607547  2705 solver.cpp:244]     Train net output #0: loss = 0.0238717 (* 1 = 0.0238717 loss)
I0403 06:59:06.799299  2705 sgd_solver.cpp:106] Iteration 6432, lr = 0.0005
I0403 06:59:18.378973  2705 solver.cpp:228] Iteration 6448, loss = 0.0123348
I0403 06:59:18.379083  2705 solver.cpp:244]     Train net output #0: loss = 0.0123349 (* 1 = 0.0123349 loss)
I0403 06:59:18.565299  2705 sgd_solver.cpp:106] Iteration 6448, lr = 0.0005
I0403 06:59:30.169437  2705 solver.cpp:228] Iteration 6464, loss = 0.0224596
I0403 06:59:30.169766  2705 solver.cpp:244]     Train net output #0: loss = 0.0224597 (* 1 = 0.0224597 loss)
I0403 06:59:30.340425  2705 sgd_solver.cpp:106] Iteration 6464, lr = 0.0005
I0403 06:59:41.923043  2705 solver.cpp:228] Iteration 6480, loss = 0.0478215
I0403 06:59:41.923154  2705 solver.cpp:244]     Train net output #0: loss = 0.0478216 (* 1 = 0.0478216 loss)
I0403 06:59:42.103325  2705 sgd_solver.cpp:106] Iteration 6480, lr = 0.0005
I0403 06:59:53.469499  2705 solver.cpp:228] Iteration 6496, loss = 0.0162042
I0403 06:59:53.469606  2705 solver.cpp:244]     Train net output #0: loss = 0.0162043 (* 1 = 0.0162043 loss)
I0403 06:59:53.644814  2705 sgd_solver.cpp:106] Iteration 6496, lr = 0.0005
I0403 06:59:55.802505  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_6500.caffemodel
I0403 06:59:58.531927  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_6500.solverstate
I0403 07:00:00.417297  2705 solver.cpp:337] Iteration 6500, Testing net (#0)
I0403 07:00:48.844342  2705 solver.cpp:404]     Test net output #0: accuracy = 0.938802
I0403 07:00:48.844650  2705 solver.cpp:404]     Test net output #1: loss = 0.219265 (* 1 = 0.219265 loss)
I0403 07:00:58.080564  2705 solver.cpp:228] Iteration 6512, loss = 0.0732745
I0403 07:00:58.080670  2705 solver.cpp:244]     Train net output #0: loss = 0.0732746 (* 1 = 0.0732746 loss)
I0403 07:00:58.258916  2705 sgd_solver.cpp:106] Iteration 6512, lr = 5e-05
I0403 07:01:09.686952  2705 solver.cpp:228] Iteration 6528, loss = 0.0105728
I0403 07:01:09.687063  2705 solver.cpp:244]     Train net output #0: loss = 0.0105729 (* 1 = 0.0105729 loss)
I0403 07:01:09.875144  2705 sgd_solver.cpp:106] Iteration 6528, lr = 5e-05
I0403 07:01:21.417948  2705 solver.cpp:228] Iteration 6544, loss = 0.0356319
I0403 07:01:21.418232  2705 solver.cpp:244]     Train net output #0: loss = 0.035632 (* 1 = 0.035632 loss)
I0403 07:01:21.605309  2705 sgd_solver.cpp:106] Iteration 6544, lr = 5e-05
I0403 07:01:32.990341  2705 solver.cpp:228] Iteration 6560, loss = 0.0591801
I0403 07:01:32.990453  2705 solver.cpp:244]     Train net output #0: loss = 0.0591802 (* 1 = 0.0591802 loss)
I0403 07:01:33.174795  2705 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 07:01:44.644683  2705 solver.cpp:228] Iteration 6576, loss = 0.0122712
I0403 07:01:44.644794  2705 solver.cpp:244]     Train net output #0: loss = 0.0122713 (* 1 = 0.0122713 loss)
I0403 07:01:44.874810  2705 sgd_solver.cpp:106] Iteration 6576, lr = 5e-05
I0403 07:01:56.287292  2705 solver.cpp:228] Iteration 6592, loss = 0.0989699
I0403 07:01:56.287619  2705 solver.cpp:244]     Train net output #0: loss = 0.09897 (* 1 = 0.09897 loss)
I0403 07:01:56.478621  2705 sgd_solver.cpp:106] Iteration 6592, lr = 5e-05
I0403 07:02:07.915724  2705 solver.cpp:228] Iteration 6608, loss = 0.0616123
I0403 07:02:07.915833  2705 solver.cpp:244]     Train net output #0: loss = 0.0616124 (* 1 = 0.0616124 loss)
I0403 07:02:08.097944  2705 sgd_solver.cpp:106] Iteration 6608, lr = 5e-05
I0403 07:02:19.500010  2705 solver.cpp:228] Iteration 6624, loss = 0.045228
I0403 07:02:19.500123  2705 solver.cpp:244]     Train net output #0: loss = 0.0452281 (* 1 = 0.0452281 loss)
I0403 07:02:19.686213  2705 sgd_solver.cpp:106] Iteration 6624, lr = 5e-05
I0403 07:02:31.246605  2705 solver.cpp:228] Iteration 6640, loss = 0.0423094
I0403 07:02:31.246860  2705 solver.cpp:244]     Train net output #0: loss = 0.0423095 (* 1 = 0.0423095 loss)
I0403 07:02:31.424367  2705 sgd_solver.cpp:106] Iteration 6640, lr = 5e-05
I0403 07:02:42.698421  2705 solver.cpp:228] Iteration 6656, loss = 0.0316775
I0403 07:02:42.698519  2705 solver.cpp:244]     Train net output #0: loss = 0.0316776 (* 1 = 0.0316776 loss)
I0403 07:02:42.871755  2705 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 07:02:54.126210  2705 solver.cpp:228] Iteration 6672, loss = 0.098842
I0403 07:02:54.126315  2705 solver.cpp:244]     Train net output #0: loss = 0.0988421 (* 1 = 0.0988421 loss)
I0403 07:02:54.302688  2705 sgd_solver.cpp:106] Iteration 6672, lr = 5e-05
I0403 07:03:05.883077  2705 solver.cpp:228] Iteration 6688, loss = 0.0276931
I0403 07:03:05.883355  2705 solver.cpp:244]     Train net output #0: loss = 0.0276932 (* 1 = 0.0276932 loss)
I0403 07:03:06.060031  2705 sgd_solver.cpp:106] Iteration 6688, lr = 5e-05
I0403 07:03:17.508772  2705 solver.cpp:228] Iteration 6704, loss = 0.0407138
I0403 07:03:17.508885  2705 solver.cpp:244]     Train net output #0: loss = 0.0407139 (* 1 = 0.0407139 loss)
I0403 07:03:17.686029  2705 sgd_solver.cpp:106] Iteration 6704, lr = 5e-05
I0403 07:03:28.953089  2705 solver.cpp:228] Iteration 6720, loss = 0.0498284
I0403 07:03:28.953189  2705 solver.cpp:244]     Train net output #0: loss = 0.0498285 (* 1 = 0.0498285 loss)
I0403 07:03:29.123931  2705 sgd_solver.cpp:106] Iteration 6720, lr = 5e-05
I0403 07:03:40.567895  2705 solver.cpp:228] Iteration 6736, loss = 0.0558054
I0403 07:03:40.568173  2705 solver.cpp:244]     Train net output #0: loss = 0.0558055 (* 1 = 0.0558055 loss)
I0403 07:03:40.735622  2705 sgd_solver.cpp:106] Iteration 6736, lr = 5e-05
I0403 07:03:52.064750  2705 solver.cpp:228] Iteration 6752, loss = 0.0530278
I0403 07:03:52.064849  2705 solver.cpp:244]     Train net output #0: loss = 0.0530279 (* 1 = 0.0530279 loss)
I0403 07:03:52.226032  2705 sgd_solver.cpp:106] Iteration 6752, lr = 5e-05
I0403 07:04:03.623239  2705 solver.cpp:228] Iteration 6768, loss = 0.0359166
I0403 07:04:03.623342  2705 solver.cpp:244]     Train net output #0: loss = 0.0359167 (* 1 = 0.0359167 loss)
I0403 07:04:03.738456  2705 sgd_solver.cpp:106] Iteration 6768, lr = 5e-05
I0403 07:04:15.375807  2705 solver.cpp:228] Iteration 6784, loss = 0.023666
I0403 07:04:15.376124  2705 solver.cpp:244]     Train net output #0: loss = 0.0236661 (* 1 = 0.0236661 loss)
I0403 07:04:15.558763  2705 sgd_solver.cpp:106] Iteration 6784, lr = 5e-05
I0403 07:04:26.834421  2705 solver.cpp:228] Iteration 6800, loss = 0.0710041
I0403 07:04:26.834529  2705 solver.cpp:244]     Train net output #0: loss = 0.0710042 (* 1 = 0.0710042 loss)
I0403 07:04:27.025441  2705 sgd_solver.cpp:106] Iteration 6800, lr = 5e-05
I0403 07:04:38.383240  2705 solver.cpp:228] Iteration 6816, loss = 0.0100767
I0403 07:04:38.383365  2705 solver.cpp:244]     Train net output #0: loss = 0.0100768 (* 1 = 0.0100768 loss)
I0403 07:04:38.565261  2705 sgd_solver.cpp:106] Iteration 6816, lr = 5e-05
I0403 07:04:44.260951  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_6825.caffemodel
I0403 07:04:47.071238  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_6825.solverstate
I0403 07:04:48.981803  2705 solver.cpp:337] Iteration 6825, Testing net (#0)
I0403 07:05:37.427618  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939401
I0403 07:05:37.427964  2705 solver.cpp:404]     Test net output #1: loss = 0.219149 (* 1 = 0.219149 loss)
I0403 07:05:42.975528  2705 solver.cpp:228] Iteration 6832, loss = 0.0361262
I0403 07:05:42.975651  2705 solver.cpp:244]     Train net output #0: loss = 0.0361263 (* 1 = 0.0361263 loss)
I0403 07:05:43.156857  2705 sgd_solver.cpp:106] Iteration 6832, lr = 5e-05
I0403 07:05:54.663311  2705 solver.cpp:228] Iteration 6848, loss = 0.047602
I0403 07:05:54.663427  2705 solver.cpp:244]     Train net output #0: loss = 0.0476021 (* 1 = 0.0476021 loss)
I0403 07:05:54.844805  2705 sgd_solver.cpp:106] Iteration 6848, lr = 5e-05
I0403 07:06:06.446293  2705 solver.cpp:228] Iteration 6864, loss = 0.0142845
I0403 07:06:06.446395  2705 solver.cpp:244]     Train net output #0: loss = 0.0142846 (* 1 = 0.0142846 loss)
I0403 07:06:06.618829  2705 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 07:06:18.019933  2705 solver.cpp:228] Iteration 6880, loss = 0.0501553
I0403 07:06:18.020258  2705 solver.cpp:244]     Train net output #0: loss = 0.0501554 (* 1 = 0.0501554 loss)
I0403 07:06:18.212668  2705 sgd_solver.cpp:106] Iteration 6880, lr = 5e-05
I0403 07:06:29.702386  2705 solver.cpp:228] Iteration 6896, loss = 0.020091
I0403 07:06:29.702486  2705 solver.cpp:244]     Train net output #0: loss = 0.0200911 (* 1 = 0.0200911 loss)
I0403 07:06:29.855139  2705 sgd_solver.cpp:106] Iteration 6896, lr = 5e-05
I0403 07:06:41.293098  2705 solver.cpp:228] Iteration 6912, loss = 0.0261004
I0403 07:06:41.293200  2705 solver.cpp:244]     Train net output #0: loss = 0.0261005 (* 1 = 0.0261005 loss)
I0403 07:06:41.471199  2705 sgd_solver.cpp:106] Iteration 6912, lr = 5e-05
I0403 07:06:52.883337  2705 solver.cpp:228] Iteration 6928, loss = 0.0253835
I0403 07:06:52.883635  2705 solver.cpp:244]     Train net output #0: loss = 0.0253836 (* 1 = 0.0253836 loss)
I0403 07:06:53.085430  2705 sgd_solver.cpp:106] Iteration 6928, lr = 5e-05
I0403 07:07:04.414898  2705 solver.cpp:228] Iteration 6944, loss = 0.0437812
I0403 07:07:04.414995  2705 solver.cpp:244]     Train net output #0: loss = 0.0437813 (* 1 = 0.0437813 loss)
I0403 07:07:04.594558  2705 sgd_solver.cpp:106] Iteration 6944, lr = 5e-05
I0403 07:07:16.071460  2705 solver.cpp:228] Iteration 6960, loss = 0.0101355
I0403 07:07:16.071573  2705 solver.cpp:244]     Train net output #0: loss = 0.0101356 (* 1 = 0.0101356 loss)
I0403 07:07:16.264822  2705 sgd_solver.cpp:106] Iteration 6960, lr = 5e-05
I0403 07:07:27.612619  2705 solver.cpp:228] Iteration 6976, loss = 0.0131067
I0403 07:07:27.612938  2705 solver.cpp:244]     Train net output #0: loss = 0.0131068 (* 1 = 0.0131068 loss)
I0403 07:07:27.816468  2705 sgd_solver.cpp:106] Iteration 6976, lr = 5e-05
I0403 07:07:39.165575  2705 solver.cpp:228] Iteration 6992, loss = 0.0266082
I0403 07:07:39.165688  2705 solver.cpp:244]     Train net output #0: loss = 0.0266083 (* 1 = 0.0266083 loss)
I0403 07:07:39.381258  2705 sgd_solver.cpp:106] Iteration 6992, lr = 5e-05
I0403 07:07:50.687830  2705 solver.cpp:228] Iteration 7008, loss = 0.0154446
I0403 07:07:50.687943  2705 solver.cpp:244]     Train net output #0: loss = 0.0154447 (* 1 = 0.0154447 loss)
I0403 07:07:50.875866  2705 sgd_solver.cpp:106] Iteration 7008, lr = 5e-05
I0403 07:08:02.357436  2705 solver.cpp:228] Iteration 7024, loss = 0.0698495
I0403 07:08:02.357733  2705 solver.cpp:244]     Train net output #0: loss = 0.0698496 (* 1 = 0.0698496 loss)
I0403 07:08:02.545795  2705 sgd_solver.cpp:106] Iteration 7024, lr = 5e-05
I0403 07:08:14.127449  2705 solver.cpp:228] Iteration 7040, loss = 0.108335
I0403 07:08:14.127544  2705 solver.cpp:244]     Train net output #0: loss = 0.108335 (* 1 = 0.108335 loss)
I0403 07:08:14.289439  2705 sgd_solver.cpp:106] Iteration 7040, lr = 5e-05
I0403 07:08:25.782704  2705 solver.cpp:228] Iteration 7056, loss = 0.0208774
I0403 07:08:25.782814  2705 solver.cpp:244]     Train net output #0: loss = 0.0208775 (* 1 = 0.0208775 loss)
I0403 07:08:25.966092  2705 sgd_solver.cpp:106] Iteration 7056, lr = 5e-05
I0403 07:08:37.260901  2705 solver.cpp:228] Iteration 7072, loss = 0.0337402
I0403 07:08:37.261211  2705 solver.cpp:244]     Train net output #0: loss = 0.0337403 (* 1 = 0.0337403 loss)
I0403 07:08:37.464582  2705 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 07:08:48.695346  2705 solver.cpp:228] Iteration 7088, loss = 0.0136157
I0403 07:08:48.695447  2705 solver.cpp:244]     Train net output #0: loss = 0.0136158 (* 1 = 0.0136158 loss)
I0403 07:08:48.875203  2705 sgd_solver.cpp:106] Iteration 7088, lr = 5e-05
I0403 07:09:00.231869  2705 solver.cpp:228] Iteration 7104, loss = 0.00866788
I0403 07:09:00.231981  2705 solver.cpp:244]     Train net output #0: loss = 0.00866797 (* 1 = 0.00866797 loss)
I0403 07:09:00.416458  2705 sgd_solver.cpp:106] Iteration 7104, lr = 5e-05
I0403 07:09:11.921458  2705 solver.cpp:228] Iteration 7120, loss = 0.0143101
I0403 07:09:11.921777  2705 solver.cpp:244]     Train net output #0: loss = 0.0143102 (* 1 = 0.0143102 loss)
I0403 07:09:12.102684  2705 sgd_solver.cpp:106] Iteration 7120, lr = 5e-05
I0403 07:09:23.337322  2705 solver.cpp:228] Iteration 7136, loss = 0.0476166
I0403 07:09:23.337431  2705 solver.cpp:244]     Train net output #0: loss = 0.0476167 (* 1 = 0.0476167 loss)
I0403 07:09:23.522593  2705 sgd_solver.cpp:106] Iteration 7136, lr = 5e-05
I0403 07:09:32.968103  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_7150.caffemodel
I0403 07:09:35.756716  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_7150.solverstate
I0403 07:09:37.675016  2705 solver.cpp:337] Iteration 7150, Testing net (#0)
I0403 07:10:26.098706  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939631
I0403 07:10:26.099058  2705 solver.cpp:404]     Test net output #1: loss = 0.216703 (* 1 = 0.216703 loss)
I0403 07:10:28.113466  2705 solver.cpp:228] Iteration 7152, loss = 0.00544098
I0403 07:10:28.113565  2705 solver.cpp:244]     Train net output #0: loss = 0.00544107 (* 1 = 0.00544107 loss)
I0403 07:10:28.262328  2705 sgd_solver.cpp:106] Iteration 7152, lr = 5e-05
I0403 07:10:39.816704  2705 solver.cpp:228] Iteration 7168, loss = 0.0127564
I0403 07:10:39.816817  2705 solver.cpp:244]     Train net output #0: loss = 0.0127565 (* 1 = 0.0127565 loss)
I0403 07:10:39.997002  2705 sgd_solver.cpp:106] Iteration 7168, lr = 5e-05
I0403 07:10:51.448715  2705 solver.cpp:228] Iteration 7184, loss = 0.0595837
I0403 07:10:51.448813  2705 solver.cpp:244]     Train net output #0: loss = 0.0595838 (* 1 = 0.0595838 loss)
I0403 07:10:51.597697  2705 sgd_solver.cpp:106] Iteration 7184, lr = 5e-05
I0403 07:11:03.019567  2705 solver.cpp:228] Iteration 7200, loss = 0.0130325
I0403 07:11:03.019872  2705 solver.cpp:244]     Train net output #0: loss = 0.0130326 (* 1 = 0.0130326 loss)
I0403 07:11:03.199686  2705 sgd_solver.cpp:106] Iteration 7200, lr = 5e-05
I0403 07:11:14.594470  2705 solver.cpp:228] Iteration 7216, loss = 0.0192185
I0403 07:11:14.594580  2705 solver.cpp:244]     Train net output #0: loss = 0.0192186 (* 1 = 0.0192186 loss)
I0403 07:11:14.775414  2705 sgd_solver.cpp:106] Iteration 7216, lr = 5e-05
I0403 07:11:26.230648  2705 solver.cpp:228] Iteration 7232, loss = 0.0162157
I0403 07:11:26.230763  2705 solver.cpp:244]     Train net output #0: loss = 0.0162158 (* 1 = 0.0162158 loss)
I0403 07:11:26.415951  2705 sgd_solver.cpp:106] Iteration 7232, lr = 5e-05
I0403 07:11:37.911087  2705 solver.cpp:228] Iteration 7248, loss = 0.120128
I0403 07:11:37.912410  2705 solver.cpp:244]     Train net output #0: loss = 0.120128 (* 1 = 0.120128 loss)
I0403 07:11:38.118876  2705 sgd_solver.cpp:106] Iteration 7248, lr = 5e-05
I0403 07:11:49.359122  2705 solver.cpp:228] Iteration 7264, loss = 0.0592142
I0403 07:11:49.359237  2705 solver.cpp:244]     Train net output #0: loss = 0.0592143 (* 1 = 0.0592143 loss)
I0403 07:11:49.588616  2705 sgd_solver.cpp:106] Iteration 7264, lr = 5e-05
I0403 07:12:00.959203  2705 solver.cpp:228] Iteration 7280, loss = 0.0117022
I0403 07:12:00.959311  2705 solver.cpp:244]     Train net output #0: loss = 0.0117023 (* 1 = 0.0117023 loss)
I0403 07:12:01.139035  2705 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 07:12:12.593760  2705 solver.cpp:228] Iteration 7296, loss = 0.0345633
I0403 07:12:12.594069  2705 solver.cpp:244]     Train net output #0: loss = 0.0345634 (* 1 = 0.0345634 loss)
I0403 07:12:12.746278  2705 sgd_solver.cpp:106] Iteration 7296, lr = 5e-05
I0403 07:12:24.383548  2705 solver.cpp:228] Iteration 7312, loss = 0.0450925
I0403 07:12:24.383648  2705 solver.cpp:244]     Train net output #0: loss = 0.0450926 (* 1 = 0.0450926 loss)
I0403 07:12:24.519558  2705 sgd_solver.cpp:106] Iteration 7312, lr = 5e-05
I0403 07:12:36.004279  2705 solver.cpp:228] Iteration 7328, loss = 0.0508739
I0403 07:12:36.004380  2705 solver.cpp:244]     Train net output #0: loss = 0.050874 (* 1 = 0.050874 loss)
I0403 07:12:36.181521  2705 sgd_solver.cpp:106] Iteration 7328, lr = 5e-05
I0403 07:12:47.591241  2705 solver.cpp:228] Iteration 7344, loss = 0.0377785
I0403 07:12:47.591552  2705 solver.cpp:244]     Train net output #0: loss = 0.0377786 (* 1 = 0.0377786 loss)
I0403 07:12:47.769079  2705 sgd_solver.cpp:106] Iteration 7344, lr = 5e-05
I0403 07:12:59.246922  2705 solver.cpp:228] Iteration 7360, loss = 0.0138187
I0403 07:12:59.247021  2705 solver.cpp:244]     Train net output #0: loss = 0.0138188 (* 1 = 0.0138188 loss)
I0403 07:12:59.404959  2705 sgd_solver.cpp:106] Iteration 7360, lr = 5e-05
I0403 07:13:10.753600  2705 solver.cpp:228] Iteration 7376, loss = 0.0375958
I0403 07:13:10.753713  2705 solver.cpp:244]     Train net output #0: loss = 0.0375959 (* 1 = 0.0375959 loss)
I0403 07:13:10.944144  2705 sgd_solver.cpp:106] Iteration 7376, lr = 5e-05
I0403 07:13:22.259071  2705 solver.cpp:228] Iteration 7392, loss = 0.0297953
I0403 07:13:22.259376  2705 solver.cpp:244]     Train net output #0: loss = 0.0297954 (* 1 = 0.0297954 loss)
I0403 07:13:22.418390  2705 sgd_solver.cpp:106] Iteration 7392, lr = 5e-05
I0403 07:13:33.842932  2705 solver.cpp:228] Iteration 7408, loss = 0.0104806
I0403 07:13:33.843042  2705 solver.cpp:244]     Train net output #0: loss = 0.0104807 (* 1 = 0.0104807 loss)
I0403 07:13:34.067878  2705 sgd_solver.cpp:106] Iteration 7408, lr = 5e-05
I0403 07:13:45.486954  2705 solver.cpp:228] Iteration 7424, loss = 0.0142263
I0403 07:13:45.487066  2705 solver.cpp:244]     Train net output #0: loss = 0.0142264 (* 1 = 0.0142264 loss)
I0403 07:13:45.721127  2705 sgd_solver.cpp:106] Iteration 7424, lr = 5e-05
I0403 07:13:57.121987  2705 solver.cpp:228] Iteration 7440, loss = 0.0252064
I0403 07:13:57.122303  2705 solver.cpp:244]     Train net output #0: loss = 0.0252065 (* 1 = 0.0252065 loss)
I0403 07:13:57.318461  2705 sgd_solver.cpp:106] Iteration 7440, lr = 5e-05
I0403 07:14:08.810871  2705 solver.cpp:228] Iteration 7456, loss = 0.0343677
I0403 07:14:08.810989  2705 solver.cpp:244]     Train net output #0: loss = 0.0343678 (* 1 = 0.0343678 loss)
I0403 07:14:09.006906  2705 sgd_solver.cpp:106] Iteration 7456, lr = 5e-05
I0403 07:14:20.408289  2705 solver.cpp:228] Iteration 7472, loss = 0.0216521
I0403 07:14:20.408401  2705 solver.cpp:244]     Train net output #0: loss = 0.0216522 (* 1 = 0.0216522 loss)
I0403 07:14:20.550434  2705 sgd_solver.cpp:106] Iteration 7472, lr = 5e-05
I0403 07:14:22.060433  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_7475.caffemodel
I0403 07:14:24.784139  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_7475.solverstate
I0403 07:14:26.622151  2705 solver.cpp:337] Iteration 7475, Testing net (#0)
I0403 07:15:15.063067  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939355
I0403 07:15:15.063387  2705 solver.cpp:404]     Test net output #1: loss = 0.21643 (* 1 = 0.21643 loss)
I0403 07:15:24.943117  2705 solver.cpp:228] Iteration 7488, loss = 0.052296
I0403 07:15:24.943214  2705 solver.cpp:244]     Train net output #0: loss = 0.0522961 (* 1 = 0.0522961 loss)
I0403 07:15:25.111490  2705 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 07:15:36.660728  2705 solver.cpp:228] Iteration 7504, loss = 0.0654795
I0403 07:15:36.660841  2705 solver.cpp:244]     Train net output #0: loss = 0.0654796 (* 1 = 0.0654796 loss)
I0403 07:15:36.848938  2705 sgd_solver.cpp:106] Iteration 7504, lr = 5e-05
I0403 07:15:48.263629  2705 solver.cpp:228] Iteration 7520, loss = 0.0345432
I0403 07:15:48.263913  2705 solver.cpp:244]     Train net output #0: loss = 0.0345433 (* 1 = 0.0345433 loss)
I0403 07:15:48.412149  2705 sgd_solver.cpp:106] Iteration 7520, lr = 5e-05
I0403 07:15:59.770418  2705 solver.cpp:228] Iteration 7536, loss = 0.0251444
I0403 07:15:59.770519  2705 solver.cpp:244]     Train net output #0: loss = 0.0251445 (* 1 = 0.0251445 loss)
I0403 07:15:59.961705  2705 sgd_solver.cpp:106] Iteration 7536, lr = 5e-05
I0403 07:16:11.274091  2705 solver.cpp:228] Iteration 7552, loss = 0.0115012
I0403 07:16:11.274193  2705 solver.cpp:244]     Train net output #0: loss = 0.0115013 (* 1 = 0.0115013 loss)
I0403 07:16:11.442824  2705 sgd_solver.cpp:106] Iteration 7552, lr = 5e-05
I0403 07:16:22.889717  2705 solver.cpp:228] Iteration 7568, loss = 0.0301676
I0403 07:16:22.890038  2705 solver.cpp:244]     Train net output #0: loss = 0.0301677 (* 1 = 0.0301677 loss)
I0403 07:16:23.032721  2705 sgd_solver.cpp:106] Iteration 7568, lr = 5e-05
I0403 07:16:34.536654  2705 solver.cpp:228] Iteration 7584, loss = 0.036305
I0403 07:16:34.536752  2705 solver.cpp:244]     Train net output #0: loss = 0.0363051 (* 1 = 0.0363051 loss)
I0403 07:16:34.705539  2705 sgd_solver.cpp:106] Iteration 7584, lr = 5e-05
I0403 07:16:46.151710  2705 solver.cpp:228] Iteration 7600, loss = 0.0325792
I0403 07:16:46.151810  2705 solver.cpp:244]     Train net output #0: loss = 0.0325793 (* 1 = 0.0325793 loss)
I0403 07:16:46.330178  2705 sgd_solver.cpp:106] Iteration 7600, lr = 5e-05
I0403 07:16:57.827718  2705 solver.cpp:228] Iteration 7616, loss = 0.0608959
I0403 07:16:57.828022  2705 solver.cpp:244]     Train net output #0: loss = 0.060896 (* 1 = 0.060896 loss)
I0403 07:16:58.010596  2705 sgd_solver.cpp:106] Iteration 7616, lr = 5e-05
I0403 07:17:09.509017  2705 solver.cpp:228] Iteration 7632, loss = 0.0199149
I0403 07:17:09.509117  2705 solver.cpp:244]     Train net output #0: loss = 0.019915 (* 1 = 0.019915 loss)
I0403 07:17:09.685894  2705 sgd_solver.cpp:106] Iteration 7632, lr = 5e-05
I0403 07:17:21.192237  2705 solver.cpp:228] Iteration 7648, loss = 0.0189646
I0403 07:17:21.192359  2705 solver.cpp:244]     Train net output #0: loss = 0.0189647 (* 1 = 0.0189647 loss)
I0403 07:17:21.379689  2705 sgd_solver.cpp:106] Iteration 7648, lr = 5e-05
I0403 07:17:32.673063  2705 solver.cpp:228] Iteration 7664, loss = 0.037332
I0403 07:17:32.673364  2705 solver.cpp:244]     Train net output #0: loss = 0.0373321 (* 1 = 0.0373321 loss)
I0403 07:17:32.885246  2705 sgd_solver.cpp:106] Iteration 7664, lr = 5e-05
I0403 07:17:44.373304  2705 solver.cpp:228] Iteration 7680, loss = 0.0535075
I0403 07:17:44.373417  2705 solver.cpp:244]     Train net output #0: loss = 0.0535076 (* 1 = 0.0535076 loss)
I0403 07:17:44.554419  2705 sgd_solver.cpp:106] Iteration 7680, lr = 5e-05
I0403 07:17:55.943924  2705 solver.cpp:228] Iteration 7696, loss = 0.00374625
I0403 07:17:55.944033  2705 solver.cpp:244]     Train net output #0: loss = 0.00374636 (* 1 = 0.00374636 loss)
I0403 07:17:56.150845  2705 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 07:18:07.593282  2705 solver.cpp:228] Iteration 7712, loss = 0.0145005
I0403 07:18:07.593606  2705 solver.cpp:244]     Train net output #0: loss = 0.0145006 (* 1 = 0.0145006 loss)
I0403 07:18:07.833472  2705 sgd_solver.cpp:106] Iteration 7712, lr = 5e-05
I0403 07:18:19.312829  2705 solver.cpp:228] Iteration 7728, loss = 0.06204
I0403 07:18:19.312930  2705 solver.cpp:244]     Train net output #0: loss = 0.0620401 (* 1 = 0.0620401 loss)
I0403 07:18:19.487011  2705 sgd_solver.cpp:106] Iteration 7728, lr = 5e-05
I0403 07:18:30.786816  2705 solver.cpp:228] Iteration 7744, loss = 0.0378159
I0403 07:18:30.786933  2705 solver.cpp:244]     Train net output #0: loss = 0.037816 (* 1 = 0.037816 loss)
I0403 07:18:30.987591  2705 sgd_solver.cpp:106] Iteration 7744, lr = 5e-05
I0403 07:18:42.399057  2705 solver.cpp:228] Iteration 7760, loss = 0.0148626
I0403 07:18:42.399382  2705 solver.cpp:244]     Train net output #0: loss = 0.0148628 (* 1 = 0.0148628 loss)
I0403 07:18:42.599074  2705 sgd_solver.cpp:106] Iteration 7760, lr = 5e-05
I0403 07:18:53.862771  2705 solver.cpp:228] Iteration 7776, loss = 0.0757362
I0403 07:18:53.862879  2705 solver.cpp:244]     Train net output #0: loss = 0.0757363 (* 1 = 0.0757363 loss)
I0403 07:18:54.057117  2705 sgd_solver.cpp:106] Iteration 7776, lr = 5e-05
I0403 07:19:05.398737  2705 solver.cpp:228] Iteration 7792, loss = 0.0614398
I0403 07:19:05.398838  2705 solver.cpp:244]     Train net output #0: loss = 0.0614399 (* 1 = 0.0614399 loss)
I0403 07:19:05.567823  2705 sgd_solver.cpp:106] Iteration 7792, lr = 5e-05
I0403 07:19:10.626044  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_7800.caffemodel
I0403 07:19:13.360910  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_7800.solverstate
I0403 07:19:15.205958  2705 solver.cpp:337] Iteration 7800, Testing net (#0)
I0403 07:20:03.632977  2705 solver.cpp:404]     Test net output #0: accuracy = 0.938525
I0403 07:20:03.633276  2705 solver.cpp:404]     Test net output #1: loss = 0.21831 (* 1 = 0.21831 loss)
I0403 07:20:09.890666  2705 solver.cpp:228] Iteration 7808, loss = 0.0137999
I0403 07:20:09.890777  2705 solver.cpp:244]     Train net output #0: loss = 0.0138 (* 1 = 0.0138 loss)
I0403 07:20:10.095340  2705 sgd_solver.cpp:106] Iteration 7808, lr = 5e-05
I0403 07:20:21.412672  2705 solver.cpp:228] Iteration 7824, loss = 0.0446954
I0403 07:20:21.412783  2705 solver.cpp:244]     Train net output #0: loss = 0.0446955 (* 1 = 0.0446955 loss)
I0403 07:20:21.593389  2705 sgd_solver.cpp:106] Iteration 7824, lr = 5e-05
I0403 07:20:32.930964  2705 solver.cpp:228] Iteration 7840, loss = 0.0641573
I0403 07:20:32.931061  2705 solver.cpp:244]     Train net output #0: loss = 0.0641574 (* 1 = 0.0641574 loss)
I0403 07:20:33.094810  2705 sgd_solver.cpp:106] Iteration 7840, lr = 5e-05
I0403 07:20:44.431253  2705 solver.cpp:228] Iteration 7856, loss = 0.0193034
I0403 07:20:44.431577  2705 solver.cpp:244]     Train net output #0: loss = 0.0193035 (* 1 = 0.0193035 loss)
I0403 07:20:44.612248  2705 sgd_solver.cpp:106] Iteration 7856, lr = 5e-05
I0403 07:20:55.973366  2705 solver.cpp:228] Iteration 7872, loss = 0.00509612
I0403 07:20:55.973464  2705 solver.cpp:244]     Train net output #0: loss = 0.00509623 (* 1 = 0.00509623 loss)
I0403 07:20:56.111296  2705 sgd_solver.cpp:106] Iteration 7872, lr = 5e-05
I0403 07:21:07.499745  2705 solver.cpp:228] Iteration 7888, loss = 0.0186967
I0403 07:21:07.499845  2705 solver.cpp:244]     Train net output #0: loss = 0.0186968 (* 1 = 0.0186968 loss)
I0403 07:21:07.674252  2705 sgd_solver.cpp:106] Iteration 7888, lr = 5e-05
I0403 07:21:19.239526  2705 solver.cpp:228] Iteration 7904, loss = 0.0129006
I0403 07:21:19.239825  2705 solver.cpp:244]     Train net output #0: loss = 0.0129007 (* 1 = 0.0129007 loss)
I0403 07:21:19.378192  2705 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 07:21:30.869341  2705 solver.cpp:228] Iteration 7920, loss = 0.0421197
I0403 07:21:30.869453  2705 solver.cpp:244]     Train net output #0: loss = 0.0421198 (* 1 = 0.0421198 loss)
I0403 07:21:31.054764  2705 sgd_solver.cpp:106] Iteration 7920, lr = 5e-05
I0403 07:21:42.490959  2705 solver.cpp:228] Iteration 7936, loss = 0.0196526
I0403 07:21:42.491067  2705 solver.cpp:244]     Train net output #0: loss = 0.0196527 (* 1 = 0.0196527 loss)
I0403 07:21:42.682076  2705 sgd_solver.cpp:106] Iteration 7936, lr = 5e-05
I0403 07:21:54.297971  2705 solver.cpp:228] Iteration 7952, loss = 0.0288083
I0403 07:21:54.298267  2705 solver.cpp:244]     Train net output #0: loss = 0.0288084 (* 1 = 0.0288084 loss)
I0403 07:21:54.468812  2705 sgd_solver.cpp:106] Iteration 7952, lr = 5e-05
I0403 07:22:06.024772  2705 solver.cpp:228] Iteration 7968, loss = 0.0227657
I0403 07:22:06.024881  2705 solver.cpp:244]     Train net output #0: loss = 0.0227658 (* 1 = 0.0227658 loss)
I0403 07:22:06.206187  2705 sgd_solver.cpp:106] Iteration 7968, lr = 5e-05
I0403 07:22:17.523234  2705 solver.cpp:228] Iteration 7984, loss = 0.0620233
I0403 07:22:17.523340  2705 solver.cpp:244]     Train net output #0: loss = 0.0620234 (* 1 = 0.0620234 loss)
I0403 07:22:17.676009  2705 sgd_solver.cpp:106] Iteration 7984, lr = 5e-05
I0403 07:22:29.077576  2705 solver.cpp:228] Iteration 8000, loss = 0.0530731
I0403 07:22:29.077925  2705 solver.cpp:244]     Train net output #0: loss = 0.0530732 (* 1 = 0.0530732 loss)
I0403 07:22:29.311754  2705 sgd_solver.cpp:106] Iteration 8000, lr = 5e-05
I0403 07:22:40.680820  2705 solver.cpp:228] Iteration 8016, loss = 0.116703
I0403 07:22:40.680933  2705 solver.cpp:244]     Train net output #0: loss = 0.116703 (* 1 = 0.116703 loss)
I0403 07:22:40.875686  2705 sgd_solver.cpp:106] Iteration 8016, lr = 5e-05
I0403 07:22:52.182453  2705 solver.cpp:228] Iteration 8032, loss = 0.0193102
I0403 07:22:52.182554  2705 solver.cpp:244]     Train net output #0: loss = 0.0193103 (* 1 = 0.0193103 loss)
I0403 07:22:52.333194  2705 sgd_solver.cpp:106] Iteration 8032, lr = 5e-05
I0403 07:23:03.889829  2705 solver.cpp:228] Iteration 8048, loss = 0.0371009
I0403 07:23:03.890132  2705 solver.cpp:244]     Train net output #0: loss = 0.037101 (* 1 = 0.037101 loss)
I0403 07:23:04.060204  2705 sgd_solver.cpp:106] Iteration 8048, lr = 5e-05
I0403 07:23:15.462182  2705 solver.cpp:228] Iteration 8064, loss = 0.0702633
I0403 07:23:15.462281  2705 solver.cpp:244]     Train net output #0: loss = 0.0702634 (* 1 = 0.0702634 loss)
I0403 07:23:15.641170  2705 sgd_solver.cpp:106] Iteration 8064, lr = 5e-05
I0403 07:23:27.067936  2705 solver.cpp:228] Iteration 8080, loss = 0.0249089
I0403 07:23:27.068033  2705 solver.cpp:244]     Train net output #0: loss = 0.024909 (* 1 = 0.024909 loss)
I0403 07:23:27.246592  2705 sgd_solver.cpp:106] Iteration 8080, lr = 5e-05
I0403 07:23:38.797178  2705 solver.cpp:228] Iteration 8096, loss = 0.0382839
I0403 07:23:38.797492  2705 solver.cpp:244]     Train net output #0: loss = 0.038284 (* 1 = 0.038284 loss)
I0403 07:23:39.004840  2705 sgd_solver.cpp:106] Iteration 8096, lr = 5e-05
I0403 07:23:50.410840  2705 solver.cpp:228] Iteration 8112, loss = 0.090198
I0403 07:23:50.410954  2705 solver.cpp:244]     Train net output #0: loss = 0.0901982 (* 1 = 0.0901982 loss)
I0403 07:23:50.643180  2705 sgd_solver.cpp:106] Iteration 8112, lr = 5e-05
I0403 07:23:59.291307  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_8125.caffemodel
I0403 07:24:02.066915  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_8125.solverstate
I0403 07:24:03.868439  2705 solver.cpp:337] Iteration 8125, Testing net (#0)
I0403 07:24:52.290139  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939125
I0403 07:24:52.290477  2705 solver.cpp:404]     Test net output #1: loss = 0.218293 (* 1 = 0.218293 loss)
I0403 07:24:54.977243  2705 solver.cpp:228] Iteration 8128, loss = 0.0280088
I0403 07:24:54.977355  2705 solver.cpp:244]     Train net output #0: loss = 0.0280089 (* 1 = 0.0280089 loss)
I0403 07:24:55.172340  2705 sgd_solver.cpp:106] Iteration 8128, lr = 5e-05
I0403 07:25:06.479616  2705 solver.cpp:228] Iteration 8144, loss = 0.031777
I0403 07:25:06.479727  2705 solver.cpp:244]     Train net output #0: loss = 0.0317771 (* 1 = 0.0317771 loss)
I0403 07:25:06.689473  2705 sgd_solver.cpp:106] Iteration 8144, lr = 5e-05
I0403 07:25:18.313124  2705 solver.cpp:228] Iteration 8160, loss = 0.0364573
I0403 07:25:18.313225  2705 solver.cpp:244]     Train net output #0: loss = 0.0364574 (* 1 = 0.0364574 loss)
I0403 07:25:18.431794  2705 sgd_solver.cpp:106] Iteration 8160, lr = 5e-05
I0403 07:25:29.852128  2705 solver.cpp:228] Iteration 8176, loss = 0.0184815
I0403 07:25:29.852443  2705 solver.cpp:244]     Train net output #0: loss = 0.0184816 (* 1 = 0.0184816 loss)
I0403 07:25:30.036799  2705 sgd_solver.cpp:106] Iteration 8176, lr = 5e-05
I0403 07:25:41.550539  2705 solver.cpp:228] Iteration 8192, loss = 0.0155023
I0403 07:25:41.550652  2705 solver.cpp:244]     Train net output #0: loss = 0.0155024 (* 1 = 0.0155024 loss)
I0403 07:25:41.743883  2705 sgd_solver.cpp:106] Iteration 8192, lr = 5e-05
I0403 07:25:53.130748  2705 solver.cpp:228] Iteration 8208, loss = 0.0560465
I0403 07:25:53.130862  2705 solver.cpp:244]     Train net output #0: loss = 0.0560467 (* 1 = 0.0560467 loss)
I0403 07:25:53.319165  2705 sgd_solver.cpp:106] Iteration 8208, lr = 5e-05
I0403 07:26:04.865203  2705 solver.cpp:228] Iteration 8224, loss = 0.0373804
I0403 07:26:04.865521  2705 solver.cpp:244]     Train net output #0: loss = 0.0373806 (* 1 = 0.0373806 loss)
I0403 07:26:05.092234  2705 sgd_solver.cpp:106] Iteration 8224, lr = 5e-05
I0403 07:26:16.714334  2705 solver.cpp:228] Iteration 8240, loss = 0.0726558
I0403 07:26:16.714437  2705 solver.cpp:244]     Train net output #0: loss = 0.0726559 (* 1 = 0.0726559 loss)
I0403 07:26:16.892433  2705 sgd_solver.cpp:106] Iteration 8240, lr = 5e-05
I0403 07:26:28.315856  2705 solver.cpp:228] Iteration 8256, loss = 0.00414173
I0403 07:26:28.315956  2705 solver.cpp:244]     Train net output #0: loss = 0.00414186 (* 1 = 0.00414186 loss)
I0403 07:26:28.495510  2705 sgd_solver.cpp:106] Iteration 8256, lr = 5e-05
I0403 07:26:39.852052  2705 solver.cpp:228] Iteration 8272, loss = 0.036565
I0403 07:26:39.852394  2705 solver.cpp:244]     Train net output #0: loss = 0.0365651 (* 1 = 0.0365651 loss)
I0403 07:26:40.079849  2705 sgd_solver.cpp:106] Iteration 8272, lr = 5e-05
I0403 07:26:51.504025  2705 solver.cpp:228] Iteration 8288, loss = 0.0444296
I0403 07:26:51.504135  2705 solver.cpp:244]     Train net output #0: loss = 0.0444298 (* 1 = 0.0444298 loss)
I0403 07:26:51.701138  2705 sgd_solver.cpp:106] Iteration 8288, lr = 5e-05
I0403 07:27:03.180646  2705 solver.cpp:228] Iteration 8304, loss = 0.0324996
I0403 07:27:03.180745  2705 solver.cpp:244]     Train net output #0: loss = 0.0324997 (* 1 = 0.0324997 loss)
I0403 07:27:03.330693  2705 sgd_solver.cpp:106] Iteration 8304, lr = 5e-05
I0403 07:27:14.898200  2705 solver.cpp:228] Iteration 8320, loss = 0.0464365
I0403 07:27:14.898488  2705 solver.cpp:244]     Train net output #0: loss = 0.0464367 (* 1 = 0.0464367 loss)
I0403 07:27:15.067389  2705 sgd_solver.cpp:106] Iteration 8320, lr = 5e-05
I0403 07:27:26.584038  2705 solver.cpp:228] Iteration 8336, loss = 0.00970331
I0403 07:27:26.584146  2705 solver.cpp:244]     Train net output #0: loss = 0.00970343 (* 1 = 0.00970343 loss)
I0403 07:27:26.775619  2705 sgd_solver.cpp:106] Iteration 8336, lr = 5e-05
I0403 07:27:38.172374  2705 solver.cpp:228] Iteration 8352, loss = 0.0655669
I0403 07:27:38.172474  2705 solver.cpp:244]     Train net output #0: loss = 0.065567 (* 1 = 0.065567 loss)
I0403 07:27:38.349352  2705 sgd_solver.cpp:106] Iteration 8352, lr = 5e-05
I0403 07:27:49.748335  2705 solver.cpp:228] Iteration 8368, loss = 0.0739098
I0403 07:27:49.748643  2705 solver.cpp:244]     Train net output #0: loss = 0.0739099 (* 1 = 0.0739099 loss)
I0403 07:27:49.924645  2705 sgd_solver.cpp:106] Iteration 8368, lr = 5e-05
I0403 07:28:01.331307  2705 solver.cpp:228] Iteration 8384, loss = 0.0635236
I0403 07:28:01.331413  2705 solver.cpp:244]     Train net output #0: loss = 0.0635237 (* 1 = 0.0635237 loss)
I0403 07:28:01.508046  2705 sgd_solver.cpp:106] Iteration 8384, lr = 5e-05
I0403 07:28:12.998733  2705 solver.cpp:228] Iteration 8400, loss = 0.0126608
I0403 07:28:12.998831  2705 solver.cpp:244]     Train net output #0: loss = 0.012661 (* 1 = 0.012661 loss)
I0403 07:28:13.178397  2705 sgd_solver.cpp:106] Iteration 8400, lr = 5e-05
I0403 07:28:24.590881  2705 solver.cpp:228] Iteration 8416, loss = 0.0162789
I0403 07:28:24.591192  2705 solver.cpp:244]     Train net output #0: loss = 0.0162791 (* 1 = 0.0162791 loss)
I0403 07:28:24.788722  2705 sgd_solver.cpp:106] Iteration 8416, lr = 5e-05
I0403 07:28:36.369294  2705 solver.cpp:228] Iteration 8432, loss = 0.0141194
I0403 07:28:36.369407  2705 solver.cpp:244]     Train net output #0: loss = 0.0141195 (* 1 = 0.0141195 loss)
I0403 07:28:36.549180  2705 sgd_solver.cpp:106] Iteration 8432, lr = 5e-05
I0403 07:28:47.816025  2705 solver.cpp:228] Iteration 8448, loss = 0.0161625
I0403 07:28:47.816138  2705 solver.cpp:244]     Train net output #0: loss = 0.0161626 (* 1 = 0.0161626 loss)
I0403 07:28:48.031600  2705 sgd_solver.cpp:106] Iteration 8448, lr = 5e-05
I0403 07:28:48.749853  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_8450.caffemodel
I0403 07:28:51.490191  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_8450.solverstate
I0403 07:28:53.360015  2705 solver.cpp:337] Iteration 8450, Testing net (#0)
I0403 07:29:41.787197  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939032
I0403 07:29:41.787541  2705 solver.cpp:404]     Test net output #1: loss = 0.217443 (* 1 = 0.217443 loss)
I0403 07:29:52.516476  2705 solver.cpp:228] Iteration 8464, loss = 0.0159456
I0403 07:29:52.516587  2705 solver.cpp:244]     Train net output #0: loss = 0.0159457 (* 1 = 0.0159457 loss)
I0403 07:29:52.698146  2705 sgd_solver.cpp:106] Iteration 8464, lr = 5e-05
I0403 07:30:04.075919  2705 solver.cpp:228] Iteration 8480, loss = 0.0202924
I0403 07:30:04.076019  2705 solver.cpp:244]     Train net output #0: loss = 0.0202926 (* 1 = 0.0202926 loss)
I0403 07:30:04.245595  2705 sgd_solver.cpp:106] Iteration 8480, lr = 5e-05
I0403 07:30:15.750000  2705 solver.cpp:228] Iteration 8496, loss = 0.0140645
I0403 07:30:15.750324  2705 solver.cpp:244]     Train net output #0: loss = 0.0140646 (* 1 = 0.0140646 loss)
I0403 07:30:15.928786  2705 sgd_solver.cpp:106] Iteration 8496, lr = 5e-05
I0403 07:30:27.195474  2705 solver.cpp:228] Iteration 8512, loss = 0.00729408
I0403 07:30:27.195590  2705 solver.cpp:244]     Train net output #0: loss = 0.00729419 (* 1 = 0.00729419 loss)
I0403 07:30:27.392287  2705 sgd_solver.cpp:106] Iteration 8512, lr = 5e-05
I0403 07:30:38.689342  2705 solver.cpp:228] Iteration 8528, loss = 0.0726791
I0403 07:30:38.689440  2705 solver.cpp:244]     Train net output #0: loss = 0.0726792 (* 1 = 0.0726792 loss)
I0403 07:30:38.877709  2705 sgd_solver.cpp:106] Iteration 8528, lr = 5e-05
I0403 07:30:50.084295  2705 solver.cpp:228] Iteration 8544, loss = 0.0218081
I0403 07:30:50.084595  2705 solver.cpp:244]     Train net output #0: loss = 0.0218082 (* 1 = 0.0218082 loss)
I0403 07:30:50.285573  2705 sgd_solver.cpp:106] Iteration 8544, lr = 5e-05
I0403 07:31:01.749300  2705 solver.cpp:228] Iteration 8560, loss = 0.0271377
I0403 07:31:01.749415  2705 solver.cpp:244]     Train net output #0: loss = 0.0271379 (* 1 = 0.0271379 loss)
I0403 07:31:01.934696  2705 sgd_solver.cpp:106] Iteration 8560, lr = 5e-05
I0403 07:31:13.197621  2705 solver.cpp:228] Iteration 8576, loss = 0.0553641
I0403 07:31:13.197731  2705 solver.cpp:244]     Train net output #0: loss = 0.0553642 (* 1 = 0.0553642 loss)
I0403 07:31:13.391824  2705 sgd_solver.cpp:106] Iteration 8576, lr = 5e-05
I0403 07:31:24.864199  2705 solver.cpp:228] Iteration 8592, loss = 0.102438
I0403 07:31:24.864506  2705 solver.cpp:244]     Train net output #0: loss = 0.102438 (* 1 = 0.102438 loss)
I0403 07:31:25.066582  2705 sgd_solver.cpp:106] Iteration 8592, lr = 5e-05
I0403 07:31:36.436959  2705 solver.cpp:228] Iteration 8608, loss = 0.0422401
I0403 07:31:36.437067  2705 solver.cpp:244]     Train net output #0: loss = 0.0422402 (* 1 = 0.0422402 loss)
I0403 07:31:36.599097  2705 sgd_solver.cpp:106] Iteration 8608, lr = 5e-05
I0403 07:31:48.139556  2705 solver.cpp:228] Iteration 8624, loss = 0.0432436
I0403 07:31:48.139652  2705 solver.cpp:244]     Train net output #0: loss = 0.0432437 (* 1 = 0.0432437 loss)
I0403 07:31:48.317399  2705 sgd_solver.cpp:106] Iteration 8624, lr = 5e-05
I0403 07:31:59.637550  2705 solver.cpp:228] Iteration 8640, loss = 0.0274568
I0403 07:31:59.637859  2705 solver.cpp:244]     Train net output #0: loss = 0.0274569 (* 1 = 0.0274569 loss)
I0403 07:31:59.843786  2705 sgd_solver.cpp:106] Iteration 8640, lr = 5e-05
I0403 07:32:11.304409  2705 solver.cpp:228] Iteration 8656, loss = 0.0205336
I0403 07:32:11.304510  2705 solver.cpp:244]     Train net output #0: loss = 0.0205337 (* 1 = 0.0205337 loss)
I0403 07:32:11.481021  2705 sgd_solver.cpp:106] Iteration 8656, lr = 5e-05
I0403 07:32:22.936805  2705 solver.cpp:228] Iteration 8672, loss = 0.0216394
I0403 07:32:22.936914  2705 solver.cpp:244]     Train net output #0: loss = 0.0216395 (* 1 = 0.0216395 loss)
I0403 07:32:23.137454  2705 sgd_solver.cpp:106] Iteration 8672, lr = 5e-05
I0403 07:32:34.536892  2705 solver.cpp:228] Iteration 8688, loss = 0.0226667
I0403 07:32:34.537225  2705 solver.cpp:244]     Train net output #0: loss = 0.0226668 (* 1 = 0.0226668 loss)
I0403 07:32:34.693198  2705 sgd_solver.cpp:106] Iteration 8688, lr = 5e-05
I0403 07:32:46.280022  2705 solver.cpp:228] Iteration 8704, loss = 0.0248049
I0403 07:32:46.280122  2705 solver.cpp:244]     Train net output #0: loss = 0.0248051 (* 1 = 0.0248051 loss)
I0403 07:32:46.456382  2705 sgd_solver.cpp:106] Iteration 8704, lr = 5e-05
I0403 07:32:57.872232  2705 solver.cpp:228] Iteration 8720, loss = 0.0208166
I0403 07:32:57.872356  2705 solver.cpp:244]     Train net output #0: loss = 0.0208168 (* 1 = 0.0208168 loss)
I0403 07:32:58.118398  2705 sgd_solver.cpp:106] Iteration 8720, lr = 5e-05
I0403 07:33:09.536711  2705 solver.cpp:228] Iteration 8736, loss = 0.019646
I0403 07:33:09.537019  2705 solver.cpp:244]     Train net output #0: loss = 0.0196461 (* 1 = 0.0196461 loss)
I0403 07:33:09.703932  2705 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 07:33:21.095515  2705 solver.cpp:228] Iteration 8752, loss = 0.0532639
I0403 07:33:21.095613  2705 solver.cpp:244]     Train net output #0: loss = 0.0532641 (* 1 = 0.0532641 loss)
I0403 07:33:21.274088  2705 sgd_solver.cpp:106] Iteration 8752, lr = 5e-05
I0403 07:33:32.527175  2705 solver.cpp:228] Iteration 8768, loss = 0.0397837
I0403 07:33:32.527282  2705 solver.cpp:244]     Train net output #0: loss = 0.0397839 (* 1 = 0.0397839 loss)
I0403 07:33:32.708500  2705 sgd_solver.cpp:106] Iteration 8768, lr = 5e-05
I0403 07:33:37.121891  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_8775.caffemodel
I0403 07:33:39.988287  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_8775.solverstate
I0403 07:33:41.901746  2705 solver.cpp:337] Iteration 8775, Testing net (#0)
I0403 07:34:30.314311  2705 solver.cpp:404]     Test net output #0: accuracy = 0.940046
I0403 07:34:30.314623  2705 solver.cpp:404]     Test net output #1: loss = 0.216568 (* 1 = 0.216568 loss)
I0403 07:34:37.421782  2705 solver.cpp:228] Iteration 8784, loss = 0.123318
I0403 07:34:37.421893  2705 solver.cpp:244]     Train net output #0: loss = 0.123318 (* 1 = 0.123318 loss)
I0403 07:34:37.643409  2705 sgd_solver.cpp:106] Iteration 8784, lr = 5e-05
I0403 07:34:49.185912  2705 solver.cpp:228] Iteration 8800, loss = 0.0768018
I0403 07:34:49.186013  2705 solver.cpp:244]     Train net output #0: loss = 0.076802 (* 1 = 0.076802 loss)
I0403 07:34:49.358012  2705 sgd_solver.cpp:106] Iteration 8800, lr = 5e-05
I0403 07:35:01.257447  2705 solver.cpp:228] Iteration 8816, loss = 0.0660607
I0403 07:35:01.257761  2705 solver.cpp:244]     Train net output #0: loss = 0.0660608 (* 1 = 0.0660608 loss)
I0403 07:35:01.486546  2705 sgd_solver.cpp:106] Iteration 8816, lr = 5e-05
I0403 07:35:13.005889  2705 solver.cpp:228] Iteration 8832, loss = 0.00816415
I0403 07:35:13.006000  2705 solver.cpp:244]     Train net output #0: loss = 0.00816429 (* 1 = 0.00816429 loss)
I0403 07:35:13.205001  2705 sgd_solver.cpp:106] Iteration 8832, lr = 5e-05
I0403 07:35:24.496891  2705 solver.cpp:228] Iteration 8848, loss = 0.0074865
I0403 07:35:24.497004  2705 solver.cpp:244]     Train net output #0: loss = 0.00748663 (* 1 = 0.00748663 loss)
I0403 07:35:24.680923  2705 sgd_solver.cpp:106] Iteration 8848, lr = 5e-05
I0403 07:35:36.233062  2705 solver.cpp:228] Iteration 8864, loss = 0.0183487
I0403 07:35:36.233386  2705 solver.cpp:244]     Train net output #0: loss = 0.0183488 (* 1 = 0.0183488 loss)
I0403 07:35:36.443795  2705 sgd_solver.cpp:106] Iteration 8864, lr = 5e-05
I0403 07:35:47.844436  2705 solver.cpp:228] Iteration 8880, loss = 0.03794
I0403 07:35:47.844537  2705 solver.cpp:244]     Train net output #0: loss = 0.0379401 (* 1 = 0.0379401 loss)
I0403 07:35:48.052103  2705 sgd_solver.cpp:106] Iteration 8880, lr = 5e-05
I0403 07:35:59.321600  2705 solver.cpp:228] Iteration 8896, loss = 0.0296327
I0403 07:35:59.321714  2705 solver.cpp:244]     Train net output #0: loss = 0.0296328 (* 1 = 0.0296328 loss)
I0403 07:35:59.527385  2705 sgd_solver.cpp:106] Iteration 8896, lr = 5e-05
I0403 07:36:10.984975  2705 solver.cpp:228] Iteration 8912, loss = 0.0158588
I0403 07:36:10.985316  2705 solver.cpp:244]     Train net output #0: loss = 0.0158589 (* 1 = 0.0158589 loss)
I0403 07:36:11.166491  2705 sgd_solver.cpp:106] Iteration 8912, lr = 5e-05
I0403 07:36:22.473851  2705 solver.cpp:228] Iteration 8928, loss = 0.0292027
I0403 07:36:22.473950  2705 solver.cpp:244]     Train net output #0: loss = 0.0292029 (* 1 = 0.0292029 loss)
I0403 07:36:22.627250  2705 sgd_solver.cpp:106] Iteration 8928, lr = 5e-05
I0403 07:36:34.228274  2705 solver.cpp:228] Iteration 8944, loss = 0.010478
I0403 07:36:34.228375  2705 solver.cpp:244]     Train net output #0: loss = 0.0104781 (* 1 = 0.0104781 loss)
I0403 07:36:34.406497  2705 sgd_solver.cpp:106] Iteration 8944, lr = 5e-05
I0403 07:36:45.730329  2705 solver.cpp:228] Iteration 8960, loss = 0.0319296
I0403 07:36:45.730654  2705 solver.cpp:244]     Train net output #0: loss = 0.0319297 (* 1 = 0.0319297 loss)
I0403 07:36:45.919015  2705 sgd_solver.cpp:106] Iteration 8960, lr = 5e-05
I0403 07:36:57.531002  2705 solver.cpp:228] Iteration 8976, loss = 0.0501676
I0403 07:36:57.531114  2705 solver.cpp:244]     Train net output #0: loss = 0.0501677 (* 1 = 0.0501677 loss)
I0403 07:36:57.737344  2705 sgd_solver.cpp:106] Iteration 8976, lr = 5e-05
I0403 07:37:09.231004  2705 solver.cpp:228] Iteration 8992, loss = 0.0851935
I0403 07:37:09.231109  2705 solver.cpp:244]     Train net output #0: loss = 0.0851937 (* 1 = 0.0851937 loss)
I0403 07:37:09.397625  2705 sgd_solver.cpp:106] Iteration 8992, lr = 5e-05
I0403 07:37:20.825956  2705 solver.cpp:228] Iteration 9008, loss = 0.0137874
I0403 07:37:20.826264  2705 solver.cpp:244]     Train net output #0: loss = 0.0137875 (* 1 = 0.0137875 loss)
I0403 07:37:21.004427  2705 sgd_solver.cpp:106] Iteration 9008, lr = 5e-05
I0403 07:37:32.288669  2705 solver.cpp:228] Iteration 9024, loss = 0.0803356
I0403 07:37:32.288772  2705 solver.cpp:244]     Train net output #0: loss = 0.0803357 (* 1 = 0.0803357 loss)
I0403 07:37:32.448626  2705 sgd_solver.cpp:106] Iteration 9024, lr = 5e-05
I0403 07:37:43.853361  2705 solver.cpp:228] Iteration 9040, loss = 0.0153062
I0403 07:37:43.853459  2705 solver.cpp:244]     Train net output #0: loss = 0.0153063 (* 1 = 0.0153063 loss)
I0403 07:37:44.025957  2705 sgd_solver.cpp:106] Iteration 9040, lr = 5e-05
I0403 07:37:55.592185  2705 solver.cpp:228] Iteration 9056, loss = 0.0322687
I0403 07:37:55.592491  2705 solver.cpp:244]     Train net output #0: loss = 0.0322688 (* 1 = 0.0322688 loss)
I0403 07:37:55.767343  2705 sgd_solver.cpp:106] Iteration 9056, lr = 5e-05
I0403 07:38:07.232866  2705 solver.cpp:228] Iteration 9072, loss = 0.024131
I0403 07:38:07.232962  2705 solver.cpp:244]     Train net output #0: loss = 0.0241312 (* 1 = 0.0241312 loss)
I0403 07:38:07.387292  2705 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 07:38:18.868721  2705 solver.cpp:228] Iteration 9088, loss = 0.030285
I0403 07:38:18.868819  2705 solver.cpp:244]     Train net output #0: loss = 0.0302852 (* 1 = 0.0302852 loss)
I0403 07:38:19.046941  2705 sgd_solver.cpp:106] Iteration 9088, lr = 5e-05
I0403 07:38:26.967036  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9100.caffemodel
I0403 07:38:29.722935  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9100.solverstate
I0403 07:38:31.619357  2705 solver.cpp:337] Iteration 9100, Testing net (#0)
I0403 07:39:20.045444  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939309
I0403 07:39:20.045783  2705 solver.cpp:404]     Test net output #1: loss = 0.218058 (* 1 = 0.218058 loss)
I0403 07:39:23.434237  2705 solver.cpp:228] Iteration 9104, loss = 0.0153035
I0403 07:39:23.434360  2705 solver.cpp:244]     Train net output #0: loss = 0.0153037 (* 1 = 0.0153037 loss)
I0403 07:39:23.631707  2705 sgd_solver.cpp:106] Iteration 9104, lr = 5e-05
I0403 07:39:35.001058  2705 solver.cpp:228] Iteration 9120, loss = 0.0312756
I0403 07:39:35.001169  2705 solver.cpp:244]     Train net output #0: loss = 0.0312757 (* 1 = 0.0312757 loss)
I0403 07:39:35.224325  2705 sgd_solver.cpp:106] Iteration 9120, lr = 5e-05
I0403 07:39:46.712055  2705 solver.cpp:228] Iteration 9136, loss = 0.047115
I0403 07:39:46.712153  2705 solver.cpp:244]     Train net output #0: loss = 0.0471151 (* 1 = 0.0471151 loss)
I0403 07:39:46.889408  2705 sgd_solver.cpp:106] Iteration 9136, lr = 5e-05
I0403 07:39:58.315673  2705 solver.cpp:228] Iteration 9152, loss = 0.0402359
I0403 07:39:58.315975  2705 solver.cpp:244]     Train net output #0: loss = 0.040236 (* 1 = 0.040236 loss)
I0403 07:39:58.493537  2705 sgd_solver.cpp:106] Iteration 9152, lr = 5e-05
I0403 07:40:09.897778  2705 solver.cpp:228] Iteration 9168, loss = 0.0684036
I0403 07:40:09.897891  2705 solver.cpp:244]     Train net output #0: loss = 0.0684038 (* 1 = 0.0684038 loss)
I0403 07:40:10.077883  2705 sgd_solver.cpp:106] Iteration 9168, lr = 5e-05
I0403 07:40:21.487335  2705 solver.cpp:228] Iteration 9184, loss = 0.013007
I0403 07:40:21.487452  2705 solver.cpp:244]     Train net output #0: loss = 0.0130071 (* 1 = 0.0130071 loss)
I0403 07:40:21.676386  2705 sgd_solver.cpp:106] Iteration 9184, lr = 5e-05
I0403 07:40:33.052520  2705 solver.cpp:228] Iteration 9200, loss = 0.0460377
I0403 07:40:33.052835  2705 solver.cpp:244]     Train net output #0: loss = 0.0460379 (* 1 = 0.0460379 loss)
I0403 07:40:33.302425  2705 sgd_solver.cpp:106] Iteration 9200, lr = 5e-05
I0403 07:40:44.568769  2705 solver.cpp:228] Iteration 9216, loss = 0.0327716
I0403 07:40:44.568877  2705 solver.cpp:244]     Train net output #0: loss = 0.0327717 (* 1 = 0.0327717 loss)
I0403 07:40:44.784981  2705 sgd_solver.cpp:106] Iteration 9216, lr = 5e-05
I0403 07:40:56.186079  2705 solver.cpp:228] Iteration 9232, loss = 0.0367291
I0403 07:40:56.186188  2705 solver.cpp:244]     Train net output #0: loss = 0.0367292 (* 1 = 0.0367292 loss)
I0403 07:40:56.374709  2705 sgd_solver.cpp:106] Iteration 9232, lr = 5e-05
I0403 07:41:07.721263  2705 solver.cpp:228] Iteration 9248, loss = 0.0108721
I0403 07:41:07.721578  2705 solver.cpp:244]     Train net output #0: loss = 0.0108722 (* 1 = 0.0108722 loss)
I0403 07:41:07.921721  2705 sgd_solver.cpp:106] Iteration 9248, lr = 5e-05
I0403 07:41:19.343425  2705 solver.cpp:228] Iteration 9264, loss = 0.017028
I0403 07:41:19.343525  2705 solver.cpp:244]     Train net output #0: loss = 0.0170282 (* 1 = 0.0170282 loss)
I0403 07:41:19.492113  2705 sgd_solver.cpp:106] Iteration 9264, lr = 5e-05
I0403 07:41:30.948379  2705 solver.cpp:228] Iteration 9280, loss = 0.028072
I0403 07:41:30.948498  2705 solver.cpp:244]     Train net output #0: loss = 0.0280721 (* 1 = 0.0280721 loss)
I0403 07:41:31.133877  2705 sgd_solver.cpp:106] Iteration 9280, lr = 5e-05
I0403 07:41:42.516485  2705 solver.cpp:228] Iteration 9296, loss = 0.0244791
I0403 07:41:42.516727  2705 solver.cpp:244]     Train net output #0: loss = 0.0244792 (* 1 = 0.0244792 loss)
I0403 07:41:42.695658  2705 sgd_solver.cpp:106] Iteration 9296, lr = 5e-05
I0403 07:41:54.331212  2705 solver.cpp:228] Iteration 9312, loss = 0.0189714
I0403 07:41:54.331326  2705 solver.cpp:244]     Train net output #0: loss = 0.0189715 (* 1 = 0.0189715 loss)
I0403 07:41:54.514410  2705 sgd_solver.cpp:106] Iteration 9312, lr = 5e-05
I0403 07:42:05.964083  2705 solver.cpp:228] Iteration 9328, loss = 0.0231077
I0403 07:42:05.964179  2705 solver.cpp:244]     Train net output #0: loss = 0.0231079 (* 1 = 0.0231079 loss)
I0403 07:42:06.127923  2705 sgd_solver.cpp:106] Iteration 9328, lr = 5e-05
I0403 07:42:17.553817  2705 solver.cpp:228] Iteration 9344, loss = 0.0303426
I0403 07:42:17.554132  2705 solver.cpp:244]     Train net output #0: loss = 0.0303428 (* 1 = 0.0303428 loss)
I0403 07:42:17.731572  2705 sgd_solver.cpp:106] Iteration 9344, lr = 5e-05
I0403 07:42:29.259711  2705 solver.cpp:228] Iteration 9360, loss = 0.0118987
I0403 07:42:29.259811  2705 solver.cpp:244]     Train net output #0: loss = 0.0118989 (* 1 = 0.0118989 loss)
I0403 07:42:29.438772  2705 sgd_solver.cpp:106] Iteration 9360, lr = 5e-05
I0403 07:42:40.923547  2705 solver.cpp:228] Iteration 9376, loss = 0.0241144
I0403 07:42:40.923666  2705 solver.cpp:244]     Train net output #0: loss = 0.0241145 (* 1 = 0.0241145 loss)
I0403 07:42:41.136505  2705 sgd_solver.cpp:106] Iteration 9376, lr = 5e-05
I0403 07:42:52.575249  2705 solver.cpp:228] Iteration 9392, loss = 0.0307986
I0403 07:42:52.575558  2705 solver.cpp:244]     Train net output #0: loss = 0.0307987 (* 1 = 0.0307987 loss)
I0403 07:42:52.753866  2705 sgd_solver.cpp:106] Iteration 9392, lr = 5e-05
I0403 07:43:04.263510  2705 solver.cpp:228] Iteration 9408, loss = 0.053586
I0403 07:43:04.263628  2705 solver.cpp:244]     Train net output #0: loss = 0.0535862 (* 1 = 0.0535862 loss)
I0403 07:43:04.479388  2705 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 07:43:15.863961  2705 solver.cpp:228] Iteration 9424, loss = 0.0289819
I0403 07:43:15.864060  2705 solver.cpp:244]     Train net output #0: loss = 0.028982 (* 1 = 0.028982 loss)
I0403 07:43:16.043203  2705 sgd_solver.cpp:106] Iteration 9424, lr = 5e-05
I0403 07:43:16.043452  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9425.caffemodel
I0403 07:43:18.815706  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9425.solverstate
I0403 07:43:20.712615  2705 solver.cpp:337] Iteration 9425, Testing net (#0)
I0403 07:44:09.153543  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939631
I0403 07:44:09.153859  2705 solver.cpp:404]     Test net output #1: loss = 0.218382 (* 1 = 0.218382 loss)
I0403 07:44:20.584349  2705 solver.cpp:228] Iteration 9440, loss = 0.0255536
I0403 07:44:20.584473  2705 solver.cpp:244]     Train net output #0: loss = 0.0255537 (* 1 = 0.0255537 loss)
I0403 07:44:20.798609  2705 sgd_solver.cpp:106] Iteration 9440, lr = 5e-05
I0403 07:44:32.110189  2705 solver.cpp:228] Iteration 9456, loss = 0.0237007
I0403 07:44:32.110298  2705 solver.cpp:244]     Train net output #0: loss = 0.0237008 (* 1 = 0.0237008 loss)
I0403 07:44:32.341763  2705 sgd_solver.cpp:106] Iteration 9456, lr = 5e-05
I0403 07:44:43.928308  2705 solver.cpp:228] Iteration 9472, loss = 0.0467207
I0403 07:44:43.928601  2705 solver.cpp:244]     Train net output #0: loss = 0.0467209 (* 1 = 0.0467209 loss)
I0403 07:44:44.119643  2705 sgd_solver.cpp:106] Iteration 9472, lr = 5e-05
I0403 07:44:55.606154  2705 solver.cpp:228] Iteration 9488, loss = 0.0118278
I0403 07:44:55.606261  2705 solver.cpp:244]     Train net output #0: loss = 0.011828 (* 1 = 0.011828 loss)
I0403 07:44:55.797814  2705 sgd_solver.cpp:106] Iteration 9488, lr = 5e-05
I0403 07:45:07.305546  2705 solver.cpp:228] Iteration 9504, loss = 0.0323539
I0403 07:45:07.305645  2705 solver.cpp:244]     Train net output #0: loss = 0.0323541 (* 1 = 0.0323541 loss)
I0403 07:45:07.475293  2705 sgd_solver.cpp:106] Iteration 9504, lr = 5e-05
I0403 07:45:18.802353  2705 solver.cpp:228] Iteration 9520, loss = 0.0191741
I0403 07:45:18.802655  2705 solver.cpp:244]     Train net output #0: loss = 0.0191743 (* 1 = 0.0191743 loss)
I0403 07:45:18.975651  2705 sgd_solver.cpp:106] Iteration 9520, lr = 5e-05
I0403 07:45:30.653888  2705 solver.cpp:228] Iteration 9536, loss = 0.0431496
I0403 07:45:30.653995  2705 solver.cpp:244]     Train net output #0: loss = 0.0431497 (* 1 = 0.0431497 loss)
I0403 07:45:30.845176  2705 sgd_solver.cpp:106] Iteration 9536, lr = 5e-05
I0403 07:45:42.308001  2705 solver.cpp:228] Iteration 9552, loss = 0.0304534
I0403 07:45:42.308099  2705 solver.cpp:244]     Train net output #0: loss = 0.0304536 (* 1 = 0.0304536 loss)
I0403 07:45:42.485549  2705 sgd_solver.cpp:106] Iteration 9552, lr = 5e-05
I0403 07:45:53.814586  2705 solver.cpp:228] Iteration 9568, loss = 0.0546961
I0403 07:45:53.814931  2705 solver.cpp:244]     Train net output #0: loss = 0.0546963 (* 1 = 0.0546963 loss)
I0403 07:45:53.995759  2705 sgd_solver.cpp:106] Iteration 9568, lr = 5e-05
I0403 07:46:05.495412  2705 solver.cpp:228] Iteration 9584, loss = 0.0929466
I0403 07:46:05.495525  2705 solver.cpp:244]     Train net output #0: loss = 0.0929467 (* 1 = 0.0929467 loss)
I0403 07:46:05.675496  2705 sgd_solver.cpp:106] Iteration 9584, lr = 5e-05
I0403 07:46:17.236414  2705 solver.cpp:228] Iteration 9600, loss = 0.0193531
I0403 07:46:17.236515  2705 solver.cpp:244]     Train net output #0: loss = 0.0193533 (* 1 = 0.0193533 loss)
I0403 07:46:17.414535  2705 sgd_solver.cpp:106] Iteration 9600, lr = 5e-05
I0403 07:46:28.647081  2705 solver.cpp:228] Iteration 9616, loss = 0.0189731
I0403 07:46:28.647387  2705 solver.cpp:244]     Train net output #0: loss = 0.0189733 (* 1 = 0.0189733 loss)
I0403 07:46:28.841763  2705 sgd_solver.cpp:106] Iteration 9616, lr = 5e-05
I0403 07:46:40.223364  2705 solver.cpp:228] Iteration 9632, loss = 0.0397181
I0403 07:46:40.223477  2705 solver.cpp:244]     Train net output #0: loss = 0.0397182 (* 1 = 0.0397182 loss)
I0403 07:46:40.419484  2705 sgd_solver.cpp:106] Iteration 9632, lr = 5e-05
I0403 07:46:51.739327  2705 solver.cpp:228] Iteration 9648, loss = 0.0400526
I0403 07:46:51.739442  2705 solver.cpp:244]     Train net output #0: loss = 0.0400528 (* 1 = 0.0400528 loss)
I0403 07:46:51.919368  2705 sgd_solver.cpp:106] Iteration 9648, lr = 5e-05
I0403 07:47:03.216243  2705 solver.cpp:228] Iteration 9664, loss = 0.0422168
I0403 07:47:03.216558  2705 solver.cpp:244]     Train net output #0: loss = 0.0422169 (* 1 = 0.0422169 loss)
I0403 07:47:03.405901  2705 sgd_solver.cpp:106] Iteration 9664, lr = 5e-05
I0403 07:47:14.768169  2705 solver.cpp:228] Iteration 9680, loss = 0.0551792
I0403 07:47:14.768280  2705 solver.cpp:244]     Train net output #0: loss = 0.0551794 (* 1 = 0.0551794 loss)
I0403 07:47:14.989598  2705 sgd_solver.cpp:106] Iteration 9680, lr = 5e-05
I0403 07:47:26.391304  2705 solver.cpp:228] Iteration 9696, loss = 0.0138505
I0403 07:47:26.391418  2705 solver.cpp:244]     Train net output #0: loss = 0.0138507 (* 1 = 0.0138507 loss)
I0403 07:47:26.586913  2705 sgd_solver.cpp:106] Iteration 9696, lr = 5e-05
I0403 07:47:38.062188  2705 solver.cpp:228] Iteration 9712, loss = 0.032972
I0403 07:47:38.062458  2705 solver.cpp:244]     Train net output #0: loss = 0.0329721 (* 1 = 0.0329721 loss)
I0403 07:47:38.261945  2705 sgd_solver.cpp:106] Iteration 9712, lr = 5e-05
I0403 07:47:49.542399  2705 solver.cpp:228] Iteration 9728, loss = 0.0621986
I0403 07:47:49.542511  2705 solver.cpp:244]     Train net output #0: loss = 0.0621988 (* 1 = 0.0621988 loss)
I0403 07:47:49.744892  2705 sgd_solver.cpp:106] Iteration 9728, lr = 5e-05
I0403 07:48:01.186697  2705 solver.cpp:228] Iteration 9744, loss = 0.017165
I0403 07:48:01.186794  2705 solver.cpp:244]     Train net output #0: loss = 0.0171652 (* 1 = 0.0171652 loss)
I0403 07:48:01.364745  2705 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 07:48:04.917863  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9750.caffemodel
I0403 07:48:07.724817  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9750.solverstate
I0403 07:48:09.646469  2705 solver.cpp:337] Iteration 9750, Testing net (#0)
I0403 07:48:58.084080  2705 solver.cpp:404]     Test net output #0: accuracy = 0.939124
I0403 07:48:58.084416  2705 solver.cpp:404]     Test net output #1: loss = 0.218298 (* 1 = 0.218298 loss)
I0403 07:49:03.829571  2705 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9758.caffemodel
I0403 07:49:06.613885  2705 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_train_from_scratch/snapshots__iter_9758.solverstate
I0403 07:49:08.531744  2705 solver.cpp:322] Optimization Done.
I0403 07:49:08.618232  2705 caffe.cpp:222] Optimization Done.
