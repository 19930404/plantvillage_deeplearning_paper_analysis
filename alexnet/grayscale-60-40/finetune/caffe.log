I0403 02:30:28.010133 28785 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.016248 28785 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.016281 28785 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:35.899415 28785 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:35.901103 28785 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:35.902384 28785 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:36.782660 28785 solver.cpp:48] Initializing solver from parameters: 
test_iter: 217
test_interval: 325
base_lr: 0.005
display: 16
max_iter: 9758
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3252
snapshot: 325
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:36.856343 28785 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:36.867403 28785 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:36.867555 28785 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:36.869465 28785 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:36.872082 28785 layer_factory.hpp:77] Creating layer data
I0403 02:30:36.874778 28785 net.cpp:91] Creating Layer data
I0403 02:30:36.874949 28785 net.cpp:399] data -> data
I0403 02:30:36.875373 28785 net.cpp:399] data -> label
I0403 02:30:36.875483 28785 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto
I0403 02:30:36.916012 28792 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/train_db
I0403 02:30:36.939187 28785 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.077118 28785 net.cpp:141] Setting up data
I0403 02:30:37.077239 28785 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.077275 28785 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.077296 28785 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.077333 28785 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.077388 28785 net.cpp:91] Creating Layer conv1
I0403 02:30:37.077414 28785 net.cpp:425] conv1 <- data
I0403 02:30:37.077451 28785 net.cpp:399] conv1 -> conv1
I0403 02:30:37.086947 28785 net.cpp:141] Setting up conv1
I0403 02:30:37.086987 28785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.087021 28785 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.087090 28785 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.087187 28785 net.cpp:91] Creating Layer relu1
I0403 02:30:37.087242 28785 net.cpp:425] relu1 <- conv1
I0403 02:30:37.087298 28785 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.087386 28785 net.cpp:141] Setting up relu1
I0403 02:30:37.087419 28785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.087460 28785 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.087481 28785 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.087507 28785 net.cpp:91] Creating Layer norm1
I0403 02:30:37.087563 28785 net.cpp:425] norm1 <- conv1
I0403 02:30:37.087587 28785 net.cpp:399] norm1 -> norm1
I0403 02:30:37.087702 28785 net.cpp:141] Setting up norm1
I0403 02:30:37.087730 28785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.087754 28785 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.087779 28785 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.087810 28785 net.cpp:91] Creating Layer pool1
I0403 02:30:37.087831 28785 net.cpp:425] pool1 <- norm1
I0403 02:30:37.087855 28785 net.cpp:399] pool1 -> pool1
I0403 02:30:37.087944 28785 net.cpp:141] Setting up pool1
I0403 02:30:37.087975 28785 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.087995 28785 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.088013 28785 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.088040 28785 net.cpp:91] Creating Layer conv2
I0403 02:30:37.088063 28785 net.cpp:425] conv2 <- pool1
I0403 02:30:37.088086 28785 net.cpp:399] conv2 -> conv2
I0403 02:30:37.088510 28794 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.105310 28785 net.cpp:141] Setting up conv2
I0403 02:30:37.105350 28785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.105370 28785 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.105397 28785 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.105423 28785 net.cpp:91] Creating Layer relu2
I0403 02:30:37.105445 28785 net.cpp:425] relu2 <- conv2
I0403 02:30:37.105468 28785 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.105492 28785 net.cpp:141] Setting up relu2
I0403 02:30:37.105515 28785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.105532 28785 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.105551 28785 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.105576 28785 net.cpp:91] Creating Layer norm2
I0403 02:30:37.105597 28785 net.cpp:425] norm2 <- conv2
I0403 02:30:37.105618 28785 net.cpp:399] norm2 -> norm2
I0403 02:30:37.105676 28785 net.cpp:141] Setting up norm2
I0403 02:30:37.105706 28785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.105726 28785 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.105743 28785 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.105769 28785 net.cpp:91] Creating Layer pool2
I0403 02:30:37.105792 28785 net.cpp:425] pool2 <- norm2
I0403 02:30:37.105814 28785 net.cpp:399] pool2 -> pool2
I0403 02:30:37.105872 28785 net.cpp:141] Setting up pool2
I0403 02:30:37.105903 28785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.105922 28785 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.105940 28785 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.105968 28785 net.cpp:91] Creating Layer conv3
I0403 02:30:37.105991 28785 net.cpp:425] conv3 <- pool2
I0403 02:30:37.106016 28785 net.cpp:399] conv3 -> conv3
I0403 02:30:37.149302 28785 net.cpp:141] Setting up conv3
I0403 02:30:37.149345 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.149366 28785 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.149394 28785 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.149420 28785 net.cpp:91] Creating Layer relu3
I0403 02:30:37.149441 28785 net.cpp:425] relu3 <- conv3
I0403 02:30:37.149463 28785 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.149487 28785 net.cpp:141] Setting up relu3
I0403 02:30:37.149507 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.149526 28785 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.149544 28785 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.149572 28785 net.cpp:91] Creating Layer conv4
I0403 02:30:37.149593 28785 net.cpp:425] conv4 <- conv3
I0403 02:30:37.149618 28785 net.cpp:399] conv4 -> conv4
I0403 02:30:37.181051 28785 net.cpp:141] Setting up conv4
I0403 02:30:37.181092 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.181113 28785 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.181159 28785 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.181185 28785 net.cpp:91] Creating Layer relu4
I0403 02:30:37.181205 28785 net.cpp:425] relu4 <- conv4
I0403 02:30:37.181227 28785 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.181252 28785 net.cpp:141] Setting up relu4
I0403 02:30:37.181282 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.181300 28785 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.181318 28785 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.181346 28785 net.cpp:91] Creating Layer conv5
I0403 02:30:37.181368 28785 net.cpp:425] conv5 <- conv4
I0403 02:30:37.181393 28785 net.cpp:399] conv5 -> conv5
I0403 02:30:37.202453 28785 net.cpp:141] Setting up conv5
I0403 02:30:37.202491 28785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.202512 28785 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.202538 28785 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.202564 28785 net.cpp:91] Creating Layer relu5
I0403 02:30:37.202585 28785 net.cpp:425] relu5 <- conv5
I0403 02:30:37.202606 28785 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.202630 28785 net.cpp:141] Setting up relu5
I0403 02:30:37.202652 28785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.202671 28785 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.202688 28785 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.202713 28785 net.cpp:91] Creating Layer pool5
I0403 02:30:37.202733 28785 net.cpp:425] pool5 <- conv5
I0403 02:30:37.202757 28785 net.cpp:399] pool5 -> pool5
I0403 02:30:37.202819 28785 net.cpp:141] Setting up pool5
I0403 02:30:37.202849 28785 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.202868 28785 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.202888 28785 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.202940 28785 net.cpp:91] Creating Layer fc6
I0403 02:30:37.202968 28785 net.cpp:425] fc6 <- pool5
I0403 02:30:37.202993 28785 net.cpp:399] fc6 -> fc6
I0403 02:30:38.752226 28785 net.cpp:141] Setting up fc6
I0403 02:30:38.752321 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.752337 28785 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.752359 28785 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.752383 28785 net.cpp:91] Creating Layer relu6
I0403 02:30:38.752399 28785 net.cpp:425] relu6 <- fc6
I0403 02:30:38.752421 28785 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.752444 28785 net.cpp:141] Setting up relu6
I0403 02:30:38.752461 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.752475 28785 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.752488 28785 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.752538 28785 net.cpp:91] Creating Layer drop6
I0403 02:30:38.752557 28785 net.cpp:425] drop6 <- fc6
I0403 02:30:38.752576 28785 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.752634 28785 net.cpp:141] Setting up drop6
I0403 02:30:38.752656 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.752671 28785 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.752686 28785 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.752707 28785 net.cpp:91] Creating Layer fc7
I0403 02:30:38.752724 28785 net.cpp:425] fc7 <- fc6
I0403 02:30:38.752743 28785 net.cpp:399] fc7 -> fc7
I0403 02:30:39.357297 28785 net.cpp:141] Setting up fc7
I0403 02:30:39.357396 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.357414 28785 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.357435 28785 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.357460 28785 net.cpp:91] Creating Layer relu7
I0403 02:30:39.357477 28785 net.cpp:425] relu7 <- fc7
I0403 02:30:39.357496 28785 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.357517 28785 net.cpp:141] Setting up relu7
I0403 02:30:39.357533 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.357547 28785 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.357560 28785 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.357612 28785 net.cpp:91] Creating Layer drop7
I0403 02:30:39.357628 28785 net.cpp:425] drop7 <- fc7
I0403 02:30:39.357648 28785 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.357686 28785 net.cpp:141] Setting up drop7
I0403 02:30:39.357709 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.357724 28785 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.357738 28785 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.357759 28785 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.357775 28785 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.357796 28785 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.363865 28785 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.363894 28785 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.363910 28785 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.363931 28785 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.363981 28785 net.cpp:91] Creating Layer loss
I0403 02:30:39.364001 28785 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.364017 28785 net.cpp:425] loss <- label
I0403 02:30:39.364043 28785 net.cpp:399] loss -> loss
I0403 02:30:39.364083 28785 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.364210 28785 net.cpp:141] Setting up loss
I0403 02:30:39.364234 28785 net.cpp:148] Top shape: (1)
I0403 02:30:39.364249 28785 net.cpp:151]     with loss weight 1
I0403 02:30:39.364358 28785 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.364374 28785 net.cpp:217] loss needs backward computation.
I0403 02:30:39.364390 28785 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.364405 28785 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.364419 28785 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.364434 28785 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.364449 28785 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.364462 28785 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.364477 28785 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.364491 28785 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.364506 28785 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.364521 28785 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.364534 28785 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.364549 28785 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.364563 28785 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.364578 28785 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.364593 28785 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.364608 28785 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.364621 28785 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.364635 28785 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.364650 28785 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.364665 28785 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.364678 28785 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.364693 28785 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.364708 28785 net.cpp:219] data does not need backward computation.
I0403 02:30:39.364723 28785 net.cpp:261] This network produces output loss
I0403 02:30:39.364750 28785 net.cpp:274] Network initialization done.
I0403 02:30:39.365949 28785 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.366009 28785 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.366693 28785 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-60-40/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.366874 28785 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.367012 28785 net.cpp:91] Creating Layer data
I0403 02:30:39.367038 28785 net.cpp:399] data -> data
I0403 02:30:39.367064 28785 net.cpp:399] data -> label
I0403 02:30:39.367089 28785 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/mean.binaryproto
I0403 02:30:39.396577 28796 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-60-40/test_db
I0403 02:30:39.410100 28785 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.662379 28785 net.cpp:141] Setting up data
I0403 02:30:39.662657 28785 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.662730 28785 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.662804 28785 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.662859 28785 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.662953 28785 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.663038 28785 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.663130 28785 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.663179 28785 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.663332 28785 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.663363 28785 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.663411 28785 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.663449 28785 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.663485 28785 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.663545 28785 net.cpp:91] Creating Layer conv1
I0403 02:30:39.663590 28785 net.cpp:425] conv1 <- data
I0403 02:30:39.663641 28785 net.cpp:399] conv1 -> conv1
I0403 02:30:39.666275 28785 net.cpp:141] Setting up conv1
I0403 02:30:39.666311 28785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.666327 28785 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.666352 28785 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.666393 28785 net.cpp:91] Creating Layer relu1
I0403 02:30:39.666437 28785 net.cpp:425] relu1 <- conv1
I0403 02:30:39.666456 28785 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.666476 28785 net.cpp:141] Setting up relu1
I0403 02:30:39.666494 28785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.666509 28785 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.666524 28785 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.666546 28785 net.cpp:91] Creating Layer norm1
I0403 02:30:39.666563 28785 net.cpp:425] norm1 <- conv1
I0403 02:30:39.666582 28785 net.cpp:399] norm1 -> norm1
I0403 02:30:39.666633 28785 net.cpp:141] Setting up norm1
I0403 02:30:39.666656 28785 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.666672 28785 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.666687 28785 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.666707 28785 net.cpp:91] Creating Layer pool1
I0403 02:30:39.666724 28785 net.cpp:425] pool1 <- norm1
I0403 02:30:39.666743 28785 net.cpp:399] pool1 -> pool1
I0403 02:30:39.666792 28785 net.cpp:141] Setting up pool1
I0403 02:30:39.666816 28785 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.666831 28785 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.666880 28785 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.666905 28785 net.cpp:91] Creating Layer conv2
I0403 02:30:39.666923 28785 net.cpp:425] conv2 <- pool1
I0403 02:30:39.666944 28785 net.cpp:399] conv2 -> conv2
I0403 02:30:39.679877 28785 net.cpp:141] Setting up conv2
I0403 02:30:39.679913 28785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.679929 28785 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.679951 28785 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.679973 28785 net.cpp:91] Creating Layer relu2
I0403 02:30:39.679991 28785 net.cpp:425] relu2 <- conv2
I0403 02:30:39.680011 28785 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.680032 28785 net.cpp:141] Setting up relu2
I0403 02:30:39.680050 28785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.680068 28785 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.680083 28785 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.680104 28785 net.cpp:91] Creating Layer norm2
I0403 02:30:39.680122 28785 net.cpp:425] norm2 <- conv2
I0403 02:30:39.680141 28785 net.cpp:399] norm2 -> norm2
I0403 02:30:39.680192 28785 net.cpp:141] Setting up norm2
I0403 02:30:39.680217 28785 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.680248 28785 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.680361 28785 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.680444 28785 net.cpp:91] Creating Layer pool2
I0403 02:30:39.680516 28785 net.cpp:425] pool2 <- norm2
I0403 02:30:39.680615 28785 net.cpp:399] pool2 -> pool2
I0403 02:30:39.680716 28785 net.cpp:141] Setting up pool2
I0403 02:30:39.680820 28785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.680920 28785 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.680986 28785 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.681016 28785 net.cpp:91] Creating Layer conv3
I0403 02:30:39.681041 28785 net.cpp:425] conv3 <- pool2
I0403 02:30:39.681068 28785 net.cpp:399] conv3 -> conv3
I0403 02:30:39.718062 28785 net.cpp:141] Setting up conv3
I0403 02:30:39.718127 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.718145 28785 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.718173 28785 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.718215 28785 net.cpp:91] Creating Layer relu3
I0403 02:30:39.718245 28785 net.cpp:425] relu3 <- conv3
I0403 02:30:39.718296 28785 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.718349 28785 net.cpp:141] Setting up relu3
I0403 02:30:39.718376 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.718394 28785 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.718408 28785 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.718435 28785 net.cpp:91] Creating Layer conv4
I0403 02:30:39.718451 28785 net.cpp:425] conv4 <- conv3
I0403 02:30:39.718473 28785 net.cpp:399] conv4 -> conv4
I0403 02:30:39.745918 28785 net.cpp:141] Setting up conv4
I0403 02:30:39.784317 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.784346 28785 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.784373 28785 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.784399 28785 net.cpp:91] Creating Layer relu4
I0403 02:30:39.784418 28785 net.cpp:425] relu4 <- conv4
I0403 02:30:39.784441 28785 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.784466 28785 net.cpp:141] Setting up relu4
I0403 02:30:39.784484 28785 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.784500 28785 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.784517 28785 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.784543 28785 net.cpp:91] Creating Layer conv5
I0403 02:30:39.784561 28785 net.cpp:425] conv5 <- conv4
I0403 02:30:39.784584 28785 net.cpp:399] conv5 -> conv5
I0403 02:30:39.805449 28785 net.cpp:141] Setting up conv5
I0403 02:30:39.805488 28785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.805537 28785 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.805564 28785 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.805588 28785 net.cpp:91] Creating Layer relu5
I0403 02:30:39.805606 28785 net.cpp:425] relu5 <- conv5
I0403 02:30:39.805626 28785 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.805647 28785 net.cpp:141] Setting up relu5
I0403 02:30:39.805668 28785 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.805685 28785 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.805699 28785 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.805726 28785 net.cpp:91] Creating Layer pool5
I0403 02:30:39.805743 28785 net.cpp:425] pool5 <- conv5
I0403 02:30:39.805764 28785 net.cpp:399] pool5 -> pool5
I0403 02:30:39.805819 28785 net.cpp:141] Setting up pool5
I0403 02:30:39.805843 28785 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.805860 28785 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.805876 28785 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.805902 28785 net.cpp:91] Creating Layer fc6
I0403 02:30:39.805920 28785 net.cpp:425] fc6 <- pool5
I0403 02:30:39.805943 28785 net.cpp:399] fc6 -> fc6
I0403 02:30:41.231644 28785 net.cpp:141] Setting up fc6
I0403 02:30:41.231739 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.231755 28785 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.231777 28785 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.231801 28785 net.cpp:91] Creating Layer relu6
I0403 02:30:41.231819 28785 net.cpp:425] relu6 <- fc6
I0403 02:30:41.231840 28785 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.231864 28785 net.cpp:141] Setting up relu6
I0403 02:30:41.231881 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.231895 28785 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.231909 28785 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.231928 28785 net.cpp:91] Creating Layer drop6
I0403 02:30:41.231943 28785 net.cpp:425] drop6 <- fc6
I0403 02:30:41.231962 28785 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.232000 28785 net.cpp:141] Setting up drop6
I0403 02:30:41.232022 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.232036 28785 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.232049 28785 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.232072 28785 net.cpp:91] Creating Layer fc7
I0403 02:30:41.232089 28785 net.cpp:425] fc7 <- fc6
I0403 02:30:41.232106 28785 net.cpp:399] fc7 -> fc7
I0403 02:30:41.840813 28785 net.cpp:141] Setting up fc7
I0403 02:30:41.840911 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.840930 28785 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.840955 28785 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.840983 28785 net.cpp:91] Creating Layer relu7
I0403 02:30:41.841004 28785 net.cpp:425] relu7 <- fc7
I0403 02:30:41.841027 28785 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.841053 28785 net.cpp:141] Setting up relu7
I0403 02:30:41.841071 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.841087 28785 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.841104 28785 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.841125 28785 net.cpp:91] Creating Layer drop7
I0403 02:30:41.841141 28785 net.cpp:425] drop7 <- fc7
I0403 02:30:41.841162 28785 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.841205 28785 net.cpp:141] Setting up drop7
I0403 02:30:41.841245 28785 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.841267 28785 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.841289 28785 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.841315 28785 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.841334 28785 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.841359 28785 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.850466 28785 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.850507 28785 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.850571 28785 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.850600 28785 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.850630 28785 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.850656 28785 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.850683 28785 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.850713 28785 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.850776 28785 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.850803 28785 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.850826 28785 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.850847 28785 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.850865 28785 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.850895 28785 net.cpp:91] Creating Layer loss
I0403 02:30:41.850917 28785 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.850940 28785 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.850968 28785 net.cpp:399] loss -> loss
I0403 02:30:41.850996 28785 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.851109 28785 net.cpp:141] Setting up loss
I0403 02:30:41.851138 28785 net.cpp:148] Top shape: (1)
I0403 02:30:41.851158 28785 net.cpp:151]     with loss weight 1
I0403 02:30:41.851191 28785 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.851212 28785 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.851239 28785 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.851264 28785 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.851292 28785 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.851321 28785 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.851361 28785 net.cpp:141] Setting up accuracy
I0403 02:30:41.851389 28785 net.cpp:148] Top shape: (1)
I0403 02:30:41.851413 28785 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.851436 28785 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.851454 28785 net.cpp:217] loss needs backward computation.
I0403 02:30:41.851474 28785 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.851492 28785 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.851512 28785 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.851531 28785 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.851552 28785 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.851575 28785 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.851593 28785 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.851609 28785 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.851629 28785 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.851646 28785 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.851666 28785 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.851689 28785 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.851711 28785 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.851730 28785 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.851749 28785 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.851775 28785 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.851794 28785 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.851819 28785 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.851842 28785 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.851866 28785 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.851887 28785 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.851909 28785 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.851933 28785 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.851969 28785 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.851990 28785 net.cpp:219] data does not need backward computation.
I0403 02:30:41.852016 28785 net.cpp:261] This network produces output accuracy
I0403 02:30:41.852036 28785 net.cpp:261] This network produces output loss
I0403 02:30:41.852072 28785 net.cpp:274] Network initialization done.
I0403 02:30:41.852205 28785 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.852742 28785 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.273990 28785 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.274080 28785 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.274116 28785 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.274174 28785 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.658999 28785 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.695785 28785 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.929992 28785 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.930073 28785 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.930097 28785 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.930143 28785 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.301623 28785 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.336284 28785 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.362365 28785 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.611845 28785 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.119607 28785 parallel.cpp:425] Starting Optimization
I0403 02:30:48.119812 28785 solver.cpp:279] Solving 
I0403 02:30:48.119835 28785 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.119976 28785 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:38.219522 28785 solver.cpp:404]     Test net output #0: accuracy = 0.0399079
I0403 02:31:38.227387 28785 solver.cpp:404]     Test net output #1: loss = 3.81082 (* 1 = 3.81082 loss)
I0403 02:31:38.812016 28785 solver.cpp:228] Iteration 0, loss = 4.19255
I0403 02:31:38.816659 28785 solver.cpp:244]     Train net output #0: loss = 4.19255 (* 1 = 4.19255 loss)
I0403 02:31:38.968583 28785 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:31:50.569501 28785 solver.cpp:228] Iteration 16, loss = 1.89445
I0403 02:31:50.575855 28785 solver.cpp:244]     Train net output #0: loss = 1.89445 (* 1 = 1.89445 loss)
I0403 02:31:50.747416 28785 sgd_solver.cpp:106] Iteration 16, lr = 0.005
I0403 02:32:02.466724 28785 solver.cpp:228] Iteration 32, loss = 1.06835
I0403 02:32:02.471604 28785 solver.cpp:244]     Train net output #0: loss = 1.06835 (* 1 = 1.06835 loss)
I0403 02:32:02.686295 28785 sgd_solver.cpp:106] Iteration 32, lr = 0.005
I0403 02:32:14.335850 28785 solver.cpp:228] Iteration 48, loss = 1.10813
I0403 02:32:14.344064 28785 solver.cpp:244]     Train net output #0: loss = 1.10813 (* 1 = 1.10813 loss)
I0403 02:32:14.523337 28785 sgd_solver.cpp:106] Iteration 48, lr = 0.005
I0403 02:32:26.007871 28785 solver.cpp:228] Iteration 64, loss = 0.669867
I0403 02:32:26.015310 28785 solver.cpp:244]     Train net output #0: loss = 0.669867 (* 1 = 0.669867 loss)
I0403 02:32:26.193277 28785 sgd_solver.cpp:106] Iteration 64, lr = 0.005
I0403 02:32:37.598064 28785 solver.cpp:228] Iteration 80, loss = 0.816203
I0403 02:32:37.604778 28785 solver.cpp:244]     Train net output #0: loss = 0.816203 (* 1 = 0.816203 loss)
I0403 02:32:37.777844 28785 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:32:49.256469 28785 solver.cpp:228] Iteration 96, loss = 0.450512
I0403 02:32:49.263000 28785 solver.cpp:244]     Train net output #0: loss = 0.450512 (* 1 = 0.450512 loss)
I0403 02:32:49.433501 28785 sgd_solver.cpp:106] Iteration 96, lr = 0.005
I0403 02:33:00.930920 28785 solver.cpp:228] Iteration 112, loss = 0.597503
I0403 02:33:00.937973 28785 solver.cpp:244]     Train net output #0: loss = 0.597503 (* 1 = 0.597503 loss)
I0403 02:33:01.101341 28785 sgd_solver.cpp:106] Iteration 112, lr = 0.005
I0403 02:33:12.557149 28785 solver.cpp:228] Iteration 128, loss = 0.720127
I0403 02:33:12.564870 28785 solver.cpp:244]     Train net output #0: loss = 0.720127 (* 1 = 0.720127 loss)
I0403 02:33:12.764544 28785 sgd_solver.cpp:106] Iteration 128, lr = 0.005
I0403 02:33:24.292812 28785 solver.cpp:228] Iteration 144, loss = 0.553391
I0403 02:33:24.300638 28785 solver.cpp:244]     Train net output #0: loss = 0.553391 (* 1 = 0.553391 loss)
I0403 02:33:24.487308 28785 sgd_solver.cpp:106] Iteration 144, lr = 0.005
I0403 02:33:35.952641 28785 solver.cpp:228] Iteration 160, loss = 0.549425
I0403 02:33:35.958035 28785 solver.cpp:244]     Train net output #0: loss = 0.549425 (* 1 = 0.549425 loss)
I0403 02:33:36.131073 28785 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:33:47.734972 28785 solver.cpp:228] Iteration 176, loss = 0.56159
I0403 02:33:47.741520 28785 solver.cpp:244]     Train net output #0: loss = 0.56159 (* 1 = 0.56159 loss)
I0403 02:33:47.921142 28785 sgd_solver.cpp:106] Iteration 176, lr = 0.005
I0403 02:33:59.467077 28785 solver.cpp:228] Iteration 192, loss = 0.438102
I0403 02:33:59.473770 28785 solver.cpp:244]     Train net output #0: loss = 0.438102 (* 1 = 0.438102 loss)
I0403 02:33:59.668172 28785 sgd_solver.cpp:106] Iteration 192, lr = 0.005
I0403 02:34:11.295353 28785 solver.cpp:228] Iteration 208, loss = 0.339448
I0403 02:34:11.301666 28785 solver.cpp:244]     Train net output #0: loss = 0.339448 (* 1 = 0.339448 loss)
I0403 02:34:11.473093 28785 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 02:34:23.036198 28785 solver.cpp:228] Iteration 224, loss = 0.501806
I0403 02:34:23.073807 28785 solver.cpp:244]     Train net output #0: loss = 0.501806 (* 1 = 0.501806 loss)
I0403 02:34:23.186085 28785 sgd_solver.cpp:106] Iteration 224, lr = 0.005
I0403 02:34:34.806001 28785 solver.cpp:228] Iteration 240, loss = 0.268483
I0403 02:34:34.812818 28785 solver.cpp:244]     Train net output #0: loss = 0.268483 (* 1 = 0.268483 loss)
I0403 02:34:34.970644 28785 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:34:46.622812 28785 solver.cpp:228] Iteration 256, loss = 0.330163
I0403 02:34:46.633358 28785 solver.cpp:244]     Train net output #0: loss = 0.330163 (* 1 = 0.330163 loss)
I0403 02:34:46.848057 28785 sgd_solver.cpp:106] Iteration 256, lr = 0.005
I0403 02:34:58.245646 28785 solver.cpp:228] Iteration 272, loss = 0.290723
I0403 02:34:58.251556 28785 solver.cpp:244]     Train net output #0: loss = 0.290723 (* 1 = 0.290723 loss)
I0403 02:34:58.439688 28785 sgd_solver.cpp:106] Iteration 272, lr = 0.005
I0403 02:35:10.089949 28785 solver.cpp:228] Iteration 288, loss = 0.311718
I0403 02:35:10.095062 28785 solver.cpp:244]     Train net output #0: loss = 0.311718 (* 1 = 0.311718 loss)
I0403 02:35:10.230195 28785 sgd_solver.cpp:106] Iteration 288, lr = 0.005
I0403 02:35:21.955725 28785 solver.cpp:228] Iteration 304, loss = 0.360744
I0403 02:35:21.962087 28785 solver.cpp:244]     Train net output #0: loss = 0.360744 (* 1 = 0.360744 loss)
I0403 02:35:22.121237 28785 sgd_solver.cpp:106] Iteration 304, lr = 0.005
I0403 02:35:33.851290 28785 solver.cpp:228] Iteration 320, loss = 0.377278
I0403 02:35:33.857394 28785 solver.cpp:244]     Train net output #0: loss = 0.377278 (* 1 = 0.377278 loss)
I0403 02:35:34.028401 28785 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:35:37.000535 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_325.caffemodel
I0403 02:35:39.829574 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_325.solverstate
I0403 02:35:41.728544 28785 solver.cpp:337] Iteration 325, Testing net (#0)
I0403 02:36:31.291438 28785 solver.cpp:404]     Test net output #0: accuracy = 0.901244
I0403 02:36:31.298974 28785 solver.cpp:404]     Test net output #1: loss = 0.297348 (* 1 = 0.297348 loss)
I0403 02:36:40.348103 28785 solver.cpp:228] Iteration 336, loss = 0.374443
I0403 02:36:40.354356 28785 solver.cpp:244]     Train net output #0: loss = 0.374443 (* 1 = 0.374443 loss)
I0403 02:36:40.526609 28785 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 02:36:52.022063 28785 solver.cpp:228] Iteration 352, loss = 0.32222
I0403 02:36:52.039103 28785 solver.cpp:244]     Train net output #0: loss = 0.322221 (* 1 = 0.322221 loss)
I0403 02:36:52.252516 28785 sgd_solver.cpp:106] Iteration 352, lr = 0.005
I0403 02:37:03.778079 28785 solver.cpp:228] Iteration 368, loss = 0.436294
I0403 02:37:03.784665 28785 solver.cpp:244]     Train net output #0: loss = 0.436294 (* 1 = 0.436294 loss)
I0403 02:37:03.929131 28785 sgd_solver.cpp:106] Iteration 368, lr = 0.005
I0403 02:37:15.551544 28785 solver.cpp:228] Iteration 384, loss = 0.445557
I0403 02:37:15.557843 28785 solver.cpp:244]     Train net output #0: loss = 0.445557 (* 1 = 0.445557 loss)
I0403 02:37:15.745012 28785 sgd_solver.cpp:106] Iteration 384, lr = 0.005
I0403 02:37:27.267315 28785 solver.cpp:228] Iteration 400, loss = 0.321906
I0403 02:37:27.272922 28785 solver.cpp:244]     Train net output #0: loss = 0.321906 (* 1 = 0.321906 loss)
I0403 02:37:27.421094 28785 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:37:39.215813 28785 solver.cpp:228] Iteration 416, loss = 0.225477
I0403 02:37:39.222219 28785 solver.cpp:244]     Train net output #0: loss = 0.225477 (* 1 = 0.225477 loss)
I0403 02:37:39.436795 28785 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 02:37:50.956389 28785 solver.cpp:228] Iteration 432, loss = 0.289319
I0403 02:37:50.962512 28785 solver.cpp:244]     Train net output #0: loss = 0.289319 (* 1 = 0.289319 loss)
I0403 02:37:51.120740 28785 sgd_solver.cpp:106] Iteration 432, lr = 0.005
I0403 02:38:02.849477 28785 solver.cpp:228] Iteration 448, loss = 0.240756
I0403 02:38:02.849575 28785 solver.cpp:244]     Train net output #0: loss = 0.240756 (* 1 = 0.240756 loss)
I0403 02:38:03.006753 28785 sgd_solver.cpp:106] Iteration 448, lr = 0.005
I0403 02:38:14.644210 28785 solver.cpp:228] Iteration 464, loss = 0.328774
I0403 02:38:14.650734 28785 solver.cpp:244]     Train net output #0: loss = 0.328774 (* 1 = 0.328774 loss)
I0403 02:38:14.863878 28785 sgd_solver.cpp:106] Iteration 464, lr = 0.005
I0403 02:38:26.362800 28785 solver.cpp:228] Iteration 480, loss = 0.266764
I0403 02:38:26.368069 28785 solver.cpp:244]     Train net output #0: loss = 0.266764 (* 1 = 0.266764 loss)
I0403 02:38:26.627662 28785 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:38:38.161502 28785 solver.cpp:228] Iteration 496, loss = 0.206086
I0403 02:38:38.168985 28785 solver.cpp:244]     Train net output #0: loss = 0.206086 (* 1 = 0.206086 loss)
I0403 02:38:38.313283 28785 sgd_solver.cpp:106] Iteration 496, lr = 0.005
I0403 02:38:50.073593 28785 solver.cpp:228] Iteration 512, loss = 0.183492
I0403 02:38:50.073917 28785 solver.cpp:244]     Train net output #0: loss = 0.183492 (* 1 = 0.183492 loss)
I0403 02:38:50.262769 28785 sgd_solver.cpp:106] Iteration 512, lr = 0.005
I0403 02:39:01.782065 28785 solver.cpp:228] Iteration 528, loss = 0.194144
I0403 02:39:01.782976 28785 solver.cpp:244]     Train net output #0: loss = 0.194144 (* 1 = 0.194144 loss)
I0403 02:39:02.018878 28785 sgd_solver.cpp:106] Iteration 528, lr = 0.005
I0403 02:39:13.453846 28785 solver.cpp:228] Iteration 544, loss = 0.240108
I0403 02:39:13.453946 28785 solver.cpp:244]     Train net output #0: loss = 0.240108 (* 1 = 0.240108 loss)
I0403 02:39:13.631464 28785 sgd_solver.cpp:106] Iteration 544, lr = 0.005
I0403 02:39:25.235646 28785 solver.cpp:228] Iteration 560, loss = 0.207773
I0403 02:39:25.235992 28785 solver.cpp:244]     Train net output #0: loss = 0.207773 (* 1 = 0.207773 loss)
I0403 02:39:25.427321 28785 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:39:36.980238 28785 solver.cpp:228] Iteration 576, loss = 0.271689
I0403 02:39:36.980355 28785 solver.cpp:244]     Train net output #0: loss = 0.27169 (* 1 = 0.27169 loss)
I0403 02:39:37.223484 28785 sgd_solver.cpp:106] Iteration 576, lr = 0.005
I0403 02:39:48.768318 28785 solver.cpp:228] Iteration 592, loss = 0.284139
I0403 02:39:48.768440 28785 solver.cpp:244]     Train net output #0: loss = 0.284139 (* 1 = 0.284139 loss)
I0403 02:39:48.953091 28785 sgd_solver.cpp:106] Iteration 592, lr = 0.005
I0403 02:40:00.425686 28785 solver.cpp:228] Iteration 608, loss = 0.21359
I0403 02:40:00.425995 28785 solver.cpp:244]     Train net output #0: loss = 0.21359 (* 1 = 0.21359 loss)
I0403 02:40:00.582535 28785 sgd_solver.cpp:106] Iteration 608, lr = 0.005
I0403 02:40:12.403302 28785 solver.cpp:228] Iteration 624, loss = 0.225841
I0403 02:40:12.403405 28785 solver.cpp:244]     Train net output #0: loss = 0.225841 (* 1 = 0.225841 loss)
I0403 02:40:12.581871 28785 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 02:40:24.069917 28785 solver.cpp:228] Iteration 640, loss = 0.169568
I0403 02:40:24.070016 28785 solver.cpp:244]     Train net output #0: loss = 0.169568 (* 1 = 0.169568 loss)
I0403 02:40:24.245777 28785 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:40:30.761036 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_650.caffemodel
I0403 02:40:33.559233 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_650.solverstate
I0403 02:40:35.477005 28785 solver.cpp:337] Iteration 650, Testing net (#0)
I0403 02:41:25.040119 28785 solver.cpp:404]     Test net output #0: accuracy = 0.930369
I0403 02:41:25.047618 28785 solver.cpp:404]     Test net output #1: loss = 0.217069 (* 1 = 0.217069 loss)
I0403 02:41:30.145998 28785 solver.cpp:228] Iteration 656, loss = 0.19544
I0403 02:41:30.151588 28785 solver.cpp:244]     Train net output #0: loss = 0.19544 (* 1 = 0.19544 loss)
I0403 02:41:30.321372 28785 sgd_solver.cpp:106] Iteration 656, lr = 0.005
I0403 02:41:42.099895 28785 solver.cpp:228] Iteration 672, loss = 0.185493
I0403 02:41:42.106019 28785 solver.cpp:244]     Train net output #0: loss = 0.185493 (* 1 = 0.185493 loss)
I0403 02:41:42.324960 28785 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 02:41:53.833547 28785 solver.cpp:228] Iteration 688, loss = 0.223656
I0403 02:41:53.840000 28785 solver.cpp:244]     Train net output #0: loss = 0.223656 (* 1 = 0.223656 loss)
I0403 02:41:54.011787 28785 sgd_solver.cpp:106] Iteration 688, lr = 0.005
I0403 02:42:05.810771 28785 solver.cpp:228] Iteration 704, loss = 0.208567
I0403 02:42:05.822046 28785 solver.cpp:244]     Train net output #0: loss = 0.208567 (* 1 = 0.208567 loss)
I0403 02:42:05.930531 28785 sgd_solver.cpp:106] Iteration 704, lr = 0.005
I0403 02:42:17.683065 28785 solver.cpp:228] Iteration 720, loss = 0.160483
I0403 02:42:17.689692 28785 solver.cpp:244]     Train net output #0: loss = 0.160483 (* 1 = 0.160483 loss)
I0403 02:42:17.947110 28785 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:42:29.463477 28785 solver.cpp:228] Iteration 736, loss = 0.149474
I0403 02:42:29.470177 28785 solver.cpp:244]     Train net output #0: loss = 0.149474 (* 1 = 0.149474 loss)
I0403 02:42:29.707378 28785 sgd_solver.cpp:106] Iteration 736, lr = 0.005
I0403 02:42:41.281582 28785 solver.cpp:228] Iteration 752, loss = 0.200362
I0403 02:42:41.287600 28785 solver.cpp:244]     Train net output #0: loss = 0.200363 (* 1 = 0.200363 loss)
I0403 02:42:41.433004 28785 sgd_solver.cpp:106] Iteration 752, lr = 0.005
I0403 02:42:53.205412 28785 solver.cpp:228] Iteration 768, loss = 0.265526
I0403 02:42:53.211529 28785 solver.cpp:244]     Train net output #0: loss = 0.265526 (* 1 = 0.265526 loss)
I0403 02:42:53.467046 28785 sgd_solver.cpp:106] Iteration 768, lr = 0.005
I0403 02:43:04.905508 28785 solver.cpp:228] Iteration 784, loss = 0.22634
I0403 02:43:04.912348 28785 solver.cpp:244]     Train net output #0: loss = 0.22634 (* 1 = 0.22634 loss)
I0403 02:43:05.075335 28785 sgd_solver.cpp:106] Iteration 784, lr = 0.005
I0403 02:43:16.511554 28785 solver.cpp:228] Iteration 800, loss = 0.175325
I0403 02:43:16.518180 28785 solver.cpp:244]     Train net output #0: loss = 0.175325 (* 1 = 0.175325 loss)
I0403 02:43:16.705783 28785 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:43:28.175163 28785 solver.cpp:228] Iteration 816, loss = 0.157079
I0403 02:43:28.181182 28785 solver.cpp:244]     Train net output #0: loss = 0.157079 (* 1 = 0.157079 loss)
I0403 02:43:28.393687 28785 sgd_solver.cpp:106] Iteration 816, lr = 0.005
I0403 02:43:39.907119 28785 solver.cpp:228] Iteration 832, loss = 0.17583
I0403 02:43:39.914038 28785 solver.cpp:244]     Train net output #0: loss = 0.17583 (* 1 = 0.17583 loss)
I0403 02:43:40.083472 28785 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 02:43:51.799139 28785 solver.cpp:228] Iteration 848, loss = 0.189424
I0403 02:43:51.805238 28785 solver.cpp:244]     Train net output #0: loss = 0.189424 (* 1 = 0.189424 loss)
I0403 02:43:52.003552 28785 sgd_solver.cpp:106] Iteration 848, lr = 0.005
I0403 02:44:03.653493 28785 solver.cpp:228] Iteration 864, loss = 0.0750277
I0403 02:44:03.659885 28785 solver.cpp:244]     Train net output #0: loss = 0.0750277 (* 1 = 0.0750277 loss)
I0403 02:44:03.833940 28785 sgd_solver.cpp:106] Iteration 864, lr = 0.005
I0403 02:44:15.487169 28785 solver.cpp:228] Iteration 880, loss = 0.174759
I0403 02:44:15.498323 28785 solver.cpp:244]     Train net output #0: loss = 0.174759 (* 1 = 0.174759 loss)
I0403 02:44:15.662065 28785 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:44:27.202570 28785 solver.cpp:228] Iteration 896, loss = 0.165208
I0403 02:44:27.208621 28785 solver.cpp:244]     Train net output #0: loss = 0.165208 (* 1 = 0.165208 loss)
I0403 02:44:27.382153 28785 sgd_solver.cpp:106] Iteration 896, lr = 0.005
I0403 02:44:38.854912 28785 solver.cpp:228] Iteration 912, loss = 0.146667
I0403 02:44:38.860973 28785 solver.cpp:244]     Train net output #0: loss = 0.146667 (* 1 = 0.146667 loss)
I0403 02:44:39.031859 28785 sgd_solver.cpp:106] Iteration 912, lr = 0.005
I0403 02:44:50.571928 28785 solver.cpp:228] Iteration 928, loss = 0.143185
I0403 02:44:50.579612 28785 solver.cpp:244]     Train net output #0: loss = 0.143185 (* 1 = 0.143185 loss)
I0403 02:44:50.799278 28785 sgd_solver.cpp:106] Iteration 928, lr = 0.005
I0403 02:45:02.183325 28785 solver.cpp:228] Iteration 944, loss = 0.0703183
I0403 02:45:02.188026 28785 solver.cpp:244]     Train net output #0: loss = 0.0703183 (* 1 = 0.0703183 loss)
I0403 02:45:02.393939 28785 sgd_solver.cpp:106] Iteration 944, lr = 0.005
I0403 02:45:13.824064 28785 solver.cpp:228] Iteration 960, loss = 0.142042
I0403 02:45:13.829927 28785 solver.cpp:244]     Train net output #0: loss = 0.142042 (* 1 = 0.142042 loss)
I0403 02:45:14.013370 28785 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:45:24.350680 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_975.caffemodel
I0403 02:45:27.108242 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_975.solverstate
I0403 02:45:28.988035 28785 solver.cpp:337] Iteration 975, Testing net (#0)
I0403 02:46:18.556598 28785 solver.cpp:404]     Test net output #0: accuracy = 0.93765
I0403 02:46:18.562574 28785 solver.cpp:404]     Test net output #1: loss = 0.186334 (* 1 = 0.186334 loss)
I0403 02:46:19.846185 28785 solver.cpp:228] Iteration 976, loss = 0.180359
I0403 02:46:19.852036 28785 solver.cpp:244]     Train net output #0: loss = 0.180359 (* 1 = 0.180359 loss)
I0403 02:46:19.981670 28785 sgd_solver.cpp:106] Iteration 976, lr = 0.005
I0403 02:46:31.793248 28785 solver.cpp:228] Iteration 992, loss = 0.131554
I0403 02:46:31.799749 28785 solver.cpp:244]     Train net output #0: loss = 0.131554 (* 1 = 0.131554 loss)
I0403 02:46:31.976734 28785 sgd_solver.cpp:106] Iteration 992, lr = 0.005
I0403 02:46:43.392504 28785 solver.cpp:228] Iteration 1008, loss = 0.203308
I0403 02:46:43.398077 28785 solver.cpp:244]     Train net output #0: loss = 0.203308 (* 1 = 0.203308 loss)
I0403 02:46:43.594532 28785 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 02:46:55.132550 28785 solver.cpp:228] Iteration 1024, loss = 0.114348
I0403 02:46:55.138988 28785 solver.cpp:244]     Train net output #0: loss = 0.114348 (* 1 = 0.114348 loss)
I0403 02:46:55.310396 28785 sgd_solver.cpp:106] Iteration 1024, lr = 0.005
I0403 02:47:06.875401 28785 solver.cpp:228] Iteration 1040, loss = 0.0245575
I0403 02:47:06.881682 28785 solver.cpp:244]     Train net output #0: loss = 0.0245576 (* 1 = 0.0245576 loss)
I0403 02:47:07.058909 28785 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:47:18.637936 28785 solver.cpp:228] Iteration 1056, loss = 0.222549
I0403 02:47:18.644399 28785 solver.cpp:244]     Train net output #0: loss = 0.222549 (* 1 = 0.222549 loss)
I0403 02:47:18.816164 28785 sgd_solver.cpp:106] Iteration 1056, lr = 0.005
I0403 02:47:30.458742 28785 solver.cpp:228] Iteration 1072, loss = 0.161539
I0403 02:47:30.464489 28785 solver.cpp:244]     Train net output #0: loss = 0.161539 (* 1 = 0.161539 loss)
I0403 02:47:30.630650 28785 sgd_solver.cpp:106] Iteration 1072, lr = 0.005
I0403 02:47:42.147550 28785 solver.cpp:228] Iteration 1088, loss = 0.0737135
I0403 02:47:42.153125 28785 solver.cpp:244]     Train net output #0: loss = 0.0737135 (* 1 = 0.0737135 loss)
I0403 02:47:42.314190 28785 sgd_solver.cpp:106] Iteration 1088, lr = 0.005
I0403 02:47:53.906383 28785 solver.cpp:228] Iteration 1104, loss = 0.199069
I0403 02:47:53.912703 28785 solver.cpp:244]     Train net output #0: loss = 0.199069 (* 1 = 0.199069 loss)
I0403 02:47:54.091781 28785 sgd_solver.cpp:106] Iteration 1104, lr = 0.005
I0403 02:48:05.676120 28785 solver.cpp:228] Iteration 1120, loss = 0.148825
I0403 02:48:05.682624 28785 solver.cpp:244]     Train net output #0: loss = 0.148825 (* 1 = 0.148825 loss)
I0403 02:48:05.865761 28785 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 02:48:17.302253 28785 solver.cpp:228] Iteration 1136, loss = 0.150844
I0403 02:48:17.309164 28785 solver.cpp:244]     Train net output #0: loss = 0.150845 (* 1 = 0.150845 loss)
I0403 02:48:17.497007 28785 sgd_solver.cpp:106] Iteration 1136, lr = 0.005
I0403 02:48:29.085064 28785 solver.cpp:228] Iteration 1152, loss = 0.133841
I0403 02:48:29.091183 28785 solver.cpp:244]     Train net output #0: loss = 0.133841 (* 1 = 0.133841 loss)
I0403 02:48:29.291988 28785 sgd_solver.cpp:106] Iteration 1152, lr = 0.005
I0403 02:48:40.940583 28785 solver.cpp:228] Iteration 1168, loss = 0.149077
I0403 02:48:40.947856 28785 solver.cpp:244]     Train net output #0: loss = 0.149077 (* 1 = 0.149077 loss)
I0403 02:48:41.137823 28785 sgd_solver.cpp:106] Iteration 1168, lr = 0.005
I0403 02:48:52.718564 28785 solver.cpp:228] Iteration 1184, loss = 0.121662
I0403 02:48:52.724700 28785 solver.cpp:244]     Train net output #0: loss = 0.121662 (* 1 = 0.121662 loss)
I0403 02:48:52.939088 28785 sgd_solver.cpp:106] Iteration 1184, lr = 0.005
I0403 02:49:04.573540 28785 solver.cpp:228] Iteration 1200, loss = 0.129713
I0403 02:49:04.580111 28785 solver.cpp:244]     Train net output #0: loss = 0.129713 (* 1 = 0.129713 loss)
I0403 02:49:04.753648 28785 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 02:49:16.411378 28785 solver.cpp:228] Iteration 1216, loss = 0.142574
I0403 02:49:16.417632 28785 solver.cpp:244]     Train net output #0: loss = 0.142574 (* 1 = 0.142574 loss)
I0403 02:49:16.670320 28785 sgd_solver.cpp:106] Iteration 1216, lr = 0.005
I0403 02:49:28.382899 28785 solver.cpp:228] Iteration 1232, loss = 0.133918
I0403 02:49:28.392144 28785 solver.cpp:244]     Train net output #0: loss = 0.133918 (* 1 = 0.133918 loss)
I0403 02:49:28.572573 28785 sgd_solver.cpp:106] Iteration 1232, lr = 0.005
I0403 02:49:40.179191 28785 solver.cpp:228] Iteration 1248, loss = 0.032047
I0403 02:49:40.186341 28785 solver.cpp:244]     Train net output #0: loss = 0.0320471 (* 1 = 0.0320471 loss)
I0403 02:49:40.352470 28785 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 02:49:52.002620 28785 solver.cpp:228] Iteration 1264, loss = 0.0641495
I0403 02:49:52.007818 28785 solver.cpp:244]     Train net output #0: loss = 0.0641495 (* 1 = 0.0641495 loss)
I0403 02:49:52.174659 28785 sgd_solver.cpp:106] Iteration 1264, lr = 0.005
I0403 02:50:03.845309 28785 solver.cpp:228] Iteration 1280, loss = 0.0260378
I0403 02:50:03.851744 28785 solver.cpp:244]     Train net output #0: loss = 0.0260378 (* 1 = 0.0260378 loss)
I0403 02:50:04.057319 28785 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 02:50:15.735795 28785 solver.cpp:228] Iteration 1296, loss = 0.115349
I0403 02:50:15.741935 28785 solver.cpp:244]     Train net output #0: loss = 0.11535 (* 1 = 0.11535 loss)
I0403 02:50:15.907058 28785 sgd_solver.cpp:106] Iteration 1296, lr = 0.005
I0403 02:50:18.102707 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_1300.caffemodel
I0403 02:50:20.877697 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_1300.solverstate
I0403 02:50:22.707304 28785 solver.cpp:337] Iteration 1300, Testing net (#0)
I0403 02:51:12.267946 28785 solver.cpp:404]     Test net output #0: accuracy = 0.942719
I0403 02:51:12.273881 28785 solver.cpp:404]     Test net output #1: loss = 0.177071 (* 1 = 0.177071 loss)
I0403 02:51:21.661442 28785 solver.cpp:228] Iteration 1312, loss = 0.097722
I0403 02:51:21.666777 28785 solver.cpp:244]     Train net output #0: loss = 0.097722 (* 1 = 0.097722 loss)
I0403 02:51:21.850584 28785 sgd_solver.cpp:106] Iteration 1312, lr = 0.005
I0403 02:51:33.296419 28785 solver.cpp:228] Iteration 1328, loss = 0.0355024
I0403 02:51:33.302613 28785 solver.cpp:244]     Train net output #0: loss = 0.0355025 (* 1 = 0.0355025 loss)
I0403 02:51:33.470975 28785 sgd_solver.cpp:106] Iteration 1328, lr = 0.005
I0403 02:51:44.963449 28785 solver.cpp:228] Iteration 1344, loss = 0.12251
I0403 02:51:44.969735 28785 solver.cpp:244]     Train net output #0: loss = 0.12251 (* 1 = 0.12251 loss)
I0403 02:51:45.146889 28785 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 02:51:56.756819 28785 solver.cpp:228] Iteration 1360, loss = 0.157382
I0403 02:51:56.761405 28785 solver.cpp:244]     Train net output #0: loss = 0.157382 (* 1 = 0.157382 loss)
I0403 02:51:56.912930 28785 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 02:52:08.568361 28785 solver.cpp:228] Iteration 1376, loss = 0.145108
I0403 02:52:08.574935 28785 solver.cpp:244]     Train net output #0: loss = 0.145108 (* 1 = 0.145108 loss)
I0403 02:52:08.746958 28785 sgd_solver.cpp:106] Iteration 1376, lr = 0.005
I0403 02:52:20.272366 28785 solver.cpp:228] Iteration 1392, loss = 0.0930702
I0403 02:52:20.279068 28785 solver.cpp:244]     Train net output #0: loss = 0.0930703 (* 1 = 0.0930703 loss)
I0403 02:52:20.557441 28785 sgd_solver.cpp:106] Iteration 1392, lr = 0.005
I0403 02:52:32.270830 28785 solver.cpp:228] Iteration 1408, loss = 0.0263806
I0403 02:52:32.277791 28785 solver.cpp:244]     Train net output #0: loss = 0.0263807 (* 1 = 0.0263807 loss)
I0403 02:52:32.457959 28785 sgd_solver.cpp:106] Iteration 1408, lr = 0.005
I0403 02:52:44.063552 28785 solver.cpp:228] Iteration 1424, loss = 0.162289
I0403 02:52:44.069612 28785 solver.cpp:244]     Train net output #0: loss = 0.162289 (* 1 = 0.162289 loss)
I0403 02:52:44.240639 28785 sgd_solver.cpp:106] Iteration 1424, lr = 0.005
I0403 02:52:56.003832 28785 solver.cpp:228] Iteration 1440, loss = 0.162674
I0403 02:52:56.009963 28785 solver.cpp:244]     Train net output #0: loss = 0.162674 (* 1 = 0.162674 loss)
I0403 02:52:56.167948 28785 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 02:53:07.886358 28785 solver.cpp:228] Iteration 1456, loss = 0.132447
I0403 02:53:07.892174 28785 solver.cpp:244]     Train net output #0: loss = 0.132447 (* 1 = 0.132447 loss)
I0403 02:53:08.061946 28785 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 02:53:19.782376 28785 solver.cpp:228] Iteration 1472, loss = 0.145984
I0403 02:53:19.787875 28785 solver.cpp:244]     Train net output #0: loss = 0.145984 (* 1 = 0.145984 loss)
I0403 02:53:19.961671 28785 sgd_solver.cpp:106] Iteration 1472, lr = 0.005
I0403 02:53:31.994354 28785 solver.cpp:228] Iteration 1488, loss = 0.136815
I0403 02:53:32.000928 28785 solver.cpp:244]     Train net output #0: loss = 0.136815 (* 1 = 0.136815 loss)
I0403 02:53:32.170383 28785 sgd_solver.cpp:106] Iteration 1488, lr = 0.005
I0403 02:53:43.758328 28785 solver.cpp:228] Iteration 1504, loss = 0.171929
I0403 02:53:43.764963 28785 solver.cpp:244]     Train net output #0: loss = 0.171929 (* 1 = 0.171929 loss)
I0403 02:53:43.931041 28785 sgd_solver.cpp:106] Iteration 1504, lr = 0.005
I0403 02:53:55.633875 28785 solver.cpp:228] Iteration 1520, loss = 0.127243
I0403 02:53:55.639163 28785 solver.cpp:244]     Train net output #0: loss = 0.127243 (* 1 = 0.127243 loss)
I0403 02:53:55.795881 28785 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 02:54:07.247529 28785 solver.cpp:228] Iteration 1536, loss = 0.0496543
I0403 02:54:07.253686 28785 solver.cpp:244]     Train net output #0: loss = 0.0496543 (* 1 = 0.0496543 loss)
I0403 02:54:07.426132 28785 sgd_solver.cpp:106] Iteration 1536, lr = 0.005
I0403 02:54:19.025195 28785 solver.cpp:228] Iteration 1552, loss = 0.129418
I0403 02:54:19.030335 28785 solver.cpp:244]     Train net output #0: loss = 0.129418 (* 1 = 0.129418 loss)
I0403 02:54:19.192941 28785 sgd_solver.cpp:106] Iteration 1552, lr = 0.005
I0403 02:54:30.763506 28785 solver.cpp:228] Iteration 1568, loss = 0.159702
I0403 02:54:30.769390 28785 solver.cpp:244]     Train net output #0: loss = 0.159702 (* 1 = 0.159702 loss)
I0403 02:54:30.973562 28785 sgd_solver.cpp:106] Iteration 1568, lr = 0.005
I0403 02:54:42.881692 28785 solver.cpp:228] Iteration 1584, loss = 0.141496
I0403 02:54:42.887944 28785 solver.cpp:244]     Train net output #0: loss = 0.141496 (* 1 = 0.141496 loss)
I0403 02:54:43.059563 28785 sgd_solver.cpp:106] Iteration 1584, lr = 0.005
I0403 02:54:54.697319 28785 solver.cpp:228] Iteration 1600, loss = 0.0866866
I0403 02:54:54.703109 28785 solver.cpp:244]     Train net output #0: loss = 0.0866867 (* 1 = 0.0866867 loss)
I0403 02:54:54.895090 28785 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 02:55:06.742578 28785 solver.cpp:228] Iteration 1616, loss = 0.108942
I0403 02:55:06.748286 28785 solver.cpp:244]     Train net output #0: loss = 0.108942 (* 1 = 0.108942 loss)
I0403 02:55:06.923970 28785 sgd_solver.cpp:106] Iteration 1616, lr = 0.005
I0403 02:55:12.726969 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_1625.caffemodel
I0403 02:55:15.502683 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_1625.solverstate
I0403 02:55:17.401860 28785 solver.cpp:337] Iteration 1625, Testing net (#0)
I0403 02:56:06.964799 28785 solver.cpp:404]     Test net output #0: accuracy = 0.943318
I0403 02:56:06.972285 28785 solver.cpp:404]     Test net output #1: loss = 0.176442 (* 1 = 0.176442 loss)
I0403 02:56:12.731998 28785 solver.cpp:228] Iteration 1632, loss = 0.0689005
I0403 02:56:12.738553 28785 solver.cpp:244]     Train net output #0: loss = 0.0689006 (* 1 = 0.0689006 loss)
I0403 02:56:12.883663 28785 sgd_solver.cpp:106] Iteration 1632, lr = 0.005
I0403 02:56:24.664861 28785 solver.cpp:228] Iteration 1648, loss = 0.182384
I0403 02:56:24.670164 28785 solver.cpp:244]     Train net output #0: loss = 0.182384 (* 1 = 0.182384 loss)
I0403 02:56:24.851936 28785 sgd_solver.cpp:106] Iteration 1648, lr = 0.005
I0403 02:56:36.422974 28785 solver.cpp:228] Iteration 1664, loss = 0.122389
I0403 02:56:36.428716 28785 solver.cpp:244]     Train net output #0: loss = 0.122389 (* 1 = 0.122389 loss)
I0403 02:56:36.658323 28785 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 02:56:48.321848 28785 solver.cpp:228] Iteration 1680, loss = 0.133856
I0403 02:56:48.328279 28785 solver.cpp:244]     Train net output #0: loss = 0.133856 (* 1 = 0.133856 loss)
I0403 02:56:48.501710 28785 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 02:57:00.197332 28785 solver.cpp:228] Iteration 1696, loss = 0.0764911
I0403 02:57:00.203079 28785 solver.cpp:244]     Train net output #0: loss = 0.0764911 (* 1 = 0.0764911 loss)
I0403 02:57:00.401314 28785 sgd_solver.cpp:106] Iteration 1696, lr = 0.005
I0403 02:57:11.946548 28785 solver.cpp:228] Iteration 1712, loss = 0.0293193
I0403 02:57:11.952595 28785 solver.cpp:244]     Train net output #0: loss = 0.0293194 (* 1 = 0.0293194 loss)
I0403 02:57:12.116673 28785 sgd_solver.cpp:106] Iteration 1712, lr = 0.005
I0403 02:57:23.943110 28785 solver.cpp:228] Iteration 1728, loss = 0.071927
I0403 02:57:23.949184 28785 solver.cpp:244]     Train net output #0: loss = 0.0719271 (* 1 = 0.0719271 loss)
I0403 02:57:24.111485 28785 sgd_solver.cpp:106] Iteration 1728, lr = 0.005
I0403 02:57:35.635588 28785 solver.cpp:228] Iteration 1744, loss = 0.111909
I0403 02:57:35.642386 28785 solver.cpp:244]     Train net output #0: loss = 0.11191 (* 1 = 0.11191 loss)
I0403 02:57:35.813571 28785 sgd_solver.cpp:106] Iteration 1744, lr = 0.005
I0403 02:57:47.455690 28785 solver.cpp:228] Iteration 1760, loss = 0.207159
I0403 02:57:47.462235 28785 solver.cpp:244]     Train net output #0: loss = 0.207159 (* 1 = 0.207159 loss)
I0403 02:57:47.626078 28785 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 02:57:59.225945 28785 solver.cpp:228] Iteration 1776, loss = 0.10315
I0403 02:57:59.254233 28785 solver.cpp:244]     Train net output #0: loss = 0.10315 (* 1 = 0.10315 loss)
I0403 02:57:59.404697 28785 sgd_solver.cpp:106] Iteration 1776, lr = 0.005
I0403 02:58:11.097651 28785 solver.cpp:228] Iteration 1792, loss = 0.125946
I0403 02:58:11.103834 28785 solver.cpp:244]     Train net output #0: loss = 0.125946 (* 1 = 0.125946 loss)
I0403 02:58:11.285374 28785 sgd_solver.cpp:106] Iteration 1792, lr = 0.005
I0403 02:58:22.980093 28785 solver.cpp:228] Iteration 1808, loss = 0.172962
I0403 02:58:22.986589 28785 solver.cpp:244]     Train net output #0: loss = 0.172962 (* 1 = 0.172962 loss)
I0403 02:58:23.174814 28785 sgd_solver.cpp:106] Iteration 1808, lr = 0.005
I0403 02:58:34.741498 28785 solver.cpp:228] Iteration 1824, loss = 0.0563145
I0403 02:58:34.747570 28785 solver.cpp:244]     Train net output #0: loss = 0.0563146 (* 1 = 0.0563146 loss)
I0403 02:58:34.921170 28785 sgd_solver.cpp:106] Iteration 1824, lr = 0.005
I0403 02:58:46.648630 28785 solver.cpp:228] Iteration 1840, loss = 0.0881859
I0403 02:58:46.654906 28785 solver.cpp:244]     Train net output #0: loss = 0.088186 (* 1 = 0.088186 loss)
I0403 02:58:46.829095 28785 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 02:58:58.453202 28785 solver.cpp:228] Iteration 1856, loss = 0.0920324
I0403 02:58:58.458369 28785 solver.cpp:244]     Train net output #0: loss = 0.0920325 (* 1 = 0.0920325 loss)
I0403 02:58:58.628049 28785 sgd_solver.cpp:106] Iteration 1856, lr = 0.005
I0403 02:59:10.133662 28785 solver.cpp:228] Iteration 1872, loss = 0.0500769
I0403 02:59:10.139842 28785 solver.cpp:244]     Train net output #0: loss = 0.0500771 (* 1 = 0.0500771 loss)
I0403 02:59:10.319972 28785 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 02:59:21.917105 28785 solver.cpp:228] Iteration 1888, loss = 0.118891
I0403 02:59:21.924769 28785 solver.cpp:244]     Train net output #0: loss = 0.118891 (* 1 = 0.118891 loss)
I0403 02:59:22.100452 28785 sgd_solver.cpp:106] Iteration 1888, lr = 0.005
I0403 02:59:33.621790 28785 solver.cpp:228] Iteration 1904, loss = 0.182174
I0403 02:59:33.628543 28785 solver.cpp:244]     Train net output #0: loss = 0.182174 (* 1 = 0.182174 loss)
I0403 02:59:33.811202 28785 sgd_solver.cpp:106] Iteration 1904, lr = 0.005
I0403 02:59:45.226537 28785 solver.cpp:228] Iteration 1920, loss = 0.0918651
I0403 02:59:45.233541 28785 solver.cpp:244]     Train net output #0: loss = 0.0918652 (* 1 = 0.0918652 loss)
I0403 02:59:45.454319 28785 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 02:59:57.065356 28785 solver.cpp:228] Iteration 1936, loss = 0.0874754
I0403 02:59:57.071362 28785 solver.cpp:244]     Train net output #0: loss = 0.0874755 (* 1 = 0.0874755 loss)
I0403 02:59:57.240687 28785 sgd_solver.cpp:106] Iteration 1936, lr = 0.005
I0403 03:00:06.748778 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_1950.caffemodel
I0403 03:00:09.503705 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_1950.solverstate
I0403 03:00:11.399476 28785 solver.cpp:337] Iteration 1950, Testing net (#0)
I0403 03:01:00.944494 28785 solver.cpp:404]     Test net output #0: accuracy = 0.953456
I0403 03:01:00.950287 28785 solver.cpp:404]     Test net output #1: loss = 0.150731 (* 1 = 0.150731 loss)
I0403 03:01:02.974123 28785 solver.cpp:228] Iteration 1952, loss = 0.0576595
I0403 03:01:02.986558 28785 solver.cpp:244]     Train net output #0: loss = 0.0576597 (* 1 = 0.0576597 loss)
I0403 03:01:03.153437 28785 sgd_solver.cpp:106] Iteration 1952, lr = 0.005
I0403 03:01:14.769527 28785 solver.cpp:228] Iteration 1968, loss = 0.0697577
I0403 03:01:14.775539 28785 solver.cpp:244]     Train net output #0: loss = 0.0697578 (* 1 = 0.0697578 loss)
I0403 03:01:14.967476 28785 sgd_solver.cpp:106] Iteration 1968, lr = 0.005
I0403 03:01:26.585088 28785 solver.cpp:228] Iteration 1984, loss = 0.0675905
I0403 03:01:26.590373 28785 solver.cpp:244]     Train net output #0: loss = 0.0675906 (* 1 = 0.0675906 loss)
I0403 03:01:26.761278 28785 sgd_solver.cpp:106] Iteration 1984, lr = 0.005
I0403 03:01:38.234143 28785 solver.cpp:228] Iteration 2000, loss = 0.0693352
I0403 03:01:38.240176 28785 solver.cpp:244]     Train net output #0: loss = 0.0693353 (* 1 = 0.0693353 loss)
I0403 03:01:38.384649 28785 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 03:01:49.975844 28785 solver.cpp:228] Iteration 2016, loss = 0.0357143
I0403 03:01:49.982233 28785 solver.cpp:244]     Train net output #0: loss = 0.0357144 (* 1 = 0.0357144 loss)
I0403 03:01:50.171082 28785 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 03:02:01.929841 28785 solver.cpp:228] Iteration 2032, loss = 0.030406
I0403 03:02:01.935879 28785 solver.cpp:244]     Train net output #0: loss = 0.0304061 (* 1 = 0.0304061 loss)
I0403 03:02:02.055105 28785 sgd_solver.cpp:106] Iteration 2032, lr = 0.005
I0403 03:02:13.842361 28785 solver.cpp:228] Iteration 2048, loss = 0.0324296
I0403 03:02:13.847640 28785 solver.cpp:244]     Train net output #0: loss = 0.0324297 (* 1 = 0.0324297 loss)
I0403 03:02:14.003417 28785 sgd_solver.cpp:106] Iteration 2048, lr = 0.005
I0403 03:02:25.657222 28785 solver.cpp:228] Iteration 2064, loss = 0.0501187
I0403 03:02:25.663599 28785 solver.cpp:244]     Train net output #0: loss = 0.0501188 (* 1 = 0.0501188 loss)
I0403 03:02:25.834323 28785 sgd_solver.cpp:106] Iteration 2064, lr = 0.005
I0403 03:02:37.405268 28785 solver.cpp:228] Iteration 2080, loss = 0.083536
I0403 03:02:37.412232 28785 solver.cpp:244]     Train net output #0: loss = 0.0835362 (* 1 = 0.0835362 loss)
I0403 03:02:37.577697 28785 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:02:49.191128 28785 solver.cpp:228] Iteration 2096, loss = 0.0988235
I0403 03:02:49.200376 28785 solver.cpp:244]     Train net output #0: loss = 0.0988237 (* 1 = 0.0988237 loss)
I0403 03:02:49.370612 28785 sgd_solver.cpp:106] Iteration 2096, lr = 0.005
I0403 03:03:01.073833 28785 solver.cpp:228] Iteration 2112, loss = 0.174182
I0403 03:03:01.079200 28785 solver.cpp:244]     Train net output #0: loss = 0.174182 (* 1 = 0.174182 loss)
I0403 03:03:01.257413 28785 sgd_solver.cpp:106] Iteration 2112, lr = 0.005
I0403 03:03:12.789649 28785 solver.cpp:228] Iteration 2128, loss = 0.0940207
I0403 03:03:12.795725 28785 solver.cpp:244]     Train net output #0: loss = 0.0940209 (* 1 = 0.0940209 loss)
I0403 03:03:12.972729 28785 sgd_solver.cpp:106] Iteration 2128, lr = 0.005
I0403 03:03:24.694625 28785 solver.cpp:228] Iteration 2144, loss = 0.0787553
I0403 03:03:24.700259 28785 solver.cpp:244]     Train net output #0: loss = 0.0787555 (* 1 = 0.0787555 loss)
I0403 03:03:24.881427 28785 sgd_solver.cpp:106] Iteration 2144, lr = 0.005
I0403 03:03:36.589100 28785 solver.cpp:228] Iteration 2160, loss = 0.0386289
I0403 03:03:36.595870 28785 solver.cpp:244]     Train net output #0: loss = 0.0386291 (* 1 = 0.0386291 loss)
I0403 03:03:36.744786 28785 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 03:03:48.393345 28785 solver.cpp:228] Iteration 2176, loss = 0.0912165
I0403 03:03:48.399180 28785 solver.cpp:244]     Train net output #0: loss = 0.0912166 (* 1 = 0.0912166 loss)
I0403 03:03:48.571795 28785 sgd_solver.cpp:106] Iteration 2176, lr = 0.005
I0403 03:04:00.135645 28785 solver.cpp:228] Iteration 2192, loss = 0.01028
I0403 03:04:00.142151 28785 solver.cpp:244]     Train net output #0: loss = 0.0102801 (* 1 = 0.0102801 loss)
I0403 03:04:00.313364 28785 sgd_solver.cpp:106] Iteration 2192, lr = 0.005
I0403 03:04:12.175982 28785 solver.cpp:228] Iteration 2208, loss = 0.0399109
I0403 03:04:12.182454 28785 solver.cpp:244]     Train net output #0: loss = 0.039911 (* 1 = 0.039911 loss)
I0403 03:04:12.353777 28785 sgd_solver.cpp:106] Iteration 2208, lr = 0.005
I0403 03:04:24.030187 28785 solver.cpp:228] Iteration 2224, loss = 0.129677
I0403 03:04:24.034847 28785 solver.cpp:244]     Train net output #0: loss = 0.129677 (* 1 = 0.129677 loss)
I0403 03:04:24.197996 28785 sgd_solver.cpp:106] Iteration 2224, lr = 0.005
I0403 03:04:35.807224 28785 solver.cpp:228] Iteration 2240, loss = 0.0883973
I0403 03:04:35.813832 28785 solver.cpp:244]     Train net output #0: loss = 0.0883974 (* 1 = 0.0883974 loss)
I0403 03:04:35.984005 28785 sgd_solver.cpp:106] Iteration 2240, lr = 0.005
I0403 03:04:47.629122 28785 solver.cpp:228] Iteration 2256, loss = 0.0647825
I0403 03:04:47.635041 28785 solver.cpp:244]     Train net output #0: loss = 0.0647826 (* 1 = 0.0647826 loss)
I0403 03:04:47.801062 28785 sgd_solver.cpp:106] Iteration 2256, lr = 0.005
I0403 03:04:59.312422 28785 solver.cpp:228] Iteration 2272, loss = 0.0452667
I0403 03:04:59.319066 28785 solver.cpp:244]     Train net output #0: loss = 0.0452668 (* 1 = 0.0452668 loss)
I0403 03:04:59.495753 28785 sgd_solver.cpp:106] Iteration 2272, lr = 0.005
I0403 03:05:00.945094 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_2275.caffemodel
I0403 03:05:03.640738 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_2275.solverstate
I0403 03:05:05.470480 28785 solver.cpp:337] Iteration 2275, Testing net (#0)
I0403 03:05:55.039216 28785 solver.cpp:404]     Test net output #0: accuracy = 0.950876
I0403 03:05:55.044553 28785 solver.cpp:404]     Test net output #1: loss = 0.157255 (* 1 = 0.157255 loss)
I0403 03:06:05.128064 28785 solver.cpp:228] Iteration 2288, loss = 0.0564348
I0403 03:06:05.134642 28785 solver.cpp:244]     Train net output #0: loss = 0.0564349 (* 1 = 0.0564349 loss)
I0403 03:06:05.306305 28785 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 03:06:16.803823 28785 solver.cpp:228] Iteration 2304, loss = 0.0383148
I0403 03:06:16.809891 28785 solver.cpp:244]     Train net output #0: loss = 0.0383149 (* 1 = 0.0383149 loss)
I0403 03:06:16.999017 28785 sgd_solver.cpp:106] Iteration 2304, lr = 0.005
I0403 03:06:28.628862 28785 solver.cpp:228] Iteration 2320, loss = 0.101628
I0403 03:06:28.635193 28785 solver.cpp:244]     Train net output #0: loss = 0.101628 (* 1 = 0.101628 loss)
I0403 03:06:28.802608 28785 sgd_solver.cpp:106] Iteration 2320, lr = 0.005
I0403 03:06:40.308992 28785 solver.cpp:228] Iteration 2336, loss = 0.0866297
I0403 03:06:40.314540 28785 solver.cpp:244]     Train net output #0: loss = 0.0866298 (* 1 = 0.0866298 loss)
I0403 03:06:40.492091 28785 sgd_solver.cpp:106] Iteration 2336, lr = 0.005
I0403 03:06:52.212589 28785 solver.cpp:228] Iteration 2352, loss = 0.0391151
I0403 03:06:52.218883 28785 solver.cpp:244]     Train net output #0: loss = 0.0391152 (* 1 = 0.0391152 loss)
I0403 03:06:52.384826 28785 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 03:07:04.001438 28785 solver.cpp:228] Iteration 2368, loss = 0.0457578
I0403 03:07:04.015477 28785 solver.cpp:244]     Train net output #0: loss = 0.0457579 (* 1 = 0.0457579 loss)
I0403 03:07:04.190987 28785 sgd_solver.cpp:106] Iteration 2368, lr = 0.005
I0403 03:07:15.890494 28785 solver.cpp:228] Iteration 2384, loss = 0.0758574
I0403 03:07:15.897117 28785 solver.cpp:244]     Train net output #0: loss = 0.0758575 (* 1 = 0.0758575 loss)
I0403 03:07:16.054994 28785 sgd_solver.cpp:106] Iteration 2384, lr = 0.005
I0403 03:07:27.646852 28785 solver.cpp:228] Iteration 2400, loss = 0.0563243
I0403 03:07:27.652667 28785 solver.cpp:244]     Train net output #0: loss = 0.0563244 (* 1 = 0.0563244 loss)
I0403 03:07:27.858058 28785 sgd_solver.cpp:106] Iteration 2400, lr = 0.005
I0403 03:07:39.325618 28785 solver.cpp:228] Iteration 2416, loss = 0.183158
I0403 03:07:39.332142 28785 solver.cpp:244]     Train net output #0: loss = 0.183158 (* 1 = 0.183158 loss)
I0403 03:07:39.502189 28785 sgd_solver.cpp:106] Iteration 2416, lr = 0.005
I0403 03:07:51.116114 28785 solver.cpp:228] Iteration 2432, loss = 0.0582103
I0403 03:07:51.122117 28785 solver.cpp:244]     Train net output #0: loss = 0.0582104 (* 1 = 0.0582104 loss)
I0403 03:07:51.291654 28785 sgd_solver.cpp:106] Iteration 2432, lr = 0.005
I0403 03:08:02.813968 28785 solver.cpp:228] Iteration 2448, loss = 0.0767254
I0403 03:08:02.820389 28785 solver.cpp:244]     Train net output #0: loss = 0.0767255 (* 1 = 0.0767255 loss)
I0403 03:08:02.982559 28785 sgd_solver.cpp:106] Iteration 2448, lr = 0.005
I0403 03:08:14.537545 28785 solver.cpp:228] Iteration 2464, loss = 0.0345636
I0403 03:08:14.543234 28785 solver.cpp:244]     Train net output #0: loss = 0.0345638 (* 1 = 0.0345638 loss)
I0403 03:08:14.721001 28785 sgd_solver.cpp:106] Iteration 2464, lr = 0.005
I0403 03:08:26.335512 28785 solver.cpp:228] Iteration 2480, loss = 0.0371352
I0403 03:08:26.341693 28785 solver.cpp:244]     Train net output #0: loss = 0.0371353 (* 1 = 0.0371353 loss)
I0403 03:08:26.519841 28785 sgd_solver.cpp:106] Iteration 2480, lr = 0.005
I0403 03:08:38.227680 28785 solver.cpp:228] Iteration 2496, loss = 0.0199805
I0403 03:08:38.233891 28785 solver.cpp:244]     Train net output #0: loss = 0.0199806 (* 1 = 0.0199806 loss)
I0403 03:08:38.393033 28785 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 03:08:49.947109 28785 solver.cpp:228] Iteration 2512, loss = 0.0382022
I0403 03:08:49.953379 28785 solver.cpp:244]     Train net output #0: loss = 0.0382023 (* 1 = 0.0382023 loss)
I0403 03:08:50.105516 28785 sgd_solver.cpp:106] Iteration 2512, lr = 0.005
I0403 03:09:01.723682 28785 solver.cpp:228] Iteration 2528, loss = 0.111846
I0403 03:09:01.730118 28785 solver.cpp:244]     Train net output #0: loss = 0.111846 (* 1 = 0.111846 loss)
I0403 03:09:01.925878 28785 sgd_solver.cpp:106] Iteration 2528, lr = 0.005
I0403 03:09:13.561864 28785 solver.cpp:228] Iteration 2544, loss = 0.0206578
I0403 03:09:13.567924 28785 solver.cpp:244]     Train net output #0: loss = 0.0206579 (* 1 = 0.0206579 loss)
I0403 03:09:13.739385 28785 sgd_solver.cpp:106] Iteration 2544, lr = 0.005
I0403 03:09:25.325808 28785 solver.cpp:228] Iteration 2560, loss = 0.0939763
I0403 03:09:25.333329 28785 solver.cpp:244]     Train net output #0: loss = 0.0939764 (* 1 = 0.0939764 loss)
I0403 03:09:25.507064 28785 sgd_solver.cpp:106] Iteration 2560, lr = 0.005
I0403 03:09:37.426913 28785 solver.cpp:228] Iteration 2576, loss = 0.0941905
I0403 03:09:37.433045 28785 solver.cpp:244]     Train net output #0: loss = 0.0941906 (* 1 = 0.0941906 loss)
I0403 03:09:37.626276 28785 sgd_solver.cpp:106] Iteration 2576, lr = 0.005
I0403 03:09:49.391108 28785 solver.cpp:228] Iteration 2592, loss = 0.0661318
I0403 03:09:49.396922 28785 solver.cpp:244]     Train net output #0: loss = 0.0661319 (* 1 = 0.0661319 loss)
I0403 03:09:49.605659 28785 sgd_solver.cpp:106] Iteration 2592, lr = 0.005
I0403 03:09:54.691743 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_2600.caffemodel
I0403 03:09:57.464025 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_2600.solverstate
I0403 03:09:59.352946 28785 solver.cpp:337] Iteration 2600, Testing net (#0)
I0403 03:10:48.910806 28785 solver.cpp:404]     Test net output #0: accuracy = 0.954747
I0403 03:10:48.918495 28785 solver.cpp:404]     Test net output #1: loss = 0.150291 (* 1 = 0.150291 loss)
I0403 03:10:55.435426 28785 solver.cpp:228] Iteration 2608, loss = 0.0376545
I0403 03:10:55.441455 28785 solver.cpp:244]     Train net output #0: loss = 0.0376546 (* 1 = 0.0376546 loss)
I0403 03:10:55.613626 28785 sgd_solver.cpp:106] Iteration 2608, lr = 0.005
I0403 03:11:07.102180 28785 solver.cpp:228] Iteration 2624, loss = 0.144577
I0403 03:11:07.107666 28785 solver.cpp:244]     Train net output #0: loss = 0.144578 (* 1 = 0.144578 loss)
I0403 03:11:07.285332 28785 sgd_solver.cpp:106] Iteration 2624, lr = 0.005
I0403 03:11:18.765220 28785 solver.cpp:228] Iteration 2640, loss = 0.0185813
I0403 03:11:18.771278 28785 solver.cpp:244]     Train net output #0: loss = 0.0185814 (* 1 = 0.0185814 loss)
I0403 03:11:18.953830 28785 sgd_solver.cpp:106] Iteration 2640, lr = 0.005
I0403 03:11:30.510313 28785 solver.cpp:228] Iteration 2656, loss = 0.167261
I0403 03:11:30.516330 28785 solver.cpp:244]     Train net output #0: loss = 0.167261 (* 1 = 0.167261 loss)
I0403 03:11:30.713033 28785 sgd_solver.cpp:106] Iteration 2656, lr = 0.005
I0403 03:11:42.293993 28785 solver.cpp:228] Iteration 2672, loss = 0.0451131
I0403 03:11:42.299911 28785 solver.cpp:244]     Train net output #0: loss = 0.0451132 (* 1 = 0.0451132 loss)
I0403 03:11:42.466119 28785 sgd_solver.cpp:106] Iteration 2672, lr = 0.005
I0403 03:11:54.299451 28785 solver.cpp:228] Iteration 2688, loss = 0.0184371
I0403 03:11:54.304908 28785 solver.cpp:244]     Train net output #0: loss = 0.0184372 (* 1 = 0.0184372 loss)
I0403 03:11:54.472686 28785 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 03:12:06.110646 28785 solver.cpp:228] Iteration 2704, loss = 0.0905224
I0403 03:12:06.117024 28785 solver.cpp:244]     Train net output #0: loss = 0.0905225 (* 1 = 0.0905225 loss)
I0403 03:12:06.287703 28785 sgd_solver.cpp:106] Iteration 2704, lr = 0.005
I0403 03:12:17.832362 28785 solver.cpp:228] Iteration 2720, loss = 0.0236971
I0403 03:12:17.838685 28785 solver.cpp:244]     Train net output #0: loss = 0.0236972 (* 1 = 0.0236972 loss)
I0403 03:12:18.011891 28785 sgd_solver.cpp:106] Iteration 2720, lr = 0.005
I0403 03:12:29.413851 28785 solver.cpp:228] Iteration 2736, loss = 0.0240648
I0403 03:12:29.423470 28785 solver.cpp:244]     Train net output #0: loss = 0.0240649 (* 1 = 0.0240649 loss)
I0403 03:12:29.667585 28785 sgd_solver.cpp:106] Iteration 2736, lr = 0.005
I0403 03:12:41.145345 28785 solver.cpp:228] Iteration 2752, loss = 0.0890161
I0403 03:12:41.150882 28785 solver.cpp:244]     Train net output #0: loss = 0.0890162 (* 1 = 0.0890162 loss)
I0403 03:12:41.341662 28785 sgd_solver.cpp:106] Iteration 2752, lr = 0.005
I0403 03:12:52.921356 28785 solver.cpp:228] Iteration 2768, loss = 0.0713604
I0403 03:12:52.928961 28785 solver.cpp:244]     Train net output #0: loss = 0.0713605 (* 1 = 0.0713605 loss)
I0403 03:12:53.109571 28785 sgd_solver.cpp:106] Iteration 2768, lr = 0.005
I0403 03:13:04.720705 28785 solver.cpp:228] Iteration 2784, loss = 0.0641426
I0403 03:13:04.727548 28785 solver.cpp:244]     Train net output #0: loss = 0.0641427 (* 1 = 0.0641427 loss)
I0403 03:13:04.915330 28785 sgd_solver.cpp:106] Iteration 2784, lr = 0.005
I0403 03:13:16.463454 28785 solver.cpp:228] Iteration 2800, loss = 0.0179075
I0403 03:13:16.469414 28785 solver.cpp:244]     Train net output #0: loss = 0.0179076 (* 1 = 0.0179076 loss)
I0403 03:13:16.684303 28785 sgd_solver.cpp:106] Iteration 2800, lr = 0.005
I0403 03:13:28.462636 28785 solver.cpp:228] Iteration 2816, loss = 0.0119658
I0403 03:13:28.469008 28785 solver.cpp:244]     Train net output #0: loss = 0.0119659 (* 1 = 0.0119659 loss)
I0403 03:13:28.620932 28785 sgd_solver.cpp:106] Iteration 2816, lr = 0.005
I0403 03:13:40.399155 28785 solver.cpp:228] Iteration 2832, loss = 0.0244747
I0403 03:13:40.405429 28785 solver.cpp:244]     Train net output #0: loss = 0.0244748 (* 1 = 0.0244748 loss)
I0403 03:13:40.513968 28785 sgd_solver.cpp:106] Iteration 2832, lr = 0.005
I0403 03:13:52.405573 28785 solver.cpp:228] Iteration 2848, loss = 0.069356
I0403 03:13:52.411231 28785 solver.cpp:244]     Train net output #0: loss = 0.0693561 (* 1 = 0.0693561 loss)
I0403 03:13:52.575572 28785 sgd_solver.cpp:106] Iteration 2848, lr = 0.005
I0403 03:14:04.167012 28785 solver.cpp:228] Iteration 2864, loss = 0.0227083
I0403 03:14:04.172757 28785 solver.cpp:244]     Train net output #0: loss = 0.0227084 (* 1 = 0.0227084 loss)
I0403 03:14:04.341616 28785 sgd_solver.cpp:106] Iteration 2864, lr = 0.005
I0403 03:14:15.915500 28785 solver.cpp:228] Iteration 2880, loss = 0.0739125
I0403 03:14:15.922185 28785 solver.cpp:244]     Train net output #0: loss = 0.0739126 (* 1 = 0.0739126 loss)
I0403 03:14:16.111032 28785 sgd_solver.cpp:106] Iteration 2880, lr = 0.005
I0403 03:14:27.523908 28785 solver.cpp:228] Iteration 2896, loss = 0.0414062
I0403 03:14:27.529990 28785 solver.cpp:244]     Train net output #0: loss = 0.0414063 (* 1 = 0.0414063 loss)
I0403 03:14:27.683331 28785 sgd_solver.cpp:106] Iteration 2896, lr = 0.005
I0403 03:14:39.352653 28785 solver.cpp:228] Iteration 2912, loss = 0.0292895
I0403 03:14:39.356928 28785 solver.cpp:244]     Train net output #0: loss = 0.0292896 (* 1 = 0.0292896 loss)
I0403 03:14:39.530346 28785 sgd_solver.cpp:106] Iteration 2912, lr = 0.005
I0403 03:14:48.280369 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_2925.caffemodel
I0403 03:14:51.044095 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_2925.solverstate
I0403 03:14:52.937960 28785 solver.cpp:337] Iteration 2925, Testing net (#0)
I0403 03:15:42.483454 28785 solver.cpp:404]     Test net output #0: accuracy = 0.954239
I0403 03:15:42.490589 28785 solver.cpp:404]     Test net output #1: loss = 0.153501 (* 1 = 0.153501 loss)
I0403 03:15:45.369819 28785 solver.cpp:228] Iteration 2928, loss = 0.0502836
I0403 03:15:45.373849 28785 solver.cpp:244]     Train net output #0: loss = 0.0502837 (* 1 = 0.0502837 loss)
I0403 03:15:45.525617 28785 sgd_solver.cpp:106] Iteration 2928, lr = 0.005
I0403 03:15:57.082558 28785 solver.cpp:228] Iteration 2944, loss = 0.0422369
I0403 03:15:57.087647 28785 solver.cpp:244]     Train net output #0: loss = 0.042237 (* 1 = 0.042237 loss)
I0403 03:15:57.298300 28785 sgd_solver.cpp:106] Iteration 2944, lr = 0.005
I0403 03:16:08.953791 28785 solver.cpp:228] Iteration 2960, loss = 0.03796
I0403 03:16:08.960137 28785 solver.cpp:244]     Train net output #0: loss = 0.0379601 (* 1 = 0.0379601 loss)
I0403 03:16:09.141160 28785 sgd_solver.cpp:106] Iteration 2960, lr = 0.005
I0403 03:16:20.725189 28785 solver.cpp:228] Iteration 2976, loss = 0.0516807
I0403 03:16:20.731242 28785 solver.cpp:244]     Train net output #0: loss = 0.0516808 (* 1 = 0.0516808 loss)
I0403 03:16:20.924417 28785 sgd_solver.cpp:106] Iteration 2976, lr = 0.005
I0403 03:16:32.522132 28785 solver.cpp:228] Iteration 2992, loss = 0.0141947
I0403 03:16:32.528041 28785 solver.cpp:244]     Train net output #0: loss = 0.0141948 (* 1 = 0.0141948 loss)
I0403 03:16:32.674005 28785 sgd_solver.cpp:106] Iteration 2992, lr = 0.005
I0403 03:16:44.337083 28785 solver.cpp:228] Iteration 3008, loss = 0.021384
I0403 03:16:44.343109 28785 solver.cpp:244]     Train net output #0: loss = 0.0213841 (* 1 = 0.0213841 loss)
I0403 03:16:44.500918 28785 sgd_solver.cpp:106] Iteration 3008, lr = 0.005
I0403 03:16:56.177436 28785 solver.cpp:228] Iteration 3024, loss = 0.0131798
I0403 03:16:56.183553 28785 solver.cpp:244]     Train net output #0: loss = 0.0131799 (* 1 = 0.0131799 loss)
I0403 03:16:56.395714 28785 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 03:17:08.123872 28785 solver.cpp:228] Iteration 3040, loss = 0.0784476
I0403 03:17:08.130381 28785 solver.cpp:244]     Train net output #0: loss = 0.0784477 (* 1 = 0.0784477 loss)
I0403 03:17:08.307420 28785 sgd_solver.cpp:106] Iteration 3040, lr = 0.005
I0403 03:17:20.046902 28785 solver.cpp:228] Iteration 3056, loss = 0.027857
I0403 03:17:20.052909 28785 solver.cpp:244]     Train net output #0: loss = 0.0278572 (* 1 = 0.0278572 loss)
I0403 03:17:20.220525 28785 sgd_solver.cpp:106] Iteration 3056, lr = 0.005
I0403 03:17:31.968070 28785 solver.cpp:228] Iteration 3072, loss = 0.0383497
I0403 03:17:31.973811 28785 solver.cpp:244]     Train net output #0: loss = 0.0383498 (* 1 = 0.0383498 loss)
I0403 03:17:32.144875 28785 sgd_solver.cpp:106] Iteration 3072, lr = 0.005
I0403 03:17:43.684139 28785 solver.cpp:228] Iteration 3088, loss = 0.0462152
I0403 03:17:43.689990 28785 solver.cpp:244]     Train net output #0: loss = 0.0462153 (* 1 = 0.0462153 loss)
I0403 03:17:43.838729 28785 sgd_solver.cpp:106] Iteration 3088, lr = 0.005
I0403 03:17:55.323556 28785 solver.cpp:228] Iteration 3104, loss = 0.0300249
I0403 03:17:55.329242 28785 solver.cpp:244]     Train net output #0: loss = 0.030025 (* 1 = 0.030025 loss)
I0403 03:17:55.504233 28785 sgd_solver.cpp:106] Iteration 3104, lr = 0.005
I0403 03:18:07.271299 28785 solver.cpp:228] Iteration 3120, loss = 0.0112818
I0403 03:18:07.276993 28785 solver.cpp:244]     Train net output #0: loss = 0.0112819 (* 1 = 0.0112819 loss)
I0403 03:18:07.418054 28785 sgd_solver.cpp:106] Iteration 3120, lr = 0.005
I0403 03:18:19.108464 28785 solver.cpp:228] Iteration 3136, loss = 0.0786586
I0403 03:18:19.114166 28785 solver.cpp:244]     Train net output #0: loss = 0.0786587 (* 1 = 0.0786587 loss)
I0403 03:18:19.287098 28785 sgd_solver.cpp:106] Iteration 3136, lr = 0.005
I0403 03:18:30.817996 28785 solver.cpp:228] Iteration 3152, loss = 0.0138457
I0403 03:18:30.823737 28785 solver.cpp:244]     Train net output #0: loss = 0.0138458 (* 1 = 0.0138458 loss)
I0403 03:18:31.016868 28785 sgd_solver.cpp:106] Iteration 3152, lr = 0.005
I0403 03:18:42.555670 28785 solver.cpp:228] Iteration 3168, loss = 0.0211795
I0403 03:18:42.562044 28785 solver.cpp:244]     Train net output #0: loss = 0.0211796 (* 1 = 0.0211796 loss)
I0403 03:18:42.741628 28785 sgd_solver.cpp:106] Iteration 3168, lr = 0.005
I0403 03:18:54.353477 28785 solver.cpp:228] Iteration 3184, loss = 0.0170767
I0403 03:18:54.359417 28785 solver.cpp:244]     Train net output #0: loss = 0.0170768 (* 1 = 0.0170768 loss)
I0403 03:18:54.556936 28785 sgd_solver.cpp:106] Iteration 3184, lr = 0.005
I0403 03:19:05.953229 28785 solver.cpp:228] Iteration 3200, loss = 0.163435
I0403 03:19:05.962713 28785 solver.cpp:244]     Train net output #0: loss = 0.163435 (* 1 = 0.163435 loss)
I0403 03:19:06.131281 28785 sgd_solver.cpp:106] Iteration 3200, lr = 0.005
I0403 03:19:17.675678 28785 solver.cpp:228] Iteration 3216, loss = 0.0521741
I0403 03:19:17.682898 28785 solver.cpp:244]     Train net output #0: loss = 0.0521742 (* 1 = 0.0521742 loss)
I0403 03:19:17.855144 28785 sgd_solver.cpp:106] Iteration 3216, lr = 0.005
I0403 03:19:29.467553 28785 solver.cpp:228] Iteration 3232, loss = 0.0152372
I0403 03:19:29.473407 28785 solver.cpp:244]     Train net output #0: loss = 0.0152373 (* 1 = 0.0152373 loss)
I0403 03:19:29.644160 28785 sgd_solver.cpp:106] Iteration 3232, lr = 0.005
I0403 03:19:41.228090 28785 solver.cpp:228] Iteration 3248, loss = 0.0111128
I0403 03:19:41.235906 28785 solver.cpp:244]     Train net output #0: loss = 0.0111129 (* 1 = 0.0111129 loss)
I0403 03:19:41.390199 28785 sgd_solver.cpp:106] Iteration 3248, lr = 0.005
I0403 03:19:42.146741 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_3250.caffemodel
I0403 03:19:44.939998 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_3250.solverstate
I0403 03:19:46.846587 28785 solver.cpp:337] Iteration 3250, Testing net (#0)
I0403 03:20:36.399211 28785 solver.cpp:404]     Test net output #0: accuracy = 0.957742
I0403 03:20:36.404796 28785 solver.cpp:404]     Test net output #1: loss = 0.143899 (* 1 = 0.143899 loss)
I0403 03:20:47.075223 28785 solver.cpp:228] Iteration 3264, loss = 0.0347513
I0403 03:20:47.080062 28785 solver.cpp:244]     Train net output #0: loss = 0.0347514 (* 1 = 0.0347514 loss)
I0403 03:20:47.244434 28785 sgd_solver.cpp:106] Iteration 3264, lr = 0.0005
I0403 03:20:59.136111 28785 solver.cpp:228] Iteration 3280, loss = 0.0161521
I0403 03:20:59.141175 28785 solver.cpp:244]     Train net output #0: loss = 0.0161522 (* 1 = 0.0161522 loss)
I0403 03:20:59.300881 28785 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 03:21:10.897861 28785 solver.cpp:228] Iteration 3296, loss = 0.0216823
I0403 03:21:10.903090 28785 solver.cpp:244]     Train net output #0: loss = 0.0216824 (* 1 = 0.0216824 loss)
I0403 03:21:11.074219 28785 sgd_solver.cpp:106] Iteration 3296, lr = 0.0005
I0403 03:21:22.674968 28785 solver.cpp:228] Iteration 3312, loss = 0.0478621
I0403 03:21:22.681514 28785 solver.cpp:244]     Train net output #0: loss = 0.0478622 (* 1 = 0.0478622 loss)
I0403 03:21:22.898311 28785 sgd_solver.cpp:106] Iteration 3312, lr = 0.0005
I0403 03:21:34.491761 28785 solver.cpp:228] Iteration 3328, loss = 0.0307277
I0403 03:21:34.499999 28785 solver.cpp:244]     Train net output #0: loss = 0.0307278 (* 1 = 0.0307278 loss)
I0403 03:21:34.698164 28785 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 03:21:46.237475 28785 solver.cpp:228] Iteration 3344, loss = 0.0453395
I0403 03:21:46.243788 28785 solver.cpp:244]     Train net output #0: loss = 0.0453397 (* 1 = 0.0453397 loss)
I0403 03:21:46.423137 28785 sgd_solver.cpp:106] Iteration 3344, lr = 0.0005
I0403 03:21:58.008036 28785 solver.cpp:228] Iteration 3360, loss = 0.00285494
I0403 03:21:58.015221 28785 solver.cpp:244]     Train net output #0: loss = 0.00285505 (* 1 = 0.00285505 loss)
I0403 03:21:58.194344 28785 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 03:22:09.765177 28785 solver.cpp:228] Iteration 3376, loss = 0.01727
I0403 03:22:09.771976 28785 solver.cpp:244]     Train net output #0: loss = 0.0172701 (* 1 = 0.0172701 loss)
I0403 03:22:09.941570 28785 sgd_solver.cpp:106] Iteration 3376, lr = 0.0005
I0403 03:22:21.666260 28785 solver.cpp:228] Iteration 3392, loss = 0.0214886
I0403 03:22:21.672286 28785 solver.cpp:244]     Train net output #0: loss = 0.0214887 (* 1 = 0.0214887 loss)
I0403 03:22:21.834980 28785 sgd_solver.cpp:106] Iteration 3392, lr = 0.0005
I0403 03:22:33.452862 28785 solver.cpp:228] Iteration 3408, loss = 0.0218984
I0403 03:22:33.458108 28785 solver.cpp:244]     Train net output #0: loss = 0.0218985 (* 1 = 0.0218985 loss)
I0403 03:22:33.625165 28785 sgd_solver.cpp:106] Iteration 3408, lr = 0.0005
I0403 03:22:45.305095 28785 solver.cpp:228] Iteration 3424, loss = 0.00282311
I0403 03:22:45.311007 28785 solver.cpp:244]     Train net output #0: loss = 0.00282322 (* 1 = 0.00282322 loss)
I0403 03:22:45.488334 28785 sgd_solver.cpp:106] Iteration 3424, lr = 0.0005
I0403 03:22:57.328936 28785 solver.cpp:228] Iteration 3440, loss = 0.00862607
I0403 03:22:57.337023 28785 solver.cpp:244]     Train net output #0: loss = 0.00862619 (* 1 = 0.00862619 loss)
I0403 03:22:57.514616 28785 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 03:23:08.994488 28785 solver.cpp:228] Iteration 3456, loss = 0.0134088
I0403 03:23:09.001411 28785 solver.cpp:244]     Train net output #0: loss = 0.0134089 (* 1 = 0.0134089 loss)
I0403 03:23:09.218312 28785 sgd_solver.cpp:106] Iteration 3456, lr = 0.0005
I0403 03:23:20.897672 28785 solver.cpp:228] Iteration 3472, loss = 0.0485408
I0403 03:23:20.905483 28785 solver.cpp:244]     Train net output #0: loss = 0.048541 (* 1 = 0.048541 loss)
I0403 03:23:21.097841 28785 sgd_solver.cpp:106] Iteration 3472, lr = 0.0005
I0403 03:23:32.573686 28785 solver.cpp:228] Iteration 3488, loss = 0.0118922
I0403 03:23:32.580713 28785 solver.cpp:244]     Train net output #0: loss = 0.0118923 (* 1 = 0.0118923 loss)
I0403 03:23:32.751230 28785 sgd_solver.cpp:106] Iteration 3488, lr = 0.0005
I0403 03:23:44.376766 28785 solver.cpp:228] Iteration 3504, loss = 0.0473899
I0403 03:23:44.383075 28785 solver.cpp:244]     Train net output #0: loss = 0.04739 (* 1 = 0.04739 loss)
I0403 03:23:44.535946 28785 sgd_solver.cpp:106] Iteration 3504, lr = 0.0005
I0403 03:23:56.266360 28785 solver.cpp:228] Iteration 3520, loss = 0.00446134
I0403 03:23:56.272971 28785 solver.cpp:244]     Train net output #0: loss = 0.00446146 (* 1 = 0.00446146 loss)
I0403 03:23:56.415129 28785 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 03:24:08.234813 28785 solver.cpp:228] Iteration 3536, loss = 0.0081149
I0403 03:24:08.240720 28785 solver.cpp:244]     Train net output #0: loss = 0.00811502 (* 1 = 0.00811502 loss)
I0403 03:24:08.385710 28785 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 03:24:19.948791 28785 solver.cpp:228] Iteration 3552, loss = 0.0106802
I0403 03:24:19.954195 28785 solver.cpp:244]     Train net output #0: loss = 0.0106803 (* 1 = 0.0106803 loss)
I0403 03:24:20.152487 28785 sgd_solver.cpp:106] Iteration 3552, lr = 0.0005
I0403 03:24:31.665349 28785 solver.cpp:228] Iteration 3568, loss = 0.00583064
I0403 03:24:31.672683 28785 solver.cpp:244]     Train net output #0: loss = 0.00583076 (* 1 = 0.00583076 loss)
I0403 03:24:31.865614 28785 sgd_solver.cpp:106] Iteration 3568, lr = 0.0005
I0403 03:24:36.231914 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_3575.caffemodel
I0403 03:24:38.982847 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_3575.solverstate
I0403 03:24:40.868880 28785 solver.cpp:337] Iteration 3575, Testing net (#0)
I0403 03:25:30.446576 28785 solver.cpp:404]     Test net output #0: accuracy = 0.964701
I0403 03:25:30.452858 28785 solver.cpp:404]     Test net output #1: loss = 0.122426 (* 1 = 0.122426 loss)
I0403 03:25:37.564934 28785 solver.cpp:228] Iteration 3584, loss = 0.00282487
I0403 03:25:37.570431 28785 solver.cpp:244]     Train net output #0: loss = 0.00282499 (* 1 = 0.00282499 loss)
I0403 03:25:37.733345 28785 sgd_solver.cpp:106] Iteration 3584, lr = 0.0005
I0403 03:25:49.398553 28785 solver.cpp:228] Iteration 3600, loss = 0.0214283
I0403 03:25:49.423337 28785 solver.cpp:244]     Train net output #0: loss = 0.0214284 (* 1 = 0.0214284 loss)
I0403 03:25:49.627635 28785 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 03:26:01.237548 28785 solver.cpp:228] Iteration 3616, loss = 0.0307111
I0403 03:26:01.243325 28785 solver.cpp:244]     Train net output #0: loss = 0.0307112 (* 1 = 0.0307112 loss)
I0403 03:26:01.423292 28785 sgd_solver.cpp:106] Iteration 3616, lr = 0.0005
I0403 03:26:12.992208 28785 solver.cpp:228] Iteration 3632, loss = 0.0108084
I0403 03:26:12.997360 28785 solver.cpp:244]     Train net output #0: loss = 0.0108085 (* 1 = 0.0108085 loss)
I0403 03:26:13.164721 28785 sgd_solver.cpp:106] Iteration 3632, lr = 0.0005
I0403 03:26:24.784049 28785 solver.cpp:228] Iteration 3648, loss = 0.0279658
I0403 03:26:24.791430 28785 solver.cpp:244]     Train net output #0: loss = 0.0279659 (* 1 = 0.0279659 loss)
I0403 03:26:24.963374 28785 sgd_solver.cpp:106] Iteration 3648, lr = 0.0005
I0403 03:26:36.595413 28785 solver.cpp:228] Iteration 3664, loss = 0.00947552
I0403 03:26:36.600227 28785 solver.cpp:244]     Train net output #0: loss = 0.00947566 (* 1 = 0.00947566 loss)
I0403 03:26:36.807797 28785 sgd_solver.cpp:106] Iteration 3664, lr = 0.0005
I0403 03:26:48.338701 28785 solver.cpp:228] Iteration 3680, loss = 0.0191334
I0403 03:26:48.374855 28785 solver.cpp:244]     Train net output #0: loss = 0.0191335 (* 1 = 0.0191335 loss)
I0403 03:26:48.540094 28785 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 03:27:00.211320 28785 solver.cpp:228] Iteration 3696, loss = 0.00284323
I0403 03:27:00.216809 28785 solver.cpp:244]     Train net output #0: loss = 0.00284336 (* 1 = 0.00284336 loss)
I0403 03:27:00.393479 28785 sgd_solver.cpp:106] Iteration 3696, lr = 0.0005
I0403 03:27:12.158982 28785 solver.cpp:228] Iteration 3712, loss = 0.0506308
I0403 03:27:12.165210 28785 solver.cpp:244]     Train net output #0: loss = 0.0506309 (* 1 = 0.0506309 loss)
I0403 03:27:12.345026 28785 sgd_solver.cpp:106] Iteration 3712, lr = 0.0005
I0403 03:27:23.765415 28785 solver.cpp:228] Iteration 3728, loss = 0.00829087
I0403 03:27:23.771883 28785 solver.cpp:244]     Train net output #0: loss = 0.00829101 (* 1 = 0.00829101 loss)
I0403 03:27:23.942499 28785 sgd_solver.cpp:106] Iteration 3728, lr = 0.0005
I0403 03:27:35.723564 28785 solver.cpp:228] Iteration 3744, loss = 0.00338459
I0403 03:27:35.730500 28785 solver.cpp:244]     Train net output #0: loss = 0.00338472 (* 1 = 0.00338472 loss)
I0403 03:27:35.906441 28785 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 03:27:47.418530 28785 solver.cpp:228] Iteration 3760, loss = 0.0171373
I0403 03:27:47.426836 28785 solver.cpp:244]     Train net output #0: loss = 0.0171374 (* 1 = 0.0171374 loss)
I0403 03:27:47.613483 28785 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 03:27:59.367249 28785 solver.cpp:228] Iteration 3776, loss = 0.0100759
I0403 03:27:59.374075 28785 solver.cpp:244]     Train net output #0: loss = 0.010076 (* 1 = 0.010076 loss)
I0403 03:27:59.588557 28785 sgd_solver.cpp:106] Iteration 3776, lr = 0.0005
I0403 03:28:11.052328 28785 solver.cpp:228] Iteration 3792, loss = 0.00423105
I0403 03:28:11.057252 28785 solver.cpp:244]     Train net output #0: loss = 0.00423118 (* 1 = 0.00423118 loss)
I0403 03:28:11.230386 28785 sgd_solver.cpp:106] Iteration 3792, lr = 0.0005
I0403 03:28:22.840715 28785 solver.cpp:228] Iteration 3808, loss = 0.0157576
I0403 03:28:22.846313 28785 solver.cpp:244]     Train net output #0: loss = 0.0157577 (* 1 = 0.0157577 loss)
I0403 03:28:22.927135 28785 sgd_solver.cpp:106] Iteration 3808, lr = 0.0005
I0403 03:28:34.974050 28785 solver.cpp:228] Iteration 3824, loss = 0.0111454
I0403 03:28:34.979730 28785 solver.cpp:244]     Train net output #0: loss = 0.0111455 (* 1 = 0.0111455 loss)
I0403 03:28:35.174633 28785 sgd_solver.cpp:106] Iteration 3824, lr = 0.0005
I0403 03:28:46.758688 28785 solver.cpp:228] Iteration 3840, loss = 0.00139773
I0403 03:28:46.764042 28785 solver.cpp:244]     Train net output #0: loss = 0.00139785 (* 1 = 0.00139785 loss)
I0403 03:28:46.922677 28785 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 03:28:58.599864 28785 solver.cpp:228] Iteration 3856, loss = 0.0375546
I0403 03:28:58.606526 28785 solver.cpp:244]     Train net output #0: loss = 0.0375548 (* 1 = 0.0375548 loss)
I0403 03:28:58.776257 28785 sgd_solver.cpp:106] Iteration 3856, lr = 0.0005
I0403 03:29:10.448374 28785 solver.cpp:228] Iteration 3872, loss = 0.00623945
I0403 03:29:10.455993 28785 solver.cpp:244]     Train net output #0: loss = 0.00623957 (* 1 = 0.00623957 loss)
I0403 03:29:10.683509 28785 sgd_solver.cpp:106] Iteration 3872, lr = 0.0005
I0403 03:29:22.285297 28785 solver.cpp:228] Iteration 3888, loss = 0.025322
I0403 03:29:22.290853 28785 solver.cpp:244]     Train net output #0: loss = 0.0253222 (* 1 = 0.0253222 loss)
I0403 03:29:22.435626 28785 sgd_solver.cpp:106] Iteration 3888, lr = 0.0005
I0403 03:29:30.626240 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_3900.caffemodel
I0403 03:29:33.366864 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_3900.solverstate
I0403 03:29:35.280074 28785 solver.cpp:337] Iteration 3900, Testing net (#0)
I0403 03:30:24.848803 28785 solver.cpp:404]     Test net output #0: accuracy = 0.966314
I0403 03:30:24.854724 28785 solver.cpp:404]     Test net output #1: loss = 0.118376 (* 1 = 0.118376 loss)
I0403 03:30:28.405858 28785 solver.cpp:228] Iteration 3904, loss = 0.0340676
I0403 03:30:28.414371 28785 solver.cpp:244]     Train net output #0: loss = 0.0340678 (* 1 = 0.0340678 loss)
I0403 03:30:28.594102 28785 sgd_solver.cpp:106] Iteration 3904, lr = 0.0005
I0403 03:30:40.177306 28785 solver.cpp:228] Iteration 3920, loss = 0.0461691
I0403 03:30:40.183910 28785 solver.cpp:244]     Train net output #0: loss = 0.0461692 (* 1 = 0.0461692 loss)
I0403 03:30:40.363219 28785 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 03:30:52.042461 28785 solver.cpp:228] Iteration 3936, loss = 0.00411348
I0403 03:30:52.049404 28785 solver.cpp:244]     Train net output #0: loss = 0.00411361 (* 1 = 0.00411361 loss)
I0403 03:30:52.212236 28785 sgd_solver.cpp:106] Iteration 3936, lr = 0.0005
I0403 03:31:03.738122 28785 solver.cpp:228] Iteration 3952, loss = 0.0204089
I0403 03:31:03.744132 28785 solver.cpp:244]     Train net output #0: loss = 0.0204091 (* 1 = 0.0204091 loss)
I0403 03:31:04.008705 28785 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 03:31:15.451587 28785 solver.cpp:228] Iteration 3968, loss = 0.0103235
I0403 03:31:15.458484 28785 solver.cpp:244]     Train net output #0: loss = 0.0103236 (* 1 = 0.0103236 loss)
I0403 03:31:15.647900 28785 sgd_solver.cpp:106] Iteration 3968, lr = 0.0005
I0403 03:31:27.170707 28785 solver.cpp:228] Iteration 3984, loss = 0.0167056
I0403 03:31:27.175699 28785 solver.cpp:244]     Train net output #0: loss = 0.0167057 (* 1 = 0.0167057 loss)
I0403 03:31:27.371567 28785 sgd_solver.cpp:106] Iteration 3984, lr = 0.0005
I0403 03:31:38.908520 28785 solver.cpp:228] Iteration 4000, loss = 0.00721006
I0403 03:31:38.914573 28785 solver.cpp:244]     Train net output #0: loss = 0.00721018 (* 1 = 0.00721018 loss)
I0403 03:31:39.101961 28785 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 03:31:50.731979 28785 solver.cpp:228] Iteration 4016, loss = 0.00641363
I0403 03:31:50.738564 28785 solver.cpp:244]     Train net output #0: loss = 0.00641376 (* 1 = 0.00641376 loss)
I0403 03:31:50.906826 28785 sgd_solver.cpp:106] Iteration 4016, lr = 0.0005
I0403 03:32:02.569216 28785 solver.cpp:228] Iteration 4032, loss = 0.00416036
I0403 03:32:02.575218 28785 solver.cpp:244]     Train net output #0: loss = 0.00416049 (* 1 = 0.00416049 loss)
I0403 03:32:02.742683 28785 sgd_solver.cpp:106] Iteration 4032, lr = 0.0005
I0403 03:32:14.280128 28785 solver.cpp:228] Iteration 4048, loss = 0.0135179
I0403 03:32:14.285063 28785 solver.cpp:244]     Train net output #0: loss = 0.013518 (* 1 = 0.013518 loss)
I0403 03:32:14.450924 28785 sgd_solver.cpp:106] Iteration 4048, lr = 0.0005
I0403 03:32:26.180718 28785 solver.cpp:228] Iteration 4064, loss = 0.0127136
I0403 03:32:26.186318 28785 solver.cpp:244]     Train net output #0: loss = 0.0127137 (* 1 = 0.0127137 loss)
I0403 03:32:26.353273 28785 sgd_solver.cpp:106] Iteration 4064, lr = 0.0005
I0403 03:32:38.139284 28785 solver.cpp:228] Iteration 4080, loss = 0.00375102
I0403 03:32:38.146704 28785 solver.cpp:244]     Train net output #0: loss = 0.00375115 (* 1 = 0.00375115 loss)
I0403 03:32:38.266644 28785 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 03:32:49.984897 28785 solver.cpp:228] Iteration 4096, loss = 0.00295852
I0403 03:32:50.078433 28785 solver.cpp:244]     Train net output #0: loss = 0.00295864 (* 1 = 0.00295864 loss)
I0403 03:32:50.160616 28785 sgd_solver.cpp:106] Iteration 4096, lr = 0.0005
I0403 03:33:01.690490 28785 solver.cpp:228] Iteration 4112, loss = 0.00263504
I0403 03:33:01.696321 28785 solver.cpp:244]     Train net output #0: loss = 0.00263517 (* 1 = 0.00263517 loss)
I0403 03:33:01.917891 28785 sgd_solver.cpp:106] Iteration 4112, lr = 0.0005
I0403 03:33:13.467274 28785 solver.cpp:228] Iteration 4128, loss = 0.00836933
I0403 03:33:13.474455 28785 solver.cpp:244]     Train net output #0: loss = 0.00836946 (* 1 = 0.00836946 loss)
I0403 03:33:13.652447 28785 sgd_solver.cpp:106] Iteration 4128, lr = 0.0005
I0403 03:33:25.218081 28785 solver.cpp:228] Iteration 4144, loss = 0.0111595
I0403 03:33:25.230770 28785 solver.cpp:244]     Train net output #0: loss = 0.0111597 (* 1 = 0.0111597 loss)
I0403 03:33:25.458331 28785 sgd_solver.cpp:106] Iteration 4144, lr = 0.0005
I0403 03:33:36.893313 28785 solver.cpp:228] Iteration 4160, loss = 0.00427322
I0403 03:33:36.899132 28785 solver.cpp:244]     Train net output #0: loss = 0.00427335 (* 1 = 0.00427335 loss)
I0403 03:33:37.065614 28785 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:33:48.626626 28785 solver.cpp:228] Iteration 4176, loss = 0.00688029
I0403 03:33:48.633484 28785 solver.cpp:244]     Train net output #0: loss = 0.00688041 (* 1 = 0.00688041 loss)
I0403 03:33:48.814036 28785 sgd_solver.cpp:106] Iteration 4176, lr = 0.0005
I0403 03:34:00.441288 28785 solver.cpp:228] Iteration 4192, loss = 0.00212626
I0403 03:34:00.447882 28785 solver.cpp:244]     Train net output #0: loss = 0.00212639 (* 1 = 0.00212639 loss)
I0403 03:34:00.640578 28785 sgd_solver.cpp:106] Iteration 4192, lr = 0.0005
I0403 03:34:12.071529 28785 solver.cpp:228] Iteration 4208, loss = 0.00203847
I0403 03:34:12.071653 28785 solver.cpp:244]     Train net output #0: loss = 0.0020386 (* 1 = 0.0020386 loss)
I0403 03:34:12.284330 28785 sgd_solver.cpp:106] Iteration 4208, lr = 0.0005
I0403 03:34:23.981062 28785 solver.cpp:228] Iteration 4224, loss = 0.00193675
I0403 03:34:23.981164 28785 solver.cpp:244]     Train net output #0: loss = 0.00193687 (* 1 = 0.00193687 loss)
I0403 03:34:24.116644 28785 sgd_solver.cpp:106] Iteration 4224, lr = 0.0005
I0403 03:34:24.116889 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_4225.caffemodel
I0403 03:34:26.945896 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_4225.solverstate
I0403 03:34:28.848908 28785 solver.cpp:337] Iteration 4225, Testing net (#0)
I0403 03:35:18.396381 28785 solver.cpp:404]     Test net output #0: accuracy = 0.966452
I0403 03:35:18.396669 28785 solver.cpp:404]     Test net output #1: loss = 0.119147 (* 1 = 0.119147 loss)
I0403 03:35:29.912096 28785 solver.cpp:228] Iteration 4240, loss = 0.00108321
I0403 03:35:29.912209 28785 solver.cpp:244]     Train net output #0: loss = 0.00108333 (* 1 = 0.00108333 loss)
I0403 03:35:30.097446 28785 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 03:35:41.692932 28785 solver.cpp:228] Iteration 4256, loss = 0.00767027
I0403 03:35:41.693042 28785 solver.cpp:244]     Train net output #0: loss = 0.0076704 (* 1 = 0.0076704 loss)
I0403 03:35:41.892848 28785 sgd_solver.cpp:106] Iteration 4256, lr = 0.0005
I0403 03:35:53.335677 28785 solver.cpp:228] Iteration 4272, loss = 0.00425185
I0403 03:35:53.335981 28785 solver.cpp:244]     Train net output #0: loss = 0.00425197 (* 1 = 0.00425197 loss)
I0403 03:35:53.534078 28785 sgd_solver.cpp:106] Iteration 4272, lr = 0.0005
I0403 03:36:05.277175 28785 solver.cpp:228] Iteration 4288, loss = 0.0267172
I0403 03:36:05.277297 28785 solver.cpp:244]     Train net output #0: loss = 0.0267174 (* 1 = 0.0267174 loss)
I0403 03:36:05.507310 28785 sgd_solver.cpp:106] Iteration 4288, lr = 0.0005
I0403 03:36:17.097051 28785 solver.cpp:228] Iteration 4304, loss = 0.00163256
I0403 03:36:17.097167 28785 solver.cpp:244]     Train net output #0: loss = 0.00163268 (* 1 = 0.00163268 loss)
I0403 03:36:17.357625 28785 sgd_solver.cpp:106] Iteration 4304, lr = 0.0005
I0403 03:36:28.891244 28785 solver.cpp:228] Iteration 4320, loss = 0.0075472
I0403 03:36:28.891594 28785 solver.cpp:244]     Train net output #0: loss = 0.00754732 (* 1 = 0.00754732 loss)
I0403 03:36:29.082733 28785 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 03:36:40.686514 28785 solver.cpp:228] Iteration 4336, loss = 0.00380241
I0403 03:36:40.686648 28785 solver.cpp:244]     Train net output #0: loss = 0.00380253 (* 1 = 0.00380253 loss)
I0403 03:36:40.874663 28785 sgd_solver.cpp:106] Iteration 4336, lr = 0.0005
I0403 03:36:52.368458 28785 solver.cpp:228] Iteration 4352, loss = 0.00195606
I0403 03:36:52.368576 28785 solver.cpp:244]     Train net output #0: loss = 0.00195617 (* 1 = 0.00195617 loss)
I0403 03:36:52.574096 28785 sgd_solver.cpp:106] Iteration 4352, lr = 0.0005
I0403 03:37:04.085957 28785 solver.cpp:228] Iteration 4368, loss = 0.0127433
I0403 03:37:04.086206 28785 solver.cpp:244]     Train net output #0: loss = 0.0127434 (* 1 = 0.0127434 loss)
I0403 03:37:04.262481 28785 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:37:15.793921 28785 solver.cpp:228] Iteration 4384, loss = 0.0128101
I0403 03:37:15.794037 28785 solver.cpp:244]     Train net output #0: loss = 0.0128102 (* 1 = 0.0128102 loss)
I0403 03:37:16.008757 28785 sgd_solver.cpp:106] Iteration 4384, lr = 0.0005
I0403 03:37:27.491765 28785 solver.cpp:228] Iteration 4400, loss = 0.0625794
I0403 03:37:27.491875 28785 solver.cpp:244]     Train net output #0: loss = 0.0625796 (* 1 = 0.0625796 loss)
I0403 03:37:27.685446 28785 sgd_solver.cpp:106] Iteration 4400, lr = 0.0005
I0403 03:37:39.574967 28785 solver.cpp:228] Iteration 4416, loss = 0.0358056
I0403 03:37:39.575271 28785 solver.cpp:244]     Train net output #0: loss = 0.0358057 (* 1 = 0.0358057 loss)
I0403 03:37:39.738606 28785 sgd_solver.cpp:106] Iteration 4416, lr = 0.0005
I0403 03:37:51.408526 28785 solver.cpp:228] Iteration 4432, loss = 0.0212336
I0403 03:37:51.408643 28785 solver.cpp:244]     Train net output #0: loss = 0.0212337 (* 1 = 0.0212337 loss)
I0403 03:37:51.595687 28785 sgd_solver.cpp:106] Iteration 4432, lr = 0.0005
I0403 03:38:03.133466 28785 solver.cpp:228] Iteration 4448, loss = 0.0155392
I0403 03:38:03.133561 28785 solver.cpp:244]     Train net output #0: loss = 0.0155393 (* 1 = 0.0155393 loss)
I0403 03:38:03.305559 28785 sgd_solver.cpp:106] Iteration 4448, lr = 0.0005
I0403 03:38:14.865629 28785 solver.cpp:228] Iteration 4464, loss = 0.00402938
I0403 03:38:14.865934 28785 solver.cpp:244]     Train net output #0: loss = 0.00402949 (* 1 = 0.00402949 loss)
I0403 03:38:15.064796 28785 sgd_solver.cpp:106] Iteration 4464, lr = 0.0005
I0403 03:38:26.522905 28785 solver.cpp:228] Iteration 4480, loss = 0.00418234
I0403 03:38:26.523005 28785 solver.cpp:244]     Train net output #0: loss = 0.00418246 (* 1 = 0.00418246 loss)
I0403 03:38:26.700112 28785 sgd_solver.cpp:106] Iteration 4480, lr = 0.0005
I0403 03:38:38.147511 28785 solver.cpp:228] Iteration 4496, loss = 0.00105798
I0403 03:38:38.147615 28785 solver.cpp:244]     Train net output #0: loss = 0.0010581 (* 1 = 0.0010581 loss)
I0403 03:38:38.322592 28785 sgd_solver.cpp:106] Iteration 4496, lr = 0.0005
I0403 03:38:49.943274 28785 solver.cpp:228] Iteration 4512, loss = 0.0119361
I0403 03:38:49.943595 28785 solver.cpp:244]     Train net output #0: loss = 0.0119362 (* 1 = 0.0119362 loss)
I0403 03:38:50.140880 28785 sgd_solver.cpp:106] Iteration 4512, lr = 0.0005
I0403 03:39:01.545222 28785 solver.cpp:228] Iteration 4528, loss = 0.0152135
I0403 03:39:01.545341 28785 solver.cpp:244]     Train net output #0: loss = 0.0152136 (* 1 = 0.0152136 loss)
I0403 03:39:01.735220 28785 sgd_solver.cpp:106] Iteration 4528, lr = 0.0005
I0403 03:39:13.475540 28785 solver.cpp:228] Iteration 4544, loss = 0.00388886
I0403 03:39:13.475654 28785 solver.cpp:244]     Train net output #0: loss = 0.00388898 (* 1 = 0.00388898 loss)
I0403 03:39:13.636853 28785 sgd_solver.cpp:106] Iteration 4544, lr = 0.0005
I0403 03:39:17.314882 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_4550.caffemodel
I0403 03:39:20.014381 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_4550.solverstate
I0403 03:39:21.852789 28785 solver.cpp:337] Iteration 4550, Testing net (#0)
I0403 03:40:11.414000 28785 solver.cpp:404]     Test net output #0: accuracy = 0.96742
I0403 03:40:11.414326 28785 solver.cpp:404]     Test net output #1: loss = 0.117298 (* 1 = 0.117298 loss)
I0403 03:40:19.277745 28785 solver.cpp:228] Iteration 4560, loss = 0.00103833
I0403 03:40:19.277847 28785 solver.cpp:244]     Train net output #0: loss = 0.00103845 (* 1 = 0.00103845 loss)
I0403 03:40:19.455205 28785 sgd_solver.cpp:106] Iteration 4560, lr = 0.0005
I0403 03:40:30.828158 28785 solver.cpp:228] Iteration 4576, loss = 0.0360121
I0403 03:40:30.828258 28785 solver.cpp:244]     Train net output #0: loss = 0.0360122 (* 1 = 0.0360122 loss)
I0403 03:40:31.006110 28785 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 03:40:42.402443 28785 solver.cpp:228] Iteration 4592, loss = 0.00300269
I0403 03:40:42.402755 28785 solver.cpp:244]     Train net output #0: loss = 0.00300281 (* 1 = 0.00300281 loss)
I0403 03:40:42.591809 28785 sgd_solver.cpp:106] Iteration 4592, lr = 0.0005
I0403 03:40:54.093647 28785 solver.cpp:228] Iteration 4608, loss = 0.0103038
I0403 03:40:54.093749 28785 solver.cpp:244]     Train net output #0: loss = 0.010304 (* 1 = 0.010304 loss)
I0403 03:40:54.264125 28785 sgd_solver.cpp:106] Iteration 4608, lr = 0.0005
I0403 03:41:05.790840 28785 solver.cpp:228] Iteration 4624, loss = 0.00216227
I0403 03:41:05.790940 28785 solver.cpp:244]     Train net output #0: loss = 0.00216239 (* 1 = 0.00216239 loss)
I0403 03:41:05.967861 28785 sgd_solver.cpp:106] Iteration 4624, lr = 0.0005
I0403 03:41:17.507707 28785 solver.cpp:228] Iteration 4640, loss = 0.013895
I0403 03:41:17.508013 28785 solver.cpp:244]     Train net output #0: loss = 0.0138951 (* 1 = 0.0138951 loss)
I0403 03:41:17.689111 28785 sgd_solver.cpp:106] Iteration 4640, lr = 0.0005
I0403 03:41:29.199214 28785 solver.cpp:228] Iteration 4656, loss = 0.00404239
I0403 03:41:29.199332 28785 solver.cpp:244]     Train net output #0: loss = 0.00404251 (* 1 = 0.00404251 loss)
I0403 03:41:29.387331 28785 sgd_solver.cpp:106] Iteration 4656, lr = 0.0005
I0403 03:41:40.967314 28785 solver.cpp:228] Iteration 4672, loss = 0.0024248
I0403 03:41:40.967428 28785 solver.cpp:244]     Train net output #0: loss = 0.00242491 (* 1 = 0.00242491 loss)
I0403 03:41:41.152541 28785 sgd_solver.cpp:106] Iteration 4672, lr = 0.0005
I0403 03:41:52.708185 28785 solver.cpp:228] Iteration 4688, loss = 0.01189
I0403 03:41:52.708479 28785 solver.cpp:244]     Train net output #0: loss = 0.0118901 (* 1 = 0.0118901 loss)
I0403 03:41:52.904377 28785 sgd_solver.cpp:106] Iteration 4688, lr = 0.0005
I0403 03:42:04.480296 28785 solver.cpp:228] Iteration 4704, loss = 0.00941858
I0403 03:42:04.480412 28785 solver.cpp:244]     Train net output #0: loss = 0.00941869 (* 1 = 0.00941869 loss)
I0403 03:42:04.692499 28785 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 03:42:16.375049 28785 solver.cpp:228] Iteration 4720, loss = 0.00246262
I0403 03:42:16.375151 28785 solver.cpp:244]     Train net output #0: loss = 0.00246273 (* 1 = 0.00246273 loss)
I0403 03:42:16.557977 28785 sgd_solver.cpp:106] Iteration 4720, lr = 0.0005
I0403 03:42:28.147157 28785 solver.cpp:228] Iteration 4736, loss = 0.0717894
I0403 03:42:28.147483 28785 solver.cpp:244]     Train net output #0: loss = 0.0717895 (* 1 = 0.0717895 loss)
I0403 03:42:28.337432 28785 sgd_solver.cpp:106] Iteration 4736, lr = 0.0005
I0403 03:42:39.975026 28785 solver.cpp:228] Iteration 4752, loss = 0.00333805
I0403 03:42:39.975142 28785 solver.cpp:244]     Train net output #0: loss = 0.00333817 (* 1 = 0.00333817 loss)
I0403 03:42:40.184702 28785 sgd_solver.cpp:106] Iteration 4752, lr = 0.0005
I0403 03:42:51.613289 28785 solver.cpp:228] Iteration 4768, loss = 0.0162121
I0403 03:42:51.613373 28785 solver.cpp:244]     Train net output #0: loss = 0.0162122 (* 1 = 0.0162122 loss)
I0403 03:42:51.791173 28785 sgd_solver.cpp:106] Iteration 4768, lr = 0.0005
I0403 03:43:03.417229 28785 solver.cpp:228] Iteration 4784, loss = 0.0100151
I0403 03:43:03.417577 28785 solver.cpp:244]     Train net output #0: loss = 0.0100152 (* 1 = 0.0100152 loss)
I0403 03:43:03.590164 28785 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 03:43:15.198073 28785 solver.cpp:228] Iteration 4800, loss = 0.00270791
I0403 03:43:15.198174 28785 solver.cpp:244]     Train net output #0: loss = 0.00270802 (* 1 = 0.00270802 loss)
I0403 03:43:15.356032 28785 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0403 03:43:26.947121 28785 solver.cpp:228] Iteration 4816, loss = 0.0386252
I0403 03:43:26.947206 28785 solver.cpp:244]     Train net output #0: loss = 0.0386253 (* 1 = 0.0386253 loss)
I0403 03:43:27.119444 28785 sgd_solver.cpp:106] Iteration 4816, lr = 0.0005
I0403 03:43:38.564373 28785 solver.cpp:228] Iteration 4832, loss = 0.00780044
I0403 03:43:38.566306 28785 solver.cpp:244]     Train net output #0: loss = 0.00780056 (* 1 = 0.00780056 loss)
I0403 03:43:38.751915 28785 sgd_solver.cpp:106] Iteration 4832, lr = 0.0005
I0403 03:43:50.135932 28785 solver.cpp:228] Iteration 4848, loss = 0.00481157
I0403 03:43:50.136045 28785 solver.cpp:244]     Train net output #0: loss = 0.00481169 (* 1 = 0.00481169 loss)
I0403 03:43:50.323415 28785 sgd_solver.cpp:106] Iteration 4848, lr = 0.0005
I0403 03:44:01.915482 28785 solver.cpp:228] Iteration 4864, loss = 0.000600741
I0403 03:44:01.915585 28785 solver.cpp:244]     Train net output #0: loss = 0.000600857 (* 1 = 0.000600857 loss)
I0403 03:44:02.080525 28785 sgd_solver.cpp:106] Iteration 4864, lr = 0.0005
I0403 03:44:09.452461 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_4875.caffemodel
I0403 03:44:12.161319 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_4875.solverstate
I0403 03:44:14.032084 28785 solver.cpp:337] Iteration 4875, Testing net (#0)
I0403 03:45:03.591217 28785 solver.cpp:404]     Test net output #0: accuracy = 0.96742
I0403 03:45:03.591548 28785 solver.cpp:404]     Test net output #1: loss = 0.116733 (* 1 = 0.116733 loss)
I0403 03:45:07.873916 28785 solver.cpp:228] Iteration 4880, loss = 0.00413531
I0403 03:45:07.874017 28785 solver.cpp:244]     Train net output #0: loss = 0.00413542 (* 1 = 0.00413542 loss)
I0403 03:45:08.050812 28785 sgd_solver.cpp:106] Iteration 4880, lr = 0.0005
I0403 03:45:19.683900 28785 solver.cpp:228] Iteration 4896, loss = 0.00319962
I0403 03:45:19.684011 28785 solver.cpp:244]     Train net output #0: loss = 0.00319973 (* 1 = 0.00319973 loss)
I0403 03:45:19.867177 28785 sgd_solver.cpp:106] Iteration 4896, lr = 0.0005
I0403 03:45:31.567617 28785 solver.cpp:228] Iteration 4912, loss = 0.00350272
I0403 03:45:31.567733 28785 solver.cpp:244]     Train net output #0: loss = 0.00350284 (* 1 = 0.00350284 loss)
I0403 03:45:31.781406 28785 sgd_solver.cpp:106] Iteration 4912, lr = 0.0005
I0403 03:45:43.302789 28785 solver.cpp:228] Iteration 4928, loss = 0.00675317
I0403 03:45:43.303092 28785 solver.cpp:244]     Train net output #0: loss = 0.00675329 (* 1 = 0.00675329 loss)
I0403 03:45:43.481560 28785 sgd_solver.cpp:106] Iteration 4928, lr = 0.0005
I0403 03:45:55.215160 28785 solver.cpp:228] Iteration 4944, loss = 0.0149692
I0403 03:45:55.215276 28785 solver.cpp:244]     Train net output #0: loss = 0.0149693 (* 1 = 0.0149693 loss)
I0403 03:45:55.411044 28785 sgd_solver.cpp:106] Iteration 4944, lr = 0.0005
I0403 03:46:06.861755 28785 solver.cpp:228] Iteration 4960, loss = 0.0145132
I0403 03:46:06.861862 28785 solver.cpp:244]     Train net output #0: loss = 0.0145133 (* 1 = 0.0145133 loss)
I0403 03:46:07.026042 28785 sgd_solver.cpp:106] Iteration 4960, lr = 0.0005
I0403 03:46:18.957679 28785 solver.cpp:228] Iteration 4976, loss = 0.00141455
I0403 03:46:18.958045 28785 solver.cpp:244]     Train net output #0: loss = 0.00141468 (* 1 = 0.00141468 loss)
I0403 03:46:19.157951 28785 sgd_solver.cpp:106] Iteration 4976, lr = 0.0005
I0403 03:46:30.812407 28785 solver.cpp:228] Iteration 4992, loss = 0.00414343
I0403 03:46:30.812516 28785 solver.cpp:244]     Train net output #0: loss = 0.00414355 (* 1 = 0.00414355 loss)
I0403 03:46:30.995549 28785 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 03:46:42.542631 28785 solver.cpp:228] Iteration 5008, loss = 0.0339099
I0403 03:46:42.542743 28785 solver.cpp:244]     Train net output #0: loss = 0.03391 (* 1 = 0.03391 loss)
I0403 03:46:42.777140 28785 sgd_solver.cpp:106] Iteration 5008, lr = 0.0005
I0403 03:46:54.538453 28785 solver.cpp:228] Iteration 5024, loss = 0.00399462
I0403 03:46:54.538789 28785 solver.cpp:244]     Train net output #0: loss = 0.00399474 (* 1 = 0.00399474 loss)
I0403 03:46:54.752074 28785 sgd_solver.cpp:106] Iteration 5024, lr = 0.0005
I0403 03:47:06.313753 28785 solver.cpp:228] Iteration 5040, loss = 0.00183064
I0403 03:47:06.313868 28785 solver.cpp:244]     Train net output #0: loss = 0.00183076 (* 1 = 0.00183076 loss)
I0403 03:47:06.515630 28785 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 03:47:18.082031 28785 solver.cpp:228] Iteration 5056, loss = 0.00647858
I0403 03:47:18.082131 28785 solver.cpp:244]     Train net output #0: loss = 0.00647869 (* 1 = 0.00647869 loss)
I0403 03:47:18.263334 28785 sgd_solver.cpp:106] Iteration 5056, lr = 0.0005
I0403 03:47:29.840498 28785 solver.cpp:228] Iteration 5072, loss = 0.0061578
I0403 03:47:29.840817 28785 solver.cpp:244]     Train net output #0: loss = 0.00615791 (* 1 = 0.00615791 loss)
I0403 03:47:30.060160 28785 sgd_solver.cpp:106] Iteration 5072, lr = 0.0005
I0403 03:47:41.542495 28785 solver.cpp:228] Iteration 5088, loss = 0.00258373
I0403 03:47:41.542604 28785 solver.cpp:244]     Train net output #0: loss = 0.00258385 (* 1 = 0.00258385 loss)
I0403 03:47:41.737704 28785 sgd_solver.cpp:106] Iteration 5088, lr = 0.0005
I0403 03:47:53.312839 28785 solver.cpp:228] Iteration 5104, loss = 0.0335847
I0403 03:47:53.312957 28785 solver.cpp:244]     Train net output #0: loss = 0.0335848 (* 1 = 0.0335848 loss)
I0403 03:47:53.520925 28785 sgd_solver.cpp:106] Iteration 5104, lr = 0.0005
I0403 03:48:04.957135 28785 solver.cpp:228] Iteration 5120, loss = 0.010549
I0403 03:48:04.957428 28785 solver.cpp:244]     Train net output #0: loss = 0.0105491 (* 1 = 0.0105491 loss)
I0403 03:48:05.140655 28785 sgd_solver.cpp:106] Iteration 5120, lr = 0.0005
I0403 03:48:16.542837 28785 solver.cpp:228] Iteration 5136, loss = 0.00960582
I0403 03:48:16.542943 28785 solver.cpp:244]     Train net output #0: loss = 0.00960594 (* 1 = 0.00960594 loss)
I0403 03:48:16.720454 28785 sgd_solver.cpp:106] Iteration 5136, lr = 0.0005
I0403 03:48:28.216231 28785 solver.cpp:228] Iteration 5152, loss = 0.00330453
I0403 03:48:28.216338 28785 solver.cpp:244]     Train net output #0: loss = 0.00330464 (* 1 = 0.00330464 loss)
I0403 03:48:28.385936 28785 sgd_solver.cpp:106] Iteration 5152, lr = 0.0005
I0403 03:48:40.052656 28785 solver.cpp:228] Iteration 5168, loss = 0.00633174
I0403 03:48:40.052938 28785 solver.cpp:244]     Train net output #0: loss = 0.00633185 (* 1 = 0.00633185 loss)
I0403 03:48:40.214455 28785 sgd_solver.cpp:106] Iteration 5168, lr = 0.0005
I0403 03:48:51.849680 28785 solver.cpp:228] Iteration 5184, loss = 0.0417418
I0403 03:48:51.849781 28785 solver.cpp:244]     Train net output #0: loss = 0.0417419 (* 1 = 0.0417419 loss)
I0403 03:48:51.947054 28785 sgd_solver.cpp:106] Iteration 5184, lr = 0.0005
I0403 03:49:03.036490 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_5200.caffemodel
I0403 03:49:05.839871 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_5200.solverstate
I0403 03:49:07.740592 28785 solver.cpp:337] Iteration 5200, Testing net (#0)
I0403 03:49:57.321517 28785 solver.cpp:404]     Test net output #0: accuracy = 0.96825
I0403 03:49:57.322867 28785 solver.cpp:404]     Test net output #1: loss = 0.116291 (* 1 = 0.116291 loss)
I0403 03:49:57.859722 28785 solver.cpp:228] Iteration 5200, loss = 0.000822411
I0403 03:49:57.859817 28785 solver.cpp:244]     Train net output #0: loss = 0.000822526 (* 1 = 0.000822526 loss)
I0403 03:49:58.007426 28785 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 03:50:09.719955 28785 solver.cpp:228] Iteration 5216, loss = 0.00123431
I0403 03:50:09.720059 28785 solver.cpp:244]     Train net output #0: loss = 0.00123443 (* 1 = 0.00123443 loss)
I0403 03:50:09.869457 28785 sgd_solver.cpp:106] Iteration 5216, lr = 0.0005
I0403 03:50:21.524123 28785 solver.cpp:228] Iteration 5232, loss = 0.0041348
I0403 03:50:21.524236 28785 solver.cpp:244]     Train net output #0: loss = 0.00413491 (* 1 = 0.00413491 loss)
I0403 03:50:21.726912 28785 sgd_solver.cpp:106] Iteration 5232, lr = 0.0005
I0403 03:50:33.266990 28785 solver.cpp:228] Iteration 5248, loss = 0.0111481
I0403 03:50:33.267316 28785 solver.cpp:244]     Train net output #0: loss = 0.0111482 (* 1 = 0.0111482 loss)
I0403 03:50:33.482369 28785 sgd_solver.cpp:106] Iteration 5248, lr = 0.0005
I0403 03:50:45.002811 28785 solver.cpp:228] Iteration 5264, loss = 0.00653884
I0403 03:50:45.002928 28785 solver.cpp:244]     Train net output #0: loss = 0.00653895 (* 1 = 0.00653895 loss)
I0403 03:50:45.233337 28785 sgd_solver.cpp:106] Iteration 5264, lr = 0.0005
I0403 03:50:56.796078 28785 solver.cpp:228] Iteration 5280, loss = 0.0073647
I0403 03:50:56.796175 28785 solver.cpp:244]     Train net output #0: loss = 0.00736481 (* 1 = 0.00736481 loss)
I0403 03:50:56.976323 28785 sgd_solver.cpp:106] Iteration 5280, lr = 0.0005
I0403 03:51:08.394419 28785 solver.cpp:228] Iteration 5296, loss = 0.0115316
I0403 03:51:08.394958 28785 solver.cpp:244]     Train net output #0: loss = 0.0115317 (* 1 = 0.0115317 loss)
I0403 03:51:08.627326 28785 sgd_solver.cpp:106] Iteration 5296, lr = 0.0005
I0403 03:51:20.536365 28785 solver.cpp:228] Iteration 5312, loss = 0.00261838
I0403 03:51:20.536481 28785 solver.cpp:244]     Train net output #0: loss = 0.00261849 (* 1 = 0.00261849 loss)
I0403 03:51:20.752820 28785 sgd_solver.cpp:106] Iteration 5312, lr = 0.0005
I0403 03:51:32.195632 28785 solver.cpp:228] Iteration 5328, loss = 0.0018965
I0403 03:51:32.195724 28785 solver.cpp:244]     Train net output #0: loss = 0.00189662 (* 1 = 0.00189662 loss)
I0403 03:51:32.431782 28785 sgd_solver.cpp:106] Iteration 5328, lr = 0.0005
I0403 03:51:44.299746 28785 solver.cpp:228] Iteration 5344, loss = 0.0020995
I0403 03:51:44.300057 28785 solver.cpp:244]     Train net output #0: loss = 0.00209961 (* 1 = 0.00209961 loss)
I0403 03:51:44.450372 28785 sgd_solver.cpp:106] Iteration 5344, lr = 0.0005
I0403 03:51:56.268862 28785 solver.cpp:228] Iteration 5360, loss = 0.0134814
I0403 03:51:56.268962 28785 solver.cpp:244]     Train net output #0: loss = 0.0134815 (* 1 = 0.0134815 loss)
I0403 03:51:56.437593 28785 sgd_solver.cpp:106] Iteration 5360, lr = 0.0005
I0403 03:52:08.029551 28785 solver.cpp:228] Iteration 5376, loss = 0.0019866
I0403 03:52:08.029654 28785 solver.cpp:244]     Train net output #0: loss = 0.00198671 (* 1 = 0.00198671 loss)
I0403 03:52:08.179695 28785 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 03:52:19.990049 28785 solver.cpp:228] Iteration 5392, loss = 0.0302678
I0403 03:52:19.990365 28785 solver.cpp:244]     Train net output #0: loss = 0.0302679 (* 1 = 0.0302679 loss)
I0403 03:52:20.173780 28785 sgd_solver.cpp:106] Iteration 5392, lr = 0.0005
I0403 03:52:31.676807 28785 solver.cpp:228] Iteration 5408, loss = 0.00406557
I0403 03:52:31.678812 28785 solver.cpp:244]     Train net output #0: loss = 0.00406568 (* 1 = 0.00406568 loss)
I0403 03:52:31.843691 28785 sgd_solver.cpp:106] Iteration 5408, lr = 0.0005
I0403 03:52:43.598064 28785 solver.cpp:228] Iteration 5424, loss = 0.00111706
I0403 03:52:43.598165 28785 solver.cpp:244]     Train net output #0: loss = 0.00111717 (* 1 = 0.00111717 loss)
I0403 03:52:43.775741 28785 sgd_solver.cpp:106] Iteration 5424, lr = 0.0005
I0403 03:52:55.287796 28785 solver.cpp:228] Iteration 5440, loss = 0.00374501
I0403 03:52:55.288147 28785 solver.cpp:244]     Train net output #0: loss = 0.00374512 (* 1 = 0.00374512 loss)
I0403 03:52:55.486829 28785 sgd_solver.cpp:106] Iteration 5440, lr = 0.0005
I0403 03:53:07.177711 28785 solver.cpp:228] Iteration 5456, loss = 0.00143261
I0403 03:53:07.177825 28785 solver.cpp:244]     Train net output #0: loss = 0.00143273 (* 1 = 0.00143273 loss)
I0403 03:53:07.354192 28785 sgd_solver.cpp:106] Iteration 5456, lr = 0.0005
I0403 03:53:18.829740 28785 solver.cpp:228] Iteration 5472, loss = 0.000409213
I0403 03:53:18.829850 28785 solver.cpp:244]     Train net output #0: loss = 0.000409326 (* 1 = 0.000409326 loss)
I0403 03:53:19.013098 28785 sgd_solver.cpp:106] Iteration 5472, lr = 0.0005
I0403 03:53:30.688509 28785 solver.cpp:228] Iteration 5488, loss = 0.00409171
I0403 03:53:30.688808 28785 solver.cpp:244]     Train net output #0: loss = 0.00409183 (* 1 = 0.00409183 loss)
I0403 03:53:30.857512 28785 sgd_solver.cpp:106] Iteration 5488, lr = 0.0005
I0403 03:53:42.457509 28785 solver.cpp:228] Iteration 5504, loss = 0.0136751
I0403 03:53:42.457623 28785 solver.cpp:244]     Train net output #0: loss = 0.0136752 (* 1 = 0.0136752 loss)
I0403 03:53:42.661329 28785 sgd_solver.cpp:106] Iteration 5504, lr = 0.0005
I0403 03:53:54.204957 28785 solver.cpp:228] Iteration 5520, loss = 0.00111206
I0403 03:53:54.205071 28785 solver.cpp:244]     Train net output #0: loss = 0.00111217 (* 1 = 0.00111217 loss)
I0403 03:53:54.402150 28785 sgd_solver.cpp:106] Iteration 5520, lr = 0.0005
I0403 03:53:57.484395 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_5525.caffemodel
I0403 03:54:00.242972 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_5525.solverstate
I0403 03:54:02.123787 28785 solver.cpp:337] Iteration 5525, Testing net (#0)
I0403 03:54:51.677052 28785 solver.cpp:404]     Test net output #0: accuracy = 0.967466
I0403 03:54:51.677346 28785 solver.cpp:404]     Test net output #1: loss = 0.120053 (* 1 = 0.120053 loss)
I0403 03:55:00.264452 28785 solver.cpp:228] Iteration 5536, loss = 0.00177078
I0403 03:55:00.264554 28785 solver.cpp:244]     Train net output #0: loss = 0.00177089 (* 1 = 0.00177089 loss)
I0403 03:55:00.447710 28785 sgd_solver.cpp:106] Iteration 5536, lr = 0.0005
I0403 03:55:12.109351 28785 solver.cpp:228] Iteration 5552, loss = 0.0147571
I0403 03:55:12.115434 28785 solver.cpp:244]     Train net output #0: loss = 0.0147572 (* 1 = 0.0147572 loss)
I0403 03:55:12.297324 28785 sgd_solver.cpp:106] Iteration 5552, lr = 0.0005
I0403 03:55:23.817562 28785 solver.cpp:228] Iteration 5568, loss = 0.0103092
I0403 03:55:23.824270 28785 solver.cpp:244]     Train net output #0: loss = 0.0103094 (* 1 = 0.0103094 loss)
I0403 03:55:23.992697 28785 sgd_solver.cpp:106] Iteration 5568, lr = 0.0005
I0403 03:55:35.537919 28785 solver.cpp:228] Iteration 5584, loss = 0.015088
I0403 03:55:35.544901 28785 solver.cpp:244]     Train net output #0: loss = 0.0150881 (* 1 = 0.0150881 loss)
I0403 03:55:35.716714 28785 sgd_solver.cpp:106] Iteration 5584, lr = 0.0005
I0403 03:55:47.453686 28785 solver.cpp:228] Iteration 5600, loss = 0.00712034
I0403 03:55:47.453797 28785 solver.cpp:244]     Train net output #0: loss = 0.00712045 (* 1 = 0.00712045 loss)
I0403 03:55:47.641667 28785 sgd_solver.cpp:106] Iteration 5600, lr = 0.0005
I0403 03:55:59.237058 28785 solver.cpp:228] Iteration 5616, loss = 0.0240621
I0403 03:55:59.237378 28785 solver.cpp:244]     Train net output #0: loss = 0.0240622 (* 1 = 0.0240622 loss)
I0403 03:55:59.422466 28785 sgd_solver.cpp:106] Iteration 5616, lr = 0.0005
I0403 03:56:11.196544 28785 solver.cpp:228] Iteration 5632, loss = 0.0102262
I0403 03:56:11.196645 28785 solver.cpp:244]     Train net output #0: loss = 0.0102263 (* 1 = 0.0102263 loss)
I0403 03:56:11.374784 28785 sgd_solver.cpp:106] Iteration 5632, lr = 0.0005
I0403 03:56:23.042356 28785 solver.cpp:228] Iteration 5648, loss = 0.0081137
I0403 03:56:23.042469 28785 solver.cpp:244]     Train net output #0: loss = 0.00811382 (* 1 = 0.00811382 loss)
I0403 03:56:23.233222 28785 sgd_solver.cpp:106] Iteration 5648, lr = 0.0005
I0403 03:56:34.786324 28785 solver.cpp:228] Iteration 5664, loss = 0.0102864
I0403 03:56:34.786659 28785 solver.cpp:244]     Train net output #0: loss = 0.0102865 (* 1 = 0.0102865 loss)
I0403 03:56:34.955627 28785 sgd_solver.cpp:106] Iteration 5664, lr = 0.0005
I0403 03:56:46.544597 28785 solver.cpp:228] Iteration 5680, loss = 0.00471044
I0403 03:56:46.544713 28785 solver.cpp:244]     Train net output #0: loss = 0.00471055 (* 1 = 0.00471055 loss)
I0403 03:56:46.729652 28785 sgd_solver.cpp:106] Iteration 5680, lr = 0.0005
I0403 03:56:58.195268 28785 solver.cpp:228] Iteration 5696, loss = 0.0103425
I0403 03:56:58.195379 28785 solver.cpp:244]     Train net output #0: loss = 0.0103426 (* 1 = 0.0103426 loss)
I0403 03:56:58.380935 28785 sgd_solver.cpp:106] Iteration 5696, lr = 0.0005
I0403 03:57:10.056637 28785 solver.cpp:228] Iteration 5712, loss = 0.00293075
I0403 03:57:10.056931 28785 solver.cpp:244]     Train net output #0: loss = 0.00293086 (* 1 = 0.00293086 loss)
I0403 03:57:10.199722 28785 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 03:57:22.115631 28785 solver.cpp:228] Iteration 5728, loss = 0.00476794
I0403 03:57:22.115736 28785 solver.cpp:244]     Train net output #0: loss = 0.00476805 (* 1 = 0.00476805 loss)
I0403 03:57:22.293460 28785 sgd_solver.cpp:106] Iteration 5728, lr = 0.0005
I0403 03:57:33.843691 28785 solver.cpp:228] Iteration 5744, loss = 0.00049797
I0403 03:57:33.843802 28785 solver.cpp:244]     Train net output #0: loss = 0.00049808 (* 1 = 0.00049808 loss)
I0403 03:57:34.057538 28785 sgd_solver.cpp:106] Iteration 5744, lr = 0.0005
I0403 03:57:45.745734 28785 solver.cpp:228] Iteration 5760, loss = 0.0131908
I0403 03:57:45.746033 28785 solver.cpp:244]     Train net output #0: loss = 0.013191 (* 1 = 0.013191 loss)
I0403 03:57:45.931650 28785 sgd_solver.cpp:106] Iteration 5760, lr = 0.0005
I0403 03:57:57.485221 28785 solver.cpp:228] Iteration 5776, loss = 0.00770877
I0403 03:57:57.485328 28785 solver.cpp:244]     Train net output #0: loss = 0.00770888 (* 1 = 0.00770888 loss)
I0403 03:57:57.643352 28785 sgd_solver.cpp:106] Iteration 5776, lr = 0.0005
I0403 03:58:09.316011 28785 solver.cpp:228] Iteration 5792, loss = 0.00288546
I0403 03:58:09.316125 28785 solver.cpp:244]     Train net output #0: loss = 0.00288558 (* 1 = 0.00288558 loss)
I0403 03:58:09.500804 28785 sgd_solver.cpp:106] Iteration 5792, lr = 0.0005
I0403 03:58:21.101403 28785 solver.cpp:228] Iteration 5808, loss = 0.0114642
I0403 03:58:21.101708 28785 solver.cpp:244]     Train net output #0: loss = 0.0114643 (* 1 = 0.0114643 loss)
I0403 03:58:21.279903 28785 sgd_solver.cpp:106] Iteration 5808, lr = 0.0005
I0403 03:58:32.776103 28785 solver.cpp:228] Iteration 5824, loss = 0.00495711
I0403 03:58:32.776213 28785 solver.cpp:244]     Train net output #0: loss = 0.00495722 (* 1 = 0.00495722 loss)
I0403 03:58:32.976841 28785 sgd_solver.cpp:106] Iteration 5824, lr = 0.0005
I0403 03:58:44.503880 28785 solver.cpp:228] Iteration 5840, loss = 0.00106927
I0403 03:58:44.503983 28785 solver.cpp:244]     Train net output #0: loss = 0.00106939 (* 1 = 0.00106939 loss)
I0403 03:58:44.667990 28785 sgd_solver.cpp:106] Iteration 5840, lr = 0.0005
I0403 03:58:51.297487 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_5850.caffemodel
I0403 03:58:54.066967 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_5850.solverstate
I0403 03:58:55.956100 28785 solver.cpp:337] Iteration 5850, Testing net (#0)
I0403 03:59:45.516341 28785 solver.cpp:404]     Test net output #0: accuracy = 0.969078
I0403 03:59:45.516682 28785 solver.cpp:404]     Test net output #1: loss = 0.115197 (* 1 = 0.115197 loss)
I0403 03:59:50.415172 28785 solver.cpp:228] Iteration 5856, loss = 0.00233749
I0403 03:59:50.415277 28785 solver.cpp:244]     Train net output #0: loss = 0.0023376 (* 1 = 0.0023376 loss)
I0403 03:59:50.565263 28785 sgd_solver.cpp:106] Iteration 5856, lr = 0.0005
I0403 04:00:02.368989 28785 solver.cpp:228] Iteration 5872, loss = 0.0155475
I0403 04:00:02.369094 28785 solver.cpp:244]     Train net output #0: loss = 0.0155476 (* 1 = 0.0155476 loss)
I0403 04:00:02.547168 28785 sgd_solver.cpp:106] Iteration 5872, lr = 0.0005
I0403 04:00:14.138653 28785 solver.cpp:228] Iteration 5888, loss = 0.0116532
I0403 04:00:14.138762 28785 solver.cpp:244]     Train net output #0: loss = 0.0116533 (* 1 = 0.0116533 loss)
I0403 04:00:14.367566 28785 sgd_solver.cpp:106] Iteration 5888, lr = 0.0005
I0403 04:00:26.040168 28785 solver.cpp:228] Iteration 5904, loss = 0.000633597
I0403 04:00:26.040483 28785 solver.cpp:244]     Train net output #0: loss = 0.000633705 (* 1 = 0.000633705 loss)
I0403 04:00:26.210366 28785 sgd_solver.cpp:106] Iteration 5904, lr = 0.0005
I0403 04:00:37.952399 28785 solver.cpp:228] Iteration 5920, loss = 0.00251223
I0403 04:00:37.952481 28785 solver.cpp:244]     Train net output #0: loss = 0.00251233 (* 1 = 0.00251233 loss)
I0403 04:00:38.112279 28785 sgd_solver.cpp:106] Iteration 5920, lr = 0.0005
I0403 04:00:49.664382 28785 solver.cpp:228] Iteration 5936, loss = 0.000583233
I0403 04:00:49.664485 28785 solver.cpp:244]     Train net output #0: loss = 0.000583339 (* 1 = 0.000583339 loss)
I0403 04:00:49.841085 28785 sgd_solver.cpp:106] Iteration 5936, lr = 0.0005
I0403 04:01:01.700026 28785 solver.cpp:228] Iteration 5952, loss = 0.00963699
I0403 04:01:01.700314 28785 solver.cpp:244]     Train net output #0: loss = 0.0096371 (* 1 = 0.0096371 loss)
I0403 04:01:01.879057 28785 sgd_solver.cpp:106] Iteration 5952, lr = 0.0005
I0403 04:01:13.444708 28785 solver.cpp:228] Iteration 5968, loss = 0.00328279
I0403 04:01:13.444819 28785 solver.cpp:244]     Train net output #0: loss = 0.0032829 (* 1 = 0.0032829 loss)
I0403 04:01:13.622220 28785 sgd_solver.cpp:106] Iteration 5968, lr = 0.0005
I0403 04:01:25.237246 28785 solver.cpp:228] Iteration 5984, loss = 0.00287475
I0403 04:01:25.237365 28785 solver.cpp:244]     Train net output #0: loss = 0.00287486 (* 1 = 0.00287486 loss)
I0403 04:01:25.457587 28785 sgd_solver.cpp:106] Iteration 5984, lr = 0.0005
I0403 04:01:37.280233 28785 solver.cpp:228] Iteration 6000, loss = 0.000545864
I0403 04:01:37.280520 28785 solver.cpp:244]     Train net output #0: loss = 0.000545976 (* 1 = 0.000545976 loss)
I0403 04:01:37.415683 28785 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0403 04:01:49.458194 28785 solver.cpp:228] Iteration 6016, loss = 0.00523114
I0403 04:01:49.458304 28785 solver.cpp:244]     Train net output #0: loss = 0.00523126 (* 1 = 0.00523126 loss)
I0403 04:01:49.625087 28785 sgd_solver.cpp:106] Iteration 6016, lr = 0.0005
I0403 04:02:01.453372 28785 solver.cpp:228] Iteration 6032, loss = 0.00685063
I0403 04:02:01.453474 28785 solver.cpp:244]     Train net output #0: loss = 0.00685074 (* 1 = 0.00685074 loss)
I0403 04:02:01.632453 28785 sgd_solver.cpp:106] Iteration 6032, lr = 0.0005
I0403 04:02:13.337676 28785 solver.cpp:228] Iteration 6048, loss = 0.0191281
I0403 04:02:13.337991 28785 solver.cpp:244]     Train net output #0: loss = 0.0191282 (* 1 = 0.0191282 loss)
I0403 04:02:13.523035 28785 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 04:02:25.044746 28785 solver.cpp:228] Iteration 6064, loss = 0.00610903
I0403 04:02:25.044860 28785 solver.cpp:244]     Train net output #0: loss = 0.00610914 (* 1 = 0.00610914 loss)
I0403 04:02:25.278110 28785 sgd_solver.cpp:106] Iteration 6064, lr = 0.0005
I0403 04:02:36.897881 28785 solver.cpp:228] Iteration 6080, loss = 0.00168241
I0403 04:02:36.897984 28785 solver.cpp:244]     Train net output #0: loss = 0.00168252 (* 1 = 0.00168252 loss)
I0403 04:02:37.063835 28785 sgd_solver.cpp:106] Iteration 6080, lr = 0.0005
I0403 04:02:48.775105 28785 solver.cpp:228] Iteration 6096, loss = 0.00838755
I0403 04:02:48.777165 28785 solver.cpp:244]     Train net output #0: loss = 0.00838766 (* 1 = 0.00838766 loss)
I0403 04:02:48.983286 28785 sgd_solver.cpp:106] Iteration 6096, lr = 0.0005
I0403 04:03:00.647120 28785 solver.cpp:228] Iteration 6112, loss = 0.00492507
I0403 04:03:00.647220 28785 solver.cpp:244]     Train net output #0: loss = 0.00492518 (* 1 = 0.00492518 loss)
I0403 04:03:00.824362 28785 sgd_solver.cpp:106] Iteration 6112, lr = 0.0005
I0403 04:03:12.538576 28785 solver.cpp:228] Iteration 6128, loss = 0.0025188
I0403 04:03:12.538693 28785 solver.cpp:244]     Train net output #0: loss = 0.00251892 (* 1 = 0.00251892 loss)
I0403 04:03:12.732338 28785 sgd_solver.cpp:106] Iteration 6128, lr = 0.0005
I0403 04:03:24.376139 28785 solver.cpp:228] Iteration 6144, loss = 0.0194035
I0403 04:03:24.376444 28785 solver.cpp:244]     Train net output #0: loss = 0.0194036 (* 1 = 0.0194036 loss)
I0403 04:03:24.554393 28785 sgd_solver.cpp:106] Iteration 6144, lr = 0.0005
I0403 04:03:36.479255 28785 solver.cpp:228] Iteration 6160, loss = 0.00106516
I0403 04:03:36.479370 28785 solver.cpp:244]     Train net output #0: loss = 0.00106527 (* 1 = 0.00106527 loss)
I0403 04:03:36.627667 28785 sgd_solver.cpp:106] Iteration 6160, lr = 0.0005
I0403 04:03:47.005772 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_6175.caffemodel
I0403 04:03:49.892674 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_6175.solverstate
I0403 04:03:51.835121 28785 solver.cpp:337] Iteration 6175, Testing net (#0)
I0403 04:04:41.402369 28785 solver.cpp:404]     Test net output #0: accuracy = 0.96765
I0403 04:04:41.402690 28785 solver.cpp:404]     Test net output #1: loss = 0.120657 (* 1 = 0.120657 loss)
I0403 04:04:42.749179 28785 solver.cpp:228] Iteration 6176, loss = 0.00042459
I0403 04:04:42.749266 28785 solver.cpp:244]     Train net output #0: loss = 0.000424697 (* 1 = 0.000424697 loss)
I0403 04:04:42.920794 28785 sgd_solver.cpp:106] Iteration 6176, lr = 0.0005
I0403 04:04:54.599195 28785 solver.cpp:228] Iteration 6192, loss = 0.00503686
I0403 04:04:54.599308 28785 solver.cpp:244]     Train net output #0: loss = 0.00503696 (* 1 = 0.00503696 loss)
I0403 04:04:54.798121 28785 sgd_solver.cpp:106] Iteration 6192, lr = 0.0005
I0403 04:05:06.531618 28785 solver.cpp:228] Iteration 6208, loss = 0.00719047
I0403 04:05:06.531744 28785 solver.cpp:244]     Train net output #0: loss = 0.00719057 (* 1 = 0.00719057 loss)
I0403 04:05:06.730463 28785 sgd_solver.cpp:106] Iteration 6208, lr = 0.0005
I0403 04:05:18.243521 28785 solver.cpp:228] Iteration 6224, loss = 0.00326107
I0403 04:05:18.243815 28785 solver.cpp:244]     Train net output #0: loss = 0.00326119 (* 1 = 0.00326119 loss)
I0403 04:05:18.416002 28785 sgd_solver.cpp:106] Iteration 6224, lr = 0.0005
I0403 04:05:29.991520 28785 solver.cpp:228] Iteration 6240, loss = 0.00484368
I0403 04:05:29.991616 28785 solver.cpp:244]     Train net output #0: loss = 0.00484379 (* 1 = 0.00484379 loss)
I0403 04:05:30.166066 28785 sgd_solver.cpp:106] Iteration 6240, lr = 0.0005
I0403 04:05:41.861805 28785 solver.cpp:228] Iteration 6256, loss = 0.00169244
I0403 04:05:41.861910 28785 solver.cpp:244]     Train net output #0: loss = 0.00169255 (* 1 = 0.00169255 loss)
I0403 04:05:42.039908 28785 sgd_solver.cpp:106] Iteration 6256, lr = 0.0005
I0403 04:05:53.539535 28785 solver.cpp:228] Iteration 6272, loss = 0.0109935
I0403 04:05:53.539839 28785 solver.cpp:244]     Train net output #0: loss = 0.0109936 (* 1 = 0.0109936 loss)
I0403 04:05:53.744303 28785 sgd_solver.cpp:106] Iteration 6272, lr = 0.0005
I0403 04:06:05.259254 28785 solver.cpp:228] Iteration 6288, loss = 0.00514256
I0403 04:06:05.259351 28785 solver.cpp:244]     Train net output #0: loss = 0.00514267 (* 1 = 0.00514267 loss)
I0403 04:06:05.418520 28785 sgd_solver.cpp:106] Iteration 6288, lr = 0.0005
I0403 04:06:17.284417 28785 solver.cpp:228] Iteration 6304, loss = 0.00201589
I0403 04:06:17.284526 28785 solver.cpp:244]     Train net output #0: loss = 0.002016 (* 1 = 0.002016 loss)
I0403 04:06:17.480271 28785 sgd_solver.cpp:106] Iteration 6304, lr = 0.0005
I0403 04:06:28.966884 28785 solver.cpp:228] Iteration 6320, loss = 0.000718022
I0403 04:06:28.967200 28785 solver.cpp:244]     Train net output #0: loss = 0.000718132 (* 1 = 0.000718132 loss)
I0403 04:06:29.123868 28785 sgd_solver.cpp:106] Iteration 6320, lr = 0.0005
I0403 04:06:40.892074 28785 solver.cpp:228] Iteration 6336, loss = 0.00290695
I0403 04:06:40.892173 28785 solver.cpp:244]     Train net output #0: loss = 0.00290706 (* 1 = 0.00290706 loss)
I0403 04:06:41.072635 28785 sgd_solver.cpp:106] Iteration 6336, lr = 0.0005
I0403 04:06:52.603567 28785 solver.cpp:228] Iteration 6352, loss = 0.00349774
I0403 04:06:52.603667 28785 solver.cpp:244]     Train net output #0: loss = 0.00349785 (* 1 = 0.00349785 loss)
I0403 04:06:52.781636 28785 sgd_solver.cpp:106] Iteration 6352, lr = 0.0005
I0403 04:07:04.472054 28785 solver.cpp:228] Iteration 6368, loss = 0.0191047
I0403 04:07:04.472371 28785 solver.cpp:244]     Train net output #0: loss = 0.0191048 (* 1 = 0.0191048 loss)
I0403 04:07:04.636224 28785 sgd_solver.cpp:106] Iteration 6368, lr = 0.0005
I0403 04:07:16.275518 28785 solver.cpp:228] Iteration 6384, loss = 0.0029074
I0403 04:07:16.275617 28785 solver.cpp:244]     Train net output #0: loss = 0.00290751 (* 1 = 0.00290751 loss)
I0403 04:07:16.423934 28785 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 04:07:28.218289 28785 solver.cpp:228] Iteration 6400, loss = 0.00712145
I0403 04:07:28.218391 28785 solver.cpp:244]     Train net output #0: loss = 0.00712156 (* 1 = 0.00712156 loss)
I0403 04:07:28.392385 28785 sgd_solver.cpp:106] Iteration 6400, lr = 0.0005
I0403 04:07:39.965957 28785 solver.cpp:228] Iteration 6416, loss = 0.000634261
I0403 04:07:39.966249 28785 solver.cpp:244]     Train net output #0: loss = 0.00063437 (* 1 = 0.00063437 loss)
I0403 04:07:40.100438 28785 sgd_solver.cpp:106] Iteration 6416, lr = 0.0005
I0403 04:07:52.133999 28785 solver.cpp:228] Iteration 6432, loss = 0.0050584
I0403 04:07:52.134095 28785 solver.cpp:244]     Train net output #0: loss = 0.00505851 (* 1 = 0.00505851 loss)
I0403 04:07:52.304533 28785 sgd_solver.cpp:106] Iteration 6432, lr = 0.0005
I0403 04:08:03.778673 28785 solver.cpp:228] Iteration 6448, loss = 0.00233985
I0403 04:08:03.778766 28785 solver.cpp:244]     Train net output #0: loss = 0.00233996 (* 1 = 0.00233996 loss)
I0403 04:08:03.949309 28785 sgd_solver.cpp:106] Iteration 6448, lr = 0.0005
I0403 04:08:15.531852 28785 solver.cpp:228] Iteration 6464, loss = 0.00476551
I0403 04:08:15.532153 28785 solver.cpp:244]     Train net output #0: loss = 0.00476562 (* 1 = 0.00476562 loss)
I0403 04:08:15.715504 28785 sgd_solver.cpp:106] Iteration 6464, lr = 0.0005
I0403 04:08:27.211169 28785 solver.cpp:228] Iteration 6480, loss = 0.00543931
I0403 04:08:27.211271 28785 solver.cpp:244]     Train net output #0: loss = 0.00543943 (* 1 = 0.00543943 loss)
I0403 04:08:27.394399 28785 sgd_solver.cpp:106] Iteration 6480, lr = 0.0005
I0403 04:08:38.812283 28785 solver.cpp:228] Iteration 6496, loss = 0.00175934
I0403 04:08:38.812391 28785 solver.cpp:244]     Train net output #0: loss = 0.00175945 (* 1 = 0.00175945 loss)
I0403 04:08:39.057534 28785 sgd_solver.cpp:106] Iteration 6496, lr = 0.0005
I0403 04:08:41.268067 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_6500.caffemodel
I0403 04:08:44.146396 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_6500.solverstate
I0403 04:08:46.112772 28785 solver.cpp:337] Iteration 6500, Testing net (#0)
I0403 04:09:35.699439 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968111
I0403 04:09:35.699777 28785 solver.cpp:404]     Test net output #1: loss = 0.122976 (* 1 = 0.122976 loss)
I0403 04:09:44.979481 28785 solver.cpp:228] Iteration 6512, loss = 0.0040276
I0403 04:09:44.980523 28785 solver.cpp:244]     Train net output #0: loss = 0.00402771 (* 1 = 0.00402771 loss)
I0403 04:09:45.107360 28785 sgd_solver.cpp:106] Iteration 6512, lr = 5e-05
I0403 04:09:56.643688 28785 solver.cpp:228] Iteration 6528, loss = 0.00472447
I0403 04:09:56.643798 28785 solver.cpp:244]     Train net output #0: loss = 0.00472459 (* 1 = 0.00472459 loss)
I0403 04:09:56.854429 28785 sgd_solver.cpp:106] Iteration 6528, lr = 5e-05
I0403 04:10:08.293642 28785 solver.cpp:228] Iteration 6544, loss = 0.00503578
I0403 04:10:08.294348 28785 solver.cpp:244]     Train net output #0: loss = 0.00503589 (* 1 = 0.00503589 loss)
I0403 04:10:08.526996 28785 sgd_solver.cpp:106] Iteration 6544, lr = 5e-05
I0403 04:10:20.158813 28785 solver.cpp:228] Iteration 6560, loss = 0.000682768
I0403 04:10:20.158913 28785 solver.cpp:244]     Train net output #0: loss = 0.000682881 (* 1 = 0.000682881 loss)
I0403 04:10:20.335881 28785 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 04:10:31.949882 28785 solver.cpp:228] Iteration 6576, loss = 0.00331993
I0403 04:10:31.949995 28785 solver.cpp:244]     Train net output #0: loss = 0.00332004 (* 1 = 0.00332004 loss)
I0403 04:10:32.101552 28785 sgd_solver.cpp:106] Iteration 6576, lr = 5e-05
I0403 04:10:43.605762 28785 solver.cpp:228] Iteration 6592, loss = 0.00410903
I0403 04:10:43.606029 28785 solver.cpp:244]     Train net output #0: loss = 0.00410914 (* 1 = 0.00410914 loss)
I0403 04:10:43.762002 28785 sgd_solver.cpp:106] Iteration 6592, lr = 5e-05
I0403 04:10:55.333940 28785 solver.cpp:228] Iteration 6608, loss = 0.00583998
I0403 04:10:55.334036 28785 solver.cpp:244]     Train net output #0: loss = 0.0058401 (* 1 = 0.0058401 loss)
I0403 04:10:55.505470 28785 sgd_solver.cpp:106] Iteration 6608, lr = 5e-05
I0403 04:11:07.038070 28785 solver.cpp:228] Iteration 6624, loss = 0.00593372
I0403 04:11:07.038179 28785 solver.cpp:244]     Train net output #0: loss = 0.00593383 (* 1 = 0.00593383 loss)
I0403 04:11:07.242828 28785 sgd_solver.cpp:106] Iteration 6624, lr = 5e-05
I0403 04:11:19.161212 28785 solver.cpp:228] Iteration 6640, loss = 0.00544579
I0403 04:11:19.161494 28785 solver.cpp:244]     Train net output #0: loss = 0.0054459 (* 1 = 0.0054459 loss)
I0403 04:11:19.325956 28785 sgd_solver.cpp:106] Iteration 6640, lr = 5e-05
I0403 04:11:30.867913 28785 solver.cpp:228] Iteration 6656, loss = 0.000629849
I0403 04:11:30.868026 28785 solver.cpp:244]     Train net output #0: loss = 0.000629964 (* 1 = 0.000629964 loss)
I0403 04:11:31.051089 28785 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 04:11:42.612139 28785 solver.cpp:228] Iteration 6672, loss = 0.00114451
I0403 04:11:42.612243 28785 solver.cpp:244]     Train net output #0: loss = 0.00114462 (* 1 = 0.00114462 loss)
I0403 04:11:42.762352 28785 sgd_solver.cpp:106] Iteration 6672, lr = 5e-05
I0403 04:11:54.295949 28785 solver.cpp:228] Iteration 6688, loss = 0.0173901
I0403 04:11:54.296259 28785 solver.cpp:244]     Train net output #0: loss = 0.0173903 (* 1 = 0.0173903 loss)
I0403 04:11:54.473100 28785 sgd_solver.cpp:106] Iteration 6688, lr = 5e-05
I0403 04:12:05.923085 28785 solver.cpp:228] Iteration 6704, loss = 0.019978
I0403 04:12:05.923197 28785 solver.cpp:244]     Train net output #0: loss = 0.0199781 (* 1 = 0.0199781 loss)
I0403 04:12:06.122462 28785 sgd_solver.cpp:106] Iteration 6704, lr = 5e-05
I0403 04:12:17.716531 28785 solver.cpp:228] Iteration 6720, loss = 0.0015685
I0403 04:12:17.716634 28785 solver.cpp:244]     Train net output #0: loss = 0.00156861 (* 1 = 0.00156861 loss)
I0403 04:12:17.883563 28785 sgd_solver.cpp:106] Iteration 6720, lr = 5e-05
I0403 04:12:29.413318 28785 solver.cpp:228] Iteration 6736, loss = 0.00254755
I0403 04:12:29.413625 28785 solver.cpp:244]     Train net output #0: loss = 0.00254766 (* 1 = 0.00254766 loss)
I0403 04:12:29.593876 28785 sgd_solver.cpp:106] Iteration 6736, lr = 5e-05
I0403 04:12:41.259169 28785 solver.cpp:228] Iteration 6752, loss = 0.000660493
I0403 04:12:41.259274 28785 solver.cpp:244]     Train net output #0: loss = 0.000660603 (* 1 = 0.000660603 loss)
I0403 04:12:41.432384 28785 sgd_solver.cpp:106] Iteration 6752, lr = 5e-05
I0403 04:12:53.219444 28785 solver.cpp:228] Iteration 6768, loss = 0.0008987
I0403 04:12:53.219544 28785 solver.cpp:244]     Train net output #0: loss = 0.000898811 (* 1 = 0.000898811 loss)
I0403 04:12:53.383190 28785 sgd_solver.cpp:106] Iteration 6768, lr = 5e-05
I0403 04:13:04.957537 28785 solver.cpp:228] Iteration 6784, loss = 0.00282044
I0403 04:13:04.957873 28785 solver.cpp:244]     Train net output #0: loss = 0.00282055 (* 1 = 0.00282055 loss)
I0403 04:13:05.114733 28785 sgd_solver.cpp:106] Iteration 6784, lr = 5e-05
I0403 04:13:16.769209 28785 solver.cpp:228] Iteration 6800, loss = 0.00245703
I0403 04:13:16.769314 28785 solver.cpp:244]     Train net output #0: loss = 0.00245715 (* 1 = 0.00245715 loss)
I0403 04:13:16.933583 28785 sgd_solver.cpp:106] Iteration 6800, lr = 5e-05
I0403 04:13:28.524655 28785 solver.cpp:228] Iteration 6816, loss = 0.00219089
I0403 04:13:28.524756 28785 solver.cpp:244]     Train net output #0: loss = 0.00219101 (* 1 = 0.00219101 loss)
I0403 04:13:28.701158 28785 sgd_solver.cpp:106] Iteration 6816, lr = 5e-05
I0403 04:13:34.559041 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_6825.caffemodel
I0403 04:13:37.288931 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_6825.solverstate
I0403 04:13:40.076572 28785 solver.cpp:337] Iteration 6825, Testing net (#0)
I0403 04:14:29.662927 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968157
I0403 04:14:29.663277 28785 solver.cpp:404]     Test net output #1: loss = 0.121475 (* 1 = 0.121475 loss)
I0403 04:14:35.286399 28785 solver.cpp:228] Iteration 6832, loss = 0.00351334
I0403 04:14:35.286500 28785 solver.cpp:244]     Train net output #0: loss = 0.00351346 (* 1 = 0.00351346 loss)
I0403 04:14:35.451494 28785 sgd_solver.cpp:106] Iteration 6832, lr = 5e-05
I0403 04:14:47.180227 28785 solver.cpp:228] Iteration 6848, loss = 0.00145705
I0403 04:14:47.180347 28785 solver.cpp:244]     Train net output #0: loss = 0.00145717 (* 1 = 0.00145717 loss)
I0403 04:14:47.358352 28785 sgd_solver.cpp:106] Iteration 6848, lr = 5e-05
I0403 04:14:58.994732 28785 solver.cpp:228] Iteration 6864, loss = 0.00320448
I0403 04:14:58.994833 28785 solver.cpp:244]     Train net output #0: loss = 0.0032046 (* 1 = 0.0032046 loss)
I0403 04:14:59.165168 28785 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 04:15:10.732606 28785 solver.cpp:228] Iteration 6880, loss = 0.0308769
I0403 04:15:10.732903 28785 solver.cpp:244]     Train net output #0: loss = 0.0308771 (* 1 = 0.0308771 loss)
I0403 04:15:10.961979 28785 sgd_solver.cpp:106] Iteration 6880, lr = 5e-05
I0403 04:15:22.664417 28785 solver.cpp:228] Iteration 6896, loss = 0.007651
I0403 04:15:22.664532 28785 solver.cpp:244]     Train net output #0: loss = 0.0076511 (* 1 = 0.0076511 loss)
I0403 04:15:22.858258 28785 sgd_solver.cpp:106] Iteration 6896, lr = 5e-05
I0403 04:15:34.528328 28785 solver.cpp:228] Iteration 6912, loss = 0.0167997
I0403 04:15:34.528429 28785 solver.cpp:244]     Train net output #0: loss = 0.0167998 (* 1 = 0.0167998 loss)
I0403 04:15:34.684408 28785 sgd_solver.cpp:106] Iteration 6912, lr = 5e-05
I0403 04:15:46.426002 28785 solver.cpp:228] Iteration 6928, loss = 0.00122736
I0403 04:15:46.426321 28785 solver.cpp:244]     Train net output #0: loss = 0.00122746 (* 1 = 0.00122746 loss)
I0403 04:15:46.627456 28785 sgd_solver.cpp:106] Iteration 6928, lr = 5e-05
I0403 04:15:58.205844 28785 solver.cpp:228] Iteration 6944, loss = 0.00304817
I0403 04:15:58.205942 28785 solver.cpp:244]     Train net output #0: loss = 0.00304827 (* 1 = 0.00304827 loss)
I0403 04:15:58.385324 28785 sgd_solver.cpp:106] Iteration 6944, lr = 5e-05
I0403 04:16:09.767789 28785 solver.cpp:228] Iteration 6960, loss = 0.00228281
I0403 04:16:09.767895 28785 solver.cpp:244]     Train net output #0: loss = 0.00228291 (* 1 = 0.00228291 loss)
I0403 04:16:09.945130 28785 sgd_solver.cpp:106] Iteration 6960, lr = 5e-05
I0403 04:16:21.568502 28785 solver.cpp:228] Iteration 6976, loss = 0.00190852
I0403 04:16:21.568862 28785 solver.cpp:244]     Train net output #0: loss = 0.00190862 (* 1 = 0.00190862 loss)
I0403 04:16:21.762609 28785 sgd_solver.cpp:106] Iteration 6976, lr = 5e-05
I0403 04:16:33.273325 28785 solver.cpp:228] Iteration 6992, loss = 0.00351192
I0403 04:16:33.273425 28785 solver.cpp:244]     Train net output #0: loss = 0.00351202 (* 1 = 0.00351202 loss)
I0403 04:16:33.439956 28785 sgd_solver.cpp:106] Iteration 6992, lr = 5e-05
I0403 04:16:45.053647 28785 solver.cpp:228] Iteration 7008, loss = 0.00327182
I0403 04:16:45.053750 28785 solver.cpp:244]     Train net output #0: loss = 0.00327192 (* 1 = 0.00327192 loss)
I0403 04:16:45.222651 28785 sgd_solver.cpp:106] Iteration 7008, lr = 5e-05
I0403 04:16:56.699831 28785 solver.cpp:228] Iteration 7024, loss = 0.00958729
I0403 04:16:56.700130 28785 solver.cpp:244]     Train net output #0: loss = 0.00958739 (* 1 = 0.00958739 loss)
I0403 04:16:56.876157 28785 sgd_solver.cpp:106] Iteration 7024, lr = 5e-05
I0403 04:17:08.385938 28785 solver.cpp:228] Iteration 7040, loss = 0.00731212
I0403 04:17:08.386041 28785 solver.cpp:244]     Train net output #0: loss = 0.00731223 (* 1 = 0.00731223 loss)
I0403 04:17:08.552646 28785 sgd_solver.cpp:106] Iteration 7040, lr = 5e-05
I0403 04:17:20.318434 28785 solver.cpp:228] Iteration 7056, loss = 0.00166077
I0403 04:17:20.318544 28785 solver.cpp:244]     Train net output #0: loss = 0.00166088 (* 1 = 0.00166088 loss)
I0403 04:17:20.501845 28785 sgd_solver.cpp:106] Iteration 7056, lr = 5e-05
I0403 04:17:32.144631 28785 solver.cpp:228] Iteration 7072, loss = 0.00246544
I0403 04:17:32.144958 28785 solver.cpp:244]     Train net output #0: loss = 0.00246554 (* 1 = 0.00246554 loss)
I0403 04:17:32.379463 28785 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 04:17:44.345326 28785 solver.cpp:228] Iteration 7088, loss = 0.000579762
I0403 04:17:44.345427 28785 solver.cpp:244]     Train net output #0: loss = 0.000579865 (* 1 = 0.000579865 loss)
I0403 04:17:44.496327 28785 sgd_solver.cpp:106] Iteration 7088, lr = 5e-05
I0403 04:17:56.180515 28785 solver.cpp:228] Iteration 7104, loss = 0.00367806
I0403 04:17:56.180629 28785 solver.cpp:244]     Train net output #0: loss = 0.00367817 (* 1 = 0.00367817 loss)
I0403 04:17:56.364053 28785 sgd_solver.cpp:106] Iteration 7104, lr = 5e-05
I0403 04:18:07.915081 28785 solver.cpp:228] Iteration 7120, loss = 0.0040365
I0403 04:18:07.915377 28785 solver.cpp:244]     Train net output #0: loss = 0.0040366 (* 1 = 0.0040366 loss)
I0403 04:18:08.083814 28785 sgd_solver.cpp:106] Iteration 7120, lr = 5e-05
I0403 04:18:19.673660 28785 solver.cpp:228] Iteration 7136, loss = 0.0017673
I0403 04:18:19.673760 28785 solver.cpp:244]     Train net output #0: loss = 0.0017674 (* 1 = 0.0017674 loss)
I0403 04:18:19.845561 28785 sgd_solver.cpp:106] Iteration 7136, lr = 5e-05
I0403 04:18:29.432536 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_7150.caffemodel
I0403 04:18:32.229490 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_7150.solverstate
I0403 04:18:34.146288 28785 solver.cpp:337] Iteration 7150, Testing net (#0)
I0403 04:19:23.707806 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968526
I0403 04:19:23.711021 28785 solver.cpp:404]     Test net output #1: loss = 0.120131 (* 1 = 0.120131 loss)
I0403 04:19:25.819592 28785 solver.cpp:228] Iteration 7152, loss = 0.0051182
I0403 04:19:25.819694 28785 solver.cpp:244]     Train net output #0: loss = 0.0051183 (* 1 = 0.0051183 loss)
I0403 04:19:25.970329 28785 sgd_solver.cpp:106] Iteration 7152, lr = 5e-05
I0403 04:19:37.686954 28785 solver.cpp:228] Iteration 7168, loss = 0.00676879
I0403 04:19:37.687067 28785 solver.cpp:244]     Train net output #0: loss = 0.0067689 (* 1 = 0.0067689 loss)
I0403 04:19:37.883481 28785 sgd_solver.cpp:106] Iteration 7168, lr = 5e-05
I0403 04:19:49.668805 28785 solver.cpp:228] Iteration 7184, loss = 0.00295775
I0403 04:19:49.668908 28785 solver.cpp:244]     Train net output #0: loss = 0.00295785 (* 1 = 0.00295785 loss)
I0403 04:19:49.845640 28785 sgd_solver.cpp:106] Iteration 7184, lr = 5e-05
I0403 04:20:01.775746 28785 solver.cpp:228] Iteration 7200, loss = 0.00541949
I0403 04:20:01.776084 28785 solver.cpp:244]     Train net output #0: loss = 0.00541959 (* 1 = 0.00541959 loss)
I0403 04:20:01.934115 28785 sgd_solver.cpp:106] Iteration 7200, lr = 5e-05
I0403 04:20:13.611655 28785 solver.cpp:228] Iteration 7216, loss = 0.000297517
I0403 04:20:13.611757 28785 solver.cpp:244]     Train net output #0: loss = 0.000297623 (* 1 = 0.000297623 loss)
I0403 04:20:13.778676 28785 sgd_solver.cpp:106] Iteration 7216, lr = 5e-05
I0403 04:20:25.316740 28785 solver.cpp:228] Iteration 7232, loss = 0.00839813
I0403 04:20:25.316841 28785 solver.cpp:244]     Train net output #0: loss = 0.00839824 (* 1 = 0.00839824 loss)
I0403 04:20:25.486413 28785 sgd_solver.cpp:106] Iteration 7232, lr = 5e-05
I0403 04:20:37.159979 28785 solver.cpp:228] Iteration 7248, loss = 0.00840633
I0403 04:20:37.160271 28785 solver.cpp:244]     Train net output #0: loss = 0.00840644 (* 1 = 0.00840644 loss)
I0403 04:20:37.306973 28785 sgd_solver.cpp:106] Iteration 7248, lr = 5e-05
I0403 04:20:49.221346 28785 solver.cpp:228] Iteration 7264, loss = 0.00305314
I0403 04:20:49.221448 28785 solver.cpp:244]     Train net output #0: loss = 0.00305325 (* 1 = 0.00305325 loss)
I0403 04:20:49.382302 28785 sgd_solver.cpp:106] Iteration 7264, lr = 5e-05
I0403 04:21:01.045805 28785 solver.cpp:228] Iteration 7280, loss = 0.000799672
I0403 04:21:01.045917 28785 solver.cpp:244]     Train net output #0: loss = 0.000799783 (* 1 = 0.000799783 loss)
I0403 04:21:01.248306 28785 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 04:21:12.992722 28785 solver.cpp:228] Iteration 7296, loss = 0.00147657
I0403 04:21:12.993013 28785 solver.cpp:244]     Train net output #0: loss = 0.00147668 (* 1 = 0.00147668 loss)
I0403 04:21:13.218886 28785 sgd_solver.cpp:106] Iteration 7296, lr = 5e-05
I0403 04:21:24.729879 28785 solver.cpp:228] Iteration 7312, loss = 0.0207276
I0403 04:21:24.729979 28785 solver.cpp:244]     Train net output #0: loss = 0.0207277 (* 1 = 0.0207277 loss)
I0403 04:21:24.891168 28785 sgd_solver.cpp:106] Iteration 7312, lr = 5e-05
I0403 04:21:36.502878 28785 solver.cpp:228] Iteration 7328, loss = 0.0178769
I0403 04:21:36.502995 28785 solver.cpp:244]     Train net output #0: loss = 0.017877 (* 1 = 0.017877 loss)
I0403 04:21:36.664050 28785 sgd_solver.cpp:106] Iteration 7328, lr = 5e-05
I0403 04:21:48.214189 28785 solver.cpp:228] Iteration 7344, loss = 0.000818657
I0403 04:21:48.214496 28785 solver.cpp:244]     Train net output #0: loss = 0.000818768 (* 1 = 0.000818768 loss)
I0403 04:21:48.387446 28785 sgd_solver.cpp:106] Iteration 7344, lr = 5e-05
I0403 04:21:59.990394 28785 solver.cpp:228] Iteration 7360, loss = 0.00957957
I0403 04:21:59.990507 28785 solver.cpp:244]     Train net output #0: loss = 0.00957968 (* 1 = 0.00957968 loss)
I0403 04:22:00.182027 28785 sgd_solver.cpp:106] Iteration 7360, lr = 5e-05
I0403 04:22:11.744635 28785 solver.cpp:228] Iteration 7376, loss = 0.00118372
I0403 04:22:11.744751 28785 solver.cpp:244]     Train net output #0: loss = 0.00118383 (* 1 = 0.00118383 loss)
I0403 04:22:11.997880 28785 sgd_solver.cpp:106] Iteration 7376, lr = 5e-05
I0403 04:22:23.512938 28785 solver.cpp:228] Iteration 7392, loss = 0.0053128
I0403 04:22:23.513260 28785 solver.cpp:244]     Train net output #0: loss = 0.00531291 (* 1 = 0.00531291 loss)
I0403 04:22:23.704445 28785 sgd_solver.cpp:106] Iteration 7392, lr = 5e-05
I0403 04:22:35.214457 28785 solver.cpp:228] Iteration 7408, loss = 0.00200744
I0403 04:22:35.214560 28785 solver.cpp:244]     Train net output #0: loss = 0.00200755 (* 1 = 0.00200755 loss)
I0403 04:22:35.387917 28785 sgd_solver.cpp:106] Iteration 7408, lr = 5e-05
I0403 04:22:46.844452 28785 solver.cpp:228] Iteration 7424, loss = 0.000694842
I0403 04:22:46.844558 28785 solver.cpp:244]     Train net output #0: loss = 0.000694953 (* 1 = 0.000694953 loss)
I0403 04:22:47.013690 28785 sgd_solver.cpp:106] Iteration 7424, lr = 5e-05
I0403 04:22:58.833561 28785 solver.cpp:228] Iteration 7440, loss = 0.000570259
I0403 04:22:58.833869 28785 solver.cpp:244]     Train net output #0: loss = 0.00057037 (* 1 = 0.00057037 loss)
I0403 04:22:59.014930 28785 sgd_solver.cpp:106] Iteration 7440, lr = 5e-05
I0403 04:23:10.520836 28785 solver.cpp:228] Iteration 7456, loss = 0.00615322
I0403 04:23:10.520956 28785 solver.cpp:244]     Train net output #0: loss = 0.00615333 (* 1 = 0.00615333 loss)
I0403 04:23:10.713114 28785 sgd_solver.cpp:106] Iteration 7456, lr = 5e-05
I0403 04:23:22.569851 28785 solver.cpp:228] Iteration 7472, loss = 0.0109653
I0403 04:23:22.569954 28785 solver.cpp:244]     Train net output #0: loss = 0.0109654 (* 1 = 0.0109654 loss)
I0403 04:23:22.747970 28785 sgd_solver.cpp:106] Iteration 7472, lr = 5e-05
I0403 04:23:24.192018 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_7475.caffemodel
I0403 04:23:26.873198 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_7475.solverstate
I0403 04:23:28.705870 28785 solver.cpp:337] Iteration 7475, Testing net (#0)
I0403 04:24:18.292829 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968525
I0403 04:24:18.293181 28785 solver.cpp:404]     Test net output #1: loss = 0.119778 (* 1 = 0.119778 loss)
I0403 04:24:28.259811 28785 solver.cpp:228] Iteration 7488, loss = 0.000791061
I0403 04:24:28.259912 28785 solver.cpp:244]     Train net output #0: loss = 0.000791172 (* 1 = 0.000791172 loss)
I0403 04:24:28.437124 28785 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 04:24:40.117264 28785 solver.cpp:228] Iteration 7504, loss = 0.00737336
I0403 04:24:40.117367 28785 solver.cpp:244]     Train net output #0: loss = 0.00737347 (* 1 = 0.00737347 loss)
I0403 04:24:40.286710 28785 sgd_solver.cpp:106] Iteration 7504, lr = 5e-05
I0403 04:24:51.764921 28785 solver.cpp:228] Iteration 7520, loss = 0.00135618
I0403 04:24:51.765216 28785 solver.cpp:244]     Train net output #0: loss = 0.00135629 (* 1 = 0.00135629 loss)
I0403 04:24:51.944181 28785 sgd_solver.cpp:106] Iteration 7520, lr = 5e-05
I0403 04:25:03.534627 28785 solver.cpp:228] Iteration 7536, loss = 0.00185322
I0403 04:25:03.534732 28785 solver.cpp:244]     Train net output #0: loss = 0.00185333 (* 1 = 0.00185333 loss)
I0403 04:25:03.713469 28785 sgd_solver.cpp:106] Iteration 7536, lr = 5e-05
I0403 04:25:15.145810 28785 solver.cpp:228] Iteration 7552, loss = 0.0013163
I0403 04:25:15.145920 28785 solver.cpp:244]     Train net output #0: loss = 0.00131641 (* 1 = 0.00131641 loss)
I0403 04:25:15.342550 28785 sgd_solver.cpp:106] Iteration 7552, lr = 5e-05
I0403 04:25:26.947479 28785 solver.cpp:228] Iteration 7568, loss = 0.00279413
I0403 04:25:26.947793 28785 solver.cpp:244]     Train net output #0: loss = 0.00279424 (* 1 = 0.00279424 loss)
I0403 04:25:27.139024 28785 sgd_solver.cpp:106] Iteration 7568, lr = 5e-05
I0403 04:25:38.925994 28785 solver.cpp:228] Iteration 7584, loss = 0.023451
I0403 04:25:38.926096 28785 solver.cpp:244]     Train net output #0: loss = 0.0234511 (* 1 = 0.0234511 loss)
I0403 04:25:39.103942 28785 sgd_solver.cpp:106] Iteration 7584, lr = 5e-05
I0403 04:25:50.789662 28785 solver.cpp:228] Iteration 7600, loss = 0.0218605
I0403 04:25:50.789777 28785 solver.cpp:244]     Train net output #0: loss = 0.0218607 (* 1 = 0.0218607 loss)
I0403 04:25:50.973116 28785 sgd_solver.cpp:106] Iteration 7600, lr = 5e-05
I0403 04:26:02.692446 28785 solver.cpp:228] Iteration 7616, loss = 0.00531017
I0403 04:26:02.692745 28785 solver.cpp:244]     Train net output #0: loss = 0.00531028 (* 1 = 0.00531028 loss)
I0403 04:26:02.865406 28785 sgd_solver.cpp:106] Iteration 7616, lr = 5e-05
I0403 04:26:14.446542 28785 solver.cpp:228] Iteration 7632, loss = 0.0272298
I0403 04:26:14.446656 28785 solver.cpp:244]     Train net output #0: loss = 0.0272299 (* 1 = 0.0272299 loss)
I0403 04:26:14.604300 28785 sgd_solver.cpp:106] Iteration 7632, lr = 5e-05
I0403 04:26:26.315038 28785 solver.cpp:228] Iteration 7648, loss = 0.000867921
I0403 04:26:26.315146 28785 solver.cpp:244]     Train net output #0: loss = 0.000868035 (* 1 = 0.000868035 loss)
I0403 04:26:26.473996 28785 sgd_solver.cpp:106] Iteration 7648, lr = 5e-05
I0403 04:26:38.109947 28785 solver.cpp:228] Iteration 7664, loss = 0.00132777
I0403 04:26:38.110282 28785 solver.cpp:244]     Train net output #0: loss = 0.00132789 (* 1 = 0.00132789 loss)
I0403 04:26:38.283869 28785 sgd_solver.cpp:106] Iteration 7664, lr = 5e-05
I0403 04:26:49.983973 28785 solver.cpp:228] Iteration 7680, loss = 0.00515299
I0403 04:26:49.984084 28785 solver.cpp:244]     Train net output #0: loss = 0.00515311 (* 1 = 0.00515311 loss)
I0403 04:26:50.218504 28785 sgd_solver.cpp:106] Iteration 7680, lr = 5e-05
I0403 04:27:01.950276 28785 solver.cpp:228] Iteration 7696, loss = 0.00108085
I0403 04:27:01.950383 28785 solver.cpp:244]     Train net output #0: loss = 0.00108097 (* 1 = 0.00108097 loss)
I0403 04:27:02.127214 28785 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 04:27:13.608692 28785 solver.cpp:228] Iteration 7712, loss = 0.00196995
I0403 04:27:13.609036 28785 solver.cpp:244]     Train net output #0: loss = 0.00197007 (* 1 = 0.00197007 loss)
I0403 04:27:13.786654 28785 sgd_solver.cpp:106] Iteration 7712, lr = 5e-05
I0403 04:27:25.507750 28785 solver.cpp:228] Iteration 7728, loss = 0.00759227
I0403 04:27:25.515501 28785 solver.cpp:244]     Train net output #0: loss = 0.00759239 (* 1 = 0.00759239 loss)
I0403 04:27:25.750766 28785 sgd_solver.cpp:106] Iteration 7728, lr = 5e-05
I0403 04:27:37.267135 28785 solver.cpp:228] Iteration 7744, loss = 0.00310333
I0403 04:27:37.267237 28785 solver.cpp:244]     Train net output #0: loss = 0.00310345 (* 1 = 0.00310345 loss)
I0403 04:27:37.444491 28785 sgd_solver.cpp:106] Iteration 7744, lr = 5e-05
I0403 04:27:48.979061 28785 solver.cpp:228] Iteration 7760, loss = 0.000778453
I0403 04:27:48.979367 28785 solver.cpp:244]     Train net output #0: loss = 0.000778572 (* 1 = 0.000778572 loss)
I0403 04:27:49.153647 28785 sgd_solver.cpp:106] Iteration 7760, lr = 5e-05
I0403 04:28:00.762562 28785 solver.cpp:228] Iteration 7776, loss = 0.00552738
I0403 04:28:00.762660 28785 solver.cpp:244]     Train net output #0: loss = 0.0055275 (* 1 = 0.0055275 loss)
I0403 04:28:00.938875 28785 sgd_solver.cpp:106] Iteration 7776, lr = 5e-05
I0403 04:28:12.592674 28785 solver.cpp:228] Iteration 7792, loss = 0.00178442
I0403 04:28:12.592777 28785 solver.cpp:244]     Train net output #0: loss = 0.00178454 (* 1 = 0.00178454 loss)
I0403 04:28:12.771814 28785 sgd_solver.cpp:106] Iteration 7792, lr = 5e-05
I0403 04:28:18.026826 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_7800.caffemodel
I0403 04:28:20.878336 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_7800.solverstate
I0403 04:28:22.795205 28785 solver.cpp:337] Iteration 7800, Testing net (#0)
I0403 04:29:12.353724 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968756
I0403 04:29:12.354030 28785 solver.cpp:404]     Test net output #1: loss = 0.119754 (* 1 = 0.119754 loss)
I0403 04:29:18.789623 28785 solver.cpp:228] Iteration 7808, loss = 0.000432318
I0403 04:29:18.789718 28785 solver.cpp:244]     Train net output #0: loss = 0.000432438 (* 1 = 0.000432438 loss)
I0403 04:29:18.939749 28785 sgd_solver.cpp:106] Iteration 7808, lr = 5e-05
I0403 04:29:30.632284 28785 solver.cpp:228] Iteration 7824, loss = 0.0163541
I0403 04:29:30.632400 28785 solver.cpp:244]     Train net output #0: loss = 0.0163542 (* 1 = 0.0163542 loss)
I0403 04:29:30.844694 28785 sgd_solver.cpp:106] Iteration 7824, lr = 5e-05
I0403 04:29:42.455905 28785 solver.cpp:228] Iteration 7840, loss = 0.00365504
I0403 04:29:42.456253 28785 solver.cpp:244]     Train net output #0: loss = 0.00365516 (* 1 = 0.00365516 loss)
I0403 04:29:42.638908 28785 sgd_solver.cpp:106] Iteration 7840, lr = 5e-05
I0403 04:29:54.395540 28785 solver.cpp:228] Iteration 7856, loss = 0.0111958
I0403 04:29:54.395644 28785 solver.cpp:244]     Train net output #0: loss = 0.0111959 (* 1 = 0.0111959 loss)
I0403 04:29:54.560900 28785 sgd_solver.cpp:106] Iteration 7856, lr = 5e-05
I0403 04:30:06.172262 28785 solver.cpp:228] Iteration 7872, loss = 0.00279015
I0403 04:30:06.172377 28785 solver.cpp:244]     Train net output #0: loss = 0.00279027 (* 1 = 0.00279027 loss)
I0403 04:30:06.361168 28785 sgd_solver.cpp:106] Iteration 7872, lr = 5e-05
I0403 04:30:17.844054 28785 solver.cpp:228] Iteration 7888, loss = 0.0143989
I0403 04:30:17.844378 28785 solver.cpp:244]     Train net output #0: loss = 0.014399 (* 1 = 0.014399 loss)
I0403 04:30:18.030553 28785 sgd_solver.cpp:106] Iteration 7888, lr = 5e-05
I0403 04:30:29.625634 28785 solver.cpp:228] Iteration 7904, loss = 0.00471302
I0403 04:30:29.625740 28785 solver.cpp:244]     Train net output #0: loss = 0.00471314 (* 1 = 0.00471314 loss)
I0403 04:30:29.804951 28785 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 04:30:41.519371 28785 solver.cpp:228] Iteration 7920, loss = 0.00657627
I0403 04:30:41.519475 28785 solver.cpp:244]     Train net output #0: loss = 0.00657639 (* 1 = 0.00657639 loss)
I0403 04:30:41.669478 28785 sgd_solver.cpp:106] Iteration 7920, lr = 5e-05
I0403 04:30:53.282795 28785 solver.cpp:228] Iteration 7936, loss = 0.00577153
I0403 04:30:53.283113 28785 solver.cpp:244]     Train net output #0: loss = 0.00577165 (* 1 = 0.00577165 loss)
I0403 04:30:53.474009 28785 sgd_solver.cpp:106] Iteration 7936, lr = 5e-05
I0403 04:31:04.950646 28785 solver.cpp:228] Iteration 7952, loss = 0.0120949
I0403 04:31:04.950763 28785 solver.cpp:244]     Train net output #0: loss = 0.012095 (* 1 = 0.012095 loss)
I0403 04:31:05.127526 28785 sgd_solver.cpp:106] Iteration 7952, lr = 5e-05
I0403 04:31:16.607830 28785 solver.cpp:228] Iteration 7968, loss = 0.000671702
I0403 04:31:16.607944 28785 solver.cpp:244]     Train net output #0: loss = 0.000671827 (* 1 = 0.000671827 loss)
I0403 04:31:16.799203 28785 sgd_solver.cpp:106] Iteration 7968, lr = 5e-05
I0403 04:31:28.371395 28785 solver.cpp:228] Iteration 7984, loss = 0.00264102
I0403 04:31:28.371711 28785 solver.cpp:244]     Train net output #0: loss = 0.00264115 (* 1 = 0.00264115 loss)
I0403 04:31:28.593658 28785 sgd_solver.cpp:106] Iteration 7984, lr = 5e-05
I0403 04:31:40.049342 28785 solver.cpp:228] Iteration 8000, loss = 0.00232048
I0403 04:31:40.049424 28785 solver.cpp:244]     Train net output #0: loss = 0.00232061 (* 1 = 0.00232061 loss)
I0403 04:31:40.230448 28785 sgd_solver.cpp:106] Iteration 8000, lr = 5e-05
I0403 04:31:51.723616 28785 solver.cpp:228] Iteration 8016, loss = 0.0109953
I0403 04:31:51.723716 28785 solver.cpp:244]     Train net output #0: loss = 0.0109954 (* 1 = 0.0109954 loss)
I0403 04:31:51.899794 28785 sgd_solver.cpp:106] Iteration 8016, lr = 5e-05
I0403 04:32:03.606627 28785 solver.cpp:228] Iteration 8032, loss = 0.00214476
I0403 04:32:03.606930 28785 solver.cpp:244]     Train net output #0: loss = 0.00214489 (* 1 = 0.00214489 loss)
I0403 04:32:03.786453 28785 sgd_solver.cpp:106] Iteration 8032, lr = 5e-05
I0403 04:32:15.275645 28785 solver.cpp:228] Iteration 8048, loss = 0.0162078
I0403 04:32:15.275743 28785 solver.cpp:244]     Train net output #0: loss = 0.0162079 (* 1 = 0.0162079 loss)
I0403 04:32:15.454816 28785 sgd_solver.cpp:106] Iteration 8048, lr = 5e-05
I0403 04:32:26.835417 28785 solver.cpp:228] Iteration 8064, loss = 0.00662454
I0403 04:32:26.835533 28785 solver.cpp:244]     Train net output #0: loss = 0.00662467 (* 1 = 0.00662467 loss)
I0403 04:32:27.021235 28785 sgd_solver.cpp:106] Iteration 8064, lr = 5e-05
I0403 04:32:38.734015 28785 solver.cpp:228] Iteration 8080, loss = 0.00167519
I0403 04:32:38.734302 28785 solver.cpp:244]     Train net output #0: loss = 0.00167533 (* 1 = 0.00167533 loss)
I0403 04:32:38.881604 28785 sgd_solver.cpp:106] Iteration 8080, lr = 5e-05
I0403 04:32:50.550312 28785 solver.cpp:228] Iteration 8096, loss = 0.00123663
I0403 04:32:50.550425 28785 solver.cpp:244]     Train net output #0: loss = 0.00123676 (* 1 = 0.00123676 loss)
I0403 04:32:50.784379 28785 sgd_solver.cpp:106] Iteration 8096, lr = 5e-05
I0403 04:33:02.365137 28785 solver.cpp:228] Iteration 8112, loss = 0.00192417
I0403 04:33:02.365241 28785 solver.cpp:244]     Train net output #0: loss = 0.0019243 (* 1 = 0.0019243 loss)
I0403 04:33:02.544271 28785 sgd_solver.cpp:106] Iteration 8112, lr = 5e-05
I0403 04:33:11.522838 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_8125.caffemodel
I0403 04:33:14.278141 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_8125.solverstate
I0403 04:33:16.164738 28785 solver.cpp:337] Iteration 8125, Testing net (#0)
I0403 04:34:05.731480 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968526
I0403 04:34:05.731801 28785 solver.cpp:404]     Test net output #1: loss = 0.120158 (* 1 = 0.120158 loss)
I0403 04:34:08.574373 28785 solver.cpp:228] Iteration 8128, loss = 9.25573e-05
I0403 04:34:08.574472 28785 solver.cpp:244]     Train net output #0: loss = 9.26916e-05 (* 1 = 9.26916e-05 loss)
I0403 04:34:08.739891 28785 sgd_solver.cpp:106] Iteration 8128, lr = 5e-05
I0403 04:34:20.396100 28785 solver.cpp:228] Iteration 8144, loss = 0.00282602
I0403 04:34:20.396209 28785 solver.cpp:244]     Train net output #0: loss = 0.00282616 (* 1 = 0.00282616 loss)
I0403 04:34:20.586652 28785 sgd_solver.cpp:106] Iteration 8144, lr = 5e-05
I0403 04:34:32.136101 28785 solver.cpp:228] Iteration 8160, loss = 0.00263924
I0403 04:34:32.136203 28785 solver.cpp:244]     Train net output #0: loss = 0.00263938 (* 1 = 0.00263938 loss)
I0403 04:34:32.314484 28785 sgd_solver.cpp:106] Iteration 8160, lr = 5e-05
I0403 04:34:43.871981 28785 solver.cpp:228] Iteration 8176, loss = 0.0116956
I0403 04:34:43.872283 28785 solver.cpp:244]     Train net output #0: loss = 0.0116957 (* 1 = 0.0116957 loss)
I0403 04:34:44.041913 28785 sgd_solver.cpp:106] Iteration 8176, lr = 5e-05
I0403 04:34:55.659162 28785 solver.cpp:228] Iteration 8192, loss = 0.000419388
I0403 04:34:55.659282 28785 solver.cpp:244]     Train net output #0: loss = 0.000419523 (* 1 = 0.000419523 loss)
I0403 04:34:55.848853 28785 sgd_solver.cpp:106] Iteration 8192, lr = 5e-05
I0403 04:35:07.561465 28785 solver.cpp:228] Iteration 8208, loss = 0.00221689
I0403 04:35:07.561589 28785 solver.cpp:244]     Train net output #0: loss = 0.00221702 (* 1 = 0.00221702 loss)
I0403 04:35:07.745079 28785 sgd_solver.cpp:106] Iteration 8208, lr = 5e-05
I0403 04:35:19.272600 28785 solver.cpp:228] Iteration 8224, loss = 0.00896128
I0403 04:35:19.272851 28785 solver.cpp:244]     Train net output #0: loss = 0.00896141 (* 1 = 0.00896141 loss)
I0403 04:35:19.432974 28785 sgd_solver.cpp:106] Iteration 8224, lr = 5e-05
I0403 04:35:31.124182 28785 solver.cpp:228] Iteration 8240, loss = 0.0355929
I0403 04:35:31.124294 28785 solver.cpp:244]     Train net output #0: loss = 0.035593 (* 1 = 0.035593 loss)
I0403 04:35:31.294829 28785 sgd_solver.cpp:106] Iteration 8240, lr = 5e-05
I0403 04:35:42.797322 28785 solver.cpp:228] Iteration 8256, loss = 0.00160091
I0403 04:35:42.797435 28785 solver.cpp:244]     Train net output #0: loss = 0.00160104 (* 1 = 0.00160104 loss)
I0403 04:35:42.987985 28785 sgd_solver.cpp:106] Iteration 8256, lr = 5e-05
I0403 04:35:54.595960 28785 solver.cpp:228] Iteration 8272, loss = 0.00313561
I0403 04:35:54.596261 28785 solver.cpp:244]     Train net output #0: loss = 0.00313574 (* 1 = 0.00313574 loss)
I0403 04:35:54.767251 28785 sgd_solver.cpp:106] Iteration 8272, lr = 5e-05
I0403 04:36:06.523871 28785 solver.cpp:228] Iteration 8288, loss = 0.00178413
I0403 04:36:06.523974 28785 solver.cpp:244]     Train net output #0: loss = 0.00178427 (* 1 = 0.00178427 loss)
I0403 04:36:06.701421 28785 sgd_solver.cpp:106] Iteration 8288, lr = 5e-05
I0403 04:36:18.416733 28785 solver.cpp:228] Iteration 8304, loss = 0.00299615
I0403 04:36:18.416844 28785 solver.cpp:244]     Train net output #0: loss = 0.00299628 (* 1 = 0.00299628 loss)
I0403 04:36:18.614981 28785 sgd_solver.cpp:106] Iteration 8304, lr = 5e-05
I0403 04:36:30.164898 28785 solver.cpp:228] Iteration 8320, loss = 0.000580381
I0403 04:36:30.165227 28785 solver.cpp:244]     Train net output #0: loss = 0.000580514 (* 1 = 0.000580514 loss)
I0403 04:36:30.339468 28785 sgd_solver.cpp:106] Iteration 8320, lr = 5e-05
I0403 04:36:42.009616 28785 solver.cpp:228] Iteration 8336, loss = 0.0236456
I0403 04:36:42.009716 28785 solver.cpp:244]     Train net output #0: loss = 0.0236458 (* 1 = 0.0236458 loss)
I0403 04:36:42.183271 28785 sgd_solver.cpp:106] Iteration 8336, lr = 5e-05
I0403 04:36:53.782444 28785 solver.cpp:228] Iteration 8352, loss = 0.003237
I0403 04:36:53.782551 28785 solver.cpp:244]     Train net output #0: loss = 0.00323713 (* 1 = 0.00323713 loss)
I0403 04:36:53.961540 28785 sgd_solver.cpp:106] Iteration 8352, lr = 5e-05
I0403 04:37:05.422873 28785 solver.cpp:228] Iteration 8368, loss = 0.0023713
I0403 04:37:05.423180 28785 solver.cpp:244]     Train net output #0: loss = 0.00237143 (* 1 = 0.00237143 loss)
I0403 04:37:05.600188 28785 sgd_solver.cpp:106] Iteration 8368, lr = 5e-05
I0403 04:37:17.215680 28785 solver.cpp:228] Iteration 8384, loss = 0.00971938
I0403 04:37:17.215791 28785 solver.cpp:244]     Train net output #0: loss = 0.00971951 (* 1 = 0.00971951 loss)
I0403 04:37:17.408237 28785 sgd_solver.cpp:106] Iteration 8384, lr = 5e-05
I0403 04:37:28.848758 28785 solver.cpp:228] Iteration 8400, loss = 0.00794425
I0403 04:37:28.848860 28785 solver.cpp:244]     Train net output #0: loss = 0.00794439 (* 1 = 0.00794439 loss)
I0403 04:37:29.029708 28785 sgd_solver.cpp:106] Iteration 8400, lr = 5e-05
I0403 04:37:40.581641 28785 solver.cpp:228] Iteration 8416, loss = 0.00156066
I0403 04:37:40.581953 28785 solver.cpp:244]     Train net output #0: loss = 0.0015608 (* 1 = 0.0015608 loss)
I0403 04:37:40.750915 28785 sgd_solver.cpp:106] Iteration 8416, lr = 5e-05
I0403 04:37:52.342735 28785 solver.cpp:228] Iteration 8432, loss = 0.00167245
I0403 04:37:52.342836 28785 solver.cpp:244]     Train net output #0: loss = 0.00167258 (* 1 = 0.00167258 loss)
I0403 04:37:52.521937 28785 sgd_solver.cpp:106] Iteration 8432, lr = 5e-05
I0403 04:38:04.196164 28785 solver.cpp:228] Iteration 8448, loss = 0.00256662
I0403 04:38:04.196279 28785 solver.cpp:244]     Train net output #0: loss = 0.00256675 (* 1 = 0.00256675 loss)
I0403 04:38:04.364629 28785 sgd_solver.cpp:106] Iteration 8448, lr = 5e-05
I0403 04:38:05.133025 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_8450.caffemodel
I0403 04:38:07.866397 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_8450.solverstate
I0403 04:38:09.770988 28785 solver.cpp:337] Iteration 8450, Testing net (#0)
I0403 04:38:59.326298 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968572
I0403 04:38:59.326601 28785 solver.cpp:404]     Test net output #1: loss = 0.120168 (* 1 = 0.120168 loss)
I0403 04:39:10.092211 28785 solver.cpp:228] Iteration 8464, loss = 0.000655641
I0403 04:39:10.092319 28785 solver.cpp:244]     Train net output #0: loss = 0.000655777 (* 1 = 0.000655777 loss)
I0403 04:39:10.270403 28785 sgd_solver.cpp:106] Iteration 8464, lr = 5e-05
I0403 04:39:21.847362 28785 solver.cpp:228] Iteration 8480, loss = 0.00693473
I0403 04:39:21.847458 28785 solver.cpp:244]     Train net output #0: loss = 0.00693487 (* 1 = 0.00693487 loss)
I0403 04:39:22.014772 28785 sgd_solver.cpp:106] Iteration 8480, lr = 5e-05
I0403 04:39:33.582195 28785 solver.cpp:228] Iteration 8496, loss = 0.00397166
I0403 04:39:33.582485 28785 solver.cpp:244]     Train net output #0: loss = 0.00397179 (* 1 = 0.00397179 loss)
I0403 04:39:33.787825 28785 sgd_solver.cpp:106] Iteration 8496, lr = 5e-05
I0403 04:39:45.292913 28785 solver.cpp:228] Iteration 8512, loss = 0.00216276
I0403 04:39:45.293006 28785 solver.cpp:244]     Train net output #0: loss = 0.00216289 (* 1 = 0.00216289 loss)
I0403 04:39:45.514610 28785 sgd_solver.cpp:106] Iteration 8512, lr = 5e-05
I0403 04:39:57.127038 28785 solver.cpp:228] Iteration 8528, loss = 0.000691709
I0403 04:39:57.127149 28785 solver.cpp:244]     Train net output #0: loss = 0.000691844 (* 1 = 0.000691844 loss)
I0403 04:39:57.320334 28785 sgd_solver.cpp:106] Iteration 8528, lr = 5e-05
I0403 04:40:08.926259 28785 solver.cpp:228] Iteration 8544, loss = 0.00182563
I0403 04:40:08.926595 28785 solver.cpp:244]     Train net output #0: loss = 0.00182576 (* 1 = 0.00182576 loss)
I0403 04:40:09.104573 28785 sgd_solver.cpp:106] Iteration 8544, lr = 5e-05
I0403 04:40:20.573276 28785 solver.cpp:228] Iteration 8560, loss = 0.0245012
I0403 04:40:20.573388 28785 solver.cpp:244]     Train net output #0: loss = 0.0245013 (* 1 = 0.0245013 loss)
I0403 04:40:20.764835 28785 sgd_solver.cpp:106] Iteration 8560, lr = 5e-05
I0403 04:40:32.165583 28785 solver.cpp:228] Iteration 8576, loss = 0.0030182
I0403 04:40:32.165696 28785 solver.cpp:244]     Train net output #0: loss = 0.00301833 (* 1 = 0.00301833 loss)
I0403 04:40:32.367980 28785 sgd_solver.cpp:106] Iteration 8576, lr = 5e-05
I0403 04:40:43.813875 28785 solver.cpp:228] Iteration 8592, loss = 0.00322385
I0403 04:40:43.814203 28785 solver.cpp:244]     Train net output #0: loss = 0.00322398 (* 1 = 0.00322398 loss)
I0403 04:40:44.034508 28785 sgd_solver.cpp:106] Iteration 8592, lr = 5e-05
I0403 04:40:55.708463 28785 solver.cpp:228] Iteration 8608, loss = 0.00488189
I0403 04:40:55.708575 28785 solver.cpp:244]     Train net output #0: loss = 0.00488203 (* 1 = 0.00488203 loss)
I0403 04:40:55.862264 28785 sgd_solver.cpp:106] Iteration 8608, lr = 5e-05
I0403 04:41:07.536839 28785 solver.cpp:228] Iteration 8624, loss = 0.00189668
I0403 04:41:07.536943 28785 solver.cpp:244]     Train net output #0: loss = 0.00189682 (* 1 = 0.00189682 loss)
I0403 04:41:07.700333 28785 sgd_solver.cpp:106] Iteration 8624, lr = 5e-05
I0403 04:41:19.303510 28785 solver.cpp:228] Iteration 8640, loss = 0.0237919
I0403 04:41:19.303918 28785 solver.cpp:244]     Train net output #0: loss = 0.023792 (* 1 = 0.023792 loss)
I0403 04:41:19.508848 28785 sgd_solver.cpp:106] Iteration 8640, lr = 5e-05
I0403 04:41:31.102135 28785 solver.cpp:228] Iteration 8656, loss = 0.00332085
I0403 04:41:31.102238 28785 solver.cpp:244]     Train net output #0: loss = 0.00332099 (* 1 = 0.00332099 loss)
I0403 04:41:31.282024 28785 sgd_solver.cpp:106] Iteration 8656, lr = 5e-05
I0403 04:41:42.836992 28785 solver.cpp:228] Iteration 8672, loss = 0.00553354
I0403 04:41:42.837106 28785 solver.cpp:244]     Train net output #0: loss = 0.00553367 (* 1 = 0.00553367 loss)
I0403 04:41:43.035975 28785 sgd_solver.cpp:106] Iteration 8672, lr = 5e-05
I0403 04:41:54.643095 28785 solver.cpp:228] Iteration 8688, loss = 0.00276754
I0403 04:41:54.643363 28785 solver.cpp:244]     Train net output #0: loss = 0.00276767 (* 1 = 0.00276767 loss)
I0403 04:41:54.834686 28785 sgd_solver.cpp:106] Iteration 8688, lr = 5e-05
I0403 04:42:06.422284 28785 solver.cpp:228] Iteration 8704, loss = 0.00824163
I0403 04:42:06.422401 28785 solver.cpp:244]     Train net output #0: loss = 0.00824175 (* 1 = 0.00824175 loss)
I0403 04:42:06.621364 28785 sgd_solver.cpp:106] Iteration 8704, lr = 5e-05
I0403 04:42:18.167932 28785 solver.cpp:228] Iteration 8720, loss = 0.00544682
I0403 04:42:18.168045 28785 solver.cpp:244]     Train net output #0: loss = 0.00544695 (* 1 = 0.00544695 loss)
I0403 04:42:18.362179 28785 sgd_solver.cpp:106] Iteration 8720, lr = 5e-05
I0403 04:42:29.914883 28785 solver.cpp:228] Iteration 8736, loss = 0.00427846
I0403 04:42:29.915182 28785 solver.cpp:244]     Train net output #0: loss = 0.00427859 (* 1 = 0.00427859 loss)
I0403 04:42:30.091464 28785 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 04:42:41.422780 28785 solver.cpp:228] Iteration 8752, loss = 0.00149455
I0403 04:42:41.422883 28785 solver.cpp:244]     Train net output #0: loss = 0.00149467 (* 1 = 0.00149467 loss)
I0403 04:42:41.601250 28785 sgd_solver.cpp:106] Iteration 8752, lr = 5e-05
I0403 04:42:53.190119 28785 solver.cpp:228] Iteration 8768, loss = 0.000769508
I0403 04:42:53.190230 28785 solver.cpp:244]     Train net output #0: loss = 0.000769629 (* 1 = 0.000769629 loss)
I0403 04:42:53.386369 28785 sgd_solver.cpp:106] Iteration 8768, lr = 5e-05
I0403 04:42:57.785480 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_8775.caffemodel
I0403 04:43:00.522981 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_8775.solverstate
I0403 04:43:02.410559 28785 solver.cpp:337] Iteration 8775, Testing net (#0)
I0403 04:43:51.982656 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968941
I0403 04:43:51.982971 28785 solver.cpp:404]     Test net output #1: loss = 0.120085 (* 1 = 0.120085 loss)
I0403 04:43:59.048611 28785 solver.cpp:228] Iteration 8784, loss = 0.00560672
I0403 04:43:59.048722 28785 solver.cpp:244]     Train net output #0: loss = 0.00560684 (* 1 = 0.00560684 loss)
I0403 04:43:59.231839 28785 sgd_solver.cpp:106] Iteration 8784, lr = 5e-05
I0403 04:44:10.854099 28785 solver.cpp:228] Iteration 8800, loss = 0.00467967
I0403 04:44:10.854213 28785 solver.cpp:244]     Train net output #0: loss = 0.00467979 (* 1 = 0.00467979 loss)
I0403 04:44:11.037367 28785 sgd_solver.cpp:106] Iteration 8800, lr = 5e-05
I0403 04:44:22.557474 28785 solver.cpp:228] Iteration 8816, loss = 0.00220352
I0403 04:44:22.557786 28785 solver.cpp:244]     Train net output #0: loss = 0.00220364 (* 1 = 0.00220364 loss)
I0403 04:44:22.726799 28785 sgd_solver.cpp:106] Iteration 8816, lr = 5e-05
I0403 04:44:34.243437 28785 solver.cpp:228] Iteration 8832, loss = 0.00334058
I0403 04:44:34.243569 28785 solver.cpp:244]     Train net output #0: loss = 0.00334069 (* 1 = 0.00334069 loss)
I0403 04:44:34.471680 28785 sgd_solver.cpp:106] Iteration 8832, lr = 5e-05
I0403 04:44:46.131974 28785 solver.cpp:228] Iteration 8848, loss = 0.00122824
I0403 04:44:46.132086 28785 solver.cpp:244]     Train net output #0: loss = 0.00122836 (* 1 = 0.00122836 loss)
I0403 04:44:46.324826 28785 sgd_solver.cpp:106] Iteration 8848, lr = 5e-05
I0403 04:44:58.023630 28785 solver.cpp:228] Iteration 8864, loss = 0.00210316
I0403 04:44:58.023937 28785 solver.cpp:244]     Train net output #0: loss = 0.00210328 (* 1 = 0.00210328 loss)
I0403 04:44:58.202448 28785 sgd_solver.cpp:106] Iteration 8864, lr = 5e-05
I0403 04:45:09.950832 28785 solver.cpp:228] Iteration 8880, loss = 0.000432577
I0403 04:45:09.950947 28785 solver.cpp:244]     Train net output #0: loss = 0.000432696 (* 1 = 0.000432696 loss)
I0403 04:45:10.134305 28785 sgd_solver.cpp:106] Iteration 8880, lr = 5e-05
I0403 04:45:21.673610 28785 solver.cpp:228] Iteration 8896, loss = 0.00217101
I0403 04:45:21.673724 28785 solver.cpp:244]     Train net output #0: loss = 0.00217112 (* 1 = 0.00217112 loss)
I0403 04:45:21.860880 28785 sgd_solver.cpp:106] Iteration 8896, lr = 5e-05
I0403 04:45:33.332130 28785 solver.cpp:228] Iteration 8912, loss = 0.00090766
I0403 04:45:33.332435 28785 solver.cpp:244]     Train net output #0: loss = 0.000907772 (* 1 = 0.000907772 loss)
I0403 04:45:33.503487 28785 sgd_solver.cpp:106] Iteration 8912, lr = 5e-05
I0403 04:45:45.253923 28785 solver.cpp:228] Iteration 8928, loss = 0.00103623
I0403 04:45:45.254024 28785 solver.cpp:244]     Train net output #0: loss = 0.00103634 (* 1 = 0.00103634 loss)
I0403 04:45:45.415714 28785 sgd_solver.cpp:106] Iteration 8928, lr = 5e-05
I0403 04:45:57.108489 28785 solver.cpp:228] Iteration 8944, loss = 0.00149934
I0403 04:45:57.108595 28785 solver.cpp:244]     Train net output #0: loss = 0.00149945 (* 1 = 0.00149945 loss)
I0403 04:45:57.274544 28785 sgd_solver.cpp:106] Iteration 8944, lr = 5e-05
I0403 04:46:08.738065 28785 solver.cpp:228] Iteration 8960, loss = 0.0141577
I0403 04:46:08.738387 28785 solver.cpp:244]     Train net output #0: loss = 0.0141578 (* 1 = 0.0141578 loss)
I0403 04:46:08.914695 28785 sgd_solver.cpp:106] Iteration 8960, lr = 5e-05
I0403 04:46:20.855631 28785 solver.cpp:228] Iteration 8976, loss = 0.000282161
I0403 04:46:20.855749 28785 solver.cpp:244]     Train net output #0: loss = 0.000282271 (* 1 = 0.000282271 loss)
I0403 04:46:21.039160 28785 sgd_solver.cpp:106] Iteration 8976, lr = 5e-05
I0403 04:46:32.424687 28785 solver.cpp:228] Iteration 8992, loss = 0.00398663
I0403 04:46:32.424792 28785 solver.cpp:244]     Train net output #0: loss = 0.00398674 (* 1 = 0.00398674 loss)
I0403 04:46:32.586849 28785 sgd_solver.cpp:106] Iteration 8992, lr = 5e-05
I0403 04:46:44.614264 28785 solver.cpp:228] Iteration 9008, loss = 0.0104686
I0403 04:46:44.614603 28785 solver.cpp:244]     Train net output #0: loss = 0.0104688 (* 1 = 0.0104688 loss)
I0403 04:46:44.824955 28785 sgd_solver.cpp:106] Iteration 9008, lr = 5e-05
I0403 04:46:56.454318 28785 solver.cpp:228] Iteration 9024, loss = 0.00153847
I0403 04:46:56.454433 28785 solver.cpp:244]     Train net output #0: loss = 0.00153858 (* 1 = 0.00153858 loss)
I0403 04:46:56.654955 28785 sgd_solver.cpp:106] Iteration 9024, lr = 5e-05
I0403 04:47:08.253003 28785 solver.cpp:228] Iteration 9040, loss = 0.00205076
I0403 04:47:08.253109 28785 solver.cpp:244]     Train net output #0: loss = 0.00205087 (* 1 = 0.00205087 loss)
I0403 04:47:08.415555 28785 sgd_solver.cpp:106] Iteration 9040, lr = 5e-05
I0403 04:47:19.919116 28785 solver.cpp:228] Iteration 9056, loss = 0.00319799
I0403 04:47:19.919409 28785 solver.cpp:244]     Train net output #0: loss = 0.0031981 (* 1 = 0.0031981 loss)
I0403 04:47:20.095479 28785 sgd_solver.cpp:106] Iteration 9056, lr = 5e-05
I0403 04:47:31.829319 28785 solver.cpp:228] Iteration 9072, loss = 0.0124161
I0403 04:47:31.829421 28785 solver.cpp:244]     Train net output #0: loss = 0.0124162 (* 1 = 0.0124162 loss)
I0403 04:47:31.926559 28785 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 04:47:43.493881 28785 solver.cpp:228] Iteration 9088, loss = 0.0074273
I0403 04:47:43.493998 28785 solver.cpp:244]     Train net output #0: loss = 0.0074274 (* 1 = 0.0074274 loss)
I0403 04:47:43.708312 28785 sgd_solver.cpp:106] Iteration 9088, lr = 5e-05
I0403 04:47:51.818328 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9100.caffemodel
I0403 04:47:54.475214 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9100.solverstate
I0403 04:47:56.248584 28785 solver.cpp:337] Iteration 9100, Testing net (#0)
I0403 04:48:45.813279 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968848
I0403 04:48:45.813591 28785 solver.cpp:404]     Test net output #1: loss = 0.120845 (* 1 = 0.120845 loss)
I0403 04:48:49.325901 28785 solver.cpp:228] Iteration 9104, loss = 0.000672146
I0403 04:48:49.326007 28785 solver.cpp:244]     Train net output #0: loss = 0.000672255 (* 1 = 0.000672255 loss)
I0403 04:48:49.511564 28785 sgd_solver.cpp:106] Iteration 9104, lr = 5e-05
I0403 04:49:01.001858 28785 solver.cpp:228] Iteration 9120, loss = 0.00126224
I0403 04:49:01.001957 28785 solver.cpp:244]     Train net output #0: loss = 0.00126235 (* 1 = 0.00126235 loss)
I0403 04:49:01.165021 28785 sgd_solver.cpp:106] Iteration 9120, lr = 5e-05
I0403 04:49:12.671749 28785 solver.cpp:228] Iteration 9136, loss = 0.0446497
I0403 04:49:12.671866 28785 solver.cpp:244]     Train net output #0: loss = 0.0446498 (* 1 = 0.0446498 loss)
I0403 04:49:12.880445 28785 sgd_solver.cpp:106] Iteration 9136, lr = 5e-05
I0403 04:49:24.368453 28785 solver.cpp:228] Iteration 9152, loss = 0.00291421
I0403 04:49:24.368708 28785 solver.cpp:244]     Train net output #0: loss = 0.00291432 (* 1 = 0.00291432 loss)
I0403 04:49:24.547843 28785 sgd_solver.cpp:106] Iteration 9152, lr = 5e-05
I0403 04:49:36.145663 28785 solver.cpp:228] Iteration 9168, loss = 0.00175131
I0403 04:49:36.145777 28785 solver.cpp:244]     Train net output #0: loss = 0.00175142 (* 1 = 0.00175142 loss)
I0403 04:49:36.369165 28785 sgd_solver.cpp:106] Iteration 9168, lr = 5e-05
I0403 04:49:48.025936 28785 solver.cpp:228] Iteration 9184, loss = 0.000389921
I0403 04:49:48.026052 28785 solver.cpp:244]     Train net output #0: loss = 0.000390031 (* 1 = 0.000390031 loss)
I0403 04:49:48.213640 28785 sgd_solver.cpp:106] Iteration 9184, lr = 5e-05
I0403 04:49:59.872931 28785 solver.cpp:228] Iteration 9200, loss = 0.00621527
I0403 04:49:59.874017 28785 solver.cpp:244]     Train net output #0: loss = 0.00621538 (* 1 = 0.00621538 loss)
I0403 04:50:00.044400 28785 sgd_solver.cpp:106] Iteration 9200, lr = 5e-05
I0403 04:50:11.652886 28785 solver.cpp:228] Iteration 9216, loss = 0.00389366
I0403 04:50:11.652992 28785 solver.cpp:244]     Train net output #0: loss = 0.00389377 (* 1 = 0.00389377 loss)
I0403 04:50:11.827483 28785 sgd_solver.cpp:106] Iteration 9216, lr = 5e-05
I0403 04:50:23.299299 28785 solver.cpp:228] Iteration 9232, loss = 0.0126328
I0403 04:50:23.299401 28785 solver.cpp:244]     Train net output #0: loss = 0.0126329 (* 1 = 0.0126329 loss)
I0403 04:50:23.465499 28785 sgd_solver.cpp:106] Iteration 9232, lr = 5e-05
I0403 04:50:35.063187 28785 solver.cpp:228] Iteration 9248, loss = 0.0380789
I0403 04:50:35.063499 28785 solver.cpp:244]     Train net output #0: loss = 0.038079 (* 1 = 0.038079 loss)
I0403 04:50:35.214265 28785 sgd_solver.cpp:106] Iteration 9248, lr = 5e-05
I0403 04:50:46.734338 28785 solver.cpp:228] Iteration 9264, loss = 0.0178805
I0403 04:50:46.734452 28785 solver.cpp:244]     Train net output #0: loss = 0.0178806 (* 1 = 0.0178806 loss)
I0403 04:50:46.944583 28785 sgd_solver.cpp:106] Iteration 9264, lr = 5e-05
I0403 04:50:58.365463 28785 solver.cpp:228] Iteration 9280, loss = 0.00271412
I0403 04:50:58.365574 28785 solver.cpp:244]     Train net output #0: loss = 0.00271423 (* 1 = 0.00271423 loss)
I0403 04:50:58.560986 28785 sgd_solver.cpp:106] Iteration 9280, lr = 5e-05
I0403 04:51:10.091771 28785 solver.cpp:228] Iteration 9296, loss = 0.0214786
I0403 04:51:10.092067 28785 solver.cpp:244]     Train net output #0: loss = 0.0214787 (* 1 = 0.0214787 loss)
I0403 04:51:10.250818 28785 sgd_solver.cpp:106] Iteration 9296, lr = 5e-05
I0403 04:51:21.793860 28785 solver.cpp:228] Iteration 9312, loss = 0.00092525
I0403 04:51:21.793958 28785 solver.cpp:244]     Train net output #0: loss = 0.00092536 (* 1 = 0.00092536 loss)
I0403 04:51:21.968664 28785 sgd_solver.cpp:106] Iteration 9312, lr = 5e-05
I0403 04:51:33.577397 28785 solver.cpp:228] Iteration 9328, loss = 0.00570358
I0403 04:51:33.577530 28785 solver.cpp:244]     Train net output #0: loss = 0.00570369 (* 1 = 0.00570369 loss)
I0403 04:51:33.764246 28785 sgd_solver.cpp:106] Iteration 9328, lr = 5e-05
I0403 04:51:45.255151 28785 solver.cpp:228] Iteration 9344, loss = 0.0091296
I0403 04:51:45.255463 28785 solver.cpp:244]     Train net output #0: loss = 0.00912972 (* 1 = 0.00912972 loss)
I0403 04:51:45.418094 28785 sgd_solver.cpp:106] Iteration 9344, lr = 5e-05
I0403 04:51:57.249656 28785 solver.cpp:228] Iteration 9360, loss = 0.00599469
I0403 04:51:57.249770 28785 solver.cpp:244]     Train net output #0: loss = 0.0059948 (* 1 = 0.0059948 loss)
I0403 04:51:57.458004 28785 sgd_solver.cpp:106] Iteration 9360, lr = 5e-05
I0403 04:52:09.027950 28785 solver.cpp:228] Iteration 9376, loss = 0.00182876
I0403 04:52:09.028054 28785 solver.cpp:244]     Train net output #0: loss = 0.00182887 (* 1 = 0.00182887 loss)
I0403 04:52:09.206661 28785 sgd_solver.cpp:106] Iteration 9376, lr = 5e-05
I0403 04:52:20.814548 28785 solver.cpp:228] Iteration 9392, loss = 0.00226294
I0403 04:52:20.814826 28785 solver.cpp:244]     Train net output #0: loss = 0.00226305 (* 1 = 0.00226305 loss)
I0403 04:52:20.965832 28785 sgd_solver.cpp:106] Iteration 9392, lr = 5e-05
I0403 04:52:32.586335 28785 solver.cpp:228] Iteration 9408, loss = 0.00239639
I0403 04:52:32.586437 28785 solver.cpp:244]     Train net output #0: loss = 0.0023965 (* 1 = 0.0023965 loss)
I0403 04:52:32.739087 28785 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 04:52:44.444692 28785 solver.cpp:228] Iteration 9424, loss = 0.00736825
I0403 04:52:44.444795 28785 solver.cpp:244]     Train net output #0: loss = 0.00736836 (* 1 = 0.00736836 loss)
I0403 04:52:44.614758 28785 sgd_solver.cpp:106] Iteration 9424, lr = 5e-05
I0403 04:52:44.614991 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9425.caffemodel
I0403 04:52:47.469854 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9425.solverstate
I0403 04:52:49.340646 28785 solver.cpp:337] Iteration 9425, Testing net (#0)
I0403 04:53:38.901103 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968802
I0403 04:53:38.901491 28785 solver.cpp:404]     Test net output #1: loss = 0.120719 (* 1 = 0.120719 loss)
I0403 04:53:50.558570 28785 solver.cpp:228] Iteration 9440, loss = 0.00876379
I0403 04:53:50.558671 28785 solver.cpp:244]     Train net output #0: loss = 0.0087639 (* 1 = 0.0087639 loss)
I0403 04:53:50.682878 28785 sgd_solver.cpp:106] Iteration 9440, lr = 5e-05
I0403 04:54:02.176645 28785 solver.cpp:228] Iteration 9456, loss = 0.0134313
I0403 04:54:02.176756 28785 solver.cpp:244]     Train net output #0: loss = 0.0134314 (* 1 = 0.0134314 loss)
I0403 04:54:02.367414 28785 sgd_solver.cpp:106] Iteration 9456, lr = 5e-05
I0403 04:54:13.928835 28785 solver.cpp:228] Iteration 9472, loss = 0.00233728
I0403 04:54:13.929160 28785 solver.cpp:244]     Train net output #0: loss = 0.0023374 (* 1 = 0.0023374 loss)
I0403 04:54:14.125645 28785 sgd_solver.cpp:106] Iteration 9472, lr = 5e-05
I0403 04:54:25.617804 28785 solver.cpp:228] Iteration 9488, loss = 0.00875444
I0403 04:54:25.617918 28785 solver.cpp:244]     Train net output #0: loss = 0.00875456 (* 1 = 0.00875456 loss)
I0403 04:54:25.800989 28785 sgd_solver.cpp:106] Iteration 9488, lr = 5e-05
I0403 04:54:37.483772 28785 solver.cpp:228] Iteration 9504, loss = 0.00160707
I0403 04:54:37.483888 28785 solver.cpp:244]     Train net output #0: loss = 0.00160719 (* 1 = 0.00160719 loss)
I0403 04:54:37.668802 28785 sgd_solver.cpp:106] Iteration 9504, lr = 5e-05
I0403 04:54:49.165913 28785 solver.cpp:228] Iteration 9520, loss = 0.0030228
I0403 04:54:49.166231 28785 solver.cpp:244]     Train net output #0: loss = 0.00302292 (* 1 = 0.00302292 loss)
I0403 04:54:49.352792 28785 sgd_solver.cpp:106] Iteration 9520, lr = 5e-05
I0403 04:55:00.908887 28785 solver.cpp:228] Iteration 9536, loss = 0.0014992
I0403 04:55:00.908987 28785 solver.cpp:244]     Train net output #0: loss = 0.00149931 (* 1 = 0.00149931 loss)
I0403 04:55:01.041704 28785 sgd_solver.cpp:106] Iteration 9536, lr = 5e-05
I0403 04:55:12.747143 28785 solver.cpp:228] Iteration 9552, loss = 0.027082
I0403 04:55:12.747263 28785 solver.cpp:244]     Train net output #0: loss = 0.0270821 (* 1 = 0.0270821 loss)
I0403 04:55:12.978904 28785 sgd_solver.cpp:106] Iteration 9552, lr = 5e-05
I0403 04:55:24.750471 28785 solver.cpp:228] Iteration 9568, loss = 0.00336392
I0403 04:55:24.750771 28785 solver.cpp:244]     Train net output #0: loss = 0.00336404 (* 1 = 0.00336404 loss)
I0403 04:55:24.931283 28785 sgd_solver.cpp:106] Iteration 9568, lr = 5e-05
I0403 04:55:36.522907 28785 solver.cpp:228] Iteration 9584, loss = 0.00070263
I0403 04:55:36.523018 28785 solver.cpp:244]     Train net output #0: loss = 0.000702744 (* 1 = 0.000702744 loss)
I0403 04:55:36.711194 28785 sgd_solver.cpp:106] Iteration 9584, lr = 5e-05
I0403 04:55:48.229882 28785 solver.cpp:228] Iteration 9600, loss = 0.00230859
I0403 04:55:48.229993 28785 solver.cpp:244]     Train net output #0: loss = 0.0023087 (* 1 = 0.0023087 loss)
I0403 04:55:48.422591 28785 sgd_solver.cpp:106] Iteration 9600, lr = 5e-05
I0403 04:56:00.292807 28785 solver.cpp:228] Iteration 9616, loss = 0.000753886
I0403 04:56:00.293103 28785 solver.cpp:244]     Train net output #0: loss = 0.000754 (* 1 = 0.000754 loss)
I0403 04:56:00.471559 28785 sgd_solver.cpp:106] Iteration 9616, lr = 5e-05
I0403 04:56:12.109185 28785 solver.cpp:228] Iteration 9632, loss = 0.00450592
I0403 04:56:12.109289 28785 solver.cpp:244]     Train net output #0: loss = 0.00450604 (* 1 = 0.00450604 loss)
I0403 04:56:12.256517 28785 sgd_solver.cpp:106] Iteration 9632, lr = 5e-05
I0403 04:56:24.245911 28785 solver.cpp:228] Iteration 9648, loss = 0.00179947
I0403 04:56:24.246016 28785 solver.cpp:244]     Train net output #0: loss = 0.00179958 (* 1 = 0.00179958 loss)
I0403 04:56:24.412757 28785 sgd_solver.cpp:106] Iteration 9648, lr = 5e-05
I0403 04:56:36.128947 28785 solver.cpp:228] Iteration 9664, loss = 0.000614373
I0403 04:56:36.129281 28785 solver.cpp:244]     Train net output #0: loss = 0.000614486 (* 1 = 0.000614486 loss)
I0403 04:56:36.304456 28785 sgd_solver.cpp:106] Iteration 9664, lr = 5e-05
I0403 04:56:48.095077 28785 solver.cpp:228] Iteration 9680, loss = 0.000806121
I0403 04:56:48.095180 28785 solver.cpp:244]     Train net output #0: loss = 0.000806235 (* 1 = 0.000806235 loss)
I0403 04:56:48.264916 28785 sgd_solver.cpp:106] Iteration 9680, lr = 5e-05
I0403 04:56:59.926026 28785 solver.cpp:228] Iteration 9696, loss = 0.00287336
I0403 04:56:59.926136 28785 solver.cpp:244]     Train net output #0: loss = 0.00287347 (* 1 = 0.00287347 loss)
I0403 04:57:00.109277 28785 sgd_solver.cpp:106] Iteration 9696, lr = 5e-05
I0403 04:57:11.573492 28785 solver.cpp:228] Iteration 9712, loss = 0.00107196
I0403 04:57:11.573757 28785 solver.cpp:244]     Train net output #0: loss = 0.00107207 (* 1 = 0.00107207 loss)
I0403 04:57:11.765293 28785 sgd_solver.cpp:106] Iteration 9712, lr = 5e-05
I0403 04:57:23.204174 28785 solver.cpp:228] Iteration 9728, loss = 0.00795621
I0403 04:57:23.204298 28785 solver.cpp:244]     Train net output #0: loss = 0.00795632 (* 1 = 0.00795632 loss)
I0403 04:57:23.407124 28785 sgd_solver.cpp:106] Iteration 9728, lr = 5e-05
I0403 04:57:35.064154 28785 solver.cpp:228] Iteration 9744, loss = 0.000600547
I0403 04:57:35.064270 28785 solver.cpp:244]     Train net output #0: loss = 0.000600659 (* 1 = 0.000600659 loss)
I0403 04:57:35.251471 28785 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 04:57:38.880265 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9750.caffemodel
I0403 04:57:41.665643 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9750.solverstate
I0403 04:57:43.573405 28785 solver.cpp:337] Iteration 9750, Testing net (#0)
I0403 04:58:33.119052 28785 solver.cpp:404]     Test net output #0: accuracy = 0.968756
I0403 04:58:33.119367 28785 solver.cpp:404]     Test net output #1: loss = 0.120881 (* 1 = 0.120881 loss)
I0403 04:58:38.942934 28785 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9758.caffemodel
I0403 04:58:41.726102 28785 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-60-40_finetune/snapshots__iter_9758.solverstate
I0403 04:58:43.632658 28785 solver.cpp:322] Optimization Done.
I0403 04:58:43.716126 28785 caffe.cpp:222] Optimization Done.
