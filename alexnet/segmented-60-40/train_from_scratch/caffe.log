I0403 06:58:14.114045 21413 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 06:58:14.114523 21413 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 06:58:14.114557 21413 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 06:58:18.236094 21413 caffe.cpp:185] Using GPUs 0, 1
I0403 06:58:18.236567 21413 caffe.cpp:190] GPU 0: Tesla K40m
I0403 06:58:18.236929 21413 caffe.cpp:190] GPU 1: Tesla K40m
I0403 06:58:18.458761 21413 solver.cpp:48] Initializing solver from parameters: 
test_iter: 217
test_interval: 325
base_lr: 0.005
display: 16
max_iter: 9762
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3254
snapshot: 325
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 06:58:18.462735 21413 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 06:58:18.471915 21413 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 06:58:18.471994 21413 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 06:58:18.473031 21413 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 06:58:18.475478 21413 layer_factory.hpp:77] Creating layer data
I0403 06:58:18.477162 21413 net.cpp:91] Creating Layer data
I0403 06:58:18.477258 21413 net.cpp:399] data -> data
I0403 06:58:18.477380 21413 net.cpp:399] data -> label
I0403 06:58:18.477464 21413 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto
I0403 06:58:18.504957 21417 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-60-40/train_db
I0403 06:58:18.514485 21413 data_layer.cpp:41] output data size: 100,3,227,227
I0403 06:58:18.630367 21413 net.cpp:141] Setting up data
I0403 06:58:18.630470 21413 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 06:58:18.630489 21413 net.cpp:148] Top shape: 100 (100)
I0403 06:58:18.630504 21413 net.cpp:156] Memory required for data: 61835200
I0403 06:58:18.630538 21413 layer_factory.hpp:77] Creating layer conv1
I0403 06:58:18.630584 21413 net.cpp:91] Creating Layer conv1
I0403 06:58:18.630606 21413 net.cpp:425] conv1 <- data
I0403 06:58:18.630638 21413 net.cpp:399] conv1 -> conv1
I0403 06:58:18.633163 21413 net.cpp:141] Setting up conv1
I0403 06:58:18.633193 21413 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:58:18.633208 21413 net.cpp:156] Memory required for data: 177995200
I0403 06:58:18.633244 21413 layer_factory.hpp:77] Creating layer relu1
I0403 06:58:18.633270 21413 net.cpp:91] Creating Layer relu1
I0403 06:58:18.633287 21413 net.cpp:425] relu1 <- conv1
I0403 06:58:18.633306 21413 net.cpp:386] relu1 -> conv1 (in-place)
I0403 06:58:18.633328 21413 net.cpp:141] Setting up relu1
I0403 06:58:18.633347 21413 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:58:18.633361 21413 net.cpp:156] Memory required for data: 294155200
I0403 06:58:18.633375 21413 layer_factory.hpp:77] Creating layer norm1
I0403 06:58:18.633433 21413 net.cpp:91] Creating Layer norm1
I0403 06:58:18.633450 21413 net.cpp:425] norm1 <- conv1
I0403 06:58:18.633467 21413 net.cpp:399] norm1 -> norm1
I0403 06:58:18.639107 21413 net.cpp:141] Setting up norm1
I0403 06:58:18.639140 21413 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:58:18.639158 21413 net.cpp:156] Memory required for data: 410315200
I0403 06:58:18.639173 21413 layer_factory.hpp:77] Creating layer pool1
I0403 06:58:18.639194 21413 net.cpp:91] Creating Layer pool1
I0403 06:58:18.639209 21413 net.cpp:425] pool1 <- norm1
I0403 06:58:18.639227 21413 net.cpp:399] pool1 -> pool1
I0403 06:58:18.639288 21413 net.cpp:141] Setting up pool1
I0403 06:58:18.639312 21413 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 06:58:18.639328 21413 net.cpp:156] Memory required for data: 438308800
I0403 06:58:18.639341 21413 layer_factory.hpp:77] Creating layer conv2
I0403 06:58:18.639364 21413 net.cpp:91] Creating Layer conv2
I0403 06:58:18.639380 21413 net.cpp:425] conv2 <- pool1
I0403 06:58:18.639400 21413 net.cpp:399] conv2 -> conv2
I0403 06:58:18.640547 21418 blocking_queue.cpp:50] Waiting for data
I0403 06:58:18.651836 21413 net.cpp:141] Setting up conv2
I0403 06:58:18.651864 21413 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:58:18.651881 21413 net.cpp:156] Memory required for data: 512958400
I0403 06:58:18.651901 21413 layer_factory.hpp:77] Creating layer relu2
I0403 06:58:18.651919 21413 net.cpp:91] Creating Layer relu2
I0403 06:58:18.651935 21413 net.cpp:425] relu2 <- conv2
I0403 06:58:18.651952 21413 net.cpp:386] relu2 -> conv2 (in-place)
I0403 06:58:18.651971 21413 net.cpp:141] Setting up relu2
I0403 06:58:18.651988 21413 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:58:18.652001 21413 net.cpp:156] Memory required for data: 587608000
I0403 06:58:18.652014 21413 layer_factory.hpp:77] Creating layer norm2
I0403 06:58:18.652031 21413 net.cpp:91] Creating Layer norm2
I0403 06:58:18.652046 21413 net.cpp:425] norm2 <- conv2
I0403 06:58:18.652062 21413 net.cpp:399] norm2 -> norm2
I0403 06:58:18.652106 21413 net.cpp:141] Setting up norm2
I0403 06:58:18.652127 21413 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:58:18.652140 21413 net.cpp:156] Memory required for data: 662257600
I0403 06:58:18.652154 21413 layer_factory.hpp:77] Creating layer pool2
I0403 06:58:18.652173 21413 net.cpp:91] Creating Layer pool2
I0403 06:58:18.652189 21413 net.cpp:425] pool2 <- norm2
I0403 06:58:18.652206 21413 net.cpp:399] pool2 -> pool2
I0403 06:58:18.652247 21413 net.cpp:141] Setting up pool2
I0403 06:58:18.652269 21413 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:58:18.652282 21413 net.cpp:156] Memory required for data: 679563200
I0403 06:58:18.652297 21413 layer_factory.hpp:77] Creating layer conv3
I0403 06:58:18.652318 21413 net.cpp:91] Creating Layer conv3
I0403 06:58:18.652333 21413 net.cpp:425] conv3 <- pool2
I0403 06:58:18.652351 21413 net.cpp:399] conv3 -> conv3
I0403 06:58:18.684381 21413 net.cpp:141] Setting up conv3
I0403 06:58:18.684412 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:18.684427 21413 net.cpp:156] Memory required for data: 705521600
I0403 06:58:18.684448 21413 layer_factory.hpp:77] Creating layer relu3
I0403 06:58:18.684466 21413 net.cpp:91] Creating Layer relu3
I0403 06:58:18.684483 21413 net.cpp:425] relu3 <- conv3
I0403 06:58:18.684499 21413 net.cpp:386] relu3 -> conv3 (in-place)
I0403 06:58:18.684516 21413 net.cpp:141] Setting up relu3
I0403 06:58:18.684536 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:18.684551 21413 net.cpp:156] Memory required for data: 731480000
I0403 06:58:18.684566 21413 layer_factory.hpp:77] Creating layer conv4
I0403 06:58:18.684587 21413 net.cpp:91] Creating Layer conv4
I0403 06:58:18.684602 21413 net.cpp:425] conv4 <- conv3
I0403 06:58:18.684620 21413 net.cpp:399] conv4 -> conv4
I0403 06:58:18.708621 21413 net.cpp:141] Setting up conv4
I0403 06:58:18.708650 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:18.708664 21413 net.cpp:156] Memory required for data: 757438400
I0403 06:58:18.708698 21413 layer_factory.hpp:77] Creating layer relu4
I0403 06:58:18.708717 21413 net.cpp:91] Creating Layer relu4
I0403 06:58:18.708734 21413 net.cpp:425] relu4 <- conv4
I0403 06:58:18.708750 21413 net.cpp:386] relu4 -> conv4 (in-place)
I0403 06:58:18.708768 21413 net.cpp:141] Setting up relu4
I0403 06:58:18.708784 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:18.708798 21413 net.cpp:156] Memory required for data: 783396800
I0403 06:58:18.708812 21413 layer_factory.hpp:77] Creating layer conv5
I0403 06:58:18.708832 21413 net.cpp:91] Creating Layer conv5
I0403 06:58:18.708847 21413 net.cpp:425] conv5 <- conv4
I0403 06:58:18.708866 21413 net.cpp:399] conv5 -> conv5
I0403 06:58:18.724961 21413 net.cpp:141] Setting up conv5
I0403 06:58:18.724992 21413 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:58:18.725006 21413 net.cpp:156] Memory required for data: 800702400
I0403 06:58:18.725028 21413 layer_factory.hpp:77] Creating layer relu5
I0403 06:58:18.725049 21413 net.cpp:91] Creating Layer relu5
I0403 06:58:18.725067 21413 net.cpp:425] relu5 <- conv5
I0403 06:58:18.725085 21413 net.cpp:386] relu5 -> conv5 (in-place)
I0403 06:58:18.725105 21413 net.cpp:141] Setting up relu5
I0403 06:58:18.725122 21413 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:58:18.725137 21413 net.cpp:156] Memory required for data: 818008000
I0403 06:58:18.725150 21413 layer_factory.hpp:77] Creating layer pool5
I0403 06:58:18.725167 21413 net.cpp:91] Creating Layer pool5
I0403 06:58:18.725183 21413 net.cpp:425] pool5 <- conv5
I0403 06:58:18.725200 21413 net.cpp:399] pool5 -> pool5
I0403 06:58:18.725245 21413 net.cpp:141] Setting up pool5
I0403 06:58:18.725270 21413 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 06:58:18.725283 21413 net.cpp:156] Memory required for data: 821694400
I0403 06:58:18.725297 21413 layer_factory.hpp:77] Creating layer fc6
I0403 06:58:18.725322 21413 net.cpp:91] Creating Layer fc6
I0403 06:58:18.725338 21413 net.cpp:425] fc6 <- pool5
I0403 06:58:18.725358 21413 net.cpp:399] fc6 -> fc6
I0403 06:58:20.078223 21413 net.cpp:141] Setting up fc6
I0403 06:58:20.078322 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:20.078339 21413 net.cpp:156] Memory required for data: 823332800
I0403 06:58:20.078361 21413 layer_factory.hpp:77] Creating layer relu6
I0403 06:58:20.078385 21413 net.cpp:91] Creating Layer relu6
I0403 06:58:20.078402 21413 net.cpp:425] relu6 <- fc6
I0403 06:58:20.078421 21413 net.cpp:386] relu6 -> fc6 (in-place)
I0403 06:58:20.078443 21413 net.cpp:141] Setting up relu6
I0403 06:58:20.078459 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:20.078474 21413 net.cpp:156] Memory required for data: 824971200
I0403 06:58:20.078487 21413 layer_factory.hpp:77] Creating layer drop6
I0403 06:58:20.078513 21413 net.cpp:91] Creating Layer drop6
I0403 06:58:20.078531 21413 net.cpp:425] drop6 <- fc6
I0403 06:58:20.078553 21413 net.cpp:386] drop6 -> fc6 (in-place)
I0403 06:58:20.078599 21413 net.cpp:141] Setting up drop6
I0403 06:58:20.078620 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:20.078634 21413 net.cpp:156] Memory required for data: 826609600
I0403 06:58:20.078647 21413 layer_factory.hpp:77] Creating layer fc7
I0403 06:58:20.078667 21413 net.cpp:91] Creating Layer fc7
I0403 06:58:20.078682 21413 net.cpp:425] fc7 <- fc6
I0403 06:58:20.078703 21413 net.cpp:399] fc7 -> fc7
I0403 06:58:20.679575 21413 net.cpp:141] Setting up fc7
I0403 06:58:20.679669 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:20.679684 21413 net.cpp:156] Memory required for data: 828248000
I0403 06:58:20.679705 21413 layer_factory.hpp:77] Creating layer relu7
I0403 06:58:20.679728 21413 net.cpp:91] Creating Layer relu7
I0403 06:58:20.679745 21413 net.cpp:425] relu7 <- fc7
I0403 06:58:20.679765 21413 net.cpp:386] relu7 -> fc7 (in-place)
I0403 06:58:20.679788 21413 net.cpp:141] Setting up relu7
I0403 06:58:20.679805 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:20.679819 21413 net.cpp:156] Memory required for data: 829886400
I0403 06:58:20.679874 21413 layer_factory.hpp:77] Creating layer drop7
I0403 06:58:20.679894 21413 net.cpp:91] Creating Layer drop7
I0403 06:58:20.679909 21413 net.cpp:425] drop7 <- fc7
I0403 06:58:20.679925 21413 net.cpp:386] drop7 -> fc7 (in-place)
I0403 06:58:20.679965 21413 net.cpp:141] Setting up drop7
I0403 06:58:20.679986 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:20.679999 21413 net.cpp:156] Memory required for data: 831524800
I0403 06:58:20.680013 21413 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 06:58:20.680032 21413 net.cpp:91] Creating Layer fc8_plantvillage
I0403 06:58:20.680047 21413 net.cpp:425] fc8_plantvillage <- fc7
I0403 06:58:20.680066 21413 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 06:58:20.686033 21413 net.cpp:141] Setting up fc8_plantvillage
I0403 06:58:20.686060 21413 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:58:20.686075 21413 net.cpp:156] Memory required for data: 831540000
I0403 06:58:20.686094 21413 layer_factory.hpp:77] Creating layer loss
I0403 06:58:20.686120 21413 net.cpp:91] Creating Layer loss
I0403 06:58:20.686136 21413 net.cpp:425] loss <- fc8_plantvillage
I0403 06:58:20.686152 21413 net.cpp:425] loss <- label
I0403 06:58:20.686173 21413 net.cpp:399] loss -> loss
I0403 06:58:20.686199 21413 layer_factory.hpp:77] Creating layer loss
I0403 06:58:20.686295 21413 net.cpp:141] Setting up loss
I0403 06:58:20.686318 21413 net.cpp:148] Top shape: (1)
I0403 06:58:20.686332 21413 net.cpp:151]     with loss weight 1
I0403 06:58:20.686390 21413 net.cpp:156] Memory required for data: 831540004
I0403 06:58:20.686404 21413 net.cpp:217] loss needs backward computation.
I0403 06:58:20.686419 21413 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 06:58:20.686434 21413 net.cpp:217] drop7 needs backward computation.
I0403 06:58:20.686447 21413 net.cpp:217] relu7 needs backward computation.
I0403 06:58:20.686460 21413 net.cpp:217] fc7 needs backward computation.
I0403 06:58:20.686473 21413 net.cpp:217] drop6 needs backward computation.
I0403 06:58:20.686487 21413 net.cpp:217] relu6 needs backward computation.
I0403 06:58:20.686501 21413 net.cpp:217] fc6 needs backward computation.
I0403 06:58:20.686519 21413 net.cpp:217] pool5 needs backward computation.
I0403 06:58:20.686539 21413 net.cpp:217] relu5 needs backward computation.
I0403 06:58:20.686555 21413 net.cpp:217] conv5 needs backward computation.
I0403 06:58:20.686569 21413 net.cpp:217] relu4 needs backward computation.
I0403 06:58:20.686583 21413 net.cpp:217] conv4 needs backward computation.
I0403 06:58:20.686596 21413 net.cpp:217] relu3 needs backward computation.
I0403 06:58:20.686610 21413 net.cpp:217] conv3 needs backward computation.
I0403 06:58:20.686625 21413 net.cpp:217] pool2 needs backward computation.
I0403 06:58:20.686637 21413 net.cpp:217] norm2 needs backward computation.
I0403 06:58:20.686651 21413 net.cpp:217] relu2 needs backward computation.
I0403 06:58:20.686664 21413 net.cpp:217] conv2 needs backward computation.
I0403 06:58:20.686678 21413 net.cpp:217] pool1 needs backward computation.
I0403 06:58:20.686692 21413 net.cpp:217] norm1 needs backward computation.
I0403 06:58:20.686705 21413 net.cpp:217] relu1 needs backward computation.
I0403 06:58:20.686719 21413 net.cpp:217] conv1 needs backward computation.
I0403 06:58:20.686733 21413 net.cpp:219] data does not need backward computation.
I0403 06:58:20.686746 21413 net.cpp:261] This network produces output loss
I0403 06:58:20.686769 21413 net.cpp:274] Network initialization done.
I0403 06:58:20.687849 21413 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 06:58:20.687904 21413 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 06:58:20.688529 21413 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 06:58:20.688689 21413 layer_factory.hpp:77] Creating layer data
I0403 06:58:20.688855 21413 net.cpp:91] Creating Layer data
I0403 06:58:20.688884 21413 net.cpp:399] data -> data
I0403 06:58:20.688907 21413 net.cpp:399] data -> label
I0403 06:58:20.688930 21413 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto
I0403 06:58:20.720055 21419 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-60-40/test_db
I0403 06:58:20.722498 21413 data_layer.cpp:41] output data size: 100,3,227,227
I0403 06:58:20.836614 21413 net.cpp:141] Setting up data
I0403 06:58:20.836715 21413 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 06:58:20.836735 21413 net.cpp:148] Top shape: 100 (100)
I0403 06:58:20.836751 21413 net.cpp:156] Memory required for data: 61835200
I0403 06:58:20.836771 21413 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 06:58:20.836799 21413 net.cpp:91] Creating Layer label_data_1_split
I0403 06:58:20.836815 21413 net.cpp:425] label_data_1_split <- label
I0403 06:58:20.836835 21413 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 06:58:20.836859 21413 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 06:58:20.836915 21413 net.cpp:141] Setting up label_data_1_split
I0403 06:58:20.836935 21413 net.cpp:148] Top shape: 100 (100)
I0403 06:58:20.836951 21413 net.cpp:148] Top shape: 100 (100)
I0403 06:58:20.836966 21413 net.cpp:156] Memory required for data: 61836000
I0403 06:58:20.836982 21413 layer_factory.hpp:77] Creating layer conv1
I0403 06:58:20.837008 21413 net.cpp:91] Creating Layer conv1
I0403 06:58:20.837025 21413 net.cpp:425] conv1 <- data
I0403 06:58:20.837044 21413 net.cpp:399] conv1 -> conv1
I0403 06:58:20.838510 21413 net.cpp:141] Setting up conv1
I0403 06:58:20.838538 21413 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:58:20.838554 21413 net.cpp:156] Memory required for data: 177996000
I0403 06:58:20.838587 21413 layer_factory.hpp:77] Creating layer relu1
I0403 06:58:20.838606 21413 net.cpp:91] Creating Layer relu1
I0403 06:58:20.838624 21413 net.cpp:425] relu1 <- conv1
I0403 06:58:20.838641 21413 net.cpp:386] relu1 -> conv1 (in-place)
I0403 06:58:20.838660 21413 net.cpp:141] Setting up relu1
I0403 06:58:20.838676 21413 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:58:20.838691 21413 net.cpp:156] Memory required for data: 294156000
I0403 06:58:20.838706 21413 layer_factory.hpp:77] Creating layer norm1
I0403 06:58:20.838726 21413 net.cpp:91] Creating Layer norm1
I0403 06:58:20.838740 21413 net.cpp:425] norm1 <- conv1
I0403 06:58:20.838757 21413 net.cpp:399] norm1 -> norm1
I0403 06:58:20.844565 21413 net.cpp:141] Setting up norm1
I0403 06:58:20.844609 21413 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:58:20.844624 21413 net.cpp:156] Memory required for data: 410316000
I0403 06:58:20.844640 21413 layer_factory.hpp:77] Creating layer pool1
I0403 06:58:20.844658 21413 net.cpp:91] Creating Layer pool1
I0403 06:58:20.844674 21413 net.cpp:425] pool1 <- norm1
I0403 06:58:20.844692 21413 net.cpp:399] pool1 -> pool1
I0403 06:58:20.844739 21413 net.cpp:141] Setting up pool1
I0403 06:58:20.844761 21413 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 06:58:20.844775 21413 net.cpp:156] Memory required for data: 438309600
I0403 06:58:20.844828 21413 layer_factory.hpp:77] Creating layer conv2
I0403 06:58:20.844852 21413 net.cpp:91] Creating Layer conv2
I0403 06:58:20.844868 21413 net.cpp:425] conv2 <- pool1
I0403 06:58:20.844887 21413 net.cpp:399] conv2 -> conv2
I0403 06:58:20.856431 21413 net.cpp:141] Setting up conv2
I0403 06:58:20.856461 21413 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:58:20.856477 21413 net.cpp:156] Memory required for data: 512959200
I0403 06:58:20.856498 21413 layer_factory.hpp:77] Creating layer relu2
I0403 06:58:20.856518 21413 net.cpp:91] Creating Layer relu2
I0403 06:58:20.856536 21413 net.cpp:425] relu2 <- conv2
I0403 06:58:20.856555 21413 net.cpp:386] relu2 -> conv2 (in-place)
I0403 06:58:20.856575 21413 net.cpp:141] Setting up relu2
I0403 06:58:20.856591 21413 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:58:20.856606 21413 net.cpp:156] Memory required for data: 587608800
I0403 06:58:20.856621 21413 layer_factory.hpp:77] Creating layer norm2
I0403 06:58:20.856638 21413 net.cpp:91] Creating Layer norm2
I0403 06:58:20.856654 21413 net.cpp:425] norm2 <- conv2
I0403 06:58:20.856673 21413 net.cpp:399] norm2 -> norm2
I0403 06:58:20.856719 21413 net.cpp:141] Setting up norm2
I0403 06:58:20.856741 21413 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:58:20.856756 21413 net.cpp:156] Memory required for data: 662258400
I0403 06:58:20.856770 21413 layer_factory.hpp:77] Creating layer pool2
I0403 06:58:20.856787 21413 net.cpp:91] Creating Layer pool2
I0403 06:58:20.856803 21413 net.cpp:425] pool2 <- norm2
I0403 06:58:20.856820 21413 net.cpp:399] pool2 -> pool2
I0403 06:58:20.856865 21413 net.cpp:141] Setting up pool2
I0403 06:58:20.856886 21413 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:58:20.856900 21413 net.cpp:156] Memory required for data: 679564000
I0403 06:58:20.856914 21413 layer_factory.hpp:77] Creating layer conv3
I0403 06:58:20.856935 21413 net.cpp:91] Creating Layer conv3
I0403 06:58:20.856951 21413 net.cpp:425] conv3 <- pool2
I0403 06:58:20.856971 21413 net.cpp:399] conv3 -> conv3
I0403 06:58:20.890094 21413 net.cpp:141] Setting up conv3
I0403 06:58:20.890164 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:20.890180 21413 net.cpp:156] Memory required for data: 705522400
I0403 06:58:20.890203 21413 layer_factory.hpp:77] Creating layer relu3
I0403 06:58:20.890226 21413 net.cpp:91] Creating Layer relu3
I0403 06:58:20.890244 21413 net.cpp:425] relu3 <- conv3
I0403 06:58:20.890264 21413 net.cpp:386] relu3 -> conv3 (in-place)
I0403 06:58:20.890283 21413 net.cpp:141] Setting up relu3
I0403 06:58:20.890300 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:20.890314 21413 net.cpp:156] Memory required for data: 731480800
I0403 06:58:20.890328 21413 layer_factory.hpp:77] Creating layer conv4
I0403 06:58:20.890350 21413 net.cpp:91] Creating Layer conv4
I0403 06:58:20.890367 21413 net.cpp:425] conv4 <- conv3
I0403 06:58:20.890386 21413 net.cpp:399] conv4 -> conv4
I0403 06:58:20.915263 21413 net.cpp:141] Setting up conv4
I0403 06:58:20.915308 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:20.915323 21413 net.cpp:156] Memory required for data: 757439200
I0403 06:58:20.915343 21413 layer_factory.hpp:77] Creating layer relu4
I0403 06:58:20.915362 21413 net.cpp:91] Creating Layer relu4
I0403 06:58:20.915380 21413 net.cpp:425] relu4 <- conv4
I0403 06:58:20.915397 21413 net.cpp:386] relu4 -> conv4 (in-place)
I0403 06:58:20.915417 21413 net.cpp:141] Setting up relu4
I0403 06:58:20.915434 21413 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:58:20.915448 21413 net.cpp:156] Memory required for data: 783397600
I0403 06:58:20.915462 21413 layer_factory.hpp:77] Creating layer conv5
I0403 06:58:20.915484 21413 net.cpp:91] Creating Layer conv5
I0403 06:58:20.915500 21413 net.cpp:425] conv5 <- conv4
I0403 06:58:20.915519 21413 net.cpp:399] conv5 -> conv5
I0403 06:58:20.932231 21413 net.cpp:141] Setting up conv5
I0403 06:58:20.932265 21413 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:58:20.932317 21413 net.cpp:156] Memory required for data: 800703200
I0403 06:58:20.932345 21413 layer_factory.hpp:77] Creating layer relu5
I0403 06:58:20.932366 21413 net.cpp:91] Creating Layer relu5
I0403 06:58:20.932382 21413 net.cpp:425] relu5 <- conv5
I0403 06:58:20.932399 21413 net.cpp:386] relu5 -> conv5 (in-place)
I0403 06:58:20.932418 21413 net.cpp:141] Setting up relu5
I0403 06:58:20.932435 21413 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:58:20.932449 21413 net.cpp:156] Memory required for data: 818008800
I0403 06:58:20.932463 21413 layer_factory.hpp:77] Creating layer pool5
I0403 06:58:20.932487 21413 net.cpp:91] Creating Layer pool5
I0403 06:58:20.932502 21413 net.cpp:425] pool5 <- conv5
I0403 06:58:20.932520 21413 net.cpp:399] pool5 -> pool5
I0403 06:58:20.932579 21413 net.cpp:141] Setting up pool5
I0403 06:58:20.932602 21413 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 06:58:20.932616 21413 net.cpp:156] Memory required for data: 821695200
I0403 06:58:20.932631 21413 layer_factory.hpp:77] Creating layer fc6
I0403 06:58:20.932651 21413 net.cpp:91] Creating Layer fc6
I0403 06:58:20.932667 21413 net.cpp:425] fc6 <- pool5
I0403 06:58:20.932687 21413 net.cpp:399] fc6 -> fc6
I0403 06:58:22.302029 21413 net.cpp:141] Setting up fc6
I0403 06:58:22.302125 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:22.302142 21413 net.cpp:156] Memory required for data: 823333600
I0403 06:58:22.302165 21413 layer_factory.hpp:77] Creating layer relu6
I0403 06:58:22.302188 21413 net.cpp:91] Creating Layer relu6
I0403 06:58:22.302206 21413 net.cpp:425] relu6 <- fc6
I0403 06:58:22.302225 21413 net.cpp:386] relu6 -> fc6 (in-place)
I0403 06:58:22.302258 21413 net.cpp:141] Setting up relu6
I0403 06:58:22.302275 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:22.302289 21413 net.cpp:156] Memory required for data: 824972000
I0403 06:58:22.302304 21413 layer_factory.hpp:77] Creating layer drop6
I0403 06:58:22.302323 21413 net.cpp:91] Creating Layer drop6
I0403 06:58:22.302338 21413 net.cpp:425] drop6 <- fc6
I0403 06:58:22.302357 21413 net.cpp:386] drop6 -> fc6 (in-place)
I0403 06:58:22.302397 21413 net.cpp:141] Setting up drop6
I0403 06:58:22.302417 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:22.302433 21413 net.cpp:156] Memory required for data: 826610400
I0403 06:58:22.302448 21413 layer_factory.hpp:77] Creating layer fc7
I0403 06:58:22.302467 21413 net.cpp:91] Creating Layer fc7
I0403 06:58:22.302482 21413 net.cpp:425] fc7 <- fc6
I0403 06:58:22.302503 21413 net.cpp:399] fc7 -> fc7
I0403 06:58:22.911612 21413 net.cpp:141] Setting up fc7
I0403 06:58:22.911713 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:22.911731 21413 net.cpp:156] Memory required for data: 828248800
I0403 06:58:22.911753 21413 layer_factory.hpp:77] Creating layer relu7
I0403 06:58:22.911778 21413 net.cpp:91] Creating Layer relu7
I0403 06:58:22.911795 21413 net.cpp:425] relu7 <- fc7
I0403 06:58:22.911818 21413 net.cpp:386] relu7 -> fc7 (in-place)
I0403 06:58:22.911841 21413 net.cpp:141] Setting up relu7
I0403 06:58:22.911859 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:22.911875 21413 net.cpp:156] Memory required for data: 829887200
I0403 06:58:22.911890 21413 layer_factory.hpp:77] Creating layer drop7
I0403 06:58:22.911912 21413 net.cpp:91] Creating Layer drop7
I0403 06:58:22.911928 21413 net.cpp:425] drop7 <- fc7
I0403 06:58:22.911947 21413 net.cpp:386] drop7 -> fc7 (in-place)
I0403 06:58:22.911986 21413 net.cpp:141] Setting up drop7
I0403 06:58:22.912010 21413 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:58:22.912027 21413 net.cpp:156] Memory required for data: 831525600
I0403 06:58:22.912044 21413 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 06:58:22.912063 21413 net.cpp:91] Creating Layer fc8_plantvillage
I0403 06:58:22.912081 21413 net.cpp:425] fc8_plantvillage <- fc7
I0403 06:58:22.912101 21413 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 06:58:22.918520 21413 net.cpp:141] Setting up fc8_plantvillage
I0403 06:58:22.918556 21413 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:58:22.918611 21413 net.cpp:156] Memory required for data: 831540800
I0403 06:58:22.918629 21413 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 06:58:22.918653 21413 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 06:58:22.918669 21413 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 06:58:22.918689 21413 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 06:58:22.918709 21413 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 06:58:22.918761 21413 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 06:58:22.918783 21413 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:58:22.918799 21413 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:58:22.918814 21413 net.cpp:156] Memory required for data: 831571200
I0403 06:58:22.918829 21413 layer_factory.hpp:77] Creating layer loss
I0403 06:58:22.918848 21413 net.cpp:91] Creating Layer loss
I0403 06:58:22.918864 21413 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 06:58:22.918880 21413 net.cpp:425] loss <- label_data_1_split_0
I0403 06:58:22.918897 21413 net.cpp:399] loss -> loss
I0403 06:58:22.918920 21413 layer_factory.hpp:77] Creating layer loss
I0403 06:58:22.919018 21413 net.cpp:141] Setting up loss
I0403 06:58:22.919042 21413 net.cpp:148] Top shape: (1)
I0403 06:58:22.919059 21413 net.cpp:151]     with loss weight 1
I0403 06:58:22.919082 21413 net.cpp:156] Memory required for data: 831571204
I0403 06:58:22.919096 21413 layer_factory.hpp:77] Creating layer accuracy
I0403 06:58:22.919116 21413 net.cpp:91] Creating Layer accuracy
I0403 06:58:22.919132 21413 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 06:58:22.919149 21413 net.cpp:425] accuracy <- label_data_1_split_1
I0403 06:58:22.919167 21413 net.cpp:399] accuracy -> accuracy
I0403 06:58:22.919194 21413 net.cpp:141] Setting up accuracy
I0403 06:58:22.919214 21413 net.cpp:148] Top shape: (1)
I0403 06:58:22.919229 21413 net.cpp:156] Memory required for data: 831571208
I0403 06:58:22.919242 21413 net.cpp:219] accuracy does not need backward computation.
I0403 06:58:22.919258 21413 net.cpp:217] loss needs backward computation.
I0403 06:58:22.919275 21413 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 06:58:22.919288 21413 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 06:58:22.919303 21413 net.cpp:217] drop7 needs backward computation.
I0403 06:58:22.919317 21413 net.cpp:217] relu7 needs backward computation.
I0403 06:58:22.919332 21413 net.cpp:217] fc7 needs backward computation.
I0403 06:58:22.919347 21413 net.cpp:217] drop6 needs backward computation.
I0403 06:58:22.919360 21413 net.cpp:217] relu6 needs backward computation.
I0403 06:58:22.919374 21413 net.cpp:217] fc6 needs backward computation.
I0403 06:58:22.919389 21413 net.cpp:217] pool5 needs backward computation.
I0403 06:58:22.919402 21413 net.cpp:217] relu5 needs backward computation.
I0403 06:58:22.919417 21413 net.cpp:217] conv5 needs backward computation.
I0403 06:58:22.919431 21413 net.cpp:217] relu4 needs backward computation.
I0403 06:58:22.919446 21413 net.cpp:217] conv4 needs backward computation.
I0403 06:58:22.919461 21413 net.cpp:217] relu3 needs backward computation.
I0403 06:58:22.919476 21413 net.cpp:217] conv3 needs backward computation.
I0403 06:58:22.919491 21413 net.cpp:217] pool2 needs backward computation.
I0403 06:58:22.919504 21413 net.cpp:217] norm2 needs backward computation.
I0403 06:58:22.919518 21413 net.cpp:217] relu2 needs backward computation.
I0403 06:58:22.919538 21413 net.cpp:217] conv2 needs backward computation.
I0403 06:58:22.919555 21413 net.cpp:217] pool1 needs backward computation.
I0403 06:58:22.919571 21413 net.cpp:217] norm1 needs backward computation.
I0403 06:58:22.919585 21413 net.cpp:217] relu1 needs backward computation.
I0403 06:58:22.919600 21413 net.cpp:217] conv1 needs backward computation.
I0403 06:58:22.919631 21413 net.cpp:219] label_data_1_split does not need backward computation.
I0403 06:58:22.919649 21413 net.cpp:219] data does not need backward computation.
I0403 06:58:22.919664 21413 net.cpp:261] This network produces output accuracy
I0403 06:58:22.919679 21413 net.cpp:261] This network produces output loss
I0403 06:58:22.919708 21413 net.cpp:274] Network initialization done.
I0403 06:58:22.919816 21413 solver.cpp:60] Solver scaffolding done.
I0403 06:58:22.943557 21413 parallel.cpp:392] GPUs pairs 0:1
I0403 06:58:23.166360 21413 data_layer.cpp:41] output data size: 100,3,227,227
I0403 06:58:25.504106 21413 parallel.cpp:425] Starting Optimization
I0403 06:58:25.504267 21413 solver.cpp:279] Solving 
I0403 06:58:25.504292 21413 solver.cpp:280] Learning Rate Policy: step
I0403 06:58:25.504494 21413 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 06:59:14.594302 21413 solver.cpp:404]     Test net output #0: accuracy = 0.0158064
I0403 06:59:14.594530 21413 solver.cpp:404]     Test net output #1: loss = 3.64632 (* 1 = 3.64632 loss)
I0403 06:59:15.172606 21413 solver.cpp:228] Iteration 0, loss = 3.65026
I0403 06:59:15.172713 21413 solver.cpp:244]     Train net output #0: loss = 3.65026 (* 1 = 3.65026 loss)
I0403 06:59:15.364629 21413 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 06:59:26.828002 21413 solver.cpp:228] Iteration 16, loss = 3.1808
I0403 06:59:26.828114 21413 solver.cpp:244]     Train net output #0: loss = 3.1808 (* 1 = 3.1808 loss)
I0403 06:59:27.047457 21413 sgd_solver.cpp:106] Iteration 16, lr = 0.005
I0403 06:59:38.558351 21413 solver.cpp:228] Iteration 32, loss = 3.31805
I0403 06:59:38.558470 21413 solver.cpp:244]     Train net output #0: loss = 3.31805 (* 1 = 3.31805 loss)
I0403 06:59:38.748888 21413 sgd_solver.cpp:106] Iteration 32, lr = 0.005
I0403 06:59:50.231657 21413 solver.cpp:228] Iteration 48, loss = 3.29499
I0403 06:59:50.231988 21413 solver.cpp:244]     Train net output #0: loss = 3.29499 (* 1 = 3.29499 loss)
I0403 06:59:50.470651 21413 sgd_solver.cpp:106] Iteration 48, lr = 0.005
I0403 07:00:01.850850 21413 solver.cpp:228] Iteration 64, loss = 2.87299
I0403 07:00:01.850960 21413 solver.cpp:244]     Train net output #0: loss = 2.87299 (* 1 = 2.87299 loss)
I0403 07:00:02.037303 21413 sgd_solver.cpp:106] Iteration 64, lr = 0.005
I0403 07:00:13.479693 21413 solver.cpp:228] Iteration 80, loss = 2.97663
I0403 07:00:13.479806 21413 solver.cpp:244]     Train net output #0: loss = 2.97663 (* 1 = 2.97663 loss)
I0403 07:00:13.663568 21413 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 07:00:25.182680 21413 solver.cpp:228] Iteration 96, loss = 2.61208
I0403 07:00:25.182970 21413 solver.cpp:244]     Train net output #0: loss = 2.61208 (* 1 = 2.61208 loss)
I0403 07:00:25.358479 21413 sgd_solver.cpp:106] Iteration 96, lr = 0.005
I0403 07:00:36.855181 21413 solver.cpp:228] Iteration 112, loss = 2.23087
I0403 07:00:36.855279 21413 solver.cpp:244]     Train net output #0: loss = 2.23087 (* 1 = 2.23087 loss)
I0403 07:00:37.036932 21413 sgd_solver.cpp:106] Iteration 112, lr = 0.005
I0403 07:00:48.502084 21413 solver.cpp:228] Iteration 128, loss = 2.33646
I0403 07:00:48.502194 21413 solver.cpp:244]     Train net output #0: loss = 2.33646 (* 1 = 2.33646 loss)
I0403 07:00:48.700278 21413 sgd_solver.cpp:106] Iteration 128, lr = 0.005
I0403 07:01:00.214262 21413 solver.cpp:228] Iteration 144, loss = 2.14307
I0403 07:01:00.214617 21413 solver.cpp:244]     Train net output #0: loss = 2.14307 (* 1 = 2.14307 loss)
I0403 07:01:00.414935 21413 sgd_solver.cpp:106] Iteration 144, lr = 0.005
I0403 07:01:11.993873 21413 solver.cpp:228] Iteration 160, loss = 1.74927
I0403 07:01:11.993976 21413 solver.cpp:244]     Train net output #0: loss = 1.74927 (* 1 = 1.74927 loss)
I0403 07:01:12.135066 21413 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 07:01:23.854393 21413 solver.cpp:228] Iteration 176, loss = 1.94929
I0403 07:01:23.854507 21413 solver.cpp:244]     Train net output #0: loss = 1.94929 (* 1 = 1.94929 loss)
I0403 07:01:24.049370 21413 sgd_solver.cpp:106] Iteration 176, lr = 0.005
I0403 07:01:35.564194 21413 solver.cpp:228] Iteration 192, loss = 1.67364
I0403 07:01:35.564518 21413 solver.cpp:244]     Train net output #0: loss = 1.67364 (* 1 = 1.67364 loss)
I0403 07:01:35.776501 21413 sgd_solver.cpp:106] Iteration 192, lr = 0.005
I0403 07:01:47.251238 21413 solver.cpp:228] Iteration 208, loss = 1.70409
I0403 07:01:47.251348 21413 solver.cpp:244]     Train net output #0: loss = 1.70409 (* 1 = 1.70409 loss)
I0403 07:01:47.442668 21413 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 07:01:58.880718 21413 solver.cpp:228] Iteration 224, loss = 1.35311
I0403 07:01:58.880828 21413 solver.cpp:244]     Train net output #0: loss = 1.35311 (* 1 = 1.35311 loss)
I0403 07:01:59.075682 21413 sgd_solver.cpp:106] Iteration 224, lr = 0.005
I0403 07:02:10.564395 21413 solver.cpp:228] Iteration 240, loss = 1.69583
I0403 07:02:10.564734 21413 solver.cpp:244]     Train net output #0: loss = 1.69583 (* 1 = 1.69583 loss)
I0403 07:02:10.764531 21413 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 07:02:22.284720 21413 solver.cpp:228] Iteration 256, loss = 1.28491
I0403 07:02:22.284831 21413 solver.cpp:244]     Train net output #0: loss = 1.28491 (* 1 = 1.28491 loss)
I0403 07:02:22.471719 21413 sgd_solver.cpp:106] Iteration 256, lr = 0.005
I0403 07:02:33.903996 21413 solver.cpp:228] Iteration 272, loss = 1.38494
I0403 07:02:33.904109 21413 solver.cpp:244]     Train net output #0: loss = 1.38494 (* 1 = 1.38494 loss)
I0403 07:02:34.138851 21413 sgd_solver.cpp:106] Iteration 272, lr = 0.005
I0403 07:02:45.633409 21413 solver.cpp:228] Iteration 288, loss = 1.17162
I0403 07:02:45.633751 21413 solver.cpp:244]     Train net output #0: loss = 1.17162 (* 1 = 1.17162 loss)
I0403 07:02:45.828140 21413 sgd_solver.cpp:106] Iteration 288, lr = 0.005
I0403 07:02:57.385154 21413 solver.cpp:228] Iteration 304, loss = 1.22436
I0403 07:02:57.385264 21413 solver.cpp:244]     Train net output #0: loss = 1.22436 (* 1 = 1.22436 loss)
I0403 07:02:57.581822 21413 sgd_solver.cpp:106] Iteration 304, lr = 0.005
I0403 07:03:09.372943 21413 solver.cpp:228] Iteration 320, loss = 1.17056
I0403 07:03:09.373054 21413 solver.cpp:244]     Train net output #0: loss = 1.17056 (* 1 = 1.17056 loss)
I0403 07:03:09.559994 21413 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 07:03:12.476213 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_325.caffemodel
I0403 07:03:15.351572 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_325.solverstate
I0403 07:03:17.130568 21413 solver.cpp:337] Iteration 325, Testing net (#0)
I0403 07:04:06.186209 21413 solver.cpp:404]     Test net output #0: accuracy = 0.665944
I0403 07:04:06.186553 21413 solver.cpp:404]     Test net output #1: loss = 1.08109 (* 1 = 1.08109 loss)
I0403 07:04:14.764902 21413 solver.cpp:228] Iteration 336, loss = 1.20842
I0403 07:04:14.765012 21413 solver.cpp:244]     Train net output #0: loss = 1.20842 (* 1 = 1.20842 loss)
I0403 07:04:15.010784 21413 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 07:04:26.511937 21413 solver.cpp:228] Iteration 352, loss = 1.20903
I0403 07:04:26.512049 21413 solver.cpp:244]     Train net output #0: loss = 1.20903 (* 1 = 1.20903 loss)
I0403 07:04:26.707936 21413 sgd_solver.cpp:106] Iteration 352, lr = 0.005
I0403 07:04:38.159575 21413 solver.cpp:228] Iteration 368, loss = 0.997908
I0403 07:04:38.159885 21413 solver.cpp:244]     Train net output #0: loss = 0.997908 (* 1 = 0.997908 loss)
I0403 07:04:38.343734 21413 sgd_solver.cpp:106] Iteration 368, lr = 0.005
I0403 07:04:49.873412 21413 solver.cpp:228] Iteration 384, loss = 1.02482
I0403 07:04:49.873523 21413 solver.cpp:244]     Train net output #0: loss = 1.02482 (* 1 = 1.02482 loss)
I0403 07:04:50.047966 21413 sgd_solver.cpp:106] Iteration 384, lr = 0.005
I0403 07:05:01.606190 21413 solver.cpp:228] Iteration 400, loss = 1.16718
I0403 07:05:01.606300 21413 solver.cpp:244]     Train net output #0: loss = 1.16718 (* 1 = 1.16718 loss)
I0403 07:05:01.777370 21413 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 07:05:13.231385 21413 solver.cpp:228] Iteration 416, loss = 0.883865
I0403 07:05:13.231726 21413 solver.cpp:244]     Train net output #0: loss = 0.883865 (* 1 = 0.883865 loss)
I0403 07:05:13.418541 21413 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 07:05:25.141093 21413 solver.cpp:228] Iteration 432, loss = 0.785298
I0403 07:05:25.141206 21413 solver.cpp:244]     Train net output #0: loss = 0.785298 (* 1 = 0.785298 loss)
I0403 07:05:25.328179 21413 sgd_solver.cpp:106] Iteration 432, lr = 0.005
I0403 07:05:36.940387 21413 solver.cpp:228] Iteration 448, loss = 0.743259
I0403 07:05:36.940506 21413 solver.cpp:244]     Train net output #0: loss = 0.743259 (* 1 = 0.743259 loss)
I0403 07:05:37.149307 21413 sgd_solver.cpp:106] Iteration 448, lr = 0.005
I0403 07:05:48.690212 21413 solver.cpp:228] Iteration 464, loss = 0.911236
I0403 07:05:48.690563 21413 solver.cpp:244]     Train net output #0: loss = 0.911236 (* 1 = 0.911236 loss)
I0403 07:05:48.873693 21413 sgd_solver.cpp:106] Iteration 464, lr = 0.005
I0403 07:06:00.469243 21413 solver.cpp:228] Iteration 480, loss = 0.771003
I0403 07:06:00.469357 21413 solver.cpp:244]     Train net output #0: loss = 0.771003 (* 1 = 0.771003 loss)
I0403 07:06:00.656334 21413 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 07:06:12.224268 21413 solver.cpp:228] Iteration 496, loss = 0.825141
I0403 07:06:12.224382 21413 solver.cpp:244]     Train net output #0: loss = 0.825141 (* 1 = 0.825141 loss)
I0403 07:06:12.444663 21413 sgd_solver.cpp:106] Iteration 496, lr = 0.005
I0403 07:06:24.114367 21413 solver.cpp:228] Iteration 512, loss = 0.906351
I0403 07:06:24.114706 21413 solver.cpp:244]     Train net output #0: loss = 0.906351 (* 1 = 0.906351 loss)
I0403 07:06:24.313454 21413 sgd_solver.cpp:106] Iteration 512, lr = 0.005
I0403 07:06:35.751621 21413 solver.cpp:228] Iteration 528, loss = 0.592011
I0403 07:06:35.751734 21413 solver.cpp:244]     Train net output #0: loss = 0.592011 (* 1 = 0.592011 loss)
I0403 07:06:35.954810 21413 sgd_solver.cpp:106] Iteration 528, lr = 0.005
I0403 07:06:47.583482 21413 solver.cpp:228] Iteration 544, loss = 0.690815
I0403 07:06:47.583590 21413 solver.cpp:244]     Train net output #0: loss = 0.690815 (* 1 = 0.690815 loss)
I0403 07:06:47.706396 21413 sgd_solver.cpp:106] Iteration 544, lr = 0.005
I0403 07:06:59.350476 21413 solver.cpp:228] Iteration 560, loss = 0.760558
I0403 07:06:59.350821 21413 solver.cpp:244]     Train net output #0: loss = 0.760558 (* 1 = 0.760558 loss)
I0403 07:06:59.577348 21413 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 07:07:11.134675 21413 solver.cpp:228] Iteration 576, loss = 0.613898
I0403 07:07:11.134776 21413 solver.cpp:244]     Train net output #0: loss = 0.613898 (* 1 = 0.613898 loss)
I0403 07:07:11.317148 21413 sgd_solver.cpp:106] Iteration 576, lr = 0.005
I0403 07:07:22.750139 21413 solver.cpp:228] Iteration 592, loss = 0.719642
I0403 07:07:22.750247 21413 solver.cpp:244]     Train net output #0: loss = 0.719642 (* 1 = 0.719642 loss)
I0403 07:07:22.953575 21413 sgd_solver.cpp:106] Iteration 592, lr = 0.005
I0403 07:07:34.527251 21413 solver.cpp:228] Iteration 608, loss = 0.834028
I0403 07:07:34.527585 21413 solver.cpp:244]     Train net output #0: loss = 0.834028 (* 1 = 0.834028 loss)
I0403 07:07:34.687762 21413 sgd_solver.cpp:106] Iteration 608, lr = 0.005
I0403 07:07:46.436555 21413 solver.cpp:228] Iteration 624, loss = 0.600225
I0403 07:07:46.436660 21413 solver.cpp:244]     Train net output #0: loss = 0.600225 (* 1 = 0.600225 loss)
I0403 07:07:46.604919 21413 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 07:07:58.078398 21413 solver.cpp:228] Iteration 640, loss = 0.602782
I0403 07:07:58.078513 21413 solver.cpp:244]     Train net output #0: loss = 0.602782 (* 1 = 0.602782 loss)
I0403 07:07:58.305183 21413 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 07:08:04.876552 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_650.caffemodel
I0403 07:08:07.626797 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_650.solverstate
I0403 07:08:09.524107 21413 solver.cpp:337] Iteration 650, Testing net (#0)
I0403 07:08:58.576140 21413 solver.cpp:404]     Test net output #0: accuracy = 0.831751
I0403 07:08:58.576483 21413 solver.cpp:404]     Test net output #1: loss = 0.518136 (* 1 = 0.518136 loss)
I0403 07:09:03.518625 21413 solver.cpp:228] Iteration 656, loss = 0.656727
I0403 07:09:03.518738 21413 solver.cpp:244]     Train net output #0: loss = 0.656727 (* 1 = 0.656727 loss)
I0403 07:09:03.725488 21413 sgd_solver.cpp:106] Iteration 656, lr = 0.005
I0403 07:09:15.509181 21413 solver.cpp:228] Iteration 672, loss = 0.91892
I0403 07:09:15.509289 21413 solver.cpp:244]     Train net output #0: loss = 0.91892 (* 1 = 0.91892 loss)
I0403 07:09:15.694730 21413 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 07:09:27.212891 21413 solver.cpp:228] Iteration 688, loss = 0.576117
I0403 07:09:27.213008 21413 solver.cpp:244]     Train net output #0: loss = 0.576117 (* 1 = 0.576117 loss)
I0403 07:09:27.437747 21413 sgd_solver.cpp:106] Iteration 688, lr = 0.005
I0403 07:09:39.074110 21413 solver.cpp:228] Iteration 704, loss = 0.706901
I0403 07:09:39.074429 21413 solver.cpp:244]     Train net output #0: loss = 0.706901 (* 1 = 0.706901 loss)
I0403 07:09:39.259033 21413 sgd_solver.cpp:106] Iteration 704, lr = 0.005
I0403 07:09:50.699699 21413 solver.cpp:228] Iteration 720, loss = 0.436793
I0403 07:09:50.699811 21413 solver.cpp:244]     Train net output #0: loss = 0.436793 (* 1 = 0.436793 loss)
I0403 07:09:50.969452 21413 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 07:10:02.589536 21413 solver.cpp:228] Iteration 736, loss = 0.618244
I0403 07:10:02.589651 21413 solver.cpp:244]     Train net output #0: loss = 0.618244 (* 1 = 0.618244 loss)
I0403 07:10:02.780791 21413 sgd_solver.cpp:106] Iteration 736, lr = 0.005
I0403 07:10:14.258879 21413 solver.cpp:228] Iteration 752, loss = 0.489549
I0403 07:10:14.259220 21413 solver.cpp:244]     Train net output #0: loss = 0.489549 (* 1 = 0.489549 loss)
I0403 07:10:14.450032 21413 sgd_solver.cpp:106] Iteration 752, lr = 0.005
I0403 07:10:26.037453 21413 solver.cpp:228] Iteration 768, loss = 0.35062
I0403 07:10:26.037567 21413 solver.cpp:244]     Train net output #0: loss = 0.35062 (* 1 = 0.35062 loss)
I0403 07:10:26.263638 21413 sgd_solver.cpp:106] Iteration 768, lr = 0.005
I0403 07:10:37.964838 21413 solver.cpp:228] Iteration 784, loss = 0.385893
I0403 07:10:37.964952 21413 solver.cpp:244]     Train net output #0: loss = 0.385893 (* 1 = 0.385893 loss)
I0403 07:10:38.189359 21413 sgd_solver.cpp:106] Iteration 784, lr = 0.005
I0403 07:10:49.962193 21413 solver.cpp:228] Iteration 800, loss = 0.695843
I0403 07:10:49.962525 21413 solver.cpp:244]     Train net output #0: loss = 0.695843 (* 1 = 0.695843 loss)
I0403 07:10:50.155432 21413 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 07:11:01.573765 21413 solver.cpp:228] Iteration 816, loss = 0.388401
I0403 07:11:01.573880 21413 solver.cpp:244]     Train net output #0: loss = 0.388401 (* 1 = 0.388401 loss)
I0403 07:11:01.769881 21413 sgd_solver.cpp:106] Iteration 816, lr = 0.005
I0403 07:11:13.242370 21413 solver.cpp:228] Iteration 832, loss = 0.513791
I0403 07:11:13.242483 21413 solver.cpp:244]     Train net output #0: loss = 0.513791 (* 1 = 0.513791 loss)
I0403 07:11:13.479534 21413 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 07:11:25.100114 21413 solver.cpp:228] Iteration 848, loss = 0.461841
I0403 07:11:25.100425 21413 solver.cpp:244]     Train net output #0: loss = 0.461841 (* 1 = 0.461841 loss)
I0403 07:11:25.282153 21413 sgd_solver.cpp:106] Iteration 848, lr = 0.005
I0403 07:11:36.744798 21413 solver.cpp:228] Iteration 864, loss = 0.497177
I0403 07:11:36.744915 21413 solver.cpp:244]     Train net output #0: loss = 0.497177 (* 1 = 0.497177 loss)
I0403 07:11:37.000869 21413 sgd_solver.cpp:106] Iteration 864, lr = 0.005
I0403 07:11:48.689005 21413 solver.cpp:228] Iteration 880, loss = 0.507974
I0403 07:11:48.689122 21413 solver.cpp:244]     Train net output #0: loss = 0.507974 (* 1 = 0.507974 loss)
I0403 07:11:48.896311 21413 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 07:12:00.352700 21413 solver.cpp:228] Iteration 896, loss = 0.697235
I0403 07:12:00.353075 21413 solver.cpp:244]     Train net output #0: loss = 0.697235 (* 1 = 0.697235 loss)
I0403 07:12:00.555752 21413 sgd_solver.cpp:106] Iteration 896, lr = 0.005
I0403 07:12:12.131072 21413 solver.cpp:228] Iteration 912, loss = 0.265147
I0403 07:12:12.131173 21413 solver.cpp:244]     Train net output #0: loss = 0.265147 (* 1 = 0.265147 loss)
I0403 07:12:12.292670 21413 sgd_solver.cpp:106] Iteration 912, lr = 0.005
I0403 07:12:24.220351 21413 solver.cpp:228] Iteration 928, loss = 0.475307
I0403 07:12:24.220469 21413 solver.cpp:244]     Train net output #0: loss = 0.475307 (* 1 = 0.475307 loss)
I0403 07:12:24.460813 21413 sgd_solver.cpp:106] Iteration 928, lr = 0.005
I0403 07:12:36.118402 21413 solver.cpp:228] Iteration 944, loss = 0.365462
I0403 07:12:36.118746 21413 solver.cpp:244]     Train net output #0: loss = 0.365462 (* 1 = 0.365462 loss)
I0403 07:12:36.321349 21413 sgd_solver.cpp:106] Iteration 944, lr = 0.005
I0403 07:12:47.720983 21413 solver.cpp:228] Iteration 960, loss = 0.273185
I0403 07:12:47.721096 21413 solver.cpp:244]     Train net output #0: loss = 0.273185 (* 1 = 0.273185 loss)
I0403 07:12:47.936563 21413 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 07:12:58.315076 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_975.caffemodel
I0403 07:13:00.951213 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_975.solverstate
I0403 07:13:02.754520 21413 solver.cpp:337] Iteration 975, Testing net (#0)
I0403 07:13:51.801286 21413 solver.cpp:404]     Test net output #0: accuracy = 0.878064
I0403 07:13:51.801614 21413 solver.cpp:404]     Test net output #1: loss = 0.377266 (* 1 = 0.377266 loss)
I0403 07:13:53.074277 21413 solver.cpp:228] Iteration 976, loss = 0.467708
I0403 07:13:53.074373 21413 solver.cpp:244]     Train net output #0: loss = 0.467708 (* 1 = 0.467708 loss)
I0403 07:13:53.240736 21413 sgd_solver.cpp:106] Iteration 976, lr = 0.005
I0403 07:14:05.026345 21413 solver.cpp:228] Iteration 992, loss = 0.244689
I0403 07:14:05.026446 21413 solver.cpp:244]     Train net output #0: loss = 0.244689 (* 1 = 0.244689 loss)
I0403 07:14:05.167491 21413 sgd_solver.cpp:106] Iteration 992, lr = 0.005
I0403 07:14:16.999688 21413 solver.cpp:228] Iteration 1008, loss = 0.268306
I0403 07:14:16.999799 21413 solver.cpp:244]     Train net output #0: loss = 0.268306 (* 1 = 0.268306 loss)
I0403 07:14:17.191009 21413 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 07:14:28.773624 21413 solver.cpp:228] Iteration 1024, loss = 0.328759
I0403 07:14:28.773964 21413 solver.cpp:244]     Train net output #0: loss = 0.328759 (* 1 = 0.328759 loss)
I0403 07:14:28.982928 21413 sgd_solver.cpp:106] Iteration 1024, lr = 0.005
I0403 07:14:40.622071 21413 solver.cpp:228] Iteration 1040, loss = 0.462307
I0403 07:14:40.622184 21413 solver.cpp:244]     Train net output #0: loss = 0.462307 (* 1 = 0.462307 loss)
I0403 07:14:40.822249 21413 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 07:14:52.391765 21413 solver.cpp:228] Iteration 1056, loss = 0.338579
I0403 07:14:52.391891 21413 solver.cpp:244]     Train net output #0: loss = 0.338579 (* 1 = 0.338579 loss)
I0403 07:14:52.575686 21413 sgd_solver.cpp:106] Iteration 1056, lr = 0.005
I0403 07:15:04.333520 21413 solver.cpp:228] Iteration 1072, loss = 0.454193
I0403 07:15:04.333902 21413 solver.cpp:244]     Train net output #0: loss = 0.454193 (* 1 = 0.454193 loss)
I0403 07:15:04.615808 21413 sgd_solver.cpp:106] Iteration 1072, lr = 0.005
I0403 07:15:16.153915 21413 solver.cpp:228] Iteration 1088, loss = 0.187568
I0403 07:15:16.154014 21413 solver.cpp:244]     Train net output #0: loss = 0.187568 (* 1 = 0.187568 loss)
I0403 07:15:16.335911 21413 sgd_solver.cpp:106] Iteration 1088, lr = 0.005
I0403 07:15:27.893820 21413 solver.cpp:228] Iteration 1104, loss = 0.14736
I0403 07:15:27.893920 21413 solver.cpp:244]     Train net output #0: loss = 0.14736 (* 1 = 0.14736 loss)
I0403 07:15:28.076175 21413 sgd_solver.cpp:106] Iteration 1104, lr = 0.005
I0403 07:15:39.703269 21413 solver.cpp:228] Iteration 1120, loss = 0.288225
I0403 07:15:39.703624 21413 solver.cpp:244]     Train net output #0: loss = 0.288225 (* 1 = 0.288225 loss)
I0403 07:15:39.901567 21413 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 07:15:51.572321 21413 solver.cpp:228] Iteration 1136, loss = 0.249969
I0403 07:15:51.572434 21413 solver.cpp:244]     Train net output #0: loss = 0.249969 (* 1 = 0.249969 loss)
I0403 07:15:51.757225 21413 sgd_solver.cpp:106] Iteration 1136, lr = 0.005
I0403 07:16:03.397534 21413 solver.cpp:228] Iteration 1152, loss = 0.342156
I0403 07:16:03.397650 21413 solver.cpp:244]     Train net output #0: loss = 0.342156 (* 1 = 0.342156 loss)
I0403 07:16:03.597004 21413 sgd_solver.cpp:106] Iteration 1152, lr = 0.005
I0403 07:16:15.145884 21413 solver.cpp:228] Iteration 1168, loss = 0.268824
I0403 07:16:15.146216 21413 solver.cpp:244]     Train net output #0: loss = 0.268824 (* 1 = 0.268824 loss)
I0403 07:16:15.355270 21413 sgd_solver.cpp:106] Iteration 1168, lr = 0.005
I0403 07:16:26.814800 21413 solver.cpp:228] Iteration 1184, loss = 0.318206
I0403 07:16:26.814914 21413 solver.cpp:244]     Train net output #0: loss = 0.318206 (* 1 = 0.318206 loss)
I0403 07:16:27.006094 21413 sgd_solver.cpp:106] Iteration 1184, lr = 0.005
I0403 07:16:38.475478 21413 solver.cpp:228] Iteration 1200, loss = 0.312227
I0403 07:16:38.475584 21413 solver.cpp:244]     Train net output #0: loss = 0.312227 (* 1 = 0.312227 loss)
I0403 07:16:38.648748 21413 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 07:16:50.243381 21413 solver.cpp:228] Iteration 1216, loss = 0.376174
I0403 07:16:50.243719 21413 solver.cpp:244]     Train net output #0: loss = 0.376174 (* 1 = 0.376174 loss)
I0403 07:16:50.432987 21413 sgd_solver.cpp:106] Iteration 1216, lr = 0.005
I0403 07:17:01.931946 21413 solver.cpp:228] Iteration 1232, loss = 0.14955
I0403 07:17:01.932054 21413 solver.cpp:244]     Train net output #0: loss = 0.14955 (* 1 = 0.14955 loss)
I0403 07:17:02.133296 21413 sgd_solver.cpp:106] Iteration 1232, lr = 0.005
I0403 07:17:13.824106 21413 solver.cpp:228] Iteration 1248, loss = 0.201047
I0403 07:17:13.824219 21413 solver.cpp:244]     Train net output #0: loss = 0.201047 (* 1 = 0.201047 loss)
I0403 07:17:14.008982 21413 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 07:17:25.459398 21413 solver.cpp:228] Iteration 1264, loss = 0.233409
I0403 07:17:25.459744 21413 solver.cpp:244]     Train net output #0: loss = 0.233409 (* 1 = 0.233409 loss)
I0403 07:17:25.685410 21413 sgd_solver.cpp:106] Iteration 1264, lr = 0.005
I0403 07:17:37.278736 21413 solver.cpp:228] Iteration 1280, loss = 0.371005
I0403 07:17:37.278837 21413 solver.cpp:244]     Train net output #0: loss = 0.371005 (* 1 = 0.371005 loss)
I0403 07:17:37.458961 21413 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 07:17:49.014727 21413 solver.cpp:228] Iteration 1296, loss = 0.460794
I0403 07:17:49.014835 21413 solver.cpp:244]     Train net output #0: loss = 0.460794 (* 1 = 0.460794 loss)
I0403 07:17:49.223903 21413 sgd_solver.cpp:106] Iteration 1296, lr = 0.005
I0403 07:17:51.412367 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_1300.caffemodel
I0403 07:17:54.051734 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_1300.solverstate
I0403 07:17:55.792531 21413 solver.cpp:337] Iteration 1300, Testing net (#0)
I0403 07:18:44.833544 21413 solver.cpp:404]     Test net output #0: accuracy = 0.898617
I0403 07:18:44.833869 21413 solver.cpp:404]     Test net output #1: loss = 0.30632 (* 1 = 0.30632 loss)
I0403 07:18:54.276898 21413 solver.cpp:228] Iteration 1312, loss = 0.306676
I0403 07:18:54.277000 21413 solver.cpp:244]     Train net output #0: loss = 0.306676 (* 1 = 0.306676 loss)
I0403 07:18:54.452888 21413 sgd_solver.cpp:106] Iteration 1312, lr = 0.005
I0403 07:19:06.011222 21413 solver.cpp:228] Iteration 1328, loss = 0.313473
I0403 07:19:06.011322 21413 solver.cpp:244]     Train net output #0: loss = 0.313473 (* 1 = 0.313473 loss)
I0403 07:19:06.188104 21413 sgd_solver.cpp:106] Iteration 1328, lr = 0.005
I0403 07:19:17.764921 21413 solver.cpp:228] Iteration 1344, loss = 0.240182
I0403 07:19:17.765256 21413 solver.cpp:244]     Train net output #0: loss = 0.240182 (* 1 = 0.240182 loss)
I0403 07:19:17.965404 21413 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 07:19:29.428016 21413 solver.cpp:228] Iteration 1360, loss = 0.186369
I0403 07:19:29.428129 21413 solver.cpp:244]     Train net output #0: loss = 0.186368 (* 1 = 0.186368 loss)
I0403 07:19:29.634927 21413 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 07:19:41.182457 21413 solver.cpp:228] Iteration 1376, loss = 0.114859
I0403 07:19:41.182574 21413 solver.cpp:244]     Train net output #0: loss = 0.114859 (* 1 = 0.114859 loss)
I0403 07:19:41.366905 21413 sgd_solver.cpp:106] Iteration 1376, lr = 0.005
I0403 07:19:52.933089 21413 solver.cpp:228] Iteration 1392, loss = 0.227834
I0403 07:19:52.933409 21413 solver.cpp:244]     Train net output #0: loss = 0.227834 (* 1 = 0.227834 loss)
I0403 07:19:53.128259 21413 sgd_solver.cpp:106] Iteration 1392, lr = 0.005
I0403 07:20:04.692848 21413 solver.cpp:228] Iteration 1408, loss = 0.246657
I0403 07:20:04.692966 21413 solver.cpp:244]     Train net output #0: loss = 0.246657 (* 1 = 0.246657 loss)
I0403 07:20:04.958351 21413 sgd_solver.cpp:106] Iteration 1408, lr = 0.005
I0403 07:20:16.448304 21413 solver.cpp:228] Iteration 1424, loss = 0.354657
I0403 07:20:16.448416 21413 solver.cpp:244]     Train net output #0: loss = 0.354657 (* 1 = 0.354657 loss)
I0403 07:20:16.635917 21413 sgd_solver.cpp:106] Iteration 1424, lr = 0.005
I0403 07:20:28.143532 21413 solver.cpp:228] Iteration 1440, loss = 0.169649
I0403 07:20:28.143873 21413 solver.cpp:244]     Train net output #0: loss = 0.169649 (* 1 = 0.169649 loss)
I0403 07:20:28.349282 21413 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 07:20:40.080294 21413 solver.cpp:228] Iteration 1456, loss = 0.284948
I0403 07:20:40.080410 21413 solver.cpp:244]     Train net output #0: loss = 0.284948 (* 1 = 0.284948 loss)
I0403 07:20:40.314610 21413 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 07:20:51.788784 21413 solver.cpp:228] Iteration 1472, loss = 0.183222
I0403 07:20:51.788899 21413 solver.cpp:244]     Train net output #0: loss = 0.183222 (* 1 = 0.183222 loss)
I0403 07:20:52.040035 21413 sgd_solver.cpp:106] Iteration 1472, lr = 0.005
I0403 07:21:03.596421 21413 solver.cpp:228] Iteration 1488, loss = 0.256544
I0403 07:21:03.596765 21413 solver.cpp:244]     Train net output #0: loss = 0.256544 (* 1 = 0.256544 loss)
I0403 07:21:03.808848 21413 sgd_solver.cpp:106] Iteration 1488, lr = 0.005
I0403 07:21:15.421677 21413 solver.cpp:228] Iteration 1504, loss = 0.304828
I0403 07:21:15.421792 21413 solver.cpp:244]     Train net output #0: loss = 0.304828 (* 1 = 0.304828 loss)
I0403 07:21:15.637192 21413 sgd_solver.cpp:106] Iteration 1504, lr = 0.005
I0403 07:21:27.426324 21413 solver.cpp:228] Iteration 1520, loss = 0.273002
I0403 07:21:27.426425 21413 solver.cpp:244]     Train net output #0: loss = 0.273002 (* 1 = 0.273002 loss)
I0403 07:21:27.586858 21413 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 07:21:39.460203 21413 solver.cpp:228] Iteration 1536, loss = 0.0964856
I0403 07:21:39.460546 21413 solver.cpp:244]     Train net output #0: loss = 0.0964855 (* 1 = 0.0964855 loss)
I0403 07:21:39.639281 21413 sgd_solver.cpp:106] Iteration 1536, lr = 0.005
I0403 07:21:51.185189 21413 solver.cpp:228] Iteration 1552, loss = 0.12742
I0403 07:21:51.185300 21413 solver.cpp:244]     Train net output #0: loss = 0.12742 (* 1 = 0.12742 loss)
I0403 07:21:51.377377 21413 sgd_solver.cpp:106] Iteration 1552, lr = 0.005
I0403 07:22:02.924099 21413 solver.cpp:228] Iteration 1568, loss = 0.172693
I0403 07:22:02.924199 21413 solver.cpp:244]     Train net output #0: loss = 0.172693 (* 1 = 0.172693 loss)
I0403 07:22:03.081802 21413 sgd_solver.cpp:106] Iteration 1568, lr = 0.005
I0403 07:22:14.614851 21413 solver.cpp:228] Iteration 1584, loss = 0.278094
I0403 07:22:14.615161 21413 solver.cpp:244]     Train net output #0: loss = 0.278093 (* 1 = 0.278093 loss)
I0403 07:22:14.783102 21413 sgd_solver.cpp:106] Iteration 1584, lr = 0.005
I0403 07:22:26.331276 21413 solver.cpp:228] Iteration 1600, loss = 0.189498
I0403 07:22:26.331378 21413 solver.cpp:244]     Train net output #0: loss = 0.189498 (* 1 = 0.189498 loss)
I0403 07:22:26.508415 21413 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 07:22:37.969399 21413 solver.cpp:228] Iteration 1616, loss = 0.330153
I0403 07:22:37.969503 21413 solver.cpp:244]     Train net output #0: loss = 0.330153 (* 1 = 0.330153 loss)
I0403 07:22:38.148232 21413 sgd_solver.cpp:106] Iteration 1616, lr = 0.005
I0403 07:22:43.957864 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_1625.caffemodel
I0403 07:22:46.911363 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_1625.solverstate
I0403 07:22:48.905872 21413 solver.cpp:337] Iteration 1625, Testing net (#0)
I0403 07:23:37.966778 21413 solver.cpp:404]     Test net output #0: accuracy = 0.913871
I0403 07:23:37.967088 21413 solver.cpp:404]     Test net output #1: loss = 0.258855 (* 1 = 0.258855 loss)
I0403 07:23:43.552114 21413 solver.cpp:228] Iteration 1632, loss = 0.378758
I0403 07:23:43.552224 21413 solver.cpp:244]     Train net output #0: loss = 0.378758 (* 1 = 0.378758 loss)
I0403 07:23:43.740628 21413 sgd_solver.cpp:106] Iteration 1632, lr = 0.005
I0403 07:23:55.139313 21413 solver.cpp:228] Iteration 1648, loss = 0.223762
I0403 07:23:55.139426 21413 solver.cpp:244]     Train net output #0: loss = 0.223761 (* 1 = 0.223761 loss)
I0403 07:23:55.323463 21413 sgd_solver.cpp:106] Iteration 1648, lr = 0.005
I0403 07:24:06.806830 21413 solver.cpp:228] Iteration 1664, loss = 0.269982
I0403 07:24:06.806946 21413 solver.cpp:244]     Train net output #0: loss = 0.269982 (* 1 = 0.269982 loss)
I0403 07:24:06.993433 21413 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 07:24:18.526130 21413 solver.cpp:228] Iteration 1680, loss = 0.300383
I0403 07:24:18.526469 21413 solver.cpp:244]     Train net output #0: loss = 0.300382 (* 1 = 0.300382 loss)
I0403 07:24:18.736440 21413 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 07:24:30.374773 21413 solver.cpp:228] Iteration 1696, loss = 0.148415
I0403 07:24:30.374887 21413 solver.cpp:244]     Train net output #0: loss = 0.148415 (* 1 = 0.148415 loss)
I0403 07:24:30.583264 21413 sgd_solver.cpp:106] Iteration 1696, lr = 0.005
I0403 07:24:42.200355 21413 solver.cpp:228] Iteration 1712, loss = 0.118908
I0403 07:24:42.200467 21413 solver.cpp:244]     Train net output #0: loss = 0.118908 (* 1 = 0.118908 loss)
I0403 07:24:42.389212 21413 sgd_solver.cpp:106] Iteration 1712, lr = 0.005
I0403 07:24:53.832967 21413 solver.cpp:228] Iteration 1728, loss = 0.209465
I0403 07:24:53.833283 21413 solver.cpp:244]     Train net output #0: loss = 0.209465 (* 1 = 0.209465 loss)
I0403 07:24:54.018157 21413 sgd_solver.cpp:106] Iteration 1728, lr = 0.005
I0403 07:25:05.634871 21413 solver.cpp:228] Iteration 1744, loss = 0.103692
I0403 07:25:05.634999 21413 solver.cpp:244]     Train net output #0: loss = 0.103692 (* 1 = 0.103692 loss)
I0403 07:25:05.834863 21413 sgd_solver.cpp:106] Iteration 1744, lr = 0.005
I0403 07:25:17.431953 21413 solver.cpp:228] Iteration 1760, loss = 0.260968
I0403 07:25:17.432062 21413 solver.cpp:244]     Train net output #0: loss = 0.260968 (* 1 = 0.260968 loss)
I0403 07:25:17.623575 21413 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 07:25:29.272967 21413 solver.cpp:228] Iteration 1776, loss = 0.191594
I0403 07:25:29.273321 21413 solver.cpp:244]     Train net output #0: loss = 0.191594 (* 1 = 0.191594 loss)
I0403 07:25:29.458046 21413 sgd_solver.cpp:106] Iteration 1776, lr = 0.005
I0403 07:25:40.923389 21413 solver.cpp:228] Iteration 1792, loss = 0.0788747
I0403 07:25:40.923491 21413 solver.cpp:244]     Train net output #0: loss = 0.0788746 (* 1 = 0.0788746 loss)
I0403 07:25:41.107734 21413 sgd_solver.cpp:106] Iteration 1792, lr = 0.005
I0403 07:25:52.577054 21413 solver.cpp:228] Iteration 1808, loss = 0.261564
I0403 07:25:52.577169 21413 solver.cpp:244]     Train net output #0: loss = 0.261564 (* 1 = 0.261564 loss)
I0403 07:25:52.771999 21413 sgd_solver.cpp:106] Iteration 1808, lr = 0.005
I0403 07:26:04.456765 21413 solver.cpp:228] Iteration 1824, loss = 0.150993
I0403 07:26:04.457118 21413 solver.cpp:244]     Train net output #0: loss = 0.150993 (* 1 = 0.150993 loss)
I0403 07:26:04.680722 21413 sgd_solver.cpp:106] Iteration 1824, lr = 0.005
I0403 07:26:16.199846 21413 solver.cpp:228] Iteration 1840, loss = 0.160206
I0403 07:26:16.199950 21413 solver.cpp:244]     Train net output #0: loss = 0.160206 (* 1 = 0.160206 loss)
I0403 07:26:16.412304 21413 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 07:26:27.919440 21413 solver.cpp:228] Iteration 1856, loss = 0.207148
I0403 07:26:27.919558 21413 solver.cpp:244]     Train net output #0: loss = 0.207148 (* 1 = 0.207148 loss)
I0403 07:26:28.112105 21413 sgd_solver.cpp:106] Iteration 1856, lr = 0.005
I0403 07:26:39.777906 21413 solver.cpp:228] Iteration 1872, loss = 0.266441
I0403 07:26:39.778209 21413 solver.cpp:244]     Train net output #0: loss = 0.266441 (* 1 = 0.266441 loss)
I0403 07:26:39.868662 21413 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 07:26:51.714010 21413 solver.cpp:228] Iteration 1888, loss = 0.204846
I0403 07:26:51.714112 21413 solver.cpp:244]     Train net output #0: loss = 0.204846 (* 1 = 0.204846 loss)
I0403 07:26:51.884941 21413 sgd_solver.cpp:106] Iteration 1888, lr = 0.005
I0403 07:27:03.586607 21413 solver.cpp:228] Iteration 1904, loss = 0.279097
I0403 07:27:03.586709 21413 solver.cpp:244]     Train net output #0: loss = 0.279097 (* 1 = 0.279097 loss)
I0403 07:27:03.765497 21413 sgd_solver.cpp:106] Iteration 1904, lr = 0.005
I0403 07:27:15.385362 21413 solver.cpp:228] Iteration 1920, loss = 0.240015
I0403 07:27:15.385668 21413 solver.cpp:244]     Train net output #0: loss = 0.240015 (* 1 = 0.240015 loss)
I0403 07:27:15.554839 21413 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 07:27:27.119252 21413 solver.cpp:228] Iteration 1936, loss = 0.204232
I0403 07:27:27.119364 21413 solver.cpp:244]     Train net output #0: loss = 0.204232 (* 1 = 0.204232 loss)
I0403 07:27:27.302171 21413 sgd_solver.cpp:106] Iteration 1936, lr = 0.005
I0403 07:27:36.728375 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_1950.caffemodel
I0403 07:27:39.361306 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_1950.solverstate
I0403 07:27:41.161063 21413 solver.cpp:337] Iteration 1950, Testing net (#0)
I0403 07:28:30.226330 21413 solver.cpp:404]     Test net output #0: accuracy = 0.923318
I0403 07:28:30.226670 21413 solver.cpp:404]     Test net output #1: loss = 0.241287 (* 1 = 0.241287 loss)
I0403 07:28:32.246637 21413 solver.cpp:228] Iteration 1952, loss = 0.122749
I0403 07:28:32.246731 21413 solver.cpp:244]     Train net output #0: loss = 0.122749 (* 1 = 0.122749 loss)
I0403 07:28:32.426367 21413 sgd_solver.cpp:106] Iteration 1952, lr = 0.005
I0403 07:28:43.804652 21413 solver.cpp:228] Iteration 1968, loss = 0.161406
I0403 07:28:43.804766 21413 solver.cpp:244]     Train net output #0: loss = 0.161406 (* 1 = 0.161406 loss)
I0403 07:28:43.993904 21413 sgd_solver.cpp:106] Iteration 1968, lr = 0.005
I0403 07:28:55.492559 21413 solver.cpp:228] Iteration 1984, loss = 0.10417
I0403 07:28:55.492676 21413 solver.cpp:244]     Train net output #0: loss = 0.10417 (* 1 = 0.10417 loss)
I0403 07:28:55.686252 21413 sgd_solver.cpp:106] Iteration 1984, lr = 0.005
I0403 07:29:07.171958 21413 solver.cpp:228] Iteration 2000, loss = 0.171325
I0403 07:29:07.172348 21413 solver.cpp:244]     Train net output #0: loss = 0.171325 (* 1 = 0.171325 loss)
I0403 07:29:07.377562 21413 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 07:29:18.894317 21413 solver.cpp:228] Iteration 2016, loss = 0.223174
I0403 07:29:18.894431 21413 solver.cpp:244]     Train net output #0: loss = 0.223174 (* 1 = 0.223174 loss)
I0403 07:29:19.119693 21413 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 07:29:30.643420 21413 solver.cpp:228] Iteration 2032, loss = 0.29165
I0403 07:29:30.643540 21413 solver.cpp:244]     Train net output #0: loss = 0.29165 (* 1 = 0.29165 loss)
I0403 07:29:30.845684 21413 sgd_solver.cpp:106] Iteration 2032, lr = 0.005
I0403 07:29:42.625124 21413 solver.cpp:228] Iteration 2048, loss = 0.191522
I0403 07:29:42.625468 21413 solver.cpp:244]     Train net output #0: loss = 0.191522 (* 1 = 0.191522 loss)
I0403 07:29:42.839624 21413 sgd_solver.cpp:106] Iteration 2048, lr = 0.005
I0403 07:29:54.211359 21413 solver.cpp:228] Iteration 2064, loss = 0.0876649
I0403 07:29:54.211462 21413 solver.cpp:244]     Train net output #0: loss = 0.0876647 (* 1 = 0.0876647 loss)
I0403 07:29:54.378686 21413 sgd_solver.cpp:106] Iteration 2064, lr = 0.005
I0403 07:30:05.792052 21413 solver.cpp:228] Iteration 2080, loss = 0.0491467
I0403 07:30:05.792155 21413 solver.cpp:244]     Train net output #0: loss = 0.0491465 (* 1 = 0.0491465 loss)
I0403 07:30:05.967973 21413 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 07:30:17.378700 21413 solver.cpp:228] Iteration 2096, loss = 0.119743
I0403 07:30:17.379034 21413 solver.cpp:244]     Train net output #0: loss = 0.119743 (* 1 = 0.119743 loss)
I0403 07:30:17.610990 21413 sgd_solver.cpp:106] Iteration 2096, lr = 0.005
I0403 07:30:29.110993 21413 solver.cpp:228] Iteration 2112, loss = 0.281072
I0403 07:30:29.111102 21413 solver.cpp:244]     Train net output #0: loss = 0.281071 (* 1 = 0.281071 loss)
I0403 07:30:29.303006 21413 sgd_solver.cpp:106] Iteration 2112, lr = 0.005
I0403 07:30:40.746121 21413 solver.cpp:228] Iteration 2128, loss = 0.303181
I0403 07:30:40.746235 21413 solver.cpp:244]     Train net output #0: loss = 0.303181 (* 1 = 0.303181 loss)
I0403 07:30:40.960081 21413 sgd_solver.cpp:106] Iteration 2128, lr = 0.005
I0403 07:30:52.509474 21413 solver.cpp:228] Iteration 2144, loss = 0.301622
I0403 07:30:52.509794 21413 solver.cpp:244]     Train net output #0: loss = 0.301622 (* 1 = 0.301622 loss)
I0403 07:30:52.723354 21413 sgd_solver.cpp:106] Iteration 2144, lr = 0.005
I0403 07:31:04.184094 21413 solver.cpp:228] Iteration 2160, loss = 0.232514
I0403 07:31:04.184195 21413 solver.cpp:244]     Train net output #0: loss = 0.232514 (* 1 = 0.232514 loss)
I0403 07:31:04.337576 21413 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 07:31:15.995455 21413 solver.cpp:228] Iteration 2176, loss = 0.151793
I0403 07:31:15.995569 21413 solver.cpp:244]     Train net output #0: loss = 0.151793 (* 1 = 0.151793 loss)
I0403 07:31:16.222939 21413 sgd_solver.cpp:106] Iteration 2176, lr = 0.005
I0403 07:31:27.848333 21413 solver.cpp:228] Iteration 2192, loss = 0.167468
I0403 07:31:27.848649 21413 solver.cpp:244]     Train net output #0: loss = 0.167468 (* 1 = 0.167468 loss)
I0403 07:31:28.032956 21413 sgd_solver.cpp:106] Iteration 2192, lr = 0.005
I0403 07:31:39.440131 21413 solver.cpp:228] Iteration 2208, loss = 0.125296
I0403 07:31:39.440245 21413 solver.cpp:244]     Train net output #0: loss = 0.125296 (* 1 = 0.125296 loss)
I0403 07:31:39.659314 21413 sgd_solver.cpp:106] Iteration 2208, lr = 0.005
I0403 07:31:51.275094 21413 solver.cpp:228] Iteration 2224, loss = 0.0857652
I0403 07:31:51.275209 21413 solver.cpp:244]     Train net output #0: loss = 0.085765 (* 1 = 0.085765 loss)
I0403 07:31:51.469665 21413 sgd_solver.cpp:106] Iteration 2224, lr = 0.005
I0403 07:32:02.817769 21413 solver.cpp:228] Iteration 2240, loss = 0.183125
I0403 07:32:02.822078 21413 solver.cpp:244]     Train net output #0: loss = 0.183125 (* 1 = 0.183125 loss)
I0403 07:32:03.036530 21413 sgd_solver.cpp:106] Iteration 2240, lr = 0.005
I0403 07:32:14.491158 21413 solver.cpp:228] Iteration 2256, loss = 0.164303
I0403 07:32:14.491271 21413 solver.cpp:244]     Train net output #0: loss = 0.164303 (* 1 = 0.164303 loss)
I0403 07:32:14.674327 21413 sgd_solver.cpp:106] Iteration 2256, lr = 0.005
I0403 07:32:26.250746 21413 solver.cpp:228] Iteration 2272, loss = 0.248373
I0403 07:32:26.250861 21413 solver.cpp:244]     Train net output #0: loss = 0.248373 (* 1 = 0.248373 loss)
I0403 07:32:26.437165 21413 sgd_solver.cpp:106] Iteration 2272, lr = 0.005
I0403 07:32:27.892246 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_2275.caffemodel
I0403 07:32:30.670683 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_2275.solverstate
I0403 07:32:32.586019 21413 solver.cpp:337] Iteration 2275, Testing net (#0)
I0403 07:33:21.627218 21413 solver.cpp:404]     Test net output #0: accuracy = 0.922949
I0403 07:33:21.627548 21413 solver.cpp:404]     Test net output #1: loss = 0.251404 (* 1 = 0.251404 loss)
I0403 07:33:31.747038 21413 solver.cpp:228] Iteration 2288, loss = 0.232252
I0403 07:33:31.747139 21413 solver.cpp:244]     Train net output #0: loss = 0.232251 (* 1 = 0.232251 loss)
I0403 07:33:31.877426 21413 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 07:33:43.817211 21413 solver.cpp:228] Iteration 2304, loss = 0.165137
I0403 07:33:43.817328 21413 solver.cpp:244]     Train net output #0: loss = 0.165136 (* 1 = 0.165136 loss)
I0403 07:33:44.027290 21413 sgd_solver.cpp:106] Iteration 2304, lr = 0.005
I0403 07:33:55.495218 21413 solver.cpp:228] Iteration 2320, loss = 0.165561
I0403 07:33:55.495548 21413 solver.cpp:244]     Train net output #0: loss = 0.165561 (* 1 = 0.165561 loss)
I0403 07:33:55.682782 21413 sgd_solver.cpp:106] Iteration 2320, lr = 0.005
I0403 07:34:07.174326 21413 solver.cpp:228] Iteration 2336, loss = 0.201984
I0403 07:34:07.174439 21413 solver.cpp:244]     Train net output #0: loss = 0.201984 (* 1 = 0.201984 loss)
I0403 07:34:07.361606 21413 sgd_solver.cpp:106] Iteration 2336, lr = 0.005
I0403 07:34:18.771564 21413 solver.cpp:228] Iteration 2352, loss = 0.130449
I0403 07:34:18.771662 21413 solver.cpp:244]     Train net output #0: loss = 0.130449 (* 1 = 0.130449 loss)
I0403 07:34:18.953991 21413 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 07:34:30.340939 21413 solver.cpp:228] Iteration 2368, loss = 0.183906
I0403 07:34:30.341241 21413 solver.cpp:244]     Train net output #0: loss = 0.183906 (* 1 = 0.183906 loss)
I0403 07:34:30.507328 21413 sgd_solver.cpp:106] Iteration 2368, lr = 0.005
I0403 07:34:42.093636 21413 solver.cpp:228] Iteration 2384, loss = 0.07438
I0403 07:34:42.093750 21413 solver.cpp:244]     Train net output #0: loss = 0.0743798 (* 1 = 0.0743798 loss)
I0403 07:34:42.306555 21413 sgd_solver.cpp:106] Iteration 2384, lr = 0.005
I0403 07:34:53.799793 21413 solver.cpp:228] Iteration 2400, loss = 0.0727832
I0403 07:34:53.799906 21413 solver.cpp:244]     Train net output #0: loss = 0.072783 (* 1 = 0.072783 loss)
I0403 07:34:53.998575 21413 sgd_solver.cpp:106] Iteration 2400, lr = 0.005
I0403 07:35:05.798624 21413 solver.cpp:228] Iteration 2416, loss = 0.0504556
I0403 07:35:05.798972 21413 solver.cpp:244]     Train net output #0: loss = 0.0504554 (* 1 = 0.0504554 loss)
I0403 07:35:06.027549 21413 sgd_solver.cpp:106] Iteration 2416, lr = 0.005
I0403 07:35:17.714167 21413 solver.cpp:228] Iteration 2432, loss = 0.0681176
I0403 07:35:17.714269 21413 solver.cpp:244]     Train net output #0: loss = 0.0681174 (* 1 = 0.0681174 loss)
I0403 07:35:17.896765 21413 sgd_solver.cpp:106] Iteration 2432, lr = 0.005
I0403 07:35:29.363195 21413 solver.cpp:228] Iteration 2448, loss = 0.13087
I0403 07:35:29.363309 21413 solver.cpp:244]     Train net output #0: loss = 0.13087 (* 1 = 0.13087 loss)
I0403 07:35:29.556429 21413 sgd_solver.cpp:106] Iteration 2448, lr = 0.005
I0403 07:35:40.932313 21413 solver.cpp:228] Iteration 2464, loss = 0.109384
I0403 07:35:40.932670 21413 solver.cpp:244]     Train net output #0: loss = 0.109384 (* 1 = 0.109384 loss)
I0403 07:35:41.118595 21413 sgd_solver.cpp:106] Iteration 2464, lr = 0.005
I0403 07:35:52.527072 21413 solver.cpp:228] Iteration 2480, loss = 0.109021
I0403 07:35:52.527187 21413 solver.cpp:244]     Train net output #0: loss = 0.109021 (* 1 = 0.109021 loss)
I0403 07:35:52.763384 21413 sgd_solver.cpp:106] Iteration 2480, lr = 0.005
I0403 07:36:04.273926 21413 solver.cpp:228] Iteration 2496, loss = 0.195285
I0403 07:36:04.274029 21413 solver.cpp:244]     Train net output #0: loss = 0.195285 (* 1 = 0.195285 loss)
I0403 07:36:04.414631 21413 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 07:36:16.178661 21413 solver.cpp:228] Iteration 2512, loss = 0.126974
I0403 07:36:16.178995 21413 solver.cpp:244]     Train net output #0: loss = 0.126974 (* 1 = 0.126974 loss)
I0403 07:36:16.377503 21413 sgd_solver.cpp:106] Iteration 2512, lr = 0.005
I0403 07:36:27.869993 21413 solver.cpp:228] Iteration 2528, loss = 0.144117
I0403 07:36:27.870110 21413 solver.cpp:244]     Train net output #0: loss = 0.144116 (* 1 = 0.144116 loss)
I0403 07:36:28.058759 21413 sgd_solver.cpp:106] Iteration 2528, lr = 0.005
I0403 07:36:39.502501 21413 solver.cpp:228] Iteration 2544, loss = 0.052954
I0403 07:36:39.502617 21413 solver.cpp:244]     Train net output #0: loss = 0.0529538 (* 1 = 0.0529538 loss)
I0403 07:36:39.686853 21413 sgd_solver.cpp:106] Iteration 2544, lr = 0.005
I0403 07:36:51.337963 21413 solver.cpp:228] Iteration 2560, loss = 0.145785
I0403 07:36:51.338289 21413 solver.cpp:244]     Train net output #0: loss = 0.145785 (* 1 = 0.145785 loss)
I0403 07:36:51.497776 21413 sgd_solver.cpp:106] Iteration 2560, lr = 0.005
I0403 07:37:03.093107 21413 solver.cpp:228] Iteration 2576, loss = 0.132402
I0403 07:37:03.093209 21413 solver.cpp:244]     Train net output #0: loss = 0.132402 (* 1 = 0.132402 loss)
I0403 07:37:03.251432 21413 sgd_solver.cpp:106] Iteration 2576, lr = 0.005
I0403 07:37:14.864365 21413 solver.cpp:228] Iteration 2592, loss = 0.060284
I0403 07:37:14.864467 21413 solver.cpp:244]     Train net output #0: loss = 0.0602838 (* 1 = 0.0602838 loss)
I0403 07:37:15.046627 21413 sgd_solver.cpp:106] Iteration 2592, lr = 0.005
I0403 07:37:20.111656 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_2600.caffemodel
I0403 07:37:22.696441 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_2600.solverstate
I0403 07:37:24.455193 21413 solver.cpp:337] Iteration 2600, Testing net (#0)
I0403 07:38:13.498445 21413 solver.cpp:404]     Test net output #0: accuracy = 0.932719
I0403 07:38:13.498776 21413 solver.cpp:404]     Test net output #1: loss = 0.212306 (* 1 = 0.212306 loss)
I0403 07:38:19.990831 21413 solver.cpp:228] Iteration 2608, loss = 0.126936
I0403 07:38:19.990942 21413 solver.cpp:244]     Train net output #0: loss = 0.126936 (* 1 = 0.126936 loss)
I0403 07:38:20.224573 21413 sgd_solver.cpp:106] Iteration 2608, lr = 0.005
I0403 07:38:31.767272 21413 solver.cpp:228] Iteration 2624, loss = 0.0978557
I0403 07:38:31.767377 21413 solver.cpp:244]     Train net output #0: loss = 0.0978555 (* 1 = 0.0978555 loss)
I0403 07:38:31.943558 21413 sgd_solver.cpp:106] Iteration 2624, lr = 0.005
I0403 07:38:43.623661 21413 solver.cpp:228] Iteration 2640, loss = 0.118991
I0403 07:38:43.624038 21413 solver.cpp:244]     Train net output #0: loss = 0.118991 (* 1 = 0.118991 loss)
I0403 07:38:43.816623 21413 sgd_solver.cpp:106] Iteration 2640, lr = 0.005
I0403 07:38:55.411968 21413 solver.cpp:228] Iteration 2656, loss = 0.121106
I0403 07:38:55.412086 21413 solver.cpp:244]     Train net output #0: loss = 0.121106 (* 1 = 0.121106 loss)
I0403 07:38:55.601223 21413 sgd_solver.cpp:106] Iteration 2656, lr = 0.005
I0403 07:39:07.195646 21413 solver.cpp:228] Iteration 2672, loss = 0.0945785
I0403 07:39:07.195752 21413 solver.cpp:244]     Train net output #0: loss = 0.0945783 (* 1 = 0.0945783 loss)
I0403 07:39:07.374768 21413 sgd_solver.cpp:106] Iteration 2672, lr = 0.005
I0403 07:39:19.007807 21413 solver.cpp:228] Iteration 2688, loss = 0.11964
I0403 07:39:19.008141 21413 solver.cpp:244]     Train net output #0: loss = 0.11964 (* 1 = 0.11964 loss)
I0403 07:39:19.192680 21413 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 07:39:30.693348 21413 solver.cpp:228] Iteration 2704, loss = 0.158085
I0403 07:39:30.693464 21413 solver.cpp:244]     Train net output #0: loss = 0.158084 (* 1 = 0.158084 loss)
I0403 07:39:30.904247 21413 sgd_solver.cpp:106] Iteration 2704, lr = 0.005
I0403 07:39:42.529827 21413 solver.cpp:228] Iteration 2720, loss = 0.181269
I0403 07:39:42.529928 21413 solver.cpp:244]     Train net output #0: loss = 0.181268 (* 1 = 0.181268 loss)
I0403 07:39:42.701804 21413 sgd_solver.cpp:106] Iteration 2720, lr = 0.005
I0403 07:39:54.438927 21413 solver.cpp:228] Iteration 2736, loss = 0.132699
I0403 07:39:54.439311 21413 solver.cpp:244]     Train net output #0: loss = 0.132699 (* 1 = 0.132699 loss)
I0403 07:39:54.655306 21413 sgd_solver.cpp:106] Iteration 2736, lr = 0.005
I0403 07:40:06.269441 21413 solver.cpp:228] Iteration 2752, loss = 0.102241
I0403 07:40:06.269559 21413 solver.cpp:244]     Train net output #0: loss = 0.102241 (* 1 = 0.102241 loss)
I0403 07:40:06.458201 21413 sgd_solver.cpp:106] Iteration 2752, lr = 0.005
I0403 07:40:17.932672 21413 solver.cpp:228] Iteration 2768, loss = 0.0967938
I0403 07:40:17.932786 21413 solver.cpp:244]     Train net output #0: loss = 0.0967936 (* 1 = 0.0967936 loss)
I0403 07:40:18.122915 21413 sgd_solver.cpp:106] Iteration 2768, lr = 0.005
I0403 07:40:29.576833 21413 solver.cpp:228] Iteration 2784, loss = 0.148584
I0403 07:40:29.577157 21413 solver.cpp:244]     Train net output #0: loss = 0.148584 (* 1 = 0.148584 loss)
I0403 07:40:29.752785 21413 sgd_solver.cpp:106] Iteration 2784, lr = 0.005
I0403 07:40:41.329478 21413 solver.cpp:228] Iteration 2800, loss = 0.17024
I0403 07:40:41.329591 21413 solver.cpp:244]     Train net output #0: loss = 0.170239 (* 1 = 0.170239 loss)
I0403 07:40:41.503417 21413 sgd_solver.cpp:106] Iteration 2800, lr = 0.005
I0403 07:40:53.197495 21413 solver.cpp:228] Iteration 2816, loss = 0.171882
I0403 07:40:53.197615 21413 solver.cpp:244]     Train net output #0: loss = 0.171882 (* 1 = 0.171882 loss)
I0403 07:40:53.410620 21413 sgd_solver.cpp:106] Iteration 2816, lr = 0.005
I0403 07:41:04.961091 21413 solver.cpp:228] Iteration 2832, loss = 0.2136
I0403 07:41:04.961360 21413 solver.cpp:244]     Train net output #0: loss = 0.2136 (* 1 = 0.2136 loss)
I0403 07:41:05.152468 21413 sgd_solver.cpp:106] Iteration 2832, lr = 0.005
I0403 07:41:16.795074 21413 solver.cpp:228] Iteration 2848, loss = 0.204932
I0403 07:41:16.795172 21413 solver.cpp:244]     Train net output #0: loss = 0.204931 (* 1 = 0.204931 loss)
I0403 07:41:16.974997 21413 sgd_solver.cpp:106] Iteration 2848, lr = 0.005
I0403 07:41:28.503576 21413 solver.cpp:228] Iteration 2864, loss = 0.134449
I0403 07:41:28.503695 21413 solver.cpp:244]     Train net output #0: loss = 0.134449 (* 1 = 0.134449 loss)
I0403 07:41:28.687824 21413 sgd_solver.cpp:106] Iteration 2864, lr = 0.005
I0403 07:41:40.299607 21413 solver.cpp:228] Iteration 2880, loss = 0.120471
I0403 07:41:40.299949 21413 solver.cpp:244]     Train net output #0: loss = 0.120471 (* 1 = 0.120471 loss)
I0403 07:41:40.495702 21413 sgd_solver.cpp:106] Iteration 2880, lr = 0.005
I0403 07:41:52.089882 21413 solver.cpp:228] Iteration 2896, loss = 0.129094
I0403 07:41:52.089993 21413 solver.cpp:244]     Train net output #0: loss = 0.129094 (* 1 = 0.129094 loss)
I0403 07:41:52.277521 21413 sgd_solver.cpp:106] Iteration 2896, lr = 0.005
I0403 07:42:03.760938 21413 solver.cpp:228] Iteration 2912, loss = 0.0832552
I0403 07:42:03.761059 21413 solver.cpp:244]     Train net output #0: loss = 0.083255 (* 1 = 0.083255 loss)
I0403 07:42:03.948988 21413 sgd_solver.cpp:106] Iteration 2912, lr = 0.005
I0403 07:42:12.629170 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_2925.caffemodel
I0403 07:42:15.190405 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_2925.solverstate
I0403 07:42:17.933008 21413 solver.cpp:337] Iteration 2925, Testing net (#0)
I0403 07:43:06.980693 21413 solver.cpp:404]     Test net output #0: accuracy = 0.93894
I0403 07:43:06.981040 21413 solver.cpp:404]     Test net output #1: loss = 0.200946 (* 1 = 0.200946 loss)
I0403 07:43:09.725142 21413 solver.cpp:228] Iteration 2928, loss = 0.0833144
I0403 07:43:09.725255 21413 solver.cpp:244]     Train net output #0: loss = 0.0833142 (* 1 = 0.0833142 loss)
I0403 07:43:09.913250 21413 sgd_solver.cpp:106] Iteration 2928, lr = 0.005
I0403 07:43:21.255214 21413 solver.cpp:228] Iteration 2944, loss = 0.095601
I0403 07:43:21.255331 21413 solver.cpp:244]     Train net output #0: loss = 0.0956008 (* 1 = 0.0956008 loss)
I0403 07:43:21.457291 21413 sgd_solver.cpp:106] Iteration 2944, lr = 0.005
I0403 07:43:32.993402 21413 solver.cpp:228] Iteration 2960, loss = 0.0578219
I0403 07:43:32.993520 21413 solver.cpp:244]     Train net output #0: loss = 0.0578217 (* 1 = 0.0578217 loss)
I0403 07:43:33.187600 21413 sgd_solver.cpp:106] Iteration 2960, lr = 0.005
I0403 07:43:44.789286 21413 solver.cpp:228] Iteration 2976, loss = 0.103313
I0403 07:43:44.789609 21413 solver.cpp:244]     Train net output #0: loss = 0.103313 (* 1 = 0.103313 loss)
I0403 07:43:44.977175 21413 sgd_solver.cpp:106] Iteration 2976, lr = 0.005
I0403 07:43:56.355777 21413 solver.cpp:228] Iteration 2992, loss = 0.0975246
I0403 07:43:56.355892 21413 solver.cpp:244]     Train net output #0: loss = 0.0975244 (* 1 = 0.0975244 loss)
I0403 07:43:56.539829 21413 sgd_solver.cpp:106] Iteration 2992, lr = 0.005
I0403 07:44:08.140050 21413 solver.cpp:228] Iteration 3008, loss = 0.106614
I0403 07:44:08.140153 21413 solver.cpp:244]     Train net output #0: loss = 0.106613 (* 1 = 0.106613 loss)
I0403 07:44:08.322222 21413 sgd_solver.cpp:106] Iteration 3008, lr = 0.005
I0403 07:44:19.716250 21413 solver.cpp:228] Iteration 3024, loss = 0.0310199
I0403 07:44:19.716590 21413 solver.cpp:244]     Train net output #0: loss = 0.0310197 (* 1 = 0.0310197 loss)
I0403 07:44:19.936170 21413 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 07:44:31.437309 21413 solver.cpp:228] Iteration 3040, loss = 0.105925
I0403 07:44:31.437424 21413 solver.cpp:244]     Train net output #0: loss = 0.105924 (* 1 = 0.105924 loss)
I0403 07:44:31.670708 21413 sgd_solver.cpp:106] Iteration 3040, lr = 0.005
I0403 07:44:43.101068 21413 solver.cpp:228] Iteration 3056, loss = 0.143364
I0403 07:44:43.101171 21413 solver.cpp:244]     Train net output #0: loss = 0.143364 (* 1 = 0.143364 loss)
I0403 07:44:43.294245 21413 sgd_solver.cpp:106] Iteration 3056, lr = 0.005
I0403 07:44:54.644129 21413 solver.cpp:228] Iteration 3072, loss = 0.0650022
I0403 07:44:54.644512 21413 solver.cpp:244]     Train net output #0: loss = 0.065002 (* 1 = 0.065002 loss)
I0403 07:44:54.851923 21413 sgd_solver.cpp:106] Iteration 3072, lr = 0.005
I0403 07:45:06.405058 21413 solver.cpp:228] Iteration 3088, loss = 0.16793
I0403 07:45:06.405174 21413 solver.cpp:244]     Train net output #0: loss = 0.16793 (* 1 = 0.16793 loss)
I0403 07:45:06.591192 21413 sgd_solver.cpp:106] Iteration 3088, lr = 0.005
I0403 07:45:18.064056 21413 solver.cpp:228] Iteration 3104, loss = 0.108325
I0403 07:45:18.064159 21413 solver.cpp:244]     Train net output #0: loss = 0.108325 (* 1 = 0.108325 loss)
I0403 07:45:18.230037 21413 sgd_solver.cpp:106] Iteration 3104, lr = 0.005
I0403 07:45:29.834574 21413 solver.cpp:228] Iteration 3120, loss = 0.192249
I0403 07:45:29.838389 21413 solver.cpp:244]     Train net output #0: loss = 0.192249 (* 1 = 0.192249 loss)
I0403 07:45:30.031996 21413 sgd_solver.cpp:106] Iteration 3120, lr = 0.005
I0403 07:45:41.497628 21413 solver.cpp:228] Iteration 3136, loss = 0.0715616
I0403 07:45:41.497745 21413 solver.cpp:244]     Train net output #0: loss = 0.0715614 (* 1 = 0.0715614 loss)
I0403 07:45:41.739671 21413 sgd_solver.cpp:106] Iteration 3136, lr = 0.005
I0403 07:45:53.218488 21413 solver.cpp:228] Iteration 3152, loss = 0.0798437
I0403 07:45:53.218616 21413 solver.cpp:244]     Train net output #0: loss = 0.0798436 (* 1 = 0.0798436 loss)
I0403 07:45:53.403560 21413 sgd_solver.cpp:106] Iteration 3152, lr = 0.005
I0403 07:46:04.944576 21413 solver.cpp:228] Iteration 3168, loss = 0.117265
I0403 07:46:04.944900 21413 solver.cpp:244]     Train net output #0: loss = 0.117264 (* 1 = 0.117264 loss)
I0403 07:46:05.123040 21413 sgd_solver.cpp:106] Iteration 3168, lr = 0.005
I0403 07:46:16.741052 21413 solver.cpp:228] Iteration 3184, loss = 0.0472824
I0403 07:46:16.741158 21413 solver.cpp:244]     Train net output #0: loss = 0.0472822 (* 1 = 0.0472822 loss)
I0403 07:46:16.922030 21413 sgd_solver.cpp:106] Iteration 3184, lr = 0.005
I0403 07:46:28.501590 21413 solver.cpp:228] Iteration 3200, loss = 0.109705
I0403 07:46:28.501713 21413 solver.cpp:244]     Train net output #0: loss = 0.109705 (* 1 = 0.109705 loss)
I0403 07:46:28.719297 21413 sgd_solver.cpp:106] Iteration 3200, lr = 0.005
I0403 07:46:40.283138 21413 solver.cpp:228] Iteration 3216, loss = 0.213382
I0403 07:46:40.283485 21413 solver.cpp:244]     Train net output #0: loss = 0.213381 (* 1 = 0.213381 loss)
I0403 07:46:40.475527 21413 sgd_solver.cpp:106] Iteration 3216, lr = 0.005
I0403 07:46:52.164521 21413 solver.cpp:228] Iteration 3232, loss = 0.0693389
I0403 07:46:52.164628 21413 solver.cpp:244]     Train net output #0: loss = 0.0693387 (* 1 = 0.0693387 loss)
I0403 07:46:52.339473 21413 sgd_solver.cpp:106] Iteration 3232, lr = 0.005
I0403 07:47:04.079339 21413 solver.cpp:228] Iteration 3248, loss = 0.112258
I0403 07:47:04.079453 21413 solver.cpp:244]     Train net output #0: loss = 0.112258 (* 1 = 0.112258 loss)
I0403 07:47:04.273665 21413 sgd_solver.cpp:106] Iteration 3248, lr = 0.005
I0403 07:47:04.997120 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_3250.caffemodel
I0403 07:47:07.586730 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_3250.solverstate
I0403 07:47:09.299161 21413 solver.cpp:337] Iteration 3250, Testing net (#0)
I0403 07:47:58.362059 21413 solver.cpp:404]     Test net output #0: accuracy = 0.940461
I0403 07:47:58.362387 21413 solver.cpp:404]     Test net output #1: loss = 0.202094 (* 1 = 0.202094 loss)
I0403 07:48:09.118088 21413 solver.cpp:228] Iteration 3264, loss = 0.101781
I0403 07:48:09.118199 21413 solver.cpp:244]     Train net output #0: loss = 0.101781 (* 1 = 0.101781 loss)
I0403 07:48:09.324676 21413 sgd_solver.cpp:106] Iteration 3264, lr = 0.0005
I0403 07:48:20.924592 21413 solver.cpp:228] Iteration 3280, loss = 0.0768946
I0403 07:48:20.924707 21413 solver.cpp:244]     Train net output #0: loss = 0.0768944 (* 1 = 0.0768944 loss)
I0403 07:48:21.134888 21413 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 07:48:32.668964 21413 solver.cpp:228] Iteration 3296, loss = 0.0257098
I0403 07:48:32.669306 21413 solver.cpp:244]     Train net output #0: loss = 0.0257096 (* 1 = 0.0257096 loss)
I0403 07:48:32.859288 21413 sgd_solver.cpp:106] Iteration 3296, lr = 0.0005
I0403 07:48:44.288272 21413 solver.cpp:228] Iteration 3312, loss = 0.0305509
I0403 07:48:44.288389 21413 solver.cpp:244]     Train net output #0: loss = 0.0305507 (* 1 = 0.0305507 loss)
I0403 07:48:44.476733 21413 sgd_solver.cpp:106] Iteration 3312, lr = 0.0005
I0403 07:48:55.895859 21413 solver.cpp:228] Iteration 3328, loss = 0.0164916
I0403 07:48:55.895972 21413 solver.cpp:244]     Train net output #0: loss = 0.0164914 (* 1 = 0.0164914 loss)
I0403 07:48:56.078346 21413 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 07:49:07.476229 21413 solver.cpp:228] Iteration 3344, loss = 0.115785
I0403 07:49:07.476608 21413 solver.cpp:244]     Train net output #0: loss = 0.115785 (* 1 = 0.115785 loss)
I0403 07:49:07.699939 21413 sgd_solver.cpp:106] Iteration 3344, lr = 0.0005
I0403 07:49:19.239645 21413 solver.cpp:228] Iteration 3360, loss = 0.011139
I0403 07:49:19.239743 21413 solver.cpp:244]     Train net output #0: loss = 0.0111388 (* 1 = 0.0111388 loss)
I0403 07:49:19.401571 21413 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 07:49:31.227859 21413 solver.cpp:228] Iteration 3376, loss = 0.020908
I0403 07:49:31.227973 21413 solver.cpp:244]     Train net output #0: loss = 0.0209078 (* 1 = 0.0209078 loss)
I0403 07:49:31.439373 21413 sgd_solver.cpp:106] Iteration 3376, lr = 0.0005
I0403 07:49:43.073590 21413 solver.cpp:228] Iteration 3392, loss = 0.00979143
I0403 07:49:43.073897 21413 solver.cpp:244]     Train net output #0: loss = 0.00979122 (* 1 = 0.00979122 loss)
I0403 07:49:43.247262 21413 sgd_solver.cpp:106] Iteration 3392, lr = 0.0005
I0403 07:49:54.954104 21413 solver.cpp:228] Iteration 3408, loss = 0.0274975
I0403 07:49:54.954205 21413 solver.cpp:244]     Train net output #0: loss = 0.0274973 (* 1 = 0.0274973 loss)
I0403 07:49:55.135823 21413 sgd_solver.cpp:106] Iteration 3408, lr = 0.0005
I0403 07:50:06.629665 21413 solver.cpp:228] Iteration 3424, loss = 0.049538
I0403 07:50:06.629779 21413 solver.cpp:244]     Train net output #0: loss = 0.0495378 (* 1 = 0.0495378 loss)
I0403 07:50:06.819006 21413 sgd_solver.cpp:106] Iteration 3424, lr = 0.0005
I0403 07:50:18.349819 21413 solver.cpp:228] Iteration 3440, loss = 0.0710828
I0403 07:50:18.350100 21413 solver.cpp:244]     Train net output #0: loss = 0.0710826 (* 1 = 0.0710826 loss)
I0403 07:50:18.522368 21413 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 07:50:29.917201 21413 solver.cpp:228] Iteration 3456, loss = 0.0863473
I0403 07:50:29.917316 21413 solver.cpp:244]     Train net output #0: loss = 0.0863471 (* 1 = 0.0863471 loss)
I0403 07:50:30.106287 21413 sgd_solver.cpp:106] Iteration 3456, lr = 0.0005
I0403 07:50:41.793539 21413 solver.cpp:228] Iteration 3472, loss = 0.00659354
I0403 07:50:41.793654 21413 solver.cpp:244]     Train net output #0: loss = 0.00659333 (* 1 = 0.00659333 loss)
I0403 07:50:41.995656 21413 sgd_solver.cpp:106] Iteration 3472, lr = 0.0005
I0403 07:50:53.451458 21413 solver.cpp:228] Iteration 3488, loss = 0.032354
I0403 07:50:53.451802 21413 solver.cpp:244]     Train net output #0: loss = 0.0323538 (* 1 = 0.0323538 loss)
I0403 07:50:53.643123 21413 sgd_solver.cpp:106] Iteration 3488, lr = 0.0005
I0403 07:51:05.317832 21413 solver.cpp:228] Iteration 3504, loss = 0.0160251
I0403 07:51:05.317947 21413 solver.cpp:244]     Train net output #0: loss = 0.0160249 (* 1 = 0.0160249 loss)
I0403 07:51:05.516309 21413 sgd_solver.cpp:106] Iteration 3504, lr = 0.0005
I0403 07:51:17.146977 21413 solver.cpp:228] Iteration 3520, loss = 0.0296261
I0403 07:51:17.147088 21413 solver.cpp:244]     Train net output #0: loss = 0.0296258 (* 1 = 0.0296258 loss)
I0403 07:51:17.332711 21413 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 07:51:28.844046 21413 solver.cpp:228] Iteration 3536, loss = 0.0809397
I0403 07:51:28.844385 21413 solver.cpp:244]     Train net output #0: loss = 0.0809395 (* 1 = 0.0809395 loss)
I0403 07:51:29.043725 21413 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 07:51:40.560818 21413 solver.cpp:228] Iteration 3552, loss = 0.116882
I0403 07:51:40.560932 21413 solver.cpp:244]     Train net output #0: loss = 0.116882 (* 1 = 0.116882 loss)
I0403 07:51:40.767333 21413 sgd_solver.cpp:106] Iteration 3552, lr = 0.0005
I0403 07:51:52.270102 21413 solver.cpp:228] Iteration 3568, loss = 0.0601838
I0403 07:51:52.270205 21413 solver.cpp:244]     Train net output #0: loss = 0.0601836 (* 1 = 0.0601836 loss)
I0403 07:51:52.415674 21413 sgd_solver.cpp:106] Iteration 3568, lr = 0.0005
I0403 07:51:56.886971 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_3575.caffemodel
I0403 07:51:59.524577 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_3575.solverstate
I0403 07:52:01.305599 21413 solver.cpp:337] Iteration 3575, Testing net (#0)
I0403 07:52:50.366077 21413 solver.cpp:404]     Test net output #0: accuracy = 0.955622
I0403 07:52:50.366410 21413 solver.cpp:404]     Test net output #1: loss = 0.149844 (* 1 = 0.149844 loss)
I0403 07:52:57.567468 21413 solver.cpp:228] Iteration 3584, loss = 0.030299
I0403 07:52:57.567574 21413 solver.cpp:244]     Train net output #0: loss = 0.0302988 (* 1 = 0.0302988 loss)
I0403 07:52:57.725318 21413 sgd_solver.cpp:106] Iteration 3584, lr = 0.0005
I0403 07:53:09.443625 21413 solver.cpp:228] Iteration 3600, loss = 0.0163327
I0403 07:53:09.443727 21413 solver.cpp:244]     Train net output #0: loss = 0.0163325 (* 1 = 0.0163325 loss)
I0403 07:53:09.618270 21413 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 07:53:21.119093 21413 solver.cpp:228] Iteration 3616, loss = 0.0033722
I0403 07:53:21.119420 21413 solver.cpp:244]     Train net output #0: loss = 0.00337198 (* 1 = 0.00337198 loss)
I0403 07:53:21.315443 21413 sgd_solver.cpp:106] Iteration 3616, lr = 0.0005
I0403 07:53:32.921735 21413 solver.cpp:228] Iteration 3632, loss = 0.0203943
I0403 07:53:32.921844 21413 solver.cpp:244]     Train net output #0: loss = 0.0203941 (* 1 = 0.0203941 loss)
I0403 07:53:33.153575 21413 sgd_solver.cpp:106] Iteration 3632, lr = 0.0005
I0403 07:53:44.743463 21413 solver.cpp:228] Iteration 3648, loss = 0.00930507
I0403 07:53:44.743588 21413 solver.cpp:244]     Train net output #0: loss = 0.00930486 (* 1 = 0.00930486 loss)
I0403 07:53:44.959480 21413 sgd_solver.cpp:106] Iteration 3648, lr = 0.0005
I0403 07:53:56.522912 21413 solver.cpp:228] Iteration 3664, loss = 0.0470739
I0403 07:53:56.523257 21413 solver.cpp:244]     Train net output #0: loss = 0.0470737 (* 1 = 0.0470737 loss)
I0403 07:53:56.706962 21413 sgd_solver.cpp:106] Iteration 3664, lr = 0.0005
I0403 07:54:08.245965 21413 solver.cpp:228] Iteration 3680, loss = 0.026717
I0403 07:54:08.246081 21413 solver.cpp:244]     Train net output #0: loss = 0.0267168 (* 1 = 0.0267168 loss)
I0403 07:54:08.435348 21413 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 07:54:20.003474 21413 solver.cpp:228] Iteration 3696, loss = 0.00597978
I0403 07:54:20.003585 21413 solver.cpp:244]     Train net output #0: loss = 0.00597957 (* 1 = 0.00597957 loss)
I0403 07:54:20.141670 21413 sgd_solver.cpp:106] Iteration 3696, lr = 0.0005
I0403 07:54:31.853121 21413 solver.cpp:228] Iteration 3712, loss = 0.0160015
I0403 07:54:31.853420 21413 solver.cpp:244]     Train net output #0: loss = 0.0160013 (* 1 = 0.0160013 loss)
I0403 07:54:32.045069 21413 sgd_solver.cpp:106] Iteration 3712, lr = 0.0005
I0403 07:54:43.760587 21413 solver.cpp:228] Iteration 3728, loss = 0.0388633
I0403 07:54:43.760699 21413 solver.cpp:244]     Train net output #0: loss = 0.0388631 (* 1 = 0.0388631 loss)
I0403 07:54:43.979430 21413 sgd_solver.cpp:106] Iteration 3728, lr = 0.0005
I0403 07:54:55.476169 21413 solver.cpp:228] Iteration 3744, loss = 0.0439728
I0403 07:54:55.476271 21413 solver.cpp:244]     Train net output #0: loss = 0.0439726 (* 1 = 0.0439726 loss)
I0403 07:54:55.655146 21413 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 07:55:07.397022 21413 solver.cpp:228] Iteration 3760, loss = 0.039831
I0403 07:55:07.397370 21413 solver.cpp:244]     Train net output #0: loss = 0.0398308 (* 1 = 0.0398308 loss)
I0403 07:55:07.609433 21413 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 07:55:19.040690 21413 solver.cpp:228] Iteration 3776, loss = 0.00989819
I0403 07:55:19.040804 21413 solver.cpp:244]     Train net output #0: loss = 0.00989798 (* 1 = 0.00989798 loss)
I0403 07:55:19.225150 21413 sgd_solver.cpp:106] Iteration 3776, lr = 0.0005
I0403 07:55:30.711758 21413 solver.cpp:228] Iteration 3792, loss = 0.0399614
I0403 07:55:30.711871 21413 solver.cpp:244]     Train net output #0: loss = 0.0399612 (* 1 = 0.0399612 loss)
I0403 07:55:30.922415 21413 sgd_solver.cpp:106] Iteration 3792, lr = 0.0005
I0403 07:55:42.414237 21413 solver.cpp:228] Iteration 3808, loss = 0.0546195
I0403 07:55:42.414631 21413 solver.cpp:244]     Train net output #0: loss = 0.0546192 (* 1 = 0.0546192 loss)
I0403 07:55:42.656338 21413 sgd_solver.cpp:106] Iteration 3808, lr = 0.0005
I0403 07:55:54.186295 21413 solver.cpp:228] Iteration 3824, loss = 0.0609877
I0403 07:55:54.186406 21413 solver.cpp:244]     Train net output #0: loss = 0.0609874 (* 1 = 0.0609874 loss)
I0403 07:55:54.382534 21413 sgd_solver.cpp:106] Iteration 3824, lr = 0.0005
I0403 07:56:06.229017 21413 solver.cpp:228] Iteration 3840, loss = 0.0463819
I0403 07:56:06.229121 21413 solver.cpp:244]     Train net output #0: loss = 0.0463817 (* 1 = 0.0463817 loss)
I0403 07:56:06.409080 21413 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 07:56:18.050516 21413 solver.cpp:228] Iteration 3856, loss = 0.0530742
I0403 07:56:18.050860 21413 solver.cpp:244]     Train net output #0: loss = 0.053074 (* 1 = 0.053074 loss)
I0403 07:56:18.233439 21413 sgd_solver.cpp:106] Iteration 3856, lr = 0.0005
I0403 07:56:30.002511 21413 solver.cpp:228] Iteration 3872, loss = 0.0594405
I0403 07:56:30.002617 21413 solver.cpp:244]     Train net output #0: loss = 0.0594403 (* 1 = 0.0594403 loss)
I0403 07:56:30.176791 21413 sgd_solver.cpp:106] Iteration 3872, lr = 0.0005
I0403 07:56:41.826935 21413 solver.cpp:228] Iteration 3888, loss = 0.0358545
I0403 07:56:41.827049 21413 solver.cpp:244]     Train net output #0: loss = 0.0358543 (* 1 = 0.0358543 loss)
I0403 07:56:42.073431 21413 sgd_solver.cpp:106] Iteration 3888, lr = 0.0005
I0403 07:56:50.249122 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_3900.caffemodel
I0403 07:56:52.985092 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_3900.solverstate
I0403 07:56:54.878813 21413 solver.cpp:337] Iteration 3900, Testing net (#0)
I0403 07:57:43.940919 21413 solver.cpp:404]     Test net output #0: accuracy = 0.95636
I0403 07:57:43.941244 21413 solver.cpp:404]     Test net output #1: loss = 0.149374 (* 1 = 0.149374 loss)
I0403 07:57:47.370681 21413 solver.cpp:228] Iteration 3904, loss = 0.0440532
I0403 07:57:47.370793 21413 solver.cpp:244]     Train net output #0: loss = 0.044053 (* 1 = 0.044053 loss)
I0403 07:57:47.554328 21413 sgd_solver.cpp:106] Iteration 3904, lr = 0.0005
I0403 07:57:59.077440 21413 solver.cpp:228] Iteration 3920, loss = 0.0403271
I0403 07:57:59.077543 21413 solver.cpp:244]     Train net output #0: loss = 0.0403269 (* 1 = 0.0403269 loss)
I0403 07:57:59.245952 21413 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 07:58:10.953646 21413 solver.cpp:228] Iteration 3936, loss = 0.0229402
I0403 07:58:10.953749 21413 solver.cpp:244]     Train net output #0: loss = 0.02294 (* 1 = 0.02294 loss)
I0403 07:58:11.146855 21413 sgd_solver.cpp:106] Iteration 3936, lr = 0.0005
I0403 07:58:22.632791 21413 solver.cpp:228] Iteration 3952, loss = 0.016155
I0403 07:58:22.633133 21413 solver.cpp:244]     Train net output #0: loss = 0.0161548 (* 1 = 0.0161548 loss)
I0403 07:58:22.818402 21413 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 07:58:34.222889 21413 solver.cpp:228] Iteration 3968, loss = 0.0388138
I0403 07:58:34.223011 21413 solver.cpp:244]     Train net output #0: loss = 0.0388137 (* 1 = 0.0388137 loss)
I0403 07:58:34.417577 21413 sgd_solver.cpp:106] Iteration 3968, lr = 0.0005
I0403 07:58:45.931020 21413 solver.cpp:228] Iteration 3984, loss = 0.0227981
I0403 07:58:45.931131 21413 solver.cpp:244]     Train net output #0: loss = 0.0227979 (* 1 = 0.0227979 loss)
I0403 07:58:46.126528 21413 sgd_solver.cpp:106] Iteration 3984, lr = 0.0005
I0403 07:58:57.642987 21413 solver.cpp:228] Iteration 4000, loss = 0.0590882
I0403 07:58:57.643362 21413 solver.cpp:244]     Train net output #0: loss = 0.059088 (* 1 = 0.059088 loss)
I0403 07:58:57.827978 21413 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 07:59:09.423638 21413 solver.cpp:228] Iteration 4016, loss = 0.00676059
I0403 07:59:09.423754 21413 solver.cpp:244]     Train net output #0: loss = 0.0067604 (* 1 = 0.0067604 loss)
I0403 07:59:09.689882 21413 sgd_solver.cpp:106] Iteration 4016, lr = 0.0005
I0403 07:59:21.209525 21413 solver.cpp:228] Iteration 4032, loss = 0.020543
I0403 07:59:21.209656 21413 solver.cpp:244]     Train net output #0: loss = 0.0205428 (* 1 = 0.0205428 loss)
I0403 07:59:21.393039 21413 sgd_solver.cpp:106] Iteration 4032, lr = 0.0005
I0403 07:59:33.084081 21413 solver.cpp:228] Iteration 4048, loss = 0.0162729
I0403 07:59:33.084417 21413 solver.cpp:244]     Train net output #0: loss = 0.0162727 (* 1 = 0.0162727 loss)
I0403 07:59:33.281368 21413 sgd_solver.cpp:106] Iteration 4048, lr = 0.0005
I0403 07:59:44.818552 21413 solver.cpp:228] Iteration 4064, loss = 0.10488
I0403 07:59:44.818665 21413 solver.cpp:244]     Train net output #0: loss = 0.104879 (* 1 = 0.104879 loss)
I0403 07:59:45.002625 21413 sgd_solver.cpp:106] Iteration 4064, lr = 0.0005
I0403 07:59:56.591657 21413 solver.cpp:228] Iteration 4080, loss = 0.0262389
I0403 07:59:56.591774 21413 solver.cpp:244]     Train net output #0: loss = 0.0262387 (* 1 = 0.0262387 loss)
I0403 07:59:56.787564 21413 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 08:00:08.379412 21413 solver.cpp:228] Iteration 4096, loss = 0.0787169
I0403 08:00:08.379766 21413 solver.cpp:244]     Train net output #0: loss = 0.0787167 (* 1 = 0.0787167 loss)
I0403 08:00:08.575670 21413 sgd_solver.cpp:106] Iteration 4096, lr = 0.0005
I0403 08:00:20.059245 21413 solver.cpp:228] Iteration 4112, loss = 0.0500866
I0403 08:00:20.059358 21413 solver.cpp:244]     Train net output #0: loss = 0.0500864 (* 1 = 0.0500864 loss)
I0403 08:00:20.287472 21413 sgd_solver.cpp:106] Iteration 4112, lr = 0.0005
I0403 08:00:31.805147 21413 solver.cpp:228] Iteration 4128, loss = 0.0145065
I0403 08:00:31.805263 21413 solver.cpp:244]     Train net output #0: loss = 0.0145063 (* 1 = 0.0145063 loss)
I0403 08:00:31.996013 21413 sgd_solver.cpp:106] Iteration 4128, lr = 0.0005
I0403 08:00:43.485415 21413 solver.cpp:228] Iteration 4144, loss = 0.0723795
I0403 08:00:43.485733 21413 solver.cpp:244]     Train net output #0: loss = 0.0723794 (* 1 = 0.0723794 loss)
I0403 08:00:43.672194 21413 sgd_solver.cpp:106] Iteration 4144, lr = 0.0005
I0403 08:00:55.177942 21413 solver.cpp:228] Iteration 4160, loss = 0.0810732
I0403 08:00:55.178052 21413 solver.cpp:244]     Train net output #0: loss = 0.081073 (* 1 = 0.081073 loss)
I0403 08:00:55.376601 21413 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 08:01:07.240486 21413 solver.cpp:228] Iteration 4176, loss = 0.00618997
I0403 08:01:07.240598 21413 solver.cpp:244]     Train net output #0: loss = 0.00618981 (* 1 = 0.00618981 loss)
I0403 08:01:07.445768 21413 sgd_solver.cpp:106] Iteration 4176, lr = 0.0005
I0403 08:01:19.123361 21413 solver.cpp:228] Iteration 4192, loss = 0.0195817
I0403 08:01:19.123704 21413 solver.cpp:244]     Train net output #0: loss = 0.0195815 (* 1 = 0.0195815 loss)
I0403 08:01:19.327061 21413 sgd_solver.cpp:106] Iteration 4192, lr = 0.0005
I0403 08:01:30.750284 21413 solver.cpp:228] Iteration 4208, loss = 0.0391684
I0403 08:01:30.750386 21413 solver.cpp:244]     Train net output #0: loss = 0.0391682 (* 1 = 0.0391682 loss)
I0403 08:01:30.927055 21413 sgd_solver.cpp:106] Iteration 4208, lr = 0.0005
I0403 08:01:42.344249 21413 solver.cpp:228] Iteration 4224, loss = 0.0357955
I0403 08:01:42.344357 21413 solver.cpp:244]     Train net output #0: loss = 0.0357954 (* 1 = 0.0357954 loss)
I0403 08:01:42.519176 21413 sgd_solver.cpp:106] Iteration 4224, lr = 0.0005
I0403 08:01:42.519404 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_4225.caffemodel
I0403 08:01:45.153518 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_4225.solverstate
I0403 08:01:46.887256 21413 solver.cpp:337] Iteration 4225, Testing net (#0)
I0403 08:02:35.933084 21413 solver.cpp:404]     Test net output #0: accuracy = 0.957235
I0403 08:02:35.933447 21413 solver.cpp:404]     Test net output #1: loss = 0.148061 (* 1 = 0.148061 loss)
I0403 08:02:47.460527 21413 solver.cpp:228] Iteration 4240, loss = 0.00747865
I0403 08:02:47.460628 21413 solver.cpp:244]     Train net output #0: loss = 0.0074785 (* 1 = 0.0074785 loss)
I0403 08:02:47.634593 21413 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 08:02:59.224609 21413 solver.cpp:228] Iteration 4256, loss = 0.0416446
I0403 08:02:59.224720 21413 solver.cpp:244]     Train net output #0: loss = 0.0416444 (* 1 = 0.0416444 loss)
I0403 08:02:59.407934 21413 sgd_solver.cpp:106] Iteration 4256, lr = 0.0005
I0403 08:03:10.961072 21413 solver.cpp:228] Iteration 4272, loss = 0.0167409
I0403 08:03:10.961392 21413 solver.cpp:244]     Train net output #0: loss = 0.0167407 (* 1 = 0.0167407 loss)
I0403 08:03:11.144332 21413 sgd_solver.cpp:106] Iteration 4272, lr = 0.0005
I0403 08:03:22.692159 21413 solver.cpp:228] Iteration 4288, loss = 0.0439878
I0403 08:03:22.692273 21413 solver.cpp:244]     Train net output #0: loss = 0.0439877 (* 1 = 0.0439877 loss)
I0403 08:03:22.877471 21413 sgd_solver.cpp:106] Iteration 4288, lr = 0.0005
I0403 08:03:34.406208 21413 solver.cpp:228] Iteration 4304, loss = 0.0206881
I0403 08:03:34.406322 21413 solver.cpp:244]     Train net output #0: loss = 0.0206879 (* 1 = 0.0206879 loss)
I0403 08:03:34.588999 21413 sgd_solver.cpp:106] Iteration 4304, lr = 0.0005
I0403 08:03:46.101438 21413 solver.cpp:228] Iteration 4320, loss = 0.026975
I0403 08:03:46.103694 21413 solver.cpp:244]     Train net output #0: loss = 0.0269748 (* 1 = 0.0269748 loss)
I0403 08:03:46.283933 21413 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 08:03:57.813863 21413 solver.cpp:228] Iteration 4336, loss = 0.0330543
I0403 08:03:57.813962 21413 solver.cpp:244]     Train net output #0: loss = 0.0330541 (* 1 = 0.0330541 loss)
I0403 08:03:57.989836 21413 sgd_solver.cpp:106] Iteration 4336, lr = 0.0005
I0403 08:04:09.474387 21413 solver.cpp:228] Iteration 4352, loss = 0.00318468
I0403 08:04:09.474509 21413 solver.cpp:244]     Train net output #0: loss = 0.00318451 (* 1 = 0.00318451 loss)
I0403 08:04:09.682476 21413 sgd_solver.cpp:106] Iteration 4352, lr = 0.0005
I0403 08:04:21.123953 21413 solver.cpp:228] Iteration 4368, loss = 0.00878865
I0403 08:04:21.124289 21413 solver.cpp:244]     Train net output #0: loss = 0.00878848 (* 1 = 0.00878848 loss)
I0403 08:04:21.312304 21413 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 08:04:32.881031 21413 solver.cpp:228] Iteration 4384, loss = 0.044176
I0403 08:04:32.881142 21413 solver.cpp:244]     Train net output #0: loss = 0.0441759 (* 1 = 0.0441759 loss)
I0403 08:04:33.095336 21413 sgd_solver.cpp:106] Iteration 4384, lr = 0.0005
I0403 08:04:44.777931 21413 solver.cpp:228] Iteration 4400, loss = 0.0149949
I0403 08:04:44.778048 21413 solver.cpp:244]     Train net output #0: loss = 0.0149947 (* 1 = 0.0149947 loss)
I0403 08:04:44.975231 21413 sgd_solver.cpp:106] Iteration 4400, lr = 0.0005
I0403 08:04:56.563897 21413 solver.cpp:228] Iteration 4416, loss = 0.102815
I0403 08:04:56.564241 21413 solver.cpp:244]     Train net output #0: loss = 0.102814 (* 1 = 0.102814 loss)
I0403 08:04:56.750576 21413 sgd_solver.cpp:106] Iteration 4416, lr = 0.0005
I0403 08:05:08.163241 21413 solver.cpp:228] Iteration 4432, loss = 0.0296814
I0403 08:05:08.163354 21413 solver.cpp:244]     Train net output #0: loss = 0.0296812 (* 1 = 0.0296812 loss)
I0403 08:05:08.362251 21413 sgd_solver.cpp:106] Iteration 4432, lr = 0.0005
I0403 08:05:19.927723 21413 solver.cpp:228] Iteration 4448, loss = 0.0378767
I0403 08:05:19.927822 21413 solver.cpp:244]     Train net output #0: loss = 0.0378765 (* 1 = 0.0378765 loss)
I0403 08:05:20.108496 21413 sgd_solver.cpp:106] Iteration 4448, lr = 0.0005
I0403 08:05:31.739563 21413 solver.cpp:228] Iteration 4464, loss = 0.0512783
I0403 08:05:31.739943 21413 solver.cpp:244]     Train net output #0: loss = 0.0512781 (* 1 = 0.0512781 loss)
I0403 08:05:31.922830 21413 sgd_solver.cpp:106] Iteration 4464, lr = 0.0005
I0403 08:05:43.481837 21413 solver.cpp:228] Iteration 4480, loss = 0.00384519
I0403 08:05:43.481946 21413 solver.cpp:244]     Train net output #0: loss = 0.003845 (* 1 = 0.003845 loss)
I0403 08:05:43.686350 21413 sgd_solver.cpp:106] Iteration 4480, lr = 0.0005
I0403 08:05:55.139402 21413 solver.cpp:228] Iteration 4496, loss = 0.014495
I0403 08:05:55.139523 21413 solver.cpp:244]     Train net output #0: loss = 0.0144949 (* 1 = 0.0144949 loss)
I0403 08:05:55.420207 21413 sgd_solver.cpp:106] Iteration 4496, lr = 0.0005
I0403 08:06:06.878211 21413 solver.cpp:228] Iteration 4512, loss = 0.0652082
I0403 08:06:06.878535 21413 solver.cpp:244]     Train net output #0: loss = 0.065208 (* 1 = 0.065208 loss)
I0403 08:06:07.052484 21413 sgd_solver.cpp:106] Iteration 4512, lr = 0.0005
I0403 08:06:18.642688 21413 solver.cpp:228] Iteration 4528, loss = 0.0479138
I0403 08:06:18.642787 21413 solver.cpp:244]     Train net output #0: loss = 0.0479136 (* 1 = 0.0479136 loss)
I0403 08:06:18.824455 21413 sgd_solver.cpp:106] Iteration 4528, lr = 0.0005
I0403 08:06:30.522734 21413 solver.cpp:228] Iteration 4544, loss = 0.0176282
I0403 08:06:30.522848 21413 solver.cpp:244]     Train net output #0: loss = 0.0176281 (* 1 = 0.0176281 loss)
I0403 08:06:30.722085 21413 sgd_solver.cpp:106] Iteration 4544, lr = 0.0005
I0403 08:06:34.371623 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_4550.caffemodel
I0403 08:06:37.118183 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_4550.solverstate
I0403 08:06:39.000315 21413 solver.cpp:337] Iteration 4550, Testing net (#0)
I0403 08:07:28.059007 21413 solver.cpp:404]     Test net output #0: accuracy = 0.957696
I0403 08:07:28.059355 21413 solver.cpp:404]     Test net output #1: loss = 0.152523 (* 1 = 0.152523 loss)
I0403 08:07:36.000394 21413 solver.cpp:228] Iteration 4560, loss = 0.0233466
I0403 08:07:36.000509 21413 solver.cpp:244]     Train net output #0: loss = 0.0233465 (* 1 = 0.0233465 loss)
I0403 08:07:36.184214 21413 sgd_solver.cpp:106] Iteration 4560, lr = 0.0005
I0403 08:07:47.872387 21413 solver.cpp:228] Iteration 4576, loss = 0.0225247
I0403 08:07:47.872500 21413 solver.cpp:244]     Train net output #0: loss = 0.0225245 (* 1 = 0.0225245 loss)
I0403 08:07:48.060281 21413 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 08:07:59.638844 21413 solver.cpp:228] Iteration 4592, loss = 0.00865066
I0403 08:07:59.639149 21413 solver.cpp:244]     Train net output #0: loss = 0.00865047 (* 1 = 0.00865047 loss)
I0403 08:07:59.826982 21413 sgd_solver.cpp:106] Iteration 4592, lr = 0.0005
I0403 08:08:11.353639 21413 solver.cpp:228] Iteration 4608, loss = 0.0280516
I0403 08:08:11.353751 21413 solver.cpp:244]     Train net output #0: loss = 0.0280515 (* 1 = 0.0280515 loss)
I0403 08:08:11.540048 21413 sgd_solver.cpp:106] Iteration 4608, lr = 0.0005
I0403 08:08:22.997568 21413 solver.cpp:228] Iteration 4624, loss = 0.0219858
I0403 08:08:22.997689 21413 solver.cpp:244]     Train net output #0: loss = 0.0219856 (* 1 = 0.0219856 loss)
I0403 08:08:23.215807 21413 sgd_solver.cpp:106] Iteration 4624, lr = 0.0005
I0403 08:08:34.758764 21413 solver.cpp:228] Iteration 4640, loss = 0.0210476
I0403 08:08:34.763077 21413 solver.cpp:244]     Train net output #0: loss = 0.0210474 (* 1 = 0.0210474 loss)
I0403 08:08:34.918517 21413 sgd_solver.cpp:106] Iteration 4640, lr = 0.0005
I0403 08:08:46.581584 21413 solver.cpp:228] Iteration 4656, loss = 0.00335278
I0403 08:08:46.581701 21413 solver.cpp:244]     Train net output #0: loss = 0.00335258 (* 1 = 0.00335258 loss)
I0403 08:08:46.823287 21413 sgd_solver.cpp:106] Iteration 4656, lr = 0.0005
I0403 08:08:58.460546 21413 solver.cpp:228] Iteration 4672, loss = 0.033852
I0403 08:08:58.460664 21413 solver.cpp:244]     Train net output #0: loss = 0.0338518 (* 1 = 0.0338518 loss)
I0403 08:08:58.666674 21413 sgd_solver.cpp:106] Iteration 4672, lr = 0.0005
I0403 08:09:10.210191 21413 solver.cpp:228] Iteration 4688, loss = 0.000339698
I0403 08:09:10.210536 21413 solver.cpp:244]     Train net output #0: loss = 0.000339497 (* 1 = 0.000339497 loss)
I0403 08:09:10.423058 21413 sgd_solver.cpp:106] Iteration 4688, lr = 0.0005
I0403 08:09:22.089859 21413 solver.cpp:228] Iteration 4704, loss = 0.00917149
I0403 08:09:22.089962 21413 solver.cpp:244]     Train net output #0: loss = 0.00917128 (* 1 = 0.00917128 loss)
I0403 08:09:22.266763 21413 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 08:09:33.759174 21413 solver.cpp:228] Iteration 4720, loss = 0.028383
I0403 08:09:33.759299 21413 solver.cpp:244]     Train net output #0: loss = 0.0283828 (* 1 = 0.0283828 loss)
I0403 08:09:33.946205 21413 sgd_solver.cpp:106] Iteration 4720, lr = 0.0005
I0403 08:09:45.542109 21413 solver.cpp:228] Iteration 4736, loss = 0.00900234
I0403 08:09:45.542429 21413 solver.cpp:244]     Train net output #0: loss = 0.00900214 (* 1 = 0.00900214 loss)
I0403 08:09:45.725756 21413 sgd_solver.cpp:106] Iteration 4736, lr = 0.0005
I0403 08:09:57.284566 21413 solver.cpp:228] Iteration 4752, loss = 0.00778165
I0403 08:09:57.284656 21413 solver.cpp:244]     Train net output #0: loss = 0.00778145 (* 1 = 0.00778145 loss)
I0403 08:09:57.478139 21413 sgd_solver.cpp:106] Iteration 4752, lr = 0.0005
I0403 08:10:09.004050 21413 solver.cpp:228] Iteration 4768, loss = 0.0324076
I0403 08:10:09.004166 21413 solver.cpp:244]     Train net output #0: loss = 0.0324074 (* 1 = 0.0324074 loss)
I0403 08:10:09.254961 21413 sgd_solver.cpp:106] Iteration 4768, lr = 0.0005
I0403 08:10:20.713332 21413 solver.cpp:228] Iteration 4784, loss = 0.00951535
I0403 08:10:20.713675 21413 solver.cpp:244]     Train net output #0: loss = 0.00951515 (* 1 = 0.00951515 loss)
I0403 08:10:20.988934 21413 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 08:10:32.460458 21413 solver.cpp:228] Iteration 4800, loss = 0.0541128
I0403 08:10:32.460561 21413 solver.cpp:244]     Train net output #0: loss = 0.0541126 (* 1 = 0.0541126 loss)
I0403 08:10:32.638339 21413 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0403 08:10:44.383559 21413 solver.cpp:228] Iteration 4816, loss = 0.0905276
I0403 08:10:44.383669 21413 solver.cpp:244]     Train net output #0: loss = 0.0905274 (* 1 = 0.0905274 loss)
I0403 08:10:44.566090 21413 sgd_solver.cpp:106] Iteration 4816, lr = 0.0005
I0403 08:10:56.189544 21413 solver.cpp:228] Iteration 4832, loss = 0.0101007
I0403 08:10:56.189865 21413 solver.cpp:244]     Train net output #0: loss = 0.0101005 (* 1 = 0.0101005 loss)
I0403 08:10:56.368337 21413 sgd_solver.cpp:106] Iteration 4832, lr = 0.0005
I0403 08:11:07.839262 21413 solver.cpp:228] Iteration 4848, loss = 0.0160588
I0403 08:11:07.839375 21413 solver.cpp:244]     Train net output #0: loss = 0.0160586 (* 1 = 0.0160586 loss)
I0403 08:11:08.023530 21413 sgd_solver.cpp:106] Iteration 4848, lr = 0.0005
I0403 08:11:19.483847 21413 solver.cpp:228] Iteration 4864, loss = 0.052938
I0403 08:11:19.483963 21413 solver.cpp:244]     Train net output #0: loss = 0.0529378 (* 1 = 0.0529378 loss)
I0403 08:11:19.677255 21413 sgd_solver.cpp:106] Iteration 4864, lr = 0.0005
I0403 08:11:26.983408 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_4875.caffemodel
I0403 08:11:29.622051 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_4875.solverstate
I0403 08:11:31.851829 21413 solver.cpp:337] Iteration 4875, Testing net (#0)
I0403 08:12:20.913981 21413 solver.cpp:404]     Test net output #0: accuracy = 0.957143
I0403 08:12:20.914315 21413 solver.cpp:404]     Test net output #1: loss = 0.152655 (* 1 = 0.152655 loss)
I0403 08:12:25.083164 21413 solver.cpp:228] Iteration 4880, loss = 0.00603751
I0403 08:12:25.083276 21413 solver.cpp:244]     Train net output #0: loss = 0.00603732 (* 1 = 0.00603732 loss)
I0403 08:12:25.267726 21413 sgd_solver.cpp:106] Iteration 4880, lr = 0.0005
I0403 08:12:36.819700 21413 solver.cpp:228] Iteration 4896, loss = 0.026969
I0403 08:12:36.819802 21413 solver.cpp:244]     Train net output #0: loss = 0.0269688 (* 1 = 0.0269688 loss)
I0403 08:12:37.002621 21413 sgd_solver.cpp:106] Iteration 4896, lr = 0.0005
I0403 08:12:48.653048 21413 solver.cpp:228] Iteration 4912, loss = 0.0130965
I0403 08:12:48.653159 21413 solver.cpp:244]     Train net output #0: loss = 0.0130963 (* 1 = 0.0130963 loss)
I0403 08:12:48.842917 21413 sgd_solver.cpp:106] Iteration 4912, lr = 0.0005
I0403 08:13:00.340821 21413 solver.cpp:228] Iteration 4928, loss = 0.0714354
I0403 08:13:00.341148 21413 solver.cpp:244]     Train net output #0: loss = 0.0714352 (* 1 = 0.0714352 loss)
I0403 08:13:00.531396 21413 sgd_solver.cpp:106] Iteration 4928, lr = 0.0005
I0403 08:13:12.357059 21413 solver.cpp:228] Iteration 4944, loss = 0.0211052
I0403 08:13:12.357162 21413 solver.cpp:244]     Train net output #0: loss = 0.021105 (* 1 = 0.021105 loss)
I0403 08:13:12.515735 21413 sgd_solver.cpp:106] Iteration 4944, lr = 0.0005
I0403 08:13:24.498476 21413 solver.cpp:228] Iteration 4960, loss = 0.00587922
I0403 08:13:24.498589 21413 solver.cpp:244]     Train net output #0: loss = 0.00587903 (* 1 = 0.00587903 loss)
I0403 08:13:24.680832 21413 sgd_solver.cpp:106] Iteration 4960, lr = 0.0005
I0403 08:13:36.291795 21413 solver.cpp:228] Iteration 4976, loss = 0.0237007
I0403 08:13:36.292141 21413 solver.cpp:244]     Train net output #0: loss = 0.0237006 (* 1 = 0.0237006 loss)
I0403 08:13:36.513231 21413 sgd_solver.cpp:106] Iteration 4976, lr = 0.0005
I0403 08:13:48.004366 21413 solver.cpp:228] Iteration 4992, loss = 0.0181093
I0403 08:13:48.004467 21413 solver.cpp:244]     Train net output #0: loss = 0.0181091 (* 1 = 0.0181091 loss)
I0403 08:13:48.184607 21413 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 08:13:59.744649 21413 solver.cpp:228] Iteration 5008, loss = 0.00397023
I0403 08:13:59.744761 21413 solver.cpp:244]     Train net output #0: loss = 0.00397003 (* 1 = 0.00397003 loss)
I0403 08:13:59.932713 21413 sgd_solver.cpp:106] Iteration 5008, lr = 0.0005
I0403 08:14:11.779919 21413 solver.cpp:228] Iteration 5024, loss = 0.00698552
I0403 08:14:11.780252 21413 solver.cpp:244]     Train net output #0: loss = 0.00698533 (* 1 = 0.00698533 loss)
I0403 08:14:11.955267 21413 sgd_solver.cpp:106] Iteration 5024, lr = 0.0005
I0403 08:14:23.464223 21413 solver.cpp:228] Iteration 5040, loss = 0.0927625
I0403 08:14:23.464339 21413 solver.cpp:244]     Train net output #0: loss = 0.0927623 (* 1 = 0.0927623 loss)
I0403 08:14:23.621137 21413 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 08:14:35.073854 21413 solver.cpp:228] Iteration 5056, loss = 0.03353
I0403 08:14:35.073972 21413 solver.cpp:244]     Train net output #0: loss = 0.0335298 (* 1 = 0.0335298 loss)
I0403 08:14:35.257377 21413 sgd_solver.cpp:106] Iteration 5056, lr = 0.0005
I0403 08:14:46.779530 21413 solver.cpp:228] Iteration 5072, loss = 0.0361204
I0403 08:14:46.783449 21413 solver.cpp:244]     Train net output #0: loss = 0.0361202 (* 1 = 0.0361202 loss)
I0403 08:14:47.049235 21413 sgd_solver.cpp:106] Iteration 5072, lr = 0.0005
I0403 08:14:58.599589 21413 solver.cpp:228] Iteration 5088, loss = 0.0472517
I0403 08:14:58.599705 21413 solver.cpp:244]     Train net output #0: loss = 0.0472516 (* 1 = 0.0472516 loss)
I0403 08:14:58.822598 21413 sgd_solver.cpp:106] Iteration 5088, lr = 0.0005
I0403 08:15:10.324101 21413 solver.cpp:228] Iteration 5104, loss = 0.0111048
I0403 08:15:10.324213 21413 solver.cpp:244]     Train net output #0: loss = 0.0111046 (* 1 = 0.0111046 loss)
I0403 08:15:10.517276 21413 sgd_solver.cpp:106] Iteration 5104, lr = 0.0005
I0403 08:15:22.215777 21413 solver.cpp:228] Iteration 5120, loss = 0.125148
I0403 08:15:22.216120 21413 solver.cpp:244]     Train net output #0: loss = 0.125148 (* 1 = 0.125148 loss)
I0403 08:15:22.393865 21413 sgd_solver.cpp:106] Iteration 5120, lr = 0.0005
I0403 08:15:33.903872 21413 solver.cpp:228] Iteration 5136, loss = 0.0276394
I0403 08:15:33.903990 21413 solver.cpp:244]     Train net output #0: loss = 0.0276392 (* 1 = 0.0276392 loss)
I0403 08:15:34.112996 21413 sgd_solver.cpp:106] Iteration 5136, lr = 0.0005
I0403 08:15:45.640820 21413 solver.cpp:228] Iteration 5152, loss = 0.00421105
I0403 08:15:45.640931 21413 solver.cpp:244]     Train net output #0: loss = 0.00421087 (* 1 = 0.00421087 loss)
I0403 08:15:45.842705 21413 sgd_solver.cpp:106] Iteration 5152, lr = 0.0005
I0403 08:15:57.282613 21413 solver.cpp:228] Iteration 5168, loss = 0.0359276
I0403 08:15:57.282919 21413 solver.cpp:244]     Train net output #0: loss = 0.0359275 (* 1 = 0.0359275 loss)
I0403 08:15:57.465301 21413 sgd_solver.cpp:106] Iteration 5168, lr = 0.0005
I0403 08:16:09.020143 21413 solver.cpp:228] Iteration 5184, loss = 0.0318705
I0403 08:16:09.020256 21413 solver.cpp:244]     Train net output #0: loss = 0.0318703 (* 1 = 0.0318703 loss)
I0403 08:16:09.226819 21413 sgd_solver.cpp:106] Iteration 5184, lr = 0.0005
I0403 08:16:20.120555 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_5200.caffemodel
I0403 08:16:22.887301 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_5200.solverstate
I0403 08:16:24.801023 21413 solver.cpp:337] Iteration 5200, Testing net (#0)
I0403 08:17:13.866701 21413 solver.cpp:404]     Test net output #0: accuracy = 0.958065
I0403 08:17:13.867033 21413 solver.cpp:404]     Test net output #1: loss = 0.152801 (* 1 = 0.152801 loss)
I0403 08:17:14.374567 21413 solver.cpp:228] Iteration 5200, loss = 0.0633518
I0403 08:17:14.374677 21413 solver.cpp:244]     Train net output #0: loss = 0.0633516 (* 1 = 0.0633516 loss)
I0403 08:17:14.567901 21413 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 08:17:26.386723 21413 solver.cpp:228] Iteration 5216, loss = 0.00528844
I0403 08:17:26.386831 21413 solver.cpp:244]     Train net output #0: loss = 0.00528825 (* 1 = 0.00528825 loss)
I0403 08:17:26.548724 21413 sgd_solver.cpp:106] Iteration 5216, lr = 0.0005
I0403 08:17:38.173460 21413 solver.cpp:228] Iteration 5232, loss = 0.0409511
I0403 08:17:38.173584 21413 solver.cpp:244]     Train net output #0: loss = 0.0409509 (* 1 = 0.0409509 loss)
I0403 08:17:38.360654 21413 sgd_solver.cpp:106] Iteration 5232, lr = 0.0005
I0403 08:17:49.858716 21413 solver.cpp:228] Iteration 5248, loss = 0.0184548
I0403 08:17:49.859033 21413 solver.cpp:244]     Train net output #0: loss = 0.0184546 (* 1 = 0.0184546 loss)
I0403 08:17:50.058210 21413 sgd_solver.cpp:106] Iteration 5248, lr = 0.0005
I0403 08:18:01.506134 21413 solver.cpp:228] Iteration 5264, loss = 0.0162824
I0403 08:18:01.506237 21413 solver.cpp:244]     Train net output #0: loss = 0.0162822 (* 1 = 0.0162822 loss)
I0403 08:18:01.688159 21413 sgd_solver.cpp:106] Iteration 5264, lr = 0.0005
I0403 08:18:13.109985 21413 solver.cpp:228] Iteration 5280, loss = 0.0250448
I0403 08:18:13.110095 21413 solver.cpp:244]     Train net output #0: loss = 0.0250446 (* 1 = 0.0250446 loss)
I0403 08:18:13.293375 21413 sgd_solver.cpp:106] Iteration 5280, lr = 0.0005
I0403 08:18:24.760223 21413 solver.cpp:228] Iteration 5296, loss = 0.0135332
I0403 08:18:24.760592 21413 solver.cpp:244]     Train net output #0: loss = 0.013533 (* 1 = 0.013533 loss)
I0403 08:18:24.952196 21413 sgd_solver.cpp:106] Iteration 5296, lr = 0.0005
I0403 08:18:36.593991 21413 solver.cpp:228] Iteration 5312, loss = 0.0380236
I0403 08:18:36.594097 21413 solver.cpp:244]     Train net output #0: loss = 0.0380234 (* 1 = 0.0380234 loss)
I0403 08:18:36.730756 21413 sgd_solver.cpp:106] Iteration 5312, lr = 0.0005
I0403 08:18:48.388099 21413 solver.cpp:228] Iteration 5328, loss = 0.0146323
I0403 08:18:48.388211 21413 solver.cpp:244]     Train net output #0: loss = 0.0146321 (* 1 = 0.0146321 loss)
I0403 08:18:48.601068 21413 sgd_solver.cpp:106] Iteration 5328, lr = 0.0005
I0403 08:18:59.999393 21413 solver.cpp:228] Iteration 5344, loss = 0.025459
I0403 08:18:59.999774 21413 solver.cpp:244]     Train net output #0: loss = 0.0254588 (* 1 = 0.0254588 loss)
I0403 08:19:00.207470 21413 sgd_solver.cpp:106] Iteration 5344, lr = 0.0005
I0403 08:19:11.655711 21413 solver.cpp:228] Iteration 5360, loss = 0.0760757
I0403 08:19:11.655843 21413 solver.cpp:244]     Train net output #0: loss = 0.0760755 (* 1 = 0.0760755 loss)
I0403 08:19:11.839498 21413 sgd_solver.cpp:106] Iteration 5360, lr = 0.0005
I0403 08:19:23.257542 21413 solver.cpp:228] Iteration 5376, loss = 0.00913265
I0403 08:19:23.257643 21413 solver.cpp:244]     Train net output #0: loss = 0.00913249 (* 1 = 0.00913249 loss)
I0403 08:19:23.435436 21413 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 08:19:34.826469 21413 solver.cpp:228] Iteration 5392, loss = 0.00812088
I0403 08:19:34.826833 21413 solver.cpp:244]     Train net output #0: loss = 0.00812072 (* 1 = 0.00812072 loss)
I0403 08:19:35.022459 21413 sgd_solver.cpp:106] Iteration 5392, lr = 0.0005
I0403 08:19:46.489035 21413 solver.cpp:228] Iteration 5408, loss = 0.0208426
I0403 08:19:46.489153 21413 solver.cpp:244]     Train net output #0: loss = 0.0208425 (* 1 = 0.0208425 loss)
I0403 08:19:46.710522 21413 sgd_solver.cpp:106] Iteration 5408, lr = 0.0005
I0403 08:19:58.359652 21413 solver.cpp:228] Iteration 5424, loss = 0.0160218
I0403 08:19:58.359766 21413 solver.cpp:244]     Train net output #0: loss = 0.0160217 (* 1 = 0.0160217 loss)
I0403 08:19:58.566123 21413 sgd_solver.cpp:106] Iteration 5424, lr = 0.0005
I0403 08:20:10.054694 21413 solver.cpp:228] Iteration 5440, loss = 0.0210712
I0403 08:20:10.055016 21413 solver.cpp:244]     Train net output #0: loss = 0.021071 (* 1 = 0.021071 loss)
I0403 08:20:10.247277 21413 sgd_solver.cpp:106] Iteration 5440, lr = 0.0005
I0403 08:20:21.867733 21413 solver.cpp:228] Iteration 5456, loss = 0.022068
I0403 08:20:21.867851 21413 solver.cpp:244]     Train net output #0: loss = 0.0220679 (* 1 = 0.0220679 loss)
I0403 08:20:22.064913 21413 sgd_solver.cpp:106] Iteration 5456, lr = 0.0005
I0403 08:20:33.520900 21413 solver.cpp:228] Iteration 5472, loss = 0.00848047
I0403 08:20:33.521019 21413 solver.cpp:244]     Train net output #0: loss = 0.0084803 (* 1 = 0.0084803 loss)
I0403 08:20:33.716831 21413 sgd_solver.cpp:106] Iteration 5472, lr = 0.0005
I0403 08:20:45.118146 21413 solver.cpp:228] Iteration 5488, loss = 0.0336173
I0403 08:20:45.118480 21413 solver.cpp:244]     Train net output #0: loss = 0.0336171 (* 1 = 0.0336171 loss)
I0403 08:20:45.315203 21413 sgd_solver.cpp:106] Iteration 5488, lr = 0.0005
I0403 08:20:56.752809 21413 solver.cpp:228] Iteration 5504, loss = 0.0448754
I0403 08:20:56.752934 21413 solver.cpp:244]     Train net output #0: loss = 0.0448752 (* 1 = 0.0448752 loss)
I0403 08:20:56.949512 21413 sgd_solver.cpp:106] Iteration 5504, lr = 0.0005
I0403 08:21:08.419986 21413 solver.cpp:228] Iteration 5520, loss = 0.00818272
I0403 08:21:08.420105 21413 solver.cpp:244]     Train net output #0: loss = 0.00818255 (* 1 = 0.00818255 loss)
I0403 08:21:08.656824 21413 sgd_solver.cpp:106] Iteration 5520, lr = 0.0005
I0403 08:21:11.565074 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_5525.caffemodel
I0403 08:21:14.345943 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_5525.solverstate
I0403 08:21:16.252272 21413 solver.cpp:337] Iteration 5525, Testing net (#0)
I0403 08:22:05.297394 21413 solver.cpp:404]     Test net output #0: accuracy = 0.958802
I0403 08:22:05.297731 21413 solver.cpp:404]     Test net output #1: loss = 0.15194 (* 1 = 0.15194 loss)
I0403 08:22:13.906471 21413 solver.cpp:228] Iteration 5536, loss = 0.0170498
I0403 08:22:13.906586 21413 solver.cpp:244]     Train net output #0: loss = 0.0170496 (* 1 = 0.0170496 loss)
I0403 08:22:14.106205 21413 sgd_solver.cpp:106] Iteration 5536, lr = 0.0005
I0403 08:22:25.735471 21413 solver.cpp:228] Iteration 5552, loss = 0.00694936
I0403 08:22:25.735589 21413 solver.cpp:244]     Train net output #0: loss = 0.00694919 (* 1 = 0.00694919 loss)
I0403 08:22:25.961457 21413 sgd_solver.cpp:106] Iteration 5552, lr = 0.0005
I0403 08:22:37.561782 21413 solver.cpp:228] Iteration 5568, loss = 0.0329163
I0403 08:22:37.562130 21413 solver.cpp:244]     Train net output #0: loss = 0.0329161 (* 1 = 0.0329161 loss)
I0403 08:22:37.760483 21413 sgd_solver.cpp:106] Iteration 5568, lr = 0.0005
I0403 08:22:49.329119 21413 solver.cpp:228] Iteration 5584, loss = 0.0156395
I0403 08:22:49.329236 21413 solver.cpp:244]     Train net output #0: loss = 0.0156394 (* 1 = 0.0156394 loss)
I0403 08:22:49.515341 21413 sgd_solver.cpp:106] Iteration 5584, lr = 0.0005
I0403 08:23:01.167302 21413 solver.cpp:228] Iteration 5600, loss = 0.029042
I0403 08:23:01.167418 21413 solver.cpp:244]     Train net output #0: loss = 0.0290418 (* 1 = 0.0290418 loss)
I0403 08:23:01.409672 21413 sgd_solver.cpp:106] Iteration 5600, lr = 0.0005
I0403 08:23:12.883559 21413 solver.cpp:228] Iteration 5616, loss = 0.0315651
I0403 08:23:12.883833 21413 solver.cpp:244]     Train net output #0: loss = 0.031565 (* 1 = 0.031565 loss)
I0403 08:23:13.080940 21413 sgd_solver.cpp:106] Iteration 5616, lr = 0.0005
I0403 08:23:24.543022 21413 solver.cpp:228] Iteration 5632, loss = 0.0301832
I0403 08:23:24.543133 21413 solver.cpp:244]     Train net output #0: loss = 0.0301831 (* 1 = 0.0301831 loss)
I0403 08:23:24.762372 21413 sgd_solver.cpp:106] Iteration 5632, lr = 0.0005
I0403 08:23:36.221180 21413 solver.cpp:228] Iteration 5648, loss = 0.0127799
I0403 08:23:36.221295 21413 solver.cpp:244]     Train net output #0: loss = 0.0127797 (* 1 = 0.0127797 loss)
I0403 08:23:36.421900 21413 sgd_solver.cpp:106] Iteration 5648, lr = 0.0005
I0403 08:23:47.840154 21413 solver.cpp:228] Iteration 5664, loss = 0.00251261
I0403 08:23:47.840484 21413 solver.cpp:244]     Train net output #0: loss = 0.00251243 (* 1 = 0.00251243 loss)
I0403 08:23:48.046751 21413 sgd_solver.cpp:106] Iteration 5664, lr = 0.0005
I0403 08:23:59.697518 21413 solver.cpp:228] Iteration 5680, loss = 0.0751525
I0403 08:23:59.697638 21413 solver.cpp:244]     Train net output #0: loss = 0.0751523 (* 1 = 0.0751523 loss)
I0403 08:23:59.863098 21413 sgd_solver.cpp:106] Iteration 5680, lr = 0.0005
I0403 08:24:11.464432 21413 solver.cpp:228] Iteration 5696, loss = 0.00775011
I0403 08:24:11.464546 21413 solver.cpp:244]     Train net output #0: loss = 0.00774994 (* 1 = 0.00774994 loss)
I0403 08:24:11.654373 21413 sgd_solver.cpp:106] Iteration 5696, lr = 0.0005
I0403 08:24:23.144747 21413 solver.cpp:228] Iteration 5712, loss = 0.0108188
I0403 08:24:23.145076 21413 solver.cpp:244]     Train net output #0: loss = 0.0108186 (* 1 = 0.0108186 loss)
I0403 08:24:23.307090 21413 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 08:24:34.844549 21413 solver.cpp:228] Iteration 5728, loss = 0.00951729
I0403 08:24:34.844672 21413 solver.cpp:244]     Train net output #0: loss = 0.00951712 (* 1 = 0.00951712 loss)
I0403 08:24:35.035580 21413 sgd_solver.cpp:106] Iteration 5728, lr = 0.0005
I0403 08:24:46.449524 21413 solver.cpp:228] Iteration 5744, loss = 0.0598328
I0403 08:24:46.449643 21413 solver.cpp:244]     Train net output #0: loss = 0.0598326 (* 1 = 0.0598326 loss)
I0403 08:24:46.632793 21413 sgd_solver.cpp:106] Iteration 5744, lr = 0.0005
I0403 08:24:58.199787 21413 solver.cpp:228] Iteration 5760, loss = 0.00622031
I0403 08:24:58.200150 21413 solver.cpp:244]     Train net output #0: loss = 0.00622015 (* 1 = 0.00622015 loss)
I0403 08:24:58.388250 21413 sgd_solver.cpp:106] Iteration 5760, lr = 0.0005
I0403 08:25:10.004796 21413 solver.cpp:228] Iteration 5776, loss = 0.0205394
I0403 08:25:10.004910 21413 solver.cpp:244]     Train net output #0: loss = 0.0205393 (* 1 = 0.0205393 loss)
I0403 08:25:10.221163 21413 sgd_solver.cpp:106] Iteration 5776, lr = 0.0005
I0403 08:25:21.741868 21413 solver.cpp:228] Iteration 5792, loss = 0.0520852
I0403 08:25:21.741971 21413 solver.cpp:244]     Train net output #0: loss = 0.052085 (* 1 = 0.052085 loss)
I0403 08:25:21.917817 21413 sgd_solver.cpp:106] Iteration 5792, lr = 0.0005
I0403 08:25:33.570606 21413 solver.cpp:228] Iteration 5808, loss = 0.0126865
I0403 08:25:33.570876 21413 solver.cpp:244]     Train net output #0: loss = 0.0126863 (* 1 = 0.0126863 loss)
I0403 08:25:33.751860 21413 sgd_solver.cpp:106] Iteration 5808, lr = 0.0005
I0403 08:25:45.316812 21413 solver.cpp:228] Iteration 5824, loss = 0.0201709
I0403 08:25:45.316926 21413 solver.cpp:244]     Train net output #0: loss = 0.0201707 (* 1 = 0.0201707 loss)
I0403 08:25:45.516782 21413 sgd_solver.cpp:106] Iteration 5824, lr = 0.0005
I0403 08:25:57.029623 21413 solver.cpp:228] Iteration 5840, loss = 0.0357677
I0403 08:25:57.029739 21413 solver.cpp:244]     Train net output #0: loss = 0.0357675 (* 1 = 0.0357675 loss)
I0403 08:25:57.241575 21413 sgd_solver.cpp:106] Iteration 5840, lr = 0.0005
I0403 08:26:03.848742 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_5850.caffemodel
I0403 08:26:06.719498 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_5850.solverstate
I0403 08:26:08.637702 21413 solver.cpp:337] Iteration 5850, Testing net (#0)
I0403 08:26:57.683009 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959078
I0403 08:26:57.683348 21413 solver.cpp:404]     Test net output #1: loss = 0.152764 (* 1 = 0.152764 loss)
I0403 08:27:02.549293 21413 solver.cpp:228] Iteration 5856, loss = 0.00450933
I0403 08:27:02.549404 21413 solver.cpp:244]     Train net output #0: loss = 0.00450917 (* 1 = 0.00450917 loss)
I0403 08:27:02.748455 21413 sgd_solver.cpp:106] Iteration 5856, lr = 0.0005
I0403 08:27:14.342614 21413 solver.cpp:228] Iteration 5872, loss = 0.00819698
I0403 08:27:14.342733 21413 solver.cpp:244]     Train net output #0: loss = 0.00819681 (* 1 = 0.00819681 loss)
I0403 08:27:14.529775 21413 sgd_solver.cpp:106] Iteration 5872, lr = 0.0005
I0403 08:27:26.069783 21413 solver.cpp:228] Iteration 5888, loss = 0.00351466
I0403 08:27:26.069895 21413 solver.cpp:244]     Train net output #0: loss = 0.00351449 (* 1 = 0.00351449 loss)
I0403 08:27:26.264124 21413 sgd_solver.cpp:106] Iteration 5888, lr = 0.0005
I0403 08:27:38.266741 21413 solver.cpp:228] Iteration 5904, loss = 0.11411
I0403 08:27:38.267067 21413 solver.cpp:244]     Train net output #0: loss = 0.114109 (* 1 = 0.114109 loss)
I0403 08:27:38.415513 21413 sgd_solver.cpp:106] Iteration 5904, lr = 0.0005
I0403 08:27:50.054260 21413 solver.cpp:228] Iteration 5920, loss = 0.00448817
I0403 08:27:50.054373 21413 solver.cpp:244]     Train net output #0: loss = 0.004488 (* 1 = 0.004488 loss)
I0403 08:27:50.240550 21413 sgd_solver.cpp:106] Iteration 5920, lr = 0.0005
I0403 08:28:01.825642 21413 solver.cpp:228] Iteration 5936, loss = 0.0182894
I0403 08:28:01.825757 21413 solver.cpp:244]     Train net output #0: loss = 0.0182893 (* 1 = 0.0182893 loss)
I0403 08:28:02.025662 21413 sgd_solver.cpp:106] Iteration 5936, lr = 0.0005
I0403 08:28:13.507336 21413 solver.cpp:228] Iteration 5952, loss = 0.00993041
I0403 08:28:13.507657 21413 solver.cpp:244]     Train net output #0: loss = 0.00993024 (* 1 = 0.00993024 loss)
I0403 08:28:13.645642 21413 sgd_solver.cpp:106] Iteration 5952, lr = 0.0005
I0403 08:28:25.258884 21413 solver.cpp:228] Iteration 5968, loss = 0.0163087
I0403 08:28:25.258999 21413 solver.cpp:244]     Train net output #0: loss = 0.0163085 (* 1 = 0.0163085 loss)
I0403 08:28:25.476173 21413 sgd_solver.cpp:106] Iteration 5968, lr = 0.0005
I0403 08:28:37.139358 21413 solver.cpp:228] Iteration 5984, loss = 0.00165173
I0403 08:28:37.139474 21413 solver.cpp:244]     Train net output #0: loss = 0.00165157 (* 1 = 0.00165157 loss)
I0403 08:28:37.332456 21413 sgd_solver.cpp:106] Iteration 5984, lr = 0.0005
I0403 08:28:48.745409 21413 solver.cpp:228] Iteration 6000, loss = 0.0196953
I0403 08:28:48.749752 21413 solver.cpp:244]     Train net output #0: loss = 0.0196951 (* 1 = 0.0196951 loss)
I0403 08:28:48.955749 21413 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0403 08:29:00.595214 21413 solver.cpp:228] Iteration 6016, loss = 0.0607453
I0403 08:29:00.595332 21413 solver.cpp:244]     Train net output #0: loss = 0.0607451 (* 1 = 0.0607451 loss)
I0403 08:29:00.812013 21413 sgd_solver.cpp:106] Iteration 6016, lr = 0.0005
I0403 08:29:12.375612 21413 solver.cpp:228] Iteration 6032, loss = 0.00362358
I0403 08:29:12.375725 21413 solver.cpp:244]     Train net output #0: loss = 0.00362342 (* 1 = 0.00362342 loss)
I0403 08:29:12.567021 21413 sgd_solver.cpp:106] Iteration 6032, lr = 0.0005
I0403 08:29:23.990893 21413 solver.cpp:228] Iteration 6048, loss = 0.0186128
I0403 08:29:23.991235 21413 solver.cpp:244]     Train net output #0: loss = 0.0186126 (* 1 = 0.0186126 loss)
I0403 08:29:24.202117 21413 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 08:29:35.764842 21413 solver.cpp:228] Iteration 6064, loss = 0.0164678
I0403 08:29:35.764955 21413 solver.cpp:244]     Train net output #0: loss = 0.0164676 (* 1 = 0.0164676 loss)
I0403 08:29:35.965229 21413 sgd_solver.cpp:106] Iteration 6064, lr = 0.0005
I0403 08:29:47.303002 21413 solver.cpp:228] Iteration 6080, loss = 0.0347006
I0403 08:29:47.303120 21413 solver.cpp:244]     Train net output #0: loss = 0.0347005 (* 1 = 0.0347005 loss)
I0403 08:29:47.580703 21413 sgd_solver.cpp:106] Iteration 6080, lr = 0.0005
I0403 08:29:59.172992 21413 solver.cpp:228] Iteration 6096, loss = 0.082677
I0403 08:29:59.173333 21413 solver.cpp:244]     Train net output #0: loss = 0.0826769 (* 1 = 0.0826769 loss)
I0403 08:29:59.358691 21413 sgd_solver.cpp:106] Iteration 6096, lr = 0.0005
I0403 08:30:10.901571 21413 solver.cpp:228] Iteration 6112, loss = 0.00756986
I0403 08:30:10.901681 21413 solver.cpp:244]     Train net output #0: loss = 0.0075697 (* 1 = 0.0075697 loss)
I0403 08:30:11.113497 21413 sgd_solver.cpp:106] Iteration 6112, lr = 0.0005
I0403 08:30:22.715463 21413 solver.cpp:228] Iteration 6128, loss = 0.0057599
I0403 08:30:22.715582 21413 solver.cpp:244]     Train net output #0: loss = 0.00575974 (* 1 = 0.00575974 loss)
I0403 08:30:22.902503 21413 sgd_solver.cpp:106] Iteration 6128, lr = 0.0005
I0403 08:30:34.446384 21413 solver.cpp:228] Iteration 6144, loss = 0.0213324
I0403 08:30:34.446732 21413 solver.cpp:244]     Train net output #0: loss = 0.0213323 (* 1 = 0.0213323 loss)
I0403 08:30:34.659659 21413 sgd_solver.cpp:106] Iteration 6144, lr = 0.0005
I0403 08:30:46.112772 21413 solver.cpp:228] Iteration 6160, loss = 0.00633669
I0403 08:30:46.112880 21413 solver.cpp:244]     Train net output #0: loss = 0.00633654 (* 1 = 0.00633654 loss)
I0403 08:30:46.329833 21413 sgd_solver.cpp:106] Iteration 6160, lr = 0.0005
I0403 08:30:56.612126 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_6175.caffemodel
I0403 08:30:59.304810 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_6175.solverstate
I0403 08:31:01.097447 21413 solver.cpp:337] Iteration 6175, Testing net (#0)
I0403 08:31:50.145328 21413 solver.cpp:404]     Test net output #0: accuracy = 0.95871
I0403 08:31:50.145651 21413 solver.cpp:404]     Test net output #1: loss = 0.155224 (* 1 = 0.155224 loss)
I0403 08:31:51.378468 21413 solver.cpp:228] Iteration 6176, loss = 0.0137056
I0403 08:31:51.378582 21413 solver.cpp:244]     Train net output #0: loss = 0.0137055 (* 1 = 0.0137055 loss)
I0403 08:31:51.586256 21413 sgd_solver.cpp:106] Iteration 6176, lr = 0.0005
I0403 08:32:03.184964 21413 solver.cpp:228] Iteration 6192, loss = 0.00683424
I0403 08:32:03.185078 21413 solver.cpp:244]     Train net output #0: loss = 0.00683408 (* 1 = 0.00683408 loss)
I0403 08:32:03.372984 21413 sgd_solver.cpp:106] Iteration 6192, lr = 0.0005
I0403 08:32:14.828903 21413 solver.cpp:228] Iteration 6208, loss = 0.00837366
I0403 08:32:14.829016 21413 solver.cpp:244]     Train net output #0: loss = 0.0083735 (* 1 = 0.0083735 loss)
I0403 08:32:15.035382 21413 sgd_solver.cpp:106] Iteration 6208, lr = 0.0005
I0403 08:32:26.832351 21413 solver.cpp:228] Iteration 6224, loss = 0.0221048
I0403 08:32:26.832739 21413 solver.cpp:244]     Train net output #0: loss = 0.0221046 (* 1 = 0.0221046 loss)
I0403 08:32:27.110098 21413 sgd_solver.cpp:106] Iteration 6224, lr = 0.0005
I0403 08:32:38.593654 21413 solver.cpp:228] Iteration 6240, loss = 0.00744347
I0403 08:32:38.593770 21413 solver.cpp:244]     Train net output #0: loss = 0.00744331 (* 1 = 0.00744331 loss)
I0403 08:32:38.787756 21413 sgd_solver.cpp:106] Iteration 6240, lr = 0.0005
I0403 08:32:50.254869 21413 solver.cpp:228] Iteration 6256, loss = 0.0270856
I0403 08:32:50.254982 21413 solver.cpp:244]     Train net output #0: loss = 0.0270854 (* 1 = 0.0270854 loss)
I0403 08:32:50.462842 21413 sgd_solver.cpp:106] Iteration 6256, lr = 0.0005
I0403 08:33:01.963722 21413 solver.cpp:228] Iteration 6272, loss = 0.0131978
I0403 08:33:01.964038 21413 solver.cpp:244]     Train net output #0: loss = 0.0131977 (* 1 = 0.0131977 loss)
I0403 08:33:02.164497 21413 sgd_solver.cpp:106] Iteration 6272, lr = 0.0005
I0403 08:33:13.683526 21413 solver.cpp:228] Iteration 6288, loss = 0.0172705
I0403 08:33:13.683639 21413 solver.cpp:244]     Train net output #0: loss = 0.0172703 (* 1 = 0.0172703 loss)
I0403 08:33:13.871413 21413 sgd_solver.cpp:106] Iteration 6288, lr = 0.0005
I0403 08:33:25.411550 21413 solver.cpp:228] Iteration 6304, loss = 0.00457239
I0403 08:33:25.411653 21413 solver.cpp:244]     Train net output #0: loss = 0.00457224 (* 1 = 0.00457224 loss)
I0403 08:33:25.586550 21413 sgd_solver.cpp:106] Iteration 6304, lr = 0.0005
I0403 08:33:37.216274 21413 solver.cpp:228] Iteration 6320, loss = 0.0336462
I0403 08:33:37.216603 21413 solver.cpp:244]     Train net output #0: loss = 0.0336461 (* 1 = 0.0336461 loss)
I0403 08:33:37.403666 21413 sgd_solver.cpp:106] Iteration 6320, lr = 0.0005
I0403 08:33:48.907285 21413 solver.cpp:228] Iteration 6336, loss = 0.0141769
I0403 08:33:48.907399 21413 solver.cpp:244]     Train net output #0: loss = 0.0141768 (* 1 = 0.0141768 loss)
I0403 08:33:49.130381 21413 sgd_solver.cpp:106] Iteration 6336, lr = 0.0005
I0403 08:34:00.817100 21413 solver.cpp:228] Iteration 6352, loss = 0.00498786
I0403 08:34:00.817217 21413 solver.cpp:244]     Train net output #0: loss = 0.00498771 (* 1 = 0.00498771 loss)
I0403 08:34:01.022908 21413 sgd_solver.cpp:106] Iteration 6352, lr = 0.0005
I0403 08:34:12.689741 21413 solver.cpp:228] Iteration 6368, loss = 0.0123733
I0403 08:34:12.690085 21413 solver.cpp:244]     Train net output #0: loss = 0.0123731 (* 1 = 0.0123731 loss)
I0403 08:34:12.879127 21413 sgd_solver.cpp:106] Iteration 6368, lr = 0.0005
I0403 08:34:24.539520 21413 solver.cpp:228] Iteration 6384, loss = 0.00934564
I0403 08:34:24.539635 21413 solver.cpp:244]     Train net output #0: loss = 0.0093455 (* 1 = 0.0093455 loss)
I0403 08:34:24.714571 21413 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 08:34:36.264117 21413 solver.cpp:228] Iteration 6400, loss = 0.00432657
I0403 08:34:36.264232 21413 solver.cpp:244]     Train net output #0: loss = 0.00432643 (* 1 = 0.00432643 loss)
I0403 08:34:36.456225 21413 sgd_solver.cpp:106] Iteration 6400, lr = 0.0005
I0403 08:34:48.123096 21413 solver.cpp:228] Iteration 6416, loss = 0.0242755
I0403 08:34:48.123436 21413 solver.cpp:244]     Train net output #0: loss = 0.0242754 (* 1 = 0.0242754 loss)
I0403 08:34:48.327559 21413 sgd_solver.cpp:106] Iteration 6416, lr = 0.0005
I0403 08:35:00.017479 21413 solver.cpp:228] Iteration 6432, loss = 0.0350178
I0403 08:35:00.017586 21413 solver.cpp:244]     Train net output #0: loss = 0.0350177 (* 1 = 0.0350177 loss)
I0403 08:35:00.199748 21413 sgd_solver.cpp:106] Iteration 6432, lr = 0.0005
I0403 08:35:11.718482 21413 solver.cpp:228] Iteration 6448, loss = 0.0145613
I0403 08:35:11.718590 21413 solver.cpp:244]     Train net output #0: loss = 0.0145612 (* 1 = 0.0145612 loss)
I0403 08:35:11.882484 21413 sgd_solver.cpp:106] Iteration 6448, lr = 0.0005
I0403 08:35:23.566311 21413 solver.cpp:228] Iteration 6464, loss = 0.0126515
I0403 08:35:23.566689 21413 solver.cpp:244]     Train net output #0: loss = 0.0126514 (* 1 = 0.0126514 loss)
I0403 08:35:23.758664 21413 sgd_solver.cpp:106] Iteration 6464, lr = 0.0005
I0403 08:35:35.306857 21413 solver.cpp:228] Iteration 6480, loss = 0.0191894
I0403 08:35:35.306958 21413 solver.cpp:244]     Train net output #0: loss = 0.0191893 (* 1 = 0.0191893 loss)
I0403 08:35:35.486223 21413 sgd_solver.cpp:106] Iteration 6480, lr = 0.0005
I0403 08:35:47.096236 21413 solver.cpp:228] Iteration 6496, loss = 0.00613497
I0403 08:35:47.096349 21413 solver.cpp:244]     Train net output #0: loss = 0.00613483 (* 1 = 0.00613483 loss)
I0403 08:35:47.273161 21413 sgd_solver.cpp:106] Iteration 6496, lr = 0.0005
I0403 08:35:49.492461 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_6500.caffemodel
I0403 08:35:52.109485 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_6500.solverstate
I0403 08:35:53.921494 21413 solver.cpp:337] Iteration 6500, Testing net (#0)
I0403 08:36:42.974475 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959678
I0403 08:36:42.974809 21413 solver.cpp:404]     Test net output #1: loss = 0.157858 (* 1 = 0.157858 loss)
I0403 08:36:52.239697 21413 solver.cpp:228] Iteration 6512, loss = 0.00554549
I0403 08:36:52.239814 21413 solver.cpp:244]     Train net output #0: loss = 0.00554536 (* 1 = 0.00554536 loss)
I0403 08:36:52.438457 21413 sgd_solver.cpp:106] Iteration 6512, lr = 5e-05
I0403 08:37:04.099211 21413 solver.cpp:228] Iteration 6528, loss = 0.0132643
I0403 08:37:04.099313 21413 solver.cpp:244]     Train net output #0: loss = 0.0132641 (* 1 = 0.0132641 loss)
I0403 08:37:04.281903 21413 sgd_solver.cpp:106] Iteration 6528, lr = 5e-05
I0403 08:37:15.739524 21413 solver.cpp:228] Iteration 6544, loss = 0.0116573
I0403 08:37:15.739868 21413 solver.cpp:244]     Train net output #0: loss = 0.0116572 (* 1 = 0.0116572 loss)
I0403 08:37:15.922816 21413 sgd_solver.cpp:106] Iteration 6544, lr = 5e-05
I0403 08:37:27.420779 21413 solver.cpp:228] Iteration 6560, loss = 0.0239355
I0403 08:37:27.420895 21413 solver.cpp:244]     Train net output #0: loss = 0.0239353 (* 1 = 0.0239353 loss)
I0403 08:37:27.632068 21413 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 08:37:39.090873 21413 solver.cpp:228] Iteration 6576, loss = 0.009188
I0403 08:37:39.090984 21413 solver.cpp:244]     Train net output #0: loss = 0.00918786 (* 1 = 0.00918786 loss)
I0403 08:37:39.279240 21413 sgd_solver.cpp:106] Iteration 6576, lr = 5e-05
I0403 08:37:50.937325 21413 solver.cpp:228] Iteration 6592, loss = 0.0133072
I0403 08:37:50.937638 21413 solver.cpp:244]     Train net output #0: loss = 0.013307 (* 1 = 0.013307 loss)
I0403 08:37:51.090903 21413 sgd_solver.cpp:106] Iteration 6592, lr = 5e-05
I0403 08:38:02.604473 21413 solver.cpp:228] Iteration 6608, loss = 0.010379
I0403 08:38:02.604594 21413 solver.cpp:244]     Train net output #0: loss = 0.0103789 (* 1 = 0.0103789 loss)
I0403 08:38:02.816372 21413 sgd_solver.cpp:106] Iteration 6608, lr = 5e-05
I0403 08:38:14.294715 21413 solver.cpp:228] Iteration 6624, loss = 0.0134539
I0403 08:38:14.294827 21413 solver.cpp:244]     Train net output #0: loss = 0.0134538 (* 1 = 0.0134538 loss)
I0403 08:38:14.477793 21413 sgd_solver.cpp:106] Iteration 6624, lr = 5e-05
I0403 08:38:26.236368 21413 solver.cpp:228] Iteration 6640, loss = 0.00190956
I0403 08:38:26.236717 21413 solver.cpp:244]     Train net output #0: loss = 0.00190942 (* 1 = 0.00190942 loss)
I0403 08:38:26.413266 21413 sgd_solver.cpp:106] Iteration 6640, lr = 5e-05
I0403 08:38:37.904634 21413 solver.cpp:228] Iteration 6656, loss = 0.0651626
I0403 08:38:37.904744 21413 solver.cpp:244]     Train net output #0: loss = 0.0651625 (* 1 = 0.0651625 loss)
I0403 08:38:38.087797 21413 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 08:38:49.624088 21413 solver.cpp:228] Iteration 6672, loss = 0.0252747
I0403 08:38:49.624203 21413 solver.cpp:244]     Train net output #0: loss = 0.0252746 (* 1 = 0.0252746 loss)
I0403 08:38:49.813105 21413 sgd_solver.cpp:106] Iteration 6672, lr = 5e-05
I0403 08:39:01.322253 21413 solver.cpp:228] Iteration 6688, loss = 0.0278499
I0403 08:39:01.322592 21413 solver.cpp:244]     Train net output #0: loss = 0.0278497 (* 1 = 0.0278497 loss)
I0403 08:39:01.530185 21413 sgd_solver.cpp:106] Iteration 6688, lr = 5e-05
I0403 08:39:13.051120 21413 solver.cpp:228] Iteration 6704, loss = 0.00384434
I0403 08:39:13.051218 21413 solver.cpp:244]     Train net output #0: loss = 0.0038442 (* 1 = 0.0038442 loss)
I0403 08:39:13.232069 21413 sgd_solver.cpp:106] Iteration 6704, lr = 5e-05
I0403 08:39:24.721012 21413 solver.cpp:228] Iteration 6720, loss = 0.013022
I0403 08:39:24.721125 21413 solver.cpp:244]     Train net output #0: loss = 0.0130218 (* 1 = 0.0130218 loss)
I0403 08:39:24.945264 21413 sgd_solver.cpp:106] Iteration 6720, lr = 5e-05
I0403 08:39:36.389528 21413 solver.cpp:228] Iteration 6736, loss = 0.00161162
I0403 08:39:36.389868 21413 solver.cpp:244]     Train net output #0: loss = 0.00161149 (* 1 = 0.00161149 loss)
I0403 08:39:36.591858 21413 sgd_solver.cpp:106] Iteration 6736, lr = 5e-05
I0403 08:39:48.116211 21413 solver.cpp:228] Iteration 6752, loss = 0.0110905
I0403 08:39:48.116314 21413 solver.cpp:244]     Train net output #0: loss = 0.0110904 (* 1 = 0.0110904 loss)
I0403 08:39:48.277928 21413 sgd_solver.cpp:106] Iteration 6752, lr = 5e-05
I0403 08:40:00.043010 21413 solver.cpp:228] Iteration 6768, loss = 0.0313727
I0403 08:40:00.043123 21413 solver.cpp:244]     Train net output #0: loss = 0.0313726 (* 1 = 0.0313726 loss)
I0403 08:40:00.236884 21413 sgd_solver.cpp:106] Iteration 6768, lr = 5e-05
I0403 08:40:11.715136 21413 solver.cpp:228] Iteration 6784, loss = 0.00852641
I0403 08:40:11.715462 21413 solver.cpp:244]     Train net output #0: loss = 0.00852627 (* 1 = 0.00852627 loss)
I0403 08:40:11.888399 21413 sgd_solver.cpp:106] Iteration 6784, lr = 5e-05
I0403 08:40:23.413362 21413 solver.cpp:228] Iteration 6800, loss = 0.00522789
I0403 08:40:23.413475 21413 solver.cpp:244]     Train net output #0: loss = 0.00522776 (* 1 = 0.00522776 loss)
I0403 08:40:23.626379 21413 sgd_solver.cpp:106] Iteration 6800, lr = 5e-05
I0403 08:40:35.257889 21413 solver.cpp:228] Iteration 6816, loss = 0.032719
I0403 08:40:35.258002 21413 solver.cpp:244]     Train net output #0: loss = 0.0327189 (* 1 = 0.0327189 loss)
I0403 08:40:35.486742 21413 sgd_solver.cpp:106] Iteration 6816, lr = 5e-05
I0403 08:40:41.450780 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_6825.caffemodel
I0403 08:40:44.109694 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_6825.solverstate
I0403 08:40:45.930516 21413 solver.cpp:337] Iteration 6825, Testing net (#0)
I0403 08:41:34.978510 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959678
I0403 08:41:34.978828 21413 solver.cpp:404]     Test net output #1: loss = 0.154881 (* 1 = 0.154881 loss)
I0403 08:41:40.774281 21413 solver.cpp:228] Iteration 6832, loss = 0.0134065
I0403 08:41:40.774397 21413 solver.cpp:244]     Train net output #0: loss = 0.0134064 (* 1 = 0.0134064 loss)
I0403 08:41:40.973597 21413 sgd_solver.cpp:106] Iteration 6832, lr = 5e-05
I0403 08:41:52.400606 21413 solver.cpp:228] Iteration 6848, loss = 0.0262534
I0403 08:41:52.400722 21413 solver.cpp:244]     Train net output #0: loss = 0.0262533 (* 1 = 0.0262533 loss)
I0403 08:41:52.603893 21413 sgd_solver.cpp:106] Iteration 6848, lr = 5e-05
I0403 08:42:04.219867 21413 solver.cpp:228] Iteration 6864, loss = 0.113453
I0403 08:42:04.219970 21413 solver.cpp:244]     Train net output #0: loss = 0.113453 (* 1 = 0.113453 loss)
I0403 08:42:04.378233 21413 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 08:42:15.930029 21413 solver.cpp:228] Iteration 6880, loss = 0.028633
I0403 08:42:15.930390 21413 solver.cpp:244]     Train net output #0: loss = 0.0286328 (* 1 = 0.0286328 loss)
I0403 08:42:16.137631 21413 sgd_solver.cpp:106] Iteration 6880, lr = 5e-05
I0403 08:42:27.652735 21413 solver.cpp:228] Iteration 6896, loss = 0.0183461
I0403 08:42:27.652864 21413 solver.cpp:244]     Train net output #0: loss = 0.018346 (* 1 = 0.018346 loss)
I0403 08:42:27.837570 21413 sgd_solver.cpp:106] Iteration 6896, lr = 5e-05
I0403 08:42:39.340075 21413 solver.cpp:228] Iteration 6912, loss = 0.00295213
I0403 08:42:39.340176 21413 solver.cpp:244]     Train net output #0: loss = 0.00295199 (* 1 = 0.00295199 loss)
I0403 08:42:39.517055 21413 sgd_solver.cpp:106] Iteration 6912, lr = 5e-05
I0403 08:42:51.140826 21413 solver.cpp:228] Iteration 6928, loss = 0.00172858
I0403 08:42:51.141134 21413 solver.cpp:244]     Train net output #0: loss = 0.00172844 (* 1 = 0.00172844 loss)
I0403 08:42:51.308187 21413 sgd_solver.cpp:106] Iteration 6928, lr = 5e-05
I0403 08:43:02.940975 21413 solver.cpp:228] Iteration 6944, loss = 0.00213374
I0403 08:43:02.941079 21413 solver.cpp:244]     Train net output #0: loss = 0.0021336 (* 1 = 0.0021336 loss)
I0403 08:43:03.118485 21413 sgd_solver.cpp:106] Iteration 6944, lr = 5e-05
I0403 08:43:14.643347 21413 solver.cpp:228] Iteration 6960, loss = 0.00247084
I0403 08:43:14.643455 21413 solver.cpp:244]     Train net output #0: loss = 0.0024707 (* 1 = 0.0024707 loss)
I0403 08:43:14.805794 21413 sgd_solver.cpp:106] Iteration 6960, lr = 5e-05
I0403 08:43:26.395628 21413 solver.cpp:228] Iteration 6976, loss = 0.00160494
I0403 08:43:26.395972 21413 solver.cpp:244]     Train net output #0: loss = 0.00160479 (* 1 = 0.00160479 loss)
I0403 08:43:26.594228 21413 sgd_solver.cpp:106] Iteration 6976, lr = 5e-05
I0403 08:43:38.170249 21413 solver.cpp:228] Iteration 6992, loss = 0.000657711
I0403 08:43:38.170369 21413 solver.cpp:244]     Train net output #0: loss = 0.000657564 (* 1 = 0.000657564 loss)
I0403 08:43:38.359134 21413 sgd_solver.cpp:106] Iteration 6992, lr = 5e-05
I0403 08:43:49.979912 21413 solver.cpp:228] Iteration 7008, loss = 0.0286382
I0403 08:43:49.980026 21413 solver.cpp:244]     Train net output #0: loss = 0.0286381 (* 1 = 0.0286381 loss)
I0403 08:43:50.189363 21413 sgd_solver.cpp:106] Iteration 7008, lr = 5e-05
I0403 08:44:01.685475 21413 solver.cpp:228] Iteration 7024, loss = 0.0145442
I0403 08:44:01.685822 21413 solver.cpp:244]     Train net output #0: loss = 0.014544 (* 1 = 0.014544 loss)
I0403 08:44:01.876083 21413 sgd_solver.cpp:106] Iteration 7024, lr = 5e-05
I0403 08:44:13.560408 21413 solver.cpp:228] Iteration 7040, loss = 0.00976134
I0403 08:44:13.560518 21413 solver.cpp:244]     Train net output #0: loss = 0.00976121 (* 1 = 0.00976121 loss)
I0403 08:44:13.759186 21413 sgd_solver.cpp:106] Iteration 7040, lr = 5e-05
I0403 08:44:25.257411 21413 solver.cpp:228] Iteration 7056, loss = 0.0241713
I0403 08:44:25.257515 21413 solver.cpp:244]     Train net output #0: loss = 0.0241711 (* 1 = 0.0241711 loss)
I0403 08:44:25.394400 21413 sgd_solver.cpp:106] Iteration 7056, lr = 5e-05
I0403 08:44:37.054636 21413 solver.cpp:228] Iteration 7072, loss = 0.0554729
I0403 08:44:37.055006 21413 solver.cpp:244]     Train net output #0: loss = 0.0554728 (* 1 = 0.0554728 loss)
I0403 08:44:37.294221 21413 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 08:44:48.943681 21413 solver.cpp:228] Iteration 7088, loss = 0.0276931
I0403 08:44:48.943794 21413 solver.cpp:244]     Train net output #0: loss = 0.0276929 (* 1 = 0.0276929 loss)
I0403 08:44:49.165329 21413 sgd_solver.cpp:106] Iteration 7088, lr = 5e-05
I0403 08:45:00.638238 21413 solver.cpp:228] Iteration 7104, loss = 0.00361289
I0403 08:45:00.638347 21413 solver.cpp:244]     Train net output #0: loss = 0.00361275 (* 1 = 0.00361275 loss)
I0403 08:45:00.844030 21413 sgd_solver.cpp:106] Iteration 7104, lr = 5e-05
I0403 08:45:12.319833 21413 solver.cpp:228] Iteration 7120, loss = 0.0108231
I0403 08:45:12.320214 21413 solver.cpp:244]     Train net output #0: loss = 0.010823 (* 1 = 0.010823 loss)
I0403 08:45:12.504487 21413 sgd_solver.cpp:106] Iteration 7120, lr = 5e-05
I0403 08:45:24.000314 21413 solver.cpp:228] Iteration 7136, loss = 0.0286431
I0403 08:45:24.000416 21413 solver.cpp:244]     Train net output #0: loss = 0.028643 (* 1 = 0.028643 loss)
I0403 08:45:24.178303 21413 sgd_solver.cpp:106] Iteration 7136, lr = 5e-05
I0403 08:45:33.759518 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_7150.caffemodel
I0403 08:45:36.480720 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_7150.solverstate
I0403 08:45:38.375633 21413 solver.cpp:337] Iteration 7150, Testing net (#0)
I0403 08:46:27.426764 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959954
I0403 08:46:27.427121 21413 solver.cpp:404]     Test net output #1: loss = 0.154563 (* 1 = 0.154563 loss)
I0403 08:46:29.428658 21413 solver.cpp:228] Iteration 7152, loss = 0.0101276
I0403 08:46:29.428763 21413 solver.cpp:244]     Train net output #0: loss = 0.0101274 (* 1 = 0.0101274 loss)
I0403 08:46:29.614657 21413 sgd_solver.cpp:106] Iteration 7152, lr = 5e-05
I0403 08:46:41.195749 21413 solver.cpp:228] Iteration 7168, loss = 0.0166953
I0403 08:46:41.195860 21413 solver.cpp:244]     Train net output #0: loss = 0.0166951 (* 1 = 0.0166951 loss)
I0403 08:46:41.396920 21413 sgd_solver.cpp:106] Iteration 7168, lr = 5e-05
I0403 08:46:52.975500 21413 solver.cpp:228] Iteration 7184, loss = 0.011536
I0403 08:46:52.975610 21413 solver.cpp:244]     Train net output #0: loss = 0.0115359 (* 1 = 0.0115359 loss)
I0403 08:46:53.170037 21413 sgd_solver.cpp:106] Iteration 7184, lr = 5e-05
I0403 08:47:04.890760 21413 solver.cpp:228] Iteration 7200, loss = 0.0136677
I0403 08:47:04.891039 21413 solver.cpp:244]     Train net output #0: loss = 0.0136676 (* 1 = 0.0136676 loss)
I0403 08:47:05.100970 21413 sgd_solver.cpp:106] Iteration 7200, lr = 5e-05
I0403 08:47:16.659787 21413 solver.cpp:228] Iteration 7216, loss = 0.0140548
I0403 08:47:16.659899 21413 solver.cpp:244]     Train net output #0: loss = 0.0140546 (* 1 = 0.0140546 loss)
I0403 08:47:16.843961 21413 sgd_solver.cpp:106] Iteration 7216, lr = 5e-05
I0403 08:47:28.421663 21413 solver.cpp:228] Iteration 7232, loss = 0.00155514
I0403 08:47:28.421768 21413 solver.cpp:244]     Train net output #0: loss = 0.00155501 (* 1 = 0.00155501 loss)
I0403 08:47:28.599714 21413 sgd_solver.cpp:106] Iteration 7232, lr = 5e-05
I0403 08:47:40.330162 21413 solver.cpp:228] Iteration 7248, loss = 0.0425313
I0403 08:47:40.330487 21413 solver.cpp:244]     Train net output #0: loss = 0.0425312 (* 1 = 0.0425312 loss)
I0403 08:47:40.508606 21413 sgd_solver.cpp:106] Iteration 7248, lr = 5e-05
I0403 08:47:51.990671 21413 solver.cpp:228] Iteration 7264, loss = 0.0201539
I0403 08:47:51.990787 21413 solver.cpp:244]     Train net output #0: loss = 0.0201537 (* 1 = 0.0201537 loss)
I0403 08:47:52.202425 21413 sgd_solver.cpp:106] Iteration 7264, lr = 5e-05
I0403 08:48:03.587455 21413 solver.cpp:228] Iteration 7280, loss = 0.0376527
I0403 08:48:03.587561 21413 solver.cpp:244]     Train net output #0: loss = 0.0376526 (* 1 = 0.0376526 loss)
I0403 08:48:03.763799 21413 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 08:48:15.356647 21413 solver.cpp:228] Iteration 7296, loss = 0.0157719
I0403 08:48:15.356984 21413 solver.cpp:244]     Train net output #0: loss = 0.0157718 (* 1 = 0.0157718 loss)
I0403 08:48:15.539873 21413 sgd_solver.cpp:106] Iteration 7296, lr = 5e-05
I0403 08:48:26.998034 21413 solver.cpp:228] Iteration 7312, loss = 0.0104521
I0403 08:48:26.998157 21413 solver.cpp:244]     Train net output #0: loss = 0.010452 (* 1 = 0.010452 loss)
I0403 08:48:27.181282 21413 sgd_solver.cpp:106] Iteration 7312, lr = 5e-05
I0403 08:48:38.651962 21413 solver.cpp:228] Iteration 7328, loss = 0.00618175
I0403 08:48:38.658835 21413 solver.cpp:244]     Train net output #0: loss = 0.00618163 (* 1 = 0.00618163 loss)
I0403 08:48:38.872668 21413 sgd_solver.cpp:106] Iteration 7328, lr = 5e-05
I0403 08:48:50.263779 21413 solver.cpp:228] Iteration 7344, loss = 0.0245144
I0403 08:48:50.264158 21413 solver.cpp:244]     Train net output #0: loss = 0.0245143 (* 1 = 0.0245143 loss)
I0403 08:48:50.462734 21413 sgd_solver.cpp:106] Iteration 7344, lr = 5e-05
I0403 08:49:02.172513 21413 solver.cpp:228] Iteration 7360, loss = 0.0291254
I0403 08:49:02.172677 21413 solver.cpp:244]     Train net output #0: loss = 0.0291253 (* 1 = 0.0291253 loss)
I0403 08:49:02.356159 21413 sgd_solver.cpp:106] Iteration 7360, lr = 5e-05
I0403 08:49:13.833047 21413 solver.cpp:228] Iteration 7376, loss = 0.0262519
I0403 08:49:13.833163 21413 solver.cpp:244]     Train net output #0: loss = 0.0262517 (* 1 = 0.0262517 loss)
I0403 08:49:14.020325 21413 sgd_solver.cpp:106] Iteration 7376, lr = 5e-05
I0403 08:49:25.583423 21413 solver.cpp:228] Iteration 7392, loss = 0.00843762
I0403 08:49:25.583777 21413 solver.cpp:244]     Train net output #0: loss = 0.0084375 (* 1 = 0.0084375 loss)
I0403 08:49:25.769686 21413 sgd_solver.cpp:106] Iteration 7392, lr = 5e-05
I0403 08:49:37.322338 21413 solver.cpp:228] Iteration 7408, loss = 0.0236162
I0403 08:49:37.322458 21413 solver.cpp:244]     Train net output #0: loss = 0.023616 (* 1 = 0.023616 loss)
I0403 08:49:37.522707 21413 sgd_solver.cpp:106] Iteration 7408, lr = 5e-05
I0403 08:49:49.095650 21413 solver.cpp:228] Iteration 7424, loss = 0.0309235
I0403 08:49:49.095754 21413 solver.cpp:244]     Train net output #0: loss = 0.0309233 (* 1 = 0.0309233 loss)
I0403 08:49:49.258266 21413 sgd_solver.cpp:106] Iteration 7424, lr = 5e-05
I0403 08:50:00.849442 21413 solver.cpp:228] Iteration 7440, loss = 0.0203996
I0403 08:50:00.849755 21413 solver.cpp:244]     Train net output #0: loss = 0.0203994 (* 1 = 0.0203994 loss)
I0403 08:50:01.052136 21413 sgd_solver.cpp:106] Iteration 7440, lr = 5e-05
I0403 08:50:12.747876 21413 solver.cpp:228] Iteration 7456, loss = 0.0372083
I0403 08:50:12.747993 21413 solver.cpp:244]     Train net output #0: loss = 0.0372082 (* 1 = 0.0372082 loss)
I0403 08:50:12.959489 21413 sgd_solver.cpp:106] Iteration 7456, lr = 5e-05
I0403 08:50:24.555661 21413 solver.cpp:228] Iteration 7472, loss = 0.010064
I0403 08:50:24.555778 21413 solver.cpp:244]     Train net output #0: loss = 0.0100639 (* 1 = 0.0100639 loss)
I0403 08:50:24.739202 21413 sgd_solver.cpp:106] Iteration 7472, lr = 5e-05
I0403 08:50:26.175186 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_7475.caffemodel
I0403 08:50:28.764421 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_7475.solverstate
I0403 08:50:30.587316 21413 solver.cpp:337] Iteration 7475, Testing net (#0)
I0403 08:51:19.636224 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959678
I0403 08:51:19.636571 21413 solver.cpp:404]     Test net output #1: loss = 0.154904 (* 1 = 0.154904 loss)
I0403 08:51:29.696928 21413 solver.cpp:228] Iteration 7488, loss = 0.00922523
I0403 08:51:29.697031 21413 solver.cpp:244]     Train net output #0: loss = 0.0092251 (* 1 = 0.0092251 loss)
I0403 08:51:29.873709 21413 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 08:51:41.367259 21413 solver.cpp:228] Iteration 7504, loss = 0.0178975
I0403 08:51:41.367362 21413 solver.cpp:244]     Train net output #0: loss = 0.0178973 (* 1 = 0.0178973 loss)
I0403 08:51:41.545588 21413 sgd_solver.cpp:106] Iteration 7504, lr = 5e-05
I0403 08:51:53.043859 21413 solver.cpp:228] Iteration 7520, loss = 0.0257439
I0403 08:51:53.044215 21413 solver.cpp:244]     Train net output #0: loss = 0.0257437 (* 1 = 0.0257437 loss)
I0403 08:51:53.237884 21413 sgd_solver.cpp:106] Iteration 7520, lr = 5e-05
I0403 08:52:04.770158 21413 solver.cpp:228] Iteration 7536, loss = 0.0548219
I0403 08:52:04.770262 21413 solver.cpp:244]     Train net output #0: loss = 0.0548218 (* 1 = 0.0548218 loss)
I0403 08:52:04.939530 21413 sgd_solver.cpp:106] Iteration 7536, lr = 5e-05
I0403 08:52:16.478788 21413 solver.cpp:228] Iteration 7552, loss = 0.00884783
I0403 08:52:16.478899 21413 solver.cpp:244]     Train net output #0: loss = 0.00884772 (* 1 = 0.00884772 loss)
I0403 08:52:16.688750 21413 sgd_solver.cpp:106] Iteration 7552, lr = 5e-05
I0403 08:52:28.100978 21413 solver.cpp:228] Iteration 7568, loss = 0.00821583
I0403 08:52:28.101327 21413 solver.cpp:244]     Train net output #0: loss = 0.00821571 (* 1 = 0.00821571 loss)
I0403 08:52:28.292649 21413 sgd_solver.cpp:106] Iteration 7568, lr = 5e-05
I0403 08:52:39.729583 21413 solver.cpp:228] Iteration 7584, loss = 0.0344864
I0403 08:52:39.729698 21413 solver.cpp:244]     Train net output #0: loss = 0.0344863 (* 1 = 0.0344863 loss)
I0403 08:52:39.967193 21413 sgd_solver.cpp:106] Iteration 7584, lr = 5e-05
I0403 08:52:51.641237 21413 solver.cpp:228] Iteration 7600, loss = 0.00279032
I0403 08:52:51.641340 21413 solver.cpp:244]     Train net output #0: loss = 0.0027902 (* 1 = 0.0027902 loss)
I0403 08:52:51.821969 21413 sgd_solver.cpp:106] Iteration 7600, lr = 5e-05
I0403 08:53:03.424768 21413 solver.cpp:228] Iteration 7616, loss = 0.0403691
I0403 08:53:03.425112 21413 solver.cpp:244]     Train net output #0: loss = 0.040369 (* 1 = 0.040369 loss)
I0403 08:53:03.621132 21413 sgd_solver.cpp:106] Iteration 7616, lr = 5e-05
I0403 08:53:15.150833 21413 solver.cpp:228] Iteration 7632, loss = 0.00171025
I0403 08:53:15.150950 21413 solver.cpp:244]     Train net output #0: loss = 0.00171013 (* 1 = 0.00171013 loss)
I0403 08:53:15.399055 21413 sgd_solver.cpp:106] Iteration 7632, lr = 5e-05
I0403 08:53:27.195452 21413 solver.cpp:228] Iteration 7648, loss = 0.0314169
I0403 08:53:27.195570 21413 solver.cpp:244]     Train net output #0: loss = 0.0314168 (* 1 = 0.0314168 loss)
I0403 08:53:27.364702 21413 sgd_solver.cpp:106] Iteration 7648, lr = 5e-05
I0403 08:53:38.773484 21413 solver.cpp:228] Iteration 7664, loss = 0.0221187
I0403 08:53:38.773834 21413 solver.cpp:244]     Train net output #0: loss = 0.0221186 (* 1 = 0.0221186 loss)
I0403 08:53:38.983062 21413 sgd_solver.cpp:106] Iteration 7664, lr = 5e-05
I0403 08:53:50.594112 21413 solver.cpp:228] Iteration 7680, loss = 0.00307084
I0403 08:53:50.594228 21413 solver.cpp:244]     Train net output #0: loss = 0.00307072 (* 1 = 0.00307072 loss)
I0403 08:53:50.825410 21413 sgd_solver.cpp:106] Iteration 7680, lr = 5e-05
I0403 08:54:02.364759 21413 solver.cpp:228] Iteration 7696, loss = 0.0397633
I0403 08:54:02.364864 21413 solver.cpp:244]     Train net output #0: loss = 0.0397632 (* 1 = 0.0397632 loss)
I0403 08:54:02.484274 21413 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 08:54:14.174885 21413 solver.cpp:228] Iteration 7712, loss = 0.00162276
I0403 08:54:14.175205 21413 solver.cpp:244]     Train net output #0: loss = 0.00162264 (* 1 = 0.00162264 loss)
I0403 08:54:14.358331 21413 sgd_solver.cpp:106] Iteration 7712, lr = 5e-05
I0403 08:54:25.875787 21413 solver.cpp:228] Iteration 7728, loss = 0.0301019
I0403 08:54:25.875900 21413 solver.cpp:244]     Train net output #0: loss = 0.0301018 (* 1 = 0.0301018 loss)
I0403 08:54:26.079412 21413 sgd_solver.cpp:106] Iteration 7728, lr = 5e-05
I0403 08:54:37.575803 21413 solver.cpp:228] Iteration 7744, loss = 0.0233634
I0403 08:54:37.575922 21413 solver.cpp:244]     Train net output #0: loss = 0.0233633 (* 1 = 0.0233633 loss)
I0403 08:54:37.819383 21413 sgd_solver.cpp:106] Iteration 7744, lr = 5e-05
I0403 08:54:49.438959 21413 solver.cpp:228] Iteration 7760, loss = 0.0277758
I0403 08:54:49.439319 21413 solver.cpp:244]     Train net output #0: loss = 0.0277757 (* 1 = 0.0277757 loss)
I0403 08:54:49.647413 21413 sgd_solver.cpp:106] Iteration 7760, lr = 5e-05
I0403 08:55:01.127290 21413 solver.cpp:228] Iteration 7776, loss = 0.0109618
I0403 08:55:01.127391 21413 solver.cpp:244]     Train net output #0: loss = 0.0109617 (* 1 = 0.0109617 loss)
I0403 08:55:01.267467 21413 sgd_solver.cpp:106] Iteration 7776, lr = 5e-05
I0403 08:55:12.816980 21413 solver.cpp:228] Iteration 7792, loss = 0.0132531
I0403 08:55:12.817098 21413 solver.cpp:244]     Train net output #0: loss = 0.013253 (* 1 = 0.013253 loss)
I0403 08:55:13.002904 21413 sgd_solver.cpp:106] Iteration 7792, lr = 5e-05
I0403 08:55:18.127877 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_7800.caffemodel
I0403 08:55:20.747248 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_7800.solverstate
I0403 08:55:22.520249 21413 solver.cpp:337] Iteration 7800, Testing net (#0)
I0403 08:56:11.558830 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959539
I0403 08:56:11.559166 21413 solver.cpp:404]     Test net output #1: loss = 0.153768 (* 1 = 0.153768 loss)
I0403 08:56:17.967531 21413 solver.cpp:228] Iteration 7808, loss = 0.00831787
I0403 08:56:17.967646 21413 solver.cpp:244]     Train net output #0: loss = 0.00831777 (* 1 = 0.00831777 loss)
I0403 08:56:18.200640 21413 sgd_solver.cpp:106] Iteration 7808, lr = 5e-05
I0403 08:56:29.863971 21413 solver.cpp:228] Iteration 7824, loss = 0.0255168
I0403 08:56:29.864086 21413 solver.cpp:244]     Train net output #0: loss = 0.0255167 (* 1 = 0.0255167 loss)
I0403 08:56:30.059137 21413 sgd_solver.cpp:106] Iteration 7824, lr = 5e-05
I0403 08:56:41.726574 21413 solver.cpp:228] Iteration 7840, loss = 0.0522333
I0403 08:56:41.726922 21413 solver.cpp:244]     Train net output #0: loss = 0.0522332 (* 1 = 0.0522332 loss)
I0403 08:56:41.950983 21413 sgd_solver.cpp:106] Iteration 7840, lr = 5e-05
I0403 08:56:53.680711 21413 solver.cpp:228] Iteration 7856, loss = 0.0537455
I0403 08:56:53.680819 21413 solver.cpp:244]     Train net output #0: loss = 0.0537454 (* 1 = 0.0537454 loss)
I0403 08:56:53.863858 21413 sgd_solver.cpp:106] Iteration 7856, lr = 5e-05
I0403 08:57:05.424690 21413 solver.cpp:228] Iteration 7872, loss = 0.0097241
I0403 08:57:05.424808 21413 solver.cpp:244]     Train net output #0: loss = 0.009724 (* 1 = 0.009724 loss)
I0403 08:57:05.626852 21413 sgd_solver.cpp:106] Iteration 7872, lr = 5e-05
I0403 08:57:17.171506 21413 solver.cpp:228] Iteration 7888, loss = 0.00394834
I0403 08:57:17.171798 21413 solver.cpp:244]     Train net output #0: loss = 0.00394826 (* 1 = 0.00394826 loss)
I0403 08:57:17.356955 21413 sgd_solver.cpp:106] Iteration 7888, lr = 5e-05
I0403 08:57:28.917137 21413 solver.cpp:228] Iteration 7904, loss = 0.00555028
I0403 08:57:28.917249 21413 solver.cpp:244]     Train net output #0: loss = 0.00555019 (* 1 = 0.00555019 loss)
I0403 08:57:29.104434 21413 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 08:57:40.789050 21413 solver.cpp:228] Iteration 7920, loss = 0.0076067
I0403 08:57:40.789155 21413 solver.cpp:244]     Train net output #0: loss = 0.00760662 (* 1 = 0.00760662 loss)
I0403 08:57:40.941805 21413 sgd_solver.cpp:106] Iteration 7920, lr = 5e-05
I0403 08:57:52.574503 21413 solver.cpp:228] Iteration 7936, loss = 0.00183268
I0403 08:57:52.574842 21413 solver.cpp:244]     Train net output #0: loss = 0.00183258 (* 1 = 0.00183258 loss)
I0403 08:57:52.765136 21413 sgd_solver.cpp:106] Iteration 7936, lr = 5e-05
I0403 08:58:04.304438 21413 solver.cpp:228] Iteration 7952, loss = 0.00179465
I0403 08:58:04.304559 21413 solver.cpp:244]     Train net output #0: loss = 0.00179455 (* 1 = 0.00179455 loss)
I0403 08:58:04.495559 21413 sgd_solver.cpp:106] Iteration 7952, lr = 5e-05
I0403 08:58:15.905632 21413 solver.cpp:228] Iteration 7968, loss = 0.00661403
I0403 08:58:15.905743 21413 solver.cpp:244]     Train net output #0: loss = 0.00661394 (* 1 = 0.00661394 loss)
I0403 08:58:16.095983 21413 sgd_solver.cpp:106] Iteration 7968, lr = 5e-05
I0403 08:58:27.736016 21413 solver.cpp:228] Iteration 7984, loss = 0.0171676
I0403 08:58:27.736392 21413 solver.cpp:244]     Train net output #0: loss = 0.0171675 (* 1 = 0.0171675 loss)
I0403 08:58:27.903184 21413 sgd_solver.cpp:106] Iteration 7984, lr = 5e-05
I0403 08:58:39.438180 21413 solver.cpp:228] Iteration 8000, loss = 0.0141367
I0403 08:58:39.438287 21413 solver.cpp:244]     Train net output #0: loss = 0.0141366 (* 1 = 0.0141366 loss)
I0403 08:58:39.619072 21413 sgd_solver.cpp:106] Iteration 8000, lr = 5e-05
I0403 08:58:51.315470 21413 solver.cpp:228] Iteration 8016, loss = 0.0261296
I0403 08:58:51.315603 21413 solver.cpp:244]     Train net output #0: loss = 0.0261296 (* 1 = 0.0261296 loss)
I0403 08:58:51.507721 21413 sgd_solver.cpp:106] Iteration 8016, lr = 5e-05
I0403 08:59:02.930506 21413 solver.cpp:228] Iteration 8032, loss = 0.0142219
I0403 08:59:02.930809 21413 solver.cpp:244]     Train net output #0: loss = 0.0142218 (* 1 = 0.0142218 loss)
I0403 08:59:03.102933 21413 sgd_solver.cpp:106] Iteration 8032, lr = 5e-05
I0403 08:59:14.754446 21413 solver.cpp:228] Iteration 8048, loss = 0.0377192
I0403 08:59:14.754566 21413 solver.cpp:244]     Train net output #0: loss = 0.0377191 (* 1 = 0.0377191 loss)
I0403 08:59:14.939419 21413 sgd_solver.cpp:106] Iteration 8048, lr = 5e-05
I0403 08:59:26.642885 21413 solver.cpp:228] Iteration 8064, loss = 0.0208842
I0403 08:59:26.642999 21413 solver.cpp:244]     Train net output #0: loss = 0.0208841 (* 1 = 0.0208841 loss)
I0403 08:59:26.860350 21413 sgd_solver.cpp:106] Iteration 8064, lr = 5e-05
I0403 08:59:38.294426 21413 solver.cpp:228] Iteration 8080, loss = 0.00517639
I0403 08:59:38.294782 21413 solver.cpp:244]     Train net output #0: loss = 0.0051763 (* 1 = 0.0051763 loss)
I0403 08:59:38.477820 21413 sgd_solver.cpp:106] Iteration 8080, lr = 5e-05
I0403 08:59:50.004117 21413 solver.cpp:228] Iteration 8096, loss = 0.0206689
I0403 08:59:50.004228 21413 solver.cpp:244]     Train net output #0: loss = 0.0206688 (* 1 = 0.0206688 loss)
I0403 08:59:50.214082 21413 sgd_solver.cpp:106] Iteration 8096, lr = 5e-05
I0403 09:00:01.717651 21413 solver.cpp:228] Iteration 8112, loss = 0.00285795
I0403 09:00:01.717767 21413 solver.cpp:244]     Train net output #0: loss = 0.00285785 (* 1 = 0.00285785 loss)
I0403 09:00:01.904094 21413 sgd_solver.cpp:106] Iteration 8112, lr = 5e-05
I0403 09:00:10.707861 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_8125.caffemodel
I0403 09:00:13.343840 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_8125.solverstate
I0403 09:00:15.134019 21413 solver.cpp:337] Iteration 8125, Testing net (#0)
I0403 09:01:04.191377 21413 solver.cpp:404]     Test net output #0: accuracy = 0.960046
I0403 09:01:04.191715 21413 solver.cpp:404]     Test net output #1: loss = 0.154034 (* 1 = 0.154034 loss)
I0403 09:01:06.926841 21413 solver.cpp:228] Iteration 8128, loss = 0.0170828
I0403 09:01:06.926951 21413 solver.cpp:244]     Train net output #0: loss = 0.0170827 (* 1 = 0.0170827 loss)
I0403 09:01:07.119587 21413 sgd_solver.cpp:106] Iteration 8128, lr = 5e-05
I0403 09:01:18.555780 21413 solver.cpp:228] Iteration 8144, loss = 0.0194314
I0403 09:01:18.555907 21413 solver.cpp:244]     Train net output #0: loss = 0.0194313 (* 1 = 0.0194313 loss)
I0403 09:01:18.740236 21413 sgd_solver.cpp:106] Iteration 8144, lr = 5e-05
I0403 09:01:30.254492 21413 solver.cpp:228] Iteration 8160, loss = 0.00588899
I0403 09:01:30.254614 21413 solver.cpp:244]     Train net output #0: loss = 0.0058889 (* 1 = 0.0058889 loss)
I0403 09:01:30.443358 21413 sgd_solver.cpp:106] Iteration 8160, lr = 5e-05
I0403 09:01:41.915786 21413 solver.cpp:228] Iteration 8176, loss = 0.00862615
I0403 09:01:41.916131 21413 solver.cpp:244]     Train net output #0: loss = 0.00862605 (* 1 = 0.00862605 loss)
I0403 09:01:42.098615 21413 sgd_solver.cpp:106] Iteration 8176, lr = 5e-05
I0403 09:01:53.763005 21413 solver.cpp:228] Iteration 8192, loss = 0.00695462
I0403 09:01:53.763109 21413 solver.cpp:244]     Train net output #0: loss = 0.00695452 (* 1 = 0.00695452 loss)
I0403 09:01:53.941699 21413 sgd_solver.cpp:106] Iteration 8192, lr = 5e-05
I0403 09:02:05.553925 21413 solver.cpp:228] Iteration 8208, loss = 0.00571473
I0403 09:02:05.554034 21413 solver.cpp:244]     Train net output #0: loss = 0.00571463 (* 1 = 0.00571463 loss)
I0403 09:02:05.762580 21413 sgd_solver.cpp:106] Iteration 8208, lr = 5e-05
I0403 09:02:17.304924 21413 solver.cpp:228] Iteration 8224, loss = 0.0259318
I0403 09:02:17.305272 21413 solver.cpp:244]     Train net output #0: loss = 0.0259317 (* 1 = 0.0259317 loss)
I0403 09:02:17.504559 21413 sgd_solver.cpp:106] Iteration 8224, lr = 5e-05
I0403 09:02:29.045270 21413 solver.cpp:228] Iteration 8240, loss = 0.00562227
I0403 09:02:29.045372 21413 solver.cpp:244]     Train net output #0: loss = 0.00562217 (* 1 = 0.00562217 loss)
I0403 09:02:29.227207 21413 sgd_solver.cpp:106] Iteration 8240, lr = 5e-05
I0403 09:02:40.846745 21413 solver.cpp:228] Iteration 8256, loss = 0.0281862
I0403 09:02:40.846849 21413 solver.cpp:244]     Train net output #0: loss = 0.0281861 (* 1 = 0.0281861 loss)
I0403 09:02:41.025048 21413 sgd_solver.cpp:106] Iteration 8256, lr = 5e-05
I0403 09:02:52.643842 21413 solver.cpp:228] Iteration 8272, loss = 0.00934385
I0403 09:02:52.644181 21413 solver.cpp:244]     Train net output #0: loss = 0.00934375 (* 1 = 0.00934375 loss)
I0403 09:02:52.846458 21413 sgd_solver.cpp:106] Iteration 8272, lr = 5e-05
I0403 09:03:04.809872 21413 solver.cpp:228] Iteration 8288, loss = 0.00226924
I0403 09:03:04.809978 21413 solver.cpp:244]     Train net output #0: loss = 0.00226914 (* 1 = 0.00226914 loss)
I0403 09:03:04.990768 21413 sgd_solver.cpp:106] Iteration 8288, lr = 5e-05
I0403 09:03:16.590606 21413 solver.cpp:228] Iteration 8304, loss = 0.0350222
I0403 09:03:16.590714 21413 solver.cpp:244]     Train net output #0: loss = 0.0350221 (* 1 = 0.0350221 loss)
I0403 09:03:16.772320 21413 sgd_solver.cpp:106] Iteration 8304, lr = 5e-05
I0403 09:03:28.204994 21413 solver.cpp:228] Iteration 8320, loss = 0.02364
I0403 09:03:28.209386 21413 solver.cpp:244]     Train net output #0: loss = 0.0236399 (* 1 = 0.0236399 loss)
I0403 09:03:28.396951 21413 sgd_solver.cpp:106] Iteration 8320, lr = 5e-05
I0403 09:03:40.235875 21413 solver.cpp:228] Iteration 8336, loss = 0.00318393
I0403 09:03:40.235991 21413 solver.cpp:244]     Train net output #0: loss = 0.00318383 (* 1 = 0.00318383 loss)
I0403 09:03:40.436424 21413 sgd_solver.cpp:106] Iteration 8336, lr = 5e-05
I0403 09:03:51.893858 21413 solver.cpp:228] Iteration 8352, loss = 0.00474018
I0403 09:03:51.893972 21413 solver.cpp:244]     Train net output #0: loss = 0.00474007 (* 1 = 0.00474007 loss)
I0403 09:03:52.100147 21413 sgd_solver.cpp:106] Iteration 8352, lr = 5e-05
I0403 09:04:03.600512 21413 solver.cpp:228] Iteration 8368, loss = 0.0164272
I0403 09:04:03.600822 21413 solver.cpp:244]     Train net output #0: loss = 0.0164271 (* 1 = 0.0164271 loss)
I0403 09:04:03.792347 21413 sgd_solver.cpp:106] Iteration 8368, lr = 5e-05
I0403 09:04:15.447067 21413 solver.cpp:228] Iteration 8384, loss = 0.00355084
I0403 09:04:15.447181 21413 solver.cpp:244]     Train net output #0: loss = 0.00355073 (* 1 = 0.00355073 loss)
I0403 09:04:15.650847 21413 sgd_solver.cpp:106] Iteration 8384, lr = 5e-05
I0403 09:04:27.173887 21413 solver.cpp:228] Iteration 8400, loss = 0.00698333
I0403 09:04:27.174003 21413 solver.cpp:244]     Train net output #0: loss = 0.00698322 (* 1 = 0.00698322 loss)
I0403 09:04:27.380777 21413 sgd_solver.cpp:106] Iteration 8400, lr = 5e-05
I0403 09:04:39.000828 21413 solver.cpp:228] Iteration 8416, loss = 0.00447466
I0403 09:04:39.001137 21413 solver.cpp:244]     Train net output #0: loss = 0.00447455 (* 1 = 0.00447455 loss)
I0403 09:04:39.201872 21413 sgd_solver.cpp:106] Iteration 8416, lr = 5e-05
I0403 09:04:50.609522 21413 solver.cpp:228] Iteration 8432, loss = 0.0100508
I0403 09:04:50.609625 21413 solver.cpp:244]     Train net output #0: loss = 0.0100507 (* 1 = 0.0100507 loss)
I0403 09:04:50.788343 21413 sgd_solver.cpp:106] Iteration 8432, lr = 5e-05
I0403 09:05:02.354931 21413 solver.cpp:228] Iteration 8448, loss = 0.0187998
I0403 09:05:02.355051 21413 solver.cpp:244]     Train net output #0: loss = 0.0187997 (* 1 = 0.0187997 loss)
I0403 09:05:02.548241 21413 sgd_solver.cpp:106] Iteration 8448, lr = 5e-05
I0403 09:05:03.252815 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_8450.caffemodel
I0403 09:05:06.125321 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_8450.solverstate
I0403 09:05:08.033442 21413 solver.cpp:337] Iteration 8450, Testing net (#0)
I0403 09:05:57.085052 21413 solver.cpp:404]     Test net output #0: accuracy = 0.960139
I0403 09:05:57.085414 21413 solver.cpp:404]     Test net output #1: loss = 0.153894 (* 1 = 0.153894 loss)
I0403 09:06:07.854917 21413 solver.cpp:228] Iteration 8464, loss = 0.00244054
I0403 09:06:07.855044 21413 solver.cpp:244]     Train net output #0: loss = 0.00244043 (* 1 = 0.00244043 loss)
I0403 09:06:08.039067 21413 sgd_solver.cpp:106] Iteration 8464, lr = 5e-05
I0403 09:06:19.714143 21413 solver.cpp:228] Iteration 8480, loss = 0.024312
I0403 09:06:19.714257 21413 solver.cpp:244]     Train net output #0: loss = 0.0243119 (* 1 = 0.0243119 loss)
I0403 09:06:19.923424 21413 sgd_solver.cpp:106] Iteration 8480, lr = 5e-05
I0403 09:06:31.603629 21413 solver.cpp:228] Iteration 8496, loss = 0.0479723
I0403 09:06:31.603955 21413 solver.cpp:244]     Train net output #0: loss = 0.0479722 (* 1 = 0.0479722 loss)
I0403 09:06:31.792124 21413 sgd_solver.cpp:106] Iteration 8496, lr = 5e-05
I0403 09:06:43.389369 21413 solver.cpp:228] Iteration 8512, loss = 0.0273789
I0403 09:06:43.389483 21413 solver.cpp:244]     Train net output #0: loss = 0.0273787 (* 1 = 0.0273787 loss)
I0403 09:06:43.578770 21413 sgd_solver.cpp:106] Iteration 8512, lr = 5e-05
I0403 09:06:55.134866 21413 solver.cpp:228] Iteration 8528, loss = 0.0138813
I0403 09:06:55.134980 21413 solver.cpp:244]     Train net output #0: loss = 0.0138812 (* 1 = 0.0138812 loss)
I0403 09:06:55.359670 21413 sgd_solver.cpp:106] Iteration 8528, lr = 5e-05
I0403 09:07:06.873673 21413 solver.cpp:228] Iteration 8544, loss = 0.00931472
I0403 09:07:06.873971 21413 solver.cpp:244]     Train net output #0: loss = 0.00931461 (* 1 = 0.00931461 loss)
I0403 09:07:07.046960 21413 sgd_solver.cpp:106] Iteration 8544, lr = 5e-05
I0403 09:07:18.639304 21413 solver.cpp:228] Iteration 8560, loss = 0.00823258
I0403 09:07:18.639417 21413 solver.cpp:244]     Train net output #0: loss = 0.00823247 (* 1 = 0.00823247 loss)
I0403 09:07:18.843328 21413 sgd_solver.cpp:106] Iteration 8560, lr = 5e-05
I0403 09:07:30.419613 21413 solver.cpp:228] Iteration 8576, loss = 0.01509
I0403 09:07:30.419730 21413 solver.cpp:244]     Train net output #0: loss = 0.0150899 (* 1 = 0.0150899 loss)
I0403 09:07:30.608765 21413 sgd_solver.cpp:106] Iteration 8576, lr = 5e-05
I0403 09:07:42.183540 21413 solver.cpp:228] Iteration 8592, loss = 0.00427746
I0403 09:07:42.183871 21413 solver.cpp:244]     Train net output #0: loss = 0.00427735 (* 1 = 0.00427735 loss)
I0403 09:07:42.358714 21413 sgd_solver.cpp:106] Iteration 8592, lr = 5e-05
I0403 09:07:53.900023 21413 solver.cpp:228] Iteration 8608, loss = 0.0293125
I0403 09:07:53.900141 21413 solver.cpp:244]     Train net output #0: loss = 0.0293124 (* 1 = 0.0293124 loss)
I0403 09:07:54.097879 21413 sgd_solver.cpp:106] Iteration 8608, lr = 5e-05
I0403 09:08:05.634526 21413 solver.cpp:228] Iteration 8624, loss = 0.0717242
I0403 09:08:05.634654 21413 solver.cpp:244]     Train net output #0: loss = 0.0717241 (* 1 = 0.0717241 loss)
I0403 09:08:05.852006 21413 sgd_solver.cpp:106] Iteration 8624, lr = 5e-05
I0403 09:08:17.562537 21413 solver.cpp:228] Iteration 8640, loss = 0.00645801
I0403 09:08:17.562909 21413 solver.cpp:244]     Train net output #0: loss = 0.00645791 (* 1 = 0.00645791 loss)
I0403 09:08:17.772939 21413 sgd_solver.cpp:106] Iteration 8640, lr = 5e-05
I0403 09:08:29.378798 21413 solver.cpp:228] Iteration 8656, loss = 0.0143418
I0403 09:08:29.378914 21413 solver.cpp:244]     Train net output #0: loss = 0.0143417 (* 1 = 0.0143417 loss)
I0403 09:08:29.568338 21413 sgd_solver.cpp:106] Iteration 8656, lr = 5e-05
I0403 09:08:41.285513 21413 solver.cpp:228] Iteration 8672, loss = 0.015887
I0403 09:08:41.285629 21413 solver.cpp:244]     Train net output #0: loss = 0.0158869 (* 1 = 0.0158869 loss)
I0403 09:08:41.478680 21413 sgd_solver.cpp:106] Iteration 8672, lr = 5e-05
I0403 09:08:53.011646 21413 solver.cpp:228] Iteration 8688, loss = 0.0120089
I0403 09:08:53.011996 21413 solver.cpp:244]     Train net output #0: loss = 0.0120088 (* 1 = 0.0120088 loss)
I0403 09:08:53.197288 21413 sgd_solver.cpp:106] Iteration 8688, lr = 5e-05
I0403 09:09:04.635311 21413 solver.cpp:228] Iteration 8704, loss = 0.00557667
I0403 09:09:04.635427 21413 solver.cpp:244]     Train net output #0: loss = 0.00557656 (* 1 = 0.00557656 loss)
I0403 09:09:04.843154 21413 sgd_solver.cpp:106] Iteration 8704, lr = 5e-05
I0403 09:09:16.400244 21413 solver.cpp:228] Iteration 8720, loss = 0.0129604
I0403 09:09:16.400362 21413 solver.cpp:244]     Train net output #0: loss = 0.0129602 (* 1 = 0.0129602 loss)
I0403 09:09:16.592270 21413 sgd_solver.cpp:106] Iteration 8720, lr = 5e-05
I0403 09:09:28.212225 21413 solver.cpp:228] Iteration 8736, loss = 0.0117934
I0403 09:09:28.212553 21413 solver.cpp:244]     Train net output #0: loss = 0.0117933 (* 1 = 0.0117933 loss)
I0403 09:09:28.378397 21413 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 09:09:40.061290 21413 solver.cpp:228] Iteration 8752, loss = 0.0106734
I0403 09:09:40.061405 21413 solver.cpp:244]     Train net output #0: loss = 0.0106733 (* 1 = 0.0106733 loss)
I0403 09:09:40.303035 21413 sgd_solver.cpp:106] Iteration 8752, lr = 5e-05
I0403 09:09:51.879365 21413 solver.cpp:228] Iteration 8768, loss = 0.00970546
I0403 09:09:51.879482 21413 solver.cpp:244]     Train net output #0: loss = 0.00970535 (* 1 = 0.00970535 loss)
I0403 09:09:52.065203 21413 sgd_solver.cpp:106] Iteration 8768, lr = 5e-05
I0403 09:09:56.512358 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_8775.caffemodel
I0403 09:09:59.147217 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_8775.solverstate
I0403 09:10:00.915751 21413 solver.cpp:337] Iteration 8775, Testing net (#0)
I0403 09:10:49.981798 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959632
I0403 09:10:49.982113 21413 solver.cpp:404]     Test net output #1: loss = 0.154766 (* 1 = 0.154766 loss)
I0403 09:10:57.154335 21413 solver.cpp:228] Iteration 8784, loss = 0.00506752
I0403 09:10:57.154448 21413 solver.cpp:244]     Train net output #0: loss = 0.00506741 (* 1 = 0.00506741 loss)
I0403 09:10:57.345146 21413 sgd_solver.cpp:106] Iteration 8784, lr = 5e-05
I0403 09:11:08.776005 21413 solver.cpp:228] Iteration 8800, loss = 0.00969788
I0403 09:11:08.776121 21413 solver.cpp:244]     Train net output #0: loss = 0.00969777 (* 1 = 0.00969777 loss)
I0403 09:11:08.973228 21413 sgd_solver.cpp:106] Iteration 8800, lr = 5e-05
I0403 09:11:20.659220 21413 solver.cpp:228] Iteration 8816, loss = 0.0583981
I0403 09:11:20.659548 21413 solver.cpp:244]     Train net output #0: loss = 0.058398 (* 1 = 0.058398 loss)
I0403 09:11:20.852068 21413 sgd_solver.cpp:106] Iteration 8816, lr = 5e-05
I0403 09:11:32.374455 21413 solver.cpp:228] Iteration 8832, loss = 0.0182737
I0403 09:11:32.374574 21413 solver.cpp:244]     Train net output #0: loss = 0.0182736 (* 1 = 0.0182736 loss)
I0403 09:11:32.567143 21413 sgd_solver.cpp:106] Iteration 8832, lr = 5e-05
I0403 09:11:44.162765 21413 solver.cpp:228] Iteration 8848, loss = 0.00407594
I0403 09:11:44.162879 21413 solver.cpp:244]     Train net output #0: loss = 0.00407584 (* 1 = 0.00407584 loss)
I0403 09:11:44.379133 21413 sgd_solver.cpp:106] Iteration 8848, lr = 5e-05
I0403 09:11:56.012917 21413 solver.cpp:228] Iteration 8864, loss = 0.0120322
I0403 09:11:56.013278 21413 solver.cpp:244]     Train net output #0: loss = 0.0120321 (* 1 = 0.0120321 loss)
I0403 09:11:56.236631 21413 sgd_solver.cpp:106] Iteration 8864, lr = 5e-05
I0403 09:12:07.724436 21413 solver.cpp:228] Iteration 8880, loss = 0.00166491
I0403 09:12:07.724553 21413 solver.cpp:244]     Train net output #0: loss = 0.00166481 (* 1 = 0.00166481 loss)
I0403 09:12:07.927141 21413 sgd_solver.cpp:106] Iteration 8880, lr = 5e-05
I0403 09:12:19.435298 21413 solver.cpp:228] Iteration 8896, loss = 0.00651016
I0403 09:12:19.435401 21413 solver.cpp:244]     Train net output #0: loss = 0.00651006 (* 1 = 0.00651006 loss)
I0403 09:12:19.617445 21413 sgd_solver.cpp:106] Iteration 8896, lr = 5e-05
I0403 09:12:31.061305 21413 solver.cpp:228] Iteration 8912, loss = 0.00265068
I0403 09:12:31.061630 21413 solver.cpp:244]     Train net output #0: loss = 0.00265058 (* 1 = 0.00265058 loss)
I0403 09:12:31.242123 21413 sgd_solver.cpp:106] Iteration 8912, lr = 5e-05
I0403 09:12:42.812294 21413 solver.cpp:228] Iteration 8928, loss = 0.00722763
I0403 09:12:42.812408 21413 solver.cpp:244]     Train net output #0: loss = 0.00722753 (* 1 = 0.00722753 loss)
I0403 09:12:43.013082 21413 sgd_solver.cpp:106] Iteration 8928, lr = 5e-05
I0403 09:12:54.758080 21413 solver.cpp:228] Iteration 8944, loss = 0.000910508
I0403 09:12:54.758196 21413 solver.cpp:244]     Train net output #0: loss = 0.000910416 (* 1 = 0.000910416 loss)
I0403 09:12:54.954315 21413 sgd_solver.cpp:106] Iteration 8944, lr = 5e-05
I0403 09:13:06.582989 21413 solver.cpp:228] Iteration 8960, loss = 0.00441298
I0403 09:13:06.583330 21413 solver.cpp:244]     Train net output #0: loss = 0.00441288 (* 1 = 0.00441288 loss)
I0403 09:13:06.776087 21413 sgd_solver.cpp:106] Iteration 8960, lr = 5e-05
I0403 09:13:18.315752 21413 solver.cpp:228] Iteration 8976, loss = 0.0133862
I0403 09:13:18.315855 21413 solver.cpp:244]     Train net output #0: loss = 0.0133861 (* 1 = 0.0133861 loss)
I0403 09:13:18.478094 21413 sgd_solver.cpp:106] Iteration 8976, lr = 5e-05
I0403 09:13:30.028759 21413 solver.cpp:228] Iteration 8992, loss = 0.0368688
I0403 09:13:30.028875 21413 solver.cpp:244]     Train net output #0: loss = 0.0368687 (* 1 = 0.0368687 loss)
I0403 09:13:30.211411 21413 sgd_solver.cpp:106] Iteration 8992, lr = 5e-05
I0403 09:13:41.855345 21413 solver.cpp:228] Iteration 9008, loss = 0.0142424
I0403 09:13:41.855671 21413 solver.cpp:244]     Train net output #0: loss = 0.0142423 (* 1 = 0.0142423 loss)
I0403 09:13:42.040606 21413 sgd_solver.cpp:106] Iteration 9008, lr = 5e-05
I0403 09:13:53.550227 21413 solver.cpp:228] Iteration 9024, loss = 0.0413297
I0403 09:13:53.550345 21413 solver.cpp:244]     Train net output #0: loss = 0.0413296 (* 1 = 0.0413296 loss)
I0403 09:13:53.735486 21413 sgd_solver.cpp:106] Iteration 9024, lr = 5e-05
I0403 09:14:05.273372 21413 solver.cpp:228] Iteration 9040, loss = 0.0131904
I0403 09:14:05.273490 21413 solver.cpp:244]     Train net output #0: loss = 0.0131903 (* 1 = 0.0131903 loss)
I0403 09:14:05.459735 21413 sgd_solver.cpp:106] Iteration 9040, lr = 5e-05
I0403 09:14:16.976208 21413 solver.cpp:228] Iteration 9056, loss = 0.00424318
I0403 09:14:16.976512 21413 solver.cpp:244]     Train net output #0: loss = 0.00424309 (* 1 = 0.00424309 loss)
I0403 09:14:17.165405 21413 sgd_solver.cpp:106] Iteration 9056, lr = 5e-05
I0403 09:14:28.825469 21413 solver.cpp:228] Iteration 9072, loss = 0.0230318
I0403 09:14:28.825587 21413 solver.cpp:244]     Train net output #0: loss = 0.0230317 (* 1 = 0.0230317 loss)
I0403 09:14:29.033567 21413 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 09:14:40.804981 21413 solver.cpp:228] Iteration 9088, loss = 0.00610285
I0403 09:14:40.805099 21413 solver.cpp:244]     Train net output #0: loss = 0.00610276 (* 1 = 0.00610276 loss)
I0403 09:14:41.005372 21413 sgd_solver.cpp:106] Iteration 9088, lr = 5e-05
I0403 09:14:49.116665 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9100.caffemodel
I0403 09:14:51.870187 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9100.solverstate
I0403 09:14:53.766693 21413 solver.cpp:337] Iteration 9100, Testing net (#0)
I0403 09:15:42.819844 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959724
I0403 09:15:42.820173 21413 solver.cpp:404]     Test net output #1: loss = 0.155014 (* 1 = 0.155014 loss)
I0403 09:15:46.252168 21413 solver.cpp:228] Iteration 9104, loss = 0.0197698
I0403 09:15:46.252272 21413 solver.cpp:244]     Train net output #0: loss = 0.0197697 (* 1 = 0.0197697 loss)
I0403 09:15:46.427306 21413 sgd_solver.cpp:106] Iteration 9104, lr = 5e-05
I0403 09:15:57.979377 21413 solver.cpp:228] Iteration 9120, loss = 0.0440144
I0403 09:15:57.979490 21413 solver.cpp:244]     Train net output #0: loss = 0.0440143 (* 1 = 0.0440143 loss)
I0403 09:15:58.193658 21413 sgd_solver.cpp:106] Iteration 9120, lr = 5e-05
I0403 09:16:09.734628 21413 solver.cpp:228] Iteration 9136, loss = 0.0128916
I0403 09:16:09.734738 21413 solver.cpp:244]     Train net output #0: loss = 0.0128915 (* 1 = 0.0128915 loss)
I0403 09:16:09.917829 21413 sgd_solver.cpp:106] Iteration 9136, lr = 5e-05
I0403 09:16:21.340513 21413 solver.cpp:228] Iteration 9152, loss = 0.00856804
I0403 09:16:21.340844 21413 solver.cpp:244]     Train net output #0: loss = 0.00856794 (* 1 = 0.00856794 loss)
I0403 09:16:21.522881 21413 sgd_solver.cpp:106] Iteration 9152, lr = 5e-05
I0403 09:16:33.082521 21413 solver.cpp:228] Iteration 9168, loss = 0.0284168
I0403 09:16:33.082635 21413 solver.cpp:244]     Train net output #0: loss = 0.0284167 (* 1 = 0.0284167 loss)
I0403 09:16:33.265142 21413 sgd_solver.cpp:106] Iteration 9168, lr = 5e-05
I0403 09:16:44.817569 21413 solver.cpp:228] Iteration 9184, loss = 0.00480447
I0403 09:16:44.817685 21413 solver.cpp:244]     Train net output #0: loss = 0.00480437 (* 1 = 0.00480437 loss)
I0403 09:16:45.027637 21413 sgd_solver.cpp:106] Iteration 9184, lr = 5e-05
I0403 09:16:56.492084 21413 solver.cpp:228] Iteration 9200, loss = 0.0156037
I0403 09:16:56.492434 21413 solver.cpp:244]     Train net output #0: loss = 0.0156036 (* 1 = 0.0156036 loss)
I0403 09:16:56.689607 21413 sgd_solver.cpp:106] Iteration 9200, lr = 5e-05
I0403 09:17:08.242974 21413 solver.cpp:228] Iteration 9216, loss = 0.0127654
I0403 09:17:08.243089 21413 solver.cpp:244]     Train net output #0: loss = 0.0127653 (* 1 = 0.0127653 loss)
I0403 09:17:08.472666 21413 sgd_solver.cpp:106] Iteration 9216, lr = 5e-05
I0403 09:17:19.900459 21413 solver.cpp:228] Iteration 9232, loss = 0.0109808
I0403 09:17:19.900566 21413 solver.cpp:244]     Train net output #0: loss = 0.0109807 (* 1 = 0.0109807 loss)
I0403 09:17:20.076774 21413 sgd_solver.cpp:106] Iteration 9232, lr = 5e-05
I0403 09:17:31.711452 21413 solver.cpp:228] Iteration 9248, loss = 0.0228091
I0403 09:17:31.711789 21413 solver.cpp:244]     Train net output #0: loss = 0.022809 (* 1 = 0.022809 loss)
I0403 09:17:31.892874 21413 sgd_solver.cpp:106] Iteration 9248, lr = 5e-05
I0403 09:17:43.594735 21413 solver.cpp:228] Iteration 9264, loss = 0.00467631
I0403 09:17:43.594841 21413 solver.cpp:244]     Train net output #0: loss = 0.00467622 (* 1 = 0.00467622 loss)
I0403 09:17:43.806605 21413 sgd_solver.cpp:106] Iteration 9264, lr = 5e-05
I0403 09:17:55.483610 21413 solver.cpp:228] Iteration 9280, loss = 0.0020101
I0403 09:17:55.483728 21413 solver.cpp:244]     Train net output #0: loss = 0.00201001 (* 1 = 0.00201001 loss)
I0403 09:17:55.685889 21413 sgd_solver.cpp:106] Iteration 9280, lr = 5e-05
I0403 09:18:07.355083 21413 solver.cpp:228] Iteration 9296, loss = 0.0226866
I0403 09:18:07.355386 21413 solver.cpp:244]     Train net output #0: loss = 0.0226865 (* 1 = 0.0226865 loss)
I0403 09:18:07.525327 21413 sgd_solver.cpp:106] Iteration 9296, lr = 5e-05
I0403 09:18:19.105224 21413 solver.cpp:228] Iteration 9312, loss = 0.0156233
I0403 09:18:19.105336 21413 solver.cpp:244]     Train net output #0: loss = 0.0156232 (* 1 = 0.0156232 loss)
I0403 09:18:19.298380 21413 sgd_solver.cpp:106] Iteration 9312, lr = 5e-05
I0403 09:18:30.792667 21413 solver.cpp:228] Iteration 9328, loss = 0.0125502
I0403 09:18:30.792771 21413 solver.cpp:244]     Train net output #0: loss = 0.0125501 (* 1 = 0.0125501 loss)
I0403 09:18:30.975401 21413 sgd_solver.cpp:106] Iteration 9328, lr = 5e-05
I0403 09:18:42.458823 21413 solver.cpp:228] Iteration 9344, loss = 0.00892486
I0403 09:18:42.459203 21413 solver.cpp:244]     Train net output #0: loss = 0.00892478 (* 1 = 0.00892478 loss)
I0403 09:18:42.643492 21413 sgd_solver.cpp:106] Iteration 9344, lr = 5e-05
I0403 09:18:54.164412 21413 solver.cpp:228] Iteration 9360, loss = 0.024755
I0403 09:18:54.164527 21413 solver.cpp:244]     Train net output #0: loss = 0.0247549 (* 1 = 0.0247549 loss)
I0403 09:18:54.352167 21413 sgd_solver.cpp:106] Iteration 9360, lr = 5e-05
I0403 09:19:05.883718 21413 solver.cpp:228] Iteration 9376, loss = 0.0567282
I0403 09:19:05.883832 21413 solver.cpp:244]     Train net output #0: loss = 0.0567281 (* 1 = 0.0567281 loss)
I0403 09:19:06.092911 21413 sgd_solver.cpp:106] Iteration 9376, lr = 5e-05
I0403 09:19:17.588975 21413 solver.cpp:228] Iteration 9392, loss = 0.00761819
I0403 09:19:17.589352 21413 solver.cpp:244]     Train net output #0: loss = 0.0076181 (* 1 = 0.0076181 loss)
I0403 09:19:17.803313 21413 sgd_solver.cpp:106] Iteration 9392, lr = 5e-05
I0403 09:19:29.374173 21413 solver.cpp:228] Iteration 9408, loss = 0.00363221
I0403 09:19:29.374284 21413 solver.cpp:244]     Train net output #0: loss = 0.00363213 (* 1 = 0.00363213 loss)
I0403 09:19:29.572875 21413 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 09:19:41.169317 21413 solver.cpp:228] Iteration 9424, loss = 0.00634323
I0403 09:19:41.169421 21413 solver.cpp:244]     Train net output #0: loss = 0.00634315 (* 1 = 0.00634315 loss)
I0403 09:19:41.338764 21413 sgd_solver.cpp:106] Iteration 9424, lr = 5e-05
I0403 09:19:41.338996 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9425.caffemodel
I0403 09:19:44.128185 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9425.solverstate
I0403 09:19:46.018471 21413 solver.cpp:337] Iteration 9425, Testing net (#0)
I0403 09:20:35.069252 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959678
I0403 09:20:35.069588 21413 solver.cpp:404]     Test net output #1: loss = 0.155229 (* 1 = 0.155229 loss)
I0403 09:20:46.527534 21413 solver.cpp:228] Iteration 9440, loss = 0.00244205
I0403 09:20:46.527648 21413 solver.cpp:244]     Train net output #0: loss = 0.00244197 (* 1 = 0.00244197 loss)
I0403 09:20:46.733299 21413 sgd_solver.cpp:106] Iteration 9440, lr = 5e-05
I0403 09:20:58.222196 21413 solver.cpp:228] Iteration 9456, loss = 0.00651468
I0403 09:20:58.222311 21413 solver.cpp:244]     Train net output #0: loss = 0.0065146 (* 1 = 0.0065146 loss)
I0403 09:20:58.429808 21413 sgd_solver.cpp:106] Iteration 9456, lr = 5e-05
I0403 09:21:10.030794 21413 solver.cpp:228] Iteration 9472, loss = 0.0210005
I0403 09:21:10.031121 21413 solver.cpp:244]     Train net output #0: loss = 0.0210004 (* 1 = 0.0210004 loss)
I0403 09:21:10.199165 21413 sgd_solver.cpp:106] Iteration 9472, lr = 5e-05
I0403 09:21:21.846870 21413 solver.cpp:228] Iteration 9488, loss = 0.0191203
I0403 09:21:21.846987 21413 solver.cpp:244]     Train net output #0: loss = 0.0191203 (* 1 = 0.0191203 loss)
I0403 09:21:22.060606 21413 sgd_solver.cpp:106] Iteration 9488, lr = 5e-05
I0403 09:21:33.656409 21413 solver.cpp:228] Iteration 9504, loss = 0.00379233
I0403 09:21:33.656529 21413 solver.cpp:244]     Train net output #0: loss = 0.00379226 (* 1 = 0.00379226 loss)
I0403 09:21:33.890290 21413 sgd_solver.cpp:106] Iteration 9504, lr = 5e-05
I0403 09:21:45.285521 21413 solver.cpp:228] Iteration 9520, loss = 0.00975475
I0403 09:21:45.285903 21413 solver.cpp:244]     Train net output #0: loss = 0.00975468 (* 1 = 0.00975468 loss)
I0403 09:21:45.559295 21413 sgd_solver.cpp:106] Iteration 9520, lr = 5e-05
I0403 09:21:57.204983 21413 solver.cpp:228] Iteration 9536, loss = 0.00927164
I0403 09:21:57.205097 21413 solver.cpp:244]     Train net output #0: loss = 0.00927157 (* 1 = 0.00927157 loss)
I0403 09:21:57.395057 21413 sgd_solver.cpp:106] Iteration 9536, lr = 5e-05
I0403 09:22:08.950963 21413 solver.cpp:228] Iteration 9552, loss = 0.0256559
I0403 09:22:08.951074 21413 solver.cpp:244]     Train net output #0: loss = 0.0256559 (* 1 = 0.0256559 loss)
I0403 09:22:09.152568 21413 sgd_solver.cpp:106] Iteration 9552, lr = 5e-05
I0403 09:22:20.689288 21413 solver.cpp:228] Iteration 9568, loss = 0.00570573
I0403 09:22:20.689638 21413 solver.cpp:244]     Train net output #0: loss = 0.00570566 (* 1 = 0.00570566 loss)
I0403 09:22:20.912560 21413 sgd_solver.cpp:106] Iteration 9568, lr = 5e-05
I0403 09:22:32.480221 21413 solver.cpp:228] Iteration 9584, loss = 0.0046212
I0403 09:22:32.480334 21413 solver.cpp:244]     Train net output #0: loss = 0.00462114 (* 1 = 0.00462114 loss)
I0403 09:22:32.670464 21413 sgd_solver.cpp:106] Iteration 9584, lr = 5e-05
I0403 09:22:44.290479 21413 solver.cpp:228] Iteration 9600, loss = 0.0235625
I0403 09:22:44.290585 21413 solver.cpp:244]     Train net output #0: loss = 0.0235625 (* 1 = 0.0235625 loss)
I0403 09:22:44.462983 21413 sgd_solver.cpp:106] Iteration 9600, lr = 5e-05
I0403 09:22:56.011849 21413 solver.cpp:228] Iteration 9616, loss = 0.00649288
I0403 09:22:56.012153 21413 solver.cpp:244]     Train net output #0: loss = 0.00649282 (* 1 = 0.00649282 loss)
I0403 09:22:56.190948 21413 sgd_solver.cpp:106] Iteration 9616, lr = 5e-05
I0403 09:23:07.672706 21413 solver.cpp:228] Iteration 9632, loss = 0.00696235
I0403 09:23:07.672811 21413 solver.cpp:244]     Train net output #0: loss = 0.00696229 (* 1 = 0.00696229 loss)
I0403 09:23:07.846587 21413 sgd_solver.cpp:106] Iteration 9632, lr = 5e-05
I0403 09:23:19.404927 21413 solver.cpp:228] Iteration 9648, loss = 0.0187767
I0403 09:23:19.405040 21413 solver.cpp:244]     Train net output #0: loss = 0.0187767 (* 1 = 0.0187767 loss)
I0403 09:23:19.607480 21413 sgd_solver.cpp:106] Iteration 9648, lr = 5e-05
I0403 09:23:31.142817 21413 solver.cpp:228] Iteration 9664, loss = 0.0597594
I0403 09:23:31.143141 21413 solver.cpp:244]     Train net output #0: loss = 0.0597594 (* 1 = 0.0597594 loss)
I0403 09:23:31.274477 21413 sgd_solver.cpp:106] Iteration 9664, lr = 5e-05
I0403 09:23:42.829979 21413 solver.cpp:228] Iteration 9680, loss = 0.00999145
I0403 09:23:42.830081 21413 solver.cpp:244]     Train net output #0: loss = 0.0099914 (* 1 = 0.0099914 loss)
I0403 09:23:42.992908 21413 sgd_solver.cpp:106] Iteration 9680, lr = 5e-05
I0403 09:23:54.504953 21413 solver.cpp:228] Iteration 9696, loss = 0.00765573
I0403 09:23:54.505074 21413 solver.cpp:244]     Train net output #0: loss = 0.00765567 (* 1 = 0.00765567 loss)
I0403 09:23:54.730198 21413 sgd_solver.cpp:106] Iteration 9696, lr = 5e-05
I0403 09:24:06.167088 21413 solver.cpp:228] Iteration 9712, loss = 0.00258259
I0403 09:24:06.167430 21413 solver.cpp:244]     Train net output #0: loss = 0.00258254 (* 1 = 0.00258254 loss)
I0403 09:24:06.375905 21413 sgd_solver.cpp:106] Iteration 9712, lr = 5e-05
I0403 09:24:18.094172 21413 solver.cpp:228] Iteration 9728, loss = 0.00441384
I0403 09:24:18.094286 21413 solver.cpp:244]     Train net output #0: loss = 0.00441378 (* 1 = 0.00441378 loss)
I0403 09:24:18.277673 21413 sgd_solver.cpp:106] Iteration 9728, lr = 5e-05
I0403 09:24:29.772176 21413 solver.cpp:228] Iteration 9744, loss = 0.00738908
I0403 09:24:29.772289 21413 solver.cpp:244]     Train net output #0: loss = 0.00738903 (* 1 = 0.00738903 loss)
I0403 09:24:29.957648 21413 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 09:24:33.629271 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9750.caffemodel
I0403 09:24:36.230803 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9750.solverstate
I0403 09:24:38.025918 21413 solver.cpp:337] Iteration 9750, Testing net (#0)
I0403 09:25:27.076917 21413 solver.cpp:404]     Test net output #0: accuracy = 0.959632
I0403 09:25:27.077263 21413 solver.cpp:404]     Test net output #1: loss = 0.154952 (* 1 = 0.154952 loss)
I0403 09:25:35.012270 21413 solver.cpp:228] Iteration 9760, loss = 0.00554796
I0403 09:25:35.012372 21413 solver.cpp:244]     Train net output #0: loss = 0.0055479 (* 1 = 0.0055479 loss)
I0403 09:25:35.188978 21413 sgd_solver.cpp:106] Iteration 9760, lr = 5e-05
I0403 09:25:35.922863 21413 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9762.caffemodel
I0403 09:25:38.554464 21413 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_train_from_scratch/snapshots__iter_9762.solverstate
I0403 09:25:40.316649 21413 solver.cpp:322] Optimization Done.
I0403 09:25:40.395267 21413 caffe.cpp:222] Optimization Done.
