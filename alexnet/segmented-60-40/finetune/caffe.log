I0403 02:30:28.135817 16973 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.136350 16973 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.136402 16973 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.217573 16973 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.219118 16973 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.220590 16973 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.074486 16973 solver.cpp:48] Initializing solver from parameters: 
test_iter: 217
test_interval: 325
base_lr: 0.005
display: 16
max_iter: 9762
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3254
snapshot: 325
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.103108 16973 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.111891 16973 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.111968 16973 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.112820 16973 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.114863 16973 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.115787 16973 net.cpp:91] Creating Layer data
I0403 02:30:37.115855 16973 net.cpp:399] data -> data
I0403 02:30:37.116024 16973 net.cpp:399] data -> label
I0403 02:30:37.116142 16973 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto
I0403 02:30:37.140338 16977 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-60-40/train_db
I0403 02:30:37.168359 16973 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.312155 16973 net.cpp:141] Setting up data
I0403 02:30:37.312278 16973 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.312304 16973 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.312324 16973 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.312361 16973 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.312417 16973 net.cpp:91] Creating Layer conv1
I0403 02:30:37.312444 16973 net.cpp:425] conv1 <- data
I0403 02:30:37.312484 16973 net.cpp:399] conv1 -> conv1
I0403 02:30:37.321696 16973 net.cpp:141] Setting up conv1
I0403 02:30:37.321739 16973 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.321760 16973 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.321863 16973 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.321998 16973 net.cpp:91] Creating Layer relu1
I0403 02:30:37.322031 16973 net.cpp:425] relu1 <- conv1
I0403 02:30:37.322057 16973 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.322103 16973 net.cpp:141] Setting up relu1
I0403 02:30:37.322129 16973 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.322147 16973 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.322165 16973 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.322190 16973 net.cpp:91] Creating Layer norm1
I0403 02:30:37.322255 16973 net.cpp:425] norm1 <- conv1
I0403 02:30:37.322278 16973 net.cpp:399] norm1 -> norm1
I0403 02:30:37.322381 16973 net.cpp:141] Setting up norm1
I0403 02:30:37.322410 16973 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.322428 16973 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.322446 16973 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.322471 16973 net.cpp:91] Creating Layer pool1
I0403 02:30:37.322490 16973 net.cpp:425] pool1 <- norm1
I0403 02:30:37.322520 16973 net.cpp:399] pool1 -> pool1
I0403 02:30:37.322607 16973 net.cpp:141] Setting up pool1
I0403 02:30:37.322638 16973 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.322656 16973 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.322674 16973 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.322702 16973 net.cpp:91] Creating Layer conv2
I0403 02:30:37.322721 16973 net.cpp:425] conv2 <- pool1
I0403 02:30:37.322746 16973 net.cpp:399] conv2 -> conv2
I0403 02:30:37.322762 16981 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.342988 16973 net.cpp:141] Setting up conv2
I0403 02:30:37.343027 16973 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.343047 16973 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.343075 16973 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.343098 16973 net.cpp:91] Creating Layer relu2
I0403 02:30:37.343119 16973 net.cpp:425] relu2 <- conv2
I0403 02:30:37.343142 16973 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.343168 16973 net.cpp:141] Setting up relu2
I0403 02:30:37.343190 16973 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.343209 16973 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.343228 16973 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.343251 16973 net.cpp:91] Creating Layer norm2
I0403 02:30:37.343271 16973 net.cpp:425] norm2 <- conv2
I0403 02:30:37.343293 16973 net.cpp:399] norm2 -> norm2
I0403 02:30:37.343358 16973 net.cpp:141] Setting up norm2
I0403 02:30:37.343385 16973 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.343405 16973 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.343423 16973 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.343448 16973 net.cpp:91] Creating Layer pool2
I0403 02:30:37.343468 16973 net.cpp:425] pool2 <- norm2
I0403 02:30:37.343492 16973 net.cpp:399] pool2 -> pool2
I0403 02:30:37.343575 16973 net.cpp:141] Setting up pool2
I0403 02:30:37.343605 16973 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.343623 16973 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.343641 16973 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.343669 16973 net.cpp:91] Creating Layer conv3
I0403 02:30:37.343690 16973 net.cpp:425] conv3 <- pool2
I0403 02:30:37.343715 16973 net.cpp:399] conv3 -> conv3
I0403 02:30:37.385625 16973 net.cpp:141] Setting up conv3
I0403 02:30:37.385666 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.385686 16973 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.385713 16973 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.385740 16973 net.cpp:91] Creating Layer relu3
I0403 02:30:37.385759 16973 net.cpp:425] relu3 <- conv3
I0403 02:30:37.385781 16973 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.385805 16973 net.cpp:141] Setting up relu3
I0403 02:30:37.385828 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.385846 16973 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.385864 16973 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.385892 16973 net.cpp:91] Creating Layer conv4
I0403 02:30:37.385912 16973 net.cpp:425] conv4 <- conv3
I0403 02:30:37.385936 16973 net.cpp:399] conv4 -> conv4
I0403 02:30:37.417551 16973 net.cpp:141] Setting up conv4
I0403 02:30:37.417593 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.417613 16973 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.417657 16973 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.417683 16973 net.cpp:91] Creating Layer relu4
I0403 02:30:37.417703 16973 net.cpp:425] relu4 <- conv4
I0403 02:30:37.417726 16973 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.417752 16973 net.cpp:141] Setting up relu4
I0403 02:30:37.417775 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.417793 16973 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.417811 16973 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.417842 16973 net.cpp:91] Creating Layer conv5
I0403 02:30:37.417865 16973 net.cpp:425] conv5 <- conv4
I0403 02:30:37.417891 16973 net.cpp:399] conv5 -> conv5
I0403 02:30:37.438982 16973 net.cpp:141] Setting up conv5
I0403 02:30:37.439020 16973 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.439040 16973 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.439067 16973 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.439092 16973 net.cpp:91] Creating Layer relu5
I0403 02:30:37.439113 16973 net.cpp:425] relu5 <- conv5
I0403 02:30:37.439136 16973 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.439159 16973 net.cpp:141] Setting up relu5
I0403 02:30:37.439180 16973 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.439199 16973 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.439218 16973 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.439240 16973 net.cpp:91] Creating Layer pool5
I0403 02:30:37.439260 16973 net.cpp:425] pool5 <- conv5
I0403 02:30:37.439285 16973 net.cpp:399] pool5 -> pool5
I0403 02:30:37.439344 16973 net.cpp:141] Setting up pool5
I0403 02:30:37.439373 16973 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.439393 16973 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.439411 16973 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.439467 16973 net.cpp:91] Creating Layer fc6
I0403 02:30:37.439492 16973 net.cpp:425] fc6 <- pool5
I0403 02:30:37.439527 16973 net.cpp:399] fc6 -> fc6
I0403 02:30:38.986739 16973 net.cpp:141] Setting up fc6
I0403 02:30:38.986836 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.986852 16973 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.986874 16973 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.986901 16973 net.cpp:91] Creating Layer relu6
I0403 02:30:38.986918 16973 net.cpp:425] relu6 <- fc6
I0403 02:30:38.986937 16973 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.986958 16973 net.cpp:141] Setting up relu6
I0403 02:30:38.986975 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.986989 16973 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.987002 16973 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.987057 16973 net.cpp:91] Creating Layer drop6
I0403 02:30:38.987076 16973 net.cpp:425] drop6 <- fc6
I0403 02:30:38.987092 16973 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.987149 16973 net.cpp:141] Setting up drop6
I0403 02:30:38.987174 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.987187 16973 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.987202 16973 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.987222 16973 net.cpp:91] Creating Layer fc7
I0403 02:30:38.987237 16973 net.cpp:425] fc7 <- fc6
I0403 02:30:38.987254 16973 net.cpp:399] fc7 -> fc7
I0403 02:30:39.609979 16973 net.cpp:141] Setting up fc7
I0403 02:30:39.610074 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.610090 16973 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.610112 16973 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.610136 16973 net.cpp:91] Creating Layer relu7
I0403 02:30:39.610153 16973 net.cpp:425] relu7 <- fc7
I0403 02:30:39.610172 16973 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.610194 16973 net.cpp:141] Setting up relu7
I0403 02:30:39.610211 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.610225 16973 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.610240 16973 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.610304 16973 net.cpp:91] Creating Layer drop7
I0403 02:30:39.610321 16973 net.cpp:425] drop7 <- fc7
I0403 02:30:39.610338 16973 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.610379 16973 net.cpp:141] Setting up drop7
I0403 02:30:39.610400 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.610415 16973 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.610430 16973 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.610450 16973 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.610466 16973 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.610486 16973 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.616838 16973 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.616869 16973 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.616886 16973 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.616904 16973 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.616952 16973 net.cpp:91] Creating Layer loss
I0403 02:30:39.616971 16973 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.616987 16973 net.cpp:425] loss <- label
I0403 02:30:39.617008 16973 net.cpp:399] loss -> loss
I0403 02:30:39.617044 16973 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.617172 16973 net.cpp:141] Setting up loss
I0403 02:30:39.617194 16973 net.cpp:148] Top shape: (1)
I0403 02:30:39.617209 16973 net.cpp:151]     with loss weight 1
I0403 02:30:39.617290 16973 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.617306 16973 net.cpp:217] loss needs backward computation.
I0403 02:30:39.617321 16973 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.617336 16973 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.617349 16973 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.617363 16973 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.617377 16973 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.617391 16973 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.617405 16973 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.617419 16973 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.617434 16973 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.617447 16973 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.617461 16973 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.617475 16973 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.617491 16973 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.617509 16973 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.617525 16973 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.617540 16973 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.617554 16973 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.617569 16973 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.617583 16973 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.617599 16973 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.617612 16973 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.617626 16973 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.617641 16973 net.cpp:219] data does not need backward computation.
I0403 02:30:39.617655 16973 net.cpp:261] This network produces output loss
I0403 02:30:39.617683 16973 net.cpp:274] Network initialization done.
I0403 02:30:39.618796 16973 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.618854 16973 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.619511 16973 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-60-40/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.619699 16973 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.620234 16973 net.cpp:91] Creating Layer data
I0403 02:30:39.620263 16973 net.cpp:399] data -> data
I0403 02:30:39.620288 16973 net.cpp:399] data -> label
I0403 02:30:39.620312 16973 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-60-40/mean.binaryproto
I0403 02:30:39.632773 16983 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-60-40/test_db
I0403 02:30:39.634014 16973 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.778223 16973 net.cpp:141] Setting up data
I0403 02:30:39.778314 16973 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.778334 16973 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.778350 16973 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.778369 16973 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.778399 16973 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.778419 16973 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.778439 16973 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.778465 16973 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.778528 16973 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.778551 16973 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.778568 16973 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.778584 16973 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.778599 16973 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.778626 16973 net.cpp:91] Creating Layer conv1
I0403 02:30:39.778643 16973 net.cpp:425] conv1 <- data
I0403 02:30:39.778663 16973 net.cpp:399] conv1 -> conv1
I0403 02:30:39.786273 16973 net.cpp:141] Setting up conv1
I0403 02:30:39.786309 16973 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.786325 16973 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.786350 16973 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.786371 16973 net.cpp:91] Creating Layer relu1
I0403 02:30:39.786387 16973 net.cpp:425] relu1 <- conv1
I0403 02:30:39.786406 16973 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.786425 16973 net.cpp:141] Setting up relu1
I0403 02:30:39.786443 16973 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.786458 16973 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.786473 16973 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.786492 16973 net.cpp:91] Creating Layer norm1
I0403 02:30:39.786525 16973 net.cpp:425] norm1 <- conv1
I0403 02:30:39.786547 16973 net.cpp:399] norm1 -> norm1
I0403 02:30:39.786598 16973 net.cpp:141] Setting up norm1
I0403 02:30:39.786620 16973 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.786635 16973 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.786650 16973 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.786669 16973 net.cpp:91] Creating Layer pool1
I0403 02:30:39.786684 16973 net.cpp:425] pool1 <- norm1
I0403 02:30:39.786702 16973 net.cpp:399] pool1 -> pool1
I0403 02:30:39.786751 16973 net.cpp:141] Setting up pool1
I0403 02:30:39.786772 16973 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.786787 16973 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.786830 16973 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.786854 16973 net.cpp:91] Creating Layer conv2
I0403 02:30:39.786870 16973 net.cpp:425] conv2 <- pool1
I0403 02:30:39.786890 16973 net.cpp:399] conv2 -> conv2
I0403 02:30:39.799181 16973 net.cpp:141] Setting up conv2
I0403 02:30:39.799213 16973 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.799229 16973 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.799252 16973 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.799273 16973 net.cpp:91] Creating Layer relu2
I0403 02:30:39.799288 16973 net.cpp:425] relu2 <- conv2
I0403 02:30:39.799307 16973 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.799327 16973 net.cpp:141] Setting up relu2
I0403 02:30:39.799345 16973 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.799360 16973 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.799374 16973 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.799393 16973 net.cpp:91] Creating Layer norm2
I0403 02:30:39.799410 16973 net.cpp:425] norm2 <- conv2
I0403 02:30:39.799428 16973 net.cpp:399] norm2 -> norm2
I0403 02:30:39.799477 16973 net.cpp:141] Setting up norm2
I0403 02:30:39.799500 16973 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.799520 16973 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.799535 16973 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.799554 16973 net.cpp:91] Creating Layer pool2
I0403 02:30:39.799571 16973 net.cpp:425] pool2 <- norm2
I0403 02:30:39.799587 16973 net.cpp:399] pool2 -> pool2
I0403 02:30:39.799635 16973 net.cpp:141] Setting up pool2
I0403 02:30:39.799656 16973 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.799671 16973 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.799686 16973 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.799708 16973 net.cpp:91] Creating Layer conv3
I0403 02:30:39.799726 16973 net.cpp:425] conv3 <- pool2
I0403 02:30:39.799744 16973 net.cpp:399] conv3 -> conv3
I0403 02:30:39.836599 16973 net.cpp:141] Setting up conv3
I0403 02:30:39.836695 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.836742 16973 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.836793 16973 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.836820 16973 net.cpp:91] Creating Layer relu3
I0403 02:30:39.836860 16973 net.cpp:425] relu3 <- conv3
I0403 02:30:39.836902 16973 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.836952 16973 net.cpp:141] Setting up relu3
I0403 02:30:39.836973 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.837003 16973 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.837039 16973 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.837087 16973 net.cpp:91] Creating Layer conv4
I0403 02:30:39.837105 16973 net.cpp:425] conv4 <- conv3
I0403 02:30:39.837151 16973 net.cpp:399] conv4 -> conv4
I0403 02:30:39.864428 16973 net.cpp:141] Setting up conv4
I0403 02:30:39.898466 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.899866 16973 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.899919 16973 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.899963 16973 net.cpp:91] Creating Layer relu4
I0403 02:30:39.899998 16973 net.cpp:425] relu4 <- conv4
I0403 02:30:39.900037 16973 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.900080 16973 net.cpp:141] Setting up relu4
I0403 02:30:39.900120 16973 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.900158 16973 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.900313 16973 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.900373 16973 net.cpp:91] Creating Layer conv5
I0403 02:30:39.900418 16973 net.cpp:425] conv5 <- conv4
I0403 02:30:39.900480 16973 net.cpp:399] conv5 -> conv5
I0403 02:30:39.919878 16973 net.cpp:141] Setting up conv5
I0403 02:30:39.937568 16973 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.937623 16973 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.937702 16973 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.937760 16973 net.cpp:91] Creating Layer relu5
I0403 02:30:39.937780 16973 net.cpp:425] relu5 <- conv5
I0403 02:30:39.937800 16973 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.937824 16973 net.cpp:141] Setting up relu5
I0403 02:30:39.937842 16973 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.937857 16973 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.937872 16973 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.937932 16973 net.cpp:91] Creating Layer pool5
I0403 02:30:39.937953 16973 net.cpp:425] pool5 <- conv5
I0403 02:30:39.938129 16973 net.cpp:399] pool5 -> pool5
I0403 02:30:39.938206 16973 net.cpp:141] Setting up pool5
I0403 02:30:39.938235 16973 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.938283 16973 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.938300 16973 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.938323 16973 net.cpp:91] Creating Layer fc6
I0403 02:30:39.938339 16973 net.cpp:425] fc6 <- pool5
I0403 02:30:39.938472 16973 net.cpp:399] fc6 -> fc6
I0403 02:30:41.347600 16973 net.cpp:141] Setting up fc6
I0403 02:30:41.347699 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.347717 16973 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.347739 16973 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.347766 16973 net.cpp:91] Creating Layer relu6
I0403 02:30:41.347784 16973 net.cpp:425] relu6 <- fc6
I0403 02:30:41.347805 16973 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.347826 16973 net.cpp:141] Setting up relu6
I0403 02:30:41.347843 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.347856 16973 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.347870 16973 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.347892 16973 net.cpp:91] Creating Layer drop6
I0403 02:30:41.347908 16973 net.cpp:425] drop6 <- fc6
I0403 02:30:41.347924 16973 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.347962 16973 net.cpp:141] Setting up drop6
I0403 02:30:41.347985 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.348001 16973 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.348014 16973 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.348034 16973 net.cpp:91] Creating Layer fc7
I0403 02:30:41.348050 16973 net.cpp:425] fc7 <- fc6
I0403 02:30:41.348068 16973 net.cpp:399] fc7 -> fc7
I0403 02:30:41.950090 16973 net.cpp:141] Setting up fc7
I0403 02:30:41.950187 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.950202 16973 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.950227 16973 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.950251 16973 net.cpp:91] Creating Layer relu7
I0403 02:30:41.950268 16973 net.cpp:425] relu7 <- fc7
I0403 02:30:41.950287 16973 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.950309 16973 net.cpp:141] Setting up relu7
I0403 02:30:41.950325 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.950338 16973 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.950353 16973 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.950373 16973 net.cpp:91] Creating Layer drop7
I0403 02:30:41.950389 16973 net.cpp:425] drop7 <- fc7
I0403 02:30:41.950407 16973 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.950448 16973 net.cpp:141] Setting up drop7
I0403 02:30:41.950469 16973 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.950482 16973 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.950496 16973 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.950521 16973 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.950537 16973 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.950558 16973 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.956550 16973 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.956580 16973 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.956631 16973 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.956650 16973 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.956670 16973 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.956686 16973 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.956702 16973 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.956722 16973 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.956771 16973 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.956794 16973 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.956809 16973 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.956822 16973 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.956836 16973 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.956853 16973 net.cpp:91] Creating Layer loss
I0403 02:30:41.956869 16973 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.956884 16973 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.956903 16973 net.cpp:399] loss -> loss
I0403 02:30:41.956926 16973 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.957015 16973 net.cpp:141] Setting up loss
I0403 02:30:41.957036 16973 net.cpp:148] Top shape: (1)
I0403 02:30:41.957051 16973 net.cpp:151]     with loss weight 1
I0403 02:30:41.957077 16973 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.957090 16973 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.957115 16973 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.957132 16973 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.957149 16973 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.957165 16973 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.957218 16973 net.cpp:141] Setting up accuracy
I0403 02:30:41.957238 16973 net.cpp:148] Top shape: (1)
I0403 02:30:41.957252 16973 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.957267 16973 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.957280 16973 net.cpp:217] loss needs backward computation.
I0403 02:30:41.957296 16973 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.957310 16973 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.957324 16973 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.957337 16973 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.957351 16973 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.957365 16973 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.957378 16973 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.957392 16973 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.957406 16973 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.957420 16973 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.957434 16973 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.957448 16973 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.957463 16973 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.957476 16973 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.957490 16973 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.957509 16973 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.957523 16973 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.957538 16973 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.957551 16973 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.957566 16973 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.957579 16973 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.957593 16973 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.957607 16973 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.957635 16973 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.957651 16973 net.cpp:219] data does not need backward computation.
I0403 02:30:41.957665 16973 net.cpp:261] This network produces output accuracy
I0403 02:30:41.957679 16973 net.cpp:261] This network produces output loss
I0403 02:30:41.957706 16973 net.cpp:274] Network initialization done.
I0403 02:30:41.957809 16973 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.958261 16973 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.296381 16973 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.296478 16973 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.296512 16973 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.296561 16973 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.673115 16973 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.709070 16973 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.869698 16973 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.869767 16973 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.869784 16973 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.869815 16973 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.249044 16973 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.283834 16973 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.310003 16973 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.535459 16973 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.080379 16973 parallel.cpp:425] Starting Optimization
I0403 02:30:48.080597 16973 solver.cpp:279] Solving 
I0403 02:30:48.080621 16973 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.080766 16973 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:37.314807 16973 solver.cpp:404]     Test net output #0: accuracy = 0.0579263
I0403 02:31:37.322116 16973 solver.cpp:404]     Test net output #1: loss = 3.96975 (* 1 = 3.96975 loss)
I0403 02:31:37.949291 16973 solver.cpp:228] Iteration 0, loss = 4.48944
I0403 02:31:37.954596 16973 solver.cpp:244]     Train net output #0: loss = 4.48944 (* 1 = 4.48944 loss)
I0403 02:31:38.057564 16973 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:31:49.678205 16973 solver.cpp:228] Iteration 16, loss = 1.0976
I0403 02:31:49.684664 16973 solver.cpp:244]     Train net output #0: loss = 1.0976 (* 1 = 1.0976 loss)
I0403 02:31:49.831280 16973 sgd_solver.cpp:106] Iteration 16, lr = 0.005
I0403 02:32:01.278688 16973 solver.cpp:228] Iteration 32, loss = 0.649612
I0403 02:32:01.285228 16973 solver.cpp:244]     Train net output #0: loss = 0.649612 (* 1 = 0.649612 loss)
I0403 02:32:01.488997 16973 sgd_solver.cpp:106] Iteration 32, lr = 0.005
I0403 02:32:12.949918 16973 solver.cpp:228] Iteration 48, loss = 0.598465
I0403 02:32:12.956224 16973 solver.cpp:244]     Train net output #0: loss = 0.598465 (* 1 = 0.598465 loss)
I0403 02:32:13.129880 16973 sgd_solver.cpp:106] Iteration 48, lr = 0.005
I0403 02:32:24.541604 16973 solver.cpp:228] Iteration 64, loss = 0.293528
I0403 02:32:24.547473 16973 solver.cpp:244]     Train net output #0: loss = 0.293528 (* 1 = 0.293528 loss)
I0403 02:32:24.729598 16973 sgd_solver.cpp:106] Iteration 64, lr = 0.005
I0403 02:32:36.119232 16973 solver.cpp:228] Iteration 80, loss = 0.421234
I0403 02:32:36.127375 16973 solver.cpp:244]     Train net output #0: loss = 0.421234 (* 1 = 0.421234 loss)
I0403 02:32:36.325681 16973 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:32:47.798261 16973 solver.cpp:228] Iteration 96, loss = 0.255936
I0403 02:32:47.804111 16973 solver.cpp:244]     Train net output #0: loss = 0.255936 (* 1 = 0.255936 loss)
I0403 02:32:47.987591 16973 sgd_solver.cpp:106] Iteration 96, lr = 0.005
I0403 02:32:59.372230 16973 solver.cpp:228] Iteration 112, loss = 0.19308
I0403 02:32:59.379546 16973 solver.cpp:244]     Train net output #0: loss = 0.19308 (* 1 = 0.19308 loss)
I0403 02:32:59.582993 16973 sgd_solver.cpp:106] Iteration 112, lr = 0.005
I0403 02:33:11.159291 16973 solver.cpp:228] Iteration 128, loss = 0.40002
I0403 02:33:11.165544 16973 solver.cpp:244]     Train net output #0: loss = 0.40002 (* 1 = 0.40002 loss)
I0403 02:33:11.345402 16973 sgd_solver.cpp:106] Iteration 128, lr = 0.005
I0403 02:33:22.810945 16973 solver.cpp:228] Iteration 144, loss = 0.30666
I0403 02:33:22.817077 16973 solver.cpp:244]     Train net output #0: loss = 0.30666 (* 1 = 0.30666 loss)
I0403 02:33:22.999287 16973 sgd_solver.cpp:106] Iteration 144, lr = 0.005
I0403 02:33:34.451691 16973 solver.cpp:228] Iteration 160, loss = 0.198633
I0403 02:33:34.457643 16973 solver.cpp:244]     Train net output #0: loss = 0.198633 (* 1 = 0.198633 loss)
I0403 02:33:34.620784 16973 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:33:46.282017 16973 solver.cpp:228] Iteration 176, loss = 0.205253
I0403 02:33:46.288275 16973 solver.cpp:244]     Train net output #0: loss = 0.205253 (* 1 = 0.205253 loss)
I0403 02:33:46.494647 16973 sgd_solver.cpp:106] Iteration 176, lr = 0.005
I0403 02:33:58.039520 16973 solver.cpp:228] Iteration 192, loss = 0.204253
I0403 02:33:58.045408 16973 solver.cpp:244]     Train net output #0: loss = 0.204253 (* 1 = 0.204253 loss)
I0403 02:33:58.243089 16973 sgd_solver.cpp:106] Iteration 192, lr = 0.005
I0403 02:34:09.778569 16973 solver.cpp:228] Iteration 208, loss = 0.173117
I0403 02:34:09.784291 16973 solver.cpp:244]     Train net output #0: loss = 0.173117 (* 1 = 0.173117 loss)
I0403 02:34:10.000061 16973 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 02:34:21.418356 16973 solver.cpp:228] Iteration 224, loss = 0.138637
I0403 02:34:21.424881 16973 solver.cpp:244]     Train net output #0: loss = 0.138637 (* 1 = 0.138637 loss)
I0403 02:34:21.605203 16973 sgd_solver.cpp:106] Iteration 224, lr = 0.005
I0403 02:34:33.070729 16973 solver.cpp:228] Iteration 240, loss = 0.239129
I0403 02:34:33.077574 16973 solver.cpp:244]     Train net output #0: loss = 0.239129 (* 1 = 0.239129 loss)
I0403 02:34:33.269963 16973 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:34:44.828656 16973 solver.cpp:228] Iteration 256, loss = 0.181563
I0403 02:34:44.835330 16973 solver.cpp:244]     Train net output #0: loss = 0.181563 (* 1 = 0.181563 loss)
I0403 02:34:45.023079 16973 sgd_solver.cpp:106] Iteration 256, lr = 0.005
I0403 02:34:56.579716 16973 solver.cpp:228] Iteration 272, loss = 0.162989
I0403 02:34:56.585294 16973 solver.cpp:244]     Train net output #0: loss = 0.162989 (* 1 = 0.162989 loss)
I0403 02:34:56.783004 16973 sgd_solver.cpp:106] Iteration 272, lr = 0.005
I0403 02:35:08.378696 16973 solver.cpp:228] Iteration 288, loss = 0.138883
I0403 02:35:08.385689 16973 solver.cpp:244]     Train net output #0: loss = 0.138883 (* 1 = 0.138883 loss)
I0403 02:35:08.546888 16973 sgd_solver.cpp:106] Iteration 288, lr = 0.005
I0403 02:35:20.220540 16973 solver.cpp:228] Iteration 304, loss = 0.113085
I0403 02:35:20.225700 16973 solver.cpp:244]     Train net output #0: loss = 0.113085 (* 1 = 0.113085 loss)
I0403 02:35:20.403053 16973 sgd_solver.cpp:106] Iteration 304, lr = 0.005
I0403 02:35:31.984416 16973 solver.cpp:228] Iteration 320, loss = 0.101276
I0403 02:35:31.990572 16973 solver.cpp:244]     Train net output #0: loss = 0.101276 (* 1 = 0.101276 loss)
I0403 02:35:32.173254 16973 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:35:35.132911 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_325.caffemodel
I0403 02:35:38.012394 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_325.solverstate
I0403 02:35:39.931823 16973 solver.cpp:337] Iteration 325, Testing net (#0)
I0403 02:36:29.135298 16973 solver.cpp:404]     Test net output #0: accuracy = 0.95083
I0403 02:36:29.142372 16973 solver.cpp:404]     Test net output #1: loss = 0.153072 (* 1 = 0.153072 loss)
I0403 02:36:37.784291 16973 solver.cpp:228] Iteration 336, loss = 0.234654
I0403 02:36:37.790945 16973 solver.cpp:244]     Train net output #0: loss = 0.234654 (* 1 = 0.234654 loss)
I0403 02:36:37.971024 16973 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 02:36:49.535293 16973 solver.cpp:228] Iteration 352, loss = 0.163089
I0403 02:36:49.542014 16973 solver.cpp:244]     Train net output #0: loss = 0.163089 (* 1 = 0.163089 loss)
I0403 02:36:49.741964 16973 sgd_solver.cpp:106] Iteration 352, lr = 0.005
I0403 02:37:01.367964 16973 solver.cpp:228] Iteration 368, loss = 0.0618114
I0403 02:37:01.373848 16973 solver.cpp:244]     Train net output #0: loss = 0.0618114 (* 1 = 0.0618114 loss)
I0403 02:37:01.554304 16973 sgd_solver.cpp:106] Iteration 368, lr = 0.005
I0403 02:37:13.421705 16973 solver.cpp:228] Iteration 384, loss = 0.0756598
I0403 02:37:13.428246 16973 solver.cpp:244]     Train net output #0: loss = 0.0756598 (* 1 = 0.0756598 loss)
I0403 02:37:13.617422 16973 sgd_solver.cpp:106] Iteration 384, lr = 0.005
I0403 02:37:25.299371 16973 solver.cpp:228] Iteration 400, loss = 0.157611
I0403 02:37:25.304836 16973 solver.cpp:244]     Train net output #0: loss = 0.157611 (* 1 = 0.157611 loss)
I0403 02:37:25.517647 16973 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:37:37.065266 16973 solver.cpp:228] Iteration 416, loss = 0.130449
I0403 02:37:37.070909 16973 solver.cpp:244]     Train net output #0: loss = 0.13045 (* 1 = 0.13045 loss)
I0403 02:37:37.253401 16973 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 02:37:48.921097 16973 solver.cpp:228] Iteration 432, loss = 0.145682
I0403 02:37:48.927031 16973 solver.cpp:244]     Train net output #0: loss = 0.145682 (* 1 = 0.145682 loss)
I0403 02:37:49.112531 16973 sgd_solver.cpp:106] Iteration 432, lr = 0.005
I0403 02:38:00.684859 16973 solver.cpp:228] Iteration 448, loss = 0.18269
I0403 02:38:00.684969 16973 solver.cpp:244]     Train net output #0: loss = 0.18269 (* 1 = 0.18269 loss)
I0403 02:38:00.870026 16973 sgd_solver.cpp:106] Iteration 448, lr = 0.005
I0403 02:38:12.537971 16973 solver.cpp:228] Iteration 464, loss = 0.0460109
I0403 02:38:12.544040 16973 solver.cpp:244]     Train net output #0: loss = 0.0460109 (* 1 = 0.0460109 loss)
I0403 02:38:12.723744 16973 sgd_solver.cpp:106] Iteration 464, lr = 0.005
I0403 02:38:24.158440 16973 solver.cpp:228] Iteration 480, loss = 0.0305509
I0403 02:38:24.164517 16973 solver.cpp:244]     Train net output #0: loss = 0.030551 (* 1 = 0.030551 loss)
I0403 02:38:24.361500 16973 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:38:35.929643 16973 solver.cpp:228] Iteration 496, loss = 0.0751511
I0403 02:38:35.936031 16973 solver.cpp:244]     Train net output #0: loss = 0.0751511 (* 1 = 0.0751511 loss)
I0403 02:38:36.096797 16973 sgd_solver.cpp:106] Iteration 496, lr = 0.005
I0403 02:38:47.671125 16973 solver.cpp:228] Iteration 512, loss = 0.094525
I0403 02:38:47.671468 16973 solver.cpp:244]     Train net output #0: loss = 0.094525 (* 1 = 0.094525 loss)
I0403 02:38:47.858909 16973 sgd_solver.cpp:106] Iteration 512, lr = 0.005
I0403 02:38:59.511973 16973 solver.cpp:228] Iteration 528, loss = 0.051353
I0403 02:38:59.512086 16973 solver.cpp:244]     Train net output #0: loss = 0.051353 (* 1 = 0.051353 loss)
I0403 02:38:59.697916 16973 sgd_solver.cpp:106] Iteration 528, lr = 0.005
I0403 02:39:11.165992 16973 solver.cpp:228] Iteration 544, loss = 0.211316
I0403 02:39:11.166092 16973 solver.cpp:244]     Train net output #0: loss = 0.211316 (* 1 = 0.211316 loss)
I0403 02:39:11.345283 16973 sgd_solver.cpp:106] Iteration 544, lr = 0.005
I0403 02:39:22.790421 16973 solver.cpp:228] Iteration 560, loss = 0.038201
I0403 02:39:22.790711 16973 solver.cpp:244]     Train net output #0: loss = 0.0382011 (* 1 = 0.0382011 loss)
I0403 02:39:22.969113 16973 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:39:34.561439 16973 solver.cpp:228] Iteration 576, loss = 0.120171
I0403 02:39:34.561555 16973 solver.cpp:244]     Train net output #0: loss = 0.120171 (* 1 = 0.120171 loss)
I0403 02:39:34.746351 16973 sgd_solver.cpp:106] Iteration 576, lr = 0.005
I0403 02:39:46.400516 16973 solver.cpp:228] Iteration 592, loss = 0.106892
I0403 02:39:46.400634 16973 solver.cpp:244]     Train net output #0: loss = 0.106893 (* 1 = 0.106893 loss)
I0403 02:39:46.602007 16973 sgd_solver.cpp:106] Iteration 592, lr = 0.005
I0403 02:39:58.150074 16973 solver.cpp:228] Iteration 608, loss = 0.141916
I0403 02:39:58.150403 16973 solver.cpp:244]     Train net output #0: loss = 0.141916 (* 1 = 0.141916 loss)
I0403 02:39:58.329908 16973 sgd_solver.cpp:106] Iteration 608, lr = 0.005
I0403 02:40:09.867784 16973 solver.cpp:228] Iteration 624, loss = 0.0253466
I0403 02:40:09.867904 16973 solver.cpp:244]     Train net output #0: loss = 0.0253467 (* 1 = 0.0253467 loss)
I0403 02:40:10.052835 16973 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 02:40:21.608880 16973 solver.cpp:228] Iteration 640, loss = 0.0226095
I0403 02:40:21.608983 16973 solver.cpp:244]     Train net output #0: loss = 0.0226096 (* 1 = 0.0226096 loss)
I0403 02:40:21.780905 16973 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:40:28.326270 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_650.caffemodel
I0403 02:40:31.067764 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_650.solverstate
I0403 02:40:32.963038 16973 solver.cpp:337] Iteration 650, Testing net (#0)
I0403 02:41:22.158543 16973 solver.cpp:404]     Test net output #0: accuracy = 0.960415
I0403 02:41:22.165861 16973 solver.cpp:404]     Test net output #1: loss = 0.124324 (* 1 = 0.124324 loss)
I0403 02:41:27.083804 16973 solver.cpp:228] Iteration 656, loss = 0.0203099
I0403 02:41:27.089650 16973 solver.cpp:244]     Train net output #0: loss = 0.0203099 (* 1 = 0.0203099 loss)
I0403 02:41:27.296658 16973 sgd_solver.cpp:106] Iteration 656, lr = 0.005
I0403 02:41:38.853873 16973 solver.cpp:228] Iteration 672, loss = 0.0928966
I0403 02:41:38.860817 16973 solver.cpp:244]     Train net output #0: loss = 0.0928967 (* 1 = 0.0928967 loss)
I0403 02:41:39.057342 16973 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 02:41:50.682915 16973 solver.cpp:228] Iteration 688, loss = 0.0928148
I0403 02:41:50.689743 16973 solver.cpp:244]     Train net output #0: loss = 0.0928149 (* 1 = 0.0928149 loss)
I0403 02:41:50.956831 16973 sgd_solver.cpp:106] Iteration 688, lr = 0.005
I0403 02:42:02.399621 16973 solver.cpp:228] Iteration 704, loss = 0.0624173
I0403 02:42:02.406318 16973 solver.cpp:244]     Train net output #0: loss = 0.0624173 (* 1 = 0.0624173 loss)
I0403 02:42:02.603559 16973 sgd_solver.cpp:106] Iteration 704, lr = 0.005
I0403 02:42:14.254040 16973 solver.cpp:228] Iteration 720, loss = 0.0496974
I0403 02:42:14.260100 16973 solver.cpp:244]     Train net output #0: loss = 0.0496974 (* 1 = 0.0496974 loss)
I0403 02:42:14.464972 16973 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:42:26.054896 16973 solver.cpp:228] Iteration 736, loss = 0.0110487
I0403 02:42:26.060395 16973 solver.cpp:244]     Train net output #0: loss = 0.0110487 (* 1 = 0.0110487 loss)
I0403 02:42:26.238241 16973 sgd_solver.cpp:106] Iteration 736, lr = 0.005
I0403 02:42:37.726984 16973 solver.cpp:228] Iteration 752, loss = 0.0892896
I0403 02:42:37.733505 16973 solver.cpp:244]     Train net output #0: loss = 0.0892897 (* 1 = 0.0892897 loss)
I0403 02:42:37.925279 16973 sgd_solver.cpp:106] Iteration 752, lr = 0.005
I0403 02:42:49.344758 16973 solver.cpp:228] Iteration 768, loss = 0.0543386
I0403 02:42:49.351446 16973 solver.cpp:244]     Train net output #0: loss = 0.0543387 (* 1 = 0.0543387 loss)
I0403 02:42:49.570399 16973 sgd_solver.cpp:106] Iteration 768, lr = 0.005
I0403 02:43:01.145015 16973 solver.cpp:228] Iteration 784, loss = 0.0395247
I0403 02:43:01.150586 16973 solver.cpp:244]     Train net output #0: loss = 0.0395247 (* 1 = 0.0395247 loss)
I0403 02:43:01.367471 16973 sgd_solver.cpp:106] Iteration 784, lr = 0.005
I0403 02:43:12.984412 16973 solver.cpp:228] Iteration 800, loss = 0.0572836
I0403 02:43:12.990833 16973 solver.cpp:244]     Train net output #0: loss = 0.0572836 (* 1 = 0.0572836 loss)
I0403 02:43:13.168304 16973 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:43:24.774308 16973 solver.cpp:228] Iteration 816, loss = 0.0816572
I0403 02:43:24.780236 16973 solver.cpp:244]     Train net output #0: loss = 0.0816573 (* 1 = 0.0816573 loss)
I0403 02:43:24.957478 16973 sgd_solver.cpp:106] Iteration 816, lr = 0.005
I0403 02:43:36.477203 16973 solver.cpp:228] Iteration 832, loss = 0.160336
I0403 02:43:36.484387 16973 solver.cpp:244]     Train net output #0: loss = 0.160336 (* 1 = 0.160336 loss)
I0403 02:43:36.698551 16973 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 02:43:48.267593 16973 solver.cpp:228] Iteration 848, loss = 0.0313305
I0403 02:43:48.273705 16973 solver.cpp:244]     Train net output #0: loss = 0.0313305 (* 1 = 0.0313305 loss)
I0403 02:43:48.490229 16973 sgd_solver.cpp:106] Iteration 848, lr = 0.005
I0403 02:44:00.031064 16973 solver.cpp:228] Iteration 864, loss = 0.0950266
I0403 02:44:00.037595 16973 solver.cpp:244]     Train net output #0: loss = 0.0950266 (* 1 = 0.0950266 loss)
I0403 02:44:00.219089 16973 sgd_solver.cpp:106] Iteration 864, lr = 0.005
I0403 02:44:11.609130 16973 solver.cpp:228] Iteration 880, loss = 0.0539985
I0403 02:44:11.614941 16973 solver.cpp:244]     Train net output #0: loss = 0.0539985 (* 1 = 0.0539985 loss)
I0403 02:44:11.793167 16973 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:44:23.306097 16973 solver.cpp:228] Iteration 896, loss = 0.0173369
I0403 02:44:23.312741 16973 solver.cpp:244]     Train net output #0: loss = 0.0173369 (* 1 = 0.0173369 loss)
I0403 02:44:23.506568 16973 sgd_solver.cpp:106] Iteration 896, lr = 0.005
I0403 02:44:35.055696 16973 solver.cpp:228] Iteration 912, loss = 0.0266711
I0403 02:44:35.061460 16973 solver.cpp:244]     Train net output #0: loss = 0.0266712 (* 1 = 0.0266712 loss)
I0403 02:44:35.285004 16973 sgd_solver.cpp:106] Iteration 912, lr = 0.005
I0403 02:44:46.933640 16973 solver.cpp:228] Iteration 928, loss = 0.249729
I0403 02:44:46.938452 16973 solver.cpp:244]     Train net output #0: loss = 0.249729 (* 1 = 0.249729 loss)
I0403 02:44:47.105105 16973 sgd_solver.cpp:106] Iteration 928, lr = 0.005
I0403 02:44:58.731863 16973 solver.cpp:228] Iteration 944, loss = 0.0626073
I0403 02:44:58.737860 16973 solver.cpp:244]     Train net output #0: loss = 0.0626073 (* 1 = 0.0626073 loss)
I0403 02:44:58.989897 16973 sgd_solver.cpp:106] Iteration 944, lr = 0.005
I0403 02:45:10.426467 16973 solver.cpp:228] Iteration 960, loss = 0.106054
I0403 02:45:10.431962 16973 solver.cpp:244]     Train net output #0: loss = 0.106054 (* 1 = 0.106054 loss)
I0403 02:45:10.625525 16973 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:45:20.763623 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_975.caffemodel
I0403 02:45:23.586194 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_975.solverstate
I0403 02:45:25.498791 16973 solver.cpp:337] Iteration 975, Testing net (#0)
I0403 02:46:14.702256 16973 solver.cpp:404]     Test net output #0: accuracy = 0.971429
I0403 02:46:14.708483 16973 solver.cpp:404]     Test net output #1: loss = 0.0975136 (* 1 = 0.0975136 loss)
I0403 02:46:15.952587 16973 solver.cpp:228] Iteration 976, loss = 0.0223865
I0403 02:46:15.958324 16973 solver.cpp:244]     Train net output #0: loss = 0.0223865 (* 1 = 0.0223865 loss)
I0403 02:46:16.150425 16973 sgd_solver.cpp:106] Iteration 976, lr = 0.005
I0403 02:46:27.708362 16973 solver.cpp:228] Iteration 992, loss = 0.0271023
I0403 02:46:27.715296 16973 solver.cpp:244]     Train net output #0: loss = 0.0271023 (* 1 = 0.0271023 loss)
I0403 02:46:27.896018 16973 sgd_solver.cpp:106] Iteration 992, lr = 0.005
I0403 02:46:39.394543 16973 solver.cpp:228] Iteration 1008, loss = 0.0425316
I0403 02:46:39.400666 16973 solver.cpp:244]     Train net output #0: loss = 0.0425317 (* 1 = 0.0425317 loss)
I0403 02:46:39.571540 16973 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 02:46:51.237084 16973 solver.cpp:228] Iteration 1024, loss = 0.0582552
I0403 02:46:51.244618 16973 solver.cpp:244]     Train net output #0: loss = 0.0582553 (* 1 = 0.0582553 loss)
I0403 02:46:51.431445 16973 sgd_solver.cpp:106] Iteration 1024, lr = 0.005
I0403 02:47:02.815251 16973 solver.cpp:228] Iteration 1040, loss = 0.0884884
I0403 02:47:02.822110 16973 solver.cpp:244]     Train net output #0: loss = 0.0884884 (* 1 = 0.0884884 loss)
I0403 02:47:03.003682 16973 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:47:14.509512 16973 solver.cpp:228] Iteration 1056, loss = 0.0635941
I0403 02:47:14.516340 16973 solver.cpp:244]     Train net output #0: loss = 0.0635941 (* 1 = 0.0635941 loss)
I0403 02:47:14.684885 16973 sgd_solver.cpp:106] Iteration 1056, lr = 0.005
I0403 02:47:26.317219 16973 solver.cpp:228] Iteration 1072, loss = 0.112419
I0403 02:47:26.323171 16973 solver.cpp:244]     Train net output #0: loss = 0.112419 (* 1 = 0.112419 loss)
I0403 02:47:26.589567 16973 sgd_solver.cpp:106] Iteration 1072, lr = 0.005
I0403 02:47:38.103085 16973 solver.cpp:228] Iteration 1088, loss = 0.101359
I0403 02:47:38.109171 16973 solver.cpp:244]     Train net output #0: loss = 0.101359 (* 1 = 0.101359 loss)
I0403 02:47:38.353978 16973 sgd_solver.cpp:106] Iteration 1088, lr = 0.005
I0403 02:47:49.804738 16973 solver.cpp:228] Iteration 1104, loss = 0.117489
I0403 02:47:49.811548 16973 solver.cpp:244]     Train net output #0: loss = 0.117489 (* 1 = 0.117489 loss)
I0403 02:47:49.998612 16973 sgd_solver.cpp:106] Iteration 1104, lr = 0.005
I0403 02:48:01.669967 16973 solver.cpp:228] Iteration 1120, loss = 0.111738
I0403 02:48:01.676738 16973 solver.cpp:244]     Train net output #0: loss = 0.111738 (* 1 = 0.111738 loss)
I0403 02:48:01.848323 16973 sgd_solver.cpp:106] Iteration 1120, lr = 0.005
I0403 02:48:13.296061 16973 solver.cpp:228] Iteration 1136, loss = 0.0520554
I0403 02:48:13.303122 16973 solver.cpp:244]     Train net output #0: loss = 0.0520554 (* 1 = 0.0520554 loss)
I0403 02:48:13.469313 16973 sgd_solver.cpp:106] Iteration 1136, lr = 0.005
I0403 02:48:25.014181 16973 solver.cpp:228] Iteration 1152, loss = 0.0936166
I0403 02:48:25.020109 16973 solver.cpp:244]     Train net output #0: loss = 0.0936166 (* 1 = 0.0936166 loss)
I0403 02:48:25.198303 16973 sgd_solver.cpp:106] Iteration 1152, lr = 0.005
I0403 02:48:36.811617 16973 solver.cpp:228] Iteration 1168, loss = 0.0541674
I0403 02:48:36.818402 16973 solver.cpp:244]     Train net output #0: loss = 0.0541674 (* 1 = 0.0541674 loss)
I0403 02:48:36.997624 16973 sgd_solver.cpp:106] Iteration 1168, lr = 0.005
I0403 02:48:48.513655 16973 solver.cpp:228] Iteration 1184, loss = 0.0619336
I0403 02:48:48.520090 16973 solver.cpp:244]     Train net output #0: loss = 0.0619336 (* 1 = 0.0619336 loss)
I0403 02:48:48.694720 16973 sgd_solver.cpp:106] Iteration 1184, lr = 0.005
I0403 02:49:00.201254 16973 solver.cpp:228] Iteration 1200, loss = 0.0195691
I0403 02:49:00.207399 16973 solver.cpp:244]     Train net output #0: loss = 0.0195691 (* 1 = 0.0195691 loss)
I0403 02:49:00.373299 16973 sgd_solver.cpp:106] Iteration 1200, lr = 0.005
I0403 02:49:11.827570 16973 solver.cpp:228] Iteration 1216, loss = 0.0676329
I0403 02:49:11.833813 16973 solver.cpp:244]     Train net output #0: loss = 0.0676329 (* 1 = 0.0676329 loss)
I0403 02:49:12.035220 16973 sgd_solver.cpp:106] Iteration 1216, lr = 0.005
I0403 02:49:23.536231 16973 solver.cpp:228] Iteration 1232, loss = 0.0323656
I0403 02:49:23.542634 16973 solver.cpp:244]     Train net output #0: loss = 0.0323656 (* 1 = 0.0323656 loss)
I0403 02:49:23.725888 16973 sgd_solver.cpp:106] Iteration 1232, lr = 0.005
I0403 02:49:35.118793 16973 solver.cpp:228] Iteration 1248, loss = 0.0464791
I0403 02:49:35.125205 16973 solver.cpp:244]     Train net output #0: loss = 0.0464791 (* 1 = 0.0464791 loss)
I0403 02:49:35.309016 16973 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 02:49:46.710185 16973 solver.cpp:228] Iteration 1264, loss = 0.0378926
I0403 02:49:46.716795 16973 solver.cpp:244]     Train net output #0: loss = 0.0378926 (* 1 = 0.0378926 loss)
I0403 02:49:46.899426 16973 sgd_solver.cpp:106] Iteration 1264, lr = 0.005
I0403 02:49:58.364760 16973 solver.cpp:228] Iteration 1280, loss = 0.0895768
I0403 02:49:58.371335 16973 solver.cpp:244]     Train net output #0: loss = 0.0895768 (* 1 = 0.0895768 loss)
I0403 02:49:58.560529 16973 sgd_solver.cpp:106] Iteration 1280, lr = 0.005
I0403 02:50:10.078605 16973 solver.cpp:228] Iteration 1296, loss = 0.0315556
I0403 02:50:10.085183 16973 solver.cpp:244]     Train net output #0: loss = 0.0315556 (* 1 = 0.0315556 loss)
I0403 02:50:10.264097 16973 sgd_solver.cpp:106] Iteration 1296, lr = 0.005
I0403 02:50:12.524022 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_1300.caffemodel
I0403 02:50:15.257462 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_1300.solverstate
I0403 02:50:17.166591 16973 solver.cpp:337] Iteration 1300, Testing net (#0)
I0403 02:51:06.355190 16973 solver.cpp:404]     Test net output #0: accuracy = 0.973917
I0403 02:51:06.363013 16973 solver.cpp:404]     Test net output #1: loss = 0.0822183 (* 1 = 0.0822183 loss)
I0403 02:51:15.785771 16973 solver.cpp:228] Iteration 1312, loss = 0.0298087
I0403 02:51:15.791900 16973 solver.cpp:244]     Train net output #0: loss = 0.0298087 (* 1 = 0.0298087 loss)
I0403 02:51:15.991951 16973 sgd_solver.cpp:106] Iteration 1312, lr = 0.005
I0403 02:51:27.530776 16973 solver.cpp:228] Iteration 1328, loss = 0.046954
I0403 02:51:27.537142 16973 solver.cpp:244]     Train net output #0: loss = 0.046954 (* 1 = 0.046954 loss)
I0403 02:51:27.715229 16973 sgd_solver.cpp:106] Iteration 1328, lr = 0.005
I0403 02:51:39.233214 16973 solver.cpp:228] Iteration 1344, loss = 0.0107016
I0403 02:51:39.239116 16973 solver.cpp:244]     Train net output #0: loss = 0.0107016 (* 1 = 0.0107016 loss)
I0403 02:51:39.467581 16973 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 02:51:51.149639 16973 solver.cpp:228] Iteration 1360, loss = 0.0232339
I0403 02:51:51.156406 16973 solver.cpp:244]     Train net output #0: loss = 0.0232339 (* 1 = 0.0232339 loss)
I0403 02:51:51.331866 16973 sgd_solver.cpp:106] Iteration 1360, lr = 0.005
I0403 02:52:02.792877 16973 solver.cpp:228] Iteration 1376, loss = 0.0375205
I0403 02:52:02.799098 16973 solver.cpp:244]     Train net output #0: loss = 0.0375205 (* 1 = 0.0375205 loss)
I0403 02:52:03.036458 16973 sgd_solver.cpp:106] Iteration 1376, lr = 0.005
I0403 02:52:14.438614 16973 solver.cpp:228] Iteration 1392, loss = 0.0540611
I0403 02:52:14.445713 16973 solver.cpp:244]     Train net output #0: loss = 0.0540611 (* 1 = 0.0540611 loss)
I0403 02:52:14.663090 16973 sgd_solver.cpp:106] Iteration 1392, lr = 0.005
I0403 02:52:26.289671 16973 solver.cpp:228] Iteration 1408, loss = 0.00726528
I0403 02:52:26.297180 16973 solver.cpp:244]     Train net output #0: loss = 0.00726528 (* 1 = 0.00726528 loss)
I0403 02:52:26.479980 16973 sgd_solver.cpp:106] Iteration 1408, lr = 0.005
I0403 02:52:37.916165 16973 solver.cpp:228] Iteration 1424, loss = 0.0532125
I0403 02:52:37.922729 16973 solver.cpp:244]     Train net output #0: loss = 0.0532125 (* 1 = 0.0532125 loss)
I0403 02:52:38.111594 16973 sgd_solver.cpp:106] Iteration 1424, lr = 0.005
I0403 02:52:49.594104 16973 solver.cpp:228] Iteration 1440, loss = 0.0102772
I0403 02:52:49.600267 16973 solver.cpp:244]     Train net output #0: loss = 0.0102772 (* 1 = 0.0102772 loss)
I0403 02:52:49.785550 16973 sgd_solver.cpp:106] Iteration 1440, lr = 0.005
I0403 02:53:01.341416 16973 solver.cpp:228] Iteration 1456, loss = 0.044294
I0403 02:53:01.347450 16973 solver.cpp:244]     Train net output #0: loss = 0.044294 (* 1 = 0.044294 loss)
I0403 02:53:01.524193 16973 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 02:53:13.108857 16973 solver.cpp:228] Iteration 1472, loss = 0.00553293
I0403 02:53:13.115569 16973 solver.cpp:244]     Train net output #0: loss = 0.00553293 (* 1 = 0.00553293 loss)
I0403 02:53:13.333216 16973 sgd_solver.cpp:106] Iteration 1472, lr = 0.005
I0403 02:53:24.890413 16973 solver.cpp:228] Iteration 1488, loss = 0.0424651
I0403 02:53:24.897157 16973 solver.cpp:244]     Train net output #0: loss = 0.0424651 (* 1 = 0.0424651 loss)
I0403 02:53:25.099222 16973 sgd_solver.cpp:106] Iteration 1488, lr = 0.005
I0403 02:53:36.668357 16973 solver.cpp:228] Iteration 1504, loss = 0.00925922
I0403 02:53:36.674033 16973 solver.cpp:244]     Train net output #0: loss = 0.00925922 (* 1 = 0.00925922 loss)
I0403 02:53:36.854578 16973 sgd_solver.cpp:106] Iteration 1504, lr = 0.005
I0403 02:53:48.370968 16973 solver.cpp:228] Iteration 1520, loss = 0.0710431
I0403 02:53:48.378114 16973 solver.cpp:244]     Train net output #0: loss = 0.0710431 (* 1 = 0.0710431 loss)
I0403 02:53:48.563206 16973 sgd_solver.cpp:106] Iteration 1520, lr = 0.005
I0403 02:54:00.087640 16973 solver.cpp:228] Iteration 1536, loss = 0.018498
I0403 02:54:00.094271 16973 solver.cpp:244]     Train net output #0: loss = 0.018498 (* 1 = 0.018498 loss)
I0403 02:54:00.320632 16973 sgd_solver.cpp:106] Iteration 1536, lr = 0.005
I0403 02:54:12.083899 16973 solver.cpp:228] Iteration 1552, loss = 0.00758307
I0403 02:54:12.090454 16973 solver.cpp:244]     Train net output #0: loss = 0.00758308 (* 1 = 0.00758308 loss)
I0403 02:54:12.343025 16973 sgd_solver.cpp:106] Iteration 1552, lr = 0.005
I0403 02:54:23.911180 16973 solver.cpp:228] Iteration 1568, loss = 0.00156974
I0403 02:54:23.918098 16973 solver.cpp:244]     Train net output #0: loss = 0.00156975 (* 1 = 0.00156975 loss)
I0403 02:54:24.113914 16973 sgd_solver.cpp:106] Iteration 1568, lr = 0.005
I0403 02:54:35.680250 16973 solver.cpp:228] Iteration 1584, loss = 0.00895348
I0403 02:54:35.686036 16973 solver.cpp:244]     Train net output #0: loss = 0.00895348 (* 1 = 0.00895348 loss)
I0403 02:54:35.865227 16973 sgd_solver.cpp:106] Iteration 1584, lr = 0.005
I0403 02:54:47.560506 16973 solver.cpp:228] Iteration 1600, loss = 0.00825853
I0403 02:54:47.566592 16973 solver.cpp:244]     Train net output #0: loss = 0.00825853 (* 1 = 0.00825853 loss)
I0403 02:54:47.756620 16973 sgd_solver.cpp:106] Iteration 1600, lr = 0.005
I0403 02:54:59.344269 16973 solver.cpp:228] Iteration 1616, loss = 0.0222529
I0403 02:54:59.351022 16973 solver.cpp:244]     Train net output #0: loss = 0.0222529 (* 1 = 0.0222529 loss)
I0403 02:54:59.535550 16973 sgd_solver.cpp:106] Iteration 1616, lr = 0.005
I0403 02:55:05.383724 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_1625.caffemodel
I0403 02:55:08.013289 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_1625.solverstate
I0403 02:55:09.816053 16973 solver.cpp:337] Iteration 1625, Testing net (#0)
I0403 02:55:59.002329 16973 solver.cpp:404]     Test net output #0: accuracy = 0.965116
I0403 02:55:59.009230 16973 solver.cpp:404]     Test net output #1: loss = 0.117613 (* 1 = 0.117613 loss)
I0403 02:56:04.628638 16973 solver.cpp:228] Iteration 1632, loss = 0.0505449
I0403 02:56:04.634611 16973 solver.cpp:244]     Train net output #0: loss = 0.0505449 (* 1 = 0.0505449 loss)
I0403 02:56:04.831948 16973 sgd_solver.cpp:106] Iteration 1632, lr = 0.005
I0403 02:56:16.423369 16973 solver.cpp:228] Iteration 1648, loss = 0.0101764
I0403 02:56:16.430392 16973 solver.cpp:244]     Train net output #0: loss = 0.0101764 (* 1 = 0.0101764 loss)
I0403 02:56:16.617425 16973 sgd_solver.cpp:106] Iteration 1648, lr = 0.005
I0403 02:56:28.150037 16973 solver.cpp:228] Iteration 1664, loss = 0.0923403
I0403 02:56:28.156853 16973 solver.cpp:244]     Train net output #0: loss = 0.0923403 (* 1 = 0.0923403 loss)
I0403 02:56:28.316900 16973 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 02:56:40.064399 16973 solver.cpp:228] Iteration 1680, loss = 0.0361475
I0403 02:56:40.070286 16973 solver.cpp:244]     Train net output #0: loss = 0.0361475 (* 1 = 0.0361475 loss)
I0403 02:56:40.226083 16973 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 02:56:51.791993 16973 solver.cpp:228] Iteration 1696, loss = 0.0507816
I0403 02:56:51.798755 16973 solver.cpp:244]     Train net output #0: loss = 0.0507816 (* 1 = 0.0507816 loss)
I0403 02:56:51.981271 16973 sgd_solver.cpp:106] Iteration 1696, lr = 0.005
I0403 02:57:03.530843 16973 solver.cpp:228] Iteration 1712, loss = 0.0133465
I0403 02:57:03.537866 16973 solver.cpp:244]     Train net output #0: loss = 0.0133465 (* 1 = 0.0133465 loss)
I0403 02:57:03.708032 16973 sgd_solver.cpp:106] Iteration 1712, lr = 0.005
I0403 02:57:15.210577 16973 solver.cpp:228] Iteration 1728, loss = 0.017717
I0403 02:57:15.216578 16973 solver.cpp:244]     Train net output #0: loss = 0.0177171 (* 1 = 0.0177171 loss)
I0403 02:57:15.406675 16973 sgd_solver.cpp:106] Iteration 1728, lr = 0.005
I0403 02:57:27.019984 16973 solver.cpp:228] Iteration 1744, loss = 0.00490189
I0403 02:57:27.026218 16973 solver.cpp:244]     Train net output #0: loss = 0.00490191 (* 1 = 0.00490191 loss)
I0403 02:57:27.210717 16973 sgd_solver.cpp:106] Iteration 1744, lr = 0.005
I0403 02:57:38.753875 16973 solver.cpp:228] Iteration 1760, loss = 0.0541715
I0403 02:57:38.759507 16973 solver.cpp:244]     Train net output #0: loss = 0.0541715 (* 1 = 0.0541715 loss)
I0403 02:57:38.991313 16973 sgd_solver.cpp:106] Iteration 1760, lr = 0.005
I0403 02:57:50.618746 16973 solver.cpp:228] Iteration 1776, loss = 0.0213594
I0403 02:57:50.625417 16973 solver.cpp:244]     Train net output #0: loss = 0.0213594 (* 1 = 0.0213594 loss)
I0403 02:57:50.822806 16973 sgd_solver.cpp:106] Iteration 1776, lr = 0.005
I0403 02:58:02.307389 16973 solver.cpp:228] Iteration 1792, loss = 0.0574669
I0403 02:58:02.313333 16973 solver.cpp:244]     Train net output #0: loss = 0.0574669 (* 1 = 0.0574669 loss)
I0403 02:58:02.523432 16973 sgd_solver.cpp:106] Iteration 1792, lr = 0.005
I0403 02:58:14.313488 16973 solver.cpp:228] Iteration 1808, loss = 0.00704222
I0403 02:58:14.320135 16973 solver.cpp:244]     Train net output #0: loss = 0.00704222 (* 1 = 0.00704222 loss)
I0403 02:58:14.520843 16973 sgd_solver.cpp:106] Iteration 1808, lr = 0.005
I0403 02:58:26.121671 16973 solver.cpp:228] Iteration 1824, loss = 0.0175666
I0403 02:58:26.128321 16973 solver.cpp:244]     Train net output #0: loss = 0.0175666 (* 1 = 0.0175666 loss)
I0403 02:58:26.297461 16973 sgd_solver.cpp:106] Iteration 1824, lr = 0.005
I0403 02:58:37.871789 16973 solver.cpp:228] Iteration 1840, loss = 0.02401
I0403 02:58:37.878525 16973 solver.cpp:244]     Train net output #0: loss = 0.02401 (* 1 = 0.02401 loss)
I0403 02:58:38.062847 16973 sgd_solver.cpp:106] Iteration 1840, lr = 0.005
I0403 02:58:49.673295 16973 solver.cpp:228] Iteration 1856, loss = 0.00981915
I0403 02:58:49.680166 16973 solver.cpp:244]     Train net output #0: loss = 0.00981915 (* 1 = 0.00981915 loss)
I0403 02:58:49.871021 16973 sgd_solver.cpp:106] Iteration 1856, lr = 0.005
I0403 02:59:01.439688 16973 solver.cpp:228] Iteration 1872, loss = 0.00373568
I0403 02:59:01.446617 16973 solver.cpp:244]     Train net output #0: loss = 0.00373568 (* 1 = 0.00373568 loss)
I0403 02:59:01.615905 16973 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 02:59:13.033329 16973 solver.cpp:228] Iteration 1888, loss = 0.0219833
I0403 02:59:13.039538 16973 solver.cpp:244]     Train net output #0: loss = 0.0219833 (* 1 = 0.0219833 loss)
I0403 02:59:13.219002 16973 sgd_solver.cpp:106] Iteration 1888, lr = 0.005
I0403 02:59:24.872356 16973 solver.cpp:228] Iteration 1904, loss = 0.0526078
I0403 02:59:24.878309 16973 solver.cpp:244]     Train net output #0: loss = 0.0526078 (* 1 = 0.0526078 loss)
I0403 02:59:25.059805 16973 sgd_solver.cpp:106] Iteration 1904, lr = 0.005
I0403 02:59:36.632089 16973 solver.cpp:228] Iteration 1920, loss = 0.0176681
I0403 02:59:36.638911 16973 solver.cpp:244]     Train net output #0: loss = 0.0176681 (* 1 = 0.0176681 loss)
I0403 02:59:36.816884 16973 sgd_solver.cpp:106] Iteration 1920, lr = 0.005
I0403 02:59:48.341617 16973 solver.cpp:228] Iteration 1936, loss = 0.00402283
I0403 02:59:48.347988 16973 solver.cpp:244]     Train net output #0: loss = 0.00402283 (* 1 = 0.00402283 loss)
I0403 02:59:48.599946 16973 sgd_solver.cpp:106] Iteration 1936, lr = 0.005
I0403 02:59:58.202399 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_1950.caffemodel
I0403 03:00:00.877688 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_1950.solverstate
I0403 03:00:02.635148 16973 solver.cpp:337] Iteration 1950, Testing net (#0)
I0403 03:00:51.835636 16973 solver.cpp:404]     Test net output #0: accuracy = 0.975346
I0403 03:00:51.841840 16973 solver.cpp:404]     Test net output #1: loss = 0.0872797 (* 1 = 0.0872797 loss)
I0403 03:00:53.859832 16973 solver.cpp:228] Iteration 1952, loss = 0.0291347
I0403 03:00:53.866299 16973 solver.cpp:244]     Train net output #0: loss = 0.0291347 (* 1 = 0.0291347 loss)
I0403 03:00:54.043813 16973 sgd_solver.cpp:106] Iteration 1952, lr = 0.005
I0403 03:01:05.570662 16973 solver.cpp:228] Iteration 1968, loss = 0.0254958
I0403 03:01:05.578457 16973 solver.cpp:244]     Train net output #0: loss = 0.0254958 (* 1 = 0.0254958 loss)
I0403 03:01:05.743593 16973 sgd_solver.cpp:106] Iteration 1968, lr = 0.005
I0403 03:01:17.278856 16973 solver.cpp:228] Iteration 1984, loss = 0.0109348
I0403 03:01:17.284626 16973 solver.cpp:244]     Train net output #0: loss = 0.0109348 (* 1 = 0.0109348 loss)
I0403 03:01:17.469460 16973 sgd_solver.cpp:106] Iteration 1984, lr = 0.005
I0403 03:01:29.183770 16973 solver.cpp:228] Iteration 2000, loss = 0.127096
I0403 03:01:29.191005 16973 solver.cpp:244]     Train net output #0: loss = 0.127096 (* 1 = 0.127096 loss)
I0403 03:01:29.375054 16973 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0403 03:01:40.997581 16973 solver.cpp:228] Iteration 2016, loss = 0.0489138
I0403 03:01:41.002900 16973 solver.cpp:244]     Train net output #0: loss = 0.0489139 (* 1 = 0.0489139 loss)
I0403 03:01:41.217224 16973 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 03:01:52.923729 16973 solver.cpp:228] Iteration 2032, loss = 0.00741218
I0403 03:01:52.929483 16973 solver.cpp:244]     Train net output #0: loss = 0.00741219 (* 1 = 0.00741219 loss)
I0403 03:01:53.086537 16973 sgd_solver.cpp:106] Iteration 2032, lr = 0.005
I0403 03:02:04.659101 16973 solver.cpp:228] Iteration 2048, loss = 0.00161849
I0403 03:02:04.666185 16973 solver.cpp:244]     Train net output #0: loss = 0.00161851 (* 1 = 0.00161851 loss)
I0403 03:02:04.844259 16973 sgd_solver.cpp:106] Iteration 2048, lr = 0.005
I0403 03:02:16.431715 16973 solver.cpp:228] Iteration 2064, loss = 0.0448671
I0403 03:02:16.438310 16973 solver.cpp:244]     Train net output #0: loss = 0.0448671 (* 1 = 0.0448671 loss)
I0403 03:02:16.614459 16973 sgd_solver.cpp:106] Iteration 2064, lr = 0.005
I0403 03:02:28.098091 16973 solver.cpp:228] Iteration 2080, loss = 0.0704733
I0403 03:02:28.125726 16973 solver.cpp:244]     Train net output #0: loss = 0.0704733 (* 1 = 0.0704733 loss)
I0403 03:02:28.323807 16973 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:02:39.778877 16973 solver.cpp:228] Iteration 2096, loss = 0.0191808
I0403 03:02:39.785135 16973 solver.cpp:244]     Train net output #0: loss = 0.0191808 (* 1 = 0.0191808 loss)
I0403 03:02:39.957069 16973 sgd_solver.cpp:106] Iteration 2096, lr = 0.005
I0403 03:02:51.433259 16973 solver.cpp:228] Iteration 2112, loss = 0.0116041
I0403 03:02:51.440423 16973 solver.cpp:244]     Train net output #0: loss = 0.0116041 (* 1 = 0.0116041 loss)
I0403 03:02:51.670071 16973 sgd_solver.cpp:106] Iteration 2112, lr = 0.005
I0403 03:03:03.392367 16973 solver.cpp:228] Iteration 2128, loss = 0.015747
I0403 03:03:03.398674 16973 solver.cpp:244]     Train net output #0: loss = 0.0157471 (* 1 = 0.0157471 loss)
I0403 03:03:03.552323 16973 sgd_solver.cpp:106] Iteration 2128, lr = 0.005
I0403 03:03:15.367697 16973 solver.cpp:228] Iteration 2144, loss = 0.0334273
I0403 03:03:15.374801 16973 solver.cpp:244]     Train net output #0: loss = 0.0334274 (* 1 = 0.0334274 loss)
I0403 03:03:15.519119 16973 sgd_solver.cpp:106] Iteration 2144, lr = 0.005
I0403 03:03:27.108325 16973 solver.cpp:228] Iteration 2160, loss = 0.0176878
I0403 03:03:27.114289 16973 solver.cpp:244]     Train net output #0: loss = 0.0176879 (* 1 = 0.0176879 loss)
I0403 03:03:27.315649 16973 sgd_solver.cpp:106] Iteration 2160, lr = 0.005
I0403 03:03:38.844718 16973 solver.cpp:228] Iteration 2176, loss = 0.0133774
I0403 03:03:38.851460 16973 solver.cpp:244]     Train net output #0: loss = 0.0133774 (* 1 = 0.0133774 loss)
I0403 03:03:39.011770 16973 sgd_solver.cpp:106] Iteration 2176, lr = 0.005
I0403 03:03:50.689144 16973 solver.cpp:228] Iteration 2192, loss = 0.0148983
I0403 03:03:50.695801 16973 solver.cpp:244]     Train net output #0: loss = 0.0148983 (* 1 = 0.0148983 loss)
I0403 03:03:50.873607 16973 sgd_solver.cpp:106] Iteration 2192, lr = 0.005
I0403 03:04:02.299765 16973 solver.cpp:228] Iteration 2208, loss = 0.0243601
I0403 03:04:02.305824 16973 solver.cpp:244]     Train net output #0: loss = 0.0243601 (* 1 = 0.0243601 loss)
I0403 03:04:02.503348 16973 sgd_solver.cpp:106] Iteration 2208, lr = 0.005
I0403 03:04:14.011293 16973 solver.cpp:228] Iteration 2224, loss = 0.00306573
I0403 03:04:14.017753 16973 solver.cpp:244]     Train net output #0: loss = 0.00306576 (* 1 = 0.00306576 loss)
I0403 03:04:14.201931 16973 sgd_solver.cpp:106] Iteration 2224, lr = 0.005
I0403 03:04:25.677901 16973 solver.cpp:228] Iteration 2240, loss = 0.0422395
I0403 03:04:25.683928 16973 solver.cpp:244]     Train net output #0: loss = 0.0422395 (* 1 = 0.0422395 loss)
I0403 03:04:25.895560 16973 sgd_solver.cpp:106] Iteration 2240, lr = 0.005
I0403 03:04:37.295138 16973 solver.cpp:228] Iteration 2256, loss = 0.000381243
I0403 03:04:37.300700 16973 solver.cpp:244]     Train net output #0: loss = 0.000381264 (* 1 = 0.000381264 loss)
I0403 03:04:37.489418 16973 sgd_solver.cpp:106] Iteration 2256, lr = 0.005
I0403 03:04:48.909791 16973 solver.cpp:228] Iteration 2272, loss = 0.0123004
I0403 03:04:48.916335 16973 solver.cpp:244]     Train net output #0: loss = 0.0123004 (* 1 = 0.0123004 loss)
I0403 03:04:49.095937 16973 sgd_solver.cpp:106] Iteration 2272, lr = 0.005
I0403 03:04:50.527815 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_2275.caffemodel
I0403 03:04:53.277673 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_2275.solverstate
I0403 03:04:55.191195 16973 solver.cpp:337] Iteration 2275, Testing net (#0)
I0403 03:05:44.382035 16973 solver.cpp:404]     Test net output #0: accuracy = 0.977328
I0403 03:05:44.389721 16973 solver.cpp:404]     Test net output #1: loss = 0.077357 (* 1 = 0.077357 loss)
I0403 03:05:54.642622 16973 solver.cpp:228] Iteration 2288, loss = 0.00159492
I0403 03:05:54.649140 16973 solver.cpp:244]     Train net output #0: loss = 0.00159495 (* 1 = 0.00159495 loss)
I0403 03:05:54.850790 16973 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 03:06:06.508543 16973 solver.cpp:228] Iteration 2304, loss = 0.000959337
I0403 03:06:06.515179 16973 solver.cpp:244]     Train net output #0: loss = 0.000959358 (* 1 = 0.000959358 loss)
I0403 03:06:06.715637 16973 sgd_solver.cpp:106] Iteration 2304, lr = 0.005
I0403 03:06:18.182723 16973 solver.cpp:228] Iteration 2320, loss = 0.0052808
I0403 03:06:18.189998 16973 solver.cpp:244]     Train net output #0: loss = 0.00528082 (* 1 = 0.00528082 loss)
I0403 03:06:18.358863 16973 sgd_solver.cpp:106] Iteration 2320, lr = 0.005
I0403 03:06:29.929608 16973 solver.cpp:228] Iteration 2336, loss = 0.00840221
I0403 03:06:29.936585 16973 solver.cpp:244]     Train net output #0: loss = 0.00840223 (* 1 = 0.00840223 loss)
I0403 03:06:30.110201 16973 sgd_solver.cpp:106] Iteration 2336, lr = 0.005
I0403 03:06:41.944564 16973 solver.cpp:228] Iteration 2352, loss = 0.0240338
I0403 03:06:41.951177 16973 solver.cpp:244]     Train net output #0: loss = 0.0240338 (* 1 = 0.0240338 loss)
I0403 03:06:42.146005 16973 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 03:06:53.753545 16973 solver.cpp:228] Iteration 2368, loss = 0.00926322
I0403 03:06:53.760583 16973 solver.cpp:244]     Train net output #0: loss = 0.00926323 (* 1 = 0.00926323 loss)
I0403 03:06:53.945009 16973 sgd_solver.cpp:106] Iteration 2368, lr = 0.005
I0403 03:07:05.549335 16973 solver.cpp:228] Iteration 2384, loss = 0.0101178
I0403 03:07:05.554591 16973 solver.cpp:244]     Train net output #0: loss = 0.0101179 (* 1 = 0.0101179 loss)
I0403 03:07:05.760025 16973 sgd_solver.cpp:106] Iteration 2384, lr = 0.005
I0403 03:07:17.294246 16973 solver.cpp:228] Iteration 2400, loss = 0.00458173
I0403 03:07:17.301211 16973 solver.cpp:244]     Train net output #0: loss = 0.00458174 (* 1 = 0.00458174 loss)
I0403 03:07:17.503082 16973 sgd_solver.cpp:106] Iteration 2400, lr = 0.005
I0403 03:07:29.044651 16973 solver.cpp:228] Iteration 2416, loss = 0.00232645
I0403 03:07:29.049990 16973 solver.cpp:244]     Train net output #0: loss = 0.00232646 (* 1 = 0.00232646 loss)
I0403 03:07:29.227169 16973 sgd_solver.cpp:106] Iteration 2416, lr = 0.005
I0403 03:07:40.799865 16973 solver.cpp:228] Iteration 2432, loss = 0.0451534
I0403 03:07:40.806187 16973 solver.cpp:244]     Train net output #0: loss = 0.0451534 (* 1 = 0.0451534 loss)
I0403 03:07:40.986340 16973 sgd_solver.cpp:106] Iteration 2432, lr = 0.005
I0403 03:07:52.623438 16973 solver.cpp:228] Iteration 2448, loss = 0.0220852
I0403 03:07:52.629503 16973 solver.cpp:244]     Train net output #0: loss = 0.0220852 (* 1 = 0.0220852 loss)
I0403 03:07:52.814769 16973 sgd_solver.cpp:106] Iteration 2448, lr = 0.005
I0403 03:08:04.526782 16973 solver.cpp:228] Iteration 2464, loss = 0.00474953
I0403 03:08:04.533694 16973 solver.cpp:244]     Train net output #0: loss = 0.00474955 (* 1 = 0.00474955 loss)
I0403 03:08:04.723156 16973 sgd_solver.cpp:106] Iteration 2464, lr = 0.005
I0403 03:08:16.262162 16973 solver.cpp:228] Iteration 2480, loss = 0.0015555
I0403 03:08:16.267747 16973 solver.cpp:244]     Train net output #0: loss = 0.00155552 (* 1 = 0.00155552 loss)
I0403 03:08:16.471053 16973 sgd_solver.cpp:106] Iteration 2480, lr = 0.005
I0403 03:08:27.959908 16973 solver.cpp:228] Iteration 2496, loss = 0.00364134
I0403 03:08:27.965088 16973 solver.cpp:244]     Train net output #0: loss = 0.00364137 (* 1 = 0.00364137 loss)
I0403 03:08:28.157268 16973 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 03:08:39.839898 16973 solver.cpp:228] Iteration 2512, loss = 0.00826056
I0403 03:08:39.846784 16973 solver.cpp:244]     Train net output #0: loss = 0.00826058 (* 1 = 0.00826058 loss)
I0403 03:08:40.062685 16973 sgd_solver.cpp:106] Iteration 2512, lr = 0.005
I0403 03:08:51.634187 16973 solver.cpp:228] Iteration 2528, loss = 0.00138471
I0403 03:08:51.640796 16973 solver.cpp:244]     Train net output #0: loss = 0.00138473 (* 1 = 0.00138473 loss)
I0403 03:08:51.817988 16973 sgd_solver.cpp:106] Iteration 2528, lr = 0.005
I0403 03:09:03.426813 16973 solver.cpp:228] Iteration 2544, loss = 0.00270176
I0403 03:09:03.433177 16973 solver.cpp:244]     Train net output #0: loss = 0.00270179 (* 1 = 0.00270179 loss)
I0403 03:09:03.620604 16973 sgd_solver.cpp:106] Iteration 2544, lr = 0.005
I0403 03:09:15.194758 16973 solver.cpp:228] Iteration 2560, loss = 0.00387733
I0403 03:09:15.201246 16973 solver.cpp:244]     Train net output #0: loss = 0.00387735 (* 1 = 0.00387735 loss)
I0403 03:09:15.413146 16973 sgd_solver.cpp:106] Iteration 2560, lr = 0.005
I0403 03:09:27.113176 16973 solver.cpp:228] Iteration 2576, loss = 0.075673
I0403 03:09:27.119321 16973 solver.cpp:244]     Train net output #0: loss = 0.075673 (* 1 = 0.075673 loss)
I0403 03:09:27.293804 16973 sgd_solver.cpp:106] Iteration 2576, lr = 0.005
I0403 03:09:38.811606 16973 solver.cpp:228] Iteration 2592, loss = 0.0097975
I0403 03:09:38.817831 16973 solver.cpp:244]     Train net output #0: loss = 0.00979751 (* 1 = 0.00979751 loss)
I0403 03:09:38.994199 16973 sgd_solver.cpp:106] Iteration 2592, lr = 0.005
I0403 03:09:44.170994 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_2600.caffemodel
I0403 03:09:46.807953 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_2600.solverstate
I0403 03:09:48.634850 16973 solver.cpp:337] Iteration 2600, Testing net (#0)
I0403 03:10:37.844749 16973 solver.cpp:404]     Test net output #0: accuracy = 0.979217
I0403 03:10:37.851708 16973 solver.cpp:404]     Test net output #1: loss = 0.075754 (* 1 = 0.075754 loss)
I0403 03:10:44.285830 16973 solver.cpp:228] Iteration 2608, loss = 0.00263546
I0403 03:10:44.292227 16973 solver.cpp:244]     Train net output #0: loss = 0.00263548 (* 1 = 0.00263548 loss)
I0403 03:10:44.471447 16973 sgd_solver.cpp:106] Iteration 2608, lr = 0.005
I0403 03:10:56.062788 16973 solver.cpp:228] Iteration 2624, loss = 0.00354369
I0403 03:10:56.069248 16973 solver.cpp:244]     Train net output #0: loss = 0.00354371 (* 1 = 0.00354371 loss)
I0403 03:10:56.243155 16973 sgd_solver.cpp:106] Iteration 2624, lr = 0.005
I0403 03:11:08.019898 16973 solver.cpp:228] Iteration 2640, loss = 0.00485512
I0403 03:11:08.026321 16973 solver.cpp:244]     Train net output #0: loss = 0.00485514 (* 1 = 0.00485514 loss)
I0403 03:11:08.188460 16973 sgd_solver.cpp:106] Iteration 2640, lr = 0.005
I0403 03:11:19.752670 16973 solver.cpp:228] Iteration 2656, loss = 0.011294
I0403 03:11:19.758865 16973 solver.cpp:244]     Train net output #0: loss = 0.011294 (* 1 = 0.011294 loss)
I0403 03:11:19.935003 16973 sgd_solver.cpp:106] Iteration 2656, lr = 0.005
I0403 03:11:31.606637 16973 solver.cpp:228] Iteration 2672, loss = 0.00103443
I0403 03:11:31.613145 16973 solver.cpp:244]     Train net output #0: loss = 0.00103445 (* 1 = 0.00103445 loss)
I0403 03:11:31.786434 16973 sgd_solver.cpp:106] Iteration 2672, lr = 0.005
I0403 03:11:43.358738 16973 solver.cpp:228] Iteration 2688, loss = 0.0128754
I0403 03:11:43.365233 16973 solver.cpp:244]     Train net output #0: loss = 0.0128754 (* 1 = 0.0128754 loss)
I0403 03:11:43.562541 16973 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 03:11:55.142595 16973 solver.cpp:228] Iteration 2704, loss = 0.00702738
I0403 03:11:55.148222 16973 solver.cpp:244]     Train net output #0: loss = 0.0070274 (* 1 = 0.0070274 loss)
I0403 03:11:55.326285 16973 sgd_solver.cpp:106] Iteration 2704, lr = 0.005
I0403 03:12:06.960577 16973 solver.cpp:228] Iteration 2720, loss = 0.00112965
I0403 03:12:06.966141 16973 solver.cpp:244]     Train net output #0: loss = 0.00112967 (* 1 = 0.00112967 loss)
I0403 03:12:07.158983 16973 sgd_solver.cpp:106] Iteration 2720, lr = 0.005
I0403 03:12:18.706632 16973 solver.cpp:228] Iteration 2736, loss = 0.00179723
I0403 03:12:18.712977 16973 solver.cpp:244]     Train net output #0: loss = 0.00179725 (* 1 = 0.00179725 loss)
I0403 03:12:18.920088 16973 sgd_solver.cpp:106] Iteration 2736, lr = 0.005
I0403 03:12:30.508244 16973 solver.cpp:228] Iteration 2752, loss = 0.00183166
I0403 03:12:30.514884 16973 solver.cpp:244]     Train net output #0: loss = 0.00183167 (* 1 = 0.00183167 loss)
I0403 03:12:30.688164 16973 sgd_solver.cpp:106] Iteration 2752, lr = 0.005
I0403 03:12:42.126734 16973 solver.cpp:228] Iteration 2768, loss = 0.00120068
I0403 03:12:42.132448 16973 solver.cpp:244]     Train net output #0: loss = 0.0012007 (* 1 = 0.0012007 loss)
I0403 03:12:42.316385 16973 sgd_solver.cpp:106] Iteration 2768, lr = 0.005
I0403 03:12:53.649596 16973 solver.cpp:228] Iteration 2784, loss = 0.0196747
I0403 03:12:53.656163 16973 solver.cpp:244]     Train net output #0: loss = 0.0196747 (* 1 = 0.0196747 loss)
I0403 03:12:53.838217 16973 sgd_solver.cpp:106] Iteration 2784, lr = 0.005
I0403 03:13:05.142859 16973 solver.cpp:228] Iteration 2800, loss = 0.0967756
I0403 03:13:05.151036 16973 solver.cpp:244]     Train net output #0: loss = 0.0967756 (* 1 = 0.0967756 loss)
I0403 03:13:05.350042 16973 sgd_solver.cpp:106] Iteration 2800, lr = 0.005
I0403 03:13:16.835332 16973 solver.cpp:228] Iteration 2816, loss = 0.0317651
I0403 03:13:16.841786 16973 solver.cpp:244]     Train net output #0: loss = 0.0317652 (* 1 = 0.0317652 loss)
I0403 03:13:17.017688 16973 sgd_solver.cpp:106] Iteration 2816, lr = 0.005
I0403 03:13:28.534252 16973 solver.cpp:228] Iteration 2832, loss = 0.00725992
I0403 03:13:28.539932 16973 solver.cpp:244]     Train net output #0: loss = 0.00725994 (* 1 = 0.00725994 loss)
I0403 03:13:28.658335 16973 sgd_solver.cpp:106] Iteration 2832, lr = 0.005
I0403 03:13:40.202514 16973 solver.cpp:228] Iteration 2848, loss = 0.0164463
I0403 03:13:40.211649 16973 solver.cpp:244]     Train net output #0: loss = 0.0164463 (* 1 = 0.0164463 loss)
I0403 03:13:40.409116 16973 sgd_solver.cpp:106] Iteration 2848, lr = 0.005
I0403 03:13:51.814198 16973 solver.cpp:228] Iteration 2864, loss = 0.0444603
I0403 03:13:51.820022 16973 solver.cpp:244]     Train net output #0: loss = 0.0444603 (* 1 = 0.0444603 loss)
I0403 03:13:52.017132 16973 sgd_solver.cpp:106] Iteration 2864, lr = 0.005
I0403 03:14:03.663357 16973 solver.cpp:228] Iteration 2880, loss = 0.00993861
I0403 03:14:03.669564 16973 solver.cpp:244]     Train net output #0: loss = 0.00993862 (* 1 = 0.00993862 loss)
I0403 03:14:03.853564 16973 sgd_solver.cpp:106] Iteration 2880, lr = 0.005
I0403 03:14:15.328650 16973 solver.cpp:228] Iteration 2896, loss = 0.0239033
I0403 03:14:15.333842 16973 solver.cpp:244]     Train net output #0: loss = 0.0239033 (* 1 = 0.0239033 loss)
I0403 03:14:15.532431 16973 sgd_solver.cpp:106] Iteration 2896, lr = 0.005
I0403 03:14:27.133774 16973 solver.cpp:228] Iteration 2912, loss = 0.00683141
I0403 03:14:27.140146 16973 solver.cpp:244]     Train net output #0: loss = 0.00683142 (* 1 = 0.00683142 loss)
I0403 03:14:27.344574 16973 sgd_solver.cpp:106] Iteration 2912, lr = 0.005
I0403 03:14:36.415657 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_2925.caffemodel
I0403 03:14:39.069502 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_2925.solverstate
I0403 03:14:40.883469 16973 solver.cpp:337] Iteration 2925, Testing net (#0)
I0403 03:15:30.089220 16973 solver.cpp:404]     Test net output #0: accuracy = 0.978433
I0403 03:15:30.097864 16973 solver.cpp:404]     Test net output #1: loss = 0.0762727 (* 1 = 0.0762727 loss)
I0403 03:15:32.827466 16973 solver.cpp:228] Iteration 2928, loss = 0.0132273
I0403 03:15:32.833457 16973 solver.cpp:244]     Train net output #0: loss = 0.0132273 (* 1 = 0.0132273 loss)
I0403 03:15:33.067734 16973 sgd_solver.cpp:106] Iteration 2928, lr = 0.005
I0403 03:15:44.585037 16973 solver.cpp:228] Iteration 2944, loss = 0.0276256
I0403 03:15:44.591269 16973 solver.cpp:244]     Train net output #0: loss = 0.0276256 (* 1 = 0.0276256 loss)
I0403 03:15:44.770792 16973 sgd_solver.cpp:106] Iteration 2944, lr = 0.005
I0403 03:15:56.263767 16973 solver.cpp:228] Iteration 2960, loss = 0.000659833
I0403 03:15:56.269178 16973 solver.cpp:244]     Train net output #0: loss = 0.000659842 (* 1 = 0.000659842 loss)
I0403 03:15:56.449637 16973 sgd_solver.cpp:106] Iteration 2960, lr = 0.005
I0403 03:16:07.870537 16973 solver.cpp:228] Iteration 2976, loss = 0.0295542
I0403 03:16:07.876735 16973 solver.cpp:244]     Train net output #0: loss = 0.0295542 (* 1 = 0.0295542 loss)
I0403 03:16:08.057600 16973 sgd_solver.cpp:106] Iteration 2976, lr = 0.005
I0403 03:16:19.555730 16973 solver.cpp:228] Iteration 2992, loss = 0.0372082
I0403 03:16:19.562415 16973 solver.cpp:244]     Train net output #0: loss = 0.0372082 (* 1 = 0.0372082 loss)
I0403 03:16:19.747869 16973 sgd_solver.cpp:106] Iteration 2992, lr = 0.005
I0403 03:16:31.139403 16973 solver.cpp:228] Iteration 3008, loss = 0.0027729
I0403 03:16:31.145673 16973 solver.cpp:244]     Train net output #0: loss = 0.00277291 (* 1 = 0.00277291 loss)
I0403 03:16:31.330363 16973 sgd_solver.cpp:106] Iteration 3008, lr = 0.005
I0403 03:16:42.840081 16973 solver.cpp:228] Iteration 3024, loss = 0.0440833
I0403 03:16:42.847770 16973 solver.cpp:244]     Train net output #0: loss = 0.0440833 (* 1 = 0.0440833 loss)
I0403 03:16:43.033855 16973 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 03:16:54.468567 16973 solver.cpp:228] Iteration 3040, loss = 0.00349277
I0403 03:16:54.475055 16973 solver.cpp:244]     Train net output #0: loss = 0.00349278 (* 1 = 0.00349278 loss)
I0403 03:16:54.710773 16973 sgd_solver.cpp:106] Iteration 3040, lr = 0.005
I0403 03:17:06.262353 16973 solver.cpp:228] Iteration 3056, loss = 0.0114801
I0403 03:17:06.269595 16973 solver.cpp:244]     Train net output #0: loss = 0.0114801 (* 1 = 0.0114801 loss)
I0403 03:17:06.437427 16973 sgd_solver.cpp:106] Iteration 3056, lr = 0.005
I0403 03:17:17.981467 16973 solver.cpp:228] Iteration 3072, loss = 0.0667556
I0403 03:17:17.988623 16973 solver.cpp:244]     Train net output #0: loss = 0.0667556 (* 1 = 0.0667556 loss)
I0403 03:17:18.205824 16973 sgd_solver.cpp:106] Iteration 3072, lr = 0.005
I0403 03:17:29.771421 16973 solver.cpp:228] Iteration 3088, loss = 0.0200651
I0403 03:17:29.777782 16973 solver.cpp:244]     Train net output #0: loss = 0.0200651 (* 1 = 0.0200651 loss)
I0403 03:17:29.958153 16973 sgd_solver.cpp:106] Iteration 3088, lr = 0.005
I0403 03:17:41.409732 16973 solver.cpp:228] Iteration 3104, loss = 0.0156014
I0403 03:17:41.416851 16973 solver.cpp:244]     Train net output #0: loss = 0.0156015 (* 1 = 0.0156015 loss)
I0403 03:17:41.591835 16973 sgd_solver.cpp:106] Iteration 3104, lr = 0.005
I0403 03:17:53.120682 16973 solver.cpp:228] Iteration 3120, loss = 0.00890597
I0403 03:17:53.127367 16973 solver.cpp:244]     Train net output #0: loss = 0.008906 (* 1 = 0.008906 loss)
I0403 03:17:53.305804 16973 sgd_solver.cpp:106] Iteration 3120, lr = 0.005
I0403 03:18:04.829756 16973 solver.cpp:228] Iteration 3136, loss = 0.0195155
I0403 03:18:04.836159 16973 solver.cpp:244]     Train net output #0: loss = 0.0195156 (* 1 = 0.0195156 loss)
I0403 03:18:05.013485 16973 sgd_solver.cpp:106] Iteration 3136, lr = 0.005
I0403 03:18:16.585948 16973 solver.cpp:228] Iteration 3152, loss = 0.0587389
I0403 03:18:16.591630 16973 solver.cpp:244]     Train net output #0: loss = 0.0587389 (* 1 = 0.0587389 loss)
I0403 03:18:16.777226 16973 sgd_solver.cpp:106] Iteration 3152, lr = 0.005
I0403 03:18:28.458129 16973 solver.cpp:228] Iteration 3168, loss = 0.0181699
I0403 03:18:28.464917 16973 solver.cpp:244]     Train net output #0: loss = 0.0181699 (* 1 = 0.0181699 loss)
I0403 03:18:28.613164 16973 sgd_solver.cpp:106] Iteration 3168, lr = 0.005
I0403 03:18:40.156041 16973 solver.cpp:228] Iteration 3184, loss = 0.00720008
I0403 03:18:40.162822 16973 solver.cpp:244]     Train net output #0: loss = 0.00720011 (* 1 = 0.00720011 loss)
I0403 03:18:40.380987 16973 sgd_solver.cpp:106] Iteration 3184, lr = 0.005
I0403 03:18:51.993989 16973 solver.cpp:228] Iteration 3200, loss = 0.018376
I0403 03:18:52.001054 16973 solver.cpp:244]     Train net output #0: loss = 0.0183761 (* 1 = 0.0183761 loss)
I0403 03:18:52.197768 16973 sgd_solver.cpp:106] Iteration 3200, lr = 0.005
I0403 03:19:03.813997 16973 solver.cpp:228] Iteration 3216, loss = 0.0113402
I0403 03:19:03.821036 16973 solver.cpp:244]     Train net output #0: loss = 0.0113403 (* 1 = 0.0113403 loss)
I0403 03:19:03.994416 16973 sgd_solver.cpp:106] Iteration 3216, lr = 0.005
I0403 03:19:15.593972 16973 solver.cpp:228] Iteration 3232, loss = 0.000812881
I0403 03:19:15.600155 16973 solver.cpp:244]     Train net output #0: loss = 0.000812902 (* 1 = 0.000812902 loss)
I0403 03:19:15.777521 16973 sgd_solver.cpp:106] Iteration 3232, lr = 0.005
I0403 03:19:27.205265 16973 solver.cpp:228] Iteration 3248, loss = 0.00698415
I0403 03:19:27.213394 16973 solver.cpp:244]     Train net output #0: loss = 0.00698417 (* 1 = 0.00698417 loss)
I0403 03:19:27.392993 16973 sgd_solver.cpp:106] Iteration 3248, lr = 0.005
I0403 03:19:28.118465 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_3250.caffemodel
I0403 03:19:30.796510 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_3250.solverstate
I0403 03:19:32.552609 16973 solver.cpp:337] Iteration 3250, Testing net (#0)
I0403 03:20:21.742647 16973 solver.cpp:404]     Test net output #0: accuracy = 0.976452
I0403 03:20:21.749400 16973 solver.cpp:404]     Test net output #1: loss = 0.084946 (* 1 = 0.084946 loss)
I0403 03:20:32.404700 16973 solver.cpp:228] Iteration 3264, loss = 0.024574
I0403 03:20:32.409986 16973 solver.cpp:244]     Train net output #0: loss = 0.0245741 (* 1 = 0.0245741 loss)
I0403 03:20:32.574542 16973 sgd_solver.cpp:106] Iteration 3264, lr = 0.0005
I0403 03:20:44.167800 16973 solver.cpp:228] Iteration 3280, loss = 0.0351136
I0403 03:20:44.174034 16973 solver.cpp:244]     Train net output #0: loss = 0.0351136 (* 1 = 0.0351136 loss)
I0403 03:20:44.321683 16973 sgd_solver.cpp:106] Iteration 3280, lr = 0.0005
I0403 03:20:55.886320 16973 solver.cpp:228] Iteration 3296, loss = 0.000539178
I0403 03:20:55.893494 16973 solver.cpp:244]     Train net output #0: loss = 0.000539199 (* 1 = 0.000539199 loss)
I0403 03:20:56.074244 16973 sgd_solver.cpp:106] Iteration 3296, lr = 0.0005
I0403 03:21:07.677569 16973 solver.cpp:228] Iteration 3312, loss = 0.00149131
I0403 03:21:07.682750 16973 solver.cpp:244]     Train net output #0: loss = 0.00149133 (* 1 = 0.00149133 loss)
I0403 03:21:07.820015 16973 sgd_solver.cpp:106] Iteration 3312, lr = 0.0005
I0403 03:21:19.441560 16973 solver.cpp:228] Iteration 3328, loss = 0.0075723
I0403 03:21:19.446723 16973 solver.cpp:244]     Train net output #0: loss = 0.00757232 (* 1 = 0.00757232 loss)
I0403 03:21:19.635731 16973 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 03:21:31.176841 16973 solver.cpp:228] Iteration 3344, loss = 0.00492712
I0403 03:21:31.184037 16973 solver.cpp:244]     Train net output #0: loss = 0.00492714 (* 1 = 0.00492714 loss)
I0403 03:21:31.366260 16973 sgd_solver.cpp:106] Iteration 3344, lr = 0.0005
I0403 03:21:42.831356 16973 solver.cpp:228] Iteration 3360, loss = 0.00466775
I0403 03:21:42.838567 16973 solver.cpp:244]     Train net output #0: loss = 0.00466777 (* 1 = 0.00466777 loss)
I0403 03:21:43.070333 16973 sgd_solver.cpp:106] Iteration 3360, lr = 0.0005
I0403 03:21:54.633469 16973 solver.cpp:228] Iteration 3376, loss = 0.00148978
I0403 03:21:54.639955 16973 solver.cpp:244]     Train net output #0: loss = 0.0014898 (* 1 = 0.0014898 loss)
I0403 03:21:54.833417 16973 sgd_solver.cpp:106] Iteration 3376, lr = 0.0005
I0403 03:22:06.207094 16973 solver.cpp:228] Iteration 3392, loss = 0.00209827
I0403 03:22:06.212656 16973 solver.cpp:244]     Train net output #0: loss = 0.0020983 (* 1 = 0.0020983 loss)
I0403 03:22:06.471626 16973 sgd_solver.cpp:106] Iteration 3392, lr = 0.0005
I0403 03:22:17.980868 16973 solver.cpp:228] Iteration 3408, loss = 0.000702238
I0403 03:22:17.988890 16973 solver.cpp:244]     Train net output #0: loss = 0.000702268 (* 1 = 0.000702268 loss)
I0403 03:22:18.164978 16973 sgd_solver.cpp:106] Iteration 3408, lr = 0.0005
I0403 03:22:29.762969 16973 solver.cpp:228] Iteration 3424, loss = 0.00103622
I0403 03:22:29.768954 16973 solver.cpp:244]     Train net output #0: loss = 0.00103626 (* 1 = 0.00103626 loss)
I0403 03:22:30.007693 16973 sgd_solver.cpp:106] Iteration 3424, lr = 0.0005
I0403 03:22:41.584271 16973 solver.cpp:228] Iteration 3440, loss = 0.00281267
I0403 03:22:41.590340 16973 solver.cpp:244]     Train net output #0: loss = 0.0028127 (* 1 = 0.0028127 loss)
I0403 03:22:41.817203 16973 sgd_solver.cpp:106] Iteration 3440, lr = 0.0005
I0403 03:22:53.292258 16973 solver.cpp:228] Iteration 3456, loss = 0.0351707
I0403 03:22:53.298346 16973 solver.cpp:244]     Train net output #0: loss = 0.0351707 (* 1 = 0.0351707 loss)
I0403 03:22:53.488350 16973 sgd_solver.cpp:106] Iteration 3456, lr = 0.0005
I0403 03:23:05.094877 16973 solver.cpp:228] Iteration 3472, loss = 0.000463165
I0403 03:23:05.101295 16973 solver.cpp:244]     Train net output #0: loss = 0.00046319 (* 1 = 0.00046319 loss)
I0403 03:23:05.277170 16973 sgd_solver.cpp:106] Iteration 3472, lr = 0.0005
I0403 03:23:16.808596 16973 solver.cpp:228] Iteration 3488, loss = 0.000803198
I0403 03:23:16.814520 16973 solver.cpp:244]     Train net output #0: loss = 0.000803222 (* 1 = 0.000803222 loss)
I0403 03:23:17.015522 16973 sgd_solver.cpp:106] Iteration 3488, lr = 0.0005
I0403 03:23:28.648924 16973 solver.cpp:228] Iteration 3504, loss = 0.000325826
I0403 03:23:28.656275 16973 solver.cpp:244]     Train net output #0: loss = 0.000325849 (* 1 = 0.000325849 loss)
I0403 03:23:28.874694 16973 sgd_solver.cpp:106] Iteration 3504, lr = 0.0005
I0403 03:23:40.656589 16973 solver.cpp:228] Iteration 3520, loss = 0.00276757
I0403 03:23:40.663202 16973 solver.cpp:244]     Train net output #0: loss = 0.00276759 (* 1 = 0.00276759 loss)
I0403 03:23:40.848461 16973 sgd_solver.cpp:106] Iteration 3520, lr = 0.0005
I0403 03:23:52.295163 16973 solver.cpp:228] Iteration 3536, loss = 0.000737352
I0403 03:23:52.302022 16973 solver.cpp:244]     Train net output #0: loss = 0.000737374 (* 1 = 0.000737374 loss)
I0403 03:23:52.468523 16973 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 03:24:03.775399 16973 solver.cpp:228] Iteration 3552, loss = 0.00105859
I0403 03:24:03.781116 16973 solver.cpp:244]     Train net output #0: loss = 0.00105861 (* 1 = 0.00105861 loss)
I0403 03:24:03.969166 16973 sgd_solver.cpp:106] Iteration 3552, lr = 0.0005
I0403 03:24:15.309146 16973 solver.cpp:228] Iteration 3568, loss = 0.00123289
I0403 03:24:15.315733 16973 solver.cpp:244]     Train net output #0: loss = 0.00123292 (* 1 = 0.00123292 loss)
I0403 03:24:15.487481 16973 sgd_solver.cpp:106] Iteration 3568, lr = 0.0005
I0403 03:24:19.878790 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_3575.caffemodel
I0403 03:24:22.642874 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_3575.solverstate
I0403 03:24:24.570111 16973 solver.cpp:337] Iteration 3575, Testing net (#0)
I0403 03:25:13.770387 16973 solver.cpp:404]     Test net output #0: accuracy = 0.983273
I0403 03:25:13.777187 16973 solver.cpp:404]     Test net output #1: loss = 0.0593841 (* 1 = 0.0593841 loss)
I0403 03:25:20.916219 16973 solver.cpp:228] Iteration 3584, loss = 0.00797657
I0403 03:25:20.923203 16973 solver.cpp:244]     Train net output #0: loss = 0.00797659 (* 1 = 0.00797659 loss)
I0403 03:25:21.103334 16973 sgd_solver.cpp:106] Iteration 3584, lr = 0.0005
I0403 03:25:32.550793 16973 solver.cpp:228] Iteration 3600, loss = 0.00586991
I0403 03:25:32.557361 16973 solver.cpp:244]     Train net output #0: loss = 0.00586993 (* 1 = 0.00586993 loss)
I0403 03:25:32.771636 16973 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0403 03:25:44.253758 16973 solver.cpp:228] Iteration 3616, loss = 0.000185712
I0403 03:25:44.259553 16973 solver.cpp:244]     Train net output #0: loss = 0.000185733 (* 1 = 0.000185733 loss)
I0403 03:25:44.436033 16973 sgd_solver.cpp:106] Iteration 3616, lr = 0.0005
I0403 03:25:55.925022 16973 solver.cpp:228] Iteration 3632, loss = 0.00264373
I0403 03:25:55.933578 16973 solver.cpp:244]     Train net output #0: loss = 0.00264375 (* 1 = 0.00264375 loss)
I0403 03:25:56.112561 16973 sgd_solver.cpp:106] Iteration 3632, lr = 0.0005
I0403 03:26:07.424832 16973 solver.cpp:228] Iteration 3648, loss = 0.00857686
I0403 03:26:07.431255 16973 solver.cpp:244]     Train net output #0: loss = 0.00857688 (* 1 = 0.00857688 loss)
I0403 03:26:07.633239 16973 sgd_solver.cpp:106] Iteration 3648, lr = 0.0005
I0403 03:26:19.082269 16973 solver.cpp:228] Iteration 3664, loss = 0.0069624
I0403 03:26:19.089347 16973 solver.cpp:244]     Train net output #0: loss = 0.00696242 (* 1 = 0.00696242 loss)
I0403 03:26:19.273067 16973 sgd_solver.cpp:106] Iteration 3664, lr = 0.0005
I0403 03:26:30.918604 16973 solver.cpp:228] Iteration 3680, loss = 0.000379383
I0403 03:26:30.925130 16973 solver.cpp:244]     Train net output #0: loss = 0.000379404 (* 1 = 0.000379404 loss)
I0403 03:26:31.101320 16973 sgd_solver.cpp:106] Iteration 3680, lr = 0.0005
I0403 03:26:42.544786 16973 solver.cpp:228] Iteration 3696, loss = 0.000369562
I0403 03:26:42.552284 16973 solver.cpp:244]     Train net output #0: loss = 0.000369582 (* 1 = 0.000369582 loss)
I0403 03:26:42.769914 16973 sgd_solver.cpp:106] Iteration 3696, lr = 0.0005
I0403 03:26:54.397583 16973 solver.cpp:228] Iteration 3712, loss = 0.000558599
I0403 03:26:54.404763 16973 solver.cpp:244]     Train net output #0: loss = 0.000558619 (* 1 = 0.000558619 loss)
I0403 03:26:54.521066 16973 sgd_solver.cpp:106] Iteration 3712, lr = 0.0005
I0403 03:27:06.320040 16973 solver.cpp:228] Iteration 3728, loss = 0.000201406
I0403 03:27:06.326004 16973 solver.cpp:244]     Train net output #0: loss = 0.000201426 (* 1 = 0.000201426 loss)
I0403 03:27:06.451292 16973 sgd_solver.cpp:106] Iteration 3728, lr = 0.0005
I0403 03:27:18.180757 16973 solver.cpp:228] Iteration 3744, loss = 0.00205586
I0403 03:27:18.187357 16973 solver.cpp:244]     Train net output #0: loss = 0.00205588 (* 1 = 0.00205588 loss)
I0403 03:27:18.380439 16973 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 03:27:29.953948 16973 solver.cpp:228] Iteration 3760, loss = 8.72072e-05
I0403 03:27:29.960994 16973 solver.cpp:244]     Train net output #0: loss = 8.72283e-05 (* 1 = 8.72283e-05 loss)
I0403 03:27:30.200597 16973 sgd_solver.cpp:106] Iteration 3760, lr = 0.0005
I0403 03:27:41.744088 16973 solver.cpp:228] Iteration 3776, loss = 0.00192902
I0403 03:27:41.749804 16973 solver.cpp:244]     Train net output #0: loss = 0.00192904 (* 1 = 0.00192904 loss)
I0403 03:27:41.953219 16973 sgd_solver.cpp:106] Iteration 3776, lr = 0.0005
I0403 03:27:53.645099 16973 solver.cpp:228] Iteration 3792, loss = 0.017628
I0403 03:27:53.651955 16973 solver.cpp:244]     Train net output #0: loss = 0.017628 (* 1 = 0.017628 loss)
I0403 03:27:53.823298 16973 sgd_solver.cpp:106] Iteration 3792, lr = 0.0005
I0403 03:28:05.423393 16973 solver.cpp:228] Iteration 3808, loss = 0.00230849
I0403 03:28:05.429692 16973 solver.cpp:244]     Train net output #0: loss = 0.00230851 (* 1 = 0.00230851 loss)
I0403 03:28:05.595319 16973 sgd_solver.cpp:106] Iteration 3808, lr = 0.0005
I0403 03:28:17.179841 16973 solver.cpp:228] Iteration 3824, loss = 0.00531977
I0403 03:28:17.187795 16973 solver.cpp:244]     Train net output #0: loss = 0.00531979 (* 1 = 0.00531979 loss)
I0403 03:28:17.382567 16973 sgd_solver.cpp:106] Iteration 3824, lr = 0.0005
I0403 03:28:28.809741 16973 solver.cpp:228] Iteration 3840, loss = 0.00218912
I0403 03:28:28.815877 16973 solver.cpp:244]     Train net output #0: loss = 0.00218914 (* 1 = 0.00218914 loss)
I0403 03:28:28.999502 16973 sgd_solver.cpp:106] Iteration 3840, lr = 0.0005
I0403 03:28:40.491886 16973 solver.cpp:228] Iteration 3856, loss = 0.000202898
I0403 03:28:40.496865 16973 solver.cpp:244]     Train net output #0: loss = 0.000202919 (* 1 = 0.000202919 loss)
I0403 03:28:40.690227 16973 sgd_solver.cpp:106] Iteration 3856, lr = 0.0005
I0403 03:28:52.386564 16973 solver.cpp:228] Iteration 3872, loss = 0.00127771
I0403 03:28:52.393656 16973 solver.cpp:244]     Train net output #0: loss = 0.00127773 (* 1 = 0.00127773 loss)
I0403 03:28:52.578927 16973 sgd_solver.cpp:106] Iteration 3872, lr = 0.0005
I0403 03:29:04.172791 16973 solver.cpp:228] Iteration 3888, loss = 0.00143219
I0403 03:29:04.179303 16973 solver.cpp:244]     Train net output #0: loss = 0.00143221 (* 1 = 0.00143221 loss)
I0403 03:29:04.361538 16973 sgd_solver.cpp:106] Iteration 3888, lr = 0.0005
I0403 03:29:12.564862 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_3900.caffemodel
I0403 03:29:15.154989 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_3900.solverstate
I0403 03:29:16.970855 16973 solver.cpp:337] Iteration 3900, Testing net (#0)
I0403 03:30:06.168345 16973 solver.cpp:404]     Test net output #0: accuracy = 0.984102
I0403 03:30:06.174887 16973 solver.cpp:404]     Test net output #1: loss = 0.056311 (* 1 = 0.056311 loss)
I0403 03:30:09.616606 16973 solver.cpp:228] Iteration 3904, loss = 0.000176258
I0403 03:30:09.624382 16973 solver.cpp:244]     Train net output #0: loss = 0.000176282 (* 1 = 0.000176282 loss)
I0403 03:30:09.818158 16973 sgd_solver.cpp:106] Iteration 3904, lr = 0.0005
I0403 03:30:21.347821 16973 solver.cpp:228] Iteration 3920, loss = 0.00351621
I0403 03:30:21.355069 16973 solver.cpp:244]     Train net output #0: loss = 0.00351624 (* 1 = 0.00351624 loss)
I0403 03:30:21.631989 16973 sgd_solver.cpp:106] Iteration 3920, lr = 0.0005
I0403 03:30:33.364702 16973 solver.cpp:228] Iteration 3936, loss = 0.0030042
I0403 03:30:33.371577 16973 solver.cpp:244]     Train net output #0: loss = 0.00300423 (* 1 = 0.00300423 loss)
I0403 03:30:33.548307 16973 sgd_solver.cpp:106] Iteration 3936, lr = 0.0005
I0403 03:30:45.027444 16973 solver.cpp:228] Iteration 3952, loss = 0.00115956
I0403 03:30:45.032261 16973 solver.cpp:244]     Train net output #0: loss = 0.00115958 (* 1 = 0.00115958 loss)
I0403 03:30:45.251071 16973 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 03:30:56.762403 16973 solver.cpp:228] Iteration 3968, loss = 0.00223017
I0403 03:30:56.767480 16973 solver.cpp:244]     Train net output #0: loss = 0.0022302 (* 1 = 0.0022302 loss)
I0403 03:30:57.021811 16973 sgd_solver.cpp:106] Iteration 3968, lr = 0.0005
I0403 03:31:08.480886 16973 solver.cpp:228] Iteration 3984, loss = 0.000731678
I0403 03:31:08.487794 16973 solver.cpp:244]     Train net output #0: loss = 0.0007317 (* 1 = 0.0007317 loss)
I0403 03:31:08.676090 16973 sgd_solver.cpp:106] Iteration 3984, lr = 0.0005
I0403 03:31:20.246572 16973 solver.cpp:228] Iteration 4000, loss = 0.000376402
I0403 03:31:20.253432 16973 solver.cpp:244]     Train net output #0: loss = 0.000376424 (* 1 = 0.000376424 loss)
I0403 03:31:20.427675 16973 sgd_solver.cpp:106] Iteration 4000, lr = 0.0005
I0403 03:31:32.066398 16973 solver.cpp:228] Iteration 4016, loss = 0.000273518
I0403 03:31:32.073408 16973 solver.cpp:244]     Train net output #0: loss = 0.00027354 (* 1 = 0.00027354 loss)
I0403 03:31:32.275369 16973 sgd_solver.cpp:106] Iteration 4016, lr = 0.0005
I0403 03:31:43.694339 16973 solver.cpp:228] Iteration 4032, loss = 0.00105055
I0403 03:31:43.699904 16973 solver.cpp:244]     Train net output #0: loss = 0.00105057 (* 1 = 0.00105057 loss)
I0403 03:31:43.879133 16973 sgd_solver.cpp:106] Iteration 4032, lr = 0.0005
I0403 03:31:55.409299 16973 solver.cpp:228] Iteration 4048, loss = 0.000557399
I0403 03:31:55.415946 16973 solver.cpp:244]     Train net output #0: loss = 0.000557421 (* 1 = 0.000557421 loss)
I0403 03:31:55.587420 16973 sgd_solver.cpp:106] Iteration 4048, lr = 0.0005
I0403 03:32:07.106932 16973 solver.cpp:228] Iteration 4064, loss = 0.00942575
I0403 03:32:07.115591 16973 solver.cpp:244]     Train net output #0: loss = 0.00942577 (* 1 = 0.00942577 loss)
I0403 03:32:07.298943 16973 sgd_solver.cpp:106] Iteration 4064, lr = 0.0005
I0403 03:32:18.785717 16973 solver.cpp:228] Iteration 4080, loss = 0.00163802
I0403 03:32:18.791573 16973 solver.cpp:244]     Train net output #0: loss = 0.00163804 (* 1 = 0.00163804 loss)
I0403 03:32:18.973386 16973 sgd_solver.cpp:106] Iteration 4080, lr = 0.0005
I0403 03:32:30.754817 16973 solver.cpp:228] Iteration 4096, loss = 0.000534982
I0403 03:32:30.762871 16973 solver.cpp:244]     Train net output #0: loss = 0.000535004 (* 1 = 0.000535004 loss)
I0403 03:32:30.952739 16973 sgd_solver.cpp:106] Iteration 4096, lr = 0.0005
I0403 03:32:42.595047 16973 solver.cpp:228] Iteration 4112, loss = 0.00179556
I0403 03:32:42.601600 16973 solver.cpp:244]     Train net output #0: loss = 0.00179558 (* 1 = 0.00179558 loss)
I0403 03:32:42.779163 16973 sgd_solver.cpp:106] Iteration 4112, lr = 0.0005
I0403 03:32:54.274670 16973 solver.cpp:228] Iteration 4128, loss = 0.0082311
I0403 03:32:54.279870 16973 solver.cpp:244]     Train net output #0: loss = 0.00823112 (* 1 = 0.00823112 loss)
I0403 03:32:54.457402 16973 sgd_solver.cpp:106] Iteration 4128, lr = 0.0005
I0403 03:33:05.931762 16973 solver.cpp:228] Iteration 4144, loss = 0.00223033
I0403 03:33:05.938573 16973 solver.cpp:244]     Train net output #0: loss = 0.00223035 (* 1 = 0.00223035 loss)
I0403 03:33:06.131541 16973 sgd_solver.cpp:106] Iteration 4144, lr = 0.0005
I0403 03:33:17.723834 16973 solver.cpp:228] Iteration 4160, loss = 0.00847028
I0403 03:33:17.730872 16973 solver.cpp:244]     Train net output #0: loss = 0.0084703 (* 1 = 0.0084703 loss)
I0403 03:33:17.917454 16973 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:33:29.331743 16973 solver.cpp:228] Iteration 4176, loss = 0.000732773
I0403 03:33:29.338057 16973 solver.cpp:244]     Train net output #0: loss = 0.000732793 (* 1 = 0.000732793 loss)
I0403 03:33:29.537372 16973 sgd_solver.cpp:106] Iteration 4176, lr = 0.0005
I0403 03:33:40.994094 16973 solver.cpp:228] Iteration 4192, loss = 0.00024357
I0403 03:33:41.000820 16973 solver.cpp:244]     Train net output #0: loss = 0.000243591 (* 1 = 0.000243591 loss)
I0403 03:33:41.169845 16973 sgd_solver.cpp:106] Iteration 4192, lr = 0.0005
I0403 03:33:52.645040 16973 solver.cpp:228] Iteration 4208, loss = 0.000214642
I0403 03:33:52.651056 16973 solver.cpp:244]     Train net output #0: loss = 0.000214662 (* 1 = 0.000214662 loss)
I0403 03:33:52.833703 16973 sgd_solver.cpp:106] Iteration 4208, lr = 0.0005
I0403 03:34:04.282711 16973 solver.cpp:228] Iteration 4224, loss = 0.000164095
I0403 03:34:04.282807 16973 solver.cpp:244]     Train net output #0: loss = 0.000164116 (* 1 = 0.000164116 loss)
I0403 03:34:04.466707 16973 sgd_solver.cpp:106] Iteration 4224, lr = 0.0005
I0403 03:34:04.466941 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_4225.caffemodel
I0403 03:34:08.849253 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_4225.solverstate
I0403 03:34:11.999341 16973 solver.cpp:337] Iteration 4225, Testing net (#0)
I0403 03:35:01.193975 16973 solver.cpp:404]     Test net output #0: accuracy = 0.98424
I0403 03:35:01.194298 16973 solver.cpp:404]     Test net output #1: loss = 0.0567701 (* 1 = 0.0567701 loss)
I0403 03:35:12.646783 16973 solver.cpp:228] Iteration 4240, loss = 0.00237144
I0403 03:35:12.646886 16973 solver.cpp:244]     Train net output #0: loss = 0.00237146 (* 1 = 0.00237146 loss)
I0403 03:35:12.828738 16973 sgd_solver.cpp:106] Iteration 4240, lr = 0.0005
I0403 03:35:24.355226 16973 solver.cpp:228] Iteration 4256, loss = 0.00203308
I0403 03:35:24.355337 16973 solver.cpp:244]     Train net output #0: loss = 0.0020331 (* 1 = 0.0020331 loss)
I0403 03:35:24.543432 16973 sgd_solver.cpp:106] Iteration 4256, lr = 0.0005
I0403 03:35:36.157266 16973 solver.cpp:228] Iteration 4272, loss = 0.00076158
I0403 03:35:36.157611 16973 solver.cpp:244]     Train net output #0: loss = 0.000761599 (* 1 = 0.000761599 loss)
I0403 03:35:36.356654 16973 sgd_solver.cpp:106] Iteration 4272, lr = 0.0005
I0403 03:35:47.882426 16973 solver.cpp:228] Iteration 4288, loss = 0.00234857
I0403 03:35:47.882544 16973 solver.cpp:244]     Train net output #0: loss = 0.00234859 (* 1 = 0.00234859 loss)
I0403 03:35:48.069386 16973 sgd_solver.cpp:106] Iteration 4288, lr = 0.0005
I0403 03:35:59.775382 16973 solver.cpp:228] Iteration 4304, loss = 0.00320105
I0403 03:35:59.775482 16973 solver.cpp:244]     Train net output #0: loss = 0.00320107 (* 1 = 0.00320107 loss)
I0403 03:35:59.953956 16973 sgd_solver.cpp:106] Iteration 4304, lr = 0.0005
I0403 03:36:11.465656 16973 solver.cpp:228] Iteration 4320, loss = 0.00171395
I0403 03:36:11.465980 16973 solver.cpp:244]     Train net output #0: loss = 0.00171397 (* 1 = 0.00171397 loss)
I0403 03:36:11.691041 16973 sgd_solver.cpp:106] Iteration 4320, lr = 0.0005
I0403 03:36:23.193302 16973 solver.cpp:228] Iteration 4336, loss = 0.0198771
I0403 03:36:23.193418 16973 solver.cpp:244]     Train net output #0: loss = 0.0198771 (* 1 = 0.0198771 loss)
I0403 03:36:23.383252 16973 sgd_solver.cpp:106] Iteration 4336, lr = 0.0005
I0403 03:36:34.876787 16973 solver.cpp:228] Iteration 4352, loss = 0.000540293
I0403 03:36:34.876884 16973 solver.cpp:244]     Train net output #0: loss = 0.000540311 (* 1 = 0.000540311 loss)
I0403 03:36:35.057286 16973 sgd_solver.cpp:106] Iteration 4352, lr = 0.0005
I0403 03:36:46.514653 16973 solver.cpp:228] Iteration 4368, loss = 0.000303319
I0403 03:36:46.515019 16973 solver.cpp:244]     Train net output #0: loss = 0.000303335 (* 1 = 0.000303335 loss)
I0403 03:36:46.703203 16973 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:36:58.259814 16973 solver.cpp:228] Iteration 4384, loss = 0.000704316
I0403 03:36:58.259917 16973 solver.cpp:244]     Train net output #0: loss = 0.000704332 (* 1 = 0.000704332 loss)
I0403 03:36:58.437839 16973 sgd_solver.cpp:106] Iteration 4384, lr = 0.0005
I0403 03:37:10.096914 16973 solver.cpp:228] Iteration 4400, loss = 0.000354312
I0403 03:37:10.097023 16973 solver.cpp:244]     Train net output #0: loss = 0.000354329 (* 1 = 0.000354329 loss)
I0403 03:37:10.280515 16973 sgd_solver.cpp:106] Iteration 4400, lr = 0.0005
I0403 03:37:21.966434 16973 solver.cpp:228] Iteration 4416, loss = 0.000650418
I0403 03:37:21.966745 16973 solver.cpp:244]     Train net output #0: loss = 0.000650435 (* 1 = 0.000650435 loss)
I0403 03:37:22.163014 16973 sgd_solver.cpp:106] Iteration 4416, lr = 0.0005
I0403 03:37:33.590260 16973 solver.cpp:228] Iteration 4432, loss = 0.000784539
I0403 03:37:33.590376 16973 solver.cpp:244]     Train net output #0: loss = 0.000784556 (* 1 = 0.000784556 loss)
I0403 03:37:33.779279 16973 sgd_solver.cpp:106] Iteration 4432, lr = 0.0005
I0403 03:37:45.120450 16973 solver.cpp:228] Iteration 4448, loss = 0.00116411
I0403 03:37:45.120568 16973 solver.cpp:244]     Train net output #0: loss = 0.00116412 (* 1 = 0.00116412 loss)
I0403 03:37:45.303975 16973 sgd_solver.cpp:106] Iteration 4448, lr = 0.0005
I0403 03:37:56.736786 16973 solver.cpp:228] Iteration 4464, loss = 0.00482034
I0403 03:37:56.737097 16973 solver.cpp:244]     Train net output #0: loss = 0.00482036 (* 1 = 0.00482036 loss)
I0403 03:37:56.953096 16973 sgd_solver.cpp:106] Iteration 4464, lr = 0.0005
I0403 03:38:08.523685 16973 solver.cpp:228] Iteration 4480, loss = 5.63241e-05
I0403 03:38:08.523792 16973 solver.cpp:244]     Train net output #0: loss = 5.63438e-05 (* 1 = 5.63438e-05 loss)
I0403 03:38:08.705453 16973 sgd_solver.cpp:106] Iteration 4480, lr = 0.0005
I0403 03:38:20.168071 16973 solver.cpp:228] Iteration 4496, loss = 0.0048385
I0403 03:38:20.168185 16973 solver.cpp:244]     Train net output #0: loss = 0.00483852 (* 1 = 0.00483852 loss)
I0403 03:38:20.420344 16973 sgd_solver.cpp:106] Iteration 4496, lr = 0.0005
I0403 03:38:32.077119 16973 solver.cpp:228] Iteration 4512, loss = 0.0023386
I0403 03:38:32.077446 16973 solver.cpp:244]     Train net output #0: loss = 0.00233863 (* 1 = 0.00233863 loss)
I0403 03:38:32.245286 16973 sgd_solver.cpp:106] Iteration 4512, lr = 0.0005
I0403 03:38:43.733166 16973 solver.cpp:228] Iteration 4528, loss = 0.000185555
I0403 03:38:43.733280 16973 solver.cpp:244]     Train net output #0: loss = 0.000185576 (* 1 = 0.000185576 loss)
I0403 03:38:43.932345 16973 sgd_solver.cpp:106] Iteration 4528, lr = 0.0005
I0403 03:38:55.465600 16973 solver.cpp:228] Iteration 4544, loss = 0.00210491
I0403 03:38:55.465714 16973 solver.cpp:244]     Train net output #0: loss = 0.00210493 (* 1 = 0.00210493 loss)
I0403 03:38:55.741152 16973 sgd_solver.cpp:106] Iteration 4544, lr = 0.0005
I0403 03:38:59.470857 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_4550.caffemodel
I0403 03:39:02.123091 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_4550.solverstate
I0403 03:39:03.915523 16973 solver.cpp:337] Iteration 4550, Testing net (#0)
I0403 03:39:53.104111 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985438
I0403 03:39:53.104450 16973 solver.cpp:404]     Test net output #1: loss = 0.0549912 (* 1 = 0.0549912 loss)
I0403 03:40:01.009308 16973 solver.cpp:228] Iteration 4560, loss = 0.000268362
I0403 03:40:01.009407 16973 solver.cpp:244]     Train net output #0: loss = 0.000268383 (* 1 = 0.000268383 loss)
I0403 03:40:01.184705 16973 sgd_solver.cpp:106] Iteration 4560, lr = 0.0005
I0403 03:40:12.757275 16973 solver.cpp:228] Iteration 4576, loss = 0.0151672
I0403 03:40:12.757380 16973 solver.cpp:244]     Train net output #0: loss = 0.0151672 (* 1 = 0.0151672 loss)
I0403 03:40:12.938119 16973 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 03:40:24.471969 16973 solver.cpp:228] Iteration 4592, loss = 0.00112111
I0403 03:40:24.472316 16973 solver.cpp:244]     Train net output #0: loss = 0.00112114 (* 1 = 0.00112114 loss)
I0403 03:40:24.658337 16973 sgd_solver.cpp:106] Iteration 4592, lr = 0.0005
I0403 03:40:36.103113 16973 solver.cpp:228] Iteration 4608, loss = 0.00100476
I0403 03:40:36.103224 16973 solver.cpp:244]     Train net output #0: loss = 0.00100478 (* 1 = 0.00100478 loss)
I0403 03:40:36.314478 16973 sgd_solver.cpp:106] Iteration 4608, lr = 0.0005
I0403 03:40:47.729728 16973 solver.cpp:228] Iteration 4624, loss = 0.00256112
I0403 03:40:47.729845 16973 solver.cpp:244]     Train net output #0: loss = 0.00256114 (* 1 = 0.00256114 loss)
I0403 03:40:47.919679 16973 sgd_solver.cpp:106] Iteration 4624, lr = 0.0005
I0403 03:40:59.370080 16973 solver.cpp:228] Iteration 4640, loss = 0.000109419
I0403 03:40:59.370421 16973 solver.cpp:244]     Train net output #0: loss = 0.000109441 (* 1 = 0.000109441 loss)
I0403 03:40:59.575949 16973 sgd_solver.cpp:106] Iteration 4640, lr = 0.0005
I0403 03:41:10.994887 16973 solver.cpp:228] Iteration 4656, loss = 0.000146123
I0403 03:41:10.994999 16973 solver.cpp:244]     Train net output #0: loss = 0.000146146 (* 1 = 0.000146146 loss)
I0403 03:41:11.184495 16973 sgd_solver.cpp:106] Iteration 4656, lr = 0.0005
I0403 03:41:22.699149 16973 solver.cpp:228] Iteration 4672, loss = 0.000763818
I0403 03:41:22.699265 16973 solver.cpp:244]     Train net output #0: loss = 0.00076384 (* 1 = 0.00076384 loss)
I0403 03:41:22.886242 16973 sgd_solver.cpp:106] Iteration 4672, lr = 0.0005
I0403 03:41:34.475767 16973 solver.cpp:228] Iteration 4688, loss = 4.60027e-05
I0403 03:41:34.476106 16973 solver.cpp:244]     Train net output #0: loss = 4.60247e-05 (* 1 = 4.60247e-05 loss)
I0403 03:41:34.675848 16973 sgd_solver.cpp:106] Iteration 4688, lr = 0.0005
I0403 03:41:46.068614 16973 solver.cpp:228] Iteration 4704, loss = 0.00014178
I0403 03:41:46.068712 16973 solver.cpp:244]     Train net output #0: loss = 0.000141802 (* 1 = 0.000141802 loss)
I0403 03:41:46.249706 16973 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 03:41:58.063335 16973 solver.cpp:228] Iteration 4720, loss = 0.00755325
I0403 03:41:58.063434 16973 solver.cpp:244]     Train net output #0: loss = 0.00755327 (* 1 = 0.00755327 loss)
I0403 03:41:58.189472 16973 sgd_solver.cpp:106] Iteration 4720, lr = 0.0005
I0403 03:42:09.906545 16973 solver.cpp:228] Iteration 4736, loss = 0.00412521
I0403 03:42:09.906905 16973 solver.cpp:244]     Train net output #0: loss = 0.00412523 (* 1 = 0.00412523 loss)
I0403 03:42:10.104804 16973 sgd_solver.cpp:106] Iteration 4736, lr = 0.0005
I0403 03:42:21.743949 16973 solver.cpp:228] Iteration 4752, loss = 0.000761577
I0403 03:42:21.744063 16973 solver.cpp:244]     Train net output #0: loss = 0.000761598 (* 1 = 0.000761598 loss)
I0403 03:42:21.938376 16973 sgd_solver.cpp:106] Iteration 4752, lr = 0.0005
I0403 03:42:33.606287 16973 solver.cpp:228] Iteration 4768, loss = 0.00107421
I0403 03:42:33.606397 16973 solver.cpp:244]     Train net output #0: loss = 0.00107423 (* 1 = 0.00107423 loss)
I0403 03:42:33.788139 16973 sgd_solver.cpp:106] Iteration 4768, lr = 0.0005
I0403 03:42:45.333165 16973 solver.cpp:228] Iteration 4784, loss = 0.00192417
I0403 03:42:45.333514 16973 solver.cpp:244]     Train net output #0: loss = 0.00192419 (* 1 = 0.00192419 loss)
I0403 03:42:45.521913 16973 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 03:42:56.940146 16973 solver.cpp:228] Iteration 4800, loss = 0.00041682
I0403 03:42:56.940248 16973 solver.cpp:244]     Train net output #0: loss = 0.00041684 (* 1 = 0.00041684 loss)
I0403 03:42:57.099122 16973 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0403 03:43:08.846294 16973 solver.cpp:228] Iteration 4816, loss = 0.000527689
I0403 03:43:08.846405 16973 solver.cpp:244]     Train net output #0: loss = 0.000527709 (* 1 = 0.000527709 loss)
I0403 03:43:09.052709 16973 sgd_solver.cpp:106] Iteration 4816, lr = 0.0005
I0403 03:43:20.602942 16973 solver.cpp:228] Iteration 4832, loss = 0.00010365
I0403 03:43:20.603247 16973 solver.cpp:244]     Train net output #0: loss = 0.000103671 (* 1 = 0.000103671 loss)
I0403 03:43:20.779284 16973 sgd_solver.cpp:106] Iteration 4832, lr = 0.0005
I0403 03:43:32.270861 16973 solver.cpp:228] Iteration 4848, loss = 0.000599326
I0403 03:43:32.270978 16973 solver.cpp:244]     Train net output #0: loss = 0.000599348 (* 1 = 0.000599348 loss)
I0403 03:43:32.477427 16973 sgd_solver.cpp:106] Iteration 4848, lr = 0.0005
I0403 03:43:43.981884 16973 solver.cpp:228] Iteration 4864, loss = 0.00273024
I0403 03:43:43.982000 16973 solver.cpp:244]     Train net output #0: loss = 0.00273027 (* 1 = 0.00273027 loss)
I0403 03:43:44.208066 16973 sgd_solver.cpp:106] Iteration 4864, lr = 0.0005
I0403 03:43:51.674055 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_4875.caffemodel
I0403 03:43:54.287317 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_4875.solverstate
I0403 03:43:56.103309 16973 solver.cpp:337] Iteration 4875, Testing net (#0)
I0403 03:44:45.298954 16973 solver.cpp:404]     Test net output #0: accuracy = 0.984701
I0403 03:44:45.299293 16973 solver.cpp:404]     Test net output #1: loss = 0.0564571 (* 1 = 0.0564571 loss)
I0403 03:44:49.474656 16973 solver.cpp:228] Iteration 4880, loss = 0.000139564
I0403 03:44:49.474771 16973 solver.cpp:244]     Train net output #0: loss = 0.000139585 (* 1 = 0.000139585 loss)
I0403 03:44:49.667904 16973 sgd_solver.cpp:106] Iteration 4880, lr = 0.0005
I0403 03:45:01.273246 16973 solver.cpp:228] Iteration 4896, loss = 0.000186555
I0403 03:45:01.273357 16973 solver.cpp:244]     Train net output #0: loss = 0.000186576 (* 1 = 0.000186576 loss)
I0403 03:45:01.457715 16973 sgd_solver.cpp:106] Iteration 4896, lr = 0.0005
I0403 03:45:13.063499 16973 solver.cpp:228] Iteration 4912, loss = 0.000124708
I0403 03:45:13.063606 16973 solver.cpp:244]     Train net output #0: loss = 0.000124728 (* 1 = 0.000124728 loss)
I0403 03:45:13.245622 16973 sgd_solver.cpp:106] Iteration 4912, lr = 0.0005
I0403 03:45:24.816602 16973 solver.cpp:228] Iteration 4928, loss = 0.0142072
I0403 03:45:24.816936 16973 solver.cpp:244]     Train net output #0: loss = 0.0142072 (* 1 = 0.0142072 loss)
I0403 03:45:25.040599 16973 sgd_solver.cpp:106] Iteration 4928, lr = 0.0005
I0403 03:45:36.542809 16973 solver.cpp:228] Iteration 4944, loss = 0.00181601
I0403 03:45:36.542925 16973 solver.cpp:244]     Train net output #0: loss = 0.00181603 (* 1 = 0.00181603 loss)
I0403 03:45:36.791414 16973 sgd_solver.cpp:106] Iteration 4944, lr = 0.0005
I0403 03:45:48.469372 16973 solver.cpp:228] Iteration 4960, loss = 0.000872253
I0403 03:45:48.469491 16973 solver.cpp:244]     Train net output #0: loss = 0.000872273 (* 1 = 0.000872273 loss)
I0403 03:45:48.660146 16973 sgd_solver.cpp:106] Iteration 4960, lr = 0.0005
I0403 03:46:00.249408 16973 solver.cpp:228] Iteration 4976, loss = 0.000177266
I0403 03:46:00.249778 16973 solver.cpp:244]     Train net output #0: loss = 0.000177286 (* 1 = 0.000177286 loss)
I0403 03:46:00.415493 16973 sgd_solver.cpp:106] Iteration 4976, lr = 0.0005
I0403 03:46:11.969689 16973 solver.cpp:228] Iteration 4992, loss = 0.000879736
I0403 03:46:11.969794 16973 solver.cpp:244]     Train net output #0: loss = 0.000879756 (* 1 = 0.000879756 loss)
I0403 03:46:12.148593 16973 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 03:46:23.545028 16973 solver.cpp:228] Iteration 5008, loss = 0.000159899
I0403 03:46:23.545150 16973 solver.cpp:244]     Train net output #0: loss = 0.000159921 (* 1 = 0.000159921 loss)
I0403 03:46:23.737648 16973 sgd_solver.cpp:106] Iteration 5008, lr = 0.0005
I0403 03:46:35.064195 16973 solver.cpp:228] Iteration 5024, loss = 0.000586545
I0403 03:46:35.066413 16973 solver.cpp:244]     Train net output #0: loss = 0.000586568 (* 1 = 0.000586568 loss)
I0403 03:46:35.263907 16973 sgd_solver.cpp:106] Iteration 5024, lr = 0.0005
I0403 03:46:46.554136 16973 solver.cpp:228] Iteration 5040, loss = 0.000385703
I0403 03:46:46.554250 16973 solver.cpp:244]     Train net output #0: loss = 0.000385725 (* 1 = 0.000385725 loss)
I0403 03:46:46.738050 16973 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 03:46:58.134781 16973 solver.cpp:228] Iteration 5056, loss = 0.00122612
I0403 03:46:58.134899 16973 solver.cpp:244]     Train net output #0: loss = 0.00122615 (* 1 = 0.00122615 loss)
I0403 03:46:58.323704 16973 sgd_solver.cpp:106] Iteration 5056, lr = 0.0005
I0403 03:47:09.786958 16973 solver.cpp:228] Iteration 5072, loss = 0.000917337
I0403 03:47:09.787303 16973 solver.cpp:244]     Train net output #0: loss = 0.000917359 (* 1 = 0.000917359 loss)
I0403 03:47:09.980592 16973 sgd_solver.cpp:106] Iteration 5072, lr = 0.0005
I0403 03:47:21.369920 16973 solver.cpp:228] Iteration 5088, loss = 0.0242042
I0403 03:47:21.370023 16973 solver.cpp:244]     Train net output #0: loss = 0.0242043 (* 1 = 0.0242043 loss)
I0403 03:47:21.549226 16973 sgd_solver.cpp:106] Iteration 5088, lr = 0.0005
I0403 03:47:32.945884 16973 solver.cpp:228] Iteration 5104, loss = 0.000957541
I0403 03:47:32.945996 16973 solver.cpp:244]     Train net output #0: loss = 0.000957563 (* 1 = 0.000957563 loss)
I0403 03:47:33.145090 16973 sgd_solver.cpp:106] Iteration 5104, lr = 0.0005
I0403 03:47:44.592699 16973 solver.cpp:228] Iteration 5120, loss = 0.000510251
I0403 03:47:44.593004 16973 solver.cpp:244]     Train net output #0: loss = 0.000510274 (* 1 = 0.000510274 loss)
I0403 03:47:44.768563 16973 sgd_solver.cpp:106] Iteration 5120, lr = 0.0005
I0403 03:47:56.410320 16973 solver.cpp:228] Iteration 5136, loss = 0.0145752
I0403 03:47:56.410437 16973 solver.cpp:244]     Train net output #0: loss = 0.0145753 (* 1 = 0.0145753 loss)
I0403 03:47:56.651576 16973 sgd_solver.cpp:106] Iteration 5136, lr = 0.0005
I0403 03:48:08.231328 16973 solver.cpp:228] Iteration 5152, loss = 0.000752978
I0403 03:48:08.231446 16973 solver.cpp:244]     Train net output #0: loss = 0.000752998 (* 1 = 0.000752998 loss)
I0403 03:48:08.434432 16973 sgd_solver.cpp:106] Iteration 5152, lr = 0.0005
I0403 03:48:20.087280 16973 solver.cpp:228] Iteration 5168, loss = 0.000122217
I0403 03:48:20.087616 16973 solver.cpp:244]     Train net output #0: loss = 0.000122237 (* 1 = 0.000122237 loss)
I0403 03:48:20.269464 16973 sgd_solver.cpp:106] Iteration 5168, lr = 0.0005
I0403 03:48:31.925562 16973 solver.cpp:228] Iteration 5184, loss = 0.000509527
I0403 03:48:31.925665 16973 solver.cpp:244]     Train net output #0: loss = 0.000509546 (* 1 = 0.000509546 loss)
I0403 03:48:32.095625 16973 sgd_solver.cpp:106] Iteration 5184, lr = 0.0005
I0403 03:48:42.992501 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_5200.caffemodel
I0403 03:48:45.752645 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_5200.solverstate
I0403 03:48:47.648015 16973 solver.cpp:337] Iteration 5200, Testing net (#0)
I0403 03:49:36.837750 16973 solver.cpp:404]     Test net output #0: accuracy = 0.984886
I0403 03:49:36.838114 16973 solver.cpp:404]     Test net output #1: loss = 0.0562559 (* 1 = 0.0562559 loss)
I0403 03:49:37.341421 16973 solver.cpp:228] Iteration 5200, loss = 0.000788843
I0403 03:49:37.341536 16973 solver.cpp:244]     Train net output #0: loss = 0.000788863 (* 1 = 0.000788863 loss)
I0403 03:49:37.534790 16973 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 03:49:49.101799 16973 solver.cpp:228] Iteration 5216, loss = 0.00266241
I0403 03:49:49.101917 16973 solver.cpp:244]     Train net output #0: loss = 0.00266243 (* 1 = 0.00266243 loss)
I0403 03:49:49.309851 16973 sgd_solver.cpp:106] Iteration 5216, lr = 0.0005
I0403 03:50:00.745467 16973 solver.cpp:228] Iteration 5232, loss = 0.00026301
I0403 03:50:00.745563 16973 solver.cpp:244]     Train net output #0: loss = 0.00026303 (* 1 = 0.00026303 loss)
I0403 03:50:00.918195 16973 sgd_solver.cpp:106] Iteration 5232, lr = 0.0005
I0403 03:50:12.452715 16973 solver.cpp:228] Iteration 5248, loss = 0.00214266
I0403 03:50:12.453055 16973 solver.cpp:244]     Train net output #0: loss = 0.00214268 (* 1 = 0.00214268 loss)
I0403 03:50:12.643602 16973 sgd_solver.cpp:106] Iteration 5248, lr = 0.0005
I0403 03:50:24.043845 16973 solver.cpp:228] Iteration 5264, loss = 0.00144055
I0403 03:50:24.043961 16973 solver.cpp:244]     Train net output #0: loss = 0.00144057 (* 1 = 0.00144057 loss)
I0403 03:50:24.247493 16973 sgd_solver.cpp:106] Iteration 5264, lr = 0.0005
I0403 03:50:36.052758 16973 solver.cpp:228] Iteration 5280, loss = 0.00188517
I0403 03:50:36.052868 16973 solver.cpp:244]     Train net output #0: loss = 0.00188519 (* 1 = 0.00188519 loss)
I0403 03:50:36.255655 16973 sgd_solver.cpp:106] Iteration 5280, lr = 0.0005
I0403 03:50:47.859207 16973 solver.cpp:228] Iteration 5296, loss = 0.000218277
I0403 03:50:47.859540 16973 solver.cpp:244]     Train net output #0: loss = 0.000218297 (* 1 = 0.000218297 loss)
I0403 03:50:48.042735 16973 sgd_solver.cpp:106] Iteration 5296, lr = 0.0005
I0403 03:50:59.465701 16973 solver.cpp:228] Iteration 5312, loss = 0.000268791
I0403 03:50:59.465812 16973 solver.cpp:244]     Train net output #0: loss = 0.000268811 (* 1 = 0.000268811 loss)
I0403 03:50:59.658684 16973 sgd_solver.cpp:106] Iteration 5312, lr = 0.0005
I0403 03:51:11.235641 16973 solver.cpp:228] Iteration 5328, loss = 0.00031602
I0403 03:51:11.235757 16973 solver.cpp:244]     Train net output #0: loss = 0.00031604 (* 1 = 0.00031604 loss)
I0403 03:51:11.441362 16973 sgd_solver.cpp:106] Iteration 5328, lr = 0.0005
I0403 03:51:22.985241 16973 solver.cpp:228] Iteration 5344, loss = 0.000838831
I0403 03:51:22.985594 16973 solver.cpp:244]     Train net output #0: loss = 0.000838852 (* 1 = 0.000838852 loss)
I0403 03:51:23.256665 16973 sgd_solver.cpp:106] Iteration 5344, lr = 0.0005
I0403 03:51:34.915426 16973 solver.cpp:228] Iteration 5360, loss = 0.00166757
I0403 03:51:34.915542 16973 solver.cpp:244]     Train net output #0: loss = 0.00166759 (* 1 = 0.00166759 loss)
I0403 03:51:35.105623 16973 sgd_solver.cpp:106] Iteration 5360, lr = 0.0005
I0403 03:51:46.528954 16973 solver.cpp:228] Iteration 5376, loss = 0.000129017
I0403 03:51:46.529057 16973 solver.cpp:244]     Train net output #0: loss = 0.000129037 (* 1 = 0.000129037 loss)
I0403 03:51:46.698428 16973 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 03:51:58.421159 16973 solver.cpp:228] Iteration 5392, loss = 0.00232205
I0403 03:51:58.421540 16973 solver.cpp:244]     Train net output #0: loss = 0.00232207 (* 1 = 0.00232207 loss)
I0403 03:51:58.632604 16973 sgd_solver.cpp:106] Iteration 5392, lr = 0.0005
I0403 03:52:10.105453 16973 solver.cpp:228] Iteration 5408, loss = 0.00489056
I0403 03:52:10.105572 16973 solver.cpp:244]     Train net output #0: loss = 0.00489058 (* 1 = 0.00489058 loss)
I0403 03:52:10.298485 16973 sgd_solver.cpp:106] Iteration 5408, lr = 0.0005
I0403 03:52:21.661367 16973 solver.cpp:228] Iteration 5424, loss = 0.000388646
I0403 03:52:21.661486 16973 solver.cpp:244]     Train net output #0: loss = 0.000388667 (* 1 = 0.000388667 loss)
I0403 03:52:21.876940 16973 sgd_solver.cpp:106] Iteration 5424, lr = 0.0005
I0403 03:52:33.277122 16973 solver.cpp:228] Iteration 5440, loss = 0.00158078
I0403 03:52:33.277470 16973 solver.cpp:244]     Train net output #0: loss = 0.0015808 (* 1 = 0.0015808 loss)
I0403 03:52:33.459100 16973 sgd_solver.cpp:106] Iteration 5440, lr = 0.0005
I0403 03:52:45.260033 16973 solver.cpp:228] Iteration 5456, loss = 0.000358139
I0403 03:52:45.260138 16973 solver.cpp:244]     Train net output #0: loss = 0.000358159 (* 1 = 0.000358159 loss)
I0403 03:52:45.439070 16973 sgd_solver.cpp:106] Iteration 5456, lr = 0.0005
I0403 03:52:56.942409 16973 solver.cpp:228] Iteration 5472, loss = 6.79372e-05
I0403 03:52:56.942524 16973 solver.cpp:244]     Train net output #0: loss = 6.79572e-05 (* 1 = 6.79572e-05 loss)
I0403 03:52:57.134774 16973 sgd_solver.cpp:106] Iteration 5472, lr = 0.0005
I0403 03:53:08.897987 16973 solver.cpp:228] Iteration 5488, loss = 0.00016521
I0403 03:53:08.898272 16973 solver.cpp:244]     Train net output #0: loss = 0.00016523 (* 1 = 0.00016523 loss)
I0403 03:53:09.040467 16973 sgd_solver.cpp:106] Iteration 5488, lr = 0.0005
I0403 03:53:20.714138 16973 solver.cpp:228] Iteration 5504, loss = 0.000926008
I0403 03:53:20.714254 16973 solver.cpp:244]     Train net output #0: loss = 0.000926028 (* 1 = 0.000926028 loss)
I0403 03:53:20.903009 16973 sgd_solver.cpp:106] Iteration 5504, lr = 0.0005
I0403 03:53:32.524219 16973 solver.cpp:228] Iteration 5520, loss = 0.00011457
I0403 03:53:32.524333 16973 solver.cpp:244]     Train net output #0: loss = 0.00011459 (* 1 = 0.00011459 loss)
I0403 03:53:32.746855 16973 sgd_solver.cpp:106] Iteration 5520, lr = 0.0005
I0403 03:53:35.703703 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_5525.caffemodel
I0403 03:53:38.461863 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_5525.solverstate
I0403 03:53:40.348685 16973 solver.cpp:337] Iteration 5525, Testing net (#0)
I0403 03:54:29.540088 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985024
I0403 03:54:29.540418 16973 solver.cpp:404]     Test net output #1: loss = 0.0566454 (* 1 = 0.0566454 loss)
I0403 03:54:38.192817 16973 solver.cpp:228] Iteration 5536, loss = 0.00113873
I0403 03:54:38.192937 16973 solver.cpp:244]     Train net output #0: loss = 0.00113875 (* 1 = 0.00113875 loss)
I0403 03:54:38.430382 16973 sgd_solver.cpp:106] Iteration 5536, lr = 0.0005
I0403 03:54:50.080824 16973 solver.cpp:228] Iteration 5552, loss = 5.41881e-05
I0403 03:54:50.080940 16973 solver.cpp:244]     Train net output #0: loss = 5.42069e-05 (* 1 = 5.42069e-05 loss)
I0403 03:54:50.279093 16973 sgd_solver.cpp:106] Iteration 5552, lr = 0.0005
I0403 03:55:01.805155 16973 solver.cpp:228] Iteration 5568, loss = 0.00012265
I0403 03:55:01.805492 16973 solver.cpp:244]     Train net output #0: loss = 0.000122669 (* 1 = 0.000122669 loss)
I0403 03:55:01.988541 16973 sgd_solver.cpp:106] Iteration 5568, lr = 0.0005
I0403 03:55:13.536317 16973 solver.cpp:228] Iteration 5584, loss = 0.000745739
I0403 03:55:13.543275 16973 solver.cpp:244]     Train net output #0: loss = 0.000745758 (* 1 = 0.000745758 loss)
I0403 03:55:13.742868 16973 sgd_solver.cpp:106] Iteration 5584, lr = 0.0005
I0403 03:55:25.209287 16973 solver.cpp:228] Iteration 5600, loss = 0.00191784
I0403 03:55:25.214674 16973 solver.cpp:244]     Train net output #0: loss = 0.00191786 (* 1 = 0.00191786 loss)
I0403 03:55:25.375864 16973 sgd_solver.cpp:106] Iteration 5600, lr = 0.0005
I0403 03:55:37.098244 16973 solver.cpp:228] Iteration 5616, loss = 0.000618458
I0403 03:55:37.103744 16973 solver.cpp:244]     Train net output #0: loss = 0.000618477 (* 1 = 0.000618477 loss)
I0403 03:55:37.250977 16973 sgd_solver.cpp:106] Iteration 5616, lr = 0.0005
I0403 03:55:48.880373 16973 solver.cpp:228] Iteration 5632, loss = 0.000148971
I0403 03:55:48.880482 16973 solver.cpp:244]     Train net output #0: loss = 0.00014899 (* 1 = 0.00014899 loss)
I0403 03:55:49.082038 16973 sgd_solver.cpp:106] Iteration 5632, lr = 0.0005
I0403 03:56:00.554985 16973 solver.cpp:228] Iteration 5648, loss = 9.9008e-05
I0403 03:56:00.555094 16973 solver.cpp:244]     Train net output #0: loss = 9.90266e-05 (* 1 = 9.90266e-05 loss)
I0403 03:56:00.734663 16973 sgd_solver.cpp:106] Iteration 5648, lr = 0.0005
I0403 03:56:12.180366 16973 solver.cpp:228] Iteration 5664, loss = 0.000577229
I0403 03:56:12.180709 16973 solver.cpp:244]     Train net output #0: loss = 0.000577248 (* 1 = 0.000577248 loss)
I0403 03:56:12.359212 16973 sgd_solver.cpp:106] Iteration 5664, lr = 0.0005
I0403 03:56:23.826210 16973 solver.cpp:228] Iteration 5680, loss = 0.000331635
I0403 03:56:23.826328 16973 solver.cpp:244]     Train net output #0: loss = 0.000331654 (* 1 = 0.000331654 loss)
I0403 03:56:24.016836 16973 sgd_solver.cpp:106] Iteration 5680, lr = 0.0005
I0403 03:56:35.507601 16973 solver.cpp:228] Iteration 5696, loss = 0.00850601
I0403 03:56:35.507704 16973 solver.cpp:244]     Train net output #0: loss = 0.00850603 (* 1 = 0.00850603 loss)
I0403 03:56:35.663997 16973 sgd_solver.cpp:106] Iteration 5696, lr = 0.0005
I0403 03:56:47.335654 16973 solver.cpp:228] Iteration 5712, loss = 0.000294347
I0403 03:56:47.336001 16973 solver.cpp:244]     Train net output #0: loss = 0.000294366 (* 1 = 0.000294366 loss)
I0403 03:56:47.528393 16973 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 03:56:59.115813 16973 solver.cpp:228] Iteration 5728, loss = 0.000257548
I0403 03:56:59.115926 16973 solver.cpp:244]     Train net output #0: loss = 0.000257567 (* 1 = 0.000257567 loss)
I0403 03:56:59.308130 16973 sgd_solver.cpp:106] Iteration 5728, lr = 0.0005
I0403 03:57:10.772750 16973 solver.cpp:228] Iteration 5744, loss = 0.00253198
I0403 03:57:10.772877 16973 solver.cpp:244]     Train net output #0: loss = 0.002532 (* 1 = 0.002532 loss)
I0403 03:57:10.981418 16973 sgd_solver.cpp:106] Iteration 5744, lr = 0.0005
I0403 03:57:22.454433 16973 solver.cpp:228] Iteration 5760, loss = 0.000198278
I0403 03:57:22.454800 16973 solver.cpp:244]     Train net output #0: loss = 0.000198296 (* 1 = 0.000198296 loss)
I0403 03:57:22.670434 16973 sgd_solver.cpp:106] Iteration 5760, lr = 0.0005
I0403 03:57:34.249632 16973 solver.cpp:228] Iteration 5776, loss = 0.00233693
I0403 03:57:34.249747 16973 solver.cpp:244]     Train net output #0: loss = 0.00233695 (* 1 = 0.00233695 loss)
I0403 03:57:34.432307 16973 sgd_solver.cpp:106] Iteration 5776, lr = 0.0005
I0403 03:57:45.929050 16973 solver.cpp:228] Iteration 5792, loss = 0.00152922
I0403 03:57:45.929162 16973 solver.cpp:244]     Train net output #0: loss = 0.00152924 (* 1 = 0.00152924 loss)
I0403 03:57:46.133004 16973 sgd_solver.cpp:106] Iteration 5792, lr = 0.0005
I0403 03:57:57.658053 16973 solver.cpp:228] Iteration 5808, loss = 0.000160231
I0403 03:57:57.658377 16973 solver.cpp:244]     Train net output #0: loss = 0.00016025 (* 1 = 0.00016025 loss)
I0403 03:57:57.795748 16973 sgd_solver.cpp:106] Iteration 5808, lr = 0.0005
I0403 03:58:09.652299 16973 solver.cpp:228] Iteration 5824, loss = 0.000419672
I0403 03:58:09.652415 16973 solver.cpp:244]     Train net output #0: loss = 0.00041969 (* 1 = 0.00041969 loss)
I0403 03:58:09.876778 16973 sgd_solver.cpp:106] Iteration 5824, lr = 0.0005
I0403 03:58:21.540680 16973 solver.cpp:228] Iteration 5840, loss = 0.000709008
I0403 03:58:21.540794 16973 solver.cpp:244]     Train net output #0: loss = 0.000709026 (* 1 = 0.000709026 loss)
I0403 03:58:21.744001 16973 sgd_solver.cpp:106] Iteration 5840, lr = 0.0005
I0403 03:58:28.450603 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_5850.caffemodel
I0403 03:58:31.195112 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_5850.solverstate
I0403 03:58:33.095116 16973 solver.cpp:337] Iteration 5850, Testing net (#0)
I0403 03:59:22.284677 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985485
I0403 03:59:22.285015 16973 solver.cpp:404]     Test net output #1: loss = 0.0558964 (* 1 = 0.0558964 loss)
I0403 03:59:27.328127 16973 solver.cpp:228] Iteration 5856, loss = 0.000156844
I0403 03:59:27.328232 16973 solver.cpp:244]     Train net output #0: loss = 0.000156864 (* 1 = 0.000156864 loss)
I0403 03:59:27.510386 16973 sgd_solver.cpp:106] Iteration 5856, lr = 0.0005
I0403 03:59:39.153970 16973 solver.cpp:228] Iteration 5872, loss = 0.00139922
I0403 03:59:39.154085 16973 solver.cpp:244]     Train net output #0: loss = 0.00139924 (* 1 = 0.00139924 loss)
I0403 03:59:39.349038 16973 sgd_solver.cpp:106] Iteration 5872, lr = 0.0005
I0403 03:59:50.860780 16973 solver.cpp:228] Iteration 5888, loss = 0.000921182
I0403 03:59:50.860893 16973 solver.cpp:244]     Train net output #0: loss = 0.000921201 (* 1 = 0.000921201 loss)
I0403 03:59:51.046577 16973 sgd_solver.cpp:106] Iteration 5888, lr = 0.0005
I0403 04:00:02.535230 16973 solver.cpp:228] Iteration 5904, loss = 0.00718612
I0403 04:00:02.535511 16973 solver.cpp:244]     Train net output #0: loss = 0.00718614 (* 1 = 0.00718614 loss)
I0403 04:00:02.726366 16973 sgd_solver.cpp:106] Iteration 5904, lr = 0.0005
I0403 04:00:14.479430 16973 solver.cpp:228] Iteration 5920, loss = 0.0150399
I0403 04:00:14.479532 16973 solver.cpp:244]     Train net output #0: loss = 0.0150399 (* 1 = 0.0150399 loss)
I0403 04:00:14.648558 16973 sgd_solver.cpp:106] Iteration 5920, lr = 0.0005
I0403 04:00:26.131078 16973 solver.cpp:228] Iteration 5936, loss = 0.000236734
I0403 04:00:26.131191 16973 solver.cpp:244]     Train net output #0: loss = 0.000236752 (* 1 = 0.000236752 loss)
I0403 04:00:26.343067 16973 sgd_solver.cpp:106] Iteration 5936, lr = 0.0005
I0403 04:00:37.762094 16973 solver.cpp:228] Iteration 5952, loss = 0.000170303
I0403 04:00:37.762454 16973 solver.cpp:244]     Train net output #0: loss = 0.000170321 (* 1 = 0.000170321 loss)
I0403 04:00:37.963093 16973 sgd_solver.cpp:106] Iteration 5952, lr = 0.0005
I0403 04:00:49.542650 16973 solver.cpp:228] Iteration 5968, loss = 0.00573644
I0403 04:00:49.542768 16973 solver.cpp:244]     Train net output #0: loss = 0.00573646 (* 1 = 0.00573646 loss)
I0403 04:00:49.736048 16973 sgd_solver.cpp:106] Iteration 5968, lr = 0.0005
I0403 04:01:01.335794 16973 solver.cpp:228] Iteration 5984, loss = 0.00248604
I0403 04:01:01.335918 16973 solver.cpp:244]     Train net output #0: loss = 0.00248606 (* 1 = 0.00248606 loss)
I0403 04:01:01.524744 16973 sgd_solver.cpp:106] Iteration 5984, lr = 0.0005
I0403 04:01:13.109263 16973 solver.cpp:228] Iteration 6000, loss = 0.000348335
I0403 04:01:13.109583 16973 solver.cpp:244]     Train net output #0: loss = 0.000348353 (* 1 = 0.000348353 loss)
I0403 04:01:13.293745 16973 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0403 04:01:24.924330 16973 solver.cpp:228] Iteration 6016, loss = 0.00351526
I0403 04:01:24.924443 16973 solver.cpp:244]     Train net output #0: loss = 0.00351528 (* 1 = 0.00351528 loss)
I0403 04:01:25.147075 16973 sgd_solver.cpp:106] Iteration 6016, lr = 0.0005
I0403 04:01:36.702239 16973 solver.cpp:228] Iteration 6032, loss = 0.000813008
I0403 04:01:36.702363 16973 solver.cpp:244]     Train net output #0: loss = 0.000813026 (* 1 = 0.000813026 loss)
I0403 04:01:36.898036 16973 sgd_solver.cpp:106] Iteration 6032, lr = 0.0005
I0403 04:01:48.489306 16973 solver.cpp:228] Iteration 6048, loss = 0.00118567
I0403 04:01:48.493587 16973 solver.cpp:244]     Train net output #0: loss = 0.00118569 (* 1 = 0.00118569 loss)
I0403 04:01:48.673189 16973 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 04:02:00.194490 16973 solver.cpp:228] Iteration 6064, loss = 0.00171024
I0403 04:02:00.194608 16973 solver.cpp:244]     Train net output #0: loss = 0.00171026 (* 1 = 0.00171026 loss)
I0403 04:02:00.399524 16973 sgd_solver.cpp:106] Iteration 6064, lr = 0.0005
I0403 04:02:12.119993 16973 solver.cpp:228] Iteration 6080, loss = 0.0143614
I0403 04:02:12.120100 16973 solver.cpp:244]     Train net output #0: loss = 0.0143615 (* 1 = 0.0143615 loss)
I0403 04:02:12.296731 16973 sgd_solver.cpp:106] Iteration 6080, lr = 0.0005
I0403 04:02:23.990275 16973 solver.cpp:228] Iteration 6096, loss = 0.00211923
I0403 04:02:23.993391 16973 solver.cpp:244]     Train net output #0: loss = 0.00211925 (* 1 = 0.00211925 loss)
I0403 04:02:24.145396 16973 sgd_solver.cpp:106] Iteration 6096, lr = 0.0005
I0403 04:02:35.859190 16973 solver.cpp:228] Iteration 6112, loss = 0.00237683
I0403 04:02:35.859314 16973 solver.cpp:244]     Train net output #0: loss = 0.00237685 (* 1 = 0.00237685 loss)
I0403 04:02:36.058465 16973 sgd_solver.cpp:106] Iteration 6112, lr = 0.0005
I0403 04:02:47.721107 16973 solver.cpp:228] Iteration 6128, loss = 0.000215378
I0403 04:02:47.721220 16973 solver.cpp:244]     Train net output #0: loss = 0.000215399 (* 1 = 0.000215399 loss)
I0403 04:02:47.920574 16973 sgd_solver.cpp:106] Iteration 6128, lr = 0.0005
I0403 04:02:59.550384 16973 solver.cpp:228] Iteration 6144, loss = 0.00393647
I0403 04:02:59.550710 16973 solver.cpp:244]     Train net output #0: loss = 0.00393649 (* 1 = 0.00393649 loss)
I0403 04:02:59.731962 16973 sgd_solver.cpp:106] Iteration 6144, lr = 0.0005
I0403 04:03:11.098381 16973 solver.cpp:228] Iteration 6160, loss = 0.000741635
I0403 04:03:11.098492 16973 solver.cpp:244]     Train net output #0: loss = 0.000741656 (* 1 = 0.000741656 loss)
I0403 04:03:11.298176 16973 sgd_solver.cpp:106] Iteration 6160, lr = 0.0005
I0403 04:03:21.504722 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_6175.caffemodel
I0403 04:03:24.287432 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_6175.solverstate
I0403 04:03:26.184881 16973 solver.cpp:337] Iteration 6175, Testing net (#0)
I0403 04:04:15.377965 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985485
I0403 04:04:15.378248 16973 solver.cpp:404]     Test net output #1: loss = 0.05812 (* 1 = 0.05812 loss)
I0403 04:04:16.609938 16973 solver.cpp:228] Iteration 6176, loss = 0.000447021
I0403 04:04:16.610054 16973 solver.cpp:244]     Train net output #0: loss = 0.000447041 (* 1 = 0.000447041 loss)
I0403 04:04:16.821521 16973 sgd_solver.cpp:106] Iteration 6176, lr = 0.0005
I0403 04:04:28.424412 16973 solver.cpp:228] Iteration 6192, loss = 4.16844e-05
I0403 04:04:28.424526 16973 solver.cpp:244]     Train net output #0: loss = 4.17027e-05 (* 1 = 4.17027e-05 loss)
I0403 04:04:28.617204 16973 sgd_solver.cpp:106] Iteration 6192, lr = 0.0005
I0403 04:04:40.194327 16973 solver.cpp:228] Iteration 6208, loss = 0.000400624
I0403 04:04:40.194432 16973 solver.cpp:244]     Train net output #0: loss = 0.000400643 (* 1 = 0.000400643 loss)
I0403 04:04:40.375234 16973 sgd_solver.cpp:106] Iteration 6208, lr = 0.0005
I0403 04:04:52.128893 16973 solver.cpp:228] Iteration 6224, loss = 0.000218214
I0403 04:04:52.129235 16973 solver.cpp:244]     Train net output #0: loss = 0.000218232 (* 1 = 0.000218232 loss)
I0403 04:04:52.328752 16973 sgd_solver.cpp:106] Iteration 6224, lr = 0.0005
I0403 04:05:03.905844 16973 solver.cpp:228] Iteration 6240, loss = 0.000664793
I0403 04:05:03.905961 16973 solver.cpp:244]     Train net output #0: loss = 0.00066481 (* 1 = 0.00066481 loss)
I0403 04:05:04.101194 16973 sgd_solver.cpp:106] Iteration 6240, lr = 0.0005
I0403 04:05:15.883935 16973 solver.cpp:228] Iteration 6256, loss = 3.81205e-05
I0403 04:05:15.884052 16973 solver.cpp:244]     Train net output #0: loss = 3.81377e-05 (* 1 = 3.81377e-05 loss)
I0403 04:05:16.083171 16973 sgd_solver.cpp:106] Iteration 6256, lr = 0.0005
I0403 04:05:27.652587 16973 solver.cpp:228] Iteration 6272, loss = 0.000252353
I0403 04:05:27.652969 16973 solver.cpp:244]     Train net output #0: loss = 0.000252371 (* 1 = 0.000252371 loss)
I0403 04:05:27.864722 16973 sgd_solver.cpp:106] Iteration 6272, lr = 0.0005
I0403 04:05:39.376971 16973 solver.cpp:228] Iteration 6288, loss = 0.0001157
I0403 04:05:39.377074 16973 solver.cpp:244]     Train net output #0: loss = 0.000115717 (* 1 = 0.000115717 loss)
I0403 04:05:39.536476 16973 sgd_solver.cpp:106] Iteration 6288, lr = 0.0005
I0403 04:05:51.191844 16973 solver.cpp:228] Iteration 6304, loss = 0.000125665
I0403 04:05:51.191956 16973 solver.cpp:244]     Train net output #0: loss = 0.000125684 (* 1 = 0.000125684 loss)
I0403 04:05:51.369552 16973 sgd_solver.cpp:106] Iteration 6304, lr = 0.0005
I0403 04:06:02.859541 16973 solver.cpp:228] Iteration 6320, loss = 0.00598238
I0403 04:06:02.859874 16973 solver.cpp:244]     Train net output #0: loss = 0.0059824 (* 1 = 0.0059824 loss)
I0403 04:06:03.048293 16973 sgd_solver.cpp:106] Iteration 6320, lr = 0.0005
I0403 04:06:14.747400 16973 solver.cpp:228] Iteration 6336, loss = 0.000549127
I0403 04:06:14.747509 16973 solver.cpp:244]     Train net output #0: loss = 0.000549146 (* 1 = 0.000549146 loss)
I0403 04:06:14.927355 16973 sgd_solver.cpp:106] Iteration 6336, lr = 0.0005
I0403 04:06:26.609946 16973 solver.cpp:228] Iteration 6352, loss = 0.000583656
I0403 04:06:26.610065 16973 solver.cpp:244]     Train net output #0: loss = 0.000583674 (* 1 = 0.000583674 loss)
I0403 04:06:26.793206 16973 sgd_solver.cpp:106] Iteration 6352, lr = 0.0005
I0403 04:06:38.438640 16973 solver.cpp:228] Iteration 6368, loss = 0.0132833
I0403 04:06:38.438969 16973 solver.cpp:244]     Train net output #0: loss = 0.0132834 (* 1 = 0.0132834 loss)
I0403 04:06:38.586176 16973 sgd_solver.cpp:106] Iteration 6368, lr = 0.0005
I0403 04:06:50.048674 16973 solver.cpp:228] Iteration 6384, loss = 0.00020058
I0403 04:06:50.048789 16973 solver.cpp:244]     Train net output #0: loss = 0.000200598 (* 1 = 0.000200598 loss)
I0403 04:06:50.232491 16973 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 04:07:01.749729 16973 solver.cpp:228] Iteration 6400, loss = 9.22927e-05
I0403 04:07:01.749845 16973 solver.cpp:244]     Train net output #0: loss = 9.2312e-05 (* 1 = 9.2312e-05 loss)
I0403 04:07:01.967727 16973 sgd_solver.cpp:106] Iteration 6400, lr = 0.0005
I0403 04:07:13.592248 16973 solver.cpp:228] Iteration 6416, loss = 0.0010227
I0403 04:07:13.592591 16973 solver.cpp:244]     Train net output #0: loss = 0.00102272 (* 1 = 0.00102272 loss)
I0403 04:07:13.803791 16973 sgd_solver.cpp:106] Iteration 6416, lr = 0.0005
I0403 04:07:25.401939 16973 solver.cpp:228] Iteration 6432, loss = 0.00022955
I0403 04:07:25.402052 16973 solver.cpp:244]     Train net output #0: loss = 0.000229569 (* 1 = 0.000229569 loss)
I0403 04:07:25.598935 16973 sgd_solver.cpp:106] Iteration 6432, lr = 0.0005
I0403 04:07:37.057210 16973 solver.cpp:228] Iteration 6448, loss = 0.000232159
I0403 04:07:37.057323 16973 solver.cpp:244]     Train net output #0: loss = 0.000232178 (* 1 = 0.000232178 loss)
I0403 04:07:37.286317 16973 sgd_solver.cpp:106] Iteration 6448, lr = 0.0005
I0403 04:07:48.711035 16973 solver.cpp:228] Iteration 6464, loss = 0.000489846
I0403 04:07:48.895501 16973 solver.cpp:244]     Train net output #0: loss = 0.000489865 (* 1 = 0.000489865 loss)
I0403 04:07:48.895596 16973 sgd_solver.cpp:106] Iteration 6464, lr = 0.0005
I0403 04:08:00.503810 16973 solver.cpp:228] Iteration 6480, loss = 0.000140736
I0403 04:08:00.503929 16973 solver.cpp:244]     Train net output #0: loss = 0.000140755 (* 1 = 0.000140755 loss)
I0403 04:08:00.688370 16973 sgd_solver.cpp:106] Iteration 6480, lr = 0.0005
I0403 04:08:12.309206 16973 solver.cpp:228] Iteration 6496, loss = 0.00260399
I0403 04:08:12.309314 16973 solver.cpp:244]     Train net output #0: loss = 0.00260401 (* 1 = 0.00260401 loss)
I0403 04:08:12.510220 16973 sgd_solver.cpp:106] Iteration 6496, lr = 0.0005
I0403 04:08:14.660013 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_6500.caffemodel
I0403 04:08:17.520105 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_6500.solverstate
I0403 04:08:19.398643 16973 solver.cpp:337] Iteration 6500, Testing net (#0)
I0403 04:09:08.607388 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985485
I0403 04:09:08.607727 16973 solver.cpp:404]     Test net output #1: loss = 0.0549918 (* 1 = 0.0549918 loss)
I0403 04:09:17.941073 16973 solver.cpp:228] Iteration 6512, loss = 5.92062e-05
I0403 04:09:17.941195 16973 solver.cpp:244]     Train net output #0: loss = 5.92248e-05 (* 1 = 5.92248e-05 loss)
I0403 04:09:18.142467 16973 sgd_solver.cpp:106] Iteration 6512, lr = 5e-05
I0403 04:09:29.719490 16973 solver.cpp:228] Iteration 6528, loss = 0.00581224
I0403 04:09:29.719607 16973 solver.cpp:244]     Train net output #0: loss = 0.00581225 (* 1 = 0.00581225 loss)
I0403 04:09:29.917332 16973 sgd_solver.cpp:106] Iteration 6528, lr = 5e-05
I0403 04:09:41.384788 16973 solver.cpp:228] Iteration 6544, loss = 6.30837e-05
I0403 04:09:41.385113 16973 solver.cpp:244]     Train net output #0: loss = 6.31023e-05 (* 1 = 6.31023e-05 loss)
I0403 04:09:41.561542 16973 sgd_solver.cpp:106] Iteration 6544, lr = 5e-05
I0403 04:09:53.131606 16973 solver.cpp:228] Iteration 6560, loss = 0.000274062
I0403 04:09:53.131716 16973 solver.cpp:244]     Train net output #0: loss = 0.00027408 (* 1 = 0.00027408 loss)
I0403 04:09:53.333796 16973 sgd_solver.cpp:106] Iteration 6560, lr = 5e-05
I0403 04:10:04.807166 16973 solver.cpp:228] Iteration 6576, loss = 0.000826751
I0403 04:10:04.807270 16973 solver.cpp:244]     Train net output #0: loss = 0.000826769 (* 1 = 0.000826769 loss)
I0403 04:10:04.987457 16973 sgd_solver.cpp:106] Iteration 6576, lr = 5e-05
I0403 04:10:16.491683 16973 solver.cpp:228] Iteration 6592, loss = 0.00212737
I0403 04:10:16.492027 16973 solver.cpp:244]     Train net output #0: loss = 0.00212739 (* 1 = 0.00212739 loss)
I0403 04:10:16.677237 16973 sgd_solver.cpp:106] Iteration 6592, lr = 5e-05
I0403 04:10:28.171469 16973 solver.cpp:228] Iteration 6608, loss = 0.00143895
I0403 04:10:28.171586 16973 solver.cpp:244]     Train net output #0: loss = 0.00143897 (* 1 = 0.00143897 loss)
I0403 04:10:28.373958 16973 sgd_solver.cpp:106] Iteration 6608, lr = 5e-05
I0403 04:10:39.906234 16973 solver.cpp:228] Iteration 6624, loss = 0.00160686
I0403 04:10:39.906332 16973 solver.cpp:244]     Train net output #0: loss = 0.00160688 (* 1 = 0.00160688 loss)
I0403 04:10:40.064494 16973 sgd_solver.cpp:106] Iteration 6624, lr = 5e-05
I0403 04:10:51.595666 16973 solver.cpp:228] Iteration 6640, loss = 4.42485e-05
I0403 04:10:51.595968 16973 solver.cpp:244]     Train net output #0: loss = 4.42668e-05 (* 1 = 4.42668e-05 loss)
I0403 04:10:51.781777 16973 sgd_solver.cpp:106] Iteration 6640, lr = 5e-05
I0403 04:11:03.299600 16973 solver.cpp:228] Iteration 6656, loss = 2.30061e-05
I0403 04:11:03.299703 16973 solver.cpp:244]     Train net output #0: loss = 2.30248e-05 (* 1 = 2.30248e-05 loss)
I0403 04:11:03.465323 16973 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 04:11:15.187790 16973 solver.cpp:228] Iteration 6672, loss = 0.00596499
I0403 04:11:15.187893 16973 solver.cpp:244]     Train net output #0: loss = 0.005965 (* 1 = 0.005965 loss)
I0403 04:11:15.321957 16973 sgd_solver.cpp:106] Iteration 6672, lr = 5e-05
I0403 04:11:27.050817 16973 solver.cpp:228] Iteration 6688, loss = 0.000107046
I0403 04:11:27.052391 16973 solver.cpp:244]     Train net output #0: loss = 0.000107064 (* 1 = 0.000107064 loss)
I0403 04:11:27.236013 16973 sgd_solver.cpp:106] Iteration 6688, lr = 5e-05
I0403 04:11:38.691826 16973 solver.cpp:228] Iteration 6704, loss = 0.000613781
I0403 04:11:38.691941 16973 solver.cpp:244]     Train net output #0: loss = 0.0006138 (* 1 = 0.0006138 loss)
I0403 04:11:38.887902 16973 sgd_solver.cpp:106] Iteration 6704, lr = 5e-05
I0403 04:11:50.334889 16973 solver.cpp:228] Iteration 6720, loss = 0.000316816
I0403 04:11:50.335002 16973 solver.cpp:244]     Train net output #0: loss = 0.000316836 (* 1 = 0.000316836 loss)
I0403 04:11:50.522385 16973 sgd_solver.cpp:106] Iteration 6720, lr = 5e-05
I0403 04:12:02.010969 16973 solver.cpp:228] Iteration 6736, loss = 0.00294331
I0403 04:12:02.011351 16973 solver.cpp:244]     Train net output #0: loss = 0.00294332 (* 1 = 0.00294332 loss)
I0403 04:12:02.240916 16973 sgd_solver.cpp:106] Iteration 6736, lr = 5e-05
I0403 04:12:13.730391 16973 solver.cpp:228] Iteration 6752, loss = 0.000200613
I0403 04:12:13.730507 16973 solver.cpp:244]     Train net output #0: loss = 0.000200633 (* 1 = 0.000200633 loss)
I0403 04:12:13.970273 16973 sgd_solver.cpp:106] Iteration 6752, lr = 5e-05
I0403 04:12:25.815474 16973 solver.cpp:228] Iteration 6768, loss = 0.00140209
I0403 04:12:25.815595 16973 solver.cpp:244]     Train net output #0: loss = 0.00140211 (* 1 = 0.00140211 loss)
I0403 04:12:26.013556 16973 sgd_solver.cpp:106] Iteration 6768, lr = 5e-05
I0403 04:12:37.625298 16973 solver.cpp:228] Iteration 6784, loss = 0.000115662
I0403 04:12:37.625640 16973 solver.cpp:244]     Train net output #0: loss = 0.000115681 (* 1 = 0.000115681 loss)
I0403 04:12:37.823042 16973 sgd_solver.cpp:106] Iteration 6784, lr = 5e-05
I0403 04:12:49.483530 16973 solver.cpp:228] Iteration 6800, loss = 0.00013513
I0403 04:12:49.483642 16973 solver.cpp:244]     Train net output #0: loss = 0.00013515 (* 1 = 0.00013515 loss)
I0403 04:12:49.672710 16973 sgd_solver.cpp:106] Iteration 6800, lr = 5e-05
I0403 04:13:01.201970 16973 solver.cpp:228] Iteration 6816, loss = 0.000270358
I0403 04:13:01.202083 16973 solver.cpp:244]     Train net output #0: loss = 0.000270378 (* 1 = 0.000270378 loss)
I0403 04:13:01.387277 16973 sgd_solver.cpp:106] Iteration 6816, lr = 5e-05
I0403 04:13:07.193260 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_6825.caffemodel
I0403 04:13:09.831485 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_6825.solverstate
I0403 04:13:11.588975 16973 solver.cpp:337] Iteration 6825, Testing net (#0)
I0403 04:14:00.774051 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985577
I0403 04:14:00.777408 16973 solver.cpp:404]     Test net output #1: loss = 0.0553371 (* 1 = 0.0553371 loss)
I0403 04:14:06.513885 16973 solver.cpp:228] Iteration 6832, loss = 0.000158505
I0403 04:14:06.514000 16973 solver.cpp:244]     Train net output #0: loss = 0.000158526 (* 1 = 0.000158526 loss)
I0403 04:14:06.714581 16973 sgd_solver.cpp:106] Iteration 6832, lr = 5e-05
I0403 04:14:18.510134 16973 solver.cpp:228] Iteration 6848, loss = 0.00375266
I0403 04:14:18.510236 16973 solver.cpp:244]     Train net output #0: loss = 0.00375269 (* 1 = 0.00375269 loss)
I0403 04:14:18.680233 16973 sgd_solver.cpp:106] Iteration 6848, lr = 5e-05
I0403 04:14:30.355339 16973 solver.cpp:228] Iteration 6864, loss = 0.00162297
I0403 04:14:30.355449 16973 solver.cpp:244]     Train net output #0: loss = 0.00162299 (* 1 = 0.00162299 loss)
I0403 04:14:30.546599 16973 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 04:14:41.967320 16973 solver.cpp:228] Iteration 6880, loss = 0.00369777
I0403 04:14:41.967602 16973 solver.cpp:244]     Train net output #0: loss = 0.00369779 (* 1 = 0.00369779 loss)
I0403 04:14:42.165357 16973 sgd_solver.cpp:106] Iteration 6880, lr = 5e-05
I0403 04:14:53.896052 16973 solver.cpp:228] Iteration 6896, loss = 6.44804e-05
I0403 04:14:53.896157 16973 solver.cpp:244]     Train net output #0: loss = 6.44997e-05 (* 1 = 6.44997e-05 loss)
I0403 04:14:54.071702 16973 sgd_solver.cpp:106] Iteration 6896, lr = 5e-05
I0403 04:15:05.805047 16973 solver.cpp:228] Iteration 6912, loss = 0.00208422
I0403 04:15:05.805161 16973 solver.cpp:244]     Train net output #0: loss = 0.00208424 (* 1 = 0.00208424 loss)
I0403 04:15:05.989913 16973 sgd_solver.cpp:106] Iteration 6912, lr = 5e-05
I0403 04:15:17.625649 16973 solver.cpp:228] Iteration 6928, loss = 3.68976e-05
I0403 04:15:17.626005 16973 solver.cpp:244]     Train net output #0: loss = 3.6917e-05 (* 1 = 3.6917e-05 loss)
I0403 04:15:17.779446 16973 sgd_solver.cpp:106] Iteration 6928, lr = 5e-05
I0403 04:15:29.647680 16973 solver.cpp:228] Iteration 6944, loss = 1.76735e-05
I0403 04:15:29.647802 16973 solver.cpp:244]     Train net output #0: loss = 1.76934e-05 (* 1 = 1.76934e-05 loss)
I0403 04:15:29.783437 16973 sgd_solver.cpp:106] Iteration 6944, lr = 5e-05
I0403 04:15:41.382997 16973 solver.cpp:228] Iteration 6960, loss = 7.78866e-05
I0403 04:15:41.383111 16973 solver.cpp:244]     Train net output #0: loss = 7.79059e-05 (* 1 = 7.79059e-05 loss)
I0403 04:15:41.591806 16973 sgd_solver.cpp:106] Iteration 6960, lr = 5e-05
I0403 04:15:53.062690 16973 solver.cpp:228] Iteration 6976, loss = 0.000225134
I0403 04:15:53.062990 16973 solver.cpp:244]     Train net output #0: loss = 0.000225154 (* 1 = 0.000225154 loss)
I0403 04:15:53.224573 16973 sgd_solver.cpp:106] Iteration 6976, lr = 5e-05
I0403 04:16:04.848702 16973 solver.cpp:228] Iteration 6992, loss = 8.79386e-05
I0403 04:16:04.848809 16973 solver.cpp:244]     Train net output #0: loss = 8.79579e-05 (* 1 = 8.79579e-05 loss)
I0403 04:16:05.046140 16973 sgd_solver.cpp:106] Iteration 6992, lr = 5e-05
I0403 04:16:16.628898 16973 solver.cpp:228] Iteration 7008, loss = 0.0010532
I0403 04:16:16.629001 16973 solver.cpp:244]     Train net output #0: loss = 0.00105322 (* 1 = 0.00105322 loss)
I0403 04:16:16.797134 16973 sgd_solver.cpp:106] Iteration 7008, lr = 5e-05
I0403 04:16:28.391912 16973 solver.cpp:228] Iteration 7024, loss = 0.00107952
I0403 04:16:28.392252 16973 solver.cpp:244]     Train net output #0: loss = 0.00107954 (* 1 = 0.00107954 loss)
I0403 04:16:28.610337 16973 sgd_solver.cpp:106] Iteration 7024, lr = 5e-05
I0403 04:16:40.113010 16973 solver.cpp:228] Iteration 7040, loss = 0.00206144
I0403 04:16:40.113121 16973 solver.cpp:244]     Train net output #0: loss = 0.00206146 (* 1 = 0.00206146 loss)
I0403 04:16:40.319846 16973 sgd_solver.cpp:106] Iteration 7040, lr = 5e-05
I0403 04:16:51.886059 16973 solver.cpp:228] Iteration 7056, loss = 0.000810108
I0403 04:16:51.886171 16973 solver.cpp:244]     Train net output #0: loss = 0.000810127 (* 1 = 0.000810127 loss)
I0403 04:16:52.069974 16973 sgd_solver.cpp:106] Iteration 7056, lr = 5e-05
I0403 04:17:03.935220 16973 solver.cpp:228] Iteration 7072, loss = 7.18551e-05
I0403 04:17:03.935534 16973 solver.cpp:244]     Train net output #0: loss = 7.18738e-05 (* 1 = 7.18738e-05 loss)
I0403 04:17:04.131749 16973 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 04:17:15.582674 16973 solver.cpp:228] Iteration 7088, loss = 0.00332415
I0403 04:17:15.582788 16973 solver.cpp:244]     Train net output #0: loss = 0.00332417 (* 1 = 0.00332417 loss)
I0403 04:17:15.799957 16973 sgd_solver.cpp:106] Iteration 7088, lr = 5e-05
I0403 04:17:27.372452 16973 solver.cpp:228] Iteration 7104, loss = 0.000628456
I0403 04:17:27.372570 16973 solver.cpp:244]     Train net output #0: loss = 0.000628475 (* 1 = 0.000628475 loss)
I0403 04:17:27.572803 16973 sgd_solver.cpp:106] Iteration 7104, lr = 5e-05
I0403 04:17:39.081351 16973 solver.cpp:228] Iteration 7120, loss = 0.00316253
I0403 04:17:39.081679 16973 solver.cpp:244]     Train net output #0: loss = 0.00316255 (* 1 = 0.00316255 loss)
I0403 04:17:39.258930 16973 sgd_solver.cpp:106] Iteration 7120, lr = 5e-05
I0403 04:17:50.948984 16973 solver.cpp:228] Iteration 7136, loss = 0.000137364
I0403 04:17:50.949098 16973 solver.cpp:244]     Train net output #0: loss = 0.000137383 (* 1 = 0.000137383 loss)
I0403 04:17:51.138985 16973 sgd_solver.cpp:106] Iteration 7136, lr = 5e-05
I0403 04:18:00.642666 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_7150.caffemodel
I0403 04:18:03.298424 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_7150.solverstate
I0403 04:18:05.093416 16973 solver.cpp:337] Iteration 7150, Testing net (#0)
I0403 04:18:54.279625 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985623
I0403 04:18:54.283879 16973 solver.cpp:404]     Test net output #1: loss = 0.0554906 (* 1 = 0.0554906 loss)
I0403 04:18:56.248579 16973 solver.cpp:228] Iteration 7152, loss = 0.00017537
I0403 04:18:56.248687 16973 solver.cpp:244]     Train net output #0: loss = 0.000175388 (* 1 = 0.000175388 loss)
I0403 04:18:56.442868 16973 sgd_solver.cpp:106] Iteration 7152, lr = 5e-05
I0403 04:19:07.959069 16973 solver.cpp:228] Iteration 7168, loss = 0.000637627
I0403 04:19:07.959169 16973 solver.cpp:244]     Train net output #0: loss = 0.000637645 (* 1 = 0.000637645 loss)
I0403 04:19:08.131629 16973 sgd_solver.cpp:106] Iteration 7168, lr = 5e-05
I0403 04:19:20.166983 16973 solver.cpp:228] Iteration 7184, loss = 0.00149305
I0403 04:19:20.167089 16973 solver.cpp:244]     Train net output #0: loss = 0.00149306 (* 1 = 0.00149306 loss)
I0403 04:19:20.344090 16973 sgd_solver.cpp:106] Iteration 7184, lr = 5e-05
I0403 04:19:32.173758 16973 solver.cpp:228] Iteration 7200, loss = 0.00231305
I0403 04:19:32.174096 16973 solver.cpp:244]     Train net output #0: loss = 0.00231307 (* 1 = 0.00231307 loss)
I0403 04:19:32.376338 16973 sgd_solver.cpp:106] Iteration 7200, lr = 5e-05
I0403 04:19:43.900883 16973 solver.cpp:228] Iteration 7216, loss = 4.23069e-05
I0403 04:19:43.901000 16973 solver.cpp:244]     Train net output #0: loss = 4.23296e-05 (* 1 = 4.23296e-05 loss)
I0403 04:19:44.100342 16973 sgd_solver.cpp:106] Iteration 7216, lr = 5e-05
I0403 04:19:55.645819 16973 solver.cpp:228] Iteration 7232, loss = 3.95998e-05
I0403 04:19:55.645941 16973 solver.cpp:244]     Train net output #0: loss = 3.96221e-05 (* 1 = 3.96221e-05 loss)
I0403 04:19:55.890666 16973 sgd_solver.cpp:106] Iteration 7232, lr = 5e-05
I0403 04:20:07.415571 16973 solver.cpp:228] Iteration 7248, loss = 0.00152967
I0403 04:20:07.415889 16973 solver.cpp:244]     Train net output #0: loss = 0.00152969 (* 1 = 0.00152969 loss)
I0403 04:20:07.621618 16973 sgd_solver.cpp:106] Iteration 7248, lr = 5e-05
I0403 04:20:19.010242 16973 solver.cpp:228] Iteration 7264, loss = 0.000423749
I0403 04:20:19.010367 16973 solver.cpp:244]     Train net output #0: loss = 0.000423771 (* 1 = 0.000423771 loss)
I0403 04:20:19.217782 16973 sgd_solver.cpp:106] Iteration 7264, lr = 5e-05
I0403 04:20:30.966274 16973 solver.cpp:228] Iteration 7280, loss = 0.00142788
I0403 04:20:30.966387 16973 solver.cpp:244]     Train net output #0: loss = 0.0014279 (* 1 = 0.0014279 loss)
I0403 04:20:31.154362 16973 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 04:20:42.569447 16973 solver.cpp:228] Iteration 7296, loss = 0.00702608
I0403 04:20:42.569717 16973 solver.cpp:244]     Train net output #0: loss = 0.0070261 (* 1 = 0.0070261 loss)
I0403 04:20:42.726008 16973 sgd_solver.cpp:106] Iteration 7296, lr = 5e-05
I0403 04:20:54.462764 16973 solver.cpp:228] Iteration 7312, loss = 0.00401391
I0403 04:20:54.462889 16973 solver.cpp:244]     Train net output #0: loss = 0.00401393 (* 1 = 0.00401393 loss)
I0403 04:20:54.663280 16973 sgd_solver.cpp:106] Iteration 7312, lr = 5e-05
I0403 04:21:06.171859 16973 solver.cpp:228] Iteration 7328, loss = 9.40597e-05
I0403 04:21:06.171958 16973 solver.cpp:244]     Train net output #0: loss = 9.40834e-05 (* 1 = 9.40834e-05 loss)
I0403 04:21:06.335245 16973 sgd_solver.cpp:106] Iteration 7328, lr = 5e-05
I0403 04:21:17.812809 16973 solver.cpp:228] Iteration 7344, loss = 0.00274574
I0403 04:21:17.813146 16973 solver.cpp:244]     Train net output #0: loss = 0.00274577 (* 1 = 0.00274577 loss)
I0403 04:21:18.048169 16973 sgd_solver.cpp:106] Iteration 7344, lr = 5e-05
I0403 04:21:29.562748 16973 solver.cpp:228] Iteration 7360, loss = 0.000602212
I0403 04:21:29.562856 16973 solver.cpp:244]     Train net output #0: loss = 0.000602235 (* 1 = 0.000602235 loss)
I0403 04:21:29.749711 16973 sgd_solver.cpp:106] Iteration 7360, lr = 5e-05
I0403 04:21:41.349442 16973 solver.cpp:228] Iteration 7376, loss = 0.000401757
I0403 04:21:41.349555 16973 solver.cpp:244]     Train net output #0: loss = 0.000401781 (* 1 = 0.000401781 loss)
I0403 04:21:41.537084 16973 sgd_solver.cpp:106] Iteration 7376, lr = 5e-05
I0403 04:21:53.075130 16973 solver.cpp:228] Iteration 7392, loss = 0.00135782
I0403 04:21:53.075497 16973 solver.cpp:244]     Train net output #0: loss = 0.00135784 (* 1 = 0.00135784 loss)
I0403 04:21:53.301596 16973 sgd_solver.cpp:106] Iteration 7392, lr = 5e-05
I0403 04:22:04.984946 16973 solver.cpp:228] Iteration 7408, loss = 0.000424394
I0403 04:22:04.985044 16973 solver.cpp:244]     Train net output #0: loss = 0.000424417 (* 1 = 0.000424417 loss)
I0403 04:22:05.152685 16973 sgd_solver.cpp:106] Iteration 7408, lr = 5e-05
I0403 04:22:16.666563 16973 solver.cpp:228] Iteration 7424, loss = 0.00285725
I0403 04:22:16.666681 16973 solver.cpp:244]     Train net output #0: loss = 0.00285727 (* 1 = 0.00285727 loss)
I0403 04:22:16.856578 16973 sgd_solver.cpp:106] Iteration 7424, lr = 5e-05
I0403 04:22:28.514376 16973 solver.cpp:228] Iteration 7440, loss = 0.000924998
I0403 04:22:28.514706 16973 solver.cpp:244]     Train net output #0: loss = 0.000925021 (* 1 = 0.000925021 loss)
I0403 04:22:28.689867 16973 sgd_solver.cpp:106] Iteration 7440, lr = 5e-05
I0403 04:22:40.287251 16973 solver.cpp:228] Iteration 7456, loss = 0.00023281
I0403 04:22:40.287353 16973 solver.cpp:244]     Train net output #0: loss = 0.000232834 (* 1 = 0.000232834 loss)
I0403 04:22:40.469393 16973 sgd_solver.cpp:106] Iteration 7456, lr = 5e-05
I0403 04:22:52.032980 16973 solver.cpp:228] Iteration 7472, loss = 0.00106434
I0403 04:22:52.033094 16973 solver.cpp:244]     Train net output #0: loss = 0.00106437 (* 1 = 0.00106437 loss)
I0403 04:22:52.223172 16973 sgd_solver.cpp:106] Iteration 7472, lr = 5e-05
I0403 04:22:53.678755 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_7475.caffemodel
I0403 04:22:56.332594 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_7475.solverstate
I0403 04:22:58.101866 16973 solver.cpp:337] Iteration 7475, Testing net (#0)
I0403 04:23:47.292738 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985807
I0403 04:23:47.293051 16973 solver.cpp:404]     Test net output #1: loss = 0.0550703 (* 1 = 0.0550703 loss)
I0403 04:23:57.273160 16973 solver.cpp:228] Iteration 7488, loss = 0.01196
I0403 04:23:57.273272 16973 solver.cpp:244]     Train net output #0: loss = 0.0119601 (* 1 = 0.0119601 loss)
I0403 04:23:57.465822 16973 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 04:24:08.903529 16973 solver.cpp:228] Iteration 7504, loss = 0.000459004
I0403 04:24:08.903645 16973 solver.cpp:244]     Train net output #0: loss = 0.000459027 (* 1 = 0.000459027 loss)
I0403 04:24:09.093588 16973 sgd_solver.cpp:106] Iteration 7504, lr = 5e-05
I0403 04:24:20.636695 16973 solver.cpp:228] Iteration 7520, loss = 4.68767e-05
I0403 04:24:20.637020 16973 solver.cpp:244]     Train net output #0: loss = 4.68999e-05 (* 1 = 4.68999e-05 loss)
I0403 04:24:20.813184 16973 sgd_solver.cpp:106] Iteration 7520, lr = 5e-05
I0403 04:24:32.411406 16973 solver.cpp:228] Iteration 7536, loss = 0.00244316
I0403 04:24:32.411509 16973 solver.cpp:244]     Train net output #0: loss = 0.00244319 (* 1 = 0.00244319 loss)
I0403 04:24:32.583204 16973 sgd_solver.cpp:106] Iteration 7536, lr = 5e-05
I0403 04:24:44.112828 16973 solver.cpp:228] Iteration 7552, loss = 0.000252809
I0403 04:24:44.112962 16973 solver.cpp:244]     Train net output #0: loss = 0.000252833 (* 1 = 0.000252833 loss)
I0403 04:24:44.325693 16973 sgd_solver.cpp:106] Iteration 7552, lr = 5e-05
I0403 04:24:55.845767 16973 solver.cpp:228] Iteration 7568, loss = 0.00178791
I0403 04:24:55.846123 16973 solver.cpp:244]     Train net output #0: loss = 0.00178793 (* 1 = 0.00178793 loss)
I0403 04:24:56.070533 16973 sgd_solver.cpp:106] Iteration 7568, lr = 5e-05
I0403 04:25:07.569717 16973 solver.cpp:228] Iteration 7584, loss = 0.00015337
I0403 04:25:07.569821 16973 solver.cpp:244]     Train net output #0: loss = 0.000153395 (* 1 = 0.000153395 loss)
I0403 04:25:07.745605 16973 sgd_solver.cpp:106] Iteration 7584, lr = 5e-05
I0403 04:25:19.161414 16973 solver.cpp:228] Iteration 7600, loss = 0.00104543
I0403 04:25:19.161531 16973 solver.cpp:244]     Train net output #0: loss = 0.00104545 (* 1 = 0.00104545 loss)
I0403 04:25:19.430935 16973 sgd_solver.cpp:106] Iteration 7600, lr = 5e-05
I0403 04:25:30.969343 16973 solver.cpp:228] Iteration 7616, loss = 0.00113318
I0403 04:25:30.969681 16973 solver.cpp:244]     Train net output #0: loss = 0.00113321 (* 1 = 0.00113321 loss)
I0403 04:25:31.240193 16973 sgd_solver.cpp:106] Iteration 7616, lr = 5e-05
I0403 04:25:42.872694 16973 solver.cpp:228] Iteration 7632, loss = 2.24619e-05
I0403 04:25:42.872809 16973 solver.cpp:244]     Train net output #0: loss = 2.24865e-05 (* 1 = 2.24865e-05 loss)
I0403 04:25:43.073086 16973 sgd_solver.cpp:106] Iteration 7632, lr = 5e-05
I0403 04:25:54.625506 16973 solver.cpp:228] Iteration 7648, loss = 0.00591073
I0403 04:25:54.625620 16973 solver.cpp:244]     Train net output #0: loss = 0.00591075 (* 1 = 0.00591075 loss)
I0403 04:25:54.812871 16973 sgd_solver.cpp:106] Iteration 7648, lr = 5e-05
I0403 04:26:06.293000 16973 solver.cpp:228] Iteration 7664, loss = 0.020603
I0403 04:26:06.293318 16973 solver.cpp:244]     Train net output #0: loss = 0.020603 (* 1 = 0.020603 loss)
I0403 04:26:06.488262 16973 sgd_solver.cpp:106] Iteration 7664, lr = 5e-05
I0403 04:26:18.110157 16973 solver.cpp:228] Iteration 7680, loss = 6.74743e-05
I0403 04:26:18.110275 16973 solver.cpp:244]     Train net output #0: loss = 6.74977e-05 (* 1 = 6.74977e-05 loss)
I0403 04:26:18.329517 16973 sgd_solver.cpp:106] Iteration 7680, lr = 5e-05
I0403 04:26:30.025559 16973 solver.cpp:228] Iteration 7696, loss = 0.0009361
I0403 04:26:30.025668 16973 solver.cpp:244]     Train net output #0: loss = 0.000936124 (* 1 = 0.000936124 loss)
I0403 04:26:30.213002 16973 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 04:26:41.791363 16973 solver.cpp:228] Iteration 7712, loss = 0.0010203
I0403 04:26:41.791712 16973 solver.cpp:244]     Train net output #0: loss = 0.00102033 (* 1 = 0.00102033 loss)
I0403 04:26:41.976778 16973 sgd_solver.cpp:106] Iteration 7712, lr = 5e-05
I0403 04:26:53.636085 16973 solver.cpp:228] Iteration 7728, loss = 0.00382546
I0403 04:26:53.636189 16973 solver.cpp:244]     Train net output #0: loss = 0.00382548 (* 1 = 0.00382548 loss)
I0403 04:26:53.816261 16973 sgd_solver.cpp:106] Iteration 7728, lr = 5e-05
I0403 04:27:05.356984 16973 solver.cpp:228] Iteration 7744, loss = 0.00287534
I0403 04:27:05.357100 16973 solver.cpp:244]     Train net output #0: loss = 0.00287536 (* 1 = 0.00287536 loss)
I0403 04:27:05.552937 16973 sgd_solver.cpp:106] Iteration 7744, lr = 5e-05
I0403 04:27:17.181138 16973 solver.cpp:228] Iteration 7760, loss = 0.000719251
I0403 04:27:17.181476 16973 solver.cpp:244]     Train net output #0: loss = 0.000719274 (* 1 = 0.000719274 loss)
I0403 04:27:17.368682 16973 sgd_solver.cpp:106] Iteration 7760, lr = 5e-05
I0403 04:27:29.009251 16973 solver.cpp:228] Iteration 7776, loss = 6.12123e-05
I0403 04:27:29.015468 16973 solver.cpp:244]     Train net output #0: loss = 6.12341e-05 (* 1 = 6.12341e-05 loss)
I0403 04:27:29.199419 16973 sgd_solver.cpp:106] Iteration 7776, lr = 5e-05
I0403 04:27:40.686420 16973 solver.cpp:228] Iteration 7792, loss = 0.000383089
I0403 04:27:40.686524 16973 solver.cpp:244]     Train net output #0: loss = 0.000383111 (* 1 = 0.000383111 loss)
I0403 04:27:40.838271 16973 sgd_solver.cpp:106] Iteration 7792, lr = 5e-05
I0403 04:27:46.002777 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_7800.caffemodel
I0403 04:27:48.775667 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_7800.solverstate
I0403 04:27:50.674480 16973 solver.cpp:337] Iteration 7800, Testing net (#0)
I0403 04:28:39.876628 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985854
I0403 04:28:39.876973 16973 solver.cpp:404]     Test net output #1: loss = 0.0550737 (* 1 = 0.0550737 loss)
I0403 04:28:46.182808 16973 solver.cpp:228] Iteration 7808, loss = 0.0019573
I0403 04:28:46.182924 16973 solver.cpp:244]     Train net output #0: loss = 0.00195732 (* 1 = 0.00195732 loss)
I0403 04:28:46.410223 16973 sgd_solver.cpp:106] Iteration 7808, lr = 5e-05
I0403 04:28:57.924470 16973 solver.cpp:228] Iteration 7824, loss = 0.00129185
I0403 04:28:57.924592 16973 solver.cpp:244]     Train net output #0: loss = 0.00129187 (* 1 = 0.00129187 loss)
I0403 04:28:58.163034 16973 sgd_solver.cpp:106] Iteration 7824, lr = 5e-05
I0403 04:29:09.695065 16973 solver.cpp:228] Iteration 7840, loss = 0.00330059
I0403 04:29:09.695179 16973 solver.cpp:244]     Train net output #0: loss = 0.00330061 (* 1 = 0.00330061 loss)
I0403 04:29:09.883592 16973 sgd_solver.cpp:106] Iteration 7840, lr = 5e-05
I0403 04:29:21.441962 16973 solver.cpp:228] Iteration 7856, loss = 0.00380187
I0403 04:29:21.442077 16973 solver.cpp:244]     Train net output #0: loss = 0.0038019 (* 1 = 0.0038019 loss)
I0403 04:29:21.638095 16973 sgd_solver.cpp:106] Iteration 7856, lr = 5e-05
I0403 04:29:33.282510 16973 solver.cpp:228] Iteration 7872, loss = 3.83838e-05
I0403 04:29:33.282625 16973 solver.cpp:244]     Train net output #0: loss = 3.84072e-05 (* 1 = 3.84072e-05 loss)
I0403 04:29:33.559821 16973 sgd_solver.cpp:106] Iteration 7872, lr = 5e-05
I0403 04:29:44.953974 16973 solver.cpp:228] Iteration 7888, loss = 0.000784636
I0403 04:29:44.954304 16973 solver.cpp:244]     Train net output #0: loss = 0.00078466 (* 1 = 0.00078466 loss)
I0403 04:29:45.154680 16973 sgd_solver.cpp:106] Iteration 7888, lr = 5e-05
I0403 04:29:56.675823 16973 solver.cpp:228] Iteration 7904, loss = 2.88851e-05
I0403 04:29:56.675926 16973 solver.cpp:244]     Train net output #0: loss = 2.89085e-05 (* 1 = 2.89085e-05 loss)
I0403 04:29:56.828289 16973 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 04:30:08.651085 16973 solver.cpp:228] Iteration 7920, loss = 0.00661534
I0403 04:30:08.651206 16973 solver.cpp:244]     Train net output #0: loss = 0.00661536 (* 1 = 0.00661536 loss)
I0403 04:30:08.857492 16973 sgd_solver.cpp:106] Iteration 7920, lr = 5e-05
I0403 04:30:20.548559 16973 solver.cpp:228] Iteration 7936, loss = 0.0014222
I0403 04:30:20.548900 16973 solver.cpp:244]     Train net output #0: loss = 0.00142223 (* 1 = 0.00142223 loss)
I0403 04:30:20.787299 16973 sgd_solver.cpp:106] Iteration 7936, lr = 5e-05
I0403 04:30:32.243769 16973 solver.cpp:228] Iteration 7952, loss = 6.3451e-05
I0403 04:30:32.243883 16973 solver.cpp:244]     Train net output #0: loss = 6.34759e-05 (* 1 = 6.34759e-05 loss)
I0403 04:30:32.432279 16973 sgd_solver.cpp:106] Iteration 7952, lr = 5e-05
I0403 04:30:44.198390 16973 solver.cpp:228] Iteration 7968, loss = 0.000460645
I0403 04:30:44.198493 16973 solver.cpp:244]     Train net output #0: loss = 0.00046067 (* 1 = 0.00046067 loss)
I0403 04:30:44.346635 16973 sgd_solver.cpp:106] Iteration 7968, lr = 5e-05
I0403 04:30:56.102812 16973 solver.cpp:228] Iteration 7984, loss = 3.21376e-05
I0403 04:30:56.103096 16973 solver.cpp:244]     Train net output #0: loss = 3.21629e-05 (* 1 = 3.21629e-05 loss)
I0403 04:30:56.292820 16973 sgd_solver.cpp:106] Iteration 7984, lr = 5e-05
I0403 04:31:07.835731 16973 solver.cpp:228] Iteration 8000, loss = 0.00164541
I0403 04:31:07.835847 16973 solver.cpp:244]     Train net output #0: loss = 0.00164543 (* 1 = 0.00164543 loss)
I0403 04:31:08.025538 16973 sgd_solver.cpp:106] Iteration 8000, lr = 5e-05
I0403 04:31:19.543366 16973 solver.cpp:228] Iteration 8016, loss = 0.000540329
I0403 04:31:19.543479 16973 solver.cpp:244]     Train net output #0: loss = 0.000540354 (* 1 = 0.000540354 loss)
I0403 04:31:19.727901 16973 sgd_solver.cpp:106] Iteration 8016, lr = 5e-05
I0403 04:31:31.301647 16973 solver.cpp:228] Iteration 8032, loss = 0.0024715
I0403 04:31:31.302037 16973 solver.cpp:244]     Train net output #0: loss = 0.00247152 (* 1 = 0.00247152 loss)
I0403 04:31:31.495646 16973 sgd_solver.cpp:106] Iteration 8032, lr = 5e-05
I0403 04:31:43.020709 16973 solver.cpp:228] Iteration 8048, loss = 0.0022068
I0403 04:31:43.020812 16973 solver.cpp:244]     Train net output #0: loss = 0.00220683 (* 1 = 0.00220683 loss)
I0403 04:31:43.179289 16973 sgd_solver.cpp:106] Iteration 8048, lr = 5e-05
I0403 04:31:54.919306 16973 solver.cpp:228] Iteration 8064, loss = 0.0020166
I0403 04:31:54.919421 16973 solver.cpp:244]     Train net output #0: loss = 0.00201662 (* 1 = 0.00201662 loss)
I0403 04:31:55.123924 16973 sgd_solver.cpp:106] Iteration 8064, lr = 5e-05
I0403 04:32:06.694130 16973 solver.cpp:228] Iteration 8080, loss = 0.000580247
I0403 04:32:06.694479 16973 solver.cpp:244]     Train net output #0: loss = 0.000580271 (* 1 = 0.000580271 loss)
I0403 04:32:06.896371 16973 sgd_solver.cpp:106] Iteration 8080, lr = 5e-05
I0403 04:32:18.641672 16973 solver.cpp:228] Iteration 8096, loss = 0.00275974
I0403 04:32:18.641789 16973 solver.cpp:244]     Train net output #0: loss = 0.00275977 (* 1 = 0.00275977 loss)
I0403 04:32:18.833760 16973 sgd_solver.cpp:106] Iteration 8096, lr = 5e-05
I0403 04:32:30.435701 16973 solver.cpp:228] Iteration 8112, loss = 0.00465515
I0403 04:32:30.435817 16973 solver.cpp:244]     Train net output #0: loss = 0.00465518 (* 1 = 0.00465518 loss)
I0403 04:32:30.655856 16973 sgd_solver.cpp:106] Iteration 8112, lr = 5e-05
I0403 04:32:39.445219 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_8125.caffemodel
I0403 04:32:42.198060 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_8125.solverstate
I0403 04:32:44.113090 16973 solver.cpp:337] Iteration 8125, Testing net (#0)
I0403 04:33:33.313482 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985761
I0403 04:33:33.313822 16973 solver.cpp:404]     Test net output #1: loss = 0.0552663 (* 1 = 0.0552663 loss)
I0403 04:33:36.014355 16973 solver.cpp:228] Iteration 8128, loss = 0.00106709
I0403 04:33:36.014464 16973 solver.cpp:244]     Train net output #0: loss = 0.00106711 (* 1 = 0.00106711 loss)
I0403 04:33:36.228338 16973 sgd_solver.cpp:106] Iteration 8128, lr = 5e-05
I0403 04:33:47.762017 16973 solver.cpp:228] Iteration 8144, loss = 0.0004108
I0403 04:33:47.762121 16973 solver.cpp:244]     Train net output #0: loss = 0.000410825 (* 1 = 0.000410825 loss)
I0403 04:33:47.944171 16973 sgd_solver.cpp:106] Iteration 8144, lr = 5e-05
I0403 04:33:59.504638 16973 solver.cpp:228] Iteration 8160, loss = 8.21614e-05
I0403 04:33:59.504742 16973 solver.cpp:244]     Train net output #0: loss = 8.21862e-05 (* 1 = 8.21862e-05 loss)
I0403 04:33:59.679003 16973 sgd_solver.cpp:106] Iteration 8160, lr = 5e-05
I0403 04:34:11.454526 16973 solver.cpp:228] Iteration 8176, loss = 0.0019376
I0403 04:34:11.454852 16973 solver.cpp:244]     Train net output #0: loss = 0.00193763 (* 1 = 0.00193763 loss)
I0403 04:34:11.683773 16973 sgd_solver.cpp:106] Iteration 8176, lr = 5e-05
I0403 04:34:23.346788 16973 solver.cpp:228] Iteration 8192, loss = 0.000689688
I0403 04:34:23.346904 16973 solver.cpp:244]     Train net output #0: loss = 0.000689712 (* 1 = 0.000689712 loss)
I0403 04:34:23.543381 16973 sgd_solver.cpp:106] Iteration 8192, lr = 5e-05
I0403 04:34:34.946274 16973 solver.cpp:228] Iteration 8208, loss = 0.000404117
I0403 04:34:34.946389 16973 solver.cpp:244]     Train net output #0: loss = 0.000404141 (* 1 = 0.000404141 loss)
I0403 04:34:35.142813 16973 sgd_solver.cpp:106] Iteration 8208, lr = 5e-05
I0403 04:34:46.663871 16973 solver.cpp:228] Iteration 8224, loss = 0.000423338
I0403 04:34:46.664199 16973 solver.cpp:244]     Train net output #0: loss = 0.000423362 (* 1 = 0.000423362 loss)
I0403 04:34:46.836910 16973 sgd_solver.cpp:106] Iteration 8224, lr = 5e-05
I0403 04:34:58.341583 16973 solver.cpp:228] Iteration 8240, loss = 0.000194271
I0403 04:34:58.341698 16973 solver.cpp:244]     Train net output #0: loss = 0.000194295 (* 1 = 0.000194295 loss)
I0403 04:34:58.539731 16973 sgd_solver.cpp:106] Iteration 8240, lr = 5e-05
I0403 04:35:10.102179 16973 solver.cpp:228] Iteration 8256, loss = 0.00181403
I0403 04:35:10.102290 16973 solver.cpp:244]     Train net output #0: loss = 0.00181405 (* 1 = 0.00181405 loss)
I0403 04:35:10.294996 16973 sgd_solver.cpp:106] Iteration 8256, lr = 5e-05
I0403 04:35:22.032896 16973 solver.cpp:228] Iteration 8272, loss = 0.000958994
I0403 04:35:22.033243 16973 solver.cpp:244]     Train net output #0: loss = 0.000959018 (* 1 = 0.000959018 loss)
I0403 04:35:22.225405 16973 sgd_solver.cpp:106] Iteration 8272, lr = 5e-05
I0403 04:35:33.765055 16973 solver.cpp:228] Iteration 8288, loss = 6.4217e-05
I0403 04:35:33.765169 16973 solver.cpp:244]     Train net output #0: loss = 6.42412e-05 (* 1 = 6.42412e-05 loss)
I0403 04:35:33.989166 16973 sgd_solver.cpp:106] Iteration 8288, lr = 5e-05
I0403 04:35:45.468075 16973 solver.cpp:228] Iteration 8304, loss = 0.0003904
I0403 04:35:45.468183 16973 solver.cpp:244]     Train net output #0: loss = 0.000390424 (* 1 = 0.000390424 loss)
I0403 04:35:45.655658 16973 sgd_solver.cpp:106] Iteration 8304, lr = 5e-05
I0403 04:35:57.279542 16973 solver.cpp:228] Iteration 8320, loss = 0.000701806
I0403 04:35:57.279857 16973 solver.cpp:244]     Train net output #0: loss = 0.000701831 (* 1 = 0.000701831 loss)
I0403 04:35:57.465920 16973 sgd_solver.cpp:106] Iteration 8320, lr = 5e-05
I0403 04:36:09.010716 16973 solver.cpp:228] Iteration 8336, loss = 0.0170637
I0403 04:36:09.010819 16973 solver.cpp:244]     Train net output #0: loss = 0.0170637 (* 1 = 0.0170637 loss)
I0403 04:36:09.162334 16973 sgd_solver.cpp:106] Iteration 8336, lr = 5e-05
I0403 04:36:20.774325 16973 solver.cpp:228] Iteration 8352, loss = 0.000889027
I0403 04:36:20.774440 16973 solver.cpp:244]     Train net output #0: loss = 0.000889056 (* 1 = 0.000889056 loss)
I0403 04:36:20.982597 16973 sgd_solver.cpp:106] Iteration 8352, lr = 5e-05
I0403 04:36:32.551542 16973 solver.cpp:228] Iteration 8368, loss = 0.000630332
I0403 04:36:32.551872 16973 solver.cpp:244]     Train net output #0: loss = 0.00063036 (* 1 = 0.00063036 loss)
I0403 04:36:32.736511 16973 sgd_solver.cpp:106] Iteration 8368, lr = 5e-05
I0403 04:36:44.224324 16973 solver.cpp:228] Iteration 8384, loss = 0.000126728
I0403 04:36:44.224436 16973 solver.cpp:244]     Train net output #0: loss = 0.000126755 (* 1 = 0.000126755 loss)
I0403 04:36:44.422332 16973 sgd_solver.cpp:106] Iteration 8384, lr = 5e-05
I0403 04:36:55.912475 16973 solver.cpp:228] Iteration 8400, loss = 0.000257179
I0403 04:36:55.912597 16973 solver.cpp:244]     Train net output #0: loss = 0.000257206 (* 1 = 0.000257206 loss)
I0403 04:36:56.106108 16973 sgd_solver.cpp:106] Iteration 8400, lr = 5e-05
I0403 04:37:07.659590 16973 solver.cpp:228] Iteration 8416, loss = 5.46017e-05
I0403 04:37:07.659936 16973 solver.cpp:244]     Train net output #0: loss = 5.46291e-05 (* 1 = 5.46291e-05 loss)
I0403 04:37:07.843154 16973 sgd_solver.cpp:106] Iteration 8416, lr = 5e-05
I0403 04:37:19.296032 16973 solver.cpp:228] Iteration 8432, loss = 0.000327502
I0403 04:37:19.296141 16973 solver.cpp:244]     Train net output #0: loss = 0.000327533 (* 1 = 0.000327533 loss)
I0403 04:37:19.503700 16973 sgd_solver.cpp:106] Iteration 8432, lr = 5e-05
I0403 04:37:31.029266 16973 solver.cpp:228] Iteration 8448, loss = 0.000425767
I0403 04:37:31.029381 16973 solver.cpp:244]     Train net output #0: loss = 0.000425798 (* 1 = 0.000425798 loss)
I0403 04:37:31.273188 16973 sgd_solver.cpp:106] Iteration 8448, lr = 5e-05
I0403 04:37:32.002385 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_8450.caffemodel
I0403 04:37:34.621973 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_8450.solverstate
I0403 04:37:36.476176 16973 solver.cpp:337] Iteration 8450, Testing net (#0)
I0403 04:38:25.670310 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985992
I0403 04:38:25.670685 16973 solver.cpp:404]     Test net output #1: loss = 0.05503 (* 1 = 0.05503 loss)
I0403 04:38:36.451943 16973 solver.cpp:228] Iteration 8464, loss = 2.03665e-05
I0403 04:38:36.452060 16973 solver.cpp:244]     Train net output #0: loss = 2.03976e-05 (* 1 = 2.03976e-05 loss)
I0403 04:38:36.646045 16973 sgd_solver.cpp:106] Iteration 8464, lr = 5e-05
I0403 04:38:48.160856 16973 solver.cpp:228] Iteration 8480, loss = 0.000137214
I0403 04:38:48.160970 16973 solver.cpp:244]     Train net output #0: loss = 0.000137245 (* 1 = 0.000137245 loss)
I0403 04:38:48.347867 16973 sgd_solver.cpp:106] Iteration 8480, lr = 5e-05
I0403 04:38:59.850208 16973 solver.cpp:228] Iteration 8496, loss = 3.095e-05
I0403 04:38:59.850539 16973 solver.cpp:244]     Train net output #0: loss = 3.09822e-05 (* 1 = 3.09822e-05 loss)
I0403 04:39:00.062599 16973 sgd_solver.cpp:106] Iteration 8496, lr = 5e-05
I0403 04:39:11.648476 16973 solver.cpp:228] Iteration 8512, loss = 0.00101817
I0403 04:39:11.648599 16973 solver.cpp:244]     Train net output #0: loss = 0.0010182 (* 1 = 0.0010182 loss)
I0403 04:39:11.832878 16973 sgd_solver.cpp:106] Iteration 8512, lr = 5e-05
I0403 04:39:23.326972 16973 solver.cpp:228] Iteration 8528, loss = 0.00128775
I0403 04:39:23.327085 16973 solver.cpp:244]     Train net output #0: loss = 0.00128779 (* 1 = 0.00128779 loss)
I0403 04:39:23.533273 16973 sgd_solver.cpp:106] Iteration 8528, lr = 5e-05
I0403 04:39:35.082064 16973 solver.cpp:228] Iteration 8544, loss = 0.000545044
I0403 04:39:35.082396 16973 solver.cpp:244]     Train net output #0: loss = 0.000545077 (* 1 = 0.000545077 loss)
I0403 04:39:35.265604 16973 sgd_solver.cpp:106] Iteration 8544, lr = 5e-05
I0403 04:39:46.760112 16973 solver.cpp:228] Iteration 8560, loss = 0.000993098
I0403 04:39:46.760228 16973 solver.cpp:244]     Train net output #0: loss = 0.000993131 (* 1 = 0.000993131 loss)
I0403 04:39:46.949002 16973 sgd_solver.cpp:106] Iteration 8560, lr = 5e-05
I0403 04:39:58.401491 16973 solver.cpp:228] Iteration 8576, loss = 0.000498943
I0403 04:39:58.401600 16973 solver.cpp:244]     Train net output #0: loss = 0.000498975 (* 1 = 0.000498975 loss)
I0403 04:39:58.548713 16973 sgd_solver.cpp:106] Iteration 8576, lr = 5e-05
I0403 04:40:10.215046 16973 solver.cpp:228] Iteration 8592, loss = 0.000738512
I0403 04:40:10.215386 16973 solver.cpp:244]     Train net output #0: loss = 0.000738545 (* 1 = 0.000738545 loss)
I0403 04:40:10.407912 16973 sgd_solver.cpp:106] Iteration 8592, lr = 5e-05
I0403 04:40:22.023681 16973 solver.cpp:228] Iteration 8608, loss = 0.0010698
I0403 04:40:22.023795 16973 solver.cpp:244]     Train net output #0: loss = 0.00106983 (* 1 = 0.00106983 loss)
I0403 04:40:22.219238 16973 sgd_solver.cpp:106] Iteration 8608, lr = 5e-05
I0403 04:40:33.908303 16973 solver.cpp:228] Iteration 8624, loss = 0.0131969
I0403 04:40:33.908416 16973 solver.cpp:244]     Train net output #0: loss = 0.013197 (* 1 = 0.013197 loss)
I0403 04:40:34.103317 16973 sgd_solver.cpp:106] Iteration 8624, lr = 5e-05
I0403 04:40:45.947206 16973 solver.cpp:228] Iteration 8640, loss = 0.000716459
I0403 04:40:45.947495 16973 solver.cpp:244]     Train net output #0: loss = 0.000716491 (* 1 = 0.000716491 loss)
I0403 04:40:46.103332 16973 sgd_solver.cpp:106] Iteration 8640, lr = 5e-05
I0403 04:40:57.593754 16973 solver.cpp:228] Iteration 8656, loss = 0.0492397
I0403 04:40:57.593868 16973 solver.cpp:244]     Train net output #0: loss = 0.0492397 (* 1 = 0.0492397 loss)
I0403 04:40:57.788936 16973 sgd_solver.cpp:106] Iteration 8656, lr = 5e-05
I0403 04:41:09.280472 16973 solver.cpp:228] Iteration 8672, loss = 0.000216093
I0403 04:41:09.280578 16973 solver.cpp:244]     Train net output #0: loss = 0.000216128 (* 1 = 0.000216128 loss)
I0403 04:41:09.462113 16973 sgd_solver.cpp:106] Iteration 8672, lr = 5e-05
I0403 04:41:20.985319 16973 solver.cpp:228] Iteration 8688, loss = 0.00300382
I0403 04:41:20.985677 16973 solver.cpp:244]     Train net output #0: loss = 0.00300385 (* 1 = 0.00300385 loss)
I0403 04:41:21.168742 16973 sgd_solver.cpp:106] Iteration 8688, lr = 5e-05
I0403 04:41:32.694298 16973 solver.cpp:228] Iteration 8704, loss = 0.000178223
I0403 04:41:32.694416 16973 solver.cpp:244]     Train net output #0: loss = 0.000178258 (* 1 = 0.000178258 loss)
I0403 04:41:32.891083 16973 sgd_solver.cpp:106] Iteration 8704, lr = 5e-05
I0403 04:41:44.389982 16973 solver.cpp:228] Iteration 8720, loss = 0.00331095
I0403 04:41:44.390087 16973 solver.cpp:244]     Train net output #0: loss = 0.00331099 (* 1 = 0.00331099 loss)
I0403 04:41:44.570109 16973 sgd_solver.cpp:106] Iteration 8720, lr = 5e-05
I0403 04:41:56.340929 16973 solver.cpp:228] Iteration 8736, loss = 0.000253678
I0403 04:41:56.341233 16973 solver.cpp:244]     Train net output #0: loss = 0.000253714 (* 1 = 0.000253714 loss)
I0403 04:41:56.520308 16973 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 04:42:08.115357 16973 solver.cpp:228] Iteration 8752, loss = 0.00376467
I0403 04:42:08.115460 16973 solver.cpp:244]     Train net output #0: loss = 0.00376471 (* 1 = 0.00376471 loss)
I0403 04:42:08.297655 16973 sgd_solver.cpp:106] Iteration 8752, lr = 5e-05
I0403 04:42:19.717321 16973 solver.cpp:228] Iteration 8768, loss = 0.00021334
I0403 04:42:19.717437 16973 solver.cpp:244]     Train net output #0: loss = 0.000213375 (* 1 = 0.000213375 loss)
I0403 04:42:19.905267 16973 sgd_solver.cpp:106] Iteration 8768, lr = 5e-05
I0403 04:42:24.350108 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_8775.caffemodel
I0403 04:42:27.063887 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_8775.solverstate
I0403 04:42:28.835429 16973 solver.cpp:337] Iteration 8775, Testing net (#0)
I0403 04:43:18.033452 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985853
I0403 04:43:18.033802 16973 solver.cpp:404]     Test net output #1: loss = 0.055387 (* 1 = 0.055387 loss)
I0403 04:43:25.319509 16973 solver.cpp:228] Iteration 8784, loss = 0.00132262
I0403 04:43:25.319624 16973 solver.cpp:244]     Train net output #0: loss = 0.00132265 (* 1 = 0.00132265 loss)
I0403 04:43:25.527570 16973 sgd_solver.cpp:106] Iteration 8784, lr = 5e-05
I0403 04:43:37.155684 16973 solver.cpp:228] Iteration 8800, loss = 0.000141316
I0403 04:43:37.155789 16973 solver.cpp:244]     Train net output #0: loss = 0.000141351 (* 1 = 0.000141351 loss)
I0403 04:43:37.321941 16973 sgd_solver.cpp:106] Iteration 8800, lr = 5e-05
I0403 04:43:48.923645 16973 solver.cpp:228] Iteration 8816, loss = 0.0188928
I0403 04:43:48.923979 16973 solver.cpp:244]     Train net output #0: loss = 0.0188928 (* 1 = 0.0188928 loss)
I0403 04:43:49.148300 16973 sgd_solver.cpp:106] Iteration 8816, lr = 5e-05
I0403 04:44:00.773290 16973 solver.cpp:228] Iteration 8832, loss = 0.00845159
I0403 04:44:00.773406 16973 solver.cpp:244]     Train net output #0: loss = 0.00845163 (* 1 = 0.00845163 loss)
I0403 04:44:00.968694 16973 sgd_solver.cpp:106] Iteration 8832, lr = 5e-05
I0403 04:44:12.714943 16973 solver.cpp:228] Iteration 8848, loss = 0.000106111
I0403 04:44:12.715059 16973 solver.cpp:244]     Train net output #0: loss = 0.000106144 (* 1 = 0.000106144 loss)
I0403 04:44:12.908051 16973 sgd_solver.cpp:106] Iteration 8848, lr = 5e-05
I0403 04:44:24.381208 16973 solver.cpp:228] Iteration 8864, loss = 0.000190316
I0403 04:44:24.381541 16973 solver.cpp:244]     Train net output #0: loss = 0.000190349 (* 1 = 0.000190349 loss)
I0403 04:44:24.618891 16973 sgd_solver.cpp:106] Iteration 8864, lr = 5e-05
I0403 04:44:36.156550 16973 solver.cpp:228] Iteration 8880, loss = 0.000227409
I0403 04:44:36.156649 16973 solver.cpp:244]     Train net output #0: loss = 0.000227442 (* 1 = 0.000227442 loss)
I0403 04:44:36.337998 16973 sgd_solver.cpp:106] Iteration 8880, lr = 5e-05
I0403 04:44:47.883249 16973 solver.cpp:228] Iteration 8896, loss = 0.000484786
I0403 04:44:47.883366 16973 solver.cpp:244]     Train net output #0: loss = 0.000484818 (* 1 = 0.000484818 loss)
I0403 04:44:48.091256 16973 sgd_solver.cpp:106] Iteration 8896, lr = 5e-05
I0403 04:44:59.621824 16973 solver.cpp:228] Iteration 8912, loss = 1.60236e-05
I0403 04:44:59.622205 16973 solver.cpp:244]     Train net output #0: loss = 1.60559e-05 (* 1 = 1.60559e-05 loss)
I0403 04:44:59.820755 16973 sgd_solver.cpp:106] Iteration 8912, lr = 5e-05
I0403 04:45:11.395956 16973 solver.cpp:228] Iteration 8928, loss = 2.39534e-05
I0403 04:45:11.396072 16973 solver.cpp:244]     Train net output #0: loss = 2.3987e-05 (* 1 = 2.3987e-05 loss)
I0403 04:45:11.612573 16973 sgd_solver.cpp:106] Iteration 8928, lr = 5e-05
I0403 04:45:23.114435 16973 solver.cpp:228] Iteration 8944, loss = 3.15773e-05
I0403 04:45:23.114559 16973 solver.cpp:244]     Train net output #0: loss = 3.16107e-05 (* 1 = 3.16107e-05 loss)
I0403 04:45:23.326225 16973 sgd_solver.cpp:106] Iteration 8944, lr = 5e-05
I0403 04:45:35.112462 16973 solver.cpp:228] Iteration 8960, loss = 0.000121615
I0403 04:45:35.112746 16973 solver.cpp:244]     Train net output #0: loss = 0.000121648 (* 1 = 0.000121648 loss)
I0403 04:45:35.298583 16973 sgd_solver.cpp:106] Iteration 8960, lr = 5e-05
I0403 04:45:46.745085 16973 solver.cpp:228] Iteration 8976, loss = 0.00102515
I0403 04:45:46.745200 16973 solver.cpp:244]     Train net output #0: loss = 0.00102519 (* 1 = 0.00102519 loss)
I0403 04:45:46.937562 16973 sgd_solver.cpp:106] Iteration 8976, lr = 5e-05
I0403 04:45:58.523213 16973 solver.cpp:228] Iteration 8992, loss = 0.00174389
I0403 04:45:58.523329 16973 solver.cpp:244]     Train net output #0: loss = 0.00174392 (* 1 = 0.00174392 loss)
I0403 04:45:58.734984 16973 sgd_solver.cpp:106] Iteration 8992, lr = 5e-05
I0403 04:46:10.202834 16973 solver.cpp:228] Iteration 9008, loss = 0.000566702
I0403 04:46:10.203146 16973 solver.cpp:244]     Train net output #0: loss = 0.000566735 (* 1 = 0.000566735 loss)
I0403 04:46:10.416659 16973 sgd_solver.cpp:106] Iteration 9008, lr = 5e-05
I0403 04:46:21.996042 16973 solver.cpp:228] Iteration 9024, loss = 0.00616144
I0403 04:46:21.996160 16973 solver.cpp:244]     Train net output #0: loss = 0.00616148 (* 1 = 0.00616148 loss)
I0403 04:46:22.186640 16973 sgd_solver.cpp:106] Iteration 9024, lr = 5e-05
I0403 04:46:33.691406 16973 solver.cpp:228] Iteration 9040, loss = 0.00574264
I0403 04:46:33.691526 16973 solver.cpp:244]     Train net output #0: loss = 0.00574267 (* 1 = 0.00574267 loss)
I0403 04:46:33.910737 16973 sgd_solver.cpp:106] Iteration 9040, lr = 5e-05
I0403 04:46:45.412186 16973 solver.cpp:228] Iteration 9056, loss = 0.00116952
I0403 04:46:45.412533 16973 solver.cpp:244]     Train net output #0: loss = 0.00116955 (* 1 = 0.00116955 loss)
I0403 04:46:45.599120 16973 sgd_solver.cpp:106] Iteration 9056, lr = 5e-05
I0403 04:46:57.214764 16973 solver.cpp:228] Iteration 9072, loss = 0.00826467
I0403 04:46:57.214866 16973 solver.cpp:244]     Train net output #0: loss = 0.0082647 (* 1 = 0.0082647 loss)
I0403 04:46:57.386065 16973 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 04:47:08.921486 16973 solver.cpp:228] Iteration 9088, loss = 0.00011298
I0403 04:47:08.921604 16973 solver.cpp:244]     Train net output #0: loss = 0.000113012 (* 1 = 0.000113012 loss)
I0403 04:47:09.117121 16973 sgd_solver.cpp:106] Iteration 9088, lr = 5e-05
I0403 04:47:17.205732 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9100.caffemodel
I0403 04:47:19.804519 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9100.solverstate
I0403 04:47:21.571390 16973 solver.cpp:337] Iteration 9100, Testing net (#0)
I0403 04:48:10.779621 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985807
I0403 04:48:10.779986 16973 solver.cpp:404]     Test net output #1: loss = 0.0557317 (* 1 = 0.0557317 loss)
I0403 04:48:14.349020 16973 solver.cpp:228] Iteration 9104, loss = 0.000437656
I0403 04:48:14.349130 16973 solver.cpp:244]     Train net output #0: loss = 0.000437688 (* 1 = 0.000437688 loss)
I0403 04:48:14.596609 16973 sgd_solver.cpp:106] Iteration 9104, lr = 5e-05
I0403 04:48:26.141867 16973 solver.cpp:228] Iteration 9120, loss = 0.00172508
I0403 04:48:26.141985 16973 solver.cpp:244]     Train net output #0: loss = 0.00172511 (* 1 = 0.00172511 loss)
I0403 04:48:26.377351 16973 sgd_solver.cpp:106] Iteration 9120, lr = 5e-05
I0403 04:48:37.874245 16973 solver.cpp:228] Iteration 9136, loss = 0.00884489
I0403 04:48:37.874380 16973 solver.cpp:244]     Train net output #0: loss = 0.00884493 (* 1 = 0.00884493 loss)
I0403 04:48:38.057102 16973 sgd_solver.cpp:106] Iteration 9136, lr = 5e-05
I0403 04:48:49.584031 16973 solver.cpp:228] Iteration 9152, loss = 0.000238629
I0403 04:48:49.584367 16973 solver.cpp:244]     Train net output #0: loss = 0.00023866 (* 1 = 0.00023866 loss)
I0403 04:48:49.769433 16973 sgd_solver.cpp:106] Iteration 9152, lr = 5e-05
I0403 04:49:01.124181 16973 solver.cpp:228] Iteration 9168, loss = 2.00685e-05
I0403 04:49:01.124284 16973 solver.cpp:244]     Train net output #0: loss = 2.01001e-05 (* 1 = 2.01001e-05 loss)
I0403 04:49:01.304277 16973 sgd_solver.cpp:106] Iteration 9168, lr = 5e-05
I0403 04:49:12.674814 16973 solver.cpp:228] Iteration 9184, loss = 0.000193801
I0403 04:49:12.674932 16973 solver.cpp:244]     Train net output #0: loss = 0.000193833 (* 1 = 0.000193833 loss)
I0403 04:49:12.859422 16973 sgd_solver.cpp:106] Iteration 9184, lr = 5e-05
I0403 04:49:24.307675 16973 solver.cpp:228] Iteration 9200, loss = 0.00393923
I0403 04:49:24.307994 16973 solver.cpp:244]     Train net output #0: loss = 0.00393926 (* 1 = 0.00393926 loss)
I0403 04:49:24.496556 16973 sgd_solver.cpp:106] Iteration 9200, lr = 5e-05
I0403 04:49:36.021051 16973 solver.cpp:228] Iteration 9216, loss = 0.00241709
I0403 04:49:36.021164 16973 solver.cpp:244]     Train net output #0: loss = 0.00241713 (* 1 = 0.00241713 loss)
I0403 04:49:36.216708 16973 sgd_solver.cpp:106] Iteration 9216, lr = 5e-05
I0403 04:49:47.703851 16973 solver.cpp:228] Iteration 9232, loss = 0.000138106
I0403 04:49:47.703968 16973 solver.cpp:244]     Train net output #0: loss = 0.000138137 (* 1 = 0.000138137 loss)
I0403 04:49:47.900038 16973 sgd_solver.cpp:106] Iteration 9232, lr = 5e-05
I0403 04:49:59.478703 16973 solver.cpp:228] Iteration 9248, loss = 0.000467456
I0403 04:49:59.479034 16973 solver.cpp:244]     Train net output #0: loss = 0.000467487 (* 1 = 0.000467487 loss)
I0403 04:49:59.660879 16973 sgd_solver.cpp:106] Iteration 9248, lr = 5e-05
I0403 04:50:11.102658 16973 solver.cpp:228] Iteration 9264, loss = 0.00143479
I0403 04:50:11.102774 16973 solver.cpp:244]     Train net output #0: loss = 0.00143482 (* 1 = 0.00143482 loss)
I0403 04:50:11.286082 16973 sgd_solver.cpp:106] Iteration 9264, lr = 5e-05
I0403 04:50:22.695977 16973 solver.cpp:228] Iteration 9280, loss = 0.000182997
I0403 04:50:22.696092 16973 solver.cpp:244]     Train net output #0: loss = 0.000183027 (* 1 = 0.000183027 loss)
I0403 04:50:22.878692 16973 sgd_solver.cpp:106] Iteration 9280, lr = 5e-05
I0403 04:50:34.320267 16973 solver.cpp:228] Iteration 9296, loss = 0.000801432
I0403 04:50:34.320605 16973 solver.cpp:244]     Train net output #0: loss = 0.000801461 (* 1 = 0.000801461 loss)
I0403 04:50:34.508146 16973 sgd_solver.cpp:106] Iteration 9296, lr = 5e-05
I0403 04:50:45.876340 16973 solver.cpp:228] Iteration 9312, loss = 0.000592841
I0403 04:50:45.876443 16973 solver.cpp:244]     Train net output #0: loss = 0.00059287 (* 1 = 0.00059287 loss)
I0403 04:50:46.058642 16973 sgd_solver.cpp:106] Iteration 9312, lr = 5e-05
I0403 04:50:57.489078 16973 solver.cpp:228] Iteration 9328, loss = 0.000115682
I0403 04:50:57.489182 16973 solver.cpp:244]     Train net output #0: loss = 0.000115713 (* 1 = 0.000115713 loss)
I0403 04:50:57.668115 16973 sgd_solver.cpp:106] Iteration 9328, lr = 5e-05
I0403 04:51:09.106215 16973 solver.cpp:228] Iteration 9344, loss = 0.000258158
I0403 04:51:09.106585 16973 solver.cpp:244]     Train net output #0: loss = 0.000258189 (* 1 = 0.000258189 loss)
I0403 04:51:09.288955 16973 sgd_solver.cpp:106] Iteration 9344, lr = 5e-05
I0403 04:51:20.883389 16973 solver.cpp:228] Iteration 9360, loss = 2.92929e-05
I0403 04:51:20.883491 16973 solver.cpp:244]     Train net output #0: loss = 2.93237e-05 (* 1 = 2.93237e-05 loss)
I0403 04:51:21.040683 16973 sgd_solver.cpp:106] Iteration 9360, lr = 5e-05
I0403 04:51:32.819824 16973 solver.cpp:228] Iteration 9376, loss = 0.000162117
I0403 04:51:32.819942 16973 solver.cpp:244]     Train net output #0: loss = 0.000162148 (* 1 = 0.000162148 loss)
I0403 04:51:33.013435 16973 sgd_solver.cpp:106] Iteration 9376, lr = 5e-05
I0403 04:51:44.582309 16973 solver.cpp:228] Iteration 9392, loss = 0.000753145
I0403 04:51:44.582656 16973 solver.cpp:244]     Train net output #0: loss = 0.000753177 (* 1 = 0.000753177 loss)
I0403 04:51:44.775943 16973 sgd_solver.cpp:106] Iteration 9392, lr = 5e-05
I0403 04:51:56.265745 16973 solver.cpp:228] Iteration 9408, loss = 0.000636137
I0403 04:51:56.265846 16973 solver.cpp:244]     Train net output #0: loss = 0.000636169 (* 1 = 0.000636169 loss)
I0403 04:51:56.438020 16973 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 04:52:07.959300 16973 solver.cpp:228] Iteration 9424, loss = 0.000290372
I0403 04:52:07.959417 16973 solver.cpp:244]     Train net output #0: loss = 0.000290403 (* 1 = 0.000290403 loss)
I0403 04:52:08.155763 16973 sgd_solver.cpp:106] Iteration 9424, lr = 5e-05
I0403 04:52:08.155998 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9425.caffemodel
I0403 04:52:10.795212 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9425.solverstate
I0403 04:52:12.557525 16973 solver.cpp:337] Iteration 9425, Testing net (#0)
I0403 04:53:01.743376 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985669
I0403 04:53:01.743703 16973 solver.cpp:404]     Test net output #1: loss = 0.0560355 (* 1 = 0.0560355 loss)
I0403 04:53:13.282546 16973 solver.cpp:228] Iteration 9440, loss = 6.89076e-05
I0403 04:53:13.282662 16973 solver.cpp:244]     Train net output #0: loss = 6.89388e-05 (* 1 = 6.89388e-05 loss)
I0403 04:53:13.530905 16973 sgd_solver.cpp:106] Iteration 9440, lr = 5e-05
I0403 04:53:25.206930 16973 solver.cpp:228] Iteration 9456, loss = 5.36357e-05
I0403 04:53:25.207034 16973 solver.cpp:244]     Train net output #0: loss = 5.36673e-05 (* 1 = 5.36673e-05 loss)
I0403 04:53:25.328161 16973 sgd_solver.cpp:106] Iteration 9456, lr = 5e-05
I0403 04:53:36.960372 16973 solver.cpp:228] Iteration 9472, loss = 8.47339e-05
I0403 04:53:36.960690 16973 solver.cpp:244]     Train net output #0: loss = 8.47652e-05 (* 1 = 8.47652e-05 loss)
I0403 04:53:37.183955 16973 sgd_solver.cpp:106] Iteration 9472, lr = 5e-05
I0403 04:53:48.672080 16973 solver.cpp:228] Iteration 9488, loss = 0.000915485
I0403 04:53:48.672194 16973 solver.cpp:244]     Train net output #0: loss = 0.000915516 (* 1 = 0.000915516 loss)
I0403 04:53:48.855804 16973 sgd_solver.cpp:106] Iteration 9488, lr = 5e-05
I0403 04:54:00.367331 16973 solver.cpp:228] Iteration 9504, loss = 0.000245204
I0403 04:54:00.367436 16973 solver.cpp:244]     Train net output #0: loss = 0.000245235 (* 1 = 0.000245235 loss)
I0403 04:54:00.549938 16973 sgd_solver.cpp:106] Iteration 9504, lr = 5e-05
I0403 04:54:12.146782 16973 solver.cpp:228] Iteration 9520, loss = 0.000142056
I0403 04:54:12.147090 16973 solver.cpp:244]     Train net output #0: loss = 0.000142087 (* 1 = 0.000142087 loss)
I0403 04:54:12.328542 16973 sgd_solver.cpp:106] Iteration 9520, lr = 5e-05
I0403 04:54:23.993526 16973 solver.cpp:228] Iteration 9536, loss = 0.00150824
I0403 04:54:23.993655 16973 solver.cpp:244]     Train net output #0: loss = 0.00150828 (* 1 = 0.00150828 loss)
I0403 04:54:24.197271 16973 sgd_solver.cpp:106] Iteration 9536, lr = 5e-05
I0403 04:54:35.790236 16973 solver.cpp:228] Iteration 9552, loss = 0.00457803
I0403 04:54:35.790338 16973 solver.cpp:244]     Train net output #0: loss = 0.00457806 (* 1 = 0.00457806 loss)
I0403 04:54:35.962963 16973 sgd_solver.cpp:106] Iteration 9552, lr = 5e-05
I0403 04:54:47.483572 16973 solver.cpp:228] Iteration 9568, loss = 0.00167919
I0403 04:54:47.483958 16973 solver.cpp:244]     Train net output #0: loss = 0.00167922 (* 1 = 0.00167922 loss)
I0403 04:54:47.683369 16973 sgd_solver.cpp:106] Iteration 9568, lr = 5e-05
I0403 04:54:59.240989 16973 solver.cpp:228] Iteration 9584, loss = 0.000550119
I0403 04:54:59.241103 16973 solver.cpp:244]     Train net output #0: loss = 0.00055015 (* 1 = 0.00055015 loss)
I0403 04:54:59.433759 16973 sgd_solver.cpp:106] Iteration 9584, lr = 5e-05
I0403 04:55:11.060464 16973 solver.cpp:228] Iteration 9600, loss = 0.000517163
I0403 04:55:11.060583 16973 solver.cpp:244]     Train net output #0: loss = 0.000517193 (* 1 = 0.000517193 loss)
I0403 04:55:11.262217 16973 sgd_solver.cpp:106] Iteration 9600, lr = 5e-05
I0403 04:55:22.882169 16973 solver.cpp:228] Iteration 9616, loss = 0.000966237
I0403 04:55:22.882510 16973 solver.cpp:244]     Train net output #0: loss = 0.000966267 (* 1 = 0.000966267 loss)
I0403 04:55:23.066699 16973 sgd_solver.cpp:106] Iteration 9616, lr = 5e-05
I0403 04:55:34.687261 16973 solver.cpp:228] Iteration 9632, loss = 0.00363362
I0403 04:55:34.687376 16973 solver.cpp:244]     Train net output #0: loss = 0.00363365 (* 1 = 0.00363365 loss)
I0403 04:55:34.920215 16973 sgd_solver.cpp:106] Iteration 9632, lr = 5e-05
I0403 04:55:46.396426 16973 solver.cpp:228] Iteration 9648, loss = 0.000221284
I0403 04:55:46.396534 16973 solver.cpp:244]     Train net output #0: loss = 0.000221315 (* 1 = 0.000221315 loss)
I0403 04:55:46.578613 16973 sgd_solver.cpp:106] Iteration 9648, lr = 5e-05
I0403 04:55:58.150151 16973 solver.cpp:228] Iteration 9664, loss = 0.000307184
I0403 04:55:58.150468 16973 solver.cpp:244]     Train net output #0: loss = 0.000307215 (* 1 = 0.000307215 loss)
I0403 04:55:58.352869 16973 sgd_solver.cpp:106] Iteration 9664, lr = 5e-05
I0403 04:56:09.916812 16973 solver.cpp:228] Iteration 9680, loss = 0.0155769
I0403 04:56:09.916926 16973 solver.cpp:244]     Train net output #0: loss = 0.0155769 (* 1 = 0.0155769 loss)
I0403 04:56:10.107928 16973 sgd_solver.cpp:106] Iteration 9680, lr = 5e-05
I0403 04:56:21.672019 16973 solver.cpp:228] Iteration 9696, loss = 0.00179593
I0403 04:56:21.672123 16973 solver.cpp:244]     Train net output #0: loss = 0.00179597 (* 1 = 0.00179597 loss)
I0403 04:56:21.824625 16973 sgd_solver.cpp:106] Iteration 9696, lr = 5e-05
I0403 04:56:33.524341 16973 solver.cpp:228] Iteration 9712, loss = 5.75557e-05
I0403 04:56:33.524664 16973 solver.cpp:244]     Train net output #0: loss = 5.75878e-05 (* 1 = 5.75878e-05 loss)
I0403 04:56:33.717241 16973 sgd_solver.cpp:106] Iteration 9712, lr = 5e-05
I0403 04:56:45.347894 16973 solver.cpp:228] Iteration 9728, loss = 0.00208084
I0403 04:56:45.347998 16973 solver.cpp:244]     Train net output #0: loss = 0.00208087 (* 1 = 0.00208087 loss)
I0403 04:56:45.530257 16973 sgd_solver.cpp:106] Iteration 9728, lr = 5e-05
I0403 04:56:57.094552 16973 solver.cpp:228] Iteration 9744, loss = 0.000168022
I0403 04:56:57.094667 16973 solver.cpp:244]     Train net output #0: loss = 0.000168054 (* 1 = 0.000168054 loss)
I0403 04:56:57.343197 16973 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 04:57:01.047919 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9750.caffemodel
I0403 04:57:03.651592 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9750.solverstate
I0403 04:57:05.435288 16973 solver.cpp:337] Iteration 9750, Testing net (#0)
I0403 04:57:54.634954 16973 solver.cpp:404]     Test net output #0: accuracy = 0.985577
I0403 04:57:54.635288 16973 solver.cpp:404]     Test net output #1: loss = 0.0559653 (* 1 = 0.0559653 loss)
I0403 04:58:02.527993 16973 solver.cpp:228] Iteration 9760, loss = 0.000225643
I0403 04:58:02.528103 16973 solver.cpp:244]     Train net output #0: loss = 0.000225675 (* 1 = 0.000225675 loss)
I0403 04:58:02.746830 16973 sgd_solver.cpp:106] Iteration 9760, lr = 5e-05
I0403 04:58:03.452796 16973 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9762.caffemodel
I0403 04:58:06.158116 16973 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-60-40_finetune/snapshots__iter_9762.solverstate
I0403 04:58:07.906790 16973 solver.cpp:322] Optimization Done.
I0403 04:58:07.986191 16973 caffe.cpp:222] Optimization Done.
