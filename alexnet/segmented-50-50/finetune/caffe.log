I0403 02:30:28.019034  2204 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.019537  2204 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.019565  2204 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.235127  2204 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.236805  2204 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.238309  2204 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.001113  2204 solver.cpp:48] Initializing solver from parameters: 
test_iter: 274
test_interval: 268
base_lr: 0.005
display: 13
max_iter: 8066
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2688
snapshot: 268
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.030696  2204 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.040009  2204 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.040086  2204 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.040930  2204 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-50-50/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.043359  2204 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.044390  2204 net.cpp:91] Creating Layer data
I0403 02:30:37.044479  2204 net.cpp:399] data -> data
I0403 02:30:37.044600  2204 net.cpp:399] data -> label
I0403 02:30:37.044667  2204 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-50-50/mean.binaryproto
I0403 02:30:37.077095  2210 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-50-50/train_db
I0403 02:30:37.089654  2204 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.231173  2204 net.cpp:141] Setting up data
I0403 02:30:37.231295  2204 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.231323  2204 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.231340  2204 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.231376  2204 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.231431  2204 net.cpp:91] Creating Layer conv1
I0403 02:30:37.231461  2204 net.cpp:425] conv1 <- data
I0403 02:30:37.231497  2204 net.cpp:399] conv1 -> conv1
I0403 02:30:37.241098  2204 net.cpp:141] Setting up conv1
I0403 02:30:37.241137  2204 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.241156  2204 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.241199  2204 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.241231  2204 net.cpp:91] Creating Layer relu1
I0403 02:30:37.241251  2204 net.cpp:425] relu1 <- conv1
I0403 02:30:37.241274  2204 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.241322  2204 net.cpp:141] Setting up relu1
I0403 02:30:37.241358  2204 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.241397  2204 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.241417  2204 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.241451  2204 net.cpp:91] Creating Layer norm1
I0403 02:30:37.241524  2204 net.cpp:425] norm1 <- conv1
I0403 02:30:37.241549  2204 net.cpp:399] norm1 -> norm1
I0403 02:30:37.241618  2204 net.cpp:141] Setting up norm1
I0403 02:30:37.241667  2204 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.241714  2204 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.241770  2204 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.241827  2204 net.cpp:91] Creating Layer pool1
I0403 02:30:37.241873  2204 net.cpp:425] pool1 <- norm1
I0403 02:30:37.241925  2204 net.cpp:399] pool1 -> pool1
I0403 02:30:37.241996  2204 net.cpp:141] Setting up pool1
I0403 02:30:37.242024  2204 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.242041  2204 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.242058  2204 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.242085  2204 net.cpp:91] Creating Layer conv2
I0403 02:30:37.242105  2204 net.cpp:425] conv2 <- pool1
I0403 02:30:37.242130  2204 net.cpp:399] conv2 -> conv2
I0403 02:30:37.242563  2212 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.257823  2204 net.cpp:141] Setting up conv2
I0403 02:30:37.257861  2204 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.257880  2204 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.257906  2204 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.257931  2204 net.cpp:91] Creating Layer relu2
I0403 02:30:37.257951  2204 net.cpp:425] relu2 <- conv2
I0403 02:30:37.257972  2204 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.257994  2204 net.cpp:141] Setting up relu2
I0403 02:30:37.258015  2204 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.258033  2204 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.258049  2204 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.258071  2204 net.cpp:91] Creating Layer norm2
I0403 02:30:37.258092  2204 net.cpp:425] norm2 <- conv2
I0403 02:30:37.258114  2204 net.cpp:399] norm2 -> norm2
I0403 02:30:37.258173  2204 net.cpp:141] Setting up norm2
I0403 02:30:37.258200  2204 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.258219  2204 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.258237  2204 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.258262  2204 net.cpp:91] Creating Layer pool2
I0403 02:30:37.258282  2204 net.cpp:425] pool2 <- norm2
I0403 02:30:37.258303  2204 net.cpp:399] pool2 -> pool2
I0403 02:30:37.258358  2204 net.cpp:141] Setting up pool2
I0403 02:30:37.258384  2204 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.258404  2204 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.258420  2204 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.258445  2204 net.cpp:91] Creating Layer conv3
I0403 02:30:37.258466  2204 net.cpp:425] conv3 <- pool2
I0403 02:30:37.258488  2204 net.cpp:399] conv3 -> conv3
I0403 02:30:37.300122  2204 net.cpp:141] Setting up conv3
I0403 02:30:37.300163  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.300184  2204 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.300209  2204 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.300231  2204 net.cpp:91] Creating Layer relu3
I0403 02:30:37.300251  2204 net.cpp:425] relu3 <- conv3
I0403 02:30:37.300273  2204 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.300297  2204 net.cpp:141] Setting up relu3
I0403 02:30:37.300318  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.300335  2204 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.300353  2204 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.300377  2204 net.cpp:91] Creating Layer conv4
I0403 02:30:37.300397  2204 net.cpp:425] conv4 <- conv3
I0403 02:30:37.300421  2204 net.cpp:399] conv4 -> conv4
I0403 02:30:37.331774  2204 net.cpp:141] Setting up conv4
I0403 02:30:37.331812  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.331832  2204 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.331876  2204 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.331899  2204 net.cpp:91] Creating Layer relu4
I0403 02:30:37.331918  2204 net.cpp:425] relu4 <- conv4
I0403 02:30:37.331939  2204 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.331962  2204 net.cpp:141] Setting up relu4
I0403 02:30:37.331982  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.332000  2204 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.332017  2204 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.332043  2204 net.cpp:91] Creating Layer conv5
I0403 02:30:37.332062  2204 net.cpp:425] conv5 <- conv4
I0403 02:30:37.332087  2204 net.cpp:399] conv5 -> conv5
I0403 02:30:37.353099  2204 net.cpp:141] Setting up conv5
I0403 02:30:37.353137  2204 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.353157  2204 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.353183  2204 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.353206  2204 net.cpp:91] Creating Layer relu5
I0403 02:30:37.353225  2204 net.cpp:425] relu5 <- conv5
I0403 02:30:37.353246  2204 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.353271  2204 net.cpp:141] Setting up relu5
I0403 02:30:37.353291  2204 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.353308  2204 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.353327  2204 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.353348  2204 net.cpp:91] Creating Layer pool5
I0403 02:30:37.353366  2204 net.cpp:425] pool5 <- conv5
I0403 02:30:37.353387  2204 net.cpp:399] pool5 -> pool5
I0403 02:30:37.353446  2204 net.cpp:141] Setting up pool5
I0403 02:30:37.353476  2204 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.353493  2204 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.353513  2204 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.353562  2204 net.cpp:91] Creating Layer fc6
I0403 02:30:37.353586  2204 net.cpp:425] fc6 <- pool5
I0403 02:30:37.353612  2204 net.cpp:399] fc6 -> fc6
I0403 02:30:38.871573  2204 net.cpp:141] Setting up fc6
I0403 02:30:38.871678  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.871693  2204 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.871716  2204 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.871737  2204 net.cpp:91] Creating Layer relu6
I0403 02:30:38.871753  2204 net.cpp:425] relu6 <- fc6
I0403 02:30:38.871779  2204 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.871803  2204 net.cpp:141] Setting up relu6
I0403 02:30:38.871819  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.871831  2204 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.871843  2204 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.871898  2204 net.cpp:91] Creating Layer drop6
I0403 02:30:38.871917  2204 net.cpp:425] drop6 <- fc6
I0403 02:30:38.871935  2204 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.871992  2204 net.cpp:141] Setting up drop6
I0403 02:30:38.872014  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.872026  2204 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.872041  2204 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.872063  2204 net.cpp:91] Creating Layer fc7
I0403 02:30:38.872078  2204 net.cpp:425] fc7 <- fc6
I0403 02:30:38.872095  2204 net.cpp:399] fc7 -> fc7
I0403 02:30:39.473186  2204 net.cpp:141] Setting up fc7
I0403 02:30:39.473283  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.473299  2204 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.473320  2204 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.473343  2204 net.cpp:91] Creating Layer relu7
I0403 02:30:39.473358  2204 net.cpp:425] relu7 <- fc7
I0403 02:30:39.473377  2204 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.473398  2204 net.cpp:141] Setting up relu7
I0403 02:30:39.473414  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.473426  2204 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.473439  2204 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.473497  2204 net.cpp:91] Creating Layer drop7
I0403 02:30:39.473515  2204 net.cpp:425] drop7 <- fc7
I0403 02:30:39.473541  2204 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.473578  2204 net.cpp:141] Setting up drop7
I0403 02:30:39.473600  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.473614  2204 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.473626  2204 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.473646  2204 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.473660  2204 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.473680  2204 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.479648  2204 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.479676  2204 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.479691  2204 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.479707  2204 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.479754  2204 net.cpp:91] Creating Layer loss
I0403 02:30:39.479775  2204 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.479791  2204 net.cpp:425] loss <- label
I0403 02:30:39.479815  2204 net.cpp:399] loss -> loss
I0403 02:30:39.479851  2204 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.479974  2204 net.cpp:141] Setting up loss
I0403 02:30:39.479996  2204 net.cpp:148] Top shape: (1)
I0403 02:30:39.480010  2204 net.cpp:151]     with loss weight 1
I0403 02:30:39.480093  2204 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.480106  2204 net.cpp:217] loss needs backward computation.
I0403 02:30:39.480120  2204 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.480134  2204 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.480146  2204 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.480159  2204 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.480170  2204 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.480183  2204 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.480195  2204 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.480209  2204 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.480222  2204 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.480235  2204 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.480248  2204 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.480262  2204 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.480274  2204 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.480288  2204 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.480299  2204 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.480314  2204 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.480326  2204 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.480340  2204 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.480352  2204 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.480365  2204 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.480377  2204 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.480391  2204 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.480404  2204 net.cpp:219] data does not need backward computation.
I0403 02:30:39.480417  2204 net.cpp:261] This network produces output loss
I0403 02:30:39.480443  2204 net.cpp:274] Network initialization done.
I0403 02:30:39.481530  2204 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.481586  2204 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.482223  2204 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-50-50/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.482393  2204 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.482555  2204 net.cpp:91] Creating Layer data
I0403 02:30:39.482580  2204 net.cpp:399] data -> data
I0403 02:30:39.482605  2204 net.cpp:399] data -> label
I0403 02:30:39.482628  2204 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-50-50/mean.binaryproto
I0403 02:30:39.504396  2214 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-50-50/test_db
I0403 02:30:39.507378  2204 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.653698  2204 net.cpp:141] Setting up data
I0403 02:30:39.653777  2204 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.653803  2204 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.653820  2204 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.653839  2204 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.653869  2204 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.653887  2204 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.653908  2204 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.653934  2204 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.653992  2204 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.654018  2204 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.654034  2204 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.654049  2204 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.654064  2204 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.654091  2204 net.cpp:91] Creating Layer conv1
I0403 02:30:39.654110  2204 net.cpp:425] conv1 <- data
I0403 02:30:39.654132  2204 net.cpp:399] conv1 -> conv1
I0403 02:30:39.655750  2204 net.cpp:141] Setting up conv1
I0403 02:30:39.655777  2204 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.655798  2204 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.655823  2204 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.655844  2204 net.cpp:91] Creating Layer relu1
I0403 02:30:39.655861  2204 net.cpp:425] relu1 <- conv1
I0403 02:30:39.655879  2204 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.655899  2204 net.cpp:141] Setting up relu1
I0403 02:30:39.655915  2204 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.655930  2204 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.655944  2204 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.655966  2204 net.cpp:91] Creating Layer norm1
I0403 02:30:39.655982  2204 net.cpp:425] norm1 <- conv1
I0403 02:30:39.655999  2204 net.cpp:399] norm1 -> norm1
I0403 02:30:39.661799  2204 net.cpp:141] Setting up norm1
I0403 02:30:39.661839  2204 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.661856  2204 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.661871  2204 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.661892  2204 net.cpp:91] Creating Layer pool1
I0403 02:30:39.661908  2204 net.cpp:425] pool1 <- norm1
I0403 02:30:39.661927  2204 net.cpp:399] pool1 -> pool1
I0403 02:30:39.661979  2204 net.cpp:141] Setting up pool1
I0403 02:30:39.662003  2204 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.662017  2204 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.662062  2204 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.662086  2204 net.cpp:91] Creating Layer conv2
I0403 02:30:39.662103  2204 net.cpp:425] conv2 <- pool1
I0403 02:30:39.662123  2204 net.cpp:399] conv2 -> conv2
I0403 02:30:39.674777  2204 net.cpp:141] Setting up conv2
I0403 02:30:39.674819  2204 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.674849  2204 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.674870  2204 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.674888  2204 net.cpp:91] Creating Layer relu2
I0403 02:30:39.674904  2204 net.cpp:425] relu2 <- conv2
I0403 02:30:39.674921  2204 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.674939  2204 net.cpp:141] Setting up relu2
I0403 02:30:39.674960  2204 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.674981  2204 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.674995  2204 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.675014  2204 net.cpp:91] Creating Layer norm2
I0403 02:30:39.675029  2204 net.cpp:425] norm2 <- conv2
I0403 02:30:39.675046  2204 net.cpp:399] norm2 -> norm2
I0403 02:30:39.675094  2204 net.cpp:141] Setting up norm2
I0403 02:30:39.675117  2204 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.675130  2204 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.675145  2204 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.675163  2204 net.cpp:91] Creating Layer pool2
I0403 02:30:39.675176  2204 net.cpp:425] pool2 <- norm2
I0403 02:30:39.675194  2204 net.cpp:399] pool2 -> pool2
I0403 02:30:39.675238  2204 net.cpp:141] Setting up pool2
I0403 02:30:39.675259  2204 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.675273  2204 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.675288  2204 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.675309  2204 net.cpp:91] Creating Layer conv3
I0403 02:30:39.675325  2204 net.cpp:425] conv3 <- pool2
I0403 02:30:39.675343  2204 net.cpp:399] conv3 -> conv3
I0403 02:30:39.709532  2204 net.cpp:141] Setting up conv3
I0403 02:30:39.709592  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.709609  2204 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.709633  2204 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.709656  2204 net.cpp:91] Creating Layer relu3
I0403 02:30:39.709673  2204 net.cpp:425] relu3 <- conv3
I0403 02:30:39.709692  2204 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.709710  2204 net.cpp:141] Setting up relu3
I0403 02:30:39.709728  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.709740  2204 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.709754  2204 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.709776  2204 net.cpp:91] Creating Layer conv4
I0403 02:30:39.709796  2204 net.cpp:425] conv4 <- conv3
I0403 02:30:39.709816  2204 net.cpp:399] conv4 -> conv4
I0403 02:30:39.735549  2204 net.cpp:141] Setting up conv4
I0403 02:30:39.735589  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.735605  2204 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.735621  2204 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.735641  2204 net.cpp:91] Creating Layer relu4
I0403 02:30:39.735656  2204 net.cpp:425] relu4 <- conv4
I0403 02:30:39.735677  2204 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.735704  2204 net.cpp:141] Setting up relu4
I0403 02:30:39.735726  2204 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.735740  2204 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.735754  2204 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.735775  2204 net.cpp:91] Creating Layer conv5
I0403 02:30:39.735795  2204 net.cpp:425] conv5 <- conv4
I0403 02:30:39.735815  2204 net.cpp:399] conv5 -> conv5
I0403 02:30:39.752692  2204 net.cpp:141] Setting up conv5
I0403 02:30:39.752724  2204 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.752768  2204 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.752794  2204 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.752813  2204 net.cpp:91] Creating Layer relu5
I0403 02:30:39.752830  2204 net.cpp:425] relu5 <- conv5
I0403 02:30:39.752846  2204 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.752864  2204 net.cpp:141] Setting up relu5
I0403 02:30:39.752881  2204 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.752892  2204 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.752907  2204 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.752926  2204 net.cpp:91] Creating Layer pool5
I0403 02:30:39.752941  2204 net.cpp:425] pool5 <- conv5
I0403 02:30:39.752961  2204 net.cpp:399] pool5 -> pool5
I0403 02:30:39.753013  2204 net.cpp:141] Setting up pool5
I0403 02:30:39.753036  2204 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.753051  2204 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.753063  2204 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.753085  2204 net.cpp:91] Creating Layer fc6
I0403 02:30:39.753101  2204 net.cpp:425] fc6 <- pool5
I0403 02:30:39.753121  2204 net.cpp:399] fc6 -> fc6
I0403 02:30:41.191951  2204 net.cpp:141] Setting up fc6
I0403 02:30:41.192059  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.192075  2204 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.192097  2204 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.192122  2204 net.cpp:91] Creating Layer relu6
I0403 02:30:41.192139  2204 net.cpp:425] relu6 <- fc6
I0403 02:30:41.192162  2204 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.192183  2204 net.cpp:141] Setting up relu6
I0403 02:30:41.192200  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.192214  2204 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.192227  2204 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.192245  2204 net.cpp:91] Creating Layer drop6
I0403 02:30:41.192260  2204 net.cpp:425] drop6 <- fc6
I0403 02:30:41.192278  2204 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.192318  2204 net.cpp:141] Setting up drop6
I0403 02:30:41.192340  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.192354  2204 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.192368  2204 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.192402  2204 net.cpp:91] Creating Layer fc7
I0403 02:30:41.192419  2204 net.cpp:425] fc7 <- fc6
I0403 02:30:41.192435  2204 net.cpp:399] fc7 -> fc7
I0403 02:30:41.809087  2204 net.cpp:141] Setting up fc7
I0403 02:30:41.809185  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.809201  2204 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.809222  2204 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.809247  2204 net.cpp:91] Creating Layer relu7
I0403 02:30:41.809262  2204 net.cpp:425] relu7 <- fc7
I0403 02:30:41.809280  2204 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.809301  2204 net.cpp:141] Setting up relu7
I0403 02:30:41.809317  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.809330  2204 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.809343  2204 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.809360  2204 net.cpp:91] Creating Layer drop7
I0403 02:30:41.809375  2204 net.cpp:425] drop7 <- fc7
I0403 02:30:41.809392  2204 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.809429  2204 net.cpp:141] Setting up drop7
I0403 02:30:41.809451  2204 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.809465  2204 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.809479  2204 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.809499  2204 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.809514  2204 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.809533  2204 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.815513  2204 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.815541  2204 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.815608  2204 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.815626  2204 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.815645  2204 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.815665  2204 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.815681  2204 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.815701  2204 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.815752  2204 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.815773  2204 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.815788  2204 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.815814  2204 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.815829  2204 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.815845  2204 net.cpp:91] Creating Layer loss
I0403 02:30:41.815860  2204 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.815876  2204 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.815892  2204 net.cpp:399] loss -> loss
I0403 02:30:41.815915  2204 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.816018  2204 net.cpp:141] Setting up loss
I0403 02:30:41.816040  2204 net.cpp:148] Top shape: (1)
I0403 02:30:41.816053  2204 net.cpp:151]     with loss weight 1
I0403 02:30:41.816079  2204 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.816100  2204 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.816118  2204 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.816133  2204 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.816148  2204 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.816166  2204 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.816220  2204 net.cpp:141] Setting up accuracy
I0403 02:30:41.816239  2204 net.cpp:148] Top shape: (1)
I0403 02:30:41.816252  2204 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.816265  2204 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.816278  2204 net.cpp:217] loss needs backward computation.
I0403 02:30:41.816293  2204 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.816305  2204 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.816318  2204 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.816331  2204 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.816344  2204 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.816356  2204 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.816368  2204 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.816381  2204 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.816393  2204 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.816406  2204 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.816421  2204 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.816434  2204 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.816447  2204 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.816459  2204 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.816473  2204 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.816484  2204 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.816498  2204 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.816510  2204 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.816522  2204 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.816535  2204 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.816548  2204 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.816561  2204 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.816573  2204 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.816602  2204 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.816617  2204 net.cpp:219] data does not need backward computation.
I0403 02:30:41.816630  2204 net.cpp:261] This network produces output accuracy
I0403 02:30:41.816644  2204 net.cpp:261] This network produces output loss
I0403 02:30:41.816678  2204 net.cpp:274] Network initialization done.
I0403 02:30:41.816779  2204 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.817255  2204 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.228505  2204 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.228577  2204 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.228595  2204 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.228636  2204 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.606859  2204 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.642937  2204 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.307680  2204 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.307763  2204 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.307787  2204 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.307842  2204 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.688629  2204 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:44.723477  2204 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.749603  2204 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:44.964965  2204 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:47.462012  2204 parallel.cpp:425] Starting Optimization
I0403 02:30:47.462226  2204 solver.cpp:279] Solving 
I0403 02:30:47.462249  2204 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:47.462396  2204 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:49.009892  2204 solver.cpp:404]     Test net output #0: accuracy = 0.0151095
I0403 02:31:49.016022  2204 solver.cpp:404]     Test net output #1: loss = 3.87488 (* 1 = 3.87488 loss)
I0403 02:31:49.584625  2204 solver.cpp:228] Iteration 0, loss = 4.20658
I0403 02:31:49.590852  2204 solver.cpp:244]     Train net output #0: loss = 4.20658 (* 1 = 4.20658 loss)
I0403 02:31:49.757180  2204 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:31:59.002786  2204 solver.cpp:228] Iteration 13, loss = 1.44444
I0403 02:31:59.008225  2204 solver.cpp:244]     Train net output #0: loss = 1.44444 (* 1 = 1.44444 loss)
I0403 02:31:59.182802  2204 sgd_solver.cpp:106] Iteration 13, lr = 0.005
I0403 02:32:08.363626  2204 solver.cpp:228] Iteration 26, loss = 1.08223
I0403 02:32:08.369933  2204 solver.cpp:244]     Train net output #0: loss = 1.08223 (* 1 = 1.08223 loss)
I0403 02:32:08.559191  2204 sgd_solver.cpp:106] Iteration 26, lr = 0.005
I0403 02:32:17.771806  2204 solver.cpp:228] Iteration 39, loss = 0.477514
I0403 02:32:17.777007  2204 solver.cpp:244]     Train net output #0: loss = 0.477514 (* 1 = 0.477514 loss)
I0403 02:32:17.953552  2204 sgd_solver.cpp:106] Iteration 39, lr = 0.005
I0403 02:32:27.100040  2204 solver.cpp:228] Iteration 52, loss = 0.806764
I0403 02:32:27.106011  2204 solver.cpp:244]     Train net output #0: loss = 0.806764 (* 1 = 0.806764 loss)
I0403 02:32:27.277784  2204 sgd_solver.cpp:106] Iteration 52, lr = 0.005
I0403 02:32:36.602993  2204 solver.cpp:228] Iteration 65, loss = 0.426008
I0403 02:32:36.609729  2204 solver.cpp:244]     Train net output #0: loss = 0.426008 (* 1 = 0.426008 loss)
I0403 02:32:36.783432  2204 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 02:32:46.090596  2204 solver.cpp:228] Iteration 78, loss = 0.358386
I0403 02:32:46.096726  2204 solver.cpp:244]     Train net output #0: loss = 0.358386 (* 1 = 0.358386 loss)
I0403 02:32:46.275460  2204 sgd_solver.cpp:106] Iteration 78, lr = 0.005
I0403 02:32:55.353521  2204 solver.cpp:228] Iteration 91, loss = 0.353394
I0403 02:32:55.359839  2204 solver.cpp:244]     Train net output #0: loss = 0.353394 (* 1 = 0.353394 loss)
I0403 02:32:55.529822  2204 sgd_solver.cpp:106] Iteration 91, lr = 0.005
I0403 02:33:04.706109  2204 solver.cpp:228] Iteration 104, loss = 0.343602
I0403 02:33:04.712060  2204 solver.cpp:244]     Train net output #0: loss = 0.343602 (* 1 = 0.343602 loss)
I0403 02:33:04.919785  2204 sgd_solver.cpp:106] Iteration 104, lr = 0.005
I0403 02:33:14.240700  2204 solver.cpp:228] Iteration 117, loss = 0.207319
I0403 02:33:14.246649  2204 solver.cpp:244]     Train net output #0: loss = 0.207319 (* 1 = 0.207319 loss)
I0403 02:33:14.478411  2204 sgd_solver.cpp:106] Iteration 117, lr = 0.005
I0403 02:33:23.757134  2204 solver.cpp:228] Iteration 130, loss = 0.55732
I0403 02:33:23.763622  2204 solver.cpp:244]     Train net output #0: loss = 0.55732 (* 1 = 0.55732 loss)
I0403 02:33:23.908238  2204 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:33:33.336784  2204 solver.cpp:228] Iteration 143, loss = 0.383249
I0403 02:33:33.341285  2204 solver.cpp:244]     Train net output #0: loss = 0.383249 (* 1 = 0.383249 loss)
I0403 02:33:33.556187  2204 sgd_solver.cpp:106] Iteration 143, lr = 0.005
I0403 02:33:42.886530  2204 solver.cpp:228] Iteration 156, loss = 0.208878
I0403 02:33:42.891599  2204 solver.cpp:244]     Train net output #0: loss = 0.208878 (* 1 = 0.208878 loss)
I0403 02:33:43.059958  2204 sgd_solver.cpp:106] Iteration 156, lr = 0.005
I0403 02:33:52.304311  2204 solver.cpp:228] Iteration 169, loss = 0.20232
I0403 02:33:52.310741  2204 solver.cpp:244]     Train net output #0: loss = 0.202321 (* 1 = 0.202321 loss)
I0403 02:33:52.483345  2204 sgd_solver.cpp:106] Iteration 169, lr = 0.005
I0403 02:34:01.830268  2204 solver.cpp:228] Iteration 182, loss = 0.167984
I0403 02:34:01.836311  2204 solver.cpp:244]     Train net output #0: loss = 0.167984 (* 1 = 0.167984 loss)
I0403 02:34:02.018949  2204 sgd_solver.cpp:106] Iteration 182, lr = 0.005
I0403 02:34:11.189064  2204 solver.cpp:228] Iteration 195, loss = 0.189607
I0403 02:34:11.189177  2204 solver.cpp:244]     Train net output #0: loss = 0.189607 (* 1 = 0.189607 loss)
I0403 02:34:11.436827  2204 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 02:34:20.703409  2204 solver.cpp:228] Iteration 208, loss = 0.249892
I0403 02:34:20.710021  2204 solver.cpp:244]     Train net output #0: loss = 0.249892 (* 1 = 0.249892 loss)
I0403 02:34:20.884505  2204 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 02:34:30.072830  2204 solver.cpp:228] Iteration 221, loss = 0.140058
I0403 02:34:30.078558  2204 solver.cpp:244]     Train net output #0: loss = 0.140058 (* 1 = 0.140058 loss)
I0403 02:34:30.315918  2204 sgd_solver.cpp:106] Iteration 221, lr = 0.005
I0403 02:34:39.768570  2204 solver.cpp:228] Iteration 234, loss = 0.232856
I0403 02:34:39.775125  2204 solver.cpp:244]     Train net output #0: loss = 0.232857 (* 1 = 0.232857 loss)
I0403 02:34:39.917703  2204 sgd_solver.cpp:106] Iteration 234, lr = 0.005
I0403 02:34:49.295852  2204 solver.cpp:228] Iteration 247, loss = 0.0600344
I0403 02:34:49.301353  2204 solver.cpp:244]     Train net output #0: loss = 0.0600344 (* 1 = 0.0600344 loss)
I0403 02:34:49.523310  2204 sgd_solver.cpp:106] Iteration 247, lr = 0.005
I0403 02:34:59.070220  2204 solver.cpp:228] Iteration 260, loss = 0.100152
I0403 02:34:59.076423  2204 solver.cpp:244]     Train net output #0: loss = 0.100152 (* 1 = 0.100152 loss)
I0403 02:34:59.221832  2204 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:35:04.364967  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_268.caffemodel
I0403 02:35:07.267307  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_268.solverstate
I0403 02:35:09.187618  2204 solver.cpp:337] Iteration 268, Testing net (#0)
I0403 02:36:10.662315  2204 solver.cpp:404]     Test net output #0: accuracy = 0.94354
I0403 02:36:10.668053  2204 solver.cpp:404]     Test net output #1: loss = 0.17194 (* 1 = 0.17194 loss)
I0403 02:36:14.832351  2204 solver.cpp:228] Iteration 273, loss = 0.133896
I0403 02:36:14.837962  2204 solver.cpp:244]     Train net output #0: loss = 0.133896 (* 1 = 0.133896 loss)
I0403 02:36:15.057145  2204 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 02:36:24.482908  2204 solver.cpp:228] Iteration 286, loss = 0.18943
I0403 02:36:24.488374  2204 solver.cpp:244]     Train net output #0: loss = 0.18943 (* 1 = 0.18943 loss)
I0403 02:36:24.639453  2204 sgd_solver.cpp:106] Iteration 286, lr = 0.005
I0403 02:36:33.833858  2204 solver.cpp:228] Iteration 299, loss = 0.0992585
I0403 02:36:33.839926  2204 solver.cpp:244]     Train net output #0: loss = 0.0992585 (* 1 = 0.0992585 loss)
I0403 02:36:34.033562  2204 sgd_solver.cpp:106] Iteration 299, lr = 0.005
I0403 02:36:43.266608  2204 solver.cpp:228] Iteration 312, loss = 0.116333
I0403 02:36:43.271450  2204 solver.cpp:244]     Train net output #0: loss = 0.116333 (* 1 = 0.116333 loss)
I0403 02:36:43.433210  2204 sgd_solver.cpp:106] Iteration 312, lr = 0.005
I0403 02:36:52.763589  2204 solver.cpp:228] Iteration 325, loss = 0.061705
I0403 02:36:52.770615  2204 solver.cpp:244]     Train net output #0: loss = 0.061705 (* 1 = 0.061705 loss)
I0403 02:36:52.950789  2204 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 02:37:02.151207  2204 solver.cpp:228] Iteration 338, loss = 0.190034
I0403 02:37:02.157902  2204 solver.cpp:244]     Train net output #0: loss = 0.190034 (* 1 = 0.190034 loss)
I0403 02:37:02.386207  2204 sgd_solver.cpp:106] Iteration 338, lr = 0.005
I0403 02:37:11.741052  2204 solver.cpp:228] Iteration 351, loss = 0.119211
I0403 02:37:11.747491  2204 solver.cpp:244]     Train net output #0: loss = 0.119211 (* 1 = 0.119211 loss)
I0403 02:37:11.953035  2204 sgd_solver.cpp:106] Iteration 351, lr = 0.005
I0403 02:37:21.192656  2204 solver.cpp:228] Iteration 364, loss = 0.215613
I0403 02:37:21.199023  2204 solver.cpp:244]     Train net output #0: loss = 0.215613 (* 1 = 0.215613 loss)
I0403 02:37:21.388787  2204 sgd_solver.cpp:106] Iteration 364, lr = 0.005
I0403 02:37:30.741581  2204 solver.cpp:228] Iteration 377, loss = 0.119184
I0403 02:37:30.748030  2204 solver.cpp:244]     Train net output #0: loss = 0.119184 (* 1 = 0.119184 loss)
I0403 02:37:30.940150  2204 sgd_solver.cpp:106] Iteration 377, lr = 0.005
I0403 02:37:40.280338  2204 solver.cpp:228] Iteration 390, loss = 0.0466488
I0403 02:37:40.286969  2204 solver.cpp:244]     Train net output #0: loss = 0.0466488 (* 1 = 0.0466488 loss)
I0403 02:37:40.460361  2204 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:37:49.679743  2204 solver.cpp:228] Iteration 403, loss = 0.256981
I0403 02:37:49.686359  2204 solver.cpp:244]     Train net output #0: loss = 0.256981 (* 1 = 0.256981 loss)
I0403 02:37:49.867480  2204 sgd_solver.cpp:106] Iteration 403, lr = 0.005
I0403 02:37:59.180799  2204 solver.cpp:228] Iteration 416, loss = 0.103163
I0403 02:37:59.181103  2204 solver.cpp:244]     Train net output #0: loss = 0.103163 (* 1 = 0.103163 loss)
I0403 02:37:59.360319  2204 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 02:38:08.520663  2204 solver.cpp:228] Iteration 429, loss = 0.0748851
I0403 02:38:08.527194  2204 solver.cpp:244]     Train net output #0: loss = 0.0748851 (* 1 = 0.0748851 loss)
I0403 02:38:08.756870  2204 sgd_solver.cpp:106] Iteration 429, lr = 0.005
I0403 02:38:18.005123  2204 solver.cpp:228] Iteration 442, loss = 0.0800113
I0403 02:38:18.011010  2204 solver.cpp:244]     Train net output #0: loss = 0.0800113 (* 1 = 0.0800113 loss)
I0403 02:38:18.189478  2204 sgd_solver.cpp:106] Iteration 442, lr = 0.005
I0403 02:38:27.462249  2204 solver.cpp:228] Iteration 455, loss = 0.107543
I0403 02:38:27.467509  2204 solver.cpp:244]     Train net output #0: loss = 0.107543 (* 1 = 0.107543 loss)
I0403 02:38:27.658314  2204 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 02:38:36.798897  2204 solver.cpp:228] Iteration 468, loss = 0.0781893
I0403 02:38:36.805563  2204 solver.cpp:244]     Train net output #0: loss = 0.0781894 (* 1 = 0.0781894 loss)
I0403 02:38:36.980661  2204 sgd_solver.cpp:106] Iteration 468, lr = 0.005
I0403 02:38:46.340898  2204 solver.cpp:228] Iteration 481, loss = 0.129632
I0403 02:38:46.341007  2204 solver.cpp:244]     Train net output #0: loss = 0.129632 (* 1 = 0.129632 loss)
I0403 02:38:46.613360  2204 sgd_solver.cpp:106] Iteration 481, lr = 0.005
I0403 02:38:55.791960  2204 solver.cpp:228] Iteration 494, loss = 0.0923922
I0403 02:38:55.792067  2204 solver.cpp:244]     Train net output #0: loss = 0.0923923 (* 1 = 0.0923923 loss)
I0403 02:38:55.939272  2204 sgd_solver.cpp:106] Iteration 494, lr = 0.005
I0403 02:39:05.379364  2204 solver.cpp:228] Iteration 507, loss = 0.0916281
I0403 02:39:05.379467  2204 solver.cpp:244]     Train net output #0: loss = 0.0916282 (* 1 = 0.0916282 loss)
I0403 02:39:05.554649  2204 sgd_solver.cpp:106] Iteration 507, lr = 0.005
I0403 02:39:14.841111  2204 solver.cpp:228] Iteration 520, loss = 0.0505167
I0403 02:39:14.841454  2204 solver.cpp:244]     Train net output #0: loss = 0.0505167 (* 1 = 0.0505167 loss)
I0403 02:39:15.023636  2204 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:39:24.325114  2204 solver.cpp:228] Iteration 533, loss = 0.0996884
I0403 02:39:24.325229  2204 solver.cpp:244]     Train net output #0: loss = 0.0996884 (* 1 = 0.0996884 loss)
I0403 02:39:24.508824  2204 sgd_solver.cpp:106] Iteration 533, lr = 0.005
I0403 02:39:25.980929  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_536.caffemodel
I0403 02:39:28.593726  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_536.solverstate
I0403 02:39:30.365854  2204 solver.cpp:337] Iteration 536, Testing net (#0)
I0403 02:40:31.859576  2204 solver.cpp:404]     Test net output #0: accuracy = 0.954818
I0403 02:40:31.864358  2204 solver.cpp:404]     Test net output #1: loss = 0.138505 (* 1 = 0.138505 loss)
I0403 02:40:39.786370  2204 solver.cpp:228] Iteration 546, loss = 0.0993723
I0403 02:40:39.792327  2204 solver.cpp:244]     Train net output #0: loss = 0.0993724 (* 1 = 0.0993724 loss)
I0403 02:40:39.963544  2204 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 02:40:49.353514  2204 solver.cpp:228] Iteration 559, loss = 0.0764484
I0403 02:40:49.361583  2204 solver.cpp:244]     Train net output #0: loss = 0.0764484 (* 1 = 0.0764484 loss)
I0403 02:40:49.545150  2204 sgd_solver.cpp:106] Iteration 559, lr = 0.005
I0403 02:40:58.720053  2204 solver.cpp:228] Iteration 572, loss = 0.0870931
I0403 02:40:58.726917  2204 solver.cpp:244]     Train net output #0: loss = 0.0870931 (* 1 = 0.0870931 loss)
I0403 02:40:58.901206  2204 sgd_solver.cpp:106] Iteration 572, lr = 0.005
I0403 02:41:08.340446  2204 solver.cpp:228] Iteration 585, loss = 0.0572522
I0403 02:41:08.346427  2204 solver.cpp:244]     Train net output #0: loss = 0.0572522 (* 1 = 0.0572522 loss)
I0403 02:41:08.525032  2204 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 02:41:17.789299  2204 solver.cpp:228] Iteration 598, loss = 0.0251467
I0403 02:41:17.796711  2204 solver.cpp:244]     Train net output #0: loss = 0.0251467 (* 1 = 0.0251467 loss)
I0403 02:41:17.952368  2204 sgd_solver.cpp:106] Iteration 598, lr = 0.005
I0403 02:41:27.253604  2204 solver.cpp:228] Iteration 611, loss = 0.110815
I0403 02:41:27.259202  2204 solver.cpp:244]     Train net output #0: loss = 0.110815 (* 1 = 0.110815 loss)
I0403 02:41:27.452847  2204 sgd_solver.cpp:106] Iteration 611, lr = 0.005
I0403 02:41:36.627956  2204 solver.cpp:228] Iteration 624, loss = 0.107633
I0403 02:41:36.634063  2204 solver.cpp:244]     Train net output #0: loss = 0.107633 (* 1 = 0.107633 loss)
I0403 02:41:36.809960  2204 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 02:41:46.073573  2204 solver.cpp:228] Iteration 637, loss = 0.0788117
I0403 02:41:46.079982  2204 solver.cpp:244]     Train net output #0: loss = 0.0788118 (* 1 = 0.0788118 loss)
I0403 02:41:46.253612  2204 sgd_solver.cpp:106] Iteration 637, lr = 0.005
I0403 02:41:55.568151  2204 solver.cpp:228] Iteration 650, loss = 0.176198
I0403 02:41:55.574555  2204 solver.cpp:244]     Train net output #0: loss = 0.176199 (* 1 = 0.176199 loss)
I0403 02:41:55.722061  2204 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:42:05.073263  2204 solver.cpp:228] Iteration 663, loss = 0.0386896
I0403 02:42:05.079578  2204 solver.cpp:244]     Train net output #0: loss = 0.0386897 (* 1 = 0.0386897 loss)
I0403 02:42:05.252250  2204 sgd_solver.cpp:106] Iteration 663, lr = 0.005
I0403 02:42:14.546666  2204 solver.cpp:228] Iteration 676, loss = 0.0251808
I0403 02:42:14.552361  2204 solver.cpp:244]     Train net output #0: loss = 0.0251808 (* 1 = 0.0251808 loss)
I0403 02:42:14.719424  2204 sgd_solver.cpp:106] Iteration 676, lr = 0.005
I0403 02:42:24.213572  2204 solver.cpp:228] Iteration 689, loss = 0.114797
I0403 02:42:24.219568  2204 solver.cpp:244]     Train net output #0: loss = 0.114797 (* 1 = 0.114797 loss)
I0403 02:42:24.388067  2204 sgd_solver.cpp:106] Iteration 689, lr = 0.005
I0403 02:42:33.669270  2204 solver.cpp:228] Iteration 702, loss = 0.150993
I0403 02:42:33.675415  2204 solver.cpp:244]     Train net output #0: loss = 0.150993 (* 1 = 0.150993 loss)
I0403 02:42:33.848815  2204 sgd_solver.cpp:106] Iteration 702, lr = 0.005
I0403 02:42:43.189561  2204 solver.cpp:228] Iteration 715, loss = 0.0835678
I0403 02:42:43.195684  2204 solver.cpp:244]     Train net output #0: loss = 0.0835679 (* 1 = 0.0835679 loss)
I0403 02:42:43.425535  2204 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 02:42:52.828835  2204 solver.cpp:228] Iteration 728, loss = 0.0247144
I0403 02:42:52.834434  2204 solver.cpp:244]     Train net output #0: loss = 0.0247145 (* 1 = 0.0247145 loss)
I0403 02:42:53.033015  2204 sgd_solver.cpp:106] Iteration 728, lr = 0.005
I0403 02:43:02.251899  2204 solver.cpp:228] Iteration 741, loss = 0.0525886
I0403 02:43:02.258327  2204 solver.cpp:244]     Train net output #0: loss = 0.0525886 (* 1 = 0.0525886 loss)
I0403 02:43:02.463333  2204 sgd_solver.cpp:106] Iteration 741, lr = 0.005
I0403 02:43:11.843816  2204 solver.cpp:228] Iteration 754, loss = 0.0917105
I0403 02:43:11.849344  2204 solver.cpp:244]     Train net output #0: loss = 0.0917105 (* 1 = 0.0917105 loss)
I0403 02:43:12.039681  2204 sgd_solver.cpp:106] Iteration 754, lr = 0.005
I0403 02:43:21.363667  2204 solver.cpp:228] Iteration 767, loss = 0.0673178
I0403 02:43:21.369907  2204 solver.cpp:244]     Train net output #0: loss = 0.0673178 (* 1 = 0.0673178 loss)
I0403 02:43:21.553200  2204 sgd_solver.cpp:106] Iteration 767, lr = 0.005
I0403 02:43:30.713706  2204 solver.cpp:228] Iteration 780, loss = 0.045074
I0403 02:43:30.719518  2204 solver.cpp:244]     Train net output #0: loss = 0.0450741 (* 1 = 0.0450741 loss)
I0403 02:43:30.905349  2204 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:43:40.161555  2204 solver.cpp:228] Iteration 793, loss = 0.140483
I0403 02:43:40.167853  2204 solver.cpp:244]     Train net output #0: loss = 0.140483 (* 1 = 0.140483 loss)
I0403 02:43:40.353310  2204 sgd_solver.cpp:106] Iteration 793, lr = 0.005
I0403 02:43:47.629614  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_804.caffemodel
I0403 02:43:50.397454  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_804.solverstate
I0403 02:43:52.321187  2204 solver.cpp:337] Iteration 804, Testing net (#0)
I0403 02:44:53.792096  2204 solver.cpp:404]     Test net output #0: accuracy = 0.962446
I0403 02:44:53.800197  2204 solver.cpp:404]     Test net output #1: loss = 0.121243 (* 1 = 0.121243 loss)
I0403 02:44:55.823815  2204 solver.cpp:228] Iteration 806, loss = 0.062925
I0403 02:44:55.828814  2204 solver.cpp:244]     Train net output #0: loss = 0.0629251 (* 1 = 0.0629251 loss)
I0403 02:44:55.959956  2204 sgd_solver.cpp:106] Iteration 806, lr = 0.005
I0403 02:45:05.311399  2204 solver.cpp:228] Iteration 819, loss = 0.0508221
I0403 02:45:05.318560  2204 solver.cpp:244]     Train net output #0: loss = 0.0508222 (* 1 = 0.0508222 loss)
I0403 02:45:05.520118  2204 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 02:45:14.881160  2204 solver.cpp:228] Iteration 832, loss = 0.0518898
I0403 02:45:14.886965  2204 solver.cpp:244]     Train net output #0: loss = 0.0518898 (* 1 = 0.0518898 loss)
I0403 02:45:15.096748  2204 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 02:45:24.408385  2204 solver.cpp:228] Iteration 845, loss = 0.0218165
I0403 02:45:24.414149  2204 solver.cpp:244]     Train net output #0: loss = 0.0218165 (* 1 = 0.0218165 loss)
I0403 02:45:24.577388  2204 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 02:45:34.130381  2204 solver.cpp:228] Iteration 858, loss = 0.103548
I0403 02:45:34.136098  2204 solver.cpp:244]     Train net output #0: loss = 0.103548 (* 1 = 0.103548 loss)
I0403 02:45:34.332479  2204 sgd_solver.cpp:106] Iteration 858, lr = 0.005
I0403 02:45:43.553243  2204 solver.cpp:228] Iteration 871, loss = 0.0126739
I0403 02:45:43.560163  2204 solver.cpp:244]     Train net output #0: loss = 0.0126739 (* 1 = 0.0126739 loss)
I0403 02:45:43.755914  2204 sgd_solver.cpp:106] Iteration 871, lr = 0.005
I0403 02:45:53.051800  2204 solver.cpp:228] Iteration 884, loss = 0.0533423
I0403 02:45:53.057220  2204 solver.cpp:244]     Train net output #0: loss = 0.0533423 (* 1 = 0.0533423 loss)
I0403 02:45:53.241214  2204 sgd_solver.cpp:106] Iteration 884, lr = 0.005
I0403 02:46:02.429431  2204 solver.cpp:228] Iteration 897, loss = 0.035146
I0403 02:46:02.435822  2204 solver.cpp:244]     Train net output #0: loss = 0.035146 (* 1 = 0.035146 loss)
I0403 02:46:02.639744  2204 sgd_solver.cpp:106] Iteration 897, lr = 0.005
I0403 02:46:11.922947  2204 solver.cpp:228] Iteration 910, loss = 0.0710524
I0403 02:46:11.928704  2204 solver.cpp:244]     Train net output #0: loss = 0.0710525 (* 1 = 0.0710525 loss)
I0403 02:46:12.106442  2204 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:46:21.523504  2204 solver.cpp:228] Iteration 923, loss = 0.0497686
I0403 02:46:21.530701  2204 solver.cpp:244]     Train net output #0: loss = 0.0497686 (* 1 = 0.0497686 loss)
I0403 02:46:21.715627  2204 sgd_solver.cpp:106] Iteration 923, lr = 0.005
I0403 02:46:31.134519  2204 solver.cpp:228] Iteration 936, loss = 0.0815747
I0403 02:46:31.141140  2204 solver.cpp:244]     Train net output #0: loss = 0.0815747 (* 1 = 0.0815747 loss)
I0403 02:46:31.318898  2204 sgd_solver.cpp:106] Iteration 936, lr = 0.005
I0403 02:46:40.572937  2204 solver.cpp:228] Iteration 949, loss = 0.0453484
I0403 02:46:40.579390  2204 solver.cpp:244]     Train net output #0: loss = 0.0453485 (* 1 = 0.0453485 loss)
I0403 02:46:40.752848  2204 sgd_solver.cpp:106] Iteration 949, lr = 0.005
I0403 02:46:50.044711  2204 solver.cpp:228] Iteration 962, loss = 0.00724393
I0403 02:46:50.051237  2204 solver.cpp:244]     Train net output #0: loss = 0.00724398 (* 1 = 0.00724398 loss)
I0403 02:46:50.225685  2204 sgd_solver.cpp:106] Iteration 962, lr = 0.005
I0403 02:46:59.528734  2204 solver.cpp:228] Iteration 975, loss = 0.0576554
I0403 02:46:59.536119  2204 solver.cpp:244]     Train net output #0: loss = 0.0576555 (* 1 = 0.0576555 loss)
I0403 02:46:59.726740  2204 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 02:47:08.907392  2204 solver.cpp:228] Iteration 988, loss = 0.0426155
I0403 02:47:08.914697  2204 solver.cpp:244]     Train net output #0: loss = 0.0426156 (* 1 = 0.0426156 loss)
I0403 02:47:09.087355  2204 sgd_solver.cpp:106] Iteration 988, lr = 0.005
I0403 02:47:18.411806  2204 solver.cpp:228] Iteration 1001, loss = 0.0242012
I0403 02:47:18.419845  2204 solver.cpp:244]     Train net output #0: loss = 0.0242013 (* 1 = 0.0242013 loss)
I0403 02:47:18.565798  2204 sgd_solver.cpp:106] Iteration 1001, lr = 0.005
I0403 02:47:27.960305  2204 solver.cpp:228] Iteration 1014, loss = 0.0515016
I0403 02:47:27.967392  2204 solver.cpp:244]     Train net output #0: loss = 0.0515017 (* 1 = 0.0515017 loss)
I0403 02:47:28.139853  2204 sgd_solver.cpp:106] Iteration 1014, lr = 0.005
I0403 02:47:37.394739  2204 solver.cpp:228] Iteration 1027, loss = 0.0531729
I0403 02:47:37.401631  2204 solver.cpp:244]     Train net output #0: loss = 0.0531729 (* 1 = 0.0531729 loss)
I0403 02:47:37.574254  2204 sgd_solver.cpp:106] Iteration 1027, lr = 0.005
I0403 02:47:46.971693  2204 solver.cpp:228] Iteration 1040, loss = 0.136203
I0403 02:47:46.978183  2204 solver.cpp:244]     Train net output #0: loss = 0.136203 (* 1 = 0.136203 loss)
I0403 02:47:47.138520  2204 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:47:56.556538  2204 solver.cpp:228] Iteration 1053, loss = 0.0262778
I0403 02:47:56.563840  2204 solver.cpp:244]     Train net output #0: loss = 0.0262779 (* 1 = 0.0262779 loss)
I0403 02:47:56.751533  2204 sgd_solver.cpp:106] Iteration 1053, lr = 0.005
I0403 02:48:06.029083  2204 solver.cpp:228] Iteration 1066, loss = 0.0348519
I0403 02:48:06.034477  2204 solver.cpp:244]     Train net output #0: loss = 0.0348519 (* 1 = 0.0348519 loss)
I0403 02:48:06.205894  2204 sgd_solver.cpp:106] Iteration 1066, lr = 0.005
I0403 02:48:09.809487  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1072.caffemodel
I0403 02:48:12.427893  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1072.solverstate
I0403 02:48:14.233618  2204 solver.cpp:337] Iteration 1072, Testing net (#0)
I0403 02:49:15.726322  2204 solver.cpp:404]     Test net output #0: accuracy = 0.962373
I0403 02:49:15.735074  2204 solver.cpp:404]     Test net output #1: loss = 0.133167 (* 1 = 0.133167 loss)
I0403 02:49:21.426769  2204 solver.cpp:228] Iteration 1079, loss = 0.0284588
I0403 02:49:21.433431  2204 solver.cpp:244]     Train net output #0: loss = 0.0284589 (* 1 = 0.0284589 loss)
I0403 02:49:21.554957  2204 sgd_solver.cpp:106] Iteration 1079, lr = 0.005
I0403 02:49:30.858438  2204 solver.cpp:228] Iteration 1092, loss = 0.00957821
I0403 02:49:30.864971  2204 solver.cpp:244]     Train net output #0: loss = 0.00957825 (* 1 = 0.00957825 loss)
I0403 02:49:31.038259  2204 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 02:49:40.259635  2204 solver.cpp:228] Iteration 1105, loss = 0.0293801
I0403 02:49:40.265326  2204 solver.cpp:244]     Train net output #0: loss = 0.0293801 (* 1 = 0.0293801 loss)
I0403 02:49:40.441817  2204 sgd_solver.cpp:106] Iteration 1105, lr = 0.005
I0403 02:49:49.622153  2204 solver.cpp:228] Iteration 1118, loss = 0.0113745
I0403 02:49:49.628134  2204 solver.cpp:244]     Train net output #0: loss = 0.0113746 (* 1 = 0.0113746 loss)
I0403 02:49:49.811748  2204 sgd_solver.cpp:106] Iteration 1118, lr = 0.005
I0403 02:49:59.005964  2204 solver.cpp:228] Iteration 1131, loss = 0.0128269
I0403 02:49:59.012066  2204 solver.cpp:244]     Train net output #0: loss = 0.012827 (* 1 = 0.012827 loss)
I0403 02:49:59.200422  2204 sgd_solver.cpp:106] Iteration 1131, lr = 0.005
I0403 02:50:08.442114  2204 solver.cpp:228] Iteration 1144, loss = 0.0910312
I0403 02:50:08.448654  2204 solver.cpp:244]     Train net output #0: loss = 0.0910312 (* 1 = 0.0910312 loss)
I0403 02:50:08.686089  2204 sgd_solver.cpp:106] Iteration 1144, lr = 0.005
I0403 02:50:18.060070  2204 solver.cpp:228] Iteration 1157, loss = 0.0324293
I0403 02:50:18.066751  2204 solver.cpp:244]     Train net output #0: loss = 0.0324293 (* 1 = 0.0324293 loss)
I0403 02:50:18.235074  2204 sgd_solver.cpp:106] Iteration 1157, lr = 0.005
I0403 02:50:27.779278  2204 solver.cpp:228] Iteration 1170, loss = 0.00508976
I0403 02:50:27.785862  2204 solver.cpp:244]     Train net output #0: loss = 0.00508979 (* 1 = 0.00508979 loss)
I0403 02:50:27.999194  2204 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 02:50:37.219147  2204 solver.cpp:228] Iteration 1183, loss = 0.0631488
I0403 02:50:37.225147  2204 solver.cpp:244]     Train net output #0: loss = 0.0631488 (* 1 = 0.0631488 loss)
I0403 02:50:37.439860  2204 sgd_solver.cpp:106] Iteration 1183, lr = 0.005
I0403 02:50:46.731976  2204 solver.cpp:228] Iteration 1196, loss = 0.0437964
I0403 02:50:46.738293  2204 solver.cpp:244]     Train net output #0: loss = 0.0437965 (* 1 = 0.0437965 loss)
I0403 02:50:46.905340  2204 sgd_solver.cpp:106] Iteration 1196, lr = 0.005
I0403 02:50:56.188979  2204 solver.cpp:228] Iteration 1209, loss = 0.0239502
I0403 02:50:56.195947  2204 solver.cpp:244]     Train net output #0: loss = 0.0239502 (* 1 = 0.0239502 loss)
I0403 02:50:56.378608  2204 sgd_solver.cpp:106] Iteration 1209, lr = 0.005
I0403 02:51:05.632833  2204 solver.cpp:228] Iteration 1222, loss = 0.0256848
I0403 02:51:05.639613  2204 solver.cpp:244]     Train net output #0: loss = 0.0256849 (* 1 = 0.0256849 loss)
I0403 02:51:05.813880  2204 sgd_solver.cpp:106] Iteration 1222, lr = 0.005
I0403 02:51:15.043323  2204 solver.cpp:228] Iteration 1235, loss = 0.0098711
I0403 02:51:15.049525  2204 solver.cpp:244]     Train net output #0: loss = 0.00987114 (* 1 = 0.00987114 loss)
I0403 02:51:15.242944  2204 sgd_solver.cpp:106] Iteration 1235, lr = 0.005
I0403 02:51:24.711724  2204 solver.cpp:228] Iteration 1248, loss = 0.035643
I0403 02:51:24.717425  2204 solver.cpp:244]     Train net output #0: loss = 0.0356431 (* 1 = 0.0356431 loss)
I0403 02:51:24.986790  2204 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 02:51:34.254643  2204 solver.cpp:228] Iteration 1261, loss = 0.0733761
I0403 02:51:34.261091  2204 solver.cpp:244]     Train net output #0: loss = 0.0733761 (* 1 = 0.0733761 loss)
I0403 02:51:34.443235  2204 sgd_solver.cpp:106] Iteration 1261, lr = 0.005
I0403 02:51:43.700333  2204 solver.cpp:228] Iteration 1274, loss = 0.0510788
I0403 02:51:43.707350  2204 solver.cpp:244]     Train net output #0: loss = 0.0510788 (* 1 = 0.0510788 loss)
I0403 02:51:43.900243  2204 sgd_solver.cpp:106] Iteration 1274, lr = 0.005
I0403 02:51:53.146869  2204 solver.cpp:228] Iteration 1287, loss = 0.00668317
I0403 02:51:53.152110  2204 solver.cpp:244]     Train net output #0: loss = 0.00668322 (* 1 = 0.00668322 loss)
I0403 02:51:53.386428  2204 sgd_solver.cpp:106] Iteration 1287, lr = 0.005
I0403 02:52:02.682072  2204 solver.cpp:228] Iteration 1300, loss = 0.0323714
I0403 02:52:02.688366  2204 solver.cpp:244]     Train net output #0: loss = 0.0323714 (* 1 = 0.0323714 loss)
I0403 02:52:02.882552  2204 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 02:52:12.390362  2204 solver.cpp:228] Iteration 1313, loss = 0.0787321
I0403 02:52:12.396569  2204 solver.cpp:244]     Train net output #0: loss = 0.0787322 (* 1 = 0.0787322 loss)
I0403 02:52:12.569073  2204 sgd_solver.cpp:106] Iteration 1313, lr = 0.005
I0403 02:52:21.753768  2204 solver.cpp:228] Iteration 1326, loss = 0.0151842
I0403 02:52:21.759268  2204 solver.cpp:244]     Train net output #0: loss = 0.0151843 (* 1 = 0.0151843 loss)
I0403 02:52:21.958463  2204 sgd_solver.cpp:106] Iteration 1326, lr = 0.005
I0403 02:52:31.213264  2204 solver.cpp:228] Iteration 1339, loss = 0.023157
I0403 02:52:31.220069  2204 solver.cpp:244]     Train net output #0: loss = 0.023157 (* 1 = 0.023157 loss)
I0403 02:52:31.394368  2204 sgd_solver.cpp:106] Iteration 1339, lr = 0.005
I0403 02:52:31.394600  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1340.caffemodel
I0403 02:52:34.142712  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1340.solverstate
I0403 02:52:36.066754  2204 solver.cpp:337] Iteration 1340, Testing net (#0)
I0403 02:53:37.552803  2204 solver.cpp:404]     Test net output #0: accuracy = 0.971935
I0403 02:53:37.559978  2204 solver.cpp:404]     Test net output #1: loss = 0.0950461 (* 1 = 0.0950461 loss)
I0403 02:53:46.781474  2204 solver.cpp:228] Iteration 1352, loss = 0.0114294
I0403 02:53:46.787981  2204 solver.cpp:244]     Train net output #0: loss = 0.0114295 (* 1 = 0.0114295 loss)
I0403 02:53:46.981297  2204 sgd_solver.cpp:106] Iteration 1352, lr = 0.005
I0403 02:53:56.234393  2204 solver.cpp:228] Iteration 1365, loss = 0.00413229
I0403 02:53:56.239642  2204 solver.cpp:244]     Train net output #0: loss = 0.00413235 (* 1 = 0.00413235 loss)
I0403 02:53:56.469629  2204 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 02:54:05.810616  2204 solver.cpp:228] Iteration 1378, loss = 0.0401373
I0403 02:54:05.816169  2204 solver.cpp:244]     Train net output #0: loss = 0.0401373 (* 1 = 0.0401373 loss)
I0403 02:54:06.013229  2204 sgd_solver.cpp:106] Iteration 1378, lr = 0.005
I0403 02:54:15.277437  2204 solver.cpp:228] Iteration 1391, loss = 0.0439807
I0403 02:54:15.283643  2204 solver.cpp:244]     Train net output #0: loss = 0.0439808 (* 1 = 0.0439808 loss)
I0403 02:54:15.428596  2204 sgd_solver.cpp:106] Iteration 1391, lr = 0.005
I0403 02:54:24.894902  2204 solver.cpp:228] Iteration 1404, loss = 0.0297495
I0403 02:54:24.901216  2204 solver.cpp:244]     Train net output #0: loss = 0.0297495 (* 1 = 0.0297495 loss)
I0403 02:54:25.059008  2204 sgd_solver.cpp:106] Iteration 1404, lr = 0.005
I0403 02:54:34.360385  2204 solver.cpp:228] Iteration 1417, loss = 0.0287709
I0403 02:54:34.367285  2204 solver.cpp:244]     Train net output #0: loss = 0.028771 (* 1 = 0.028771 loss)
I0403 02:54:34.539795  2204 sgd_solver.cpp:106] Iteration 1417, lr = 0.005
I0403 02:54:43.870637  2204 solver.cpp:228] Iteration 1430, loss = 0.00696598
I0403 02:54:43.877035  2204 solver.cpp:244]     Train net output #0: loss = 0.00696605 (* 1 = 0.00696605 loss)
I0403 02:54:44.036478  2204 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 02:54:53.301868  2204 solver.cpp:228] Iteration 1443, loss = 0.0751394
I0403 02:54:53.309134  2204 solver.cpp:244]     Train net output #0: loss = 0.0751395 (* 1 = 0.0751395 loss)
I0403 02:54:53.480707  2204 sgd_solver.cpp:106] Iteration 1443, lr = 0.005
I0403 02:55:02.763679  2204 solver.cpp:228] Iteration 1456, loss = 0.0151032
I0403 02:55:02.769418  2204 solver.cpp:244]     Train net output #0: loss = 0.0151033 (* 1 = 0.0151033 loss)
I0403 02:55:02.943418  2204 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 02:55:12.231166  2204 solver.cpp:228] Iteration 1469, loss = 0.0530653
I0403 02:55:12.237725  2204 solver.cpp:244]     Train net output #0: loss = 0.0530654 (* 1 = 0.0530654 loss)
I0403 02:55:12.430064  2204 sgd_solver.cpp:106] Iteration 1469, lr = 0.005
I0403 02:55:21.826645  2204 solver.cpp:228] Iteration 1482, loss = 0.0205606
I0403 02:55:21.832284  2204 solver.cpp:244]     Train net output #0: loss = 0.0205606 (* 1 = 0.0205606 loss)
I0403 02:55:21.976330  2204 sgd_solver.cpp:106] Iteration 1482, lr = 0.005
I0403 02:55:31.460562  2204 solver.cpp:228] Iteration 1495, loss = 0.00941355
I0403 02:55:31.466850  2204 solver.cpp:244]     Train net output #0: loss = 0.00941362 (* 1 = 0.00941362 loss)
I0403 02:55:31.644984  2204 sgd_solver.cpp:106] Iteration 1495, lr = 0.005
I0403 02:55:40.880018  2204 solver.cpp:228] Iteration 1508, loss = 0.0460934
I0403 02:55:40.885496  2204 solver.cpp:244]     Train net output #0: loss = 0.0460935 (* 1 = 0.0460935 loss)
I0403 02:55:41.067718  2204 sgd_solver.cpp:106] Iteration 1508, lr = 0.005
I0403 02:55:50.659797  2204 solver.cpp:228] Iteration 1521, loss = 0.0288913
I0403 02:55:50.666131  2204 solver.cpp:244]     Train net output #0: loss = 0.0288914 (* 1 = 0.0288914 loss)
I0403 02:55:50.847270  2204 sgd_solver.cpp:106] Iteration 1521, lr = 0.005
I0403 02:56:00.153882  2204 solver.cpp:228] Iteration 1534, loss = 0.00992608
I0403 02:56:00.159976  2204 solver.cpp:244]     Train net output #0: loss = 0.00992615 (* 1 = 0.00992615 loss)
I0403 02:56:00.333477  2204 sgd_solver.cpp:106] Iteration 1534, lr = 0.005
I0403 02:56:09.583884  2204 solver.cpp:228] Iteration 1547, loss = 0.0318626
I0403 02:56:09.591330  2204 solver.cpp:244]     Train net output #0: loss = 0.0318627 (* 1 = 0.0318627 loss)
I0403 02:56:09.764484  2204 sgd_solver.cpp:106] Iteration 1547, lr = 0.005
I0403 02:56:18.974817  2204 solver.cpp:228] Iteration 1560, loss = 0.0974243
I0403 02:56:18.982349  2204 solver.cpp:244]     Train net output #0: loss = 0.0974244 (* 1 = 0.0974244 loss)
I0403 02:56:19.151432  2204 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 02:56:28.467773  2204 solver.cpp:228] Iteration 1573, loss = 0.0102981
I0403 02:56:28.472723  2204 solver.cpp:244]     Train net output #0: loss = 0.0102981 (* 1 = 0.0102981 loss)
I0403 02:56:28.646488  2204 sgd_solver.cpp:106] Iteration 1573, lr = 0.005
I0403 02:56:37.883488  2204 solver.cpp:228] Iteration 1586, loss = 0.0219347
I0403 02:56:37.888852  2204 solver.cpp:244]     Train net output #0: loss = 0.0219347 (* 1 = 0.0219347 loss)
I0403 02:56:38.033038  2204 sgd_solver.cpp:106] Iteration 1586, lr = 0.005
I0403 02:56:47.348142  2204 solver.cpp:228] Iteration 1599, loss = 0.0159678
I0403 02:56:47.357689  2204 solver.cpp:244]     Train net output #0: loss = 0.0159679 (* 1 = 0.0159679 loss)
I0403 02:56:47.560761  2204 sgd_solver.cpp:106] Iteration 1599, lr = 0.005
I0403 02:56:53.312427  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1608.caffemodel
I0403 02:56:56.088691  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1608.solverstate
I0403 02:56:58.010239  2204 solver.cpp:337] Iteration 1608, Testing net (#0)
I0403 02:57:59.501451  2204 solver.cpp:404]     Test net output #0: accuracy = 0.974088
I0403 02:57:59.508494  2204 solver.cpp:404]     Test net output #1: loss = 0.0916348 (* 1 = 0.0916348 loss)
I0403 02:58:02.904481  2204 solver.cpp:228] Iteration 1612, loss = 0.0257806
I0403 02:58:02.910432  2204 solver.cpp:244]     Train net output #0: loss = 0.0257807 (* 1 = 0.0257807 loss)
I0403 02:58:03.099455  2204 sgd_solver.cpp:106] Iteration 1612, lr = 0.005
I0403 02:58:12.212158  2204 solver.cpp:228] Iteration 1625, loss = 0.00165673
I0403 02:58:12.219276  2204 solver.cpp:244]     Train net output #0: loss = 0.0016568 (* 1 = 0.0016568 loss)
I0403 02:58:12.476244  2204 sgd_solver.cpp:106] Iteration 1625, lr = 0.005
I0403 02:58:21.632946  2204 solver.cpp:228] Iteration 1638, loss = 0.0200984
I0403 02:58:21.639206  2204 solver.cpp:244]     Train net output #0: loss = 0.0200985 (* 1 = 0.0200985 loss)
I0403 02:58:21.802495  2204 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 02:58:31.100453  2204 solver.cpp:228] Iteration 1651, loss = 0.0123297
I0403 02:58:31.106992  2204 solver.cpp:244]     Train net output #0: loss = 0.0123298 (* 1 = 0.0123298 loss)
I0403 02:58:31.282815  2204 sgd_solver.cpp:106] Iteration 1651, lr = 0.005
I0403 02:58:40.493871  2204 solver.cpp:228] Iteration 1664, loss = 0.00692796
I0403 02:58:40.500335  2204 solver.cpp:244]     Train net output #0: loss = 0.00692802 (* 1 = 0.00692802 loss)
I0403 02:58:40.690783  2204 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 02:58:49.981813  2204 solver.cpp:228] Iteration 1677, loss = 0.0234752
I0403 02:58:49.987819  2204 solver.cpp:244]     Train net output #0: loss = 0.0234753 (* 1 = 0.0234753 loss)
I0403 02:58:50.216241  2204 sgd_solver.cpp:106] Iteration 1677, lr = 0.005
I0403 02:58:59.580914  2204 solver.cpp:228] Iteration 1690, loss = 0.0964987
I0403 02:58:59.586629  2204 solver.cpp:244]     Train net output #0: loss = 0.0964988 (* 1 = 0.0964988 loss)
I0403 02:58:59.741646  2204 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 02:59:09.261843  2204 solver.cpp:228] Iteration 1703, loss = 0.0478403
I0403 02:59:09.268255  2204 solver.cpp:244]     Train net output #0: loss = 0.0478404 (* 1 = 0.0478404 loss)
I0403 02:59:09.424716  2204 sgd_solver.cpp:106] Iteration 1703, lr = 0.005
I0403 02:59:18.881747  2204 solver.cpp:228] Iteration 1716, loss = 0.090347
I0403 02:59:18.886553  2204 solver.cpp:244]     Train net output #0: loss = 0.0903471 (* 1 = 0.0903471 loss)
I0403 02:59:19.102360  2204 sgd_solver.cpp:106] Iteration 1716, lr = 0.005
I0403 02:59:28.396854  2204 solver.cpp:228] Iteration 1729, loss = 0.0162143
I0403 02:59:28.403436  2204 solver.cpp:244]     Train net output #0: loss = 0.0162143 (* 1 = 0.0162143 loss)
I0403 02:59:28.626724  2204 sgd_solver.cpp:106] Iteration 1729, lr = 0.005
I0403 02:59:37.964881  2204 solver.cpp:228] Iteration 1742, loss = 0.0188269
I0403 02:59:37.970868  2204 solver.cpp:244]     Train net output #0: loss = 0.0188269 (* 1 = 0.0188269 loss)
I0403 02:59:38.175838  2204 sgd_solver.cpp:106] Iteration 1742, lr = 0.005
I0403 02:59:47.401027  2204 solver.cpp:228] Iteration 1755, loss = 0.0184283
I0403 02:59:47.406509  2204 solver.cpp:244]     Train net output #0: loss = 0.0184284 (* 1 = 0.0184284 loss)
I0403 02:59:47.605913  2204 sgd_solver.cpp:106] Iteration 1755, lr = 0.005
I0403 02:59:57.054582  2204 solver.cpp:228] Iteration 1768, loss = 0.00759696
I0403 02:59:57.060206  2204 solver.cpp:244]     Train net output #0: loss = 0.00759702 (* 1 = 0.00759702 loss)
I0403 02:59:57.246707  2204 sgd_solver.cpp:106] Iteration 1768, lr = 0.005
I0403 03:00:06.501257  2204 solver.cpp:228] Iteration 1781, loss = 0.0161542
I0403 03:00:06.507288  2204 solver.cpp:244]     Train net output #0: loss = 0.0161543 (* 1 = 0.0161543 loss)
I0403 03:00:06.706450  2204 sgd_solver.cpp:106] Iteration 1781, lr = 0.005
I0403 03:00:15.970288  2204 solver.cpp:228] Iteration 1794, loss = 0.0310321
I0403 03:00:15.976992  2204 solver.cpp:244]     Train net output #0: loss = 0.0310322 (* 1 = 0.0310322 loss)
I0403 03:00:16.152891  2204 sgd_solver.cpp:106] Iteration 1794, lr = 0.005
I0403 03:00:25.359820  2204 solver.cpp:228] Iteration 1807, loss = 0.00599926
I0403 03:00:25.366698  2204 solver.cpp:244]     Train net output #0: loss = 0.00599933 (* 1 = 0.00599933 loss)
I0403 03:00:25.540711  2204 sgd_solver.cpp:106] Iteration 1807, lr = 0.005
I0403 03:00:34.744473  2204 solver.cpp:228] Iteration 1820, loss = 0.0289617
I0403 03:00:34.749475  2204 solver.cpp:244]     Train net output #0: loss = 0.0289618 (* 1 = 0.0289618 loss)
I0403 03:00:34.937796  2204 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 03:00:44.168954  2204 solver.cpp:228] Iteration 1833, loss = 0.00183347
I0403 03:00:44.175582  2204 solver.cpp:244]     Train net output #0: loss = 0.00183353 (* 1 = 0.00183353 loss)
I0403 03:00:44.349954  2204 sgd_solver.cpp:106] Iteration 1833, lr = 0.005
I0403 03:00:53.695262  2204 solver.cpp:228] Iteration 1846, loss = 0.0721037
I0403 03:00:53.701588  2204 solver.cpp:244]     Train net output #0: loss = 0.0721038 (* 1 = 0.0721038 loss)
I0403 03:00:53.867851  2204 sgd_solver.cpp:106] Iteration 1846, lr = 0.005
I0403 03:01:03.159672  2204 solver.cpp:228] Iteration 1859, loss = 0.0144399
I0403 03:01:03.165685  2204 solver.cpp:244]     Train net output #0: loss = 0.01444 (* 1 = 0.01444 loss)
I0403 03:01:03.359907  2204 sgd_solver.cpp:106] Iteration 1859, lr = 0.005
I0403 03:01:12.702105  2204 solver.cpp:228] Iteration 1872, loss = 0.0237951
I0403 03:01:12.708902  2204 solver.cpp:244]     Train net output #0: loss = 0.0237951 (* 1 = 0.0237951 loss)
I0403 03:01:12.890821  2204 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 03:01:15.085162  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1876.caffemodel
I0403 03:01:17.724948  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_1876.solverstate
I0403 03:01:19.513022  2204 solver.cpp:337] Iteration 1876, Testing net (#0)
I0403 03:02:20.995587  2204 solver.cpp:404]     Test net output #0: accuracy = 0.976168
I0403 03:02:21.002106  2204 solver.cpp:404]     Test net output #1: loss = 0.0845201 (* 1 = 0.0845201 loss)
I0403 03:02:28.025518  2204 solver.cpp:228] Iteration 1885, loss = 0.013676
I0403 03:02:28.032157  2204 solver.cpp:244]     Train net output #0: loss = 0.013676 (* 1 = 0.013676 loss)
I0403 03:02:28.235679  2204 sgd_solver.cpp:106] Iteration 1885, lr = 0.005
I0403 03:02:37.549852  2204 solver.cpp:228] Iteration 1898, loss = 0.0155198
I0403 03:02:37.555961  2204 solver.cpp:244]     Train net output #0: loss = 0.0155199 (* 1 = 0.0155199 loss)
I0403 03:02:37.737265  2204 sgd_solver.cpp:106] Iteration 1898, lr = 0.005
I0403 03:02:46.969266  2204 solver.cpp:228] Iteration 1911, loss = 0.0395181
I0403 03:02:46.975653  2204 solver.cpp:244]     Train net output #0: loss = 0.0395181 (* 1 = 0.0395181 loss)
I0403 03:02:47.148777  2204 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 03:02:56.419695  2204 solver.cpp:228] Iteration 1924, loss = 0.0637029
I0403 03:02:56.427132  2204 solver.cpp:244]     Train net output #0: loss = 0.0637029 (* 1 = 0.0637029 loss)
I0403 03:02:56.636366  2204 sgd_solver.cpp:106] Iteration 1924, lr = 0.005
I0403 03:03:05.891309  2204 solver.cpp:228] Iteration 1937, loss = 0.0408643
I0403 03:03:05.897405  2204 solver.cpp:244]     Train net output #0: loss = 0.0408644 (* 1 = 0.0408644 loss)
I0403 03:03:06.053112  2204 sgd_solver.cpp:106] Iteration 1937, lr = 0.005
I0403 03:03:15.434259  2204 solver.cpp:228] Iteration 1950, loss = 0.00843491
I0403 03:03:15.441540  2204 solver.cpp:244]     Train net output #0: loss = 0.00843498 (* 1 = 0.00843498 loss)
I0403 03:03:15.613401  2204 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 03:03:25.291679  2204 solver.cpp:228] Iteration 1963, loss = 0.00325287
I0403 03:03:25.298370  2204 solver.cpp:244]     Train net output #0: loss = 0.00325294 (* 1 = 0.00325294 loss)
I0403 03:03:25.526530  2204 sgd_solver.cpp:106] Iteration 1963, lr = 0.005
I0403 03:03:34.734376  2204 solver.cpp:228] Iteration 1976, loss = 0.0105913
I0403 03:03:34.740813  2204 solver.cpp:244]     Train net output #0: loss = 0.0105914 (* 1 = 0.0105914 loss)
I0403 03:03:34.914091  2204 sgd_solver.cpp:106] Iteration 1976, lr = 0.005
I0403 03:03:44.230556  2204 solver.cpp:228] Iteration 1989, loss = 0.0387375
I0403 03:03:44.237175  2204 solver.cpp:244]     Train net output #0: loss = 0.0387376 (* 1 = 0.0387376 loss)
I0403 03:03:44.399229  2204 sgd_solver.cpp:106] Iteration 1989, lr = 0.005
I0403 03:03:53.631867  2204 solver.cpp:228] Iteration 2002, loss = 0.0525534
I0403 03:03:53.638402  2204 solver.cpp:244]     Train net output #0: loss = 0.0525535 (* 1 = 0.0525535 loss)
I0403 03:03:53.855718  2204 sgd_solver.cpp:106] Iteration 2002, lr = 0.005
I0403 03:04:03.112972  2204 solver.cpp:228] Iteration 2015, loss = 0.0141832
I0403 03:04:03.119130  2204 solver.cpp:244]     Train net output #0: loss = 0.0141833 (* 1 = 0.0141833 loss)
I0403 03:04:03.270900  2204 sgd_solver.cpp:106] Iteration 2015, lr = 0.005
I0403 03:04:12.873381  2204 solver.cpp:228] Iteration 2028, loss = 0.0100996
I0403 03:04:12.880211  2204 solver.cpp:244]     Train net output #0: loss = 0.0100997 (* 1 = 0.0100997 loss)
I0403 03:04:13.095648  2204 sgd_solver.cpp:106] Iteration 2028, lr = 0.005
I0403 03:04:22.390769  2204 solver.cpp:228] Iteration 2041, loss = 0.0141843
I0403 03:04:22.396057  2204 solver.cpp:244]     Train net output #0: loss = 0.0141844 (* 1 = 0.0141844 loss)
I0403 03:04:22.571959  2204 sgd_solver.cpp:106] Iteration 2041, lr = 0.005
I0403 03:04:31.821385  2204 solver.cpp:228] Iteration 2054, loss = 0.0044186
I0403 03:04:31.827889  2204 solver.cpp:244]     Train net output #0: loss = 0.0044187 (* 1 = 0.0044187 loss)
I0403 03:04:32.050321  2204 sgd_solver.cpp:106] Iteration 2054, lr = 0.005
I0403 03:04:41.440296  2204 solver.cpp:228] Iteration 2067, loss = 0.00928225
I0403 03:04:41.447188  2204 solver.cpp:244]     Train net output #0: loss = 0.00928234 (* 1 = 0.00928234 loss)
I0403 03:04:41.618649  2204 sgd_solver.cpp:106] Iteration 2067, lr = 0.005
I0403 03:04:51.033887  2204 solver.cpp:228] Iteration 2080, loss = 0.0150265
I0403 03:04:51.040591  2204 solver.cpp:244]     Train net output #0: loss = 0.0150266 (* 1 = 0.0150266 loss)
I0403 03:04:51.236304  2204 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:05:00.687721  2204 solver.cpp:228] Iteration 2093, loss = 0.00731961
I0403 03:05:00.694221  2204 solver.cpp:244]     Train net output #0: loss = 0.0073197 (* 1 = 0.0073197 loss)
I0403 03:05:00.796314  2204 sgd_solver.cpp:106] Iteration 2093, lr = 0.005
I0403 03:05:10.324390  2204 solver.cpp:228] Iteration 2106, loss = 0.0330449
I0403 03:05:10.331395  2204 solver.cpp:244]     Train net output #0: loss = 0.033045 (* 1 = 0.033045 loss)
I0403 03:05:10.509523  2204 sgd_solver.cpp:106] Iteration 2106, lr = 0.005
I0403 03:05:19.555887  2204 solver.cpp:228] Iteration 2119, loss = 0.0291126
I0403 03:05:19.562095  2204 solver.cpp:244]     Train net output #0: loss = 0.0291127 (* 1 = 0.0291127 loss)
I0403 03:05:19.743167  2204 sgd_solver.cpp:106] Iteration 2119, lr = 0.005
I0403 03:05:29.085116  2204 solver.cpp:228] Iteration 2132, loss = 0.00270833
I0403 03:05:29.089874  2204 solver.cpp:244]     Train net output #0: loss = 0.00270841 (* 1 = 0.00270841 loss)
I0403 03:05:29.284922  2204 sgd_solver.cpp:106] Iteration 2132, lr = 0.005
I0403 03:05:37.229746  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2144.caffemodel
I0403 03:05:40.009533  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2144.solverstate
I0403 03:05:41.929419  2204 solver.cpp:337] Iteration 2144, Testing net (#0)
I0403 03:06:43.420559  2204 solver.cpp:404]     Test net output #0: accuracy = 0.980475
I0403 03:06:43.427507  2204 solver.cpp:404]     Test net output #1: loss = 0.069769 (* 1 = 0.069769 loss)
I0403 03:06:44.658898  2204 solver.cpp:228] Iteration 2145, loss = 0.00754056
I0403 03:06:44.664916  2204 solver.cpp:244]     Train net output #0: loss = 0.00754064 (* 1 = 0.00754064 loss)
I0403 03:06:44.866287  2204 sgd_solver.cpp:106] Iteration 2145, lr = 0.005
I0403 03:06:54.249261  2204 solver.cpp:228] Iteration 2158, loss = 0.0158651
I0403 03:06:54.255059  2204 solver.cpp:244]     Train net output #0: loss = 0.0158651 (* 1 = 0.0158651 loss)
I0403 03:06:54.433534  2204 sgd_solver.cpp:106] Iteration 2158, lr = 0.005
I0403 03:07:03.692277  2204 solver.cpp:228] Iteration 2171, loss = 0.025085
I0403 03:07:03.698544  2204 solver.cpp:244]     Train net output #0: loss = 0.0250851 (* 1 = 0.0250851 loss)
I0403 03:07:03.880108  2204 sgd_solver.cpp:106] Iteration 2171, lr = 0.005
I0403 03:07:13.324530  2204 solver.cpp:228] Iteration 2184, loss = 0.000963006
I0403 03:07:13.331115  2204 solver.cpp:244]     Train net output #0: loss = 0.000963101 (* 1 = 0.000963101 loss)
I0403 03:07:13.506219  2204 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 03:07:22.958549  2204 solver.cpp:228] Iteration 2197, loss = 0.00812817
I0403 03:07:22.964576  2204 solver.cpp:244]     Train net output #0: loss = 0.00812826 (* 1 = 0.00812826 loss)
I0403 03:07:23.139977  2204 sgd_solver.cpp:106] Iteration 2197, lr = 0.005
I0403 03:07:32.505952  2204 solver.cpp:228] Iteration 2210, loss = 0.000722047
I0403 03:07:32.512753  2204 solver.cpp:244]     Train net output #0: loss = 0.000722136 (* 1 = 0.000722136 loss)
I0403 03:07:32.649904  2204 sgd_solver.cpp:106] Iteration 2210, lr = 0.005
I0403 03:07:42.088770  2204 solver.cpp:228] Iteration 2223, loss = 0.0295876
I0403 03:07:42.095365  2204 solver.cpp:244]     Train net output #0: loss = 0.0295877 (* 1 = 0.0295877 loss)
I0403 03:07:42.303141  2204 sgd_solver.cpp:106] Iteration 2223, lr = 0.005
I0403 03:07:51.559422  2204 solver.cpp:228] Iteration 2236, loss = 0.00295088
I0403 03:07:51.566804  2204 solver.cpp:244]     Train net output #0: loss = 0.00295097 (* 1 = 0.00295097 loss)
I0403 03:07:51.758201  2204 sgd_solver.cpp:106] Iteration 2236, lr = 0.005
I0403 03:08:01.043673  2204 solver.cpp:228] Iteration 2249, loss = 0.00276872
I0403 03:08:01.050603  2204 solver.cpp:244]     Train net output #0: loss = 0.00276881 (* 1 = 0.00276881 loss)
I0403 03:08:01.206431  2204 sgd_solver.cpp:106] Iteration 2249, lr = 0.005
I0403 03:08:10.546751  2204 solver.cpp:228] Iteration 2262, loss = 0.0433421
I0403 03:08:10.553298  2204 solver.cpp:244]     Train net output #0: loss = 0.0433422 (* 1 = 0.0433422 loss)
I0403 03:08:10.741713  2204 sgd_solver.cpp:106] Iteration 2262, lr = 0.005
I0403 03:08:20.032245  2204 solver.cpp:228] Iteration 2275, loss = 0.001179
I0403 03:08:20.038020  2204 solver.cpp:244]     Train net output #0: loss = 0.00117908 (* 1 = 0.00117908 loss)
I0403 03:08:20.245631  2204 sgd_solver.cpp:106] Iteration 2275, lr = 0.005
I0403 03:08:29.573006  2204 solver.cpp:228] Iteration 2288, loss = 0.00345616
I0403 03:08:29.580085  2204 solver.cpp:244]     Train net output #0: loss = 0.00345624 (* 1 = 0.00345624 loss)
I0403 03:08:29.774103  2204 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 03:08:39.258934  2204 solver.cpp:228] Iteration 2301, loss = 0.0142562
I0403 03:08:39.265457  2204 solver.cpp:244]     Train net output #0: loss = 0.0142562 (* 1 = 0.0142562 loss)
I0403 03:08:39.453651  2204 sgd_solver.cpp:106] Iteration 2301, lr = 0.005
I0403 03:08:48.676297  2204 solver.cpp:228] Iteration 2314, loss = 0.0158967
I0403 03:08:48.682577  2204 solver.cpp:244]     Train net output #0: loss = 0.0158968 (* 1 = 0.0158968 loss)
I0403 03:08:48.861873  2204 sgd_solver.cpp:106] Iteration 2314, lr = 0.005
I0403 03:08:58.155618  2204 solver.cpp:228] Iteration 2327, loss = 0.0295105
I0403 03:08:58.161249  2204 solver.cpp:244]     Train net output #0: loss = 0.0295106 (* 1 = 0.0295106 loss)
I0403 03:08:58.342443  2204 sgd_solver.cpp:106] Iteration 2327, lr = 0.005
I0403 03:09:07.682342  2204 solver.cpp:228] Iteration 2340, loss = 0.0015404
I0403 03:09:07.687899  2204 solver.cpp:244]     Train net output #0: loss = 0.00154046 (* 1 = 0.00154046 loss)
I0403 03:09:07.871006  2204 sgd_solver.cpp:106] Iteration 2340, lr = 0.005
I0403 03:09:17.115998  2204 solver.cpp:228] Iteration 2353, loss = 0.0173929
I0403 03:09:17.122809  2204 solver.cpp:244]     Train net output #0: loss = 0.017393 (* 1 = 0.017393 loss)
I0403 03:09:17.299723  2204 sgd_solver.cpp:106] Iteration 2353, lr = 0.005
I0403 03:09:26.463835  2204 solver.cpp:228] Iteration 2366, loss = 0.00751305
I0403 03:09:26.470899  2204 solver.cpp:244]     Train net output #0: loss = 0.00751311 (* 1 = 0.00751311 loss)
I0403 03:09:26.670965  2204 sgd_solver.cpp:106] Iteration 2366, lr = 0.005
I0403 03:09:35.931041  2204 solver.cpp:228] Iteration 2379, loss = 0.0332786
I0403 03:09:35.936492  2204 solver.cpp:244]     Train net output #0: loss = 0.0332786 (* 1 = 0.0332786 loss)
I0403 03:09:36.112814  2204 sgd_solver.cpp:106] Iteration 2379, lr = 0.005
I0403 03:09:45.763304  2204 solver.cpp:228] Iteration 2392, loss = 0.0109018
I0403 03:09:45.769700  2204 solver.cpp:244]     Train net output #0: loss = 0.0109019 (* 1 = 0.0109019 loss)
I0403 03:09:45.962901  2204 sgd_solver.cpp:106] Iteration 2392, lr = 0.005
I0403 03:09:55.195616  2204 solver.cpp:228] Iteration 2405, loss = 0.00258695
I0403 03:09:55.202589  2204 solver.cpp:244]     Train net output #0: loss = 0.002587 (* 1 = 0.002587 loss)
I0403 03:09:55.395714  2204 sgd_solver.cpp:106] Iteration 2405, lr = 0.005
I0403 03:09:59.788415  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2412.caffemodel
I0403 03:10:02.632349  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2412.solverstate
I0403 03:10:04.415657  2204 solver.cpp:337] Iteration 2412, Testing net (#0)
I0403 03:11:05.898718  2204 solver.cpp:404]     Test net output #0: accuracy = 0.981278
I0403 03:11:05.905709  2204 solver.cpp:404]     Test net output #1: loss = 0.0662713 (* 1 = 0.0662713 loss)
I0403 03:11:10.871117  2204 solver.cpp:228] Iteration 2418, loss = 0.000592423
I0403 03:11:10.877454  2204 solver.cpp:244]     Train net output #0: loss = 0.000592471 (* 1 = 0.000592471 loss)
I0403 03:11:11.118284  2204 sgd_solver.cpp:106] Iteration 2418, lr = 0.005
I0403 03:11:20.399441  2204 solver.cpp:228] Iteration 2431, loss = 0.000604589
I0403 03:11:20.405026  2204 solver.cpp:244]     Train net output #0: loss = 0.000604641 (* 1 = 0.000604641 loss)
I0403 03:11:20.603179  2204 sgd_solver.cpp:106] Iteration 2431, lr = 0.005
I0403 03:11:29.893196  2204 solver.cpp:228] Iteration 2444, loss = 0.0108964
I0403 03:11:29.899538  2204 solver.cpp:244]     Train net output #0: loss = 0.0108964 (* 1 = 0.0108964 loss)
I0403 03:11:30.050284  2204 sgd_solver.cpp:106] Iteration 2444, lr = 0.005
I0403 03:11:39.410490  2204 solver.cpp:228] Iteration 2457, loss = 0.000411535
I0403 03:11:39.416798  2204 solver.cpp:244]     Train net output #0: loss = 0.000411588 (* 1 = 0.000411588 loss)
I0403 03:11:39.592811  2204 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 03:11:48.974545  2204 solver.cpp:228] Iteration 2470, loss = 0.0364459
I0403 03:11:48.980804  2204 solver.cpp:244]     Train net output #0: loss = 0.0364459 (* 1 = 0.0364459 loss)
I0403 03:11:49.167554  2204 sgd_solver.cpp:106] Iteration 2470, lr = 0.005
I0403 03:11:58.422185  2204 solver.cpp:228] Iteration 2483, loss = 0.101468
I0403 03:11:58.428771  2204 solver.cpp:244]     Train net output #0: loss = 0.101468 (* 1 = 0.101468 loss)
I0403 03:11:58.655367  2204 sgd_solver.cpp:106] Iteration 2483, lr = 0.005
I0403 03:12:08.012609  2204 solver.cpp:228] Iteration 2496, loss = 0.0080984
I0403 03:12:08.018820  2204 solver.cpp:244]     Train net output #0: loss = 0.00809846 (* 1 = 0.00809846 loss)
I0403 03:12:08.199375  2204 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 03:12:17.532367  2204 solver.cpp:228] Iteration 2509, loss = 0.118737
I0403 03:12:17.538931  2204 solver.cpp:244]     Train net output #0: loss = 0.118737 (* 1 = 0.118737 loss)
I0403 03:12:17.715981  2204 sgd_solver.cpp:106] Iteration 2509, lr = 0.005
I0403 03:12:26.931547  2204 solver.cpp:228] Iteration 2522, loss = 0.00855725
I0403 03:12:26.938392  2204 solver.cpp:244]     Train net output #0: loss = 0.00855731 (* 1 = 0.00855731 loss)
I0403 03:12:27.112701  2204 sgd_solver.cpp:106] Iteration 2522, lr = 0.005
I0403 03:12:36.477336  2204 solver.cpp:228] Iteration 2535, loss = 0.0013167
I0403 03:12:36.483942  2204 solver.cpp:244]     Train net output #0: loss = 0.00131676 (* 1 = 0.00131676 loss)
I0403 03:12:36.619645  2204 sgd_solver.cpp:106] Iteration 2535, lr = 0.005
I0403 03:12:46.074887  2204 solver.cpp:228] Iteration 2548, loss = 0.00398909
I0403 03:12:46.080828  2204 solver.cpp:244]     Train net output #0: loss = 0.00398914 (* 1 = 0.00398914 loss)
I0403 03:12:46.248862  2204 sgd_solver.cpp:106] Iteration 2548, lr = 0.005
I0403 03:12:55.489078  2204 solver.cpp:228] Iteration 2561, loss = 0.00965704
I0403 03:12:55.495913  2204 solver.cpp:244]     Train net output #0: loss = 0.00965709 (* 1 = 0.00965709 loss)
I0403 03:12:55.678005  2204 sgd_solver.cpp:106] Iteration 2561, lr = 0.005
I0403 03:13:05.035889  2204 solver.cpp:228] Iteration 2574, loss = 0.0339254
I0403 03:13:05.044777  2204 solver.cpp:244]     Train net output #0: loss = 0.0339254 (* 1 = 0.0339254 loss)
I0403 03:13:05.247084  2204 sgd_solver.cpp:106] Iteration 2574, lr = 0.005
I0403 03:13:14.611825  2204 solver.cpp:228] Iteration 2587, loss = 0.000754056
I0403 03:13:14.618351  2204 solver.cpp:244]     Train net output #0: loss = 0.000754102 (* 1 = 0.000754102 loss)
I0403 03:13:14.805088  2204 sgd_solver.cpp:106] Iteration 2587, lr = 0.005
I0403 03:13:24.219631  2204 solver.cpp:228] Iteration 2600, loss = 0.00313418
I0403 03:13:24.225697  2204 solver.cpp:244]     Train net output #0: loss = 0.00313422 (* 1 = 0.00313422 loss)
I0403 03:13:24.394496  2204 sgd_solver.cpp:106] Iteration 2600, lr = 0.005
I0403 03:13:34.010038  2204 solver.cpp:228] Iteration 2613, loss = 0.00342556
I0403 03:13:34.016875  2204 solver.cpp:244]     Train net output #0: loss = 0.0034256 (* 1 = 0.0034256 loss)
I0403 03:13:34.189085  2204 sgd_solver.cpp:106] Iteration 2613, lr = 0.005
I0403 03:13:43.562070  2204 solver.cpp:228] Iteration 2626, loss = 0.0480831
I0403 03:13:43.569267  2204 solver.cpp:244]     Train net output #0: loss = 0.0480831 (* 1 = 0.0480831 loss)
I0403 03:13:43.758429  2204 sgd_solver.cpp:106] Iteration 2626, lr = 0.005
I0403 03:13:52.983969  2204 solver.cpp:228] Iteration 2639, loss = 0.00615203
I0403 03:13:52.990000  2204 solver.cpp:244]     Train net output #0: loss = 0.00615208 (* 1 = 0.00615208 loss)
I0403 03:13:53.165946  2204 sgd_solver.cpp:106] Iteration 2639, lr = 0.005
I0403 03:14:02.496788  2204 solver.cpp:228] Iteration 2652, loss = 0.0016531
I0403 03:14:02.503234  2204 solver.cpp:244]     Train net output #0: loss = 0.00165314 (* 1 = 0.00165314 loss)
I0403 03:14:02.699213  2204 sgd_solver.cpp:106] Iteration 2652, lr = 0.005
I0403 03:14:12.000133  2204 solver.cpp:228] Iteration 2665, loss = 0.0366392
I0403 03:14:12.006014  2204 solver.cpp:244]     Train net output #0: loss = 0.0366392 (* 1 = 0.0366392 loss)
I0403 03:14:12.163002  2204 sgd_solver.cpp:106] Iteration 2665, lr = 0.005
I0403 03:14:21.383249  2204 solver.cpp:228] Iteration 2678, loss = 0.00853047
I0403 03:14:21.389446  2204 solver.cpp:244]     Train net output #0: loss = 0.00853052 (* 1 = 0.00853052 loss)
I0403 03:14:21.586737  2204 sgd_solver.cpp:106] Iteration 2678, lr = 0.005
I0403 03:14:22.294217  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2680.caffemodel
I0403 03:14:24.942800  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2680.solverstate
I0403 03:14:26.712726  2204 solver.cpp:337] Iteration 2680, Testing net (#0)
I0403 03:15:28.192445  2204 solver.cpp:404]     Test net output #0: accuracy = 0.978869
I0403 03:15:28.198760  2204 solver.cpp:404]     Test net output #1: loss = 0.0770457 (* 1 = 0.0770457 loss)
I0403 03:15:36.794090  2204 solver.cpp:228] Iteration 2691, loss = 0.0257038
I0403 03:15:36.800462  2204 solver.cpp:244]     Train net output #0: loss = 0.0257038 (* 1 = 0.0257038 loss)
I0403 03:15:37.019556  2204 sgd_solver.cpp:106] Iteration 2691, lr = 0.0005
I0403 03:15:46.205021  2204 solver.cpp:228] Iteration 2704, loss = 0.004939
I0403 03:15:46.210772  2204 solver.cpp:244]     Train net output #0: loss = 0.00493905 (* 1 = 0.00493905 loss)
I0403 03:15:46.486389  2204 sgd_solver.cpp:106] Iteration 2704, lr = 0.0005
I0403 03:15:55.685617  2204 solver.cpp:228] Iteration 2717, loss = 0.00291081
I0403 03:15:55.690429  2204 solver.cpp:244]     Train net output #0: loss = 0.00291085 (* 1 = 0.00291085 loss)
I0403 03:15:55.864013  2204 sgd_solver.cpp:106] Iteration 2717, lr = 0.0005
I0403 03:16:04.976150  2204 solver.cpp:228] Iteration 2730, loss = 0.000393358
I0403 03:16:04.982282  2204 solver.cpp:244]     Train net output #0: loss = 0.000393397 (* 1 = 0.000393397 loss)
I0403 03:16:05.179740  2204 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 03:16:14.359354  2204 solver.cpp:228] Iteration 2743, loss = 0.00204489
I0403 03:16:14.365797  2204 solver.cpp:244]     Train net output #0: loss = 0.00204493 (* 1 = 0.00204493 loss)
I0403 03:16:14.575189  2204 sgd_solver.cpp:106] Iteration 2743, lr = 0.0005
I0403 03:16:23.770350  2204 solver.cpp:228] Iteration 2756, loss = 0.0411665
I0403 03:16:23.776829  2204 solver.cpp:244]     Train net output #0: loss = 0.0411665 (* 1 = 0.0411665 loss)
I0403 03:16:23.965054  2204 sgd_solver.cpp:106] Iteration 2756, lr = 0.0005
I0403 03:16:33.264925  2204 solver.cpp:228] Iteration 2769, loss = 0.000488583
I0403 03:16:33.271519  2204 solver.cpp:244]     Train net output #0: loss = 0.000488621 (* 1 = 0.000488621 loss)
I0403 03:16:33.431382  2204 sgd_solver.cpp:106] Iteration 2769, lr = 0.0005
I0403 03:16:42.673961  2204 solver.cpp:228] Iteration 2782, loss = 0.0560965
I0403 03:16:42.681140  2204 solver.cpp:244]     Train net output #0: loss = 0.0560965 (* 1 = 0.0560965 loss)
I0403 03:16:42.871613  2204 sgd_solver.cpp:106] Iteration 2782, lr = 0.0005
I0403 03:16:52.122745  2204 solver.cpp:228] Iteration 2795, loss = 0.0189494
I0403 03:16:52.129180  2204 solver.cpp:244]     Train net output #0: loss = 0.0189495 (* 1 = 0.0189495 loss)
I0403 03:16:52.327054  2204 sgd_solver.cpp:106] Iteration 2795, lr = 0.0005
I0403 03:17:01.552032  2204 solver.cpp:228] Iteration 2808, loss = 0.00982503
I0403 03:17:01.558245  2204 solver.cpp:244]     Train net output #0: loss = 0.00982506 (* 1 = 0.00982506 loss)
I0403 03:17:01.739485  2204 sgd_solver.cpp:106] Iteration 2808, lr = 0.0005
I0403 03:17:11.002986  2204 solver.cpp:228] Iteration 2821, loss = 0.000914618
I0403 03:17:11.008810  2204 solver.cpp:244]     Train net output #0: loss = 0.000914656 (* 1 = 0.000914656 loss)
I0403 03:17:11.192049  2204 sgd_solver.cpp:106] Iteration 2821, lr = 0.0005
I0403 03:17:20.570225  2204 solver.cpp:228] Iteration 2834, loss = 0.000457246
I0403 03:17:20.577332  2204 solver.cpp:244]     Train net output #0: loss = 0.000457282 (* 1 = 0.000457282 loss)
I0403 03:17:20.749552  2204 sgd_solver.cpp:106] Iteration 2834, lr = 0.0005
I0403 03:17:30.051206  2204 solver.cpp:228] Iteration 2847, loss = 0.000527456
I0403 03:17:30.057080  2204 solver.cpp:244]     Train net output #0: loss = 0.000527492 (* 1 = 0.000527492 loss)
I0403 03:17:30.263972  2204 sgd_solver.cpp:106] Iteration 2847, lr = 0.0005
I0403 03:17:39.695754  2204 solver.cpp:228] Iteration 2860, loss = 0.000792131
I0403 03:17:39.709240  2204 solver.cpp:244]     Train net output #0: loss = 0.000792167 (* 1 = 0.000792167 loss)
I0403 03:17:39.896540  2204 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 03:17:49.386876  2204 solver.cpp:228] Iteration 2873, loss = 0.000373665
I0403 03:17:49.393502  2204 solver.cpp:244]     Train net output #0: loss = 0.000373702 (* 1 = 0.000373702 loss)
I0403 03:17:49.606281  2204 sgd_solver.cpp:106] Iteration 2873, lr = 0.0005
I0403 03:17:59.066817  2204 solver.cpp:228] Iteration 2886, loss = 0.0159796
I0403 03:17:59.072679  2204 solver.cpp:244]     Train net output #0: loss = 0.0159796 (* 1 = 0.0159796 loss)
I0403 03:17:59.195343  2204 sgd_solver.cpp:106] Iteration 2886, lr = 0.0005
I0403 03:18:08.646901  2204 solver.cpp:228] Iteration 2899, loss = 0.000905455
I0403 03:18:08.652494  2204 solver.cpp:244]     Train net output #0: loss = 0.000905492 (* 1 = 0.000905492 loss)
I0403 03:18:08.839637  2204 sgd_solver.cpp:106] Iteration 2899, lr = 0.0005
I0403 03:18:17.988641  2204 solver.cpp:228] Iteration 2912, loss = 0.00740763
I0403 03:18:17.995429  2204 solver.cpp:244]     Train net output #0: loss = 0.00740767 (* 1 = 0.00740767 loss)
I0403 03:18:18.143153  2204 sgd_solver.cpp:106] Iteration 2912, lr = 0.0005
I0403 03:18:27.777304  2204 solver.cpp:228] Iteration 2925, loss = 0.0462932
I0403 03:18:27.783854  2204 solver.cpp:244]     Train net output #0: loss = 0.0462932 (* 1 = 0.0462932 loss)
I0403 03:18:27.898946  2204 sgd_solver.cpp:106] Iteration 2925, lr = 0.0005
I0403 03:18:37.171249  2204 solver.cpp:228] Iteration 2938, loss = 8.36785e-05
I0403 03:18:37.177580  2204 solver.cpp:244]     Train net output #0: loss = 8.37129e-05 (* 1 = 8.37129e-05 loss)
I0403 03:18:37.361491  2204 sgd_solver.cpp:106] Iteration 2938, lr = 0.0005
I0403 03:18:44.073544  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2948.caffemodel
I0403 03:18:46.662120  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_2948.solverstate
I0403 03:18:48.410248  2204 solver.cpp:337] Iteration 2948, Testing net (#0)
I0403 03:19:49.906191  2204 solver.cpp:404]     Test net output #0: accuracy = 0.984672
I0403 03:19:49.913722  2204 solver.cpp:404]     Test net output #1: loss = 0.0576606 (* 1 = 0.0576606 loss)
I0403 03:19:52.633690  2204 solver.cpp:228] Iteration 2951, loss = 0.00121101
I0403 03:19:52.640959  2204 solver.cpp:244]     Train net output #0: loss = 0.00121105 (* 1 = 0.00121105 loss)
I0403 03:19:52.820401  2204 sgd_solver.cpp:106] Iteration 2951, lr = 0.0005
I0403 03:20:02.188146  2204 solver.cpp:228] Iteration 2964, loss = 0.000820497
I0403 03:20:02.195210  2204 solver.cpp:244]     Train net output #0: loss = 0.000820531 (* 1 = 0.000820531 loss)
I0403 03:20:02.406141  2204 sgd_solver.cpp:106] Iteration 2964, lr = 0.0005
I0403 03:20:11.702507  2204 solver.cpp:228] Iteration 2977, loss = 0.00190812
I0403 03:20:11.708168  2204 solver.cpp:244]     Train net output #0: loss = 0.00190815 (* 1 = 0.00190815 loss)
I0403 03:20:11.945852  2204 sgd_solver.cpp:106] Iteration 2977, lr = 0.0005
I0403 03:20:21.267652  2204 solver.cpp:228] Iteration 2990, loss = 0.0446612
I0403 03:20:21.274282  2204 solver.cpp:244]     Train net output #0: loss = 0.0446612 (* 1 = 0.0446612 loss)
I0403 03:20:21.441987  2204 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 03:20:30.829545  2204 solver.cpp:228] Iteration 3003, loss = 0.00171625
I0403 03:20:30.836199  2204 solver.cpp:244]     Train net output #0: loss = 0.00171629 (* 1 = 0.00171629 loss)
I0403 03:20:31.046646  2204 sgd_solver.cpp:106] Iteration 3003, lr = 0.0005
I0403 03:20:40.371624  2204 solver.cpp:228] Iteration 3016, loss = 0.00101324
I0403 03:20:40.377223  2204 solver.cpp:244]     Train net output #0: loss = 0.00101328 (* 1 = 0.00101328 loss)
I0403 03:20:40.537199  2204 sgd_solver.cpp:106] Iteration 3016, lr = 0.0005
I0403 03:20:49.811478  2204 solver.cpp:228] Iteration 3029, loss = 0.0014499
I0403 03:20:49.818238  2204 solver.cpp:244]     Train net output #0: loss = 0.00144994 (* 1 = 0.00144994 loss)
I0403 03:20:50.027431  2204 sgd_solver.cpp:106] Iteration 3029, lr = 0.0005
I0403 03:20:59.363544  2204 solver.cpp:228] Iteration 3042, loss = 0.00456964
I0403 03:20:59.369725  2204 solver.cpp:244]     Train net output #0: loss = 0.00456967 (* 1 = 0.00456967 loss)
I0403 03:20:59.567051  2204 sgd_solver.cpp:106] Iteration 3042, lr = 0.0005
I0403 03:21:08.829396  2204 solver.cpp:228] Iteration 3055, loss = 0.00620837
I0403 03:21:08.835059  2204 solver.cpp:244]     Train net output #0: loss = 0.0062084 (* 1 = 0.0062084 loss)
I0403 03:21:09.046241  2204 sgd_solver.cpp:106] Iteration 3055, lr = 0.0005
I0403 03:21:18.197280  2204 solver.cpp:228] Iteration 3068, loss = 0.00102942
I0403 03:21:18.203690  2204 solver.cpp:244]     Train net output #0: loss = 0.00102946 (* 1 = 0.00102946 loss)
I0403 03:21:18.406416  2204 sgd_solver.cpp:106] Iteration 3068, lr = 0.0005
I0403 03:21:27.785867  2204 solver.cpp:228] Iteration 3081, loss = 0.00895891
I0403 03:21:27.792482  2204 solver.cpp:244]     Train net output #0: loss = 0.00895895 (* 1 = 0.00895895 loss)
I0403 03:21:27.961235  2204 sgd_solver.cpp:106] Iteration 3081, lr = 0.0005
I0403 03:21:37.255513  2204 solver.cpp:228] Iteration 3094, loss = 0.004533
I0403 03:21:37.260282  2204 solver.cpp:244]     Train net output #0: loss = 0.00453303 (* 1 = 0.00453303 loss)
I0403 03:21:37.457747  2204 sgd_solver.cpp:106] Iteration 3094, lr = 0.0005
I0403 03:21:46.720727  2204 solver.cpp:228] Iteration 3107, loss = 0.00585194
I0403 03:21:46.725250  2204 solver.cpp:244]     Train net output #0: loss = 0.00585198 (* 1 = 0.00585198 loss)
I0403 03:21:46.900205  2204 sgd_solver.cpp:106] Iteration 3107, lr = 0.0005
I0403 03:21:56.183037  2204 solver.cpp:228] Iteration 3120, loss = 0.000737574
I0403 03:21:56.188109  2204 solver.cpp:244]     Train net output #0: loss = 0.000737612 (* 1 = 0.000737612 loss)
I0403 03:21:56.371225  2204 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 03:22:05.623188  2204 solver.cpp:228] Iteration 3133, loss = 0.000829199
I0403 03:22:05.630303  2204 solver.cpp:244]     Train net output #0: loss = 0.000829237 (* 1 = 0.000829237 loss)
I0403 03:22:05.811982  2204 sgd_solver.cpp:106] Iteration 3133, lr = 0.0005
I0403 03:22:15.067999  2204 solver.cpp:228] Iteration 3146, loss = 0.000761829
I0403 03:22:15.075255  2204 solver.cpp:244]     Train net output #0: loss = 0.000761867 (* 1 = 0.000761867 loss)
I0403 03:22:15.252910  2204 sgd_solver.cpp:106] Iteration 3146, lr = 0.0005
I0403 03:22:24.447229  2204 solver.cpp:228] Iteration 3159, loss = 0.00402372
I0403 03:22:24.453627  2204 solver.cpp:244]     Train net output #0: loss = 0.00402376 (* 1 = 0.00402376 loss)
I0403 03:22:24.641393  2204 sgd_solver.cpp:106] Iteration 3159, lr = 0.0005
I0403 03:22:33.934587  2204 solver.cpp:228] Iteration 3172, loss = 0.00178173
I0403 03:22:33.939697  2204 solver.cpp:244]     Train net output #0: loss = 0.00178177 (* 1 = 0.00178177 loss)
I0403 03:22:34.135256  2204 sgd_solver.cpp:106] Iteration 3172, lr = 0.0005
I0403 03:22:43.604887  2204 solver.cpp:228] Iteration 3185, loss = 0.000810309
I0403 03:22:43.612738  2204 solver.cpp:244]     Train net output #0: loss = 0.00081035 (* 1 = 0.00081035 loss)
I0403 03:22:43.781579  2204 sgd_solver.cpp:106] Iteration 3185, lr = 0.0005
I0403 03:22:53.092358  2204 solver.cpp:228] Iteration 3198, loss = 0.000590333
I0403 03:22:53.098626  2204 solver.cpp:244]     Train net output #0: loss = 0.000590374 (* 1 = 0.000590374 loss)
I0403 03:22:53.272464  2204 sgd_solver.cpp:106] Iteration 3198, lr = 0.0005
I0403 03:23:02.470088  2204 solver.cpp:228] Iteration 3211, loss = 7.21826e-05
I0403 03:23:02.477442  2204 solver.cpp:244]     Train net output #0: loss = 7.22237e-05 (* 1 = 7.22237e-05 loss)
I0403 03:23:02.716332  2204 sgd_solver.cpp:106] Iteration 3211, lr = 0.0005
I0403 03:23:05.615607  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_3216.caffemodel
I0403 03:23:08.386289  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_3216.solverstate
I0403 03:23:10.299876  2204 solver.cpp:337] Iteration 3216, Testing net (#0)
I0403 03:24:11.789157  2204 solver.cpp:404]     Test net output #0: accuracy = 0.98533
I0403 03:24:11.795936  2204 solver.cpp:404]     Test net output #1: loss = 0.0550352 (* 1 = 0.0550352 loss)
I0403 03:24:18.128278  2204 solver.cpp:228] Iteration 3224, loss = 0.00735362
I0403 03:24:18.134474  2204 solver.cpp:244]     Train net output #0: loss = 0.00735366 (* 1 = 0.00735366 loss)
I0403 03:24:18.334244  2204 sgd_solver.cpp:106] Iteration 3224, lr = 0.0005
I0403 03:24:27.591042  2204 solver.cpp:228] Iteration 3237, loss = 0.00232885
I0403 03:24:27.597012  2204 solver.cpp:244]     Train net output #0: loss = 0.00232889 (* 1 = 0.00232889 loss)
I0403 03:24:27.797935  2204 sgd_solver.cpp:106] Iteration 3237, lr = 0.0005
I0403 03:24:37.140051  2204 solver.cpp:228] Iteration 3250, loss = 0.00123001
I0403 03:24:37.146046  2204 solver.cpp:244]     Train net output #0: loss = 0.00123005 (* 1 = 0.00123005 loss)
I0403 03:24:37.332072  2204 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 03:24:46.641512  2204 solver.cpp:228] Iteration 3263, loss = 0.00360772
I0403 03:24:46.647413  2204 solver.cpp:244]     Train net output #0: loss = 0.00360776 (* 1 = 0.00360776 loss)
I0403 03:24:46.826447  2204 sgd_solver.cpp:106] Iteration 3263, lr = 0.0005
I0403 03:24:56.231606  2204 solver.cpp:228] Iteration 3276, loss = 0.00748267
I0403 03:24:56.238286  2204 solver.cpp:244]     Train net output #0: loss = 0.00748271 (* 1 = 0.00748271 loss)
I0403 03:24:56.372475  2204 sgd_solver.cpp:106] Iteration 3276, lr = 0.0005
I0403 03:25:05.874048  2204 solver.cpp:228] Iteration 3289, loss = 0.000963489
I0403 03:25:05.880103  2204 solver.cpp:244]     Train net output #0: loss = 0.000963529 (* 1 = 0.000963529 loss)
I0403 03:25:06.068539  2204 sgd_solver.cpp:106] Iteration 3289, lr = 0.0005
I0403 03:25:15.262325  2204 solver.cpp:228] Iteration 3302, loss = 0.0141606
I0403 03:25:15.267457  2204 solver.cpp:244]     Train net output #0: loss = 0.0141606 (* 1 = 0.0141606 loss)
I0403 03:25:15.459167  2204 sgd_solver.cpp:106] Iteration 3302, lr = 0.0005
I0403 03:25:24.820780  2204 solver.cpp:228] Iteration 3315, loss = 0.000596039
I0403 03:25:24.829880  2204 solver.cpp:244]     Train net output #0: loss = 0.000596079 (* 1 = 0.000596079 loss)
I0403 03:25:24.963906  2204 sgd_solver.cpp:106] Iteration 3315, lr = 0.0005
I0403 03:25:34.335180  2204 solver.cpp:228] Iteration 3328, loss = 0.000490437
I0403 03:25:34.342216  2204 solver.cpp:244]     Train net output #0: loss = 0.000490478 (* 1 = 0.000490478 loss)
I0403 03:25:34.526561  2204 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 03:25:43.807301  2204 solver.cpp:228] Iteration 3341, loss = 0.00131828
I0403 03:25:43.813534  2204 solver.cpp:244]     Train net output #0: loss = 0.00131832 (* 1 = 0.00131832 loss)
I0403 03:25:44.018095  2204 sgd_solver.cpp:106] Iteration 3341, lr = 0.0005
I0403 03:25:53.331992  2204 solver.cpp:228] Iteration 3354, loss = 0.000816351
I0403 03:25:53.340234  2204 solver.cpp:244]     Train net output #0: loss = 0.000816392 (* 1 = 0.000816392 loss)
I0403 03:25:53.546942  2204 sgd_solver.cpp:106] Iteration 3354, lr = 0.0005
I0403 03:26:02.750725  2204 solver.cpp:228] Iteration 3367, loss = 0.013198
I0403 03:26:02.757213  2204 solver.cpp:244]     Train net output #0: loss = 0.0131981 (* 1 = 0.0131981 loss)
I0403 03:26:02.915369  2204 sgd_solver.cpp:106] Iteration 3367, lr = 0.0005
I0403 03:26:12.348037  2204 solver.cpp:228] Iteration 3380, loss = 0.0001826
I0403 03:26:12.353899  2204 solver.cpp:244]     Train net output #0: loss = 0.000182641 (* 1 = 0.000182641 loss)
I0403 03:26:12.517482  2204 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 03:26:21.750902  2204 solver.cpp:228] Iteration 3393, loss = 0.00134708
I0403 03:26:21.757552  2204 solver.cpp:244]     Train net output #0: loss = 0.00134712 (* 1 = 0.00134712 loss)
I0403 03:26:21.950090  2204 sgd_solver.cpp:106] Iteration 3393, lr = 0.0005
I0403 03:26:31.297533  2204 solver.cpp:228] Iteration 3406, loss = 0.00134755
I0403 03:26:31.303947  2204 solver.cpp:244]     Train net output #0: loss = 0.00134759 (* 1 = 0.00134759 loss)
I0403 03:26:31.449064  2204 sgd_solver.cpp:106] Iteration 3406, lr = 0.0005
I0403 03:26:41.074877  2204 solver.cpp:228] Iteration 3419, loss = 0.00675556
I0403 03:26:41.082096  2204 solver.cpp:244]     Train net output #0: loss = 0.0067556 (* 1 = 0.0067556 loss)
I0403 03:26:41.269450  2204 sgd_solver.cpp:106] Iteration 3419, lr = 0.0005
I0403 03:26:50.492095  2204 solver.cpp:228] Iteration 3432, loss = 0.0130449
I0403 03:26:50.497707  2204 solver.cpp:244]     Train net output #0: loss = 0.013045 (* 1 = 0.013045 loss)
I0403 03:26:50.695406  2204 sgd_solver.cpp:106] Iteration 3432, lr = 0.0005
I0403 03:27:00.189522  2204 solver.cpp:228] Iteration 3445, loss = 0.00527317
I0403 03:27:00.195574  2204 solver.cpp:244]     Train net output #0: loss = 0.00527321 (* 1 = 0.00527321 loss)
I0403 03:27:00.366333  2204 sgd_solver.cpp:106] Iteration 3445, lr = 0.0005
I0403 03:27:09.749526  2204 solver.cpp:228] Iteration 3458, loss = 0.0038217
I0403 03:27:09.756288  2204 solver.cpp:244]     Train net output #0: loss = 0.00382174 (* 1 = 0.00382174 loss)
I0403 03:27:09.900799  2204 sgd_solver.cpp:106] Iteration 3458, lr = 0.0005
I0403 03:27:19.201282  2204 solver.cpp:228] Iteration 3471, loss = 0.00565268
I0403 03:27:19.208457  2204 solver.cpp:244]     Train net output #0: loss = 0.00565272 (* 1 = 0.00565272 loss)
I0403 03:27:19.406358  2204 sgd_solver.cpp:106] Iteration 3471, lr = 0.0005
I0403 03:27:28.099056  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_3484.caffemodel
I0403 03:27:30.853364  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_3484.solverstate
I0403 03:27:32.760960  2204 solver.cpp:337] Iteration 3484, Testing net (#0)
I0403 03:28:34.247443  2204 solver.cpp:404]     Test net output #0: accuracy = 0.985658
I0403 03:28:34.254562  2204 solver.cpp:404]     Test net output #1: loss = 0.0542802 (* 1 = 0.0542802 loss)
I0403 03:28:34.764493  2204 solver.cpp:228] Iteration 3484, loss = 0.00130751
I0403 03:28:34.770550  2204 solver.cpp:244]     Train net output #0: loss = 0.00130755 (* 1 = 0.00130755 loss)
I0403 03:28:34.947603  2204 sgd_solver.cpp:106] Iteration 3484, lr = 0.0005
I0403 03:28:44.290941  2204 solver.cpp:228] Iteration 3497, loss = 0.0233145
I0403 03:28:44.296303  2204 solver.cpp:244]     Train net output #0: loss = 0.0233145 (* 1 = 0.0233145 loss)
I0403 03:28:44.502509  2204 sgd_solver.cpp:106] Iteration 3497, lr = 0.0005
I0403 03:28:53.801523  2204 solver.cpp:228] Iteration 3510, loss = 0.00012298
I0403 03:28:53.808190  2204 solver.cpp:244]     Train net output #0: loss = 0.000123018 (* 1 = 0.000123018 loss)
I0403 03:28:53.994631  2204 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 03:29:03.321811  2204 solver.cpp:228] Iteration 3523, loss = 0.00530377
I0403 03:29:03.327574  2204 solver.cpp:244]     Train net output #0: loss = 0.00530381 (* 1 = 0.00530381 loss)
I0403 03:29:03.566884  2204 sgd_solver.cpp:106] Iteration 3523, lr = 0.0005
I0403 03:29:12.918141  2204 solver.cpp:228] Iteration 3536, loss = 0.00109171
I0403 03:29:12.925292  2204 solver.cpp:244]     Train net output #0: loss = 0.00109175 (* 1 = 0.00109175 loss)
I0403 03:29:13.141672  2204 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 03:29:22.422796  2204 solver.cpp:228] Iteration 3549, loss = 0.0319504
I0403 03:29:22.428690  2204 solver.cpp:244]     Train net output #0: loss = 0.0319504 (* 1 = 0.0319504 loss)
I0403 03:29:22.611863  2204 sgd_solver.cpp:106] Iteration 3549, lr = 0.0005
I0403 03:29:31.829588  2204 solver.cpp:228] Iteration 3562, loss = 0.00504519
I0403 03:29:31.835286  2204 solver.cpp:244]     Train net output #0: loss = 0.00504523 (* 1 = 0.00504523 loss)
I0403 03:29:32.036468  2204 sgd_solver.cpp:106] Iteration 3562, lr = 0.0005
I0403 03:29:41.285063  2204 solver.cpp:228] Iteration 3575, loss = 0.000597228
I0403 03:29:41.291972  2204 solver.cpp:244]     Train net output #0: loss = 0.000597265 (* 1 = 0.000597265 loss)
I0403 03:29:41.464166  2204 sgd_solver.cpp:106] Iteration 3575, lr = 0.0005
I0403 03:29:50.755642  2204 solver.cpp:228] Iteration 3588, loss = 0.0244953
I0403 03:29:50.762035  2204 solver.cpp:244]     Train net output #0: loss = 0.0244953 (* 1 = 0.0244953 loss)
I0403 03:29:50.938467  2204 sgd_solver.cpp:106] Iteration 3588, lr = 0.0005
I0403 03:30:00.123852  2204 solver.cpp:228] Iteration 3601, loss = 0.000825643
I0403 03:30:00.130715  2204 solver.cpp:244]     Train net output #0: loss = 0.000825677 (* 1 = 0.000825677 loss)
I0403 03:30:00.335808  2204 sgd_solver.cpp:106] Iteration 3601, lr = 0.0005
I0403 03:30:09.743371  2204 solver.cpp:228] Iteration 3614, loss = 0.000777098
I0403 03:30:09.749524  2204 solver.cpp:244]     Train net output #0: loss = 0.000777133 (* 1 = 0.000777133 loss)
I0403 03:30:09.921282  2204 sgd_solver.cpp:106] Iteration 3614, lr = 0.0005
I0403 03:30:19.165941  2204 solver.cpp:228] Iteration 3627, loss = 0.00469235
I0403 03:30:19.173347  2204 solver.cpp:244]     Train net output #0: loss = 0.00469239 (* 1 = 0.00469239 loss)
I0403 03:30:19.367224  2204 sgd_solver.cpp:106] Iteration 3627, lr = 0.0005
I0403 03:30:28.495755  2204 solver.cpp:228] Iteration 3640, loss = 0.0132249
I0403 03:30:28.504552  2204 solver.cpp:244]     Train net output #0: loss = 0.0132249 (* 1 = 0.0132249 loss)
I0403 03:30:28.692986  2204 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 03:30:37.912645  2204 solver.cpp:228] Iteration 3653, loss = 0.00182352
I0403 03:30:37.919497  2204 solver.cpp:244]     Train net output #0: loss = 0.00182356 (* 1 = 0.00182356 loss)
I0403 03:30:38.109390  2204 sgd_solver.cpp:106] Iteration 3653, lr = 0.0005
I0403 03:30:47.449848  2204 solver.cpp:228] Iteration 3666, loss = 0.000911507
I0403 03:30:47.456990  2204 solver.cpp:244]     Train net output #0: loss = 0.000911544 (* 1 = 0.000911544 loss)
I0403 03:30:47.635614  2204 sgd_solver.cpp:106] Iteration 3666, lr = 0.0005
I0403 03:30:56.837157  2204 solver.cpp:228] Iteration 3679, loss = 9.72794e-05
I0403 03:30:56.842218  2204 solver.cpp:244]     Train net output #0: loss = 9.73163e-05 (* 1 = 9.73163e-05 loss)
I0403 03:30:56.990591  2204 sgd_solver.cpp:106] Iteration 3679, lr = 0.0005
I0403 03:31:06.312149  2204 solver.cpp:228] Iteration 3692, loss = 0.00173743
I0403 03:31:06.319553  2204 solver.cpp:244]     Train net output #0: loss = 0.00173747 (* 1 = 0.00173747 loss)
I0403 03:31:06.519500  2204 sgd_solver.cpp:106] Iteration 3692, lr = 0.0005
I0403 03:31:15.783347  2204 solver.cpp:228] Iteration 3705, loss = 0.0149171
I0403 03:31:15.789660  2204 solver.cpp:244]     Train net output #0: loss = 0.0149171 (* 1 = 0.0149171 loss)
I0403 03:31:15.968998  2204 sgd_solver.cpp:106] Iteration 3705, lr = 0.0005
I0403 03:31:25.300349  2204 solver.cpp:228] Iteration 3718, loss = 0.000809828
I0403 03:31:25.306277  2204 solver.cpp:244]     Train net output #0: loss = 0.000809865 (* 1 = 0.000809865 loss)
I0403 03:31:25.551481  2204 sgd_solver.cpp:106] Iteration 3718, lr = 0.0005
I0403 03:31:34.893609  2204 solver.cpp:228] Iteration 3731, loss = 0.00307472
I0403 03:31:34.899041  2204 solver.cpp:244]     Train net output #0: loss = 0.00307475 (* 1 = 0.00307475 loss)
I0403 03:31:35.060219  2204 sgd_solver.cpp:106] Iteration 3731, lr = 0.0005
I0403 03:31:44.323403  2204 solver.cpp:228] Iteration 3744, loss = 0.000364805
I0403 03:31:44.328971  2204 solver.cpp:244]     Train net output #0: loss = 0.000364841 (* 1 = 0.000364841 loss)
I0403 03:31:44.513694  2204 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 03:31:49.629102  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_3752.caffemodel
I0403 03:31:52.460968  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_3752.solverstate
I0403 03:31:54.349721  2204 solver.cpp:337] Iteration 3752, Testing net (#0)
I0403 03:32:55.864694  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986023
I0403 03:32:55.870576  2204 solver.cpp:404]     Test net output #1: loss = 0.0527508 (* 1 = 0.0527508 loss)
I0403 03:33:00.003865  2204 solver.cpp:228] Iteration 3757, loss = 0.000663586
I0403 03:33:00.011391  2204 solver.cpp:244]     Train net output #0: loss = 0.000663622 (* 1 = 0.000663622 loss)
I0403 03:33:00.235692  2204 sgd_solver.cpp:106] Iteration 3757, lr = 0.0005
I0403 03:33:09.452227  2204 solver.cpp:228] Iteration 3770, loss = 0.000739047
I0403 03:33:09.458827  2204 solver.cpp:244]     Train net output #0: loss = 0.000739085 (* 1 = 0.000739085 loss)
I0403 03:33:09.676368  2204 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 03:33:18.935489  2204 solver.cpp:228] Iteration 3783, loss = 0.00237998
I0403 03:33:18.941716  2204 solver.cpp:244]     Train net output #0: loss = 0.00238002 (* 1 = 0.00238002 loss)
I0403 03:33:19.085561  2204 sgd_solver.cpp:106] Iteration 3783, lr = 0.0005
I0403 03:33:28.296515  2204 solver.cpp:228] Iteration 3796, loss = 0.0072906
I0403 03:33:28.303366  2204 solver.cpp:244]     Train net output #0: loss = 0.00729063 (* 1 = 0.00729063 loss)
I0403 03:33:28.485502  2204 sgd_solver.cpp:106] Iteration 3796, lr = 0.0005
I0403 03:33:37.603027  2204 solver.cpp:228] Iteration 3809, loss = 0.0014877
I0403 03:33:37.610528  2204 solver.cpp:244]     Train net output #0: loss = 0.00148773 (* 1 = 0.00148773 loss)
I0403 03:33:37.783080  2204 sgd_solver.cpp:106] Iteration 3809, lr = 0.0005
I0403 03:33:46.884804  2204 solver.cpp:228] Iteration 3822, loss = 0.00115905
I0403 03:33:46.892413  2204 solver.cpp:244]     Train net output #0: loss = 0.00115909 (* 1 = 0.00115909 loss)
I0403 03:33:47.073310  2204 sgd_solver.cpp:106] Iteration 3822, lr = 0.0005
I0403 03:33:56.262439  2204 solver.cpp:228] Iteration 3835, loss = 0.000571287
I0403 03:33:56.268111  2204 solver.cpp:244]     Train net output #0: loss = 0.000571319 (* 1 = 0.000571319 loss)
I0403 03:33:56.441154  2204 sgd_solver.cpp:106] Iteration 3835, lr = 0.0005
I0403 03:34:05.597466  2204 solver.cpp:228] Iteration 3848, loss = 0.00274545
I0403 03:34:05.597842  2204 solver.cpp:244]     Train net output #0: loss = 0.00274548 (* 1 = 0.00274548 loss)
I0403 03:34:05.791249  2204 sgd_solver.cpp:106] Iteration 3848, lr = 0.0005
I0403 03:34:15.129004  2204 solver.cpp:228] Iteration 3861, loss = 0.00020916
I0403 03:34:15.129109  2204 solver.cpp:244]     Train net output #0: loss = 0.000209192 (* 1 = 0.000209192 loss)
I0403 03:34:15.289834  2204 sgd_solver.cpp:106] Iteration 3861, lr = 0.0005
I0403 03:34:24.655783  2204 solver.cpp:228] Iteration 3874, loss = 0.00105607
I0403 03:34:24.655900  2204 solver.cpp:244]     Train net output #0: loss = 0.0010561 (* 1 = 0.0010561 loss)
I0403 03:34:24.839612  2204 sgd_solver.cpp:106] Iteration 3874, lr = 0.0005
I0403 03:34:34.128038  2204 solver.cpp:228] Iteration 3887, loss = 0.00017488
I0403 03:34:34.128139  2204 solver.cpp:244]     Train net output #0: loss = 0.000174912 (* 1 = 0.000174912 loss)
I0403 03:34:34.303010  2204 sgd_solver.cpp:106] Iteration 3887, lr = 0.0005
I0403 03:34:43.601747  2204 solver.cpp:228] Iteration 3900, loss = 0.000154704
I0403 03:34:43.602100  2204 solver.cpp:244]     Train net output #0: loss = 0.000154736 (* 1 = 0.000154736 loss)
I0403 03:34:43.789455  2204 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 03:34:52.877075  2204 solver.cpp:228] Iteration 3913, loss = 0.0012727
I0403 03:34:52.877178  2204 solver.cpp:244]     Train net output #0: loss = 0.00127273 (* 1 = 0.00127273 loss)
I0403 03:34:53.053968  2204 sgd_solver.cpp:106] Iteration 3913, lr = 0.0005
I0403 03:35:02.192611  2204 solver.cpp:228] Iteration 3926, loss = 3.2414e-05
I0403 03:35:02.192715  2204 solver.cpp:244]     Train net output #0: loss = 3.24461e-05 (* 1 = 3.24461e-05 loss)
I0403 03:35:02.368152  2204 sgd_solver.cpp:106] Iteration 3926, lr = 0.0005
I0403 03:35:12.042878  2204 solver.cpp:228] Iteration 3939, loss = 0.000648142
I0403 03:35:12.051928  2204 solver.cpp:244]     Train net output #0: loss = 0.000648174 (* 1 = 0.000648174 loss)
I0403 03:35:12.234969  2204 sgd_solver.cpp:106] Iteration 3939, lr = 0.0005
I0403 03:35:21.584398  2204 solver.cpp:228] Iteration 3952, loss = 0.00115034
I0403 03:35:21.584713  2204 solver.cpp:244]     Train net output #0: loss = 0.00115037 (* 1 = 0.00115037 loss)
I0403 03:35:21.796651  2204 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 03:35:31.096801  2204 solver.cpp:228] Iteration 3965, loss = 0.000576421
I0403 03:35:31.096914  2204 solver.cpp:244]     Train net output #0: loss = 0.000576453 (* 1 = 0.000576453 loss)
I0403 03:35:31.310775  2204 sgd_solver.cpp:106] Iteration 3965, lr = 0.0005
I0403 03:35:40.579941  2204 solver.cpp:228] Iteration 3978, loss = 0.000717664
I0403 03:35:40.580060  2204 solver.cpp:244]     Train net output #0: loss = 0.000717696 (* 1 = 0.000717696 loss)
I0403 03:35:40.762465  2204 sgd_solver.cpp:106] Iteration 3978, lr = 0.0005
I0403 03:35:50.039326  2204 solver.cpp:228] Iteration 3991, loss = 0.000250674
I0403 03:35:50.039441  2204 solver.cpp:244]     Train net output #0: loss = 0.000250704 (* 1 = 0.000250704 loss)
I0403 03:35:50.220499  2204 sgd_solver.cpp:106] Iteration 3991, lr = 0.0005
I0403 03:35:59.529991  2204 solver.cpp:228] Iteration 4004, loss = 0.000647052
I0403 03:35:59.530308  2204 solver.cpp:244]     Train net output #0: loss = 0.000647081 (* 1 = 0.000647081 loss)
I0403 03:35:59.633747  2204 sgd_solver.cpp:106] Iteration 4004, lr = 0.0005
I0403 03:36:09.106551  2204 solver.cpp:228] Iteration 4017, loss = 7.85987e-05
I0403 03:36:09.106667  2204 solver.cpp:244]     Train net output #0: loss = 7.86283e-05 (* 1 = 7.86283e-05 loss)
I0403 03:36:09.295745  2204 sgd_solver.cpp:106] Iteration 4017, lr = 0.0005
I0403 03:36:10.722699  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4020.caffemodel
I0403 03:36:13.382988  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4020.solverstate
I0403 03:36:15.120781  2204 solver.cpp:337] Iteration 4020, Testing net (#0)
I0403 03:37:16.606472  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986498
I0403 03:37:16.606845  2204 solver.cpp:404]     Test net output #1: loss = 0.054363 (* 1 = 0.054363 loss)
I0403 03:37:24.493245  2204 solver.cpp:228] Iteration 4030, loss = 0.000436509
I0403 03:37:24.493347  2204 solver.cpp:244]     Train net output #0: loss = 0.000436538 (* 1 = 0.000436538 loss)
I0403 03:37:24.666023  2204 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 03:37:34.062937  2204 solver.cpp:228] Iteration 4043, loss = 0.00107365
I0403 03:37:34.063040  2204 solver.cpp:244]     Train net output #0: loss = 0.00107368 (* 1 = 0.00107368 loss)
I0403 03:37:34.232298  2204 sgd_solver.cpp:106] Iteration 4043, lr = 0.0005
I0403 03:37:43.720263  2204 solver.cpp:228] Iteration 4056, loss = 0.00813302
I0403 03:37:43.720371  2204 solver.cpp:244]     Train net output #0: loss = 0.00813305 (* 1 = 0.00813305 loss)
I0403 03:37:43.903738  2204 sgd_solver.cpp:106] Iteration 4056, lr = 0.0005
I0403 03:37:53.193086  2204 solver.cpp:228] Iteration 4069, loss = 0.00130468
I0403 03:37:53.193433  2204 solver.cpp:244]     Train net output #0: loss = 0.00130471 (* 1 = 0.00130471 loss)
I0403 03:37:53.413849  2204 sgd_solver.cpp:106] Iteration 4069, lr = 0.0005
I0403 03:38:02.738813  2204 solver.cpp:228] Iteration 4082, loss = 0.00153993
I0403 03:38:02.738924  2204 solver.cpp:244]     Train net output #0: loss = 0.00153996 (* 1 = 0.00153996 loss)
I0403 03:38:02.945322  2204 sgd_solver.cpp:106] Iteration 4082, lr = 0.0005
I0403 03:38:12.197021  2204 solver.cpp:228] Iteration 4095, loss = 0.0026446
I0403 03:38:12.197137  2204 solver.cpp:244]     Train net output #0: loss = 0.00264463 (* 1 = 0.00264463 loss)
I0403 03:38:12.401556  2204 sgd_solver.cpp:106] Iteration 4095, lr = 0.0005
I0403 03:38:21.722383  2204 solver.cpp:228] Iteration 4108, loss = 0.00088923
I0403 03:38:21.722486  2204 solver.cpp:244]     Train net output #0: loss = 0.000889262 (* 1 = 0.000889262 loss)
I0403 03:38:21.902066  2204 sgd_solver.cpp:106] Iteration 4108, lr = 0.0005
I0403 03:38:31.159807  2204 solver.cpp:228] Iteration 4121, loss = 0.00139539
I0403 03:38:31.160143  2204 solver.cpp:244]     Train net output #0: loss = 0.00139542 (* 1 = 0.00139542 loss)
I0403 03:38:31.362419  2204 sgd_solver.cpp:106] Iteration 4121, lr = 0.0005
I0403 03:38:40.615262  2204 solver.cpp:228] Iteration 4134, loss = 0.00138388
I0403 03:38:40.615378  2204 solver.cpp:244]     Train net output #0: loss = 0.00138391 (* 1 = 0.00138391 loss)
I0403 03:38:40.799749  2204 sgd_solver.cpp:106] Iteration 4134, lr = 0.0005
I0403 03:38:50.205327  2204 solver.cpp:228] Iteration 4147, loss = 0.00142161
I0403 03:38:50.205443  2204 solver.cpp:244]     Train net output #0: loss = 0.00142164 (* 1 = 0.00142164 loss)
I0403 03:38:50.392971  2204 sgd_solver.cpp:106] Iteration 4147, lr = 0.0005
I0403 03:38:59.735237  2204 solver.cpp:228] Iteration 4160, loss = 0.000548856
I0403 03:38:59.735348  2204 solver.cpp:244]     Train net output #0: loss = 0.000548888 (* 1 = 0.000548888 loss)
I0403 03:38:59.913153  2204 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:39:09.234145  2204 solver.cpp:228] Iteration 4173, loss = 0.0107927
I0403 03:39:09.234480  2204 solver.cpp:244]     Train net output #0: loss = 0.0107928 (* 1 = 0.0107928 loss)
I0403 03:39:09.419883  2204 sgd_solver.cpp:106] Iteration 4173, lr = 0.0005
I0403 03:39:18.649921  2204 solver.cpp:228] Iteration 4186, loss = 0.0020508
I0403 03:39:18.650032  2204 solver.cpp:244]     Train net output #0: loss = 0.00205083 (* 1 = 0.00205083 loss)
I0403 03:39:18.847342  2204 sgd_solver.cpp:106] Iteration 4186, lr = 0.0005
I0403 03:39:28.261637  2204 solver.cpp:228] Iteration 4199, loss = 0.00655527
I0403 03:39:28.261752  2204 solver.cpp:244]     Train net output #0: loss = 0.0065553 (* 1 = 0.0065553 loss)
I0403 03:39:28.522122  2204 sgd_solver.cpp:106] Iteration 4199, lr = 0.0005
I0403 03:39:37.924116  2204 solver.cpp:228] Iteration 4212, loss = 0.000493607
I0403 03:39:37.924226  2204 solver.cpp:244]     Train net output #0: loss = 0.00049364 (* 1 = 0.00049364 loss)
I0403 03:39:38.078570  2204 sgd_solver.cpp:106] Iteration 4212, lr = 0.0005
I0403 03:39:47.492450  2204 solver.cpp:228] Iteration 4225, loss = 0.00375171
I0403 03:39:47.492828  2204 solver.cpp:244]     Train net output #0: loss = 0.00375175 (* 1 = 0.00375175 loss)
I0403 03:39:47.766599  2204 sgd_solver.cpp:106] Iteration 4225, lr = 0.0005
I0403 03:39:56.983227  2204 solver.cpp:228] Iteration 4238, loss = 0.00166392
I0403 03:39:56.983335  2204 solver.cpp:244]     Train net output #0: loss = 0.00166395 (* 1 = 0.00166395 loss)
I0403 03:39:57.170202  2204 sgd_solver.cpp:106] Iteration 4238, lr = 0.0005
I0403 03:40:06.431277  2204 solver.cpp:228] Iteration 4251, loss = 0.00249174
I0403 03:40:06.431380  2204 solver.cpp:244]     Train net output #0: loss = 0.00249178 (* 1 = 0.00249178 loss)
I0403 03:40:06.609613  2204 sgd_solver.cpp:106] Iteration 4251, lr = 0.0005
I0403 03:40:15.916388  2204 solver.cpp:228] Iteration 4264, loss = 0.000894991
I0403 03:40:15.916507  2204 solver.cpp:244]     Train net output #0: loss = 0.000895023 (* 1 = 0.000895023 loss)
I0403 03:40:16.100716  2204 sgd_solver.cpp:106] Iteration 4264, lr = 0.0005
I0403 03:40:25.301369  2204 solver.cpp:228] Iteration 4277, loss = 0.000589073
I0403 03:40:25.301693  2204 solver.cpp:244]     Train net output #0: loss = 0.000589104 (* 1 = 0.000589104 loss)
I0403 03:40:25.474009  2204 sgd_solver.cpp:106] Iteration 4277, lr = 0.0005
I0403 03:40:32.821120  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4288.caffemodel
I0403 03:40:35.595885  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4288.solverstate
I0403 03:40:37.494127  2204 solver.cpp:337] Iteration 4288, Testing net (#0)
I0403 03:41:38.988916  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986351
I0403 03:41:38.989248  2204 solver.cpp:404]     Test net output #1: loss = 0.0527189 (* 1 = 0.0527189 loss)
I0403 03:41:40.967979  2204 solver.cpp:228] Iteration 4290, loss = 0.000472707
I0403 03:41:40.968092  2204 solver.cpp:244]     Train net output #0: loss = 0.000472738 (* 1 = 0.000472738 loss)
I0403 03:41:41.163072  2204 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 03:41:50.436642  2204 solver.cpp:228] Iteration 4303, loss = 0.00439404
I0403 03:41:50.436754  2204 solver.cpp:244]     Train net output #0: loss = 0.00439407 (* 1 = 0.00439407 loss)
I0403 03:41:50.619165  2204 sgd_solver.cpp:106] Iteration 4303, lr = 0.0005
I0403 03:41:59.874644  2204 solver.cpp:228] Iteration 4316, loss = 2.07028e-05
I0403 03:41:59.874757  2204 solver.cpp:244]     Train net output #0: loss = 2.07351e-05 (* 1 = 2.07351e-05 loss)
I0403 03:42:00.145869  2204 sgd_solver.cpp:106] Iteration 4316, lr = 0.0005
I0403 03:42:09.270952  2204 solver.cpp:228] Iteration 4329, loss = 0.000349435
I0403 03:42:09.271289  2204 solver.cpp:244]     Train net output #0: loss = 0.000349468 (* 1 = 0.000349468 loss)
I0403 03:42:09.452958  2204 sgd_solver.cpp:106] Iteration 4329, lr = 0.0005
I0403 03:42:18.705358  2204 solver.cpp:228] Iteration 4342, loss = 8.04323e-05
I0403 03:42:18.705482  2204 solver.cpp:244]     Train net output #0: loss = 8.04646e-05 (* 1 = 8.04646e-05 loss)
I0403 03:42:18.894585  2204 sgd_solver.cpp:106] Iteration 4342, lr = 0.0005
I0403 03:42:28.041764  2204 solver.cpp:228] Iteration 4355, loss = 6.93034e-05
I0403 03:42:28.041865  2204 solver.cpp:244]     Train net output #0: loss = 6.93357e-05 (* 1 = 6.93357e-05 loss)
I0403 03:42:28.221141  2204 sgd_solver.cpp:106] Iteration 4355, lr = 0.0005
I0403 03:42:37.414633  2204 solver.cpp:228] Iteration 4368, loss = 0.000229458
I0403 03:42:37.414733  2204 solver.cpp:244]     Train net output #0: loss = 0.000229489 (* 1 = 0.000229489 loss)
I0403 03:42:37.584671  2204 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:42:46.787145  2204 solver.cpp:228] Iteration 4381, loss = 0.00247813
I0403 03:42:46.787497  2204 solver.cpp:244]     Train net output #0: loss = 0.00247816 (* 1 = 0.00247816 loss)
I0403 03:42:46.963523  2204 sgd_solver.cpp:106] Iteration 4381, lr = 0.0005
I0403 03:42:56.127732  2204 solver.cpp:228] Iteration 4394, loss = 0.00260913
I0403 03:42:56.127856  2204 solver.cpp:244]     Train net output #0: loss = 0.00260917 (* 1 = 0.00260917 loss)
I0403 03:42:56.357779  2204 sgd_solver.cpp:106] Iteration 4394, lr = 0.0005
I0403 03:43:05.600826  2204 solver.cpp:228] Iteration 4407, loss = 0.000997187
I0403 03:43:05.600944  2204 solver.cpp:244]     Train net output #0: loss = 0.000997217 (* 1 = 0.000997217 loss)
I0403 03:43:05.811774  2204 sgd_solver.cpp:106] Iteration 4407, lr = 0.0005
I0403 03:43:15.059777  2204 solver.cpp:228] Iteration 4420, loss = 0.000899399
I0403 03:43:15.059880  2204 solver.cpp:244]     Train net output #0: loss = 0.000899429 (* 1 = 0.000899429 loss)
I0403 03:43:15.223008  2204 sgd_solver.cpp:106] Iteration 4420, lr = 0.0005
I0403 03:43:24.461205  2204 solver.cpp:228] Iteration 4433, loss = 0.000393472
I0403 03:43:24.461498  2204 solver.cpp:244]     Train net output #0: loss = 0.000393502 (* 1 = 0.000393502 loss)
I0403 03:43:24.642371  2204 sgd_solver.cpp:106] Iteration 4433, lr = 0.0005
I0403 03:43:33.792568  2204 solver.cpp:228] Iteration 4446, loss = 0.00395854
I0403 03:43:33.792670  2204 solver.cpp:244]     Train net output #0: loss = 0.00395857 (* 1 = 0.00395857 loss)
I0403 03:43:33.959089  2204 sgd_solver.cpp:106] Iteration 4446, lr = 0.0005
I0403 03:43:43.143694  2204 solver.cpp:228] Iteration 4459, loss = 0.000249271
I0403 03:43:43.143818  2204 solver.cpp:244]     Train net output #0: loss = 0.0002493 (* 1 = 0.0002493 loss)
I0403 03:43:43.301838  2204 sgd_solver.cpp:106] Iteration 4459, lr = 0.0005
I0403 03:43:52.503165  2204 solver.cpp:228] Iteration 4472, loss = 0.000571288
I0403 03:43:52.503280  2204 solver.cpp:244]     Train net output #0: loss = 0.000571317 (* 1 = 0.000571317 loss)
I0403 03:43:52.687032  2204 sgd_solver.cpp:106] Iteration 4472, lr = 0.0005
I0403 03:44:01.880440  2204 solver.cpp:228] Iteration 4485, loss = 0.00174196
I0403 03:44:01.880764  2204 solver.cpp:244]     Train net output #0: loss = 0.00174199 (* 1 = 0.00174199 loss)
I0403 03:44:02.055408  2204 sgd_solver.cpp:106] Iteration 4485, lr = 0.0005
I0403 03:44:11.393900  2204 solver.cpp:228] Iteration 4498, loss = 0.000152267
I0403 03:44:11.394018  2204 solver.cpp:244]     Train net output #0: loss = 0.000152297 (* 1 = 0.000152297 loss)
I0403 03:44:11.576477  2204 sgd_solver.cpp:106] Iteration 4498, lr = 0.0005
I0403 03:44:20.881777  2204 solver.cpp:228] Iteration 4511, loss = 0.000985028
I0403 03:44:20.881896  2204 solver.cpp:244]     Train net output #0: loss = 0.000985058 (* 1 = 0.000985058 loss)
I0403 03:44:21.084681  2204 sgd_solver.cpp:106] Iteration 4511, lr = 0.0005
I0403 03:44:30.222059  2204 solver.cpp:228] Iteration 4524, loss = 0.00116514
I0403 03:44:30.222182  2204 solver.cpp:244]     Train net output #0: loss = 0.00116517 (* 1 = 0.00116517 loss)
I0403 03:44:30.421192  2204 sgd_solver.cpp:106] Iteration 4524, lr = 0.0005
I0403 03:44:39.670461  2204 solver.cpp:228] Iteration 4537, loss = 0.000587171
I0403 03:44:39.670809  2204 solver.cpp:244]     Train net output #0: loss = 0.0005872 (* 1 = 0.0005872 loss)
I0403 03:44:39.890518  2204 sgd_solver.cpp:106] Iteration 4537, lr = 0.0005
I0403 03:44:49.100602  2204 solver.cpp:228] Iteration 4550, loss = 6.78818e-05
I0403 03:44:49.100705  2204 solver.cpp:244]     Train net output #0: loss = 6.79115e-05 (* 1 = 6.79115e-05 loss)
I0403 03:44:49.262830  2204 sgd_solver.cpp:106] Iteration 4550, lr = 0.0005
I0403 03:44:52.900123  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4556.caffemodel
I0403 03:44:55.644240  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4556.solverstate
I0403 03:44:57.933884  2204 solver.cpp:337] Iteration 4556, Testing net (#0)
I0403 03:45:59.403848  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986424
I0403 03:45:59.405170  2204 solver.cpp:404]     Test net output #1: loss = 0.0536235 (* 1 = 0.0536235 loss)
I0403 03:46:05.159921  2204 solver.cpp:228] Iteration 4563, loss = 0.000261292
I0403 03:46:05.160022  2204 solver.cpp:244]     Train net output #0: loss = 0.000261322 (* 1 = 0.000261322 loss)
I0403 03:46:05.338829  2204 sgd_solver.cpp:106] Iteration 4563, lr = 0.0005
I0403 03:46:14.543329  2204 solver.cpp:228] Iteration 4576, loss = 0.000350342
I0403 03:46:14.543436  2204 solver.cpp:244]     Train net output #0: loss = 0.000350372 (* 1 = 0.000350372 loss)
I0403 03:46:14.721984  2204 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 03:46:23.922302  2204 solver.cpp:228] Iteration 4589, loss = 0.00187835
I0403 03:46:23.922405  2204 solver.cpp:244]     Train net output #0: loss = 0.00187838 (* 1 = 0.00187838 loss)
I0403 03:46:24.086721  2204 sgd_solver.cpp:106] Iteration 4589, lr = 0.0005
I0403 03:46:33.440481  2204 solver.cpp:228] Iteration 4602, loss = 0.00494802
I0403 03:46:33.440795  2204 solver.cpp:244]     Train net output #0: loss = 0.00494805 (* 1 = 0.00494805 loss)
I0403 03:46:33.620205  2204 sgd_solver.cpp:106] Iteration 4602, lr = 0.0005
I0403 03:46:42.912910  2204 solver.cpp:228] Iteration 4615, loss = 0.00103286
I0403 03:46:42.913003  2204 solver.cpp:244]     Train net output #0: loss = 0.00103289 (* 1 = 0.00103289 loss)
I0403 03:46:43.080811  2204 sgd_solver.cpp:106] Iteration 4615, lr = 0.0005
I0403 03:46:52.417564  2204 solver.cpp:228] Iteration 4628, loss = 0.00127374
I0403 03:46:52.417676  2204 solver.cpp:244]     Train net output #0: loss = 0.00127377 (* 1 = 0.00127377 loss)
I0403 03:46:52.568225  2204 sgd_solver.cpp:106] Iteration 4628, lr = 0.0005
I0403 03:47:02.063089  2204 solver.cpp:228] Iteration 4641, loss = 0.00357632
I0403 03:47:02.063206  2204 solver.cpp:244]     Train net output #0: loss = 0.00357635 (* 1 = 0.00357635 loss)
I0403 03:47:02.273207  2204 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 03:47:11.506700  2204 solver.cpp:228] Iteration 4654, loss = 0.00322458
I0403 03:47:11.507050  2204 solver.cpp:244]     Train net output #0: loss = 0.00322461 (* 1 = 0.00322461 loss)
I0403 03:47:11.682427  2204 sgd_solver.cpp:106] Iteration 4654, lr = 0.0005
I0403 03:47:20.923774  2204 solver.cpp:228] Iteration 4667, loss = 0.00145149
I0403 03:47:20.923874  2204 solver.cpp:244]     Train net output #0: loss = 0.00145152 (* 1 = 0.00145152 loss)
I0403 03:47:21.092160  2204 sgd_solver.cpp:106] Iteration 4667, lr = 0.0005
I0403 03:47:30.451232  2204 solver.cpp:228] Iteration 4680, loss = 0.0112654
I0403 03:47:30.451338  2204 solver.cpp:244]     Train net output #0: loss = 0.0112654 (* 1 = 0.0112654 loss)
I0403 03:47:30.618415  2204 sgd_solver.cpp:106] Iteration 4680, lr = 0.0005
I0403 03:47:39.873232  2204 solver.cpp:228] Iteration 4693, loss = 9.9185e-05
I0403 03:47:39.873337  2204 solver.cpp:244]     Train net output #0: loss = 9.92154e-05 (* 1 = 9.92154e-05 loss)
I0403 03:47:40.049979  2204 sgd_solver.cpp:106] Iteration 4693, lr = 0.0005
I0403 03:47:49.467839  2204 solver.cpp:228] Iteration 4706, loss = 0.00128178
I0403 03:47:49.468183  2204 solver.cpp:244]     Train net output #0: loss = 0.00128181 (* 1 = 0.00128181 loss)
I0403 03:47:49.649366  2204 sgd_solver.cpp:106] Iteration 4706, lr = 0.0005
I0403 03:47:58.949616  2204 solver.cpp:228] Iteration 4719, loss = 0.00198883
I0403 03:47:58.949717  2204 solver.cpp:244]     Train net output #0: loss = 0.00198886 (* 1 = 0.00198886 loss)
I0403 03:47:59.101047  2204 sgd_solver.cpp:106] Iteration 4719, lr = 0.0005
I0403 03:48:08.406082  2204 solver.cpp:228] Iteration 4732, loss = 0.00043245
I0403 03:48:08.406201  2204 solver.cpp:244]     Train net output #0: loss = 0.000432481 (* 1 = 0.000432481 loss)
I0403 03:48:08.646492  2204 sgd_solver.cpp:106] Iteration 4732, lr = 0.0005
I0403 03:48:17.953413  2204 solver.cpp:228] Iteration 4745, loss = 0.000294878
I0403 03:48:17.953531  2204 solver.cpp:244]     Train net output #0: loss = 0.000294909 (* 1 = 0.000294909 loss)
I0403 03:48:18.137092  2204 sgd_solver.cpp:106] Iteration 4745, lr = 0.0005
I0403 03:48:27.598511  2204 solver.cpp:228] Iteration 4758, loss = 5.20803e-05
I0403 03:48:27.598883  2204 solver.cpp:244]     Train net output #0: loss = 5.21109e-05 (* 1 = 5.21109e-05 loss)
I0403 03:48:27.759021  2204 sgd_solver.cpp:106] Iteration 4758, lr = 0.0005
I0403 03:48:37.158844  2204 solver.cpp:228] Iteration 4771, loss = 0.00230505
I0403 03:48:37.158963  2204 solver.cpp:244]     Train net output #0: loss = 0.00230508 (* 1 = 0.00230508 loss)
I0403 03:48:37.376782  2204 sgd_solver.cpp:106] Iteration 4771, lr = 0.0005
I0403 03:48:46.645951  2204 solver.cpp:228] Iteration 4784, loss = 0.011606
I0403 03:48:46.646064  2204 solver.cpp:244]     Train net output #0: loss = 0.011606 (* 1 = 0.011606 loss)
I0403 03:48:46.848737  2204 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 03:48:56.094033  2204 solver.cpp:228] Iteration 4797, loss = 0.000278707
I0403 03:48:56.094147  2204 solver.cpp:244]     Train net output #0: loss = 0.000278737 (* 1 = 0.000278737 loss)
I0403 03:48:56.283445  2204 sgd_solver.cpp:106] Iteration 4797, lr = 0.0005
I0403 03:49:05.838457  2204 solver.cpp:228] Iteration 4810, loss = 0.000445752
I0403 03:49:05.838781  2204 solver.cpp:244]     Train net output #0: loss = 0.000445783 (* 1 = 0.000445783 loss)
I0403 03:49:06.029245  2204 sgd_solver.cpp:106] Iteration 4810, lr = 0.0005
I0403 03:49:15.356262  2204 solver.cpp:228] Iteration 4823, loss = 0.000760092
I0403 03:49:15.356377  2204 solver.cpp:244]     Train net output #0: loss = 0.000760123 (* 1 = 0.000760123 loss)
I0403 03:49:15.539198  2204 sgd_solver.cpp:106] Iteration 4823, lr = 0.0005
I0403 03:49:15.539433  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4824.caffemodel
I0403 03:49:18.288472  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_4824.solverstate
I0403 03:49:20.198354  2204 solver.cpp:337] Iteration 4824, Testing net (#0)
I0403 03:50:21.691881  2204 solver.cpp:404]     Test net output #0: accuracy = 0.985184
I0403 03:50:21.692210  2204 solver.cpp:404]     Test net output #1: loss = 0.0560287 (* 1 = 0.0560287 loss)
I0403 03:50:30.947891  2204 solver.cpp:228] Iteration 4836, loss = 0.000394897
I0403 03:50:30.948001  2204 solver.cpp:244]     Train net output #0: loss = 0.000394927 (* 1 = 0.000394927 loss)
I0403 03:50:31.173368  2204 sgd_solver.cpp:106] Iteration 4836, lr = 0.0005
I0403 03:50:40.715677  2204 solver.cpp:228] Iteration 4849, loss = 0.000398238
I0403 03:50:40.715782  2204 solver.cpp:244]     Train net output #0: loss = 0.000398268 (* 1 = 0.000398268 loss)
I0403 03:50:40.893815  2204 sgd_solver.cpp:106] Iteration 4849, lr = 0.0005
I0403 03:50:50.252607  2204 solver.cpp:228] Iteration 4862, loss = 0.00045254
I0403 03:50:50.252724  2204 solver.cpp:244]     Train net output #0: loss = 0.00045257 (* 1 = 0.00045257 loss)
I0403 03:50:50.454226  2204 sgd_solver.cpp:106] Iteration 4862, lr = 0.0005
I0403 03:50:59.710783  2204 solver.cpp:228] Iteration 4875, loss = 0.000377743
I0403 03:50:59.711117  2204 solver.cpp:244]     Train net output #0: loss = 0.000377773 (* 1 = 0.000377773 loss)
I0403 03:50:59.921325  2204 sgd_solver.cpp:106] Iteration 4875, lr = 0.0005
I0403 03:51:09.161938  2204 solver.cpp:228] Iteration 4888, loss = 9.29541e-05
I0403 03:51:09.162042  2204 solver.cpp:244]     Train net output #0: loss = 9.2984e-05 (* 1 = 9.2984e-05 loss)
I0403 03:51:09.341749  2204 sgd_solver.cpp:106] Iteration 4888, lr = 0.0005
I0403 03:51:18.561620  2204 solver.cpp:228] Iteration 4901, loss = 0.00300256
I0403 03:51:18.561734  2204 solver.cpp:244]     Train net output #0: loss = 0.00300259 (* 1 = 0.00300259 loss)
I0403 03:51:18.806457  2204 sgd_solver.cpp:106] Iteration 4901, lr = 0.0005
I0403 03:51:28.029642  2204 solver.cpp:228] Iteration 4914, loss = 0.000291712
I0403 03:51:28.029764  2204 solver.cpp:244]     Train net output #0: loss = 0.000291742 (* 1 = 0.000291742 loss)
I0403 03:51:28.236768  2204 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 03:51:37.587199  2204 solver.cpp:228] Iteration 4927, loss = 0.000688012
I0403 03:51:37.587566  2204 solver.cpp:244]     Train net output #0: loss = 0.000688043 (* 1 = 0.000688043 loss)
I0403 03:51:37.796558  2204 sgd_solver.cpp:106] Iteration 4927, lr = 0.0005
I0403 03:51:46.978294  2204 solver.cpp:228] Iteration 4940, loss = 0.00970699
I0403 03:51:46.978410  2204 solver.cpp:244]     Train net output #0: loss = 0.00970702 (* 1 = 0.00970702 loss)
I0403 03:51:47.206157  2204 sgd_solver.cpp:106] Iteration 4940, lr = 0.0005
I0403 03:51:56.403821  2204 solver.cpp:228] Iteration 4953, loss = 0.000294479
I0403 03:51:56.403942  2204 solver.cpp:244]     Train net output #0: loss = 0.000294511 (* 1 = 0.000294511 loss)
I0403 03:51:56.657049  2204 sgd_solver.cpp:106] Iteration 4953, lr = 0.0005
I0403 03:52:05.916627  2204 solver.cpp:228] Iteration 4966, loss = 0.0010548
I0403 03:52:05.916735  2204 solver.cpp:244]     Train net output #0: loss = 0.00105483 (* 1 = 0.00105483 loss)
I0403 03:52:06.089009  2204 sgd_solver.cpp:106] Iteration 4966, lr = 0.0005
I0403 03:52:15.867624  2204 solver.cpp:228] Iteration 4979, loss = 0.000197996
I0403 03:52:15.867959  2204 solver.cpp:244]     Train net output #0: loss = 0.000198028 (* 1 = 0.000198028 loss)
I0403 03:52:16.017858  2204 sgd_solver.cpp:106] Iteration 4979, lr = 0.0005
I0403 03:52:25.452199  2204 solver.cpp:228] Iteration 4992, loss = 0.00599747
I0403 03:52:25.452314  2204 solver.cpp:244]     Train net output #0: loss = 0.0059975 (* 1 = 0.0059975 loss)
I0403 03:52:25.650216  2204 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 03:52:35.103314  2204 solver.cpp:228] Iteration 5005, loss = 0.000665962
I0403 03:52:35.103418  2204 solver.cpp:244]     Train net output #0: loss = 0.000665994 (* 1 = 0.000665994 loss)
I0403 03:52:35.283139  2204 sgd_solver.cpp:106] Iteration 5005, lr = 0.0005
I0403 03:52:44.505854  2204 solver.cpp:228] Iteration 5018, loss = 0.00116229
I0403 03:52:44.505944  2204 solver.cpp:244]     Train net output #0: loss = 0.00116233 (* 1 = 0.00116233 loss)
I0403 03:52:44.686488  2204 sgd_solver.cpp:106] Iteration 5018, lr = 0.0005
I0403 03:52:53.970657  2204 solver.cpp:228] Iteration 5031, loss = 4.70153e-05
I0403 03:52:53.970979  2204 solver.cpp:244]     Train net output #0: loss = 4.70499e-05 (* 1 = 4.70499e-05 loss)
I0403 03:52:54.149323  2204 sgd_solver.cpp:106] Iteration 5031, lr = 0.0005
I0403 03:53:03.375658  2204 solver.cpp:228] Iteration 5044, loss = 0.00034233
I0403 03:53:03.375761  2204 solver.cpp:244]     Train net output #0: loss = 0.000342364 (* 1 = 0.000342364 loss)
I0403 03:53:03.544242  2204 sgd_solver.cpp:106] Iteration 5044, lr = 0.0005
I0403 03:53:12.896437  2204 solver.cpp:228] Iteration 5057, loss = 0.000287702
I0403 03:53:12.896538  2204 solver.cpp:244]     Train net output #0: loss = 0.000287735 (* 1 = 0.000287735 loss)
I0403 03:53:13.060992  2204 sgd_solver.cpp:106] Iteration 5057, lr = 0.0005
I0403 03:53:22.319281  2204 solver.cpp:228] Iteration 5070, loss = 0.000566285
I0403 03:53:22.319401  2204 solver.cpp:244]     Train net output #0: loss = 0.000566316 (* 1 = 0.000566316 loss)
I0403 03:53:22.557171  2204 sgd_solver.cpp:106] Iteration 5070, lr = 0.0005
I0403 03:53:31.808404  2204 solver.cpp:228] Iteration 5083, loss = 0.000166081
I0403 03:53:31.808715  2204 solver.cpp:244]     Train net output #0: loss = 0.000166112 (* 1 = 0.000166112 loss)
I0403 03:53:32.004091  2204 sgd_solver.cpp:106] Iteration 5083, lr = 0.0005
I0403 03:53:37.733121  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5092.caffemodel
I0403 03:53:40.496165  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5092.solverstate
I0403 03:53:42.376507  2204 solver.cpp:337] Iteration 5092, Testing net (#0)
I0403 03:54:43.872009  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986278
I0403 03:54:43.873425  2204 solver.cpp:404]     Test net output #1: loss = 0.0526464 (* 1 = 0.0526464 loss)
I0403 03:54:47.450335  2204 solver.cpp:228] Iteration 5096, loss = 8.37856e-05
I0403 03:54:47.450449  2204 solver.cpp:244]     Train net output #0: loss = 8.38171e-05 (* 1 = 8.38171e-05 loss)
I0403 03:54:47.631294  2204 sgd_solver.cpp:106] Iteration 5096, lr = 0.0005
I0403 03:54:57.010164  2204 solver.cpp:228] Iteration 5109, loss = 0.00752831
I0403 03:54:57.010272  2204 solver.cpp:244]     Train net output #0: loss = 0.00752834 (* 1 = 0.00752834 loss)
I0403 03:54:57.166967  2204 sgd_solver.cpp:106] Iteration 5109, lr = 0.0005
I0403 03:55:06.589751  2204 solver.cpp:228] Iteration 5122, loss = 0.000210569
I0403 03:55:06.596902  2204 solver.cpp:244]     Train net output #0: loss = 0.0002106 (* 1 = 0.0002106 loss)
I0403 03:55:06.786450  2204 sgd_solver.cpp:106] Iteration 5122, lr = 0.0005
I0403 03:55:16.001988  2204 solver.cpp:228] Iteration 5135, loss = 0.00161476
I0403 03:55:16.002281  2204 solver.cpp:244]     Train net output #0: loss = 0.00161479 (* 1 = 0.00161479 loss)
I0403 03:55:16.216310  2204 sgd_solver.cpp:106] Iteration 5135, lr = 0.0005
I0403 03:55:25.499200  2204 solver.cpp:228] Iteration 5148, loss = 0.000376696
I0403 03:55:25.504916  2204 solver.cpp:244]     Train net output #0: loss = 0.000376726 (* 1 = 0.000376726 loss)
I0403 03:55:25.664199  2204 sgd_solver.cpp:106] Iteration 5148, lr = 0.0005
I0403 03:55:34.905938  2204 solver.cpp:228] Iteration 5161, loss = 0.00539767
I0403 03:55:34.912807  2204 solver.cpp:244]     Train net output #0: loss = 0.0053977 (* 1 = 0.0053977 loss)
I0403 03:55:35.089525  2204 sgd_solver.cpp:106] Iteration 5161, lr = 0.0005
I0403 03:55:44.387461  2204 solver.cpp:228] Iteration 5174, loss = 0.000144428
I0403 03:55:44.387567  2204 solver.cpp:244]     Train net output #0: loss = 0.000144458 (* 1 = 0.000144458 loss)
I0403 03:55:44.535199  2204 sgd_solver.cpp:106] Iteration 5174, lr = 0.0005
I0403 03:55:54.046300  2204 solver.cpp:228] Iteration 5187, loss = 0.000332905
I0403 03:55:54.046656  2204 solver.cpp:244]     Train net output #0: loss = 0.000332934 (* 1 = 0.000332934 loss)
I0403 03:55:54.211194  2204 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 03:56:03.637310  2204 solver.cpp:228] Iteration 5200, loss = 0.000222549
I0403 03:56:03.637414  2204 solver.cpp:244]     Train net output #0: loss = 0.000222579 (* 1 = 0.000222579 loss)
I0403 03:56:03.817117  2204 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 03:56:13.451992  2204 solver.cpp:228] Iteration 5213, loss = 0.00543871
I0403 03:56:13.452103  2204 solver.cpp:244]     Train net output #0: loss = 0.00543874 (* 1 = 0.00543874 loss)
I0403 03:56:13.656802  2204 sgd_solver.cpp:106] Iteration 5213, lr = 0.0005
I0403 03:56:22.882567  2204 solver.cpp:228] Iteration 5226, loss = 2.53131e-05
I0403 03:56:22.882671  2204 solver.cpp:244]     Train net output #0: loss = 2.5342e-05 (* 1 = 2.5342e-05 loss)
I0403 03:56:23.055368  2204 sgd_solver.cpp:106] Iteration 5226, lr = 0.0005
I0403 03:56:32.441754  2204 solver.cpp:228] Iteration 5239, loss = 0.00124034
I0403 03:56:32.442113  2204 solver.cpp:244]     Train net output #0: loss = 0.00124037 (* 1 = 0.00124037 loss)
I0403 03:56:32.606680  2204 sgd_solver.cpp:106] Iteration 5239, lr = 0.0005
I0403 03:56:41.959542  2204 solver.cpp:228] Iteration 5252, loss = 0.000113113
I0403 03:56:41.959647  2204 solver.cpp:244]     Train net output #0: loss = 0.000113141 (* 1 = 0.000113141 loss)
I0403 03:56:42.119575  2204 sgd_solver.cpp:106] Iteration 5252, lr = 0.0005
I0403 03:56:51.371099  2204 solver.cpp:228] Iteration 5265, loss = 0.000114704
I0403 03:56:51.371215  2204 solver.cpp:244]     Train net output #0: loss = 0.000114733 (* 1 = 0.000114733 loss)
I0403 03:56:51.600879  2204 sgd_solver.cpp:106] Iteration 5265, lr = 0.0005
I0403 03:57:01.068471  2204 solver.cpp:228] Iteration 5278, loss = 0.0143378
I0403 03:57:01.068574  2204 solver.cpp:244]     Train net output #0: loss = 0.0143379 (* 1 = 0.0143379 loss)
I0403 03:57:01.224395  2204 sgd_solver.cpp:106] Iteration 5278, lr = 0.0005
I0403 03:57:10.565475  2204 solver.cpp:228] Iteration 5291, loss = 0.0106643
I0403 03:57:10.568871  2204 solver.cpp:244]     Train net output #0: loss = 0.0106643 (* 1 = 0.0106643 loss)
I0403 03:57:10.795622  2204 sgd_solver.cpp:106] Iteration 5291, lr = 0.0005
I0403 03:57:20.006729  2204 solver.cpp:228] Iteration 5304, loss = 8.2169e-05
I0403 03:57:20.006845  2204 solver.cpp:244]     Train net output #0: loss = 8.2197e-05 (* 1 = 8.2197e-05 loss)
I0403 03:57:20.199506  2204 sgd_solver.cpp:106] Iteration 5304, lr = 0.0005
I0403 03:57:29.438091  2204 solver.cpp:228] Iteration 5317, loss = 0.0102069
I0403 03:57:29.438192  2204 solver.cpp:244]     Train net output #0: loss = 0.0102069 (* 1 = 0.0102069 loss)
I0403 03:57:29.591125  2204 sgd_solver.cpp:106] Iteration 5317, lr = 0.0005
I0403 03:57:39.000135  2204 solver.cpp:228] Iteration 5330, loss = 0.00351309
I0403 03:57:39.000239  2204 solver.cpp:244]     Train net output #0: loss = 0.00351312 (* 1 = 0.00351312 loss)
I0403 03:57:39.127882  2204 sgd_solver.cpp:106] Iteration 5330, lr = 0.0005
I0403 03:57:48.513037  2204 solver.cpp:228] Iteration 5343, loss = 0.0216292
I0403 03:57:48.513393  2204 solver.cpp:244]     Train net output #0: loss = 0.0216292 (* 1 = 0.0216292 loss)
I0403 03:57:48.741592  2204 sgd_solver.cpp:106] Iteration 5343, lr = 0.0005
I0403 03:57:57.994568  2204 solver.cpp:228] Iteration 5356, loss = 0.000472108
I0403 03:57:57.994679  2204 solver.cpp:244]     Train net output #0: loss = 0.000472138 (* 1 = 0.000472138 loss)
I0403 03:57:58.178946  2204 sgd_solver.cpp:106] Iteration 5356, lr = 0.0005
I0403 03:58:00.362639  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5360.caffemodel
I0403 03:58:03.117179  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5360.solverstate
I0403 03:58:04.902947  2204 solver.cpp:337] Iteration 5360, Testing net (#0)
I0403 03:59:06.397119  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986205
I0403 03:59:06.397452  2204 solver.cpp:404]     Test net output #1: loss = 0.0526611 (* 1 = 0.0526611 loss)
I0403 03:59:13.494181  2204 solver.cpp:228] Iteration 5369, loss = 0.000548476
I0403 03:59:13.494297  2204 solver.cpp:244]     Train net output #0: loss = 0.000548505 (* 1 = 0.000548505 loss)
I0403 03:59:13.693291  2204 sgd_solver.cpp:106] Iteration 5369, lr = 0.0005
I0403 03:59:23.051204  2204 solver.cpp:228] Iteration 5382, loss = 0.000202936
I0403 03:59:23.051323  2204 solver.cpp:244]     Train net output #0: loss = 0.000202966 (* 1 = 0.000202966 loss)
I0403 03:59:23.234470  2204 sgd_solver.cpp:106] Iteration 5382, lr = 5e-05
I0403 03:59:32.644882  2204 solver.cpp:228] Iteration 5395, loss = 0.000102954
I0403 03:59:32.644989  2204 solver.cpp:244]     Train net output #0: loss = 0.000102983 (* 1 = 0.000102983 loss)
I0403 03:59:32.820178  2204 sgd_solver.cpp:106] Iteration 5395, lr = 5e-05
I0403 03:59:42.139422  2204 solver.cpp:228] Iteration 5408, loss = 0.0115873
I0403 03:59:42.139750  2204 solver.cpp:244]     Train net output #0: loss = 0.0115873 (* 1 = 0.0115873 loss)
I0403 03:59:42.300288  2204 sgd_solver.cpp:106] Iteration 5408, lr = 5e-05
I0403 03:59:52.140794  2204 solver.cpp:228] Iteration 5421, loss = 0.000170748
I0403 03:59:52.140897  2204 solver.cpp:244]     Train net output #0: loss = 0.000170778 (* 1 = 0.000170778 loss)
I0403 03:59:52.319099  2204 sgd_solver.cpp:106] Iteration 5421, lr = 5e-05
I0403 04:00:01.863267  2204 solver.cpp:228] Iteration 5434, loss = 0.000117111
I0403 04:00:01.863368  2204 solver.cpp:244]     Train net output #0: loss = 0.000117139 (* 1 = 0.000117139 loss)
I0403 04:00:02.018453  2204 sgd_solver.cpp:106] Iteration 5434, lr = 5e-05
I0403 04:00:11.612809  2204 solver.cpp:228] Iteration 5447, loss = 0.000322552
I0403 04:00:11.612913  2204 solver.cpp:244]     Train net output #0: loss = 0.00032258 (* 1 = 0.00032258 loss)
I0403 04:00:11.788439  2204 sgd_solver.cpp:106] Iteration 5447, lr = 5e-05
I0403 04:00:21.162925  2204 solver.cpp:228] Iteration 5460, loss = 0.00153337
I0403 04:00:21.163287  2204 solver.cpp:244]     Train net output #0: loss = 0.0015334 (* 1 = 0.0015334 loss)
I0403 04:00:21.356488  2204 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 04:00:30.576678  2204 solver.cpp:228] Iteration 5473, loss = 0.000288313
I0403 04:00:30.576784  2204 solver.cpp:244]     Train net output #0: loss = 0.000288342 (* 1 = 0.000288342 loss)
I0403 04:00:30.727413  2204 sgd_solver.cpp:106] Iteration 5473, lr = 5e-05
I0403 04:00:39.989979  2204 solver.cpp:228] Iteration 5486, loss = 0.000382498
I0403 04:00:39.990082  2204 solver.cpp:244]     Train net output #0: loss = 0.000382527 (* 1 = 0.000382527 loss)
I0403 04:00:40.129459  2204 sgd_solver.cpp:106] Iteration 5486, lr = 5e-05
I0403 04:00:49.464046  2204 solver.cpp:228] Iteration 5499, loss = 0.000295085
I0403 04:00:49.464159  2204 solver.cpp:244]     Train net output #0: loss = 0.000295114 (* 1 = 0.000295114 loss)
I0403 04:00:49.679214  2204 sgd_solver.cpp:106] Iteration 5499, lr = 5e-05
I0403 04:00:59.008740  2204 solver.cpp:228] Iteration 5512, loss = 0.000152021
I0403 04:00:59.009068  2204 solver.cpp:244]     Train net output #0: loss = 0.00015205 (* 1 = 0.00015205 loss)
I0403 04:00:59.157847  2204 sgd_solver.cpp:106] Iteration 5512, lr = 5e-05
I0403 04:01:08.661104  2204 solver.cpp:228] Iteration 5525, loss = 1.76911e-05
I0403 04:01:08.661221  2204 solver.cpp:244]     Train net output #0: loss = 1.77202e-05 (* 1 = 1.77202e-05 loss)
I0403 04:01:08.852493  2204 sgd_solver.cpp:106] Iteration 5525, lr = 5e-05
I0403 04:01:18.124881  2204 solver.cpp:228] Iteration 5538, loss = 0.000168907
I0403 04:01:18.124984  2204 solver.cpp:244]     Train net output #0: loss = 0.000168937 (* 1 = 0.000168937 loss)
I0403 04:01:18.300930  2204 sgd_solver.cpp:106] Iteration 5538, lr = 5e-05
I0403 04:01:27.800230  2204 solver.cpp:228] Iteration 5551, loss = 0.000696212
I0403 04:01:27.800333  2204 solver.cpp:244]     Train net output #0: loss = 0.000696242 (* 1 = 0.000696242 loss)
I0403 04:01:27.965957  2204 sgd_solver.cpp:106] Iteration 5551, lr = 5e-05
I0403 04:01:37.367861  2204 solver.cpp:228] Iteration 5564, loss = 7.64383e-05
I0403 04:01:37.368204  2204 solver.cpp:244]     Train net output #0: loss = 7.64678e-05 (* 1 = 7.64678e-05 loss)
I0403 04:01:37.573775  2204 sgd_solver.cpp:106] Iteration 5564, lr = 5e-05
I0403 04:01:46.794875  2204 solver.cpp:228] Iteration 5577, loss = 0.000343375
I0403 04:01:46.794991  2204 solver.cpp:244]     Train net output #0: loss = 0.000343404 (* 1 = 0.000343404 loss)
I0403 04:01:46.979727  2204 sgd_solver.cpp:106] Iteration 5577, lr = 5e-05
I0403 04:01:56.466059  2204 solver.cpp:228] Iteration 5590, loss = 0.00199611
I0403 04:01:56.466166  2204 solver.cpp:244]     Train net output #0: loss = 0.00199614 (* 1 = 0.00199614 loss)
I0403 04:01:56.586422  2204 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 04:02:05.952620  2204 solver.cpp:228] Iteration 5603, loss = 0.000974836
I0403 04:02:05.952735  2204 solver.cpp:244]     Train net output #0: loss = 0.000974866 (* 1 = 0.000974866 loss)
I0403 04:02:06.139675  2204 sgd_solver.cpp:106] Iteration 5603, lr = 5e-05
I0403 04:02:15.322942  2204 solver.cpp:228] Iteration 5616, loss = 0.000133211
I0403 04:02:15.323263  2204 solver.cpp:244]     Train net output #0: loss = 0.000133241 (* 1 = 0.000133241 loss)
I0403 04:02:15.515647  2204 sgd_solver.cpp:106] Iteration 5616, lr = 5e-05
I0403 04:02:23.633702  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5628.caffemodel
I0403 04:02:26.297461  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5628.solverstate
I0403 04:02:28.054618  2204 solver.cpp:337] Iteration 5628, Testing net (#0)
I0403 04:03:29.539258  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986132
I0403 04:03:29.539620  2204 solver.cpp:404]     Test net output #1: loss = 0.0522472 (* 1 = 0.0522472 loss)
I0403 04:03:30.771497  2204 solver.cpp:228] Iteration 5629, loss = 0.0033632
I0403 04:03:30.771592  2204 solver.cpp:244]     Train net output #0: loss = 0.00336323 (* 1 = 0.00336323 loss)
I0403 04:03:30.949254  2204 sgd_solver.cpp:106] Iteration 5629, lr = 5e-05
I0403 04:03:40.225531  2204 solver.cpp:228] Iteration 5642, loss = 0.00137968
I0403 04:03:40.225643  2204 solver.cpp:244]     Train net output #0: loss = 0.00137971 (* 1 = 0.00137971 loss)
I0403 04:03:40.386111  2204 sgd_solver.cpp:106] Iteration 5642, lr = 5e-05
I0403 04:03:49.640283  2204 solver.cpp:228] Iteration 5655, loss = 0.000478472
I0403 04:03:49.640398  2204 solver.cpp:244]     Train net output #0: loss = 0.000478502 (* 1 = 0.000478502 loss)
I0403 04:03:49.842128  2204 sgd_solver.cpp:106] Iteration 5655, lr = 5e-05
I0403 04:03:59.216269  2204 solver.cpp:228] Iteration 5668, loss = 0.00308624
I0403 04:03:59.216367  2204 solver.cpp:244]     Train net output #0: loss = 0.00308627 (* 1 = 0.00308627 loss)
I0403 04:03:59.382060  2204 sgd_solver.cpp:106] Iteration 5668, lr = 5e-05
I0403 04:04:08.907276  2204 solver.cpp:228] Iteration 5681, loss = 0.000554623
I0403 04:04:08.907583  2204 solver.cpp:244]     Train net output #0: loss = 0.000554652 (* 1 = 0.000554652 loss)
I0403 04:04:09.031724  2204 sgd_solver.cpp:106] Iteration 5681, lr = 5e-05
I0403 04:04:18.344152  2204 solver.cpp:228] Iteration 5694, loss = 0.000516938
I0403 04:04:18.344269  2204 solver.cpp:244]     Train net output #0: loss = 0.000516967 (* 1 = 0.000516967 loss)
I0403 04:04:18.526921  2204 sgd_solver.cpp:106] Iteration 5694, lr = 5e-05
I0403 04:04:27.805019  2204 solver.cpp:228] Iteration 5707, loss = 0.000287879
I0403 04:04:27.813956  2204 solver.cpp:244]     Train net output #0: loss = 0.000287907 (* 1 = 0.000287907 loss)
I0403 04:04:28.009865  2204 sgd_solver.cpp:106] Iteration 5707, lr = 5e-05
I0403 04:04:37.309888  2204 solver.cpp:228] Iteration 5720, loss = 0.000472577
I0403 04:04:37.309993  2204 solver.cpp:244]     Train net output #0: loss = 0.000472605 (* 1 = 0.000472605 loss)
I0403 04:04:37.485159  2204 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 04:04:46.754348  2204 solver.cpp:228] Iteration 5733, loss = 3.07667e-05
I0403 04:04:46.754659  2204 solver.cpp:244]     Train net output #0: loss = 3.07948e-05 (* 1 = 3.07948e-05 loss)
I0403 04:04:46.930555  2204 sgd_solver.cpp:106] Iteration 5733, lr = 5e-05
I0403 04:04:56.133728  2204 solver.cpp:228] Iteration 5746, loss = 0.000251102
I0403 04:04:56.133847  2204 solver.cpp:244]     Train net output #0: loss = 0.00025113 (* 1 = 0.00025113 loss)
I0403 04:04:56.319147  2204 sgd_solver.cpp:106] Iteration 5746, lr = 5e-05
I0403 04:05:05.679885  2204 solver.cpp:228] Iteration 5759, loss = 0.000633619
I0403 04:05:05.679982  2204 solver.cpp:244]     Train net output #0: loss = 0.000633647 (* 1 = 0.000633647 loss)
I0403 04:05:05.833701  2204 sgd_solver.cpp:106] Iteration 5759, lr = 5e-05
I0403 04:05:15.197383  2204 solver.cpp:228] Iteration 5772, loss = 8.39077e-05
I0403 04:05:15.197496  2204 solver.cpp:244]     Train net output #0: loss = 8.39352e-05 (* 1 = 8.39352e-05 loss)
I0403 04:05:15.379714  2204 sgd_solver.cpp:106] Iteration 5772, lr = 5e-05
I0403 04:05:24.720438  2204 solver.cpp:228] Iteration 5785, loss = 3.35436e-05
I0403 04:05:24.720751  2204 solver.cpp:244]     Train net output #0: loss = 3.35711e-05 (* 1 = 3.35711e-05 loss)
I0403 04:05:24.956301  2204 sgd_solver.cpp:106] Iteration 5785, lr = 5e-05
I0403 04:05:34.437058  2204 solver.cpp:228] Iteration 5798, loss = 0.00134507
I0403 04:05:34.437172  2204 solver.cpp:244]     Train net output #0: loss = 0.00134509 (* 1 = 0.00134509 loss)
I0403 04:05:34.584892  2204 sgd_solver.cpp:106] Iteration 5798, lr = 5e-05
I0403 04:05:43.987406  2204 solver.cpp:228] Iteration 5811, loss = 0.000764083
I0403 04:05:43.987522  2204 solver.cpp:244]     Train net output #0: loss = 0.000764111 (* 1 = 0.000764111 loss)
I0403 04:05:44.202302  2204 sgd_solver.cpp:106] Iteration 5811, lr = 5e-05
I0403 04:05:53.391487  2204 solver.cpp:228] Iteration 5824, loss = 0.000660514
I0403 04:05:53.392491  2204 solver.cpp:244]     Train net output #0: loss = 0.000660542 (* 1 = 0.000660542 loss)
I0403 04:05:53.589766  2204 sgd_solver.cpp:106] Iteration 5824, lr = 5e-05
I0403 04:06:02.853677  2204 solver.cpp:228] Iteration 5837, loss = 0.000413176
I0403 04:06:02.854012  2204 solver.cpp:244]     Train net output #0: loss = 0.000413204 (* 1 = 0.000413204 loss)
I0403 04:06:03.026722  2204 sgd_solver.cpp:106] Iteration 5837, lr = 5e-05
I0403 04:06:12.302952  2204 solver.cpp:228] Iteration 5850, loss = 0.000150716
I0403 04:06:12.303072  2204 solver.cpp:244]     Train net output #0: loss = 0.000150744 (* 1 = 0.000150744 loss)
I0403 04:06:12.545255  2204 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 04:06:21.805990  2204 solver.cpp:228] Iteration 5863, loss = 0.0138121
I0403 04:06:21.806097  2204 solver.cpp:244]     Train net output #0: loss = 0.0138122 (* 1 = 0.0138122 loss)
I0403 04:06:21.981678  2204 sgd_solver.cpp:106] Iteration 5863, lr = 5e-05
I0403 04:06:31.302381  2204 solver.cpp:228] Iteration 5876, loss = 0.000429673
I0403 04:06:31.302495  2204 solver.cpp:244]     Train net output #0: loss = 0.000429701 (* 1 = 0.000429701 loss)
I0403 04:06:31.493964  2204 sgd_solver.cpp:106] Iteration 5876, lr = 5e-05
I0403 04:06:40.736757  2204 solver.cpp:228] Iteration 5889, loss = 0.000193324
I0403 04:06:40.737093  2204 solver.cpp:244]     Train net output #0: loss = 0.000193352 (* 1 = 0.000193352 loss)
I0403 04:06:40.922183  2204 sgd_solver.cpp:106] Iteration 5889, lr = 5e-05
I0403 04:06:45.276139  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5896.caffemodel
I0403 04:06:47.968346  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_5896.solverstate
I0403 04:06:49.774268  2204 solver.cpp:337] Iteration 5896, Testing net (#0)
I0403 04:07:51.274152  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986315
I0403 04:07:51.274490  2204 solver.cpp:404]     Test net output #1: loss = 0.0522789 (* 1 = 0.0522789 loss)
I0403 04:07:56.143045  2204 solver.cpp:228] Iteration 5902, loss = 0.000393332
I0403 04:07:56.143159  2204 solver.cpp:244]     Train net output #0: loss = 0.00039336 (* 1 = 0.00039336 loss)
I0403 04:07:56.361341  2204 sgd_solver.cpp:106] Iteration 5902, lr = 5e-05
I0403 04:08:05.711755  2204 solver.cpp:228] Iteration 5915, loss = 0.000668183
I0403 04:08:05.711880  2204 solver.cpp:244]     Train net output #0: loss = 0.000668211 (* 1 = 0.000668211 loss)
I0403 04:08:05.900897  2204 sgd_solver.cpp:106] Iteration 5915, lr = 5e-05
I0403 04:08:15.129776  2204 solver.cpp:228] Iteration 5928, loss = 0.00191682
I0403 04:08:15.129891  2204 solver.cpp:244]     Train net output #0: loss = 0.00191685 (* 1 = 0.00191685 loss)
I0403 04:08:15.312377  2204 sgd_solver.cpp:106] Iteration 5928, lr = 5e-05
I0403 04:08:24.492039  2204 solver.cpp:228] Iteration 5941, loss = 0.000528783
I0403 04:08:24.492374  2204 solver.cpp:244]     Train net output #0: loss = 0.000528811 (* 1 = 0.000528811 loss)
I0403 04:08:24.719090  2204 sgd_solver.cpp:106] Iteration 5941, lr = 5e-05
I0403 04:08:33.933696  2204 solver.cpp:228] Iteration 5954, loss = 0.000867304
I0403 04:08:33.933812  2204 solver.cpp:244]     Train net output #0: loss = 0.000867333 (* 1 = 0.000867333 loss)
I0403 04:08:34.113999  2204 sgd_solver.cpp:106] Iteration 5954, lr = 5e-05
I0403 04:08:43.326264  2204 solver.cpp:228] Iteration 5967, loss = 0.000357892
I0403 04:08:43.326375  2204 solver.cpp:244]     Train net output #0: loss = 0.00035792 (* 1 = 0.00035792 loss)
I0403 04:08:43.482172  2204 sgd_solver.cpp:106] Iteration 5967, lr = 5e-05
I0403 04:08:53.052381  2204 solver.cpp:228] Iteration 5980, loss = 4.97159e-05
I0403 04:08:53.052489  2204 solver.cpp:244]     Train net output #0: loss = 4.97446e-05 (* 1 = 4.97446e-05 loss)
I0403 04:08:53.203631  2204 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 04:09:02.580129  2204 solver.cpp:228] Iteration 5993, loss = 0.000989564
I0403 04:09:02.580513  2204 solver.cpp:244]     Train net output #0: loss = 0.000989593 (* 1 = 0.000989593 loss)
I0403 04:09:02.783349  2204 sgd_solver.cpp:106] Iteration 5993, lr = 5e-05
I0403 04:09:12.050778  2204 solver.cpp:228] Iteration 6006, loss = 3.63607e-05
I0403 04:09:12.050910  2204 solver.cpp:244]     Train net output #0: loss = 3.63891e-05 (* 1 = 3.63891e-05 loss)
I0403 04:09:12.250141  2204 sgd_solver.cpp:106] Iteration 6006, lr = 5e-05
I0403 04:09:21.453325  2204 solver.cpp:228] Iteration 6019, loss = 0.000190812
I0403 04:09:21.453444  2204 solver.cpp:244]     Train net output #0: loss = 0.000190841 (* 1 = 0.000190841 loss)
I0403 04:09:21.648200  2204 sgd_solver.cpp:106] Iteration 6019, lr = 5e-05
I0403 04:09:30.822901  2204 solver.cpp:228] Iteration 6032, loss = 0.000326326
I0403 04:09:30.823006  2204 solver.cpp:244]     Train net output #0: loss = 0.000326354 (* 1 = 0.000326354 loss)
I0403 04:09:31.013741  2204 sgd_solver.cpp:106] Iteration 6032, lr = 5e-05
I0403 04:09:40.152395  2204 solver.cpp:228] Iteration 6045, loss = 0.000913274
I0403 04:09:40.152729  2204 solver.cpp:244]     Train net output #0: loss = 0.000913302 (* 1 = 0.000913302 loss)
I0403 04:09:40.349934  2204 sgd_solver.cpp:106] Iteration 6045, lr = 5e-05
I0403 04:09:49.759536  2204 solver.cpp:228] Iteration 6058, loss = 0.000223246
I0403 04:09:49.759637  2204 solver.cpp:244]     Train net output #0: loss = 0.000223274 (* 1 = 0.000223274 loss)
I0403 04:09:49.937721  2204 sgd_solver.cpp:106] Iteration 6058, lr = 5e-05
I0403 04:09:59.461570  2204 solver.cpp:228] Iteration 6071, loss = 0.00130305
I0403 04:09:59.461683  2204 solver.cpp:244]     Train net output #0: loss = 0.00130308 (* 1 = 0.00130308 loss)
I0403 04:09:59.654191  2204 sgd_solver.cpp:106] Iteration 6071, lr = 5e-05
I0403 04:10:08.902798  2204 solver.cpp:228] Iteration 6084, loss = 0.000500346
I0403 04:10:08.902911  2204 solver.cpp:244]     Train net output #0: loss = 0.000500374 (* 1 = 0.000500374 loss)
I0403 04:10:09.111904  2204 sgd_solver.cpp:106] Iteration 6084, lr = 5e-05
I0403 04:10:18.523998  2204 solver.cpp:228] Iteration 6097, loss = 0.000233675
I0403 04:10:18.529901  2204 solver.cpp:244]     Train net output #0: loss = 0.000233704 (* 1 = 0.000233704 loss)
I0403 04:10:18.720717  2204 sgd_solver.cpp:106] Iteration 6097, lr = 5e-05
I0403 04:10:28.135393  2204 solver.cpp:228] Iteration 6110, loss = 0.000242892
I0403 04:10:28.135498  2204 solver.cpp:244]     Train net output #0: loss = 0.000242921 (* 1 = 0.000242921 loss)
I0403 04:10:28.310117  2204 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 04:10:37.421128  2204 solver.cpp:228] Iteration 6123, loss = 0.000392484
I0403 04:10:37.421242  2204 solver.cpp:244]     Train net output #0: loss = 0.000392513 (* 1 = 0.000392513 loss)
I0403 04:10:37.668699  2204 sgd_solver.cpp:106] Iteration 6123, lr = 5e-05
I0403 04:10:46.888684  2204 solver.cpp:228] Iteration 6136, loss = 4.10345e-05
I0403 04:10:46.888808  2204 solver.cpp:244]     Train net output #0: loss = 4.10634e-05 (* 1 = 4.10634e-05 loss)
I0403 04:10:47.051859  2204 sgd_solver.cpp:106] Iteration 6136, lr = 5e-05
I0403 04:10:56.321408  2204 solver.cpp:228] Iteration 6149, loss = 0.000562594
I0403 04:10:56.321753  2204 solver.cpp:244]     Train net output #0: loss = 0.000562623 (* 1 = 0.000562623 loss)
I0403 04:10:56.522853  2204 sgd_solver.cpp:106] Iteration 6149, lr = 5e-05
I0403 04:11:05.752955  2204 solver.cpp:228] Iteration 6162, loss = 0.000187946
I0403 04:11:05.753065  2204 solver.cpp:244]     Train net output #0: loss = 0.000187975 (* 1 = 0.000187975 loss)
I0403 04:11:05.969069  2204 sgd_solver.cpp:106] Iteration 6162, lr = 5e-05
I0403 04:11:06.680093  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6164.caffemodel
I0403 04:11:09.324111  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6164.solverstate
I0403 04:11:11.118315  2204 solver.cpp:337] Iteration 6164, Testing net (#0)
I0403 04:12:12.614652  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986315
I0403 04:12:12.615074  2204 solver.cpp:404]     Test net output #1: loss = 0.0525734 (* 1 = 0.0525734 loss)
I0403 04:12:21.210747  2204 solver.cpp:228] Iteration 6175, loss = 0.00704497
I0403 04:12:21.210861  2204 solver.cpp:244]     Train net output #0: loss = 0.00704499 (* 1 = 0.00704499 loss)
I0403 04:12:21.383266  2204 sgd_solver.cpp:106] Iteration 6175, lr = 5e-05
I0403 04:12:30.695157  2204 solver.cpp:228] Iteration 6188, loss = 0.00030118
I0403 04:12:30.695273  2204 solver.cpp:244]     Train net output #0: loss = 0.000301209 (* 1 = 0.000301209 loss)
I0403 04:12:30.879036  2204 sgd_solver.cpp:106] Iteration 6188, lr = 5e-05
I0403 04:12:40.263764  2204 solver.cpp:228] Iteration 6201, loss = 5.81545e-05
I0403 04:12:40.263881  2204 solver.cpp:244]     Train net output #0: loss = 5.81834e-05 (* 1 = 5.81834e-05 loss)
I0403 04:12:40.506330  2204 sgd_solver.cpp:106] Iteration 6201, lr = 5e-05
I0403 04:12:49.665701  2204 solver.cpp:228] Iteration 6214, loss = 0.000266587
I0403 04:12:49.666059  2204 solver.cpp:244]     Train net output #0: loss = 0.000266615 (* 1 = 0.000266615 loss)
I0403 04:12:49.853812  2204 sgd_solver.cpp:106] Iteration 6214, lr = 5e-05
I0403 04:12:59.103356  2204 solver.cpp:228] Iteration 6227, loss = 0.000614802
I0403 04:12:59.103471  2204 solver.cpp:244]     Train net output #0: loss = 0.000614831 (* 1 = 0.000614831 loss)
I0403 04:12:59.293454  2204 sgd_solver.cpp:106] Iteration 6227, lr = 5e-05
I0403 04:13:08.614037  2204 solver.cpp:228] Iteration 6240, loss = 0.000485861
I0403 04:13:08.614156  2204 solver.cpp:244]     Train net output #0: loss = 0.00048589 (* 1 = 0.00048589 loss)
I0403 04:13:08.807329  2204 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 04:13:17.987057  2204 solver.cpp:228] Iteration 6253, loss = 0.00208525
I0403 04:13:17.987171  2204 solver.cpp:244]     Train net output #0: loss = 0.00208528 (* 1 = 0.00208528 loss)
I0403 04:13:18.203017  2204 sgd_solver.cpp:106] Iteration 6253, lr = 5e-05
I0403 04:13:27.409941  2204 solver.cpp:228] Iteration 6266, loss = 8.62795e-05
I0403 04:13:27.413807  2204 solver.cpp:244]     Train net output #0: loss = 8.63082e-05 (* 1 = 8.63082e-05 loss)
I0403 04:13:27.570884  2204 sgd_solver.cpp:106] Iteration 6266, lr = 5e-05
I0403 04:13:36.803148  2204 solver.cpp:228] Iteration 6279, loss = 9.02055e-05
I0403 04:13:36.803251  2204 solver.cpp:244]     Train net output #0: loss = 9.02371e-05 (* 1 = 9.02371e-05 loss)
I0403 04:13:37.001097  2204 sgd_solver.cpp:106] Iteration 6279, lr = 5e-05
I0403 04:13:46.259778  2204 solver.cpp:228] Iteration 6292, loss = 3.26868e-05
I0403 04:13:46.259884  2204 solver.cpp:244]     Train net output #0: loss = 3.27183e-05 (* 1 = 3.27183e-05 loss)
I0403 04:13:46.438870  2204 sgd_solver.cpp:106] Iteration 6292, lr = 5e-05
I0403 04:13:55.726694  2204 solver.cpp:228] Iteration 6305, loss = 7.01137e-05
I0403 04:13:55.726811  2204 solver.cpp:244]     Train net output #0: loss = 7.01453e-05 (* 1 = 7.01453e-05 loss)
I0403 04:13:55.963044  2204 sgd_solver.cpp:106] Iteration 6305, lr = 5e-05
I0403 04:14:05.377245  2204 solver.cpp:228] Iteration 6318, loss = 0.0013855
I0403 04:14:05.377557  2204 solver.cpp:244]     Train net output #0: loss = 0.00138553 (* 1 = 0.00138553 loss)
I0403 04:14:05.564201  2204 sgd_solver.cpp:106] Iteration 6318, lr = 5e-05
I0403 04:14:14.785503  2204 solver.cpp:228] Iteration 6331, loss = 0.000926749
I0403 04:14:14.785610  2204 solver.cpp:244]     Train net output #0: loss = 0.000926781 (* 1 = 0.000926781 loss)
I0403 04:14:14.956060  2204 sgd_solver.cpp:106] Iteration 6331, lr = 5e-05
I0403 04:14:24.134702  2204 solver.cpp:228] Iteration 6344, loss = 0.000764409
I0403 04:14:24.134814  2204 solver.cpp:244]     Train net output #0: loss = 0.000764441 (* 1 = 0.000764441 loss)
I0403 04:14:24.314638  2204 sgd_solver.cpp:106] Iteration 6344, lr = 5e-05
I0403 04:14:33.506772  2204 solver.cpp:228] Iteration 6357, loss = 0.000217122
I0403 04:14:33.507818  2204 solver.cpp:244]     Train net output #0: loss = 0.000217154 (* 1 = 0.000217154 loss)
I0403 04:14:33.687818  2204 sgd_solver.cpp:106] Iteration 6357, lr = 5e-05
I0403 04:14:42.973341  2204 solver.cpp:228] Iteration 6370, loss = 0.000169832
I0403 04:14:42.973717  2204 solver.cpp:244]     Train net output #0: loss = 0.000169864 (* 1 = 0.000169864 loss)
I0403 04:14:43.142001  2204 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 04:14:52.503969  2204 solver.cpp:228] Iteration 6383, loss = 4.98784e-05
I0403 04:14:52.504067  2204 solver.cpp:244]     Train net output #0: loss = 4.99103e-05 (* 1 = 4.99103e-05 loss)
I0403 04:14:52.681284  2204 sgd_solver.cpp:106] Iteration 6383, lr = 5e-05
I0403 04:15:01.972863  2204 solver.cpp:228] Iteration 6396, loss = 0.000447811
I0403 04:15:01.972975  2204 solver.cpp:244]     Train net output #0: loss = 0.000447845 (* 1 = 0.000447845 loss)
I0403 04:15:02.160712  2204 sgd_solver.cpp:106] Iteration 6396, lr = 5e-05
I0403 04:15:11.400856  2204 solver.cpp:228] Iteration 6409, loss = 8.39502e-05
I0403 04:15:11.400974  2204 solver.cpp:244]     Train net output #0: loss = 8.39852e-05 (* 1 = 8.39852e-05 loss)
I0403 04:15:11.592010  2204 sgd_solver.cpp:106] Iteration 6409, lr = 5e-05
I0403 04:15:20.874646  2204 solver.cpp:228] Iteration 6422, loss = 0.00633763
I0403 04:15:20.874979  2204 solver.cpp:244]     Train net output #0: loss = 0.00633766 (* 1 = 0.00633766 loss)
I0403 04:15:21.085634  2204 sgd_solver.cpp:106] Iteration 6422, lr = 5e-05
I0403 04:15:27.587169  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6432.caffemodel
I0403 04:15:30.240511  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6432.solverstate
I0403 04:15:32.045892  2204 solver.cpp:337] Iteration 6432, Testing net (#0)
I0403 04:16:33.532079  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986351
I0403 04:16:33.532414  2204 solver.cpp:404]     Test net output #1: loss = 0.0527269 (* 1 = 0.0527269 loss)
I0403 04:16:36.361624  2204 solver.cpp:228] Iteration 6435, loss = 0.00244395
I0403 04:16:36.361728  2204 solver.cpp:244]     Train net output #0: loss = 0.00244398 (* 1 = 0.00244398 loss)
I0403 04:16:36.527098  2204 sgd_solver.cpp:106] Iteration 6435, lr = 5e-05
I0403 04:16:45.662554  2204 solver.cpp:228] Iteration 6448, loss = 0.000468445
I0403 04:16:45.662672  2204 solver.cpp:244]     Train net output #0: loss = 0.000468479 (* 1 = 0.000468479 loss)
I0403 04:16:45.895787  2204 sgd_solver.cpp:106] Iteration 6448, lr = 5e-05
I0403 04:16:55.198487  2204 solver.cpp:228] Iteration 6461, loss = 0.00104826
I0403 04:16:55.198603  2204 solver.cpp:244]     Train net output #0: loss = 0.0010483 (* 1 = 0.0010483 loss)
I0403 04:16:55.380906  2204 sgd_solver.cpp:106] Iteration 6461, lr = 5e-05
I0403 04:17:04.723429  2204 solver.cpp:228] Iteration 6474, loss = 0.00427962
I0403 04:17:04.723767  2204 solver.cpp:244]     Train net output #0: loss = 0.00427965 (* 1 = 0.00427965 loss)
I0403 04:17:04.905668  2204 sgd_solver.cpp:106] Iteration 6474, lr = 5e-05
I0403 04:17:14.188426  2204 solver.cpp:228] Iteration 6487, loss = 0.00321791
I0403 04:17:14.188529  2204 solver.cpp:244]     Train net output #0: loss = 0.00321795 (* 1 = 0.00321795 loss)
I0403 04:17:14.351219  2204 sgd_solver.cpp:106] Iteration 6487, lr = 5e-05
I0403 04:17:23.737773  2204 solver.cpp:228] Iteration 6500, loss = 0.000453484
I0403 04:17:23.737890  2204 solver.cpp:244]     Train net output #0: loss = 0.00045352 (* 1 = 0.00045352 loss)
I0403 04:17:23.870091  2204 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 04:17:33.320454  2204 solver.cpp:228] Iteration 6513, loss = 0.0019272
I0403 04:17:33.320559  2204 solver.cpp:244]     Train net output #0: loss = 0.00192724 (* 1 = 0.00192724 loss)
I0403 04:17:33.499438  2204 sgd_solver.cpp:106] Iteration 6513, lr = 5e-05
I0403 04:17:42.846371  2204 solver.cpp:228] Iteration 6526, loss = 0.00190611
I0403 04:17:42.847651  2204 solver.cpp:244]     Train net output #0: loss = 0.00190615 (* 1 = 0.00190615 loss)
I0403 04:17:43.056849  2204 sgd_solver.cpp:106] Iteration 6526, lr = 5e-05
I0403 04:17:52.323204  2204 solver.cpp:228] Iteration 6539, loss = 3.47625e-05
I0403 04:17:52.323309  2204 solver.cpp:244]     Train net output #0: loss = 3.47979e-05 (* 1 = 3.47979e-05 loss)
I0403 04:17:52.488041  2204 sgd_solver.cpp:106] Iteration 6539, lr = 5e-05
I0403 04:18:01.798812  2204 solver.cpp:228] Iteration 6552, loss = 0.00382855
I0403 04:18:01.798929  2204 solver.cpp:244]     Train net output #0: loss = 0.00382858 (* 1 = 0.00382858 loss)
I0403 04:18:01.990947  2204 sgd_solver.cpp:106] Iteration 6552, lr = 5e-05
I0403 04:18:11.264154  2204 solver.cpp:228] Iteration 6565, loss = 0.00041421
I0403 04:18:11.264256  2204 solver.cpp:244]     Train net output #0: loss = 0.000414246 (* 1 = 0.000414246 loss)
I0403 04:18:11.440031  2204 sgd_solver.cpp:106] Iteration 6565, lr = 5e-05
I0403 04:18:20.762979  2204 solver.cpp:228] Iteration 6578, loss = 0.000172078
I0403 04:18:20.763311  2204 solver.cpp:244]     Train net output #0: loss = 0.000172115 (* 1 = 0.000172115 loss)
I0403 04:18:20.952992  2204 sgd_solver.cpp:106] Iteration 6578, lr = 5e-05
I0403 04:18:30.396642  2204 solver.cpp:228] Iteration 6591, loss = 9.4993e-05
I0403 04:18:30.396747  2204 solver.cpp:244]     Train net output #0: loss = 9.50303e-05 (* 1 = 9.50303e-05 loss)
I0403 04:18:30.561298  2204 sgd_solver.cpp:106] Iteration 6591, lr = 5e-05
I0403 04:18:39.926296  2204 solver.cpp:228] Iteration 6604, loss = 0.000648163
I0403 04:18:39.926410  2204 solver.cpp:244]     Train net output #0: loss = 0.000648201 (* 1 = 0.000648201 loss)
I0403 04:18:40.114114  2204 sgd_solver.cpp:106] Iteration 6604, lr = 5e-05
I0403 04:18:49.311949  2204 solver.cpp:228] Iteration 6617, loss = 0.000106718
I0403 04:18:49.312064  2204 solver.cpp:244]     Train net output #0: loss = 0.000106755 (* 1 = 0.000106755 loss)
I0403 04:18:49.498586  2204 sgd_solver.cpp:106] Iteration 6617, lr = 5e-05
I0403 04:18:58.709668  2204 solver.cpp:228] Iteration 6630, loss = 0.00038834
I0403 04:18:58.710005  2204 solver.cpp:244]     Train net output #0: loss = 0.000388376 (* 1 = 0.000388376 loss)
I0403 04:18:58.903448  2204 sgd_solver.cpp:106] Iteration 6630, lr = 5e-05
I0403 04:19:08.150879  2204 solver.cpp:228] Iteration 6643, loss = 3.50713e-05
I0403 04:19:08.150980  2204 solver.cpp:244]     Train net output #0: loss = 3.51086e-05 (* 1 = 3.51086e-05 loss)
I0403 04:19:08.311539  2204 sgd_solver.cpp:106] Iteration 6643, lr = 5e-05
I0403 04:19:17.670006  2204 solver.cpp:228] Iteration 6656, loss = 0.00112233
I0403 04:19:17.670115  2204 solver.cpp:244]     Train net output #0: loss = 0.00112237 (* 1 = 0.00112237 loss)
I0403 04:19:17.849367  2204 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 04:19:27.058367  2204 solver.cpp:228] Iteration 6669, loss = 0.00150881
I0403 04:19:27.058472  2204 solver.cpp:244]     Train net output #0: loss = 0.00150884 (* 1 = 0.00150884 loss)
I0403 04:19:27.266371  2204 sgd_solver.cpp:106] Iteration 6669, lr = 5e-05
I0403 04:19:36.595782  2204 solver.cpp:228] Iteration 6682, loss = 0.00137323
I0403 04:19:36.596148  2204 solver.cpp:244]     Train net output #0: loss = 0.00137327 (* 1 = 0.00137327 loss)
I0403 04:19:36.779327  2204 sgd_solver.cpp:106] Iteration 6682, lr = 5e-05
I0403 04:19:45.990970  2204 solver.cpp:228] Iteration 6695, loss = 0.00028514
I0403 04:19:45.991086  2204 solver.cpp:244]     Train net output #0: loss = 0.000285177 (* 1 = 0.000285177 loss)
I0403 04:19:46.216356  2204 sgd_solver.cpp:106] Iteration 6695, lr = 5e-05
I0403 04:19:49.071604  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6700.caffemodel
I0403 04:19:51.827934  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6700.solverstate
I0403 04:19:53.725159  2204 solver.cpp:337] Iteration 6700, Testing net (#0)
I0403 04:20:55.202373  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986534
I0403 04:20:55.202744  2204 solver.cpp:404]     Test net output #1: loss = 0.0530439 (* 1 = 0.0530439 loss)
I0403 04:21:01.551403  2204 solver.cpp:228] Iteration 6708, loss = 1.82918e-05
I0403 04:21:01.551518  2204 solver.cpp:244]     Train net output #0: loss = 1.83281e-05 (* 1 = 1.83281e-05 loss)
I0403 04:21:01.763973  2204 sgd_solver.cpp:106] Iteration 6708, lr = 5e-05
I0403 04:21:11.174783  2204 solver.cpp:228] Iteration 6721, loss = 0.00196253
I0403 04:21:11.174901  2204 solver.cpp:244]     Train net output #0: loss = 0.00196256 (* 1 = 0.00196256 loss)
I0403 04:21:11.359997  2204 sgd_solver.cpp:106] Iteration 6721, lr = 5e-05
I0403 04:21:20.580960  2204 solver.cpp:228] Iteration 6734, loss = 1.49065e-05
I0403 04:21:20.581075  2204 solver.cpp:244]     Train net output #0: loss = 1.49435e-05 (* 1 = 1.49435e-05 loss)
I0403 04:21:20.763486  2204 sgd_solver.cpp:106] Iteration 6734, lr = 5e-05
I0403 04:21:30.015998  2204 solver.cpp:228] Iteration 6747, loss = 0.0177908
I0403 04:21:30.016430  2204 solver.cpp:244]     Train net output #0: loss = 0.0177909 (* 1 = 0.0177909 loss)
I0403 04:21:30.209887  2204 sgd_solver.cpp:106] Iteration 6747, lr = 5e-05
I0403 04:21:39.413270  2204 solver.cpp:228] Iteration 6760, loss = 0.00023265
I0403 04:21:39.413388  2204 solver.cpp:244]     Train net output #0: loss = 0.000232688 (* 1 = 0.000232688 loss)
I0403 04:21:39.618649  2204 sgd_solver.cpp:106] Iteration 6760, lr = 5e-05
I0403 04:21:48.909001  2204 solver.cpp:228] Iteration 6773, loss = 8.55789e-05
I0403 04:21:48.909121  2204 solver.cpp:244]     Train net output #0: loss = 8.56174e-05 (* 1 = 8.56174e-05 loss)
I0403 04:21:49.137606  2204 sgd_solver.cpp:106] Iteration 6773, lr = 5e-05
I0403 04:21:58.411249  2204 solver.cpp:228] Iteration 6786, loss = 0.0015379
I0403 04:21:58.411368  2204 solver.cpp:244]     Train net output #0: loss = 0.00153794 (* 1 = 0.00153794 loss)
I0403 04:21:58.598754  2204 sgd_solver.cpp:106] Iteration 6786, lr = 5e-05
I0403 04:22:07.838595  2204 solver.cpp:228] Iteration 6799, loss = 0.000500436
I0403 04:22:07.838917  2204 solver.cpp:244]     Train net output #0: loss = 0.000500474 (* 1 = 0.000500474 loss)
I0403 04:22:08.019285  2204 sgd_solver.cpp:106] Iteration 6799, lr = 5e-05
I0403 04:22:17.231873  2204 solver.cpp:228] Iteration 6812, loss = 0.00905581
I0403 04:22:17.231992  2204 solver.cpp:244]     Train net output #0: loss = 0.00905585 (* 1 = 0.00905585 loss)
I0403 04:22:17.416218  2204 sgd_solver.cpp:106] Iteration 6812, lr = 5e-05
I0403 04:22:26.737007  2204 solver.cpp:228] Iteration 6825, loss = 7.48964e-05
I0403 04:22:26.737120  2204 solver.cpp:244]     Train net output #0: loss = 7.4935e-05 (* 1 = 7.4935e-05 loss)
I0403 04:22:26.869321  2204 sgd_solver.cpp:106] Iteration 6825, lr = 5e-05
I0403 04:22:36.148121  2204 solver.cpp:228] Iteration 6838, loss = 0.00275222
I0403 04:22:36.148236  2204 solver.cpp:244]     Train net output #0: loss = 0.00275226 (* 1 = 0.00275226 loss)
I0403 04:22:36.330668  2204 sgd_solver.cpp:106] Iteration 6838, lr = 5e-05
I0403 04:22:45.556190  2204 solver.cpp:228] Iteration 6851, loss = 0.00301636
I0403 04:22:45.558672  2204 solver.cpp:244]     Train net output #0: loss = 0.0030164 (* 1 = 0.0030164 loss)
I0403 04:22:45.741467  2204 sgd_solver.cpp:106] Iteration 6851, lr = 5e-05
I0403 04:22:54.952070  2204 solver.cpp:228] Iteration 6864, loss = 0.0108593
I0403 04:22:54.952183  2204 solver.cpp:244]     Train net output #0: loss = 0.0108593 (* 1 = 0.0108593 loss)
I0403 04:22:55.143918  2204 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 04:23:04.279008  2204 solver.cpp:228] Iteration 6877, loss = 6.93832e-05
I0403 04:23:04.279112  2204 solver.cpp:244]     Train net output #0: loss = 6.94208e-05 (* 1 = 6.94208e-05 loss)
I0403 04:23:04.458715  2204 sgd_solver.cpp:106] Iteration 6877, lr = 5e-05
I0403 04:23:13.822270  2204 solver.cpp:228] Iteration 6890, loss = 0.000122347
I0403 04:23:13.822407  2204 solver.cpp:244]     Train net output #0: loss = 0.000122385 (* 1 = 0.000122385 loss)
I0403 04:23:14.003514  2204 sgd_solver.cpp:106] Iteration 6890, lr = 5e-05
I0403 04:23:23.347484  2204 solver.cpp:228] Iteration 6903, loss = 0.00013582
I0403 04:23:23.347776  2204 solver.cpp:244]     Train net output #0: loss = 0.000135858 (* 1 = 0.000135858 loss)
I0403 04:23:23.482513  2204 sgd_solver.cpp:106] Iteration 6903, lr = 5e-05
I0403 04:23:32.828517  2204 solver.cpp:228] Iteration 6916, loss = 9.20306e-05
I0403 04:23:32.828630  2204 solver.cpp:244]     Train net output #0: loss = 9.20696e-05 (* 1 = 9.20696e-05 loss)
I0403 04:23:33.024392  2204 sgd_solver.cpp:106] Iteration 6916, lr = 5e-05
I0403 04:23:42.357311  2204 solver.cpp:228] Iteration 6929, loss = 7.76029e-05
I0403 04:23:42.357426  2204 solver.cpp:244]     Train net output #0: loss = 7.76419e-05 (* 1 = 7.76419e-05 loss)
I0403 04:23:42.557903  2204 sgd_solver.cpp:106] Iteration 6929, lr = 5e-05
I0403 04:23:51.896764  2204 solver.cpp:228] Iteration 6942, loss = 0.000286592
I0403 04:23:51.896880  2204 solver.cpp:244]     Train net output #0: loss = 0.000286631 (* 1 = 0.000286631 loss)
I0403 04:23:52.102254  2204 sgd_solver.cpp:106] Iteration 6942, lr = 5e-05
I0403 04:24:01.401319  2204 solver.cpp:228] Iteration 6955, loss = 5.09126e-05
I0403 04:24:01.401656  2204 solver.cpp:244]     Train net output #0: loss = 5.09518e-05 (* 1 = 5.09518e-05 loss)
I0403 04:24:01.589047  2204 sgd_solver.cpp:106] Iteration 6955, lr = 5e-05
I0403 04:24:10.320835  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6968.caffemodel
I0403 04:24:13.035233  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_6968.solverstate
I0403 04:24:14.827899  2204 solver.cpp:337] Iteration 6968, Testing net (#0)
I0403 04:25:16.334779  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986461
I0403 04:25:16.335091  2204 solver.cpp:404]     Test net output #1: loss = 0.0529893 (* 1 = 0.0529893 loss)
I0403 04:25:16.843976  2204 solver.cpp:228] Iteration 6968, loss = 6.01757e-05
I0403 04:25:16.844086  2204 solver.cpp:244]     Train net output #0: loss = 6.02145e-05 (* 1 = 6.02145e-05 loss)
I0403 04:25:17.043082  2204 sgd_solver.cpp:106] Iteration 6968, lr = 5e-05
I0403 04:25:26.420011  2204 solver.cpp:228] Iteration 6981, loss = 0.000563855
I0403 04:25:26.420115  2204 solver.cpp:244]     Train net output #0: loss = 0.000563894 (* 1 = 0.000563894 loss)
I0403 04:25:26.593192  2204 sgd_solver.cpp:106] Iteration 6981, lr = 5e-05
I0403 04:25:35.946264  2204 solver.cpp:228] Iteration 6994, loss = 0.0102519
I0403 04:25:35.946364  2204 solver.cpp:244]     Train net output #0: loss = 0.010252 (* 1 = 0.010252 loss)
I0403 04:25:36.121006  2204 sgd_solver.cpp:106] Iteration 6994, lr = 5e-05
I0403 04:25:45.465190  2204 solver.cpp:228] Iteration 7007, loss = 0.000208828
I0403 04:25:45.465308  2204 solver.cpp:244]     Train net output #0: loss = 0.000208867 (* 1 = 0.000208867 loss)
I0403 04:25:45.683837  2204 sgd_solver.cpp:106] Iteration 7007, lr = 5e-05
I0403 04:25:55.063742  2204 solver.cpp:228] Iteration 7020, loss = 0.000946896
I0403 04:25:55.064085  2204 solver.cpp:244]     Train net output #0: loss = 0.000946935 (* 1 = 0.000946935 loss)
I0403 04:25:55.277192  2204 sgd_solver.cpp:106] Iteration 7020, lr = 5e-05
I0403 04:26:04.484225  2204 solver.cpp:228] Iteration 7033, loss = 0.0128786
I0403 04:26:04.484339  2204 solver.cpp:244]     Train net output #0: loss = 0.0128786 (* 1 = 0.0128786 loss)
I0403 04:26:04.726109  2204 sgd_solver.cpp:106] Iteration 7033, lr = 5e-05
I0403 04:26:13.941488  2204 solver.cpp:228] Iteration 7046, loss = 0.000191154
I0403 04:26:13.941606  2204 solver.cpp:244]     Train net output #0: loss = 0.000191192 (* 1 = 0.000191192 loss)
I0403 04:26:14.128839  2204 sgd_solver.cpp:106] Iteration 7046, lr = 5e-05
I0403 04:26:23.588053  2204 solver.cpp:228] Iteration 7059, loss = 0.0121823
I0403 04:26:23.588152  2204 solver.cpp:244]     Train net output #0: loss = 0.0121823 (* 1 = 0.0121823 loss)
I0403 04:26:23.763250  2204 sgd_solver.cpp:106] Iteration 7059, lr = 5e-05
I0403 04:26:33.070194  2204 solver.cpp:228] Iteration 7072, loss = 0.00163217
I0403 04:26:33.070524  2204 solver.cpp:244]     Train net output #0: loss = 0.00163221 (* 1 = 0.00163221 loss)
I0403 04:26:33.250922  2204 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 04:26:42.433945  2204 solver.cpp:228] Iteration 7085, loss = 0.00322032
I0403 04:26:42.434051  2204 solver.cpp:244]     Train net output #0: loss = 0.00322036 (* 1 = 0.00322036 loss)
I0403 04:26:42.598187  2204 sgd_solver.cpp:106] Iteration 7085, lr = 5e-05
I0403 04:26:52.051122  2204 solver.cpp:228] Iteration 7098, loss = 0.00111949
I0403 04:26:52.051229  2204 solver.cpp:244]     Train net output #0: loss = 0.00111953 (* 1 = 0.00111953 loss)
I0403 04:26:52.214540  2204 sgd_solver.cpp:106] Iteration 7098, lr = 5e-05
I0403 04:27:01.545263  2204 solver.cpp:228] Iteration 7111, loss = 5.23037e-05
I0403 04:27:01.545354  2204 solver.cpp:244]     Train net output #0: loss = 5.23432e-05 (* 1 = 5.23432e-05 loss)
I0403 04:27:01.728977  2204 sgd_solver.cpp:106] Iteration 7111, lr = 5e-05
I0403 04:27:11.144704  2204 solver.cpp:228] Iteration 7124, loss = 0.000108334
I0403 04:27:11.145047  2204 solver.cpp:244]     Train net output #0: loss = 0.000108374 (* 1 = 0.000108374 loss)
I0403 04:27:11.369532  2204 sgd_solver.cpp:106] Iteration 7124, lr = 5e-05
I0403 04:27:20.661813  2204 solver.cpp:228] Iteration 7137, loss = 0.00682462
I0403 04:27:20.668660  2204 solver.cpp:244]     Train net output #0: loss = 0.00682466 (* 1 = 0.00682466 loss)
I0403 04:27:20.838943  2204 sgd_solver.cpp:106] Iteration 7137, lr = 5e-05
I0403 04:27:30.163374  2204 solver.cpp:228] Iteration 7150, loss = 0.00245004
I0403 04:27:30.163486  2204 solver.cpp:244]     Train net output #0: loss = 0.00245008 (* 1 = 0.00245008 loss)
I0403 04:27:30.357815  2204 sgd_solver.cpp:106] Iteration 7150, lr = 5e-05
I0403 04:27:40.194186  2204 solver.cpp:228] Iteration 7163, loss = 0.000141865
I0403 04:27:40.194291  2204 solver.cpp:244]     Train net output #0: loss = 0.000141905 (* 1 = 0.000141905 loss)
I0403 04:27:40.353149  2204 sgd_solver.cpp:106] Iteration 7163, lr = 5e-05
I0403 04:27:49.644062  2204 solver.cpp:228] Iteration 7176, loss = 0.000233707
I0403 04:27:49.644404  2204 solver.cpp:244]     Train net output #0: loss = 0.000233746 (* 1 = 0.000233746 loss)
I0403 04:27:49.832177  2204 sgd_solver.cpp:106] Iteration 7176, lr = 5e-05
I0403 04:27:59.090332  2204 solver.cpp:228] Iteration 7189, loss = 0.000572741
I0403 04:27:59.090427  2204 solver.cpp:244]     Train net output #0: loss = 0.000572779 (* 1 = 0.000572779 loss)
I0403 04:27:59.249125  2204 sgd_solver.cpp:106] Iteration 7189, lr = 5e-05
I0403 04:28:08.617727  2204 solver.cpp:228] Iteration 7202, loss = 0.00035996
I0403 04:28:08.617836  2204 solver.cpp:244]     Train net output #0: loss = 0.000359999 (* 1 = 0.000359999 loss)
I0403 04:28:08.793110  2204 sgd_solver.cpp:106] Iteration 7202, lr = 5e-05
I0403 04:28:18.064261  2204 solver.cpp:228] Iteration 7215, loss = 0.000485302
I0403 04:28:18.064365  2204 solver.cpp:244]     Train net output #0: loss = 0.000485341 (* 1 = 0.000485341 loss)
I0403 04:28:18.235404  2204 sgd_solver.cpp:106] Iteration 7215, lr = 5e-05
I0403 04:28:27.616413  2204 solver.cpp:228] Iteration 7228, loss = 0.00163419
I0403 04:28:27.616701  2204 solver.cpp:244]     Train net output #0: loss = 0.00163423 (* 1 = 0.00163423 loss)
I0403 04:28:27.799666  2204 sgd_solver.cpp:106] Iteration 7228, lr = 5e-05
I0403 04:28:32.942366  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_7236.caffemodel
I0403 04:28:35.625449  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_7236.solverstate
I0403 04:28:37.431793  2204 solver.cpp:337] Iteration 7236, Testing net (#0)
I0403 04:29:38.912742  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986534
I0403 04:29:38.914357  2204 solver.cpp:404]     Test net output #1: loss = 0.05274 (* 1 = 0.05274 loss)
I0403 04:29:43.013631  2204 solver.cpp:228] Iteration 7241, loss = 0.000268893
I0403 04:29:43.013742  2204 solver.cpp:244]     Train net output #0: loss = 0.000268932 (* 1 = 0.000268932 loss)
I0403 04:29:43.230674  2204 sgd_solver.cpp:106] Iteration 7241, lr = 5e-05
I0403 04:29:52.495499  2204 solver.cpp:228] Iteration 7254, loss = 0.000612923
I0403 04:29:52.495615  2204 solver.cpp:244]     Train net output #0: loss = 0.000612963 (* 1 = 0.000612963 loss)
I0403 04:29:52.736353  2204 sgd_solver.cpp:106] Iteration 7254, lr = 5e-05
I0403 04:30:02.031011  2204 solver.cpp:228] Iteration 7267, loss = 0.000218617
I0403 04:30:02.031126  2204 solver.cpp:244]     Train net output #0: loss = 0.000218656 (* 1 = 0.000218656 loss)
I0403 04:30:02.225806  2204 sgd_solver.cpp:106] Iteration 7267, lr = 5e-05
I0403 04:30:11.682507  2204 solver.cpp:228] Iteration 7280, loss = 0.00555955
I0403 04:30:11.682831  2204 solver.cpp:244]     Train net output #0: loss = 0.00555959 (* 1 = 0.00555959 loss)
I0403 04:30:11.859259  2204 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 04:30:21.077905  2204 solver.cpp:228] Iteration 7293, loss = 0.00249434
I0403 04:30:21.078011  2204 solver.cpp:244]     Train net output #0: loss = 0.00249438 (* 1 = 0.00249438 loss)
I0403 04:30:21.233724  2204 sgd_solver.cpp:106] Iteration 7293, lr = 5e-05
I0403 04:30:30.623702  2204 solver.cpp:228] Iteration 7306, loss = 0.0058944
I0403 04:30:30.623818  2204 solver.cpp:244]     Train net output #0: loss = 0.00589444 (* 1 = 0.00589444 loss)
I0403 04:30:30.819628  2204 sgd_solver.cpp:106] Iteration 7306, lr = 5e-05
I0403 04:30:40.276916  2204 solver.cpp:228] Iteration 7319, loss = 0.000509077
I0403 04:30:40.277020  2204 solver.cpp:244]     Train net output #0: loss = 0.000509116 (* 1 = 0.000509116 loss)
I0403 04:30:40.428683  2204 sgd_solver.cpp:106] Iteration 7319, lr = 5e-05
I0403 04:30:49.844583  2204 solver.cpp:228] Iteration 7332, loss = 0.000275993
I0403 04:30:49.844926  2204 solver.cpp:244]     Train net output #0: loss = 0.000276033 (* 1 = 0.000276033 loss)
I0403 04:30:50.047636  2204 sgd_solver.cpp:106] Iteration 7332, lr = 5e-05
I0403 04:30:59.340662  2204 solver.cpp:228] Iteration 7345, loss = 0.00513405
I0403 04:30:59.340785  2204 solver.cpp:244]     Train net output #0: loss = 0.00513409 (* 1 = 0.00513409 loss)
I0403 04:30:59.538720  2204 sgd_solver.cpp:106] Iteration 7345, lr = 5e-05
I0403 04:31:08.792800  2204 solver.cpp:228] Iteration 7358, loss = 0.000866121
I0403 04:31:08.792908  2204 solver.cpp:244]     Train net output #0: loss = 0.00086616 (* 1 = 0.00086616 loss)
I0403 04:31:08.996343  2204 sgd_solver.cpp:106] Iteration 7358, lr = 5e-05
I0403 04:31:18.180708  2204 solver.cpp:228] Iteration 7371, loss = 7.26528e-05
I0403 04:31:18.180819  2204 solver.cpp:244]     Train net output #0: loss = 7.26924e-05 (* 1 = 7.26924e-05 loss)
I0403 04:31:18.360306  2204 sgd_solver.cpp:106] Iteration 7371, lr = 5e-05
I0403 04:31:27.692129  2204 solver.cpp:228] Iteration 7384, loss = 0.000395849
I0403 04:31:27.692430  2204 solver.cpp:244]     Train net output #0: loss = 0.000395888 (* 1 = 0.000395888 loss)
I0403 04:31:27.804270  2204 sgd_solver.cpp:106] Iteration 7384, lr = 5e-05
I0403 04:31:37.339051  2204 solver.cpp:228] Iteration 7397, loss = 8.53059e-05
I0403 04:31:37.339162  2204 solver.cpp:244]     Train net output #0: loss = 8.53455e-05 (* 1 = 8.53455e-05 loss)
I0403 04:31:37.561101  2204 sgd_solver.cpp:106] Iteration 7397, lr = 5e-05
I0403 04:31:46.855940  2204 solver.cpp:228] Iteration 7410, loss = 0.000227427
I0403 04:31:46.856043  2204 solver.cpp:244]     Train net output #0: loss = 0.000227467 (* 1 = 0.000227467 loss)
I0403 04:31:47.032691  2204 sgd_solver.cpp:106] Iteration 7410, lr = 5e-05
I0403 04:31:56.223368  2204 solver.cpp:228] Iteration 7423, loss = 6.2295e-05
I0403 04:31:56.223470  2204 solver.cpp:244]     Train net output #0: loss = 6.23351e-05 (* 1 = 6.23351e-05 loss)
I0403 04:31:56.392097  2204 sgd_solver.cpp:106] Iteration 7423, lr = 5e-05
I0403 04:32:05.882668  2204 solver.cpp:228] Iteration 7436, loss = 0.000602889
I0403 04:32:05.883016  2204 solver.cpp:244]     Train net output #0: loss = 0.000602929 (* 1 = 0.000602929 loss)
I0403 04:32:06.070365  2204 sgd_solver.cpp:106] Iteration 7436, lr = 5e-05
I0403 04:32:15.297309  2204 solver.cpp:228] Iteration 7449, loss = 6.25722e-05
I0403 04:32:15.297425  2204 solver.cpp:244]     Train net output #0: loss = 6.26122e-05 (* 1 = 6.26122e-05 loss)
I0403 04:32:15.481243  2204 sgd_solver.cpp:106] Iteration 7449, lr = 5e-05
I0403 04:32:24.767149  2204 solver.cpp:228] Iteration 7462, loss = 0.00164706
I0403 04:32:24.767252  2204 solver.cpp:244]     Train net output #0: loss = 0.0016471 (* 1 = 0.0016471 loss)
I0403 04:32:24.942349  2204 sgd_solver.cpp:106] Iteration 7462, lr = 5e-05
I0403 04:32:34.158115  2204 solver.cpp:228] Iteration 7475, loss = 0.00197521
I0403 04:32:34.158233  2204 solver.cpp:244]     Train net output #0: loss = 0.00197525 (* 1 = 0.00197525 loss)
I0403 04:32:34.354667  2204 sgd_solver.cpp:106] Iteration 7475, lr = 5e-05
I0403 04:32:43.631294  2204 solver.cpp:228] Iteration 7488, loss = 0.00952037
I0403 04:32:43.631604  2204 solver.cpp:244]     Train net output #0: loss = 0.00952041 (* 1 = 0.00952041 loss)
I0403 04:32:43.802633  2204 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 04:32:52.873147  2204 solver.cpp:228] Iteration 7501, loss = 0.00172046
I0403 04:32:52.873263  2204 solver.cpp:244]     Train net output #0: loss = 0.0017205 (* 1 = 0.0017205 loss)
I0403 04:32:53.072016  2204 sgd_solver.cpp:106] Iteration 7501, lr = 5e-05
I0403 04:32:54.524293  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_7504.caffemodel
I0403 04:32:57.236357  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_7504.solverstate
I0403 04:32:59.077967  2204 solver.cpp:337] Iteration 7504, Testing net (#0)
I0403 04:34:00.561023  2204 solver.cpp:404]     Test net output #0: accuracy = 0.98657
I0403 04:34:00.561359  2204 solver.cpp:404]     Test net output #1: loss = 0.0529211 (* 1 = 0.0529211 loss)
I0403 04:34:08.341651  2204 solver.cpp:228] Iteration 7514, loss = 0.000393573
I0403 04:34:08.341752  2204 solver.cpp:244]     Train net output #0: loss = 0.000393615 (* 1 = 0.000393615 loss)
I0403 04:34:08.514868  2204 sgd_solver.cpp:106] Iteration 7514, lr = 5e-05
I0403 04:34:17.686028  2204 solver.cpp:228] Iteration 7527, loss = 0.000168904
I0403 04:34:17.686142  2204 solver.cpp:244]     Train net output #0: loss = 0.000168946 (* 1 = 0.000168946 loss)
I0403 04:34:17.923921  2204 sgd_solver.cpp:106] Iteration 7527, lr = 5e-05
I0403 04:34:27.222345  2204 solver.cpp:228] Iteration 7540, loss = 0.000191429
I0403 04:34:27.222446  2204 solver.cpp:244]     Train net output #0: loss = 0.000191472 (* 1 = 0.000191472 loss)
I0403 04:34:27.402845  2204 sgd_solver.cpp:106] Iteration 7540, lr = 5e-05
I0403 04:34:36.627796  2204 solver.cpp:228] Iteration 7553, loss = 0.00487106
I0403 04:34:36.628123  2204 solver.cpp:244]     Train net output #0: loss = 0.00487111 (* 1 = 0.00487111 loss)
I0403 04:34:36.806839  2204 sgd_solver.cpp:106] Iteration 7553, lr = 5e-05
I0403 04:34:46.307658  2204 solver.cpp:228] Iteration 7566, loss = 0.000679238
I0403 04:34:46.307761  2204 solver.cpp:244]     Train net output #0: loss = 0.00067928 (* 1 = 0.00067928 loss)
I0403 04:34:46.486299  2204 sgd_solver.cpp:106] Iteration 7566, lr = 5e-05
I0403 04:34:55.690188  2204 solver.cpp:228] Iteration 7579, loss = 0.000480278
I0403 04:34:55.690292  2204 solver.cpp:244]     Train net output #0: loss = 0.000480321 (* 1 = 0.000480321 loss)
I0403 04:34:55.863502  2204 sgd_solver.cpp:106] Iteration 7579, lr = 5e-05
I0403 04:35:05.205487  2204 solver.cpp:228] Iteration 7592, loss = 0.000636243
I0403 04:35:05.205601  2204 solver.cpp:244]     Train net output #0: loss = 0.000636285 (* 1 = 0.000636285 loss)
I0403 04:35:05.399579  2204 sgd_solver.cpp:106] Iteration 7592, lr = 5e-05
I0403 04:35:14.749815  2204 solver.cpp:228] Iteration 7605, loss = 8.60832e-05
I0403 04:35:14.750135  2204 solver.cpp:244]     Train net output #0: loss = 8.61259e-05 (* 1 = 8.61259e-05 loss)
I0403 04:35:14.921922  2204 sgd_solver.cpp:106] Iteration 7605, lr = 5e-05
I0403 04:35:24.175276  2204 solver.cpp:228] Iteration 7618, loss = 0.000512529
I0403 04:35:24.175390  2204 solver.cpp:244]     Train net output #0: loss = 0.000512572 (* 1 = 0.000512572 loss)
I0403 04:35:24.385663  2204 sgd_solver.cpp:106] Iteration 7618, lr = 5e-05
I0403 04:35:33.682572  2204 solver.cpp:228] Iteration 7631, loss = 0.000447204
I0403 04:35:33.682687  2204 solver.cpp:244]     Train net output #0: loss = 0.000447247 (* 1 = 0.000447247 loss)
I0403 04:35:33.871160  2204 sgd_solver.cpp:106] Iteration 7631, lr = 5e-05
I0403 04:35:43.096081  2204 solver.cpp:228] Iteration 7644, loss = 0.000233962
I0403 04:35:43.096192  2204 solver.cpp:244]     Train net output #0: loss = 0.000234005 (* 1 = 0.000234005 loss)
I0403 04:35:43.316290  2204 sgd_solver.cpp:106] Iteration 7644, lr = 5e-05
I0403 04:35:52.577204  2204 solver.cpp:228] Iteration 7657, loss = 0.000669372
I0403 04:35:52.577533  2204 solver.cpp:244]     Train net output #0: loss = 0.000669415 (* 1 = 0.000669415 loss)
I0403 04:35:52.786213  2204 sgd_solver.cpp:106] Iteration 7657, lr = 5e-05
I0403 04:36:01.958932  2204 solver.cpp:228] Iteration 7670, loss = 0.000376369
I0403 04:36:01.959049  2204 solver.cpp:244]     Train net output #0: loss = 0.000376412 (* 1 = 0.000376412 loss)
I0403 04:36:02.140372  2204 sgd_solver.cpp:106] Iteration 7670, lr = 5e-05
I0403 04:36:11.583818  2204 solver.cpp:228] Iteration 7683, loss = 0.000494093
I0403 04:36:11.583930  2204 solver.cpp:244]     Train net output #0: loss = 0.000494136 (* 1 = 0.000494136 loss)
I0403 04:36:11.752749  2204 sgd_solver.cpp:106] Iteration 7683, lr = 5e-05
I0403 04:36:21.154983  2204 solver.cpp:228] Iteration 7696, loss = 0.000527618
I0403 04:36:21.155088  2204 solver.cpp:244]     Train net output #0: loss = 0.00052766 (* 1 = 0.00052766 loss)
I0403 04:36:21.328842  2204 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 04:36:30.590107  2204 solver.cpp:228] Iteration 7709, loss = 0.0155728
I0403 04:36:30.590450  2204 solver.cpp:244]     Train net output #0: loss = 0.0155729 (* 1 = 0.0155729 loss)
I0403 04:36:30.777375  2204 sgd_solver.cpp:106] Iteration 7709, lr = 5e-05
I0403 04:36:39.942499  2204 solver.cpp:228] Iteration 7722, loss = 0.00131421
I0403 04:36:39.942613  2204 solver.cpp:244]     Train net output #0: loss = 0.00131426 (* 1 = 0.00131426 loss)
I0403 04:36:40.140702  2204 sgd_solver.cpp:106] Iteration 7722, lr = 5e-05
I0403 04:36:49.388548  2204 solver.cpp:228] Iteration 7735, loss = 0.0147276
I0403 04:36:49.388664  2204 solver.cpp:244]     Train net output #0: loss = 0.0147276 (* 1 = 0.0147276 loss)
I0403 04:36:49.591473  2204 sgd_solver.cpp:106] Iteration 7735, lr = 5e-05
I0403 04:36:58.776701  2204 solver.cpp:228] Iteration 7748, loss = 0.00054589
I0403 04:36:58.776821  2204 solver.cpp:244]     Train net output #0: loss = 0.000545933 (* 1 = 0.000545933 loss)
I0403 04:36:59.046213  2204 sgd_solver.cpp:106] Iteration 7748, lr = 5e-05
I0403 04:37:08.233572  2204 solver.cpp:228] Iteration 7761, loss = 0.000412556
I0403 04:37:08.233940  2204 solver.cpp:244]     Train net output #0: loss = 0.000412598 (* 1 = 0.000412598 loss)
I0403 04:37:08.418849  2204 sgd_solver.cpp:106] Iteration 7761, lr = 5e-05
I0403 04:37:15.563117  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_7772.caffemodel
I0403 04:37:18.251360  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_7772.solverstate
I0403 04:37:20.082819  2204 solver.cpp:337] Iteration 7772, Testing net (#0)
I0403 04:38:21.559840  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986606
I0403 04:38:21.568758  2204 solver.cpp:404]     Test net output #1: loss = 0.0526877 (* 1 = 0.0526877 loss)
I0403 04:38:23.502902  2204 solver.cpp:228] Iteration 7774, loss = 7.62917e-05
I0403 04:38:23.503018  2204 solver.cpp:244]     Train net output #0: loss = 7.63347e-05 (* 1 = 7.63347e-05 loss)
I0403 04:38:23.669775  2204 sgd_solver.cpp:106] Iteration 7774, lr = 5e-05
I0403 04:38:32.884515  2204 solver.cpp:228] Iteration 7787, loss = 6.37178e-05
I0403 04:38:32.884630  2204 solver.cpp:244]     Train net output #0: loss = 6.37603e-05 (* 1 = 6.37603e-05 loss)
I0403 04:38:33.072480  2204 sgd_solver.cpp:106] Iteration 7787, lr = 5e-05
I0403 04:38:42.303066  2204 solver.cpp:228] Iteration 7800, loss = 0.00208339
I0403 04:38:42.303182  2204 solver.cpp:244]     Train net output #0: loss = 0.00208343 (* 1 = 0.00208343 loss)
I0403 04:38:42.489091  2204 sgd_solver.cpp:106] Iteration 7800, lr = 5e-05
I0403 04:38:51.860041  2204 solver.cpp:228] Iteration 7813, loss = 0.000276297
I0403 04:38:51.860388  2204 solver.cpp:244]     Train net output #0: loss = 0.00027634 (* 1 = 0.00027634 loss)
I0403 04:38:52.056747  2204 sgd_solver.cpp:106] Iteration 7813, lr = 5e-05
I0403 04:39:01.309161  2204 solver.cpp:228] Iteration 7826, loss = 0.00337349
I0403 04:39:01.309262  2204 solver.cpp:244]     Train net output #0: loss = 0.00337354 (* 1 = 0.00337354 loss)
I0403 04:39:01.483213  2204 sgd_solver.cpp:106] Iteration 7826, lr = 5e-05
I0403 04:39:10.746373  2204 solver.cpp:228] Iteration 7839, loss = 0.000204978
I0403 04:39:10.746477  2204 solver.cpp:244]     Train net output #0: loss = 0.000205021 (* 1 = 0.000205021 loss)
I0403 04:39:10.923079  2204 sgd_solver.cpp:106] Iteration 7839, lr = 5e-05
I0403 04:39:20.196069  2204 solver.cpp:228] Iteration 7852, loss = 0.000288516
I0403 04:39:20.196184  2204 solver.cpp:244]     Train net output #0: loss = 0.000288561 (* 1 = 0.000288561 loss)
I0403 04:39:20.400179  2204 sgd_solver.cpp:106] Iteration 7852, lr = 5e-05
I0403 04:39:29.772342  2204 solver.cpp:228] Iteration 7865, loss = 0.000400027
I0403 04:39:29.772662  2204 solver.cpp:244]     Train net output #0: loss = 0.000400072 (* 1 = 0.000400072 loss)
I0403 04:39:29.977032  2204 sgd_solver.cpp:106] Iteration 7865, lr = 5e-05
I0403 04:39:39.222090  2204 solver.cpp:228] Iteration 7878, loss = 0.00319946
I0403 04:39:39.222193  2204 solver.cpp:244]     Train net output #0: loss = 0.0031995 (* 1 = 0.0031995 loss)
I0403 04:39:39.398229  2204 sgd_solver.cpp:106] Iteration 7878, lr = 5e-05
I0403 04:39:48.610968  2204 solver.cpp:228] Iteration 7891, loss = 0.000957478
I0403 04:39:48.611085  2204 solver.cpp:244]     Train net output #0: loss = 0.000957525 (* 1 = 0.000957525 loss)
I0403 04:39:48.804136  2204 sgd_solver.cpp:106] Iteration 7891, lr = 5e-05
I0403 04:39:57.997064  2204 solver.cpp:228] Iteration 7904, loss = 0.00109367
I0403 04:39:57.997167  2204 solver.cpp:244]     Train net output #0: loss = 0.00109372 (* 1 = 0.00109372 loss)
I0403 04:39:58.176012  2204 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 04:40:07.557629  2204 solver.cpp:228] Iteration 7917, loss = 0.000663111
I0403 04:40:07.557965  2204 solver.cpp:244]     Train net output #0: loss = 0.000663161 (* 1 = 0.000663161 loss)
I0403 04:40:07.692862  2204 sgd_solver.cpp:106] Iteration 7917, lr = 5e-05
I0403 04:40:17.209537  2204 solver.cpp:228] Iteration 7930, loss = 0.000612592
I0403 04:40:17.209640  2204 solver.cpp:244]     Train net output #0: loss = 0.000612641 (* 1 = 0.000612641 loss)
I0403 04:40:17.331892  2204 sgd_solver.cpp:106] Iteration 7930, lr = 5e-05
I0403 04:40:26.644834  2204 solver.cpp:228] Iteration 7943, loss = 0.000433169
I0403 04:40:26.644948  2204 solver.cpp:244]     Train net output #0: loss = 0.000433218 (* 1 = 0.000433218 loss)
I0403 04:40:26.840350  2204 sgd_solver.cpp:106] Iteration 7943, lr = 5e-05
I0403 04:40:36.044049  2204 solver.cpp:228] Iteration 7956, loss = 0.000174638
I0403 04:40:36.044157  2204 solver.cpp:244]     Train net output #0: loss = 0.000174688 (* 1 = 0.000174688 loss)
I0403 04:40:36.192219  2204 sgd_solver.cpp:106] Iteration 7956, lr = 5e-05
I0403 04:40:45.657112  2204 solver.cpp:228] Iteration 7969, loss = 0.000236999
I0403 04:40:45.657495  2204 solver.cpp:244]     Train net output #0: loss = 0.000237049 (* 1 = 0.000237049 loss)
I0403 04:40:45.844008  2204 sgd_solver.cpp:106] Iteration 7969, lr = 5e-05
I0403 04:40:55.061172  2204 solver.cpp:228] Iteration 7982, loss = 0.000454244
I0403 04:40:55.061285  2204 solver.cpp:244]     Train net output #0: loss = 0.000454294 (* 1 = 0.000454294 loss)
I0403 04:40:55.246944  2204 sgd_solver.cpp:106] Iteration 7982, lr = 5e-05
I0403 04:41:04.378593  2204 solver.cpp:228] Iteration 7995, loss = 0.00323133
I0403 04:41:04.378712  2204 solver.cpp:244]     Train net output #0: loss = 0.00323138 (* 1 = 0.00323138 loss)
I0403 04:41:04.616291  2204 sgd_solver.cpp:106] Iteration 7995, lr = 5e-05
I0403 04:41:13.980480  2204 solver.cpp:228] Iteration 8008, loss = 0.0010208
I0403 04:41:13.980595  2204 solver.cpp:244]     Train net output #0: loss = 0.00102085 (* 1 = 0.00102085 loss)
I0403 04:41:14.179849  2204 sgd_solver.cpp:106] Iteration 8008, lr = 5e-05
I0403 04:41:23.503322  2204 solver.cpp:228] Iteration 8021, loss = 6.31877e-05
I0403 04:41:23.503669  2204 solver.cpp:244]     Train net output #0: loss = 6.32381e-05 (* 1 = 6.32381e-05 loss)
I0403 04:41:23.689745  2204 sgd_solver.cpp:106] Iteration 8021, lr = 5e-05
I0403 04:41:33.048593  2204 solver.cpp:228] Iteration 8034, loss = 0.0238644
I0403 04:41:33.048709  2204 solver.cpp:244]     Train net output #0: loss = 0.0238644 (* 1 = 0.0238644 loss)
I0403 04:41:33.237680  2204 sgd_solver.cpp:106] Iteration 8034, lr = 5e-05
I0403 04:41:36.931447  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_8040.caffemodel
I0403 04:41:39.585414  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_8040.solverstate
I0403 04:41:41.355598  2204 solver.cpp:337] Iteration 8040, Testing net (#0)
I0403 04:42:42.838707  2204 solver.cpp:404]     Test net output #0: accuracy = 0.986862
I0403 04:42:42.839015  2204 solver.cpp:404]     Test net output #1: loss = 0.0525751 (* 1 = 0.0525751 loss)
I0403 04:42:48.508314  2204 solver.cpp:228] Iteration 8047, loss = 0.000271881
I0403 04:42:48.508416  2204 solver.cpp:244]     Train net output #0: loss = 0.000271932 (* 1 = 0.000271932 loss)
I0403 04:42:48.676640  2204 sgd_solver.cpp:106] Iteration 8047, lr = 5e-05
I0403 04:42:57.932822  2204 solver.cpp:228] Iteration 8060, loss = 0.00186294
I0403 04:42:57.932922  2204 solver.cpp:244]     Train net output #0: loss = 0.00186299 (* 1 = 0.00186299 loss)
I0403 04:42:58.112699  2204 sgd_solver.cpp:106] Iteration 8060, lr = 5e-05
I0403 04:43:01.703488  2204 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_8066.caffemodel
I0403 04:43:04.349954  2204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-50-50_finetune/snapshots__iter_8066.solverstate
I0403 04:43:06.148095  2204 solver.cpp:322] Optimization Done.
I0403 04:43:06.235283  2204 caffe.cpp:222] Optimization Done.
