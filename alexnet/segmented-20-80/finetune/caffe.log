I0403 02:30:28.016795 28786 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.017599 28786 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.017658 28786 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:35.901309 28786 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:35.902694 28786 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:35.904227 28786 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:36.785444 28786 solver.cpp:48] Initializing solver from parameters: 
test_iter: 436
test_interval: 106
base_lr: 0.005
display: 5
max_iter: 3199
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1066
snapshot: 106
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:36.856815 28786 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:36.867343 28786 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:36.867563 28786 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:36.869418 28786 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-20-80/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:36.872097 28786 layer_factory.hpp:77] Creating layer data
I0403 02:30:36.874838 28786 net.cpp:91] Creating Layer data
I0403 02:30:36.874969 28786 net.cpp:399] data -> data
I0403 02:30:36.875413 28786 net.cpp:399] data -> label
I0403 02:30:36.875527 28786 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-20-80/mean.binaryproto
I0403 02:30:36.915694 28793 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-20-80/train_db
I0403 02:30:36.947507 28786 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.086957 28786 net.cpp:141] Setting up data
I0403 02:30:37.087086 28786 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.087134 28786 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.087180 28786 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.087249 28786 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.087316 28786 net.cpp:91] Creating Layer conv1
I0403 02:30:37.087380 28786 net.cpp:425] conv1 <- data
I0403 02:30:37.087422 28786 net.cpp:399] conv1 -> conv1
I0403 02:30:37.096631 28786 net.cpp:141] Setting up conv1
I0403 02:30:37.096668 28786 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.096689 28786 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.096732 28786 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.096765 28786 net.cpp:91] Creating Layer relu1
I0403 02:30:37.096786 28786 net.cpp:425] relu1 <- conv1
I0403 02:30:37.096809 28786 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.096839 28786 net.cpp:141] Setting up relu1
I0403 02:30:37.096863 28786 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.096881 28786 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.096899 28786 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.096923 28786 net.cpp:91] Creating Layer norm1
I0403 02:30:37.096982 28786 net.cpp:425] norm1 <- conv1
I0403 02:30:37.097007 28786 net.cpp:399] norm1 -> norm1
I0403 02:30:37.097077 28786 net.cpp:141] Setting up norm1
I0403 02:30:37.097105 28786 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.097123 28786 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.097141 28786 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.097165 28786 net.cpp:91] Creating Layer pool1
I0403 02:30:37.097185 28786 net.cpp:425] pool1 <- norm1
I0403 02:30:37.097208 28786 net.cpp:399] pool1 -> pool1
I0403 02:30:37.097276 28786 net.cpp:141] Setting up pool1
I0403 02:30:37.097306 28786 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.097324 28786 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.097342 28786 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.097368 28786 net.cpp:91] Creating Layer conv2
I0403 02:30:37.097389 28786 net.cpp:425] conv2 <- pool1
I0403 02:30:37.097412 28786 net.cpp:399] conv2 -> conv2
I0403 02:30:37.097724 28795 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.114748 28786 net.cpp:141] Setting up conv2
I0403 02:30:37.114785 28786 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.114807 28786 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.114833 28786 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.114859 28786 net.cpp:91] Creating Layer relu2
I0403 02:30:37.114879 28786 net.cpp:425] relu2 <- conv2
I0403 02:30:37.114902 28786 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.114926 28786 net.cpp:141] Setting up relu2
I0403 02:30:37.114948 28786 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.114965 28786 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.114984 28786 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.115006 28786 net.cpp:91] Creating Layer norm2
I0403 02:30:37.115026 28786 net.cpp:425] norm2 <- conv2
I0403 02:30:37.115048 28786 net.cpp:399] norm2 -> norm2
I0403 02:30:37.115108 28786 net.cpp:141] Setting up norm2
I0403 02:30:37.115134 28786 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.115151 28786 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.115169 28786 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.115193 28786 net.cpp:91] Creating Layer pool2
I0403 02:30:37.115216 28786 net.cpp:425] pool2 <- norm2
I0403 02:30:37.115238 28786 net.cpp:399] pool2 -> pool2
I0403 02:30:37.115294 28786 net.cpp:141] Setting up pool2
I0403 02:30:37.115322 28786 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.115340 28786 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.115358 28786 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.115386 28786 net.cpp:91] Creating Layer conv3
I0403 02:30:37.115408 28786 net.cpp:425] conv3 <- pool2
I0403 02:30:37.115433 28786 net.cpp:399] conv3 -> conv3
I0403 02:30:37.157114 28786 net.cpp:141] Setting up conv3
I0403 02:30:37.157155 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.157176 28786 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.157203 28786 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.157228 28786 net.cpp:91] Creating Layer relu3
I0403 02:30:37.157248 28786 net.cpp:425] relu3 <- conv3
I0403 02:30:37.157271 28786 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.157295 28786 net.cpp:141] Setting up relu3
I0403 02:30:37.157316 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.157335 28786 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.157351 28786 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.157378 28786 net.cpp:91] Creating Layer conv4
I0403 02:30:37.157400 28786 net.cpp:425] conv4 <- conv3
I0403 02:30:37.157425 28786 net.cpp:399] conv4 -> conv4
I0403 02:30:37.188809 28786 net.cpp:141] Setting up conv4
I0403 02:30:37.188849 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.188870 28786 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.188915 28786 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.188941 28786 net.cpp:91] Creating Layer relu4
I0403 02:30:37.188962 28786 net.cpp:425] relu4 <- conv4
I0403 02:30:37.188987 28786 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.189012 28786 net.cpp:141] Setting up relu4
I0403 02:30:37.189031 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.189050 28786 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.189069 28786 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.189095 28786 net.cpp:91] Creating Layer conv5
I0403 02:30:37.189116 28786 net.cpp:425] conv5 <- conv4
I0403 02:30:37.189139 28786 net.cpp:399] conv5 -> conv5
I0403 02:30:37.210180 28786 net.cpp:141] Setting up conv5
I0403 02:30:37.210218 28786 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.210238 28786 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.210268 28786 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.210294 28786 net.cpp:91] Creating Layer relu5
I0403 02:30:37.210314 28786 net.cpp:425] relu5 <- conv5
I0403 02:30:37.210336 28786 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.210361 28786 net.cpp:141] Setting up relu5
I0403 02:30:37.210381 28786 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.210399 28786 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.210417 28786 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.210438 28786 net.cpp:91] Creating Layer pool5
I0403 02:30:37.210458 28786 net.cpp:425] pool5 <- conv5
I0403 02:30:37.210479 28786 net.cpp:399] pool5 -> pool5
I0403 02:30:37.210544 28786 net.cpp:141] Setting up pool5
I0403 02:30:37.210572 28786 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.210592 28786 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.210610 28786 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.210644 28786 net.cpp:91] Creating Layer fc6
I0403 02:30:37.210665 28786 net.cpp:425] fc6 <- pool5
I0403 02:30:37.210688 28786 net.cpp:399] fc6 -> fc6
I0403 02:30:38.753813 28786 net.cpp:141] Setting up fc6
I0403 02:30:38.753891 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.753907 28786 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.753929 28786 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.753952 28786 net.cpp:91] Creating Layer relu6
I0403 02:30:38.753968 28786 net.cpp:425] relu6 <- fc6
I0403 02:30:38.753985 28786 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.754006 28786 net.cpp:141] Setting up relu6
I0403 02:30:38.754024 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.754037 28786 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.754050 28786 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.754076 28786 net.cpp:91] Creating Layer drop6
I0403 02:30:38.754092 28786 net.cpp:425] drop6 <- fc6
I0403 02:30:38.754109 28786 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.754153 28786 net.cpp:141] Setting up drop6
I0403 02:30:38.754173 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.754187 28786 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.754201 28786 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.754220 28786 net.cpp:91] Creating Layer fc7
I0403 02:30:38.754236 28786 net.cpp:425] fc7 <- fc6
I0403 02:30:38.754257 28786 net.cpp:399] fc7 -> fc7
I0403 02:30:39.368747 28786 net.cpp:141] Setting up fc7
I0403 02:30:39.368824 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.368840 28786 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.368860 28786 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.368883 28786 net.cpp:91] Creating Layer relu7
I0403 02:30:39.368906 28786 net.cpp:425] relu7 <- fc7
I0403 02:30:39.368935 28786 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.368964 28786 net.cpp:141] Setting up relu7
I0403 02:30:39.368985 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.369007 28786 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.369030 28786 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.369087 28786 net.cpp:91] Creating Layer drop7
I0403 02:30:39.369112 28786 net.cpp:425] drop7 <- fc7
I0403 02:30:39.369137 28786 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.369185 28786 net.cpp:141] Setting up drop7
I0403 02:30:39.369213 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.369233 28786 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.369271 28786 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.369292 28786 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.369308 28786 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.369325 28786 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.375607 28786 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.375635 28786 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.375651 28786 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.375669 28786 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.375695 28786 net.cpp:91] Creating Layer loss
I0403 02:30:39.375716 28786 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.375735 28786 net.cpp:425] loss <- label
I0403 02:30:39.375758 28786 net.cpp:399] loss -> loss
I0403 02:30:39.375803 28786 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.375929 28786 net.cpp:141] Setting up loss
I0403 02:30:39.375952 28786 net.cpp:148] Top shape: (1)
I0403 02:30:39.375967 28786 net.cpp:151]     with loss weight 1
I0403 02:30:39.376027 28786 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.376046 28786 net.cpp:217] loss needs backward computation.
I0403 02:30:39.376063 28786 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.376088 28786 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.376106 28786 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.376121 28786 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.376152 28786 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.376206 28786 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.376220 28786 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.376235 28786 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.376250 28786 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.376266 28786 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.376281 28786 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.376296 28786 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.376309 28786 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.376323 28786 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.376338 28786 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.376353 28786 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.376368 28786 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.376382 28786 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.376396 28786 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.376420 28786 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.376435 28786 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.376451 28786 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.376468 28786 net.cpp:219] data does not need backward computation.
I0403 02:30:39.376482 28786 net.cpp:261] This network produces output loss
I0403 02:30:39.376507 28786 net.cpp:274] Network initialization done.
I0403 02:30:39.377671 28786 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.377746 28786 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.378428 28786 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-20-80/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.378613 28786 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.378767 28786 net.cpp:91] Creating Layer data
I0403 02:30:39.378793 28786 net.cpp:399] data -> data
I0403 02:30:39.378818 28786 net.cpp:399] data -> label
I0403 02:30:39.378840 28786 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-20-80/mean.binaryproto
I0403 02:30:39.406869 28797 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-20-80/test_db
I0403 02:30:39.414291 28786 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.592988 28786 net.cpp:141] Setting up data
I0403 02:30:39.661955 28786 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.662163 28786 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.662308 28786 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.662341 28786 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.662540 28786 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.662634 28786 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.662667 28786 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.662741 28786 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.662876 28786 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.662947 28786 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.663005 28786 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.663074 28786 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.663136 28786 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.663194 28786 net.cpp:91] Creating Layer conv1
I0403 02:30:39.663259 28786 net.cpp:425] conv1 <- data
I0403 02:30:39.663283 28786 net.cpp:399] conv1 -> conv1
I0403 02:30:39.664865 28786 net.cpp:141] Setting up conv1
I0403 02:30:39.664892 28786 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.664907 28786 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.664932 28786 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.664952 28786 net.cpp:91] Creating Layer relu1
I0403 02:30:39.664968 28786 net.cpp:425] relu1 <- conv1
I0403 02:30:39.664986 28786 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.665005 28786 net.cpp:141] Setting up relu1
I0403 02:30:39.665024 28786 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.665036 28786 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.665051 28786 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.665072 28786 net.cpp:91] Creating Layer norm1
I0403 02:30:39.665088 28786 net.cpp:425] norm1 <- conv1
I0403 02:30:39.665107 28786 net.cpp:399] norm1 -> norm1
I0403 02:30:39.665155 28786 net.cpp:141] Setting up norm1
I0403 02:30:39.665176 28786 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.665191 28786 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.665205 28786 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.665225 28786 net.cpp:91] Creating Layer pool1
I0403 02:30:39.665241 28786 net.cpp:425] pool1 <- norm1
I0403 02:30:39.665259 28786 net.cpp:399] pool1 -> pool1
I0403 02:30:39.665310 28786 net.cpp:141] Setting up pool1
I0403 02:30:39.665333 28786 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.665346 28786 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.665387 28786 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.665410 28786 net.cpp:91] Creating Layer conv2
I0403 02:30:39.665426 28786 net.cpp:425] conv2 <- pool1
I0403 02:30:39.665446 28786 net.cpp:399] conv2 -> conv2
I0403 02:30:39.677989 28786 net.cpp:141] Setting up conv2
I0403 02:30:39.678022 28786 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.678038 28786 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.678059 28786 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.678078 28786 net.cpp:91] Creating Layer relu2
I0403 02:30:39.678094 28786 net.cpp:425] relu2 <- conv2
I0403 02:30:39.678112 28786 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.678131 28786 net.cpp:141] Setting up relu2
I0403 02:30:39.678148 28786 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.678161 28786 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.678175 28786 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.678195 28786 net.cpp:91] Creating Layer norm2
I0403 02:30:39.678210 28786 net.cpp:425] norm2 <- conv2
I0403 02:30:39.678228 28786 net.cpp:399] norm2 -> norm2
I0403 02:30:39.678277 28786 net.cpp:141] Setting up norm2
I0403 02:30:39.678300 28786 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.678314 28786 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.678329 28786 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.678349 28786 net.cpp:91] Creating Layer pool2
I0403 02:30:39.678364 28786 net.cpp:425] pool2 <- norm2
I0403 02:30:39.678380 28786 net.cpp:399] pool2 -> pool2
I0403 02:30:39.678426 28786 net.cpp:141] Setting up pool2
I0403 02:30:39.678448 28786 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.678463 28786 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.678486 28786 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.678521 28786 net.cpp:91] Creating Layer conv3
I0403 02:30:39.678562 28786 net.cpp:425] conv3 <- pool2
I0403 02:30:39.678588 28786 net.cpp:399] conv3 -> conv3
I0403 02:30:39.715375 28786 net.cpp:141] Setting up conv3
I0403 02:30:39.740193 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.740218 28786 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.740247 28786 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.740272 28786 net.cpp:91] Creating Layer relu3
I0403 02:30:39.740288 28786 net.cpp:425] relu3 <- conv3
I0403 02:30:39.740309 28786 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.740331 28786 net.cpp:141] Setting up relu3
I0403 02:30:39.740355 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.740373 28786 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.740388 28786 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.740494 28786 net.cpp:91] Creating Layer conv4
I0403 02:30:39.740535 28786 net.cpp:425] conv4 <- conv3
I0403 02:30:39.740558 28786 net.cpp:399] conv4 -> conv4
I0403 02:30:39.768527 28786 net.cpp:141] Setting up conv4
I0403 02:30:39.768568 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.768584 28786 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.768606 28786 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.768628 28786 net.cpp:91] Creating Layer relu4
I0403 02:30:39.768646 28786 net.cpp:425] relu4 <- conv4
I0403 02:30:39.768666 28786 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.768687 28786 net.cpp:141] Setting up relu4
I0403 02:30:39.768707 28786 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.768721 28786 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.768736 28786 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.768759 28786 net.cpp:91] Creating Layer conv5
I0403 02:30:39.768775 28786 net.cpp:425] conv5 <- conv4
I0403 02:30:39.768795 28786 net.cpp:399] conv5 -> conv5
I0403 02:30:39.787760 28786 net.cpp:141] Setting up conv5
I0403 02:30:39.787803 28786 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.787844 28786 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.787873 28786 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.787894 28786 net.cpp:91] Creating Layer relu5
I0403 02:30:39.787911 28786 net.cpp:425] relu5 <- conv5
I0403 02:30:39.787930 28786 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.787950 28786 net.cpp:141] Setting up relu5
I0403 02:30:39.788044 28786 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.788060 28786 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.788123 28786 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.788208 28786 net.cpp:91] Creating Layer pool5
I0403 02:30:39.788269 28786 net.cpp:425] pool5 <- conv5
I0403 02:30:39.788302 28786 net.cpp:399] pool5 -> pool5
I0403 02:30:39.788372 28786 net.cpp:141] Setting up pool5
I0403 02:30:39.788400 28786 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.788415 28786 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.788430 28786 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.788452 28786 net.cpp:91] Creating Layer fc6
I0403 02:30:39.788468 28786 net.cpp:425] fc6 <- pool5
I0403 02:30:39.788491 28786 net.cpp:399] fc6 -> fc6
I0403 02:30:41.169184 28786 net.cpp:141] Setting up fc6
I0403 02:30:41.169270 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.169286 28786 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.169309 28786 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.169333 28786 net.cpp:91] Creating Layer relu6
I0403 02:30:41.169351 28786 net.cpp:425] relu6 <- fc6
I0403 02:30:41.169371 28786 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.169394 28786 net.cpp:141] Setting up relu6
I0403 02:30:41.169409 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.169422 28786 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.169437 28786 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.169458 28786 net.cpp:91] Creating Layer drop6
I0403 02:30:41.169474 28786 net.cpp:425] drop6 <- fc6
I0403 02:30:41.169491 28786 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.169533 28786 net.cpp:141] Setting up drop6
I0403 02:30:41.169553 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.169566 28786 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.169580 28786 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.169601 28786 net.cpp:91] Creating Layer fc7
I0403 02:30:41.169615 28786 net.cpp:425] fc7 <- fc6
I0403 02:30:41.169636 28786 net.cpp:399] fc7 -> fc7
I0403 02:30:41.772807 28786 net.cpp:141] Setting up fc7
I0403 02:30:41.772892 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.772910 28786 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.772933 28786 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.772958 28786 net.cpp:91] Creating Layer relu7
I0403 02:30:41.772975 28786 net.cpp:425] relu7 <- fc7
I0403 02:30:41.772999 28786 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.773023 28786 net.cpp:141] Setting up relu7
I0403 02:30:41.773042 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.773056 28786 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.773072 28786 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.773090 28786 net.cpp:91] Creating Layer drop7
I0403 02:30:41.773104 28786 net.cpp:425] drop7 <- fc7
I0403 02:30:41.773120 28786 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.773161 28786 net.cpp:141] Setting up drop7
I0403 02:30:41.773182 28786 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.773196 28786 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.773211 28786 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.773233 28786 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.773248 28786 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.773267 28786 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.779263 28786 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.779290 28786 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.779341 28786 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.779361 28786 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.779379 28786 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.779395 28786 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.779413 28786 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.779435 28786 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.779484 28786 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.779503 28786 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.779525 28786 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.779538 28786 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.779552 28786 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.779572 28786 net.cpp:91] Creating Layer loss
I0403 02:30:41.779587 28786 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.779603 28786 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.779619 28786 net.cpp:399] loss -> loss
I0403 02:30:41.779641 28786 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.779732 28786 net.cpp:141] Setting up loss
I0403 02:30:41.779755 28786 net.cpp:148] Top shape: (1)
I0403 02:30:41.779770 28786 net.cpp:151]     with loss weight 1
I0403 02:30:41.779793 28786 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.779808 28786 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.779826 28786 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.779842 28786 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.779857 28786 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.779875 28786 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.779932 28786 net.cpp:141] Setting up accuracy
I0403 02:30:41.779952 28786 net.cpp:148] Top shape: (1)
I0403 02:30:41.779965 28786 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.779979 28786 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.779994 28786 net.cpp:217] loss needs backward computation.
I0403 02:30:41.780007 28786 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.780021 28786 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.780035 28786 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.780050 28786 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.780062 28786 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.780076 28786 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.780089 28786 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.780102 28786 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.780117 28786 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.780130 28786 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.780144 28786 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.780158 28786 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.780171 28786 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.780185 28786 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.780200 28786 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.780215 28786 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.780228 28786 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.780242 28786 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.780256 28786 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.780269 28786 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.780283 28786 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.780298 28786 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.780313 28786 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.780339 28786 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.780355 28786 net.cpp:219] data does not need backward computation.
I0403 02:30:41.780369 28786 net.cpp:261] This network produces output accuracy
I0403 02:30:41.780382 28786 net.cpp:261] This network produces output loss
I0403 02:30:41.780410 28786 net.cpp:274] Network initialization done.
I0403 02:30:41.780517 28786 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.780963 28786 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.315371 28786 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.315443 28786 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.315462 28786 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.315500 28786 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.752905 28786 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.795166 28786 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.013438 28786 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.013520 28786 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:45.013541 28786 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:45.013591 28786 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.484675 28786 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.529274 28786 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.556139 28786 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.822991 28786 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:48.415633 28786 parallel.cpp:425] Starting Optimization
I0403 02:30:48.415791 28786 solver.cpp:279] Solving 
I0403 02:30:48.415814 28786 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:48.415966 28786 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:32:27.628161 28786 solver.cpp:404]     Test net output #0: accuracy = 0.0335551
I0403 02:32:27.635452 28786 solver.cpp:404]     Test net output #1: loss = 3.86624 (* 1 = 3.86624 loss)
I0403 02:32:28.218601 28786 solver.cpp:228] Iteration 0, loss = 4.33365
I0403 02:32:28.224556 28786 solver.cpp:244]     Train net output #0: loss = 4.33365 (* 1 = 4.33365 loss)
I0403 02:32:28.377264 28786 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:31.851083 28786 solver.cpp:228] Iteration 5, loss = 2.77306
I0403 02:32:31.857592 28786 solver.cpp:244]     Train net output #0: loss = 2.77306 (* 1 = 2.77306 loss)
I0403 02:32:32.024330 28786 sgd_solver.cpp:106] Iteration 5, lr = 0.005
I0403 02:32:35.554981 28786 solver.cpp:228] Iteration 10, loss = 1.62678
I0403 02:32:35.561897 28786 solver.cpp:244]     Train net output #0: loss = 1.62678 (* 1 = 1.62678 loss)
I0403 02:32:35.712855 28786 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 02:32:39.247051 28786 solver.cpp:228] Iteration 15, loss = 1.481
I0403 02:32:39.251911 28786 solver.cpp:244]     Train net output #0: loss = 1.481 (* 1 = 1.481 loss)
I0403 02:32:39.443660 28786 sgd_solver.cpp:106] Iteration 15, lr = 0.005
I0403 02:32:42.859557 28786 solver.cpp:228] Iteration 20, loss = 1.02956
I0403 02:32:42.867079 28786 solver.cpp:244]     Train net output #0: loss = 1.02956 (* 1 = 1.02956 loss)
I0403 02:32:43.038851 28786 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 02:32:46.485255 28786 solver.cpp:228] Iteration 25, loss = 0.921187
I0403 02:32:46.491127 28786 solver.cpp:244]     Train net output #0: loss = 0.921187 (* 1 = 0.921187 loss)
I0403 02:32:46.664005 28786 sgd_solver.cpp:106] Iteration 25, lr = 0.005
I0403 02:32:50.134608 28786 solver.cpp:228] Iteration 30, loss = 0.681642
I0403 02:32:50.138761 28786 solver.cpp:244]     Train net output #0: loss = 0.681642 (* 1 = 0.681642 loss)
I0403 02:32:50.307131 28786 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 02:32:53.777655 28786 solver.cpp:228] Iteration 35, loss = 0.636553
I0403 02:32:53.785919 28786 solver.cpp:244]     Train net output #0: loss = 0.636553 (* 1 = 0.636553 loss)
I0403 02:32:53.954499 28786 sgd_solver.cpp:106] Iteration 35, lr = 0.005
I0403 02:32:57.376567 28786 solver.cpp:228] Iteration 40, loss = 0.42818
I0403 02:32:57.383580 28786 solver.cpp:244]     Train net output #0: loss = 0.42818 (* 1 = 0.42818 loss)
I0403 02:32:57.582315 28786 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 02:33:01.070279 28786 solver.cpp:228] Iteration 45, loss = 0.449248
I0403 02:33:01.076318 28786 solver.cpp:244]     Train net output #0: loss = 0.449248 (* 1 = 0.449248 loss)
I0403 02:33:01.235569 28786 sgd_solver.cpp:106] Iteration 45, lr = 0.005
I0403 02:33:04.755362 28786 solver.cpp:228] Iteration 50, loss = 0.417423
I0403 02:33:04.761991 28786 solver.cpp:244]     Train net output #0: loss = 0.417423 (* 1 = 0.417423 loss)
I0403 02:33:05.027724 28786 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 02:33:08.469804 28786 solver.cpp:228] Iteration 55, loss = 0.419523
I0403 02:33:08.476896 28786 solver.cpp:244]     Train net output #0: loss = 0.419523 (* 1 = 0.419523 loss)
I0403 02:33:08.682097 28786 sgd_solver.cpp:106] Iteration 55, lr = 0.005
I0403 02:33:12.156060 28786 solver.cpp:228] Iteration 60, loss = 0.532124
I0403 02:33:12.160737 28786 solver.cpp:244]     Train net output #0: loss = 0.532124 (* 1 = 0.532124 loss)
I0403 02:33:12.397853 28786 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 02:33:15.843785 28786 solver.cpp:228] Iteration 65, loss = 0.491594
I0403 02:33:15.850679 28786 solver.cpp:244]     Train net output #0: loss = 0.491594 (* 1 = 0.491594 loss)
I0403 02:33:16.004787 28786 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 02:33:19.577718 28786 solver.cpp:228] Iteration 70, loss = 0.337057
I0403 02:33:19.582924 28786 solver.cpp:244]     Train net output #0: loss = 0.337057 (* 1 = 0.337057 loss)
I0403 02:33:19.828466 28786 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 02:33:23.237679 28786 solver.cpp:228] Iteration 75, loss = 0.311774
I0403 02:33:23.241735 28786 solver.cpp:244]     Train net output #0: loss = 0.311774 (* 1 = 0.311774 loss)
I0403 02:33:23.469926 28786 sgd_solver.cpp:106] Iteration 75, lr = 0.005
I0403 02:33:26.998289 28786 solver.cpp:228] Iteration 80, loss = 0.29778
I0403 02:33:26.998386 28786 solver.cpp:244]     Train net output #0: loss = 0.29778 (* 1 = 0.29778 loss)
I0403 02:33:27.177296 28786 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 02:33:30.738517 28786 solver.cpp:228] Iteration 85, loss = 0.217486
I0403 02:33:30.738610 28786 solver.cpp:244]     Train net output #0: loss = 0.217486 (* 1 = 0.217486 loss)
I0403 02:33:30.876787 28786 sgd_solver.cpp:106] Iteration 85, lr = 0.005
I0403 02:33:34.430297 28786 solver.cpp:228] Iteration 90, loss = 0.447997
I0403 02:33:34.436347 28786 solver.cpp:244]     Train net output #0: loss = 0.447997 (* 1 = 0.447997 loss)
I0403 02:33:34.612320 28786 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 02:33:38.044009 28786 solver.cpp:228] Iteration 95, loss = 0.429654
I0403 02:33:38.050034 28786 solver.cpp:244]     Train net output #0: loss = 0.429654 (* 1 = 0.429654 loss)
I0403 02:33:38.279175 28786 sgd_solver.cpp:106] Iteration 95, lr = 0.005
I0403 02:33:41.731910 28786 solver.cpp:228] Iteration 100, loss = 0.238409
I0403 02:33:41.738102 28786 solver.cpp:244]     Train net output #0: loss = 0.238409 (* 1 = 0.238409 loss)
I0403 02:33:41.916730 28786 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 02:33:45.340064 28786 solver.cpp:228] Iteration 105, loss = 0.209345
I0403 02:33:45.346972 28786 solver.cpp:244]     Train net output #0: loss = 0.209345 (* 1 = 0.209345 loss)
I0403 02:33:45.561184 28786 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 02:33:45.561419 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_106.caffemodel
I0403 02:33:48.294242 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_106.solverstate
I0403 02:33:50.070878 28786 solver.cpp:337] Iteration 106, Testing net (#0)
I0403 02:35:29.235554 28786 solver.cpp:404]     Test net output #0: accuracy = 0.905597
I0403 02:35:29.242604 28786 solver.cpp:404]     Test net output #1: loss = 0.292546 (* 1 = 0.292546 loss)
I0403 02:35:32.703624 28786 solver.cpp:228] Iteration 110, loss = 0.192744
I0403 02:35:32.709010 28786 solver.cpp:244]     Train net output #0: loss = 0.192744 (* 1 = 0.192744 loss)
I0403 02:35:32.909348 28786 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 02:35:36.428506 28786 solver.cpp:228] Iteration 115, loss = 0.148685
I0403 02:35:36.434960 28786 solver.cpp:244]     Train net output #0: loss = 0.148685 (* 1 = 0.148685 loss)
I0403 02:35:36.537641 28786 sgd_solver.cpp:106] Iteration 115, lr = 0.005
I0403 02:35:40.105183 28786 solver.cpp:228] Iteration 120, loss = 0.117748
I0403 02:35:40.116847 28786 solver.cpp:244]     Train net output #0: loss = 0.117748 (* 1 = 0.117748 loss)
I0403 02:35:40.295886 28786 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 02:35:43.812677 28786 solver.cpp:228] Iteration 125, loss = 0.176631
I0403 02:35:43.818353 28786 solver.cpp:244]     Train net output #0: loss = 0.176631 (* 1 = 0.176631 loss)
I0403 02:35:44.001482 28786 sgd_solver.cpp:106] Iteration 125, lr = 0.005
I0403 02:35:47.548998 28786 solver.cpp:228] Iteration 130, loss = 0.138128
I0403 02:35:47.555368 28786 solver.cpp:244]     Train net output #0: loss = 0.138128 (* 1 = 0.138128 loss)
I0403 02:35:47.672679 28786 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:35:51.219686 28786 solver.cpp:228] Iteration 135, loss = 0.289813
I0403 02:35:51.226187 28786 solver.cpp:244]     Train net output #0: loss = 0.289813 (* 1 = 0.289813 loss)
I0403 02:35:51.454401 28786 sgd_solver.cpp:106] Iteration 135, lr = 0.005
I0403 02:35:54.975663 28786 solver.cpp:228] Iteration 140, loss = 0.184104
I0403 02:35:54.981904 28786 solver.cpp:244]     Train net output #0: loss = 0.184104 (* 1 = 0.184104 loss)
I0403 02:35:55.140625 28786 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 02:35:58.692428 28786 solver.cpp:228] Iteration 145, loss = 0.1662
I0403 02:35:58.698307 28786 solver.cpp:244]     Train net output #0: loss = 0.1662 (* 1 = 0.1662 loss)
I0403 02:35:58.916541 28786 sgd_solver.cpp:106] Iteration 145, lr = 0.005
I0403 02:36:02.387145 28786 solver.cpp:228] Iteration 150, loss = 0.185524
I0403 02:36:02.393906 28786 solver.cpp:244]     Train net output #0: loss = 0.185524 (* 1 = 0.185524 loss)
I0403 02:36:02.562862 28786 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 02:36:06.015100 28786 solver.cpp:228] Iteration 155, loss = 0.227506
I0403 02:36:06.021224 28786 solver.cpp:244]     Train net output #0: loss = 0.227506 (* 1 = 0.227506 loss)
I0403 02:36:06.210033 28786 sgd_solver.cpp:106] Iteration 155, lr = 0.005
I0403 02:36:09.651545 28786 solver.cpp:228] Iteration 160, loss = 0.198528
I0403 02:36:09.657794 28786 solver.cpp:244]     Train net output #0: loss = 0.198528 (* 1 = 0.198528 loss)
I0403 02:36:09.836877 28786 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 02:36:13.248216 28786 solver.cpp:228] Iteration 165, loss = 0.20291
I0403 02:36:13.255942 28786 solver.cpp:244]     Train net output #0: loss = 0.20291 (* 1 = 0.20291 loss)
I0403 02:36:13.425742 28786 sgd_solver.cpp:106] Iteration 165, lr = 0.005
I0403 02:36:16.904750 28786 solver.cpp:228] Iteration 170, loss = 0.165752
I0403 02:36:16.910706 28786 solver.cpp:244]     Train net output #0: loss = 0.165752 (* 1 = 0.165752 loss)
I0403 02:36:17.082622 28786 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 02:36:20.651877 28786 solver.cpp:228] Iteration 175, loss = 0.107491
I0403 02:36:20.658677 28786 solver.cpp:244]     Train net output #0: loss = 0.107491 (* 1 = 0.107491 loss)
I0403 02:36:20.797569 28786 sgd_solver.cpp:106] Iteration 175, lr = 0.005
I0403 02:36:24.320075 28786 solver.cpp:228] Iteration 180, loss = 0.0691553
I0403 02:36:24.326556 28786 solver.cpp:244]     Train net output #0: loss = 0.0691553 (* 1 = 0.0691553 loss)
I0403 02:36:24.491550 28786 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 02:36:28.054364 28786 solver.cpp:228] Iteration 185, loss = 0.0974014
I0403 02:36:28.059664 28786 solver.cpp:244]     Train net output #0: loss = 0.0974014 (* 1 = 0.0974014 loss)
I0403 02:36:28.233608 28786 sgd_solver.cpp:106] Iteration 185, lr = 0.005
I0403 02:36:31.755916 28786 solver.cpp:228] Iteration 190, loss = 0.185636
I0403 02:36:31.762228 28786 solver.cpp:244]     Train net output #0: loss = 0.185636 (* 1 = 0.185636 loss)
I0403 02:36:31.994520 28786 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 02:36:35.413187 28786 solver.cpp:228] Iteration 195, loss = 0.300054
I0403 02:36:35.419407 28786 solver.cpp:244]     Train net output #0: loss = 0.300054 (* 1 = 0.300054 loss)
I0403 02:36:35.571584 28786 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 02:36:39.122624 28786 solver.cpp:228] Iteration 200, loss = 0.0644458
I0403 02:36:39.128974 28786 solver.cpp:244]     Train net output #0: loss = 0.0644458 (* 1 = 0.0644458 loss)
I0403 02:36:39.307641 28786 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 02:36:42.820590 28786 solver.cpp:228] Iteration 205, loss = 0.256934
I0403 02:36:42.827530 28786 solver.cpp:244]     Train net output #0: loss = 0.256934 (* 1 = 0.256934 loss)
I0403 02:36:42.980881 28786 sgd_solver.cpp:106] Iteration 205, lr = 0.005
I0403 02:36:46.435571 28786 solver.cpp:228] Iteration 210, loss = 0.180598
I0403 02:36:46.441489 28786 solver.cpp:244]     Train net output #0: loss = 0.180598 (* 1 = 0.180598 loss)
I0403 02:36:46.687662 28786 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:36:47.395977 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_212.caffemodel
I0403 02:36:50.163888 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_212.solverstate
I0403 02:36:52.089874 28786 solver.cpp:337] Iteration 212, Testing net (#0)
I0403 02:38:31.285512 28786 solver.cpp:404]     Test net output #0: accuracy = 0.934175
I0403 02:38:31.292095 28786 solver.cpp:404]     Test net output #1: loss = 0.208361 (* 1 = 0.208361 loss)
I0403 02:38:33.986402 28786 solver.cpp:228] Iteration 215, loss = 0.18193
I0403 02:38:33.986498 28786 solver.cpp:244]     Train net output #0: loss = 0.18193 (* 1 = 0.18193 loss)
I0403 02:38:34.218170 28786 sgd_solver.cpp:106] Iteration 215, lr = 0.005
I0403 02:38:37.686576 28786 solver.cpp:228] Iteration 220, loss = 0.128634
I0403 02:38:37.686671 28786 solver.cpp:244]     Train net output #0: loss = 0.128634 (* 1 = 0.128634 loss)
I0403 02:38:37.871714 28786 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 02:38:41.322293 28786 solver.cpp:228] Iteration 225, loss = 0.147225
I0403 02:38:41.322387 28786 solver.cpp:244]     Train net output #0: loss = 0.147225 (* 1 = 0.147225 loss)
I0403 02:38:41.511436 28786 sgd_solver.cpp:106] Iteration 225, lr = 0.005
I0403 02:38:45.012702 28786 solver.cpp:228] Iteration 230, loss = 0.182666
I0403 02:38:45.012790 28786 solver.cpp:244]     Train net output #0: loss = 0.182666 (* 1 = 0.182666 loss)
I0403 02:38:45.184082 28786 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 02:38:48.691191 28786 solver.cpp:228] Iteration 235, loss = 0.141623
I0403 02:38:48.691277 28786 solver.cpp:244]     Train net output #0: loss = 0.141623 (* 1 = 0.141623 loss)
I0403 02:38:48.870312 28786 sgd_solver.cpp:106] Iteration 235, lr = 0.005
I0403 02:38:52.346231 28786 solver.cpp:228] Iteration 240, loss = 0.0598115
I0403 02:38:52.346318 28786 solver.cpp:244]     Train net output #0: loss = 0.0598115 (* 1 = 0.0598115 loss)
I0403 02:38:52.513640 28786 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 02:38:55.975127 28786 solver.cpp:228] Iteration 245, loss = 0.10139
I0403 02:38:55.975220 28786 solver.cpp:244]     Train net output #0: loss = 0.10139 (* 1 = 0.10139 loss)
I0403 02:38:56.163759 28786 sgd_solver.cpp:106] Iteration 245, lr = 0.005
I0403 02:38:59.659442 28786 solver.cpp:228] Iteration 250, loss = 0.130292
I0403 02:38:59.659528 28786 solver.cpp:244]     Train net output #0: loss = 0.130292 (* 1 = 0.130292 loss)
I0403 02:38:59.788439 28786 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 02:39:03.347250 28786 solver.cpp:228] Iteration 255, loss = 0.0625279
I0403 02:39:03.347607 28786 solver.cpp:244]     Train net output #0: loss = 0.0625279 (* 1 = 0.0625279 loss)
I0403 02:39:03.493638 28786 sgd_solver.cpp:106] Iteration 255, lr = 0.005
I0403 02:39:07.195232 28786 solver.cpp:228] Iteration 260, loss = 0.14147
I0403 02:39:07.195329 28786 solver.cpp:244]     Train net output #0: loss = 0.14147 (* 1 = 0.14147 loss)
I0403 02:39:07.410604 28786 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:39:10.947919 28786 solver.cpp:228] Iteration 265, loss = 0.0908839
I0403 02:39:10.948011 28786 solver.cpp:244]     Train net output #0: loss = 0.0908839 (* 1 = 0.0908839 loss)
I0403 02:39:11.124116 28786 sgd_solver.cpp:106] Iteration 265, lr = 0.005
I0403 02:39:14.657423 28786 solver.cpp:228] Iteration 270, loss = 0.0664196
I0403 02:39:14.657521 28786 solver.cpp:244]     Train net output #0: loss = 0.0664197 (* 1 = 0.0664197 loss)
I0403 02:39:14.841903 28786 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 02:39:18.315145 28786 solver.cpp:228] Iteration 275, loss = 0.0473572
I0403 02:39:18.315230 28786 solver.cpp:244]     Train net output #0: loss = 0.0473572 (* 1 = 0.0473572 loss)
I0403 02:39:18.486012 28786 sgd_solver.cpp:106] Iteration 275, lr = 0.005
I0403 02:39:21.977078 28786 solver.cpp:228] Iteration 280, loss = 0.073726
I0403 02:39:21.977177 28786 solver.cpp:244]     Train net output #0: loss = 0.073726 (* 1 = 0.073726 loss)
I0403 02:39:22.174413 28786 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 02:39:25.669167 28786 solver.cpp:228] Iteration 285, loss = 0.118641
I0403 02:39:25.669253 28786 solver.cpp:244]     Train net output #0: loss = 0.118642 (* 1 = 0.118642 loss)
I0403 02:39:25.839546 28786 sgd_solver.cpp:106] Iteration 285, lr = 0.005
I0403 02:39:29.312157 28786 solver.cpp:228] Iteration 290, loss = 0.0822373
I0403 02:39:29.312253 28786 solver.cpp:244]     Train net output #0: loss = 0.0822374 (* 1 = 0.0822374 loss)
I0403 02:39:29.510365 28786 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 02:39:32.993180 28786 solver.cpp:228] Iteration 295, loss = 0.0636572
I0403 02:39:32.993275 28786 solver.cpp:244]     Train net output #0: loss = 0.0636572 (* 1 = 0.0636572 loss)
I0403 02:39:33.201719 28786 sgd_solver.cpp:106] Iteration 295, lr = 0.005
I0403 02:39:36.691016 28786 solver.cpp:228] Iteration 300, loss = 0.0677849
I0403 02:39:36.691310 28786 solver.cpp:244]     Train net output #0: loss = 0.067785 (* 1 = 0.067785 loss)
I0403 02:39:36.867303 28786 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 02:39:40.465283 28786 solver.cpp:228] Iteration 305, loss = 0.0359614
I0403 02:39:40.465371 28786 solver.cpp:244]     Train net output #0: loss = 0.0359615 (* 1 = 0.0359615 loss)
I0403 02:39:40.642091 28786 sgd_solver.cpp:106] Iteration 305, lr = 0.005
I0403 02:39:44.249771 28786 solver.cpp:228] Iteration 310, loss = 0.0361088
I0403 02:39:44.249857 28786 solver.cpp:244]     Train net output #0: loss = 0.0361088 (* 1 = 0.0361088 loss)
I0403 02:39:44.369751 28786 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 02:39:47.909301 28786 solver.cpp:228] Iteration 315, loss = 0.0256781
I0403 02:39:47.909397 28786 solver.cpp:244]     Train net output #0: loss = 0.0256782 (* 1 = 0.0256782 loss)
I0403 02:39:48.110419 28786 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 02:39:49.535874 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_318.caffemodel
I0403 02:39:52.291695 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_318.solverstate
I0403 02:39:54.204303 28786 solver.cpp:337] Iteration 318, Testing net (#0)
I0403 02:41:33.386224 28786 solver.cpp:404]     Test net output #0: accuracy = 0.953166
I0403 02:41:33.396689 28786 solver.cpp:404]     Test net output #1: loss = 0.157419 (* 1 = 0.157419 loss)
I0403 02:41:35.436435 28786 solver.cpp:228] Iteration 320, loss = 0.100272
I0403 02:41:35.442315 28786 solver.cpp:244]     Train net output #0: loss = 0.100272 (* 1 = 0.100272 loss)
I0403 02:41:35.668627 28786 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 02:41:39.124629 28786 solver.cpp:228] Iteration 325, loss = 0.118672
I0403 02:41:39.131049 28786 solver.cpp:244]     Train net output #0: loss = 0.118672 (* 1 = 0.118672 loss)
I0403 02:41:39.303732 28786 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 02:41:42.746145 28786 solver.cpp:228] Iteration 330, loss = 0.0784718
I0403 02:41:42.751778 28786 solver.cpp:244]     Train net output #0: loss = 0.0784719 (* 1 = 0.0784719 loss)
I0403 02:41:43.004909 28786 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 02:41:46.409911 28786 solver.cpp:228] Iteration 335, loss = 0.177524
I0403 02:41:46.416604 28786 solver.cpp:244]     Train net output #0: loss = 0.177524 (* 1 = 0.177524 loss)
I0403 02:41:46.640900 28786 sgd_solver.cpp:106] Iteration 335, lr = 0.005
I0403 02:41:50.084452 28786 solver.cpp:228] Iteration 340, loss = 0.067669
I0403 02:41:50.090733 28786 solver.cpp:244]     Train net output #0: loss = 0.067669 (* 1 = 0.067669 loss)
I0403 02:41:50.264523 28786 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 02:41:53.709463 28786 solver.cpp:228] Iteration 345, loss = 0.0512418
I0403 02:41:53.715724 28786 solver.cpp:244]     Train net output #0: loss = 0.0512419 (* 1 = 0.0512419 loss)
I0403 02:41:53.900367 28786 sgd_solver.cpp:106] Iteration 345, lr = 0.005
I0403 02:41:57.307101 28786 solver.cpp:228] Iteration 350, loss = 0.0352072
I0403 02:41:57.313086 28786 solver.cpp:244]     Train net output #0: loss = 0.0352072 (* 1 = 0.0352072 loss)
I0403 02:41:57.491101 28786 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 02:42:01.095064 28786 solver.cpp:228] Iteration 355, loss = 0.0276146
I0403 02:42:01.101840 28786 solver.cpp:244]     Train net output #0: loss = 0.0276147 (* 1 = 0.0276147 loss)
I0403 02:42:01.262617 28786 sgd_solver.cpp:106] Iteration 355, lr = 0.005
I0403 02:42:04.731200 28786 solver.cpp:228] Iteration 360, loss = 0.0354805
I0403 02:42:04.737221 28786 solver.cpp:244]     Train net output #0: loss = 0.0354805 (* 1 = 0.0354805 loss)
I0403 02:42:04.910990 28786 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 02:42:08.417474 28786 solver.cpp:228] Iteration 365, loss = 0.0687997
I0403 02:42:08.423605 28786 solver.cpp:244]     Train net output #0: loss = 0.0687998 (* 1 = 0.0687998 loss)
I0403 02:42:08.594679 28786 sgd_solver.cpp:106] Iteration 365, lr = 0.005
I0403 02:42:12.131160 28786 solver.cpp:228] Iteration 370, loss = 0.0595006
I0403 02:42:12.137310 28786 solver.cpp:244]     Train net output #0: loss = 0.0595007 (* 1 = 0.0595007 loss)
I0403 02:42:12.306030 28786 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 02:42:15.744863 28786 solver.cpp:228] Iteration 375, loss = 0.176632
I0403 02:42:15.750180 28786 solver.cpp:244]     Train net output #0: loss = 0.176632 (* 1 = 0.176632 loss)
I0403 02:42:15.943411 28786 sgd_solver.cpp:106] Iteration 375, lr = 0.005
I0403 02:42:19.356225 28786 solver.cpp:228] Iteration 380, loss = 0.127545
I0403 02:42:19.361982 28786 solver.cpp:244]     Train net output #0: loss = 0.127546 (* 1 = 0.127546 loss)
I0403 02:42:19.561331 28786 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 02:42:23.066925 28786 solver.cpp:228] Iteration 385, loss = 0.0959285
I0403 02:42:23.073580 28786 solver.cpp:244]     Train net output #0: loss = 0.0959286 (* 1 = 0.0959286 loss)
I0403 02:42:23.250680 28786 sgd_solver.cpp:106] Iteration 385, lr = 0.005
I0403 02:42:26.754870 28786 solver.cpp:228] Iteration 390, loss = 0.0363786
I0403 02:42:26.760457 28786 solver.cpp:244]     Train net output #0: loss = 0.0363787 (* 1 = 0.0363787 loss)
I0403 02:42:26.941715 28786 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:42:30.406292 28786 solver.cpp:228] Iteration 395, loss = 0.0712157
I0403 02:42:30.412154 28786 solver.cpp:244]     Train net output #0: loss = 0.0712157 (* 1 = 0.0712157 loss)
I0403 02:42:30.594805 28786 sgd_solver.cpp:106] Iteration 395, lr = 0.005
I0403 02:42:34.098964 28786 solver.cpp:228] Iteration 400, loss = 0.0945719
I0403 02:42:34.105409 28786 solver.cpp:244]     Train net output #0: loss = 0.0945719 (* 1 = 0.0945719 loss)
I0403 02:42:34.278759 28786 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 02:42:37.729867 28786 solver.cpp:228] Iteration 405, loss = 0.0494973
I0403 02:42:37.736754 28786 solver.cpp:244]     Train net output #0: loss = 0.0494973 (* 1 = 0.0494973 loss)
I0403 02:42:37.916290 28786 sgd_solver.cpp:106] Iteration 405, lr = 0.005
I0403 02:42:41.375136 28786 solver.cpp:228] Iteration 410, loss = 0.106987
I0403 02:42:41.381630 28786 solver.cpp:244]     Train net output #0: loss = 0.106987 (* 1 = 0.106987 loss)
I0403 02:42:41.545413 28786 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 02:42:45.070617 28786 solver.cpp:228] Iteration 415, loss = 0.027918
I0403 02:42:45.076560 28786 solver.cpp:244]     Train net output #0: loss = 0.0279181 (* 1 = 0.0279181 loss)
I0403 02:42:45.257736 28786 sgd_solver.cpp:106] Iteration 415, lr = 0.005
I0403 02:42:48.677340 28786 solver.cpp:228] Iteration 420, loss = 0.0668549
I0403 02:42:48.683637 28786 solver.cpp:244]     Train net output #0: loss = 0.066855 (* 1 = 0.066855 loss)
I0403 02:42:48.856305 28786 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:42:51.102130 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_424.caffemodel
I0403 02:42:53.788069 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_424.solverstate
I0403 02:42:55.605247 28786 solver.cpp:337] Iteration 424, Testing net (#0)
I0403 02:44:34.779698 28786 solver.cpp:404]     Test net output #0: accuracy = 0.950482
I0403 02:44:34.786337 28786 solver.cpp:404]     Test net output #1: loss = 0.172415 (* 1 = 0.172415 loss)
I0403 02:44:36.025563 28786 solver.cpp:228] Iteration 425, loss = 0.0296139
I0403 02:44:36.030336 28786 solver.cpp:244]     Train net output #0: loss = 0.029614 (* 1 = 0.029614 loss)
I0403 02:44:36.205087 28786 sgd_solver.cpp:106] Iteration 425, lr = 0.005
I0403 02:44:39.647863 28786 solver.cpp:228] Iteration 430, loss = 0.0101061
I0403 02:44:39.654438 28786 solver.cpp:244]     Train net output #0: loss = 0.0101062 (* 1 = 0.0101062 loss)
I0403 02:44:39.830463 28786 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 02:44:43.266428 28786 solver.cpp:228] Iteration 435, loss = 0.0466442
I0403 02:44:43.272141 28786 solver.cpp:244]     Train net output #0: loss = 0.0466443 (* 1 = 0.0466443 loss)
I0403 02:44:43.453236 28786 sgd_solver.cpp:106] Iteration 435, lr = 0.005
I0403 02:44:46.880760 28786 solver.cpp:228] Iteration 440, loss = 0.0702128
I0403 02:44:46.885670 28786 solver.cpp:244]     Train net output #0: loss = 0.0702128 (* 1 = 0.0702128 loss)
I0403 02:44:47.052942 28786 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 02:44:50.685503 28786 solver.cpp:228] Iteration 445, loss = 0.0266663
I0403 02:44:50.692821 28786 solver.cpp:244]     Train net output #0: loss = 0.0266664 (* 1 = 0.0266664 loss)
I0403 02:44:50.867668 28786 sgd_solver.cpp:106] Iteration 445, lr = 0.005
I0403 02:44:54.340024 28786 solver.cpp:228] Iteration 450, loss = 0.0085126
I0403 02:44:54.346189 28786 solver.cpp:244]     Train net output #0: loss = 0.00851266 (* 1 = 0.00851266 loss)
I0403 02:44:54.523866 28786 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 02:44:57.981328 28786 solver.cpp:228] Iteration 455, loss = 0.0241946
I0403 02:44:57.987192 28786 solver.cpp:244]     Train net output #0: loss = 0.0241946 (* 1 = 0.0241946 loss)
I0403 02:44:58.171316 28786 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 02:45:01.644554 28786 solver.cpp:228] Iteration 460, loss = 0.0254272
I0403 02:45:01.650913 28786 solver.cpp:244]     Train net output #0: loss = 0.0254272 (* 1 = 0.0254272 loss)
I0403 02:45:01.845705 28786 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 02:45:05.296167 28786 solver.cpp:228] Iteration 465, loss = 0.0308237
I0403 02:45:05.302803 28786 solver.cpp:244]     Train net output #0: loss = 0.0308238 (* 1 = 0.0308238 loss)
I0403 02:45:05.484412 28786 sgd_solver.cpp:106] Iteration 465, lr = 0.005
I0403 02:45:08.966886 28786 solver.cpp:228] Iteration 470, loss = 0.113741
I0403 02:45:08.973182 28786 solver.cpp:244]     Train net output #0: loss = 0.113741 (* 1 = 0.113741 loss)
I0403 02:45:09.145627 28786 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 02:45:12.547255 28786 solver.cpp:228] Iteration 475, loss = 0.0690379
I0403 02:45:12.553346 28786 solver.cpp:244]     Train net output #0: loss = 0.069038 (* 1 = 0.069038 loss)
I0403 02:45:12.719841 28786 sgd_solver.cpp:106] Iteration 475, lr = 0.005
I0403 02:45:16.171205 28786 solver.cpp:228] Iteration 480, loss = 0.0687623
I0403 02:45:16.176995 28786 solver.cpp:244]     Train net output #0: loss = 0.0687623 (* 1 = 0.0687623 loss)
I0403 02:45:16.370914 28786 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 02:45:19.841003 28786 solver.cpp:228] Iteration 485, loss = 0.105709
I0403 02:45:19.847152 28786 solver.cpp:244]     Train net output #0: loss = 0.105709 (* 1 = 0.105709 loss)
I0403 02:45:20.027092 28786 sgd_solver.cpp:106] Iteration 485, lr = 0.005
I0403 02:45:23.457137 28786 solver.cpp:228] Iteration 490, loss = 0.113219
I0403 02:45:23.463153 28786 solver.cpp:244]     Train net output #0: loss = 0.113219 (* 1 = 0.113219 loss)
I0403 02:45:23.637290 28786 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 02:45:27.111033 28786 solver.cpp:228] Iteration 495, loss = 0.0694836
I0403 02:45:27.115489 28786 solver.cpp:244]     Train net output #0: loss = 0.0694836 (* 1 = 0.0694836 loss)
I0403 02:45:27.290969 28786 sgd_solver.cpp:106] Iteration 495, lr = 0.005
I0403 02:45:30.732060 28786 solver.cpp:228] Iteration 500, loss = 0.0220132
I0403 02:45:30.738592 28786 solver.cpp:244]     Train net output #0: loss = 0.0220133 (* 1 = 0.0220133 loss)
I0403 02:45:30.911373 28786 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 02:45:34.344184 28786 solver.cpp:228] Iteration 505, loss = 0.00663445
I0403 02:45:34.350587 28786 solver.cpp:244]     Train net output #0: loss = 0.00663451 (* 1 = 0.00663451 loss)
I0403 02:45:34.531438 28786 sgd_solver.cpp:106] Iteration 505, lr = 0.005
I0403 02:45:37.924075 28786 solver.cpp:228] Iteration 510, loss = 0.0345476
I0403 02:45:37.930212 28786 solver.cpp:244]     Train net output #0: loss = 0.0345477 (* 1 = 0.0345477 loss)
I0403 02:45:38.166970 28786 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 02:45:41.601708 28786 solver.cpp:228] Iteration 515, loss = 0.0193002
I0403 02:45:41.606782 28786 solver.cpp:244]     Train net output #0: loss = 0.0193003 (* 1 = 0.0193003 loss)
I0403 02:45:41.801129 28786 sgd_solver.cpp:106] Iteration 515, lr = 0.005
I0403 02:45:45.210786 28786 solver.cpp:228] Iteration 520, loss = 0.0545608
I0403 02:45:45.217604 28786 solver.cpp:244]     Train net output #0: loss = 0.0545608 (* 1 = 0.0545608 loss)
I0403 02:45:45.394021 28786 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:45:48.798375 28786 solver.cpp:228] Iteration 525, loss = 0.0451167
I0403 02:45:48.805205 28786 solver.cpp:244]     Train net output #0: loss = 0.0451168 (* 1 = 0.0451168 loss)
I0403 02:45:48.971670 28786 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 02:45:52.006122 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_530.caffemodel
I0403 02:45:54.777045 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_530.solverstate
I0403 02:45:56.693405 28786 solver.cpp:337] Iteration 530, Testing net (#0)
I0403 02:47:35.877317 28786 solver.cpp:404]     Test net output #0: accuracy = 0.946629
I0403 02:47:35.883806 28786 solver.cpp:404]     Test net output #1: loss = 0.196936 (* 1 = 0.196936 loss)
I0403 02:47:36.436071 28786 solver.cpp:228] Iteration 530, loss = 0.0784169
I0403 02:47:36.441715 28786 solver.cpp:244]     Train net output #0: loss = 0.078417 (* 1 = 0.078417 loss)
I0403 02:47:36.562918 28786 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 02:47:40.158948 28786 solver.cpp:228] Iteration 535, loss = 0.0656072
I0403 02:47:40.165499 28786 solver.cpp:244]     Train net output #0: loss = 0.0656073 (* 1 = 0.0656073 loss)
I0403 02:47:40.340710 28786 sgd_solver.cpp:106] Iteration 535, lr = 0.005
I0403 02:47:43.728498 28786 solver.cpp:228] Iteration 540, loss = 0.133716
I0403 02:47:43.733999 28786 solver.cpp:244]     Train net output #0: loss = 0.133716 (* 1 = 0.133716 loss)
I0403 02:47:43.949146 28786 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 02:47:47.438706 28786 solver.cpp:228] Iteration 545, loss = 0.064438
I0403 02:47:47.445009 28786 solver.cpp:244]     Train net output #0: loss = 0.0644381 (* 1 = 0.0644381 loss)
I0403 02:47:47.644583 28786 sgd_solver.cpp:106] Iteration 545, lr = 0.005
I0403 02:47:51.053263 28786 solver.cpp:228] Iteration 550, loss = 0.022464
I0403 02:47:51.059078 28786 solver.cpp:244]     Train net output #0: loss = 0.0224641 (* 1 = 0.0224641 loss)
I0403 02:47:51.244000 28786 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 02:47:54.738252 28786 solver.cpp:228] Iteration 555, loss = 0.170413
I0403 02:47:54.744086 28786 solver.cpp:244]     Train net output #0: loss = 0.170413 (* 1 = 0.170413 loss)
I0403 02:47:54.914403 28786 sgd_solver.cpp:106] Iteration 555, lr = 0.005
I0403 02:47:58.401340 28786 solver.cpp:228] Iteration 560, loss = 0.102251
I0403 02:47:58.416259 28786 solver.cpp:244]     Train net output #0: loss = 0.102251 (* 1 = 0.102251 loss)
I0403 02:47:58.580994 28786 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 02:48:02.231709 28786 solver.cpp:228] Iteration 565, loss = 0.0144044
I0403 02:48:02.238097 28786 solver.cpp:244]     Train net output #0: loss = 0.0144045 (* 1 = 0.0144045 loss)
I0403 02:48:02.395066 28786 sgd_solver.cpp:106] Iteration 565, lr = 0.005
I0403 02:48:05.903952 28786 solver.cpp:228] Iteration 570, loss = 0.0140972
I0403 02:48:05.911057 28786 solver.cpp:244]     Train net output #0: loss = 0.0140973 (* 1 = 0.0140973 loss)
I0403 02:48:06.082813 28786 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 02:48:09.554160 28786 solver.cpp:228] Iteration 575, loss = 0.0423201
I0403 02:48:09.560091 28786 solver.cpp:244]     Train net output #0: loss = 0.0423202 (* 1 = 0.0423202 loss)
I0403 02:48:09.706266 28786 sgd_solver.cpp:106] Iteration 575, lr = 0.005
I0403 02:48:13.307833 28786 solver.cpp:228] Iteration 580, loss = 0.0756505
I0403 02:48:13.313254 28786 solver.cpp:244]     Train net output #0: loss = 0.0756506 (* 1 = 0.0756506 loss)
I0403 02:48:13.512495 28786 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 02:48:16.999898 28786 solver.cpp:228] Iteration 585, loss = 0.0217635
I0403 02:48:17.005874 28786 solver.cpp:244]     Train net output #0: loss = 0.0217636 (* 1 = 0.0217636 loss)
I0403 02:48:17.224709 28786 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 02:48:20.782465 28786 solver.cpp:228] Iteration 590, loss = 0.138942
I0403 02:48:20.789063 28786 solver.cpp:244]     Train net output #0: loss = 0.138942 (* 1 = 0.138942 loss)
I0403 02:48:20.926980 28786 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 02:48:24.483168 28786 solver.cpp:228] Iteration 595, loss = 0.0305456
I0403 02:48:24.489970 28786 solver.cpp:244]     Train net output #0: loss = 0.0305456 (* 1 = 0.0305456 loss)
I0403 02:48:24.672052 28786 sgd_solver.cpp:106] Iteration 595, lr = 0.005
I0403 02:48:28.113931 28786 solver.cpp:228] Iteration 600, loss = 0.0885015
I0403 02:48:28.120121 28786 solver.cpp:244]     Train net output #0: loss = 0.0885016 (* 1 = 0.0885016 loss)
I0403 02:48:28.317360 28786 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 02:48:31.766788 28786 solver.cpp:228] Iteration 605, loss = 0.00688902
I0403 02:48:31.773628 28786 solver.cpp:244]     Train net output #0: loss = 0.00688907 (* 1 = 0.00688907 loss)
I0403 02:48:31.937255 28786 sgd_solver.cpp:106] Iteration 605, lr = 0.005
I0403 02:48:35.419276 28786 solver.cpp:228] Iteration 610, loss = 0.0146069
I0403 02:48:35.424427 28786 solver.cpp:244]     Train net output #0: loss = 0.0146069 (* 1 = 0.0146069 loss)
I0403 02:48:35.596503 28786 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 02:48:39.026777 28786 solver.cpp:228] Iteration 615, loss = 0.0428004
I0403 02:48:39.033200 28786 solver.cpp:244]     Train net output #0: loss = 0.0428005 (* 1 = 0.0428005 loss)
I0403 02:48:39.253840 28786 sgd_solver.cpp:106] Iteration 615, lr = 0.005
I0403 02:48:42.677012 28786 solver.cpp:228] Iteration 620, loss = 0.0230099
I0403 02:48:42.682797 28786 solver.cpp:244]     Train net output #0: loss = 0.02301 (* 1 = 0.02301 loss)
I0403 02:48:42.863474 28786 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 02:48:46.296830 28786 solver.cpp:228] Iteration 625, loss = 0.0102307
I0403 02:48:46.303656 28786 solver.cpp:244]     Train net output #0: loss = 0.0102308 (* 1 = 0.0102308 loss)
I0403 02:48:46.479670 28786 sgd_solver.cpp:106] Iteration 625, lr = 0.005
I0403 02:48:49.914127 28786 solver.cpp:228] Iteration 630, loss = 0.0424534
I0403 02:48:49.920527 28786 solver.cpp:244]     Train net output #0: loss = 0.0424535 (* 1 = 0.0424535 loss)
I0403 02:48:50.094794 28786 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:48:53.495319 28786 solver.cpp:228] Iteration 635, loss = 0.0386019
I0403 02:48:53.502249 28786 solver.cpp:244]     Train net output #0: loss = 0.0386019 (* 1 = 0.0386019 loss)
I0403 02:48:53.674185 28786 sgd_solver.cpp:106] Iteration 635, lr = 0.005
I0403 02:48:53.680501 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_636.caffemodel
I0403 02:48:56.338449 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_636.solverstate
I0403 02:48:58.163996 28786 solver.cpp:337] Iteration 636, Testing net (#0)
I0403 02:50:37.332844 28786 solver.cpp:404]     Test net output #0: accuracy = 0.951767
I0403 02:50:37.339485 28786 solver.cpp:404]     Test net output #1: loss = 0.179787 (* 1 = 0.179787 loss)
I0403 02:50:40.771333 28786 solver.cpp:228] Iteration 640, loss = 0.0561628
I0403 02:50:40.778153 28786 solver.cpp:244]     Train net output #0: loss = 0.0561629 (* 1 = 0.0561629 loss)
I0403 02:50:40.961400 28786 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 02:50:44.475266 28786 solver.cpp:228] Iteration 645, loss = 0.10467
I0403 02:50:44.481506 28786 solver.cpp:244]     Train net output #0: loss = 0.10467 (* 1 = 0.10467 loss)
I0403 02:50:44.653980 28786 sgd_solver.cpp:106] Iteration 645, lr = 0.005
I0403 02:50:48.118209 28786 solver.cpp:228] Iteration 650, loss = 0.0256385
I0403 02:50:48.123905 28786 solver.cpp:244]     Train net output #0: loss = 0.0256386 (* 1 = 0.0256386 loss)
I0403 02:50:48.304608 28786 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:50:51.723601 28786 solver.cpp:228] Iteration 655, loss = 0.0548842
I0403 02:50:51.729594 28786 solver.cpp:244]     Train net output #0: loss = 0.0548842 (* 1 = 0.0548842 loss)
I0403 02:50:51.913362 28786 sgd_solver.cpp:106] Iteration 655, lr = 0.005
I0403 02:50:55.356365 28786 solver.cpp:228] Iteration 660, loss = 0.0255146
I0403 02:50:55.362669 28786 solver.cpp:244]     Train net output #0: loss = 0.0255146 (* 1 = 0.0255146 loss)
I0403 02:50:55.557972 28786 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 02:50:58.993332 28786 solver.cpp:228] Iteration 665, loss = 0.00299712
I0403 02:50:58.999104 28786 solver.cpp:244]     Train net output #0: loss = 0.00299716 (* 1 = 0.00299716 loss)
I0403 02:50:59.205869 28786 sgd_solver.cpp:106] Iteration 665, lr = 0.005
I0403 02:51:02.705354 28786 solver.cpp:228] Iteration 670, loss = 0.016753
I0403 02:51:02.712033 28786 solver.cpp:244]     Train net output #0: loss = 0.016753 (* 1 = 0.016753 loss)
I0403 02:51:02.884999 28786 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 02:51:06.348309 28786 solver.cpp:228] Iteration 675, loss = 0.0696108
I0403 02:51:06.368640 28786 solver.cpp:244]     Train net output #0: loss = 0.0696109 (* 1 = 0.0696109 loss)
I0403 02:51:06.532117 28786 sgd_solver.cpp:106] Iteration 675, lr = 0.005
I0403 02:51:10.009285 28786 solver.cpp:228] Iteration 680, loss = 0.138358
I0403 02:51:10.015709 28786 solver.cpp:244]     Train net output #0: loss = 0.138358 (* 1 = 0.138358 loss)
I0403 02:51:10.223593 28786 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 02:51:13.623664 28786 solver.cpp:228] Iteration 685, loss = 0.0293368
I0403 02:51:13.630653 28786 solver.cpp:244]     Train net output #0: loss = 0.0293368 (* 1 = 0.0293368 loss)
I0403 02:51:13.840337 28786 sgd_solver.cpp:106] Iteration 685, lr = 0.005
I0403 02:51:17.294718 28786 solver.cpp:228] Iteration 690, loss = 0.0359101
I0403 02:51:17.301365 28786 solver.cpp:244]     Train net output #0: loss = 0.0359101 (* 1 = 0.0359101 loss)
I0403 02:51:17.474567 28786 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 02:51:20.962136 28786 solver.cpp:228] Iteration 695, loss = 0.0436726
I0403 02:51:20.967895 28786 solver.cpp:244]     Train net output #0: loss = 0.0436727 (* 1 = 0.0436727 loss)
I0403 02:51:21.144775 28786 sgd_solver.cpp:106] Iteration 695, lr = 0.005
I0403 02:51:24.603446 28786 solver.cpp:228] Iteration 700, loss = 0.0877256
I0403 02:51:24.608535 28786 solver.cpp:244]     Train net output #0: loss = 0.0877256 (* 1 = 0.0877256 loss)
I0403 02:51:24.801314 28786 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 02:51:28.339977 28786 solver.cpp:228] Iteration 705, loss = 0.0470269
I0403 02:51:28.346391 28786 solver.cpp:244]     Train net output #0: loss = 0.0470269 (* 1 = 0.0470269 loss)
I0403 02:51:28.454834 28786 sgd_solver.cpp:106] Iteration 705, lr = 0.005
I0403 02:51:32.083962 28786 solver.cpp:228] Iteration 710, loss = 0.00252182
I0403 02:51:32.090970 28786 solver.cpp:244]     Train net output #0: loss = 0.00252187 (* 1 = 0.00252187 loss)
I0403 02:51:32.246248 28786 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 02:51:35.791394 28786 solver.cpp:228] Iteration 715, loss = 0.0118427
I0403 02:51:35.798074 28786 solver.cpp:244]     Train net output #0: loss = 0.0118428 (* 1 = 0.0118428 loss)
I0403 02:51:36.014648 28786 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 02:51:39.457918 28786 solver.cpp:228] Iteration 720, loss = 0.0203577
I0403 02:51:39.464437 28786 solver.cpp:244]     Train net output #0: loss = 0.0203577 (* 1 = 0.0203577 loss)
I0403 02:51:39.640401 28786 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 02:51:43.059077 28786 solver.cpp:228] Iteration 725, loss = 0.0564758
I0403 02:51:43.066167 28786 solver.cpp:244]     Train net output #0: loss = 0.0564758 (* 1 = 0.0564758 loss)
I0403 02:51:43.252552 28786 sgd_solver.cpp:106] Iteration 725, lr = 0.005
I0403 02:51:46.701911 28786 solver.cpp:228] Iteration 730, loss = 0.0169498
I0403 02:51:46.708317 28786 solver.cpp:244]     Train net output #0: loss = 0.0169498 (* 1 = 0.0169498 loss)
I0403 02:51:46.881165 28786 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 02:51:50.331351 28786 solver.cpp:228] Iteration 735, loss = 0.00678615
I0403 02:51:50.337398 28786 solver.cpp:244]     Train net output #0: loss = 0.00678621 (* 1 = 0.00678621 loss)
I0403 02:51:50.511061 28786 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 02:51:53.967357 28786 solver.cpp:228] Iteration 740, loss = 0.046945
I0403 02:51:53.973259 28786 solver.cpp:244]     Train net output #0: loss = 0.046945 (* 1 = 0.046945 loss)
I0403 02:51:54.146162 28786 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 02:51:54.865034 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_742.caffemodel
I0403 02:51:57.564096 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_742.solverstate
I0403 02:51:59.395691 28786 solver.cpp:337] Iteration 742, Testing net (#0)
I0403 02:53:38.585391 28786 solver.cpp:404]     Test net output #0: accuracy = 0.955757
I0403 02:53:38.592067 28786 solver.cpp:404]     Test net output #1: loss = 0.171851 (* 1 = 0.171851 loss)
I0403 02:53:41.356812 28786 solver.cpp:228] Iteration 745, loss = 0.0178261
I0403 02:53:41.363423 28786 solver.cpp:244]     Train net output #0: loss = 0.0178262 (* 1 = 0.0178262 loss)
I0403 02:53:41.571835 28786 sgd_solver.cpp:106] Iteration 745, lr = 0.005
I0403 02:53:45.016968 28786 solver.cpp:228] Iteration 750, loss = 0.016875
I0403 02:53:45.023221 28786 solver.cpp:244]     Train net output #0: loss = 0.016875 (* 1 = 0.016875 loss)
I0403 02:53:45.210031 28786 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 02:53:48.764608 28786 solver.cpp:228] Iteration 755, loss = 0.0214867
I0403 02:53:48.769970 28786 solver.cpp:244]     Train net output #0: loss = 0.0214867 (* 1 = 0.0214867 loss)
I0403 02:53:48.961083 28786 sgd_solver.cpp:106] Iteration 755, lr = 0.005
I0403 02:53:52.424202 28786 solver.cpp:228] Iteration 760, loss = 0.0329199
I0403 02:53:52.429425 28786 solver.cpp:244]     Train net output #0: loss = 0.03292 (* 1 = 0.03292 loss)
I0403 02:53:52.610790 28786 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 02:53:56.139014 28786 solver.cpp:228] Iteration 765, loss = 0.0327567
I0403 02:53:56.145874 28786 solver.cpp:244]     Train net output #0: loss = 0.0327568 (* 1 = 0.0327568 loss)
I0403 02:53:56.322305 28786 sgd_solver.cpp:106] Iteration 765, lr = 0.005
I0403 02:53:59.786296 28786 solver.cpp:228] Iteration 770, loss = 0.0224751
I0403 02:53:59.791774 28786 solver.cpp:244]     Train net output #0: loss = 0.0224751 (* 1 = 0.0224751 loss)
I0403 02:53:59.952978 28786 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 02:54:03.408517 28786 solver.cpp:228] Iteration 775, loss = 0.0514614
I0403 02:54:03.414899 28786 solver.cpp:244]     Train net output #0: loss = 0.0514614 (* 1 = 0.0514614 loss)
I0403 02:54:03.584589 28786 sgd_solver.cpp:106] Iteration 775, lr = 0.005
I0403 02:54:07.027456 28786 solver.cpp:228] Iteration 780, loss = 0.0216716
I0403 02:54:07.032572 28786 solver.cpp:244]     Train net output #0: loss = 0.0216717 (* 1 = 0.0216717 loss)
I0403 02:54:07.248308 28786 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:54:10.664156 28786 solver.cpp:228] Iteration 785, loss = 0.0112678
I0403 02:54:10.670174 28786 solver.cpp:244]     Train net output #0: loss = 0.0112679 (* 1 = 0.0112679 loss)
I0403 02:54:10.918462 28786 sgd_solver.cpp:106] Iteration 785, lr = 0.005
I0403 02:54:14.357555 28786 solver.cpp:228] Iteration 790, loss = 0.0198197
I0403 02:54:14.363452 28786 solver.cpp:244]     Train net output #0: loss = 0.0198197 (* 1 = 0.0198197 loss)
I0403 02:54:14.540832 28786 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 02:54:17.938483 28786 solver.cpp:228] Iteration 795, loss = 0.015549
I0403 02:54:17.943851 28786 solver.cpp:244]     Train net output #0: loss = 0.015549 (* 1 = 0.015549 loss)
I0403 02:54:18.178557 28786 sgd_solver.cpp:106] Iteration 795, lr = 0.005
I0403 02:54:21.702807 28786 solver.cpp:228] Iteration 800, loss = 0.0338689
I0403 02:54:21.707921 28786 solver.cpp:244]     Train net output #0: loss = 0.033869 (* 1 = 0.033869 loss)
I0403 02:54:21.885006 28786 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 02:54:25.423182 28786 solver.cpp:228] Iteration 805, loss = 0.0625269
I0403 02:54:25.429349 28786 solver.cpp:244]     Train net output #0: loss = 0.0625269 (* 1 = 0.0625269 loss)
I0403 02:54:25.601589 28786 sgd_solver.cpp:106] Iteration 805, lr = 0.005
I0403 02:54:29.013365 28786 solver.cpp:228] Iteration 810, loss = 0.0686284
I0403 02:54:29.020195 28786 solver.cpp:244]     Train net output #0: loss = 0.0686284 (* 1 = 0.0686284 loss)
I0403 02:54:29.195641 28786 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 02:54:32.717118 28786 solver.cpp:228] Iteration 815, loss = 0.016391
I0403 02:54:32.723261 28786 solver.cpp:244]     Train net output #0: loss = 0.0163911 (* 1 = 0.0163911 loss)
I0403 02:54:32.927392 28786 sgd_solver.cpp:106] Iteration 815, lr = 0.005
I0403 02:54:36.390642 28786 solver.cpp:228] Iteration 820, loss = 0.0498452
I0403 02:54:36.395808 28786 solver.cpp:244]     Train net output #0: loss = 0.0498453 (* 1 = 0.0498453 loss)
I0403 02:54:36.556531 28786 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 02:54:40.095227 28786 solver.cpp:228] Iteration 825, loss = 0.00974947
I0403 02:54:40.101492 28786 solver.cpp:244]     Train net output #0: loss = 0.00974948 (* 1 = 0.00974948 loss)
I0403 02:54:40.242383 28786 sgd_solver.cpp:106] Iteration 825, lr = 0.005
I0403 02:54:43.825248 28786 solver.cpp:228] Iteration 830, loss = 0.0403956
I0403 02:54:43.831491 28786 solver.cpp:244]     Train net output #0: loss = 0.0403956 (* 1 = 0.0403956 loss)
I0403 02:54:44.011299 28786 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 02:54:47.466600 28786 solver.cpp:228] Iteration 835, loss = 0.0381629
I0403 02:54:47.472610 28786 solver.cpp:244]     Train net output #0: loss = 0.038163 (* 1 = 0.038163 loss)
I0403 02:54:47.670056 28786 sgd_solver.cpp:106] Iteration 835, lr = 0.005
I0403 02:54:51.139196 28786 solver.cpp:228] Iteration 840, loss = 0.0310614
I0403 02:54:51.144006 28786 solver.cpp:244]     Train net output #0: loss = 0.0310614 (* 1 = 0.0310614 loss)
I0403 02:54:51.351116 28786 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:54:54.876322 28786 solver.cpp:228] Iteration 845, loss = 0.0210204
I0403 02:54:54.881557 28786 solver.cpp:244]     Train net output #0: loss = 0.0210204 (* 1 = 0.0210204 loss)
I0403 02:54:55.072670 28786 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 02:54:56.503500 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_848.caffemodel
I0403 02:54:59.315743 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_848.solverstate
I0403 02:55:01.256001 28786 solver.cpp:337] Iteration 848, Testing net (#0)
I0403 02:56:40.436372 28786 solver.cpp:404]     Test net output #0: accuracy = 0.962616
I0403 02:56:40.448565 28786 solver.cpp:404]     Test net output #1: loss = 0.143632 (* 1 = 0.143632 loss)
I0403 02:56:42.488481 28786 solver.cpp:228] Iteration 850, loss = 0.0297494
I0403 02:56:42.494699 28786 solver.cpp:244]     Train net output #0: loss = 0.0297494 (* 1 = 0.0297494 loss)
I0403 02:56:42.589725 28786 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 02:56:46.230778 28786 solver.cpp:228] Iteration 855, loss = 0.0112928
I0403 02:56:46.237220 28786 solver.cpp:244]     Train net output #0: loss = 0.0112928 (* 1 = 0.0112928 loss)
I0403 02:56:46.427255 28786 sgd_solver.cpp:106] Iteration 855, lr = 0.005
I0403 02:56:49.918151 28786 solver.cpp:228] Iteration 860, loss = 0.0542946
I0403 02:56:49.924968 28786 solver.cpp:244]     Train net output #0: loss = 0.0542947 (* 1 = 0.0542947 loss)
I0403 02:56:50.095876 28786 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 02:56:53.548667 28786 solver.cpp:228] Iteration 865, loss = 0.023157
I0403 02:56:53.554083 28786 solver.cpp:244]     Train net output #0: loss = 0.023157 (* 1 = 0.023157 loss)
I0403 02:56:53.724563 28786 sgd_solver.cpp:106] Iteration 865, lr = 0.005
I0403 02:56:57.234289 28786 solver.cpp:228] Iteration 870, loss = 0.0266636
I0403 02:56:57.241255 28786 solver.cpp:244]     Train net output #0: loss = 0.0266636 (* 1 = 0.0266636 loss)
I0403 02:56:57.414901 28786 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 02:57:00.899739 28786 solver.cpp:228] Iteration 875, loss = 0.0412791
I0403 02:57:00.906750 28786 solver.cpp:244]     Train net output #0: loss = 0.0412791 (* 1 = 0.0412791 loss)
I0403 02:57:01.082598 28786 sgd_solver.cpp:106] Iteration 875, lr = 0.005
I0403 02:57:04.568430 28786 solver.cpp:228] Iteration 880, loss = 0.0144571
I0403 02:57:04.574832 28786 solver.cpp:244]     Train net output #0: loss = 0.0144571 (* 1 = 0.0144571 loss)
I0403 02:57:04.693173 28786 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 02:57:08.287533 28786 solver.cpp:228] Iteration 885, loss = 0.113441
I0403 02:57:08.292825 28786 solver.cpp:244]     Train net output #0: loss = 0.113441 (* 1 = 0.113441 loss)
I0403 02:57:08.490932 28786 sgd_solver.cpp:106] Iteration 885, lr = 0.005
I0403 02:57:12.006386 28786 solver.cpp:228] Iteration 890, loss = 0.0170223
I0403 02:57:12.013473 28786 solver.cpp:244]     Train net output #0: loss = 0.0170223 (* 1 = 0.0170223 loss)
I0403 02:57:12.210963 28786 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 02:57:15.626952 28786 solver.cpp:228] Iteration 895, loss = 0.0437285
I0403 02:57:15.632861 28786 solver.cpp:244]     Train net output #0: loss = 0.0437286 (* 1 = 0.0437286 loss)
I0403 02:57:15.805979 28786 sgd_solver.cpp:106] Iteration 895, lr = 0.005
I0403 02:57:19.221374 28786 solver.cpp:228] Iteration 900, loss = 0.0109012
I0403 02:57:19.227162 28786 solver.cpp:244]     Train net output #0: loss = 0.0109012 (* 1 = 0.0109012 loss)
I0403 02:57:19.444603 28786 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 02:57:22.931221 28786 solver.cpp:228] Iteration 905, loss = 0.0822506
I0403 02:57:22.937065 28786 solver.cpp:244]     Train net output #0: loss = 0.0822507 (* 1 = 0.0822507 loss)
I0403 02:57:23.102294 28786 sgd_solver.cpp:106] Iteration 905, lr = 0.005
I0403 02:57:26.617733 28786 solver.cpp:228] Iteration 910, loss = 0.00583281
I0403 02:57:26.624411 28786 solver.cpp:244]     Train net output #0: loss = 0.00583284 (* 1 = 0.00583284 loss)
I0403 02:57:26.830382 28786 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:57:30.314801 28786 solver.cpp:228] Iteration 915, loss = 0.00400537
I0403 02:57:30.321033 28786 solver.cpp:244]     Train net output #0: loss = 0.0040054 (* 1 = 0.0040054 loss)
I0403 02:57:30.472239 28786 sgd_solver.cpp:106] Iteration 915, lr = 0.005
I0403 02:57:34.010848 28786 solver.cpp:228] Iteration 920, loss = 0.0314004
I0403 02:57:34.016865 28786 solver.cpp:244]     Train net output #0: loss = 0.0314004 (* 1 = 0.0314004 loss)
I0403 02:57:34.195993 28786 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 02:57:37.795858 28786 solver.cpp:228] Iteration 925, loss = 0.00292576
I0403 02:57:37.802034 28786 solver.cpp:244]     Train net output #0: loss = 0.00292578 (* 1 = 0.00292578 loss)
I0403 02:57:37.931570 28786 sgd_solver.cpp:106] Iteration 925, lr = 0.005
I0403 02:57:41.645210 28786 solver.cpp:228] Iteration 930, loss = 0.00740142
I0403 02:57:41.651283 28786 solver.cpp:244]     Train net output #0: loss = 0.00740144 (* 1 = 0.00740144 loss)
I0403 02:57:41.807911 28786 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 02:57:45.372597 28786 solver.cpp:228] Iteration 935, loss = 0.0213596
I0403 02:57:45.379310 28786 solver.cpp:244]     Train net output #0: loss = 0.0213596 (* 1 = 0.0213596 loss)
I0403 02:57:45.572242 28786 sgd_solver.cpp:106] Iteration 935, lr = 0.005
I0403 02:57:48.994303 28786 solver.cpp:228] Iteration 940, loss = 0.00377884
I0403 02:57:49.000936 28786 solver.cpp:244]     Train net output #0: loss = 0.00377886 (* 1 = 0.00377886 loss)
I0403 02:57:49.177120 28786 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 02:57:52.662848 28786 solver.cpp:228] Iteration 945, loss = 0.0450195
I0403 02:57:52.669186 28786 solver.cpp:244]     Train net output #0: loss = 0.0450195 (* 1 = 0.0450195 loss)
I0403 02:57:52.843839 28786 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 02:57:56.286777 28786 solver.cpp:228] Iteration 950, loss = 0.0437474
I0403 02:57:56.291841 28786 solver.cpp:244]     Train net output #0: loss = 0.0437474 (* 1 = 0.0437474 loss)
I0403 02:57:56.445880 28786 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 02:57:58.705363 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_954.caffemodel
I0403 02:58:01.482563 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_954.solverstate
I0403 02:58:03.417309 28786 solver.cpp:337] Iteration 954, Testing net (#0)
I0403 02:59:42.593075 28786 solver.cpp:404]     Test net output #0: accuracy = 0.959749
I0403 02:59:42.599645 28786 solver.cpp:404]     Test net output #1: loss = 0.145205 (* 1 = 0.145205 loss)
I0403 02:59:43.831251 28786 solver.cpp:228] Iteration 955, loss = 0.012958
I0403 02:59:43.837200 28786 solver.cpp:244]     Train net output #0: loss = 0.012958 (* 1 = 0.012958 loss)
I0403 02:59:44.009609 28786 sgd_solver.cpp:106] Iteration 955, lr = 0.005
I0403 02:59:47.426900 28786 solver.cpp:228] Iteration 960, loss = 0.0492343
I0403 02:59:47.432962 28786 solver.cpp:244]     Train net output #0: loss = 0.0492344 (* 1 = 0.0492344 loss)
I0403 02:59:47.631958 28786 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 02:59:51.116345 28786 solver.cpp:228] Iteration 965, loss = 0.00425441
I0403 02:59:51.122999 28786 solver.cpp:244]     Train net output #0: loss = 0.00425443 (* 1 = 0.00425443 loss)
I0403 02:59:51.291458 28786 sgd_solver.cpp:106] Iteration 965, lr = 0.005
I0403 02:59:54.730783 28786 solver.cpp:228] Iteration 970, loss = 0.042461
I0403 02:59:54.736420 28786 solver.cpp:244]     Train net output #0: loss = 0.0424611 (* 1 = 0.0424611 loss)
I0403 02:59:54.913681 28786 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 02:59:58.342710 28786 solver.cpp:228] Iteration 975, loss = 0.0271645
I0403 02:59:58.348459 28786 solver.cpp:244]     Train net output #0: loss = 0.0271645 (* 1 = 0.0271645 loss)
I0403 02:59:58.500664 28786 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 03:00:01.985122 28786 solver.cpp:228] Iteration 980, loss = 0.0279556
I0403 03:00:01.990161 28786 solver.cpp:244]     Train net output #0: loss = 0.0279556 (* 1 = 0.0279556 loss)
I0403 03:00:02.174535 28786 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 03:00:05.587119 28786 solver.cpp:228] Iteration 985, loss = 0.0184858
I0403 03:00:05.592558 28786 solver.cpp:244]     Train net output #0: loss = 0.0184859 (* 1 = 0.0184859 loss)
I0403 03:00:05.766585 28786 sgd_solver.cpp:106] Iteration 985, lr = 0.005
I0403 03:00:09.210657 28786 solver.cpp:228] Iteration 990, loss = 0.038901
I0403 03:00:09.216975 28786 solver.cpp:244]     Train net output #0: loss = 0.038901 (* 1 = 0.038901 loss)
I0403 03:00:09.394675 28786 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 03:00:12.805557 28786 solver.cpp:228] Iteration 995, loss = 0.00682312
I0403 03:00:12.811965 28786 solver.cpp:244]     Train net output #0: loss = 0.00682314 (* 1 = 0.00682314 loss)
I0403 03:00:13.001209 28786 sgd_solver.cpp:106] Iteration 995, lr = 0.005
I0403 03:00:16.468855 28786 solver.cpp:228] Iteration 1000, loss = 0.0288993
I0403 03:00:16.475633 28786 solver.cpp:244]     Train net output #0: loss = 0.0288993 (* 1 = 0.0288993 loss)
I0403 03:00:16.623574 28786 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 03:00:20.346544 28786 solver.cpp:228] Iteration 1005, loss = 0.148015
I0403 03:00:20.353441 28786 solver.cpp:244]     Train net output #0: loss = 0.148015 (* 1 = 0.148015 loss)
I0403 03:00:20.524263 28786 sgd_solver.cpp:106] Iteration 1005, lr = 0.005
I0403 03:00:23.984227 28786 solver.cpp:228] Iteration 1010, loss = 0.0275244
I0403 03:00:23.990057 28786 solver.cpp:244]     Train net output #0: loss = 0.0275244 (* 1 = 0.0275244 loss)
I0403 03:00:24.153488 28786 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 03:00:27.594033 28786 solver.cpp:228] Iteration 1015, loss = 0.0128197
I0403 03:00:27.600806 28786 solver.cpp:244]     Train net output #0: loss = 0.0128198 (* 1 = 0.0128198 loss)
I0403 03:00:27.762562 28786 sgd_solver.cpp:106] Iteration 1015, lr = 0.005
I0403 03:00:31.298984 28786 solver.cpp:228] Iteration 1020, loss = 0.0241051
I0403 03:00:31.304836 28786 solver.cpp:244]     Train net output #0: loss = 0.0241051 (* 1 = 0.0241051 loss)
I0403 03:00:31.485162 28786 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 03:00:34.987468 28786 solver.cpp:228] Iteration 1025, loss = 0.0407829
I0403 03:00:34.993199 28786 solver.cpp:244]     Train net output #0: loss = 0.0407829 (* 1 = 0.0407829 loss)
I0403 03:00:35.213964 28786 sgd_solver.cpp:106] Iteration 1025, lr = 0.005
I0403 03:00:38.670423 28786 solver.cpp:228] Iteration 1030, loss = 0.0249981
I0403 03:00:38.676656 28786 solver.cpp:244]     Train net output #0: loss = 0.0249981 (* 1 = 0.0249981 loss)
I0403 03:00:38.877866 28786 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 03:00:42.274828 28786 solver.cpp:228] Iteration 1035, loss = 0.0025192
I0403 03:00:42.279932 28786 solver.cpp:244]     Train net output #0: loss = 0.00251921 (* 1 = 0.00251921 loss)
I0403 03:00:42.491376 28786 sgd_solver.cpp:106] Iteration 1035, lr = 0.005
I0403 03:00:45.966997 28786 solver.cpp:228] Iteration 1040, loss = 0.0316531
I0403 03:00:45.973233 28786 solver.cpp:244]     Train net output #0: loss = 0.0316531 (* 1 = 0.0316531 loss)
I0403 03:00:46.184145 28786 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 03:00:49.606482 28786 solver.cpp:228] Iteration 1045, loss = 0.00403875
I0403 03:00:49.611940 28786 solver.cpp:244]     Train net output #0: loss = 0.00403877 (* 1 = 0.00403877 loss)
I0403 03:00:49.785801 28786 sgd_solver.cpp:106] Iteration 1045, lr = 0.005
I0403 03:00:53.248237 28786 solver.cpp:228] Iteration 1050, loss = 0.0296697
I0403 03:00:53.253862 28786 solver.cpp:244]     Train net output #0: loss = 0.0296697 (* 1 = 0.0296697 loss)
I0403 03:00:53.431905 28786 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 03:00:56.843907 28786 solver.cpp:228] Iteration 1055, loss = 0.0234038
I0403 03:00:56.850050 28786 solver.cpp:244]     Train net output #0: loss = 0.0234038 (* 1 = 0.0234038 loss)
I0403 03:00:57.021352 28786 sgd_solver.cpp:106] Iteration 1055, lr = 0.005
I0403 03:00:59.893986 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1060.caffemodel
I0403 03:01:02.696502 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1060.solverstate
I0403 03:01:04.632807 28786 solver.cpp:337] Iteration 1060, Testing net (#0)
I0403 03:02:43.834475 28786 solver.cpp:404]     Test net output #0: accuracy = 0.960001
I0403 03:02:43.841634 28786 solver.cpp:404]     Test net output #1: loss = 0.150371 (* 1 = 0.150371 loss)
I0403 03:02:44.366209 28786 solver.cpp:228] Iteration 1060, loss = 0.0139687
I0403 03:02:44.371918 28786 solver.cpp:244]     Train net output #0: loss = 0.0139687 (* 1 = 0.0139687 loss)
I0403 03:02:44.546854 28786 sgd_solver.cpp:106] Iteration 1060, lr = 0.005
I0403 03:02:47.966755 28786 solver.cpp:228] Iteration 1065, loss = 0.00924232
I0403 03:02:47.974418 28786 solver.cpp:244]     Train net output #0: loss = 0.00924234 (* 1 = 0.00924234 loss)
I0403 03:02:48.154903 28786 sgd_solver.cpp:106] Iteration 1065, lr = 0.005
I0403 03:02:51.575916 28786 solver.cpp:228] Iteration 1070, loss = 0.00130531
I0403 03:02:51.581663 28786 solver.cpp:244]     Train net output #0: loss = 0.00130533 (* 1 = 0.00130533 loss)
I0403 03:02:51.755764 28786 sgd_solver.cpp:106] Iteration 1070, lr = 0.0005
I0403 03:02:55.217176 28786 solver.cpp:228] Iteration 1075, loss = 0.0213953
I0403 03:02:55.223119 28786 solver.cpp:244]     Train net output #0: loss = 0.0213953 (* 1 = 0.0213953 loss)
I0403 03:02:55.400493 28786 sgd_solver.cpp:106] Iteration 1075, lr = 0.0005
I0403 03:02:58.804728 28786 solver.cpp:228] Iteration 1080, loss = 0.0132054
I0403 03:02:58.811069 28786 solver.cpp:244]     Train net output #0: loss = 0.0132055 (* 1 = 0.0132055 loss)
I0403 03:02:58.997103 28786 sgd_solver.cpp:106] Iteration 1080, lr = 0.0005
I0403 03:03:02.492442 28786 solver.cpp:228] Iteration 1085, loss = 0.0169782
I0403 03:03:02.498479 28786 solver.cpp:244]     Train net output #0: loss = 0.0169782 (* 1 = 0.0169782 loss)
I0403 03:03:02.665666 28786 sgd_solver.cpp:106] Iteration 1085, lr = 0.0005
I0403 03:03:06.135610 28786 solver.cpp:228] Iteration 1090, loss = 0.00149345
I0403 03:03:06.140776 28786 solver.cpp:244]     Train net output #0: loss = 0.00149347 (* 1 = 0.00149347 loss)
I0403 03:03:06.325690 28786 sgd_solver.cpp:106] Iteration 1090, lr = 0.0005
I0403 03:03:09.756829 28786 solver.cpp:228] Iteration 1095, loss = 0.00475409
I0403 03:03:09.762362 28786 solver.cpp:244]     Train net output #0: loss = 0.00475411 (* 1 = 0.00475411 loss)
I0403 03:03:09.936074 28786 sgd_solver.cpp:106] Iteration 1095, lr = 0.0005
I0403 03:03:13.407542 28786 solver.cpp:228] Iteration 1100, loss = 0.005952
I0403 03:03:13.413152 28786 solver.cpp:244]     Train net output #0: loss = 0.00595202 (* 1 = 0.00595202 loss)
I0403 03:03:13.576158 28786 sgd_solver.cpp:106] Iteration 1100, lr = 0.0005
I0403 03:03:17.005374 28786 solver.cpp:228] Iteration 1105, loss = 0.00347941
I0403 03:03:17.011917 28786 solver.cpp:244]     Train net output #0: loss = 0.00347942 (* 1 = 0.00347942 loss)
I0403 03:03:17.186193 28786 sgd_solver.cpp:106] Iteration 1105, lr = 0.0005
I0403 03:03:20.617563 28786 solver.cpp:228] Iteration 1110, loss = 0.00909561
I0403 03:03:20.623035 28786 solver.cpp:244]     Train net output #0: loss = 0.00909563 (* 1 = 0.00909563 loss)
I0403 03:03:20.799886 28786 sgd_solver.cpp:106] Iteration 1110, lr = 0.0005
I0403 03:03:24.266165 28786 solver.cpp:228] Iteration 1115, loss = 0.00493901
I0403 03:03:24.272511 28786 solver.cpp:244]     Train net output #0: loss = 0.00493903 (* 1 = 0.00493903 loss)
I0403 03:03:24.460189 28786 sgd_solver.cpp:106] Iteration 1115, lr = 0.0005
I0403 03:03:27.877465 28786 solver.cpp:228] Iteration 1120, loss = 0.00308753
I0403 03:03:27.883780 28786 solver.cpp:244]     Train net output #0: loss = 0.00308754 (* 1 = 0.00308754 loss)
I0403 03:03:28.056576 28786 sgd_solver.cpp:106] Iteration 1120, lr = 0.0005
I0403 03:03:31.516918 28786 solver.cpp:228] Iteration 1125, loss = 0.00513944
I0403 03:03:31.522469 28786 solver.cpp:244]     Train net output #0: loss = 0.00513945 (* 1 = 0.00513945 loss)
I0403 03:03:31.699133 28786 sgd_solver.cpp:106] Iteration 1125, lr = 0.0005
I0403 03:03:35.257123 28786 solver.cpp:228] Iteration 1130, loss = 0.00405907
I0403 03:03:35.262434 28786 solver.cpp:244]     Train net output #0: loss = 0.00405909 (* 1 = 0.00405909 loss)
I0403 03:03:35.420797 28786 sgd_solver.cpp:106] Iteration 1130, lr = 0.0005
I0403 03:03:38.929894 28786 solver.cpp:228] Iteration 1135, loss = 0.0312943
I0403 03:03:38.935482 28786 solver.cpp:244]     Train net output #0: loss = 0.0312943 (* 1 = 0.0312943 loss)
I0403 03:03:39.171494 28786 sgd_solver.cpp:106] Iteration 1135, lr = 0.0005
I0403 03:03:42.729151 28786 solver.cpp:228] Iteration 1140, loss = 0.000317234
I0403 03:03:42.735219 28786 solver.cpp:244]     Train net output #0: loss = 0.00031725 (* 1 = 0.00031725 loss)
I0403 03:03:42.906731 28786 sgd_solver.cpp:106] Iteration 1140, lr = 0.0005
I0403 03:03:46.318159 28786 solver.cpp:228] Iteration 1145, loss = 0.00613435
I0403 03:03:46.323559 28786 solver.cpp:244]     Train net output #0: loss = 0.00613436 (* 1 = 0.00613436 loss)
I0403 03:03:46.494091 28786 sgd_solver.cpp:106] Iteration 1145, lr = 0.0005
I0403 03:03:49.915166 28786 solver.cpp:228] Iteration 1150, loss = 0.0083222
I0403 03:03:49.920990 28786 solver.cpp:244]     Train net output #0: loss = 0.00832222 (* 1 = 0.00832222 loss)
I0403 03:03:50.107116 28786 sgd_solver.cpp:106] Iteration 1150, lr = 0.0005
I0403 03:03:53.514544 28786 solver.cpp:228] Iteration 1155, loss = 0.00207956
I0403 03:03:53.521219 28786 solver.cpp:244]     Train net output #0: loss = 0.00207958 (* 1 = 0.00207958 loss)
I0403 03:03:53.687582 28786 sgd_solver.cpp:106] Iteration 1155, lr = 0.0005
I0403 03:03:57.194823 28786 solver.cpp:228] Iteration 1160, loss = 0.00428722
I0403 03:03:57.202226 28786 solver.cpp:244]     Train net output #0: loss = 0.00428723 (* 1 = 0.00428723 loss)
I0403 03:03:57.415683 28786 sgd_solver.cpp:106] Iteration 1160, lr = 0.0005
I0403 03:04:00.860967 28786 solver.cpp:228] Iteration 1165, loss = 0.00172122
I0403 03:04:00.866691 28786 solver.cpp:244]     Train net output #0: loss = 0.00172123 (* 1 = 0.00172123 loss)
I0403 03:04:01.090580 28786 sgd_solver.cpp:106] Iteration 1165, lr = 0.0005
I0403 03:04:01.090812 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1166.caffemodel
I0403 03:04:03.768929 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1166.solverstate
I0403 03:04:05.546043 28786 solver.cpp:337] Iteration 1166, Testing net (#0)
I0403 03:05:44.731247 28786 solver.cpp:404]     Test net output #0: accuracy = 0.968097
I0403 03:05:44.737409 28786 solver.cpp:404]     Test net output #1: loss = 0.119228 (* 1 = 0.119228 loss)
I0403 03:05:48.148509 28786 solver.cpp:228] Iteration 1170, loss = 0.00681683
I0403 03:05:48.155205 28786 solver.cpp:244]     Train net output #0: loss = 0.00681684 (* 1 = 0.00681684 loss)
I0403 03:05:48.342851 28786 sgd_solver.cpp:106] Iteration 1170, lr = 0.0005
I0403 03:05:51.767261 28786 solver.cpp:228] Iteration 1175, loss = 0.00286335
I0403 03:05:51.773555 28786 solver.cpp:244]     Train net output #0: loss = 0.00286337 (* 1 = 0.00286337 loss)
I0403 03:05:51.942114 28786 sgd_solver.cpp:106] Iteration 1175, lr = 0.0005
I0403 03:05:55.382185 28786 solver.cpp:228] Iteration 1180, loss = 0.00130909
I0403 03:05:55.388141 28786 solver.cpp:244]     Train net output #0: loss = 0.00130911 (* 1 = 0.00130911 loss)
I0403 03:05:55.585953 28786 sgd_solver.cpp:106] Iteration 1180, lr = 0.0005
I0403 03:05:58.992957 28786 solver.cpp:228] Iteration 1185, loss = 0.00415248
I0403 03:05:58.999656 28786 solver.cpp:244]     Train net output #0: loss = 0.00415249 (* 1 = 0.00415249 loss)
I0403 03:05:59.184188 28786 sgd_solver.cpp:106] Iteration 1185, lr = 0.0005
I0403 03:06:02.684044 28786 solver.cpp:228] Iteration 1190, loss = 0.0305726
I0403 03:06:02.689477 28786 solver.cpp:244]     Train net output #0: loss = 0.0305726 (* 1 = 0.0305726 loss)
I0403 03:06:02.836141 28786 sgd_solver.cpp:106] Iteration 1190, lr = 0.0005
I0403 03:06:06.366500 28786 solver.cpp:228] Iteration 1195, loss = 0.000653333
I0403 03:06:06.372972 28786 solver.cpp:244]     Train net output #0: loss = 0.000653349 (* 1 = 0.000653349 loss)
I0403 03:06:06.546370 28786 sgd_solver.cpp:106] Iteration 1195, lr = 0.0005
I0403 03:06:09.947150 28786 solver.cpp:228] Iteration 1200, loss = 0.00669306
I0403 03:06:09.952682 28786 solver.cpp:244]     Train net output #0: loss = 0.00669308 (* 1 = 0.00669308 loss)
I0403 03:06:10.142935 28786 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0403 03:06:13.625473 28786 solver.cpp:228] Iteration 1205, loss = 0.0032745
I0403 03:06:13.631005 28786 solver.cpp:244]     Train net output #0: loss = 0.00327452 (* 1 = 0.00327452 loss)
I0403 03:06:13.828054 28786 sgd_solver.cpp:106] Iteration 1205, lr = 0.0005
I0403 03:06:17.282095 28786 solver.cpp:228] Iteration 1210, loss = 0.0110299
I0403 03:06:17.288329 28786 solver.cpp:244]     Train net output #0: loss = 0.0110299 (* 1 = 0.0110299 loss)
I0403 03:06:17.455260 28786 sgd_solver.cpp:106] Iteration 1210, lr = 0.0005
I0403 03:06:20.885553 28786 solver.cpp:228] Iteration 1215, loss = 0.00311971
I0403 03:06:20.892143 28786 solver.cpp:244]     Train net output #0: loss = 0.00311972 (* 1 = 0.00311972 loss)
I0403 03:06:21.065093 28786 sgd_solver.cpp:106] Iteration 1215, lr = 0.0005
I0403 03:06:24.558956 28786 solver.cpp:228] Iteration 1220, loss = 0.000322876
I0403 03:06:24.564929 28786 solver.cpp:244]     Train net output #0: loss = 0.000322892 (* 1 = 0.000322892 loss)
I0403 03:06:24.738181 28786 sgd_solver.cpp:106] Iteration 1220, lr = 0.0005
I0403 03:06:28.170824 28786 solver.cpp:228] Iteration 1225, loss = 0.00222154
I0403 03:06:28.176916 28786 solver.cpp:244]     Train net output #0: loss = 0.00222156 (* 1 = 0.00222156 loss)
I0403 03:06:28.350404 28786 sgd_solver.cpp:106] Iteration 1225, lr = 0.0005
I0403 03:06:31.758062 28786 solver.cpp:228] Iteration 1230, loss = 0.000618425
I0403 03:06:31.764659 28786 solver.cpp:244]     Train net output #0: loss = 0.000618444 (* 1 = 0.000618444 loss)
I0403 03:06:31.953415 28786 sgd_solver.cpp:106] Iteration 1230, lr = 0.0005
I0403 03:06:35.402482 28786 solver.cpp:228] Iteration 1235, loss = 0.000228181
I0403 03:06:35.408071 28786 solver.cpp:244]     Train net output #0: loss = 0.000228199 (* 1 = 0.000228199 loss)
I0403 03:06:35.565161 28786 sgd_solver.cpp:106] Iteration 1235, lr = 0.0005
I0403 03:06:39.055009 28786 solver.cpp:228] Iteration 1240, loss = 0.000724178
I0403 03:06:39.060819 28786 solver.cpp:244]     Train net output #0: loss = 0.000724196 (* 1 = 0.000724196 loss)
I0403 03:06:39.240231 28786 sgd_solver.cpp:106] Iteration 1240, lr = 0.0005
I0403 03:06:42.775032 28786 solver.cpp:228] Iteration 1245, loss = 0.00138417
I0403 03:06:42.781652 28786 solver.cpp:244]     Train net output #0: loss = 0.00138419 (* 1 = 0.00138419 loss)
I0403 03:06:42.985729 28786 sgd_solver.cpp:106] Iteration 1245, lr = 0.0005
I0403 03:06:46.461277 28786 solver.cpp:228] Iteration 1250, loss = 0.00258546
I0403 03:06:46.467885 28786 solver.cpp:244]     Train net output #0: loss = 0.00258547 (* 1 = 0.00258547 loss)
I0403 03:06:46.640210 28786 sgd_solver.cpp:106] Iteration 1250, lr = 0.0005
I0403 03:06:50.107311 28786 solver.cpp:228] Iteration 1255, loss = 0.0103892
I0403 03:06:50.113219 28786 solver.cpp:244]     Train net output #0: loss = 0.0103892 (* 1 = 0.0103892 loss)
I0403 03:06:50.324563 28786 sgd_solver.cpp:106] Iteration 1255, lr = 0.0005
I0403 03:06:53.855959 28786 solver.cpp:228] Iteration 1260, loss = 0.00930855
I0403 03:06:53.861860 28786 solver.cpp:244]     Train net output #0: loss = 0.00930857 (* 1 = 0.00930857 loss)
I0403 03:06:54.025667 28786 sgd_solver.cpp:106] Iteration 1260, lr = 0.0005
I0403 03:06:57.509196 28786 solver.cpp:228] Iteration 1265, loss = 0.000331128
I0403 03:06:57.515360 28786 solver.cpp:244]     Train net output #0: loss = 0.000331147 (* 1 = 0.000331147 loss)
I0403 03:06:57.675997 28786 sgd_solver.cpp:106] Iteration 1265, lr = 0.0005
I0403 03:07:01.152546 28786 solver.cpp:228] Iteration 1270, loss = 0.00499971
I0403 03:07:01.159361 28786 solver.cpp:244]     Train net output #0: loss = 0.00499973 (* 1 = 0.00499973 loss)
I0403 03:07:01.356274 28786 sgd_solver.cpp:106] Iteration 1270, lr = 0.0005
I0403 03:07:02.061321 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1272.caffemodel
I0403 03:07:04.897553 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1272.solverstate
I0403 03:07:06.806545 28786 solver.cpp:337] Iteration 1272, Testing net (#0)
I0403 03:08:45.987352 28786 solver.cpp:404]     Test net output #0: accuracy = 0.969245
I0403 03:08:45.993665 28786 solver.cpp:404]     Test net output #1: loss = 0.116906 (* 1 = 0.116906 loss)
I0403 03:08:48.824224 28786 solver.cpp:228] Iteration 1275, loss = 0.0239618
I0403 03:08:48.830142 28786 solver.cpp:244]     Train net output #0: loss = 0.0239618 (* 1 = 0.0239618 loss)
I0403 03:08:49.008743 28786 sgd_solver.cpp:106] Iteration 1275, lr = 0.0005
I0403 03:08:52.465704 28786 solver.cpp:228] Iteration 1280, loss = 0.00557019
I0403 03:08:52.471949 28786 solver.cpp:244]     Train net output #0: loss = 0.00557021 (* 1 = 0.00557021 loss)
I0403 03:08:52.655622 28786 sgd_solver.cpp:106] Iteration 1280, lr = 0.0005
I0403 03:08:56.202355 28786 solver.cpp:228] Iteration 1285, loss = 0.0106804
I0403 03:08:56.208438 28786 solver.cpp:244]     Train net output #0: loss = 0.0106804 (* 1 = 0.0106804 loss)
I0403 03:08:56.380765 28786 sgd_solver.cpp:106] Iteration 1285, lr = 0.0005
I0403 03:08:59.853600 28786 solver.cpp:228] Iteration 1290, loss = 0.00663324
I0403 03:08:59.859083 28786 solver.cpp:244]     Train net output #0: loss = 0.00663326 (* 1 = 0.00663326 loss)
I0403 03:09:00.067893 28786 sgd_solver.cpp:106] Iteration 1290, lr = 0.0005
I0403 03:09:03.522037 28786 solver.cpp:228] Iteration 1295, loss = 0.0005478
I0403 03:09:03.528745 28786 solver.cpp:244]     Train net output #0: loss = 0.000547813 (* 1 = 0.000547813 loss)
I0403 03:09:03.743330 28786 sgd_solver.cpp:106] Iteration 1295, lr = 0.0005
I0403 03:09:07.191088 28786 solver.cpp:228] Iteration 1300, loss = 0.00147066
I0403 03:09:07.196871 28786 solver.cpp:244]     Train net output #0: loss = 0.00147067 (* 1 = 0.00147067 loss)
I0403 03:09:07.388568 28786 sgd_solver.cpp:106] Iteration 1300, lr = 0.0005
I0403 03:09:10.808450 28786 solver.cpp:228] Iteration 1305, loss = 0.00200425
I0403 03:09:10.813709 28786 solver.cpp:244]     Train net output #0: loss = 0.00200426 (* 1 = 0.00200426 loss)
I0403 03:09:10.993820 28786 sgd_solver.cpp:106] Iteration 1305, lr = 0.0005
I0403 03:09:14.404708 28786 solver.cpp:228] Iteration 1310, loss = 0.000932071
I0403 03:09:14.411415 28786 solver.cpp:244]     Train net output #0: loss = 0.000932085 (* 1 = 0.000932085 loss)
I0403 03:09:14.622426 28786 sgd_solver.cpp:106] Iteration 1310, lr = 0.0005
I0403 03:09:18.030297 28786 solver.cpp:228] Iteration 1315, loss = 0.000829649
I0403 03:09:18.035100 28786 solver.cpp:244]     Train net output #0: loss = 0.000829663 (* 1 = 0.000829663 loss)
I0403 03:09:18.209300 28786 sgd_solver.cpp:106] Iteration 1315, lr = 0.0005
I0403 03:09:21.726032 28786 solver.cpp:228] Iteration 1320, loss = 0.0334664
I0403 03:09:21.731478 28786 solver.cpp:244]     Train net output #0: loss = 0.0334664 (* 1 = 0.0334664 loss)
I0403 03:09:21.882315 28786 sgd_solver.cpp:106] Iteration 1320, lr = 0.0005
I0403 03:09:25.415647 28786 solver.cpp:228] Iteration 1325, loss = 0.000148301
I0403 03:09:25.422309 28786 solver.cpp:244]     Train net output #0: loss = 0.000148316 (* 1 = 0.000148316 loss)
I0403 03:09:25.607681 28786 sgd_solver.cpp:106] Iteration 1325, lr = 0.0005
I0403 03:09:29.138149 28786 solver.cpp:228] Iteration 1330, loss = 0.00201538
I0403 03:09:29.144008 28786 solver.cpp:244]     Train net output #0: loss = 0.00201539 (* 1 = 0.00201539 loss)
I0403 03:09:29.290609 28786 sgd_solver.cpp:106] Iteration 1330, lr = 0.0005
I0403 03:09:32.814116 28786 solver.cpp:228] Iteration 1335, loss = 0.00192002
I0403 03:09:32.820364 28786 solver.cpp:244]     Train net output #0: loss = 0.00192003 (* 1 = 0.00192003 loss)
I0403 03:09:33.014762 28786 sgd_solver.cpp:106] Iteration 1335, lr = 0.0005
I0403 03:09:36.401160 28786 solver.cpp:228] Iteration 1340, loss = 0.00279924
I0403 03:09:36.407080 28786 solver.cpp:244]     Train net output #0: loss = 0.00279925 (* 1 = 0.00279925 loss)
I0403 03:09:36.600843 28786 sgd_solver.cpp:106] Iteration 1340, lr = 0.0005
I0403 03:09:40.114799 28786 solver.cpp:228] Iteration 1345, loss = 0.00777854
I0403 03:09:40.121220 28786 solver.cpp:244]     Train net output #0: loss = 0.00777855 (* 1 = 0.00777855 loss)
I0403 03:09:40.355587 28786 sgd_solver.cpp:106] Iteration 1345, lr = 0.0005
I0403 03:09:43.777987 28786 solver.cpp:228] Iteration 1350, loss = 0.000837712
I0403 03:09:43.784476 28786 solver.cpp:244]     Train net output #0: loss = 0.000837727 (* 1 = 0.000837727 loss)
I0403 03:09:43.965081 28786 sgd_solver.cpp:106] Iteration 1350, lr = 0.0005
I0403 03:09:47.458297 28786 solver.cpp:228] Iteration 1355, loss = 0.00278435
I0403 03:09:47.463946 28786 solver.cpp:244]     Train net output #0: loss = 0.00278437 (* 1 = 0.00278437 loss)
I0403 03:09:47.632586 28786 sgd_solver.cpp:106] Iteration 1355, lr = 0.0005
I0403 03:09:51.161336 28786 solver.cpp:228] Iteration 1360, loss = 0.00409137
I0403 03:09:51.167757 28786 solver.cpp:244]     Train net output #0: loss = 0.00409138 (* 1 = 0.00409138 loss)
I0403 03:09:51.313326 28786 sgd_solver.cpp:106] Iteration 1360, lr = 0.0005
I0403 03:09:54.940007 28786 solver.cpp:228] Iteration 1365, loss = 0.00855131
I0403 03:09:54.947216 28786 solver.cpp:244]     Train net output #0: loss = 0.00855133 (* 1 = 0.00855133 loss)
I0403 03:09:55.158392 28786 sgd_solver.cpp:106] Iteration 1365, lr = 0.0005
I0403 03:09:58.575139 28786 solver.cpp:228] Iteration 1370, loss = 0.00398414
I0403 03:09:58.590204 28786 solver.cpp:244]     Train net output #0: loss = 0.00398416 (* 1 = 0.00398416 loss)
I0403 03:09:58.755861 28786 sgd_solver.cpp:106] Iteration 1370, lr = 0.0005
I0403 03:10:02.228826 28786 solver.cpp:228] Iteration 1375, loss = 0.000330057
I0403 03:10:02.235385 28786 solver.cpp:244]     Train net output #0: loss = 0.000330072 (* 1 = 0.000330072 loss)
I0403 03:10:02.392470 28786 sgd_solver.cpp:106] Iteration 1375, lr = 0.0005
I0403 03:10:03.884655 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1378.caffemodel
I0403 03:10:06.649626 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1378.solverstate
I0403 03:10:08.569653 28786 solver.cpp:337] Iteration 1378, Testing net (#0)
I0403 03:11:47.777053 28786 solver.cpp:404]     Test net output #0: accuracy = 0.970941
I0403 03:11:47.784764 28786 solver.cpp:404]     Test net output #1: loss = 0.111501 (* 1 = 0.111501 loss)
I0403 03:11:49.743232 28786 solver.cpp:228] Iteration 1380, loss = 0.000154146
I0403 03:11:49.749241 28786 solver.cpp:244]     Train net output #0: loss = 0.000154162 (* 1 = 0.000154162 loss)
I0403 03:11:49.945274 28786 sgd_solver.cpp:106] Iteration 1380, lr = 0.0005
I0403 03:11:53.392051 28786 solver.cpp:228] Iteration 1385, loss = 0.00155122
I0403 03:11:53.398334 28786 solver.cpp:244]     Train net output #0: loss = 0.00155124 (* 1 = 0.00155124 loss)
I0403 03:11:53.572254 28786 sgd_solver.cpp:106] Iteration 1385, lr = 0.0005
I0403 03:11:57.076268 28786 solver.cpp:228] Iteration 1390, loss = 0.000394108
I0403 03:11:57.080987 28786 solver.cpp:244]     Train net output #0: loss = 0.000394125 (* 1 = 0.000394125 loss)
I0403 03:11:57.252012 28786 sgd_solver.cpp:106] Iteration 1390, lr = 0.0005
I0403 03:12:00.790318 28786 solver.cpp:228] Iteration 1395, loss = 0.000537774
I0403 03:12:00.796814 28786 solver.cpp:244]     Train net output #0: loss = 0.000537791 (* 1 = 0.000537791 loss)
I0403 03:12:00.970057 28786 sgd_solver.cpp:106] Iteration 1395, lr = 0.0005
I0403 03:12:04.416661 28786 solver.cpp:228] Iteration 1400, loss = 0.00239564
I0403 03:12:04.422050 28786 solver.cpp:244]     Train net output #0: loss = 0.00239566 (* 1 = 0.00239566 loss)
I0403 03:12:04.596741 28786 sgd_solver.cpp:106] Iteration 1400, lr = 0.0005
I0403 03:12:08.032699 28786 solver.cpp:228] Iteration 1405, loss = 0.000245661
I0403 03:12:08.037703 28786 solver.cpp:244]     Train net output #0: loss = 0.000245678 (* 1 = 0.000245678 loss)
I0403 03:12:08.307448 28786 sgd_solver.cpp:106] Iteration 1405, lr = 0.0005
I0403 03:12:11.718824 28786 solver.cpp:228] Iteration 1410, loss = 0.00222651
I0403 03:12:11.725508 28786 solver.cpp:244]     Train net output #0: loss = 0.00222653 (* 1 = 0.00222653 loss)
I0403 03:12:11.907456 28786 sgd_solver.cpp:106] Iteration 1410, lr = 0.0005
I0403 03:12:15.331670 28786 solver.cpp:228] Iteration 1415, loss = 0.0015515
I0403 03:12:15.339001 28786 solver.cpp:244]     Train net output #0: loss = 0.00155152 (* 1 = 0.00155152 loss)
I0403 03:12:15.555418 28786 sgd_solver.cpp:106] Iteration 1415, lr = 0.0005
I0403 03:12:18.957923 28786 solver.cpp:228] Iteration 1420, loss = 0.00146741
I0403 03:12:18.964578 28786 solver.cpp:244]     Train net output #0: loss = 0.00146743 (* 1 = 0.00146743 loss)
I0403 03:12:19.217865 28786 sgd_solver.cpp:106] Iteration 1420, lr = 0.0005
I0403 03:12:22.716889 28786 solver.cpp:228] Iteration 1425, loss = 0.000780268
I0403 03:12:22.722414 28786 solver.cpp:244]     Train net output #0: loss = 0.000780284 (* 1 = 0.000780284 loss)
I0403 03:12:22.927902 28786 sgd_solver.cpp:106] Iteration 1425, lr = 0.0005
I0403 03:12:26.461673 28786 solver.cpp:228] Iteration 1430, loss = 0.00339749
I0403 03:12:26.468228 28786 solver.cpp:244]     Train net output #0: loss = 0.00339751 (* 1 = 0.00339751 loss)
I0403 03:12:26.657805 28786 sgd_solver.cpp:106] Iteration 1430, lr = 0.0005
I0403 03:12:30.117439 28786 solver.cpp:228] Iteration 1435, loss = 0.00145701
I0403 03:12:30.123056 28786 solver.cpp:244]     Train net output #0: loss = 0.00145703 (* 1 = 0.00145703 loss)
I0403 03:12:30.309070 28786 sgd_solver.cpp:106] Iteration 1435, lr = 0.0005
I0403 03:12:33.773088 28786 solver.cpp:228] Iteration 1440, loss = 0.00152199
I0403 03:12:33.779373 28786 solver.cpp:244]     Train net output #0: loss = 0.00152201 (* 1 = 0.00152201 loss)
I0403 03:12:33.985716 28786 sgd_solver.cpp:106] Iteration 1440, lr = 0.0005
I0403 03:12:37.456064 28786 solver.cpp:228] Iteration 1445, loss = 0.00132537
I0403 03:12:37.462932 28786 solver.cpp:244]     Train net output #0: loss = 0.00132538 (* 1 = 0.00132538 loss)
I0403 03:12:37.632401 28786 sgd_solver.cpp:106] Iteration 1445, lr = 0.0005
I0403 03:12:41.077296 28786 solver.cpp:228] Iteration 1450, loss = 0.000593659
I0403 03:12:41.083952 28786 solver.cpp:244]     Train net output #0: loss = 0.000593676 (* 1 = 0.000593676 loss)
I0403 03:12:41.281587 28786 sgd_solver.cpp:106] Iteration 1450, lr = 0.0005
I0403 03:12:44.706713 28786 solver.cpp:228] Iteration 1455, loss = 0.00482855
I0403 03:12:44.713259 28786 solver.cpp:244]     Train net output #0: loss = 0.00482857 (* 1 = 0.00482857 loss)
I0403 03:12:44.881554 28786 sgd_solver.cpp:106] Iteration 1455, lr = 0.0005
I0403 03:12:48.453553 28786 solver.cpp:228] Iteration 1460, loss = 0.00246486
I0403 03:12:48.459206 28786 solver.cpp:244]     Train net output #0: loss = 0.00246488 (* 1 = 0.00246488 loss)
I0403 03:12:48.623229 28786 sgd_solver.cpp:106] Iteration 1460, lr = 0.0005
I0403 03:12:52.123608 28786 solver.cpp:228] Iteration 1465, loss = 0.000356867
I0403 03:12:52.128723 28786 solver.cpp:244]     Train net output #0: loss = 0.000356885 (* 1 = 0.000356885 loss)
I0403 03:12:52.294446 28786 sgd_solver.cpp:106] Iteration 1465, lr = 0.0005
I0403 03:12:55.756464 28786 solver.cpp:228] Iteration 1470, loss = 0.0228022
I0403 03:12:55.762300 28786 solver.cpp:244]     Train net output #0: loss = 0.0228022 (* 1 = 0.0228022 loss)
I0403 03:12:55.935550 28786 sgd_solver.cpp:106] Iteration 1470, lr = 0.0005
I0403 03:12:59.452371 28786 solver.cpp:228] Iteration 1475, loss = 0.000686827
I0403 03:12:59.458379 28786 solver.cpp:244]     Train net output #0: loss = 0.000686843 (* 1 = 0.000686843 loss)
I0403 03:12:59.620564 28786 sgd_solver.cpp:106] Iteration 1475, lr = 0.0005
I0403 03:13:03.211217 28786 solver.cpp:228] Iteration 1480, loss = 0.00282916
I0403 03:13:03.217350 28786 solver.cpp:244]     Train net output #0: loss = 0.00282918 (* 1 = 0.00282918 loss)
I0403 03:13:03.368712 28786 sgd_solver.cpp:106] Iteration 1480, lr = 0.0005
I0403 03:13:05.612061 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1484.caffemodel
I0403 03:13:08.238814 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1484.solverstate
I0403 03:13:10.027956 28786 solver.cpp:337] Iteration 1484, Testing net (#0)
I0403 03:14:49.219393 28786 solver.cpp:404]     Test net output #0: accuracy = 0.971767
I0403 03:14:49.246127 28786 solver.cpp:404]     Test net output #1: loss = 0.110388 (* 1 = 0.110388 loss)
I0403 03:14:50.504413 28786 solver.cpp:228] Iteration 1485, loss = 0.00010404
I0403 03:14:50.531265 28786 solver.cpp:244]     Train net output #0: loss = 0.000104058 (* 1 = 0.000104058 loss)
I0403 03:14:50.686980 28786 sgd_solver.cpp:106] Iteration 1485, lr = 0.0005
I0403 03:14:54.094211 28786 solver.cpp:228] Iteration 1490, loss = 0.00137478
I0403 03:14:54.099494 28786 solver.cpp:244]     Train net output #0: loss = 0.0013748 (* 1 = 0.0013748 loss)
I0403 03:14:54.274885 28786 sgd_solver.cpp:106] Iteration 1490, lr = 0.0005
I0403 03:14:57.715538 28786 solver.cpp:228] Iteration 1495, loss = 0.00470628
I0403 03:14:57.722144 28786 solver.cpp:244]     Train net output #0: loss = 0.0047063 (* 1 = 0.0047063 loss)
I0403 03:14:57.915554 28786 sgd_solver.cpp:106] Iteration 1495, lr = 0.0005
I0403 03:15:01.333868 28786 solver.cpp:228] Iteration 1500, loss = 0.000491651
I0403 03:15:01.340030 28786 solver.cpp:244]     Train net output #0: loss = 0.000491669 (* 1 = 0.000491669 loss)
I0403 03:15:01.515223 28786 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0403 03:15:04.941772 28786 solver.cpp:228] Iteration 1505, loss = 0.00584921
I0403 03:15:04.948771 28786 solver.cpp:244]     Train net output #0: loss = 0.00584923 (* 1 = 0.00584923 loss)
I0403 03:15:05.127080 28786 sgd_solver.cpp:106] Iteration 1505, lr = 0.0005
I0403 03:15:08.597967 28786 solver.cpp:228] Iteration 1510, loss = 0.00185424
I0403 03:15:08.603744 28786 solver.cpp:244]     Train net output #0: loss = 0.00185425 (* 1 = 0.00185425 loss)
I0403 03:15:08.783530 28786 sgd_solver.cpp:106] Iteration 1510, lr = 0.0005
I0403 03:15:12.196754 28786 solver.cpp:228] Iteration 1515, loss = 0.00519488
I0403 03:15:12.203325 28786 solver.cpp:244]     Train net output #0: loss = 0.0051949 (* 1 = 0.0051949 loss)
I0403 03:15:12.379551 28786 sgd_solver.cpp:106] Iteration 1515, lr = 0.0005
I0403 03:15:15.827467 28786 solver.cpp:228] Iteration 1520, loss = 0.00212729
I0403 03:15:15.833019 28786 solver.cpp:244]     Train net output #0: loss = 0.00212731 (* 1 = 0.00212731 loss)
I0403 03:15:16.014081 28786 sgd_solver.cpp:106] Iteration 1520, lr = 0.0005
I0403 03:15:19.446522 28786 solver.cpp:228] Iteration 1525, loss = 0.00316971
I0403 03:15:19.453070 28786 solver.cpp:244]     Train net output #0: loss = 0.00316973 (* 1 = 0.00316973 loss)
I0403 03:15:19.625311 28786 sgd_solver.cpp:106] Iteration 1525, lr = 0.0005
I0403 03:15:23.058480 28786 solver.cpp:228] Iteration 1530, loss = 0.000532147
I0403 03:15:23.064349 28786 solver.cpp:244]     Train net output #0: loss = 0.000532164 (* 1 = 0.000532164 loss)
I0403 03:15:23.235231 28786 sgd_solver.cpp:106] Iteration 1530, lr = 0.0005
I0403 03:15:26.668812 28786 solver.cpp:228] Iteration 1535, loss = 8.65022e-05
I0403 03:15:26.674945 28786 solver.cpp:244]     Train net output #0: loss = 8.65201e-05 (* 1 = 8.65201e-05 loss)
I0403 03:15:26.887842 28786 sgd_solver.cpp:106] Iteration 1535, lr = 0.0005
I0403 03:15:30.362390 28786 solver.cpp:228] Iteration 1540, loss = 0.0193159
I0403 03:15:30.370343 28786 solver.cpp:244]     Train net output #0: loss = 0.0193159 (* 1 = 0.0193159 loss)
I0403 03:15:30.580606 28786 sgd_solver.cpp:106] Iteration 1540, lr = 0.0005
I0403 03:15:34.100219 28786 solver.cpp:228] Iteration 1545, loss = 0.000409153
I0403 03:15:34.106992 28786 solver.cpp:244]     Train net output #0: loss = 0.000409172 (* 1 = 0.000409172 loss)
I0403 03:15:34.282630 28786 sgd_solver.cpp:106] Iteration 1545, lr = 0.0005
I0403 03:15:37.766739 28786 solver.cpp:228] Iteration 1550, loss = 0.000264799
I0403 03:15:37.771951 28786 solver.cpp:244]     Train net output #0: loss = 0.000264817 (* 1 = 0.000264817 loss)
I0403 03:15:37.930938 28786 sgd_solver.cpp:106] Iteration 1550, lr = 0.0005
I0403 03:15:41.530673 28786 solver.cpp:228] Iteration 1555, loss = 7.61679e-05
I0403 03:15:41.536978 28786 solver.cpp:244]     Train net output #0: loss = 7.61858e-05 (* 1 = 7.61858e-05 loss)
I0403 03:15:41.729780 28786 sgd_solver.cpp:106] Iteration 1555, lr = 0.0005
I0403 03:15:45.207130 28786 solver.cpp:228] Iteration 1560, loss = 0.00352687
I0403 03:15:45.212822 28786 solver.cpp:244]     Train net output #0: loss = 0.00352689 (* 1 = 0.00352689 loss)
I0403 03:15:45.408730 28786 sgd_solver.cpp:106] Iteration 1560, lr = 0.0005
I0403 03:15:48.865242 28786 solver.cpp:228] Iteration 1565, loss = 0.00131679
I0403 03:15:48.872146 28786 solver.cpp:244]     Train net output #0: loss = 0.00131681 (* 1 = 0.00131681 loss)
I0403 03:15:49.048046 28786 sgd_solver.cpp:106] Iteration 1565, lr = 0.0005
I0403 03:15:52.482550 28786 solver.cpp:228] Iteration 1570, loss = 0.000307766
I0403 03:15:52.489333 28786 solver.cpp:244]     Train net output #0: loss = 0.000307785 (* 1 = 0.000307785 loss)
I0403 03:15:52.657652 28786 sgd_solver.cpp:106] Iteration 1570, lr = 0.0005
I0403 03:15:56.238682 28786 solver.cpp:228] Iteration 1575, loss = 0.00334195
I0403 03:15:56.243927 28786 solver.cpp:244]     Train net output #0: loss = 0.00334197 (* 1 = 0.00334197 loss)
I0403 03:15:56.364816 28786 sgd_solver.cpp:106] Iteration 1575, lr = 0.0005
I0403 03:15:59.897853 28786 solver.cpp:228] Iteration 1580, loss = 0.00120735
I0403 03:15:59.903656 28786 solver.cpp:244]     Train net output #0: loss = 0.00120736 (* 1 = 0.00120736 loss)
I0403 03:16:00.124498 28786 sgd_solver.cpp:106] Iteration 1580, lr = 0.0005
I0403 03:16:03.535261 28786 solver.cpp:228] Iteration 1585, loss = 0.000334775
I0403 03:16:03.541620 28786 solver.cpp:244]     Train net output #0: loss = 0.000334793 (* 1 = 0.000334793 loss)
I0403 03:16:03.723245 28786 sgd_solver.cpp:106] Iteration 1585, lr = 0.0005
I0403 03:16:06.603821 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1590.caffemodel
I0403 03:16:09.231071 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1590.solverstate
I0403 03:16:11.049706 28786 solver.cpp:337] Iteration 1590, Testing net (#0)
I0403 03:17:50.243367 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972134
I0403 03:17:50.251032 28786 solver.cpp:404]     Test net output #1: loss = 0.10878 (* 1 = 0.10878 loss)
I0403 03:17:50.794766 28786 solver.cpp:228] Iteration 1590, loss = 0.00375153
I0403 03:17:50.801180 28786 solver.cpp:244]     Train net output #0: loss = 0.00375155 (* 1 = 0.00375155 loss)
I0403 03:17:50.952250 28786 sgd_solver.cpp:106] Iteration 1590, lr = 0.0005
I0403 03:17:54.479743 28786 solver.cpp:228] Iteration 1595, loss = 0.0017084
I0403 03:17:54.486734 28786 solver.cpp:244]     Train net output #0: loss = 0.00170842 (* 1 = 0.00170842 loss)
I0403 03:17:54.692370 28786 sgd_solver.cpp:106] Iteration 1595, lr = 0.0005
I0403 03:17:58.133180 28786 solver.cpp:228] Iteration 1600, loss = 0.00799333
I0403 03:17:58.138017 28786 solver.cpp:244]     Train net output #0: loss = 0.00799335 (* 1 = 0.00799335 loss)
I0403 03:17:58.347549 28786 sgd_solver.cpp:106] Iteration 1600, lr = 0.0005
I0403 03:18:01.810921 28786 solver.cpp:228] Iteration 1605, loss = 0.00287792
I0403 03:18:01.816295 28786 solver.cpp:244]     Train net output #0: loss = 0.00287793 (* 1 = 0.00287793 loss)
I0403 03:18:01.994324 28786 sgd_solver.cpp:106] Iteration 1605, lr = 0.0005
I0403 03:18:05.461390 28786 solver.cpp:228] Iteration 1610, loss = 0.00494125
I0403 03:18:05.467586 28786 solver.cpp:244]     Train net output #0: loss = 0.00494127 (* 1 = 0.00494127 loss)
I0403 03:18:05.639650 28786 sgd_solver.cpp:106] Iteration 1610, lr = 0.0005
I0403 03:18:09.150810 28786 solver.cpp:228] Iteration 1615, loss = 0.000788266
I0403 03:18:09.157301 28786 solver.cpp:244]     Train net output #0: loss = 0.000788284 (* 1 = 0.000788284 loss)
I0403 03:18:09.330096 28786 sgd_solver.cpp:106] Iteration 1615, lr = 0.0005
I0403 03:18:12.822063 28786 solver.cpp:228] Iteration 1620, loss = 0.00105113
I0403 03:18:12.827924 28786 solver.cpp:244]     Train net output #0: loss = 0.00105114 (* 1 = 0.00105114 loss)
I0403 03:18:13.000180 28786 sgd_solver.cpp:106] Iteration 1620, lr = 0.0005
I0403 03:18:16.417201 28786 solver.cpp:228] Iteration 1625, loss = 0.0025435
I0403 03:18:16.422992 28786 solver.cpp:244]     Train net output #0: loss = 0.00254352 (* 1 = 0.00254352 loss)
I0403 03:18:16.604722 28786 sgd_solver.cpp:106] Iteration 1625, lr = 0.0005
I0403 03:18:20.059077 28786 solver.cpp:228] Iteration 1630, loss = 0.000548183
I0403 03:18:20.065292 28786 solver.cpp:244]     Train net output #0: loss = 0.000548201 (* 1 = 0.000548201 loss)
I0403 03:18:20.210620 28786 sgd_solver.cpp:106] Iteration 1630, lr = 0.0005
I0403 03:18:23.761068 28786 solver.cpp:228] Iteration 1635, loss = 0.00246956
I0403 03:18:23.768060 28786 solver.cpp:244]     Train net output #0: loss = 0.00246958 (* 1 = 0.00246958 loss)
I0403 03:18:23.957494 28786 sgd_solver.cpp:106] Iteration 1635, lr = 0.0005
I0403 03:18:27.527317 28786 solver.cpp:228] Iteration 1640, loss = 0.000460033
I0403 03:18:27.533838 28786 solver.cpp:244]     Train net output #0: loss = 0.000460051 (* 1 = 0.000460051 loss)
I0403 03:18:27.722282 28786 sgd_solver.cpp:106] Iteration 1640, lr = 0.0005
I0403 03:18:31.171897 28786 solver.cpp:228] Iteration 1645, loss = 0.000334861
I0403 03:18:31.177680 28786 solver.cpp:244]     Train net output #0: loss = 0.000334879 (* 1 = 0.000334879 loss)
I0403 03:18:31.354291 28786 sgd_solver.cpp:106] Iteration 1645, lr = 0.0005
I0403 03:18:34.930208 28786 solver.cpp:228] Iteration 1650, loss = 0.0019395
I0403 03:18:34.936986 28786 solver.cpp:244]     Train net output #0: loss = 0.00193952 (* 1 = 0.00193952 loss)
I0403 03:18:35.142063 28786 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I0403 03:18:38.589179 28786 solver.cpp:228] Iteration 1655, loss = 0.000209456
I0403 03:18:38.595809 28786 solver.cpp:244]     Train net output #0: loss = 0.000209475 (* 1 = 0.000209475 loss)
I0403 03:18:38.787524 28786 sgd_solver.cpp:106] Iteration 1655, lr = 0.0005
I0403 03:18:42.183624 28786 solver.cpp:228] Iteration 1660, loss = 0.000941812
I0403 03:18:42.188565 28786 solver.cpp:244]     Train net output #0: loss = 0.000941831 (* 1 = 0.000941831 loss)
I0403 03:18:42.417284 28786 sgd_solver.cpp:106] Iteration 1660, lr = 0.0005
I0403 03:18:45.931867 28786 solver.cpp:228] Iteration 1665, loss = 0.0187688
I0403 03:18:45.937144 28786 solver.cpp:244]     Train net output #0: loss = 0.0187688 (* 1 = 0.0187688 loss)
I0403 03:18:46.136170 28786 sgd_solver.cpp:106] Iteration 1665, lr = 0.0005
I0403 03:18:49.601497 28786 solver.cpp:228] Iteration 1670, loss = 0.00814469
I0403 03:18:49.608386 28786 solver.cpp:244]     Train net output #0: loss = 0.00814471 (* 1 = 0.00814471 loss)
I0403 03:18:49.800722 28786 sgd_solver.cpp:106] Iteration 1670, lr = 0.0005
I0403 03:18:53.292846 28786 solver.cpp:228] Iteration 1675, loss = 0.0183847
I0403 03:18:53.299195 28786 solver.cpp:244]     Train net output #0: loss = 0.0183848 (* 1 = 0.0183848 loss)
I0403 03:18:53.470582 28786 sgd_solver.cpp:106] Iteration 1675, lr = 0.0005
I0403 03:18:56.898154 28786 solver.cpp:228] Iteration 1680, loss = 0.000667568
I0403 03:18:56.904048 28786 solver.cpp:244]     Train net output #0: loss = 0.000667585 (* 1 = 0.000667585 loss)
I0403 03:18:57.121539 28786 sgd_solver.cpp:106] Iteration 1680, lr = 0.0005
I0403 03:19:00.660517 28786 solver.cpp:228] Iteration 1685, loss = 0.000566646
I0403 03:19:00.666537 28786 solver.cpp:244]     Train net output #0: loss = 0.000566661 (* 1 = 0.000566661 loss)
I0403 03:19:00.851092 28786 sgd_solver.cpp:106] Iteration 1685, lr = 0.0005
I0403 03:19:04.281780 28786 solver.cpp:228] Iteration 1690, loss = 0.000356047
I0403 03:19:04.288314 28786 solver.cpp:244]     Train net output #0: loss = 0.000356062 (* 1 = 0.000356062 loss)
I0403 03:19:04.482269 28786 sgd_solver.cpp:106] Iteration 1690, lr = 0.0005
I0403 03:19:07.945317 28786 solver.cpp:228] Iteration 1695, loss = 0.000147779
I0403 03:19:07.951887 28786 solver.cpp:244]     Train net output #0: loss = 0.000147794 (* 1 = 0.000147794 loss)
I0403 03:19:08.140801 28786 sgd_solver.cpp:106] Iteration 1695, lr = 0.0005
I0403 03:19:08.141033 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1696.caffemodel
I0403 03:19:10.898911 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1696.solverstate
I0403 03:19:12.807986 28786 solver.cpp:337] Iteration 1696, Testing net (#0)
I0403 03:20:51.986232 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972157
I0403 03:20:51.993178 28786 solver.cpp:404]     Test net output #1: loss = 0.110216 (* 1 = 0.110216 loss)
I0403 03:20:55.515318 28786 solver.cpp:228] Iteration 1700, loss = 0.000892829
I0403 03:20:55.522410 28786 solver.cpp:244]     Train net output #0: loss = 0.000892844 (* 1 = 0.000892844 loss)
I0403 03:20:55.694903 28786 sgd_solver.cpp:106] Iteration 1700, lr = 0.0005
I0403 03:20:59.140432 28786 solver.cpp:228] Iteration 1705, loss = 0.00160885
I0403 03:20:59.145292 28786 solver.cpp:244]     Train net output #0: loss = 0.00160887 (* 1 = 0.00160887 loss)
I0403 03:20:59.368427 28786 sgd_solver.cpp:106] Iteration 1705, lr = 0.0005
I0403 03:21:02.996042 28786 solver.cpp:228] Iteration 1710, loss = 8.81115e-05
I0403 03:21:03.003213 28786 solver.cpp:244]     Train net output #0: loss = 8.81274e-05 (* 1 = 8.81274e-05 loss)
I0403 03:21:03.163393 28786 sgd_solver.cpp:106] Iteration 1710, lr = 0.0005
I0403 03:21:06.710242 28786 solver.cpp:228] Iteration 1715, loss = 0.00233049
I0403 03:21:06.715486 28786 solver.cpp:244]     Train net output #0: loss = 0.0023305 (* 1 = 0.0023305 loss)
I0403 03:21:06.889225 28786 sgd_solver.cpp:106] Iteration 1715, lr = 0.0005
I0403 03:21:10.434566 28786 solver.cpp:228] Iteration 1720, loss = 0.00219519
I0403 03:21:10.440960 28786 solver.cpp:244]     Train net output #0: loss = 0.0021952 (* 1 = 0.0021952 loss)
I0403 03:21:10.576283 28786 sgd_solver.cpp:106] Iteration 1720, lr = 0.0005
I0403 03:21:14.094440 28786 solver.cpp:228] Iteration 1725, loss = 0.00479882
I0403 03:21:14.100708 28786 solver.cpp:244]     Train net output #0: loss = 0.00479883 (* 1 = 0.00479883 loss)
I0403 03:21:14.290474 28786 sgd_solver.cpp:106] Iteration 1725, lr = 0.0005
I0403 03:21:17.741988 28786 solver.cpp:228] Iteration 1730, loss = 0.00433917
I0403 03:21:17.748250 28786 solver.cpp:244]     Train net output #0: loss = 0.00433918 (* 1 = 0.00433918 loss)
I0403 03:21:17.930932 28786 sgd_solver.cpp:106] Iteration 1730, lr = 0.0005
I0403 03:21:21.407438 28786 solver.cpp:228] Iteration 1735, loss = 0.00108058
I0403 03:21:21.414141 28786 solver.cpp:244]     Train net output #0: loss = 0.00108059 (* 1 = 0.00108059 loss)
I0403 03:21:21.592007 28786 sgd_solver.cpp:106] Iteration 1735, lr = 0.0005
I0403 03:21:25.066452 28786 solver.cpp:228] Iteration 1740, loss = 0.00596581
I0403 03:21:25.072088 28786 solver.cpp:244]     Train net output #0: loss = 0.00596582 (* 1 = 0.00596582 loss)
I0403 03:21:25.237254 28786 sgd_solver.cpp:106] Iteration 1740, lr = 0.0005
I0403 03:21:28.757381 28786 solver.cpp:228] Iteration 1745, loss = 0.00362278
I0403 03:21:28.764797 28786 solver.cpp:244]     Train net output #0: loss = 0.00362279 (* 1 = 0.00362279 loss)
I0403 03:21:28.949722 28786 sgd_solver.cpp:106] Iteration 1745, lr = 0.0005
I0403 03:21:32.370780 28786 solver.cpp:228] Iteration 1750, loss = 0.000808351
I0403 03:21:32.376888 28786 solver.cpp:244]     Train net output #0: loss = 0.00080836 (* 1 = 0.00080836 loss)
I0403 03:21:32.551805 28786 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I0403 03:21:36.044225 28786 solver.cpp:228] Iteration 1755, loss = 0.000141716
I0403 03:21:36.050798 28786 solver.cpp:244]     Train net output #0: loss = 0.000141726 (* 1 = 0.000141726 loss)
I0403 03:21:36.233157 28786 sgd_solver.cpp:106] Iteration 1755, lr = 0.0005
I0403 03:21:39.807237 28786 solver.cpp:228] Iteration 1760, loss = 0.00648577
I0403 03:21:39.813755 28786 solver.cpp:244]     Train net output #0: loss = 0.00648578 (* 1 = 0.00648578 loss)
I0403 03:21:39.981397 28786 sgd_solver.cpp:106] Iteration 1760, lr = 0.0005
I0403 03:21:43.446101 28786 solver.cpp:228] Iteration 1765, loss = 0.00442196
I0403 03:21:43.452074 28786 solver.cpp:244]     Train net output #0: loss = 0.00442197 (* 1 = 0.00442197 loss)
I0403 03:21:43.635087 28786 sgd_solver.cpp:106] Iteration 1765, lr = 0.0005
I0403 03:21:47.137114 28786 solver.cpp:228] Iteration 1770, loss = 0.00118155
I0403 03:21:47.141824 28786 solver.cpp:244]     Train net output #0: loss = 0.00118156 (* 1 = 0.00118156 loss)
I0403 03:21:47.317733 28786 sgd_solver.cpp:106] Iteration 1770, lr = 0.0005
I0403 03:21:50.791285 28786 solver.cpp:228] Iteration 1775, loss = 0.00012988
I0403 03:21:50.798936 28786 solver.cpp:244]     Train net output #0: loss = 0.000129891 (* 1 = 0.000129891 loss)
I0403 03:21:50.949440 28786 sgd_solver.cpp:106] Iteration 1775, lr = 0.0005
I0403 03:21:54.494964 28786 solver.cpp:228] Iteration 1780, loss = 9.99454e-05
I0403 03:21:54.503283 28786 solver.cpp:244]     Train net output #0: loss = 9.99555e-05 (* 1 = 9.99555e-05 loss)
I0403 03:21:54.692962 28786 sgd_solver.cpp:106] Iteration 1780, lr = 0.0005
I0403 03:21:58.162438 28786 solver.cpp:228] Iteration 1785, loss = 0.00092302
I0403 03:21:58.169129 28786 solver.cpp:244]     Train net output #0: loss = 0.00092303 (* 1 = 0.00092303 loss)
I0403 03:21:58.350834 28786 sgd_solver.cpp:106] Iteration 1785, lr = 0.0005
I0403 03:22:01.763348 28786 solver.cpp:228] Iteration 1790, loss = 0.0045245
I0403 03:22:01.771769 28786 solver.cpp:244]     Train net output #0: loss = 0.00452451 (* 1 = 0.00452451 loss)
I0403 03:22:01.971035 28786 sgd_solver.cpp:106] Iteration 1790, lr = 0.0005
I0403 03:22:05.708624 28786 solver.cpp:228] Iteration 1795, loss = 0.000323895
I0403 03:22:05.715453 28786 solver.cpp:244]     Train net output #0: loss = 0.000323905 (* 1 = 0.000323905 loss)
I0403 03:22:05.852419 28786 sgd_solver.cpp:106] Iteration 1795, lr = 0.0005
I0403 03:22:09.375263 28786 solver.cpp:228] Iteration 1800, loss = 0.0022199
I0403 03:22:09.381755 28786 solver.cpp:244]     Train net output #0: loss = 0.00221991 (* 1 = 0.00221991 loss)
I0403 03:22:09.563194 28786 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0403 03:22:10.277250 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1802.caffemodel
I0403 03:22:13.059342 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1802.solverstate
I0403 03:22:14.971771 28786 solver.cpp:337] Iteration 1802, Testing net (#0)
I0403 03:23:54.148804 28786 solver.cpp:404]     Test net output #0: accuracy = 0.971446
I0403 03:23:54.155454 28786 solver.cpp:404]     Test net output #1: loss = 0.113823 (* 1 = 0.113823 loss)
I0403 03:23:56.891688 28786 solver.cpp:228] Iteration 1805, loss = 0.00022271
I0403 03:23:56.897385 28786 solver.cpp:244]     Train net output #0: loss = 0.000222719 (* 1 = 0.000222719 loss)
I0403 03:23:57.071964 28786 sgd_solver.cpp:106] Iteration 1805, lr = 0.0005
I0403 03:24:00.534070 28786 solver.cpp:228] Iteration 1810, loss = 0.000826342
I0403 03:24:00.541096 28786 solver.cpp:244]     Train net output #0: loss = 0.000826352 (* 1 = 0.000826352 loss)
I0403 03:24:00.719177 28786 sgd_solver.cpp:106] Iteration 1810, lr = 0.0005
I0403 03:24:04.151244 28786 solver.cpp:228] Iteration 1815, loss = 0.00158601
I0403 03:24:04.156805 28786 solver.cpp:244]     Train net output #0: loss = 0.00158602 (* 1 = 0.00158602 loss)
I0403 03:24:04.358103 28786 sgd_solver.cpp:106] Iteration 1815, lr = 0.0005
I0403 03:24:07.754961 28786 solver.cpp:228] Iteration 1820, loss = 0.0037996
I0403 03:24:07.761324 28786 solver.cpp:244]     Train net output #0: loss = 0.00379961 (* 1 = 0.00379961 loss)
I0403 03:24:08.025030 28786 sgd_solver.cpp:106] Iteration 1820, lr = 0.0005
I0403 03:24:11.453323 28786 solver.cpp:228] Iteration 1825, loss = 0.0099165
I0403 03:24:11.459344 28786 solver.cpp:244]     Train net output #0: loss = 0.00991651 (* 1 = 0.00991651 loss)
I0403 03:24:11.665583 28786 sgd_solver.cpp:106] Iteration 1825, lr = 0.0005
I0403 03:24:15.148195 28786 solver.cpp:228] Iteration 1830, loss = 0.000731151
I0403 03:24:15.154870 28786 solver.cpp:244]     Train net output #0: loss = 0.000731161 (* 1 = 0.000731161 loss)
I0403 03:24:15.392477 28786 sgd_solver.cpp:106] Iteration 1830, lr = 0.0005
I0403 03:24:18.840792 28786 solver.cpp:228] Iteration 1835, loss = 0.00354778
I0403 03:24:18.846997 28786 solver.cpp:244]     Train net output #0: loss = 0.00354779 (* 1 = 0.00354779 loss)
I0403 03:24:19.020313 28786 sgd_solver.cpp:106] Iteration 1835, lr = 0.0005
I0403 03:24:22.438514 28786 solver.cpp:228] Iteration 1840, loss = 0.00472845
I0403 03:24:22.447129 28786 solver.cpp:244]     Train net output #0: loss = 0.00472846 (* 1 = 0.00472846 loss)
I0403 03:24:22.644786 28786 sgd_solver.cpp:106] Iteration 1840, lr = 0.0005
I0403 03:24:26.126885 28786 solver.cpp:228] Iteration 1845, loss = 0.000138291
I0403 03:24:26.132814 28786 solver.cpp:244]     Train net output #0: loss = 0.000138301 (* 1 = 0.000138301 loss)
I0403 03:24:26.357518 28786 sgd_solver.cpp:106] Iteration 1845, lr = 0.0005
I0403 03:24:29.917974 28786 solver.cpp:228] Iteration 1850, loss = 0.000441795
I0403 03:24:29.924337 28786 solver.cpp:244]     Train net output #0: loss = 0.000441806 (* 1 = 0.000441806 loss)
I0403 03:24:30.080358 28786 sgd_solver.cpp:106] Iteration 1850, lr = 0.0005
I0403 03:24:33.622308 28786 solver.cpp:228] Iteration 1855, loss = 0.00338616
I0403 03:24:33.628980 28786 solver.cpp:244]     Train net output #0: loss = 0.00338617 (* 1 = 0.00338617 loss)
I0403 03:24:33.802012 28786 sgd_solver.cpp:106] Iteration 1855, lr = 0.0005
I0403 03:24:37.339285 28786 solver.cpp:228] Iteration 1860, loss = 0.00194287
I0403 03:24:37.347609 28786 solver.cpp:244]     Train net output #0: loss = 0.00194288 (* 1 = 0.00194288 loss)
I0403 03:24:37.544594 28786 sgd_solver.cpp:106] Iteration 1860, lr = 0.0005
I0403 03:24:40.980280 28786 solver.cpp:228] Iteration 1865, loss = 0.000677329
I0403 03:24:40.987043 28786 solver.cpp:244]     Train net output #0: loss = 0.00067734 (* 1 = 0.00067734 loss)
I0403 03:24:41.171097 28786 sgd_solver.cpp:106] Iteration 1865, lr = 0.0005
I0403 03:24:44.593554 28786 solver.cpp:228] Iteration 1870, loss = 0.000302518
I0403 03:24:44.601685 28786 solver.cpp:244]     Train net output #0: loss = 0.000302529 (* 1 = 0.000302529 loss)
I0403 03:24:44.772289 28786 sgd_solver.cpp:106] Iteration 1870, lr = 0.0005
I0403 03:24:48.171561 28786 solver.cpp:228] Iteration 1875, loss = 0.000428231
I0403 03:24:48.177888 28786 solver.cpp:244]     Train net output #0: loss = 0.000428243 (* 1 = 0.000428243 loss)
I0403 03:24:48.400979 28786 sgd_solver.cpp:106] Iteration 1875, lr = 0.0005
I0403 03:24:51.801826 28786 solver.cpp:228] Iteration 1880, loss = 0.00131741
I0403 03:24:51.806936 28786 solver.cpp:244]     Train net output #0: loss = 0.00131742 (* 1 = 0.00131742 loss)
I0403 03:24:51.982480 28786 sgd_solver.cpp:106] Iteration 1880, lr = 0.0005
I0403 03:24:55.424316 28786 solver.cpp:228] Iteration 1885, loss = 0.00138819
I0403 03:24:55.430613 28786 solver.cpp:244]     Train net output #0: loss = 0.0013882 (* 1 = 0.0013882 loss)
I0403 03:24:55.635149 28786 sgd_solver.cpp:106] Iteration 1885, lr = 0.0005
I0403 03:24:59.076369 28786 solver.cpp:228] Iteration 1890, loss = 0.000958317
I0403 03:24:59.081833 28786 solver.cpp:244]     Train net output #0: loss = 0.000958328 (* 1 = 0.000958328 loss)
I0403 03:24:59.262868 28786 sgd_solver.cpp:106] Iteration 1890, lr = 0.0005
I0403 03:25:02.753455 28786 solver.cpp:228] Iteration 1895, loss = 0.00139006
I0403 03:25:02.761121 28786 solver.cpp:244]     Train net output #0: loss = 0.00139007 (* 1 = 0.00139007 loss)
I0403 03:25:02.918489 28786 sgd_solver.cpp:106] Iteration 1895, lr = 0.0005
I0403 03:25:06.395683 28786 solver.cpp:228] Iteration 1900, loss = 0.00109584
I0403 03:25:06.400893 28786 solver.cpp:244]     Train net output #0: loss = 0.00109585 (* 1 = 0.00109585 loss)
I0403 03:25:06.575671 28786 sgd_solver.cpp:106] Iteration 1900, lr = 0.0005
I0403 03:25:10.095382 28786 solver.cpp:228] Iteration 1905, loss = 0.000785463
I0403 03:25:10.101492 28786 solver.cpp:244]     Train net output #0: loss = 0.000785476 (* 1 = 0.000785476 loss)
I0403 03:25:10.252152 28786 sgd_solver.cpp:106] Iteration 1905, lr = 0.0005
I0403 03:25:11.757237 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1908.caffemodel
I0403 03:25:14.512197 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_1908.solverstate
I0403 03:25:16.417425 28786 solver.cpp:337] Iteration 1908, Testing net (#0)
I0403 03:26:55.597396 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972455
I0403 03:26:55.606215 28786 solver.cpp:404]     Test net output #1: loss = 0.110629 (* 1 = 0.110629 loss)
I0403 03:26:57.599493 28786 solver.cpp:228] Iteration 1910, loss = 0.00491114
I0403 03:26:57.604910 28786 solver.cpp:244]     Train net output #0: loss = 0.00491116 (* 1 = 0.00491116 loss)
I0403 03:26:57.754010 28786 sgd_solver.cpp:106] Iteration 1910, lr = 0.0005
I0403 03:27:01.416288 28786 solver.cpp:228] Iteration 1915, loss = 0.0136711
I0403 03:27:01.420977 28786 solver.cpp:244]     Train net output #0: loss = 0.0136711 (* 1 = 0.0136711 loss)
I0403 03:27:01.600450 28786 sgd_solver.cpp:106] Iteration 1915, lr = 0.0005
I0403 03:27:05.057958 28786 solver.cpp:228] Iteration 1920, loss = 0.00256123
I0403 03:27:05.063941 28786 solver.cpp:244]     Train net output #0: loss = 0.00256125 (* 1 = 0.00256125 loss)
I0403 03:27:05.304666 28786 sgd_solver.cpp:106] Iteration 1920, lr = 0.0005
I0403 03:27:08.766535 28786 solver.cpp:228] Iteration 1925, loss = 0.00055187
I0403 03:27:08.779803 28786 solver.cpp:244]     Train net output #0: loss = 0.000551883 (* 1 = 0.000551883 loss)
I0403 03:27:08.978057 28786 sgd_solver.cpp:106] Iteration 1925, lr = 0.0005
I0403 03:27:12.452343 28786 solver.cpp:228] Iteration 1930, loss = 0.00479751
I0403 03:27:12.458326 28786 solver.cpp:244]     Train net output #0: loss = 0.00479752 (* 1 = 0.00479752 loss)
I0403 03:27:12.632491 28786 sgd_solver.cpp:106] Iteration 1930, lr = 0.0005
I0403 03:27:16.083262 28786 solver.cpp:228] Iteration 1935, loss = 7.34739e-05
I0403 03:27:16.088629 28786 solver.cpp:244]     Train net output #0: loss = 7.34885e-05 (* 1 = 7.34885e-05 loss)
I0403 03:27:16.258908 28786 sgd_solver.cpp:106] Iteration 1935, lr = 0.0005
I0403 03:27:19.754981 28786 solver.cpp:228] Iteration 1940, loss = 0.000144536
I0403 03:27:19.761627 28786 solver.cpp:244]     Train net output #0: loss = 0.00014455 (* 1 = 0.00014455 loss)
I0403 03:27:19.940768 28786 sgd_solver.cpp:106] Iteration 1940, lr = 0.0005
I0403 03:27:23.456782 28786 solver.cpp:228] Iteration 1945, loss = 0.0016823
I0403 03:27:23.463603 28786 solver.cpp:244]     Train net output #0: loss = 0.00168231 (* 1 = 0.00168231 loss)
I0403 03:27:23.640403 28786 sgd_solver.cpp:106] Iteration 1945, lr = 0.0005
I0403 03:27:27.004652 28786 solver.cpp:228] Iteration 1950, loss = 0.00177469
I0403 03:27:27.010179 28786 solver.cpp:244]     Train net output #0: loss = 0.00177471 (* 1 = 0.00177471 loss)
I0403 03:27:27.186889 28786 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I0403 03:27:30.644053 28786 solver.cpp:228] Iteration 1955, loss = 0.00509239
I0403 03:27:30.648598 28786 solver.cpp:244]     Train net output #0: loss = 0.0050924 (* 1 = 0.0050924 loss)
I0403 03:27:30.838239 28786 sgd_solver.cpp:106] Iteration 1955, lr = 0.0005
I0403 03:27:34.317473 28786 solver.cpp:228] Iteration 1960, loss = 0.00253763
I0403 03:27:34.322798 28786 solver.cpp:244]     Train net output #0: loss = 0.00253764 (* 1 = 0.00253764 loss)
I0403 03:27:34.517576 28786 sgd_solver.cpp:106] Iteration 1960, lr = 0.0005
I0403 03:27:37.999452 28786 solver.cpp:228] Iteration 1965, loss = 3.82829e-05
I0403 03:27:38.007226 28786 solver.cpp:244]     Train net output #0: loss = 3.82968e-05 (* 1 = 3.82968e-05 loss)
I0403 03:27:38.168694 28786 sgd_solver.cpp:106] Iteration 1965, lr = 0.0005
I0403 03:27:41.666348 28786 solver.cpp:228] Iteration 1970, loss = 0.00625197
I0403 03:27:41.672497 28786 solver.cpp:244]     Train net output #0: loss = 0.00625198 (* 1 = 0.00625198 loss)
I0403 03:27:41.833014 28786 sgd_solver.cpp:106] Iteration 1970, lr = 0.0005
I0403 03:27:45.284936 28786 solver.cpp:228] Iteration 1975, loss = 0.0101711
I0403 03:27:45.291293 28786 solver.cpp:244]     Train net output #0: loss = 0.0101711 (* 1 = 0.0101711 loss)
I0403 03:27:45.465672 28786 sgd_solver.cpp:106] Iteration 1975, lr = 0.0005
I0403 03:27:49.118355 28786 solver.cpp:228] Iteration 1980, loss = 0.000805949
I0403 03:27:49.124474 28786 solver.cpp:244]     Train net output #0: loss = 0.000805963 (* 1 = 0.000805963 loss)
I0403 03:27:49.220365 28786 sgd_solver.cpp:106] Iteration 1980, lr = 0.0005
I0403 03:27:52.863975 28786 solver.cpp:228] Iteration 1985, loss = 0.00108242
I0403 03:27:52.871696 28786 solver.cpp:244]     Train net output #0: loss = 0.00108243 (* 1 = 0.00108243 loss)
I0403 03:27:53.050068 28786 sgd_solver.cpp:106] Iteration 1985, lr = 0.0005
I0403 03:27:56.485270 28786 solver.cpp:228] Iteration 1990, loss = 0.000183929
I0403 03:27:56.490753 28786 solver.cpp:244]     Train net output #0: loss = 0.000183943 (* 1 = 0.000183943 loss)
I0403 03:27:56.711158 28786 sgd_solver.cpp:106] Iteration 1990, lr = 0.0005
I0403 03:28:00.105134 28786 solver.cpp:228] Iteration 1995, loss = 0.0037306
I0403 03:28:00.115437 28786 solver.cpp:244]     Train net output #0: loss = 0.00373061 (* 1 = 0.00373061 loss)
I0403 03:28:00.294893 28786 sgd_solver.cpp:106] Iteration 1995, lr = 0.0005
I0403 03:28:03.714253 28786 solver.cpp:228] Iteration 2000, loss = 0.00304004
I0403 03:28:03.720482 28786 solver.cpp:244]     Train net output #0: loss = 0.00304006 (* 1 = 0.00304006 loss)
I0403 03:28:03.894325 28786 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I0403 03:28:07.349947 28786 solver.cpp:228] Iteration 2005, loss = 0.00040906
I0403 03:28:07.355875 28786 solver.cpp:244]     Train net output #0: loss = 0.000409074 (* 1 = 0.000409074 loss)
I0403 03:28:07.536623 28786 sgd_solver.cpp:106] Iteration 2005, lr = 0.0005
I0403 03:28:11.030867 28786 solver.cpp:228] Iteration 2010, loss = 0.00119297
I0403 03:28:11.036996 28786 solver.cpp:244]     Train net output #0: loss = 0.00119299 (* 1 = 0.00119299 loss)
I0403 03:28:11.232631 28786 sgd_solver.cpp:106] Iteration 2010, lr = 0.0005
I0403 03:28:13.421876 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2014.caffemodel
I0403 03:28:16.171732 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2014.solverstate
I0403 03:28:18.077921 28786 solver.cpp:337] Iteration 2014, Testing net (#0)
I0403 03:29:57.277695 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972936
I0403 03:29:57.284200 28786 solver.cpp:404]     Test net output #1: loss = 0.108966 (* 1 = 0.108966 loss)
I0403 03:29:58.559938 28786 solver.cpp:228] Iteration 2015, loss = 9.47556e-05
I0403 03:29:58.566956 28786 solver.cpp:244]     Train net output #0: loss = 9.47702e-05 (* 1 = 9.47702e-05 loss)
I0403 03:29:58.747871 28786 sgd_solver.cpp:106] Iteration 2015, lr = 0.0005
I0403 03:30:02.224182 28786 solver.cpp:228] Iteration 2020, loss = 0.000604761
I0403 03:30:02.229845 28786 solver.cpp:244]     Train net output #0: loss = 0.000604775 (* 1 = 0.000604775 loss)
I0403 03:30:02.364369 28786 sgd_solver.cpp:106] Iteration 2020, lr = 0.0005
I0403 03:30:05.919025 28786 solver.cpp:228] Iteration 2025, loss = 0.0018386
I0403 03:30:05.925016 28786 solver.cpp:244]     Train net output #0: loss = 0.00183861 (* 1 = 0.00183861 loss)
I0403 03:30:06.142360 28786 sgd_solver.cpp:106] Iteration 2025, lr = 0.0005
I0403 03:30:09.554692 28786 solver.cpp:228] Iteration 2030, loss = 0.00127402
I0403 03:30:09.561030 28786 solver.cpp:244]     Train net output #0: loss = 0.00127403 (* 1 = 0.00127403 loss)
I0403 03:30:09.741102 28786 sgd_solver.cpp:106] Iteration 2030, lr = 0.0005
I0403 03:30:13.177758 28786 solver.cpp:228] Iteration 2035, loss = 0.00768036
I0403 03:30:13.182981 28786 solver.cpp:244]     Train net output #0: loss = 0.00768038 (* 1 = 0.00768038 loss)
I0403 03:30:13.414417 28786 sgd_solver.cpp:106] Iteration 2035, lr = 0.0005
I0403 03:30:16.861830 28786 solver.cpp:228] Iteration 2040, loss = 0.000654638
I0403 03:30:16.868088 28786 solver.cpp:244]     Train net output #0: loss = 0.000654653 (* 1 = 0.000654653 loss)
I0403 03:30:17.048091 28786 sgd_solver.cpp:106] Iteration 2040, lr = 0.0005
I0403 03:30:20.432004 28786 solver.cpp:228] Iteration 2045, loss = 0.00463218
I0403 03:30:20.439051 28786 solver.cpp:244]     Train net output #0: loss = 0.00463219 (* 1 = 0.00463219 loss)
I0403 03:30:20.680692 28786 sgd_solver.cpp:106] Iteration 2045, lr = 0.0005
I0403 03:30:24.185492 28786 solver.cpp:228] Iteration 2050, loss = 0.000301389
I0403 03:30:24.191735 28786 solver.cpp:244]     Train net output #0: loss = 0.000301404 (* 1 = 0.000301404 loss)
I0403 03:30:24.392024 28786 sgd_solver.cpp:106] Iteration 2050, lr = 0.0005
I0403 03:30:27.817975 28786 solver.cpp:228] Iteration 2055, loss = 0.000199401
I0403 03:30:27.825664 28786 solver.cpp:244]     Train net output #0: loss = 0.000199416 (* 1 = 0.000199416 loss)
I0403 03:30:28.002650 28786 sgd_solver.cpp:106] Iteration 2055, lr = 0.0005
I0403 03:30:31.393273 28786 solver.cpp:228] Iteration 2060, loss = 0.00281413
I0403 03:30:31.398613 28786 solver.cpp:244]     Train net output #0: loss = 0.00281414 (* 1 = 0.00281414 loss)
I0403 03:30:31.587865 28786 sgd_solver.cpp:106] Iteration 2060, lr = 0.0005
I0403 03:30:35.012966 28786 solver.cpp:228] Iteration 2065, loss = 6.29118e-05
I0403 03:30:35.020928 28786 solver.cpp:244]     Train net output #0: loss = 6.29265e-05 (* 1 = 6.29265e-05 loss)
I0403 03:30:35.212083 28786 sgd_solver.cpp:106] Iteration 2065, lr = 0.0005
I0403 03:30:38.669571 28786 solver.cpp:228] Iteration 2070, loss = 0.00180526
I0403 03:30:38.674782 28786 solver.cpp:244]     Train net output #0: loss = 0.00180528 (* 1 = 0.00180528 loss)
I0403 03:30:38.866791 28786 sgd_solver.cpp:106] Iteration 2070, lr = 0.0005
I0403 03:30:42.406105 28786 solver.cpp:228] Iteration 2075, loss = 0.000997192
I0403 03:30:42.412607 28786 solver.cpp:244]     Train net output #0: loss = 0.000997207 (* 1 = 0.000997207 loss)
I0403 03:30:42.584472 28786 sgd_solver.cpp:106] Iteration 2075, lr = 0.0005
I0403 03:30:46.115162 28786 solver.cpp:228] Iteration 2080, loss = 0.00186275
I0403 03:30:46.120652 28786 solver.cpp:244]     Train net output #0: loss = 0.00186277 (* 1 = 0.00186277 loss)
I0403 03:30:46.337407 28786 sgd_solver.cpp:106] Iteration 2080, lr = 0.0005
I0403 03:30:49.789124 28786 solver.cpp:228] Iteration 2085, loss = 0.00115727
I0403 03:30:49.795718 28786 solver.cpp:244]     Train net output #0: loss = 0.00115729 (* 1 = 0.00115729 loss)
I0403 03:30:49.966670 28786 sgd_solver.cpp:106] Iteration 2085, lr = 0.0005
I0403 03:30:53.520972 28786 solver.cpp:228] Iteration 2090, loss = 0.00154286
I0403 03:30:53.529330 28786 solver.cpp:244]     Train net output #0: loss = 0.00154288 (* 1 = 0.00154288 loss)
I0403 03:30:53.700369 28786 sgd_solver.cpp:106] Iteration 2090, lr = 0.0005
I0403 03:30:57.124066 28786 solver.cpp:228] Iteration 2095, loss = 0.00104794
I0403 03:30:57.130686 28786 solver.cpp:244]     Train net output #0: loss = 0.00104795 (* 1 = 0.00104795 loss)
I0403 03:30:57.307133 28786 sgd_solver.cpp:106] Iteration 2095, lr = 0.0005
I0403 03:31:00.793653 28786 solver.cpp:228] Iteration 2100, loss = 0.000490307
I0403 03:31:00.800637 28786 solver.cpp:244]     Train net output #0: loss = 0.000490322 (* 1 = 0.000490322 loss)
I0403 03:31:00.983198 28786 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0403 03:31:04.421852 28786 solver.cpp:228] Iteration 2105, loss = 0.000428028
I0403 03:31:04.428812 28786 solver.cpp:244]     Train net output #0: loss = 0.000428043 (* 1 = 0.000428043 loss)
I0403 03:31:04.586221 28786 sgd_solver.cpp:106] Iteration 2105, lr = 0.0005
I0403 03:31:08.130705 28786 solver.cpp:228] Iteration 2110, loss = 0.000474741
I0403 03:31:08.137074 28786 solver.cpp:244]     Train net output #0: loss = 0.000474756 (* 1 = 0.000474756 loss)
I0403 03:31:08.307082 28786 sgd_solver.cpp:106] Iteration 2110, lr = 0.0005
I0403 03:31:11.777339 28786 solver.cpp:228] Iteration 2115, loss = 0.00160262
I0403 03:31:11.783926 28786 solver.cpp:244]     Train net output #0: loss = 0.00160264 (* 1 = 0.00160264 loss)
I0403 03:31:11.968286 28786 sgd_solver.cpp:106] Iteration 2115, lr = 0.0005
I0403 03:31:14.872045 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2120.caffemodel
I0403 03:31:17.656815 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2120.solverstate
I0403 03:31:19.577638 28786 solver.cpp:337] Iteration 2120, Testing net (#0)
I0403 03:32:58.769495 28786 solver.cpp:404]     Test net output #0: accuracy = 0.973097
I0403 03:32:58.777480 28786 solver.cpp:404]     Test net output #1: loss = 0.110657 (* 1 = 0.110657 loss)
I0403 03:32:59.294348 28786 solver.cpp:228] Iteration 2120, loss = 0.000200808
I0403 03:32:59.302399 28786 solver.cpp:244]     Train net output #0: loss = 0.000200823 (* 1 = 0.000200823 loss)
I0403 03:32:59.472515 28786 sgd_solver.cpp:106] Iteration 2120, lr = 0.0005
I0403 03:33:03.034353 28786 solver.cpp:228] Iteration 2125, loss = 0.00216434
I0403 03:33:03.040263 28786 solver.cpp:244]     Train net output #0: loss = 0.00216436 (* 1 = 0.00216436 loss)
I0403 03:33:03.213718 28786 sgd_solver.cpp:106] Iteration 2125, lr = 0.0005
I0403 03:33:06.810433 28786 solver.cpp:228] Iteration 2130, loss = 0.00110825
I0403 03:33:06.815992 28786 solver.cpp:244]     Train net output #0: loss = 0.00110827 (* 1 = 0.00110827 loss)
I0403 03:33:06.995712 28786 sgd_solver.cpp:106] Iteration 2130, lr = 0.0005
I0403 03:33:10.474874 28786 solver.cpp:228] Iteration 2135, loss = 0.00136844
I0403 03:33:10.479630 28786 solver.cpp:244]     Train net output #0: loss = 0.00136845 (* 1 = 0.00136845 loss)
I0403 03:33:10.633191 28786 sgd_solver.cpp:106] Iteration 2135, lr = 5e-05
I0403 03:33:14.148227 28786 solver.cpp:228] Iteration 2140, loss = 0.000168499
I0403 03:33:14.154881 28786 solver.cpp:244]     Train net output #0: loss = 0.000168514 (* 1 = 0.000168514 loss)
I0403 03:33:14.333701 28786 sgd_solver.cpp:106] Iteration 2140, lr = 5e-05
I0403 03:33:17.889791 28786 solver.cpp:228] Iteration 2145, loss = 0.0166337
I0403 03:33:17.897753 28786 solver.cpp:244]     Train net output #0: loss = 0.0166337 (* 1 = 0.0166337 loss)
I0403 03:33:18.105430 28786 sgd_solver.cpp:106] Iteration 2145, lr = 5e-05
I0403 03:33:21.496834 28786 solver.cpp:228] Iteration 2150, loss = 0.0016807
I0403 03:33:21.505188 28786 solver.cpp:244]     Train net output #0: loss = 0.00168071 (* 1 = 0.00168071 loss)
I0403 03:33:21.680234 28786 sgd_solver.cpp:106] Iteration 2150, lr = 5e-05
I0403 03:33:25.156584 28786 solver.cpp:228] Iteration 2155, loss = 0.000466001
I0403 03:33:25.162969 28786 solver.cpp:244]     Train net output #0: loss = 0.000466017 (* 1 = 0.000466017 loss)
I0403 03:33:25.345140 28786 sgd_solver.cpp:106] Iteration 2155, lr = 5e-05
I0403 03:33:28.893468 28786 solver.cpp:228] Iteration 2160, loss = 0.000429825
I0403 03:33:28.900061 28786 solver.cpp:244]     Train net output #0: loss = 0.000429841 (* 1 = 0.000429841 loss)
I0403 03:33:29.054275 28786 sgd_solver.cpp:106] Iteration 2160, lr = 5e-05
I0403 03:33:32.530298 28786 solver.cpp:228] Iteration 2165, loss = 0.00121141
I0403 03:33:32.536877 28786 solver.cpp:244]     Train net output #0: loss = 0.00121142 (* 1 = 0.00121142 loss)
I0403 03:33:32.755223 28786 sgd_solver.cpp:106] Iteration 2165, lr = 5e-05
I0403 03:33:36.203548 28786 solver.cpp:228] Iteration 2170, loss = 0.000972509
I0403 03:33:36.210587 28786 solver.cpp:244]     Train net output #0: loss = 0.000972523 (* 1 = 0.000972523 loss)
I0403 03:33:36.375241 28786 sgd_solver.cpp:106] Iteration 2170, lr = 5e-05
I0403 03:33:39.972882 28786 solver.cpp:228] Iteration 2175, loss = 0.00024985
I0403 03:33:39.979854 28786 solver.cpp:244]     Train net output #0: loss = 0.000249864 (* 1 = 0.000249864 loss)
I0403 03:33:40.133826 28786 sgd_solver.cpp:106] Iteration 2175, lr = 5e-05
I0403 03:33:43.829690 28786 solver.cpp:228] Iteration 2180, loss = 0.00050224
I0403 03:33:43.835522 28786 solver.cpp:244]     Train net output #0: loss = 0.000502255 (* 1 = 0.000502255 loss)
I0403 03:33:43.957705 28786 sgd_solver.cpp:106] Iteration 2180, lr = 5e-05
I0403 03:33:47.582110 28786 solver.cpp:228] Iteration 2185, loss = 0.000124029
I0403 03:33:47.588531 28786 solver.cpp:244]     Train net output #0: loss = 0.000124044 (* 1 = 0.000124044 loss)
I0403 03:33:47.780256 28786 sgd_solver.cpp:106] Iteration 2185, lr = 5e-05
I0403 03:33:51.283468 28786 solver.cpp:228] Iteration 2190, loss = 0.000280567
I0403 03:33:51.289911 28786 solver.cpp:244]     Train net output #0: loss = 0.000280581 (* 1 = 0.000280581 loss)
I0403 03:33:51.466848 28786 sgd_solver.cpp:106] Iteration 2190, lr = 5e-05
I0403 03:33:54.940631 28786 solver.cpp:228] Iteration 2195, loss = 0.000494393
I0403 03:33:54.940729 28786 solver.cpp:244]     Train net output #0: loss = 0.000494408 (* 1 = 0.000494408 loss)
I0403 03:33:55.137872 28786 sgd_solver.cpp:106] Iteration 2195, lr = 5e-05
I0403 03:33:58.578485 28786 solver.cpp:228] Iteration 2200, loss = 0.000306875
I0403 03:33:58.578588 28786 solver.cpp:244]     Train net output #0: loss = 0.00030689 (* 1 = 0.00030689 loss)
I0403 03:33:58.790827 28786 sgd_solver.cpp:106] Iteration 2200, lr = 5e-05
I0403 03:34:02.259333 28786 solver.cpp:228] Iteration 2205, loss = 0.000765839
I0403 03:34:02.259697 28786 solver.cpp:244]     Train net output #0: loss = 0.000765854 (* 1 = 0.000765854 loss)
I0403 03:34:02.487984 28786 sgd_solver.cpp:106] Iteration 2205, lr = 5e-05
I0403 03:34:06.088593 28786 solver.cpp:228] Iteration 2210, loss = 6.94857e-05
I0403 03:34:06.088681 28786 solver.cpp:244]     Train net output #0: loss = 6.95006e-05 (* 1 = 6.95006e-05 loss)
I0403 03:34:06.220687 28786 sgd_solver.cpp:106] Iteration 2210, lr = 5e-05
I0403 03:34:09.844440 28786 solver.cpp:228] Iteration 2215, loss = 0.000625365
I0403 03:34:09.844528 28786 solver.cpp:244]     Train net output #0: loss = 0.00062538 (* 1 = 0.00062538 loss)
I0403 03:34:10.046484 28786 sgd_solver.cpp:106] Iteration 2215, lr = 5e-05
I0403 03:34:13.597717 28786 solver.cpp:228] Iteration 2220, loss = 0.000607134
I0403 03:34:13.597805 28786 solver.cpp:244]     Train net output #0: loss = 0.000607149 (* 1 = 0.000607149 loss)
I0403 03:34:13.773666 28786 sgd_solver.cpp:106] Iteration 2220, lr = 5e-05
I0403 03:34:17.254575 28786 solver.cpp:228] Iteration 2225, loss = 0.000214418
I0403 03:34:17.254660 28786 solver.cpp:244]     Train net output #0: loss = 0.000214434 (* 1 = 0.000214434 loss)
I0403 03:34:17.427655 28786 sgd_solver.cpp:106] Iteration 2225, lr = 5e-05
I0403 03:34:17.427888 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2226.caffemodel
I0403 03:34:20.221659 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2226.solverstate
I0403 03:34:22.140223 28786 solver.cpp:337] Iteration 2226, Testing net (#0)
I0403 03:36:01.318667 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972959
I0403 03:36:01.318990 28786 solver.cpp:404]     Test net output #1: loss = 0.111843 (* 1 = 0.111843 loss)
I0403 03:36:04.750229 28786 solver.cpp:228] Iteration 2230, loss = 0.00292677
I0403 03:36:04.750324 28786 solver.cpp:244]     Train net output #0: loss = 0.00292679 (* 1 = 0.00292679 loss)
I0403 03:36:04.954854 28786 sgd_solver.cpp:106] Iteration 2230, lr = 5e-05
I0403 03:36:08.435992 28786 solver.cpp:228] Iteration 2235, loss = 0.00184671
I0403 03:36:08.436079 28786 solver.cpp:244]     Train net output #0: loss = 0.00184673 (* 1 = 0.00184673 loss)
I0403 03:36:08.618170 28786 sgd_solver.cpp:106] Iteration 2235, lr = 5e-05
I0403 03:36:12.097251 28786 solver.cpp:228] Iteration 2240, loss = 0.000832501
I0403 03:36:12.097352 28786 solver.cpp:244]     Train net output #0: loss = 0.000832516 (* 1 = 0.000832516 loss)
I0403 03:36:12.287847 28786 sgd_solver.cpp:106] Iteration 2240, lr = 5e-05
I0403 03:36:15.756124 28786 solver.cpp:228] Iteration 2245, loss = 0.00369686
I0403 03:36:15.756213 28786 solver.cpp:244]     Train net output #0: loss = 0.00369687 (* 1 = 0.00369687 loss)
I0403 03:36:15.964524 28786 sgd_solver.cpp:106] Iteration 2245, lr = 5e-05
I0403 03:36:19.448714 28786 solver.cpp:228] Iteration 2250, loss = 0.000595098
I0403 03:36:19.448812 28786 solver.cpp:244]     Train net output #0: loss = 0.000595115 (* 1 = 0.000595115 loss)
I0403 03:36:19.667466 28786 sgd_solver.cpp:106] Iteration 2250, lr = 5e-05
I0403 03:36:23.143066 28786 solver.cpp:228] Iteration 2255, loss = 0.0026453
I0403 03:36:23.143169 28786 solver.cpp:244]     Train net output #0: loss = 0.00264532 (* 1 = 0.00264532 loss)
I0403 03:36:23.357941 28786 sgd_solver.cpp:106] Iteration 2255, lr = 5e-05
I0403 03:36:26.821063 28786 solver.cpp:228] Iteration 2260, loss = 0.00211198
I0403 03:36:26.821158 28786 solver.cpp:244]     Train net output #0: loss = 0.002112 (* 1 = 0.002112 loss)
I0403 03:36:27.038815 28786 sgd_solver.cpp:106] Iteration 2260, lr = 5e-05
I0403 03:36:30.512823 28786 solver.cpp:228] Iteration 2265, loss = 0.000469517
I0403 03:36:30.512920 28786 solver.cpp:244]     Train net output #0: loss = 0.000469535 (* 1 = 0.000469535 loss)
I0403 03:36:30.725981 28786 sgd_solver.cpp:106] Iteration 2265, lr = 5e-05
I0403 03:36:34.279410 28786 solver.cpp:228] Iteration 2270, loss = 0.000494103
I0403 03:36:34.279765 28786 solver.cpp:244]     Train net output #0: loss = 0.000494121 (* 1 = 0.000494121 loss)
I0403 03:36:34.446843 28786 sgd_solver.cpp:106] Iteration 2270, lr = 5e-05
I0403 03:36:37.946036 28786 solver.cpp:228] Iteration 2275, loss = 0.00374295
I0403 03:36:37.946133 28786 solver.cpp:244]     Train net output #0: loss = 0.00374297 (* 1 = 0.00374297 loss)
I0403 03:36:38.142539 28786 sgd_solver.cpp:106] Iteration 2275, lr = 5e-05
I0403 03:36:41.609547 28786 solver.cpp:228] Iteration 2280, loss = 0.0454517
I0403 03:36:41.609645 28786 solver.cpp:244]     Train net output #0: loss = 0.0454517 (* 1 = 0.0454517 loss)
I0403 03:36:41.813376 28786 sgd_solver.cpp:106] Iteration 2280, lr = 5e-05
I0403 03:36:45.357249 28786 solver.cpp:228] Iteration 2285, loss = 0.000149882
I0403 03:36:45.357343 28786 solver.cpp:244]     Train net output #0: loss = 0.000149901 (* 1 = 0.000149901 loss)
I0403 03:36:45.546458 28786 sgd_solver.cpp:106] Iteration 2285, lr = 5e-05
I0403 03:36:48.958948 28786 solver.cpp:228] Iteration 2290, loss = 0.00684038
I0403 03:36:48.959048 28786 solver.cpp:244]     Train net output #0: loss = 0.00684039 (* 1 = 0.00684039 loss)
I0403 03:36:49.153563 28786 sgd_solver.cpp:106] Iteration 2290, lr = 5e-05
I0403 03:36:52.588460 28786 solver.cpp:228] Iteration 2295, loss = 0.000297011
I0403 03:36:52.588556 28786 solver.cpp:244]     Train net output #0: loss = 0.000297029 (* 1 = 0.000297029 loss)
I0403 03:36:52.817476 28786 sgd_solver.cpp:106] Iteration 2295, lr = 5e-05
I0403 03:36:56.262192 28786 solver.cpp:228] Iteration 2300, loss = 0.00321999
I0403 03:36:56.262291 28786 solver.cpp:244]     Train net output #0: loss = 0.00322001 (* 1 = 0.00322001 loss)
I0403 03:36:56.497737 28786 sgd_solver.cpp:106] Iteration 2300, lr = 5e-05
I0403 03:36:59.950223 28786 solver.cpp:228] Iteration 2305, loss = 0.000914911
I0403 03:36:59.950323 28786 solver.cpp:244]     Train net output #0: loss = 0.000914929 (* 1 = 0.000914929 loss)
I0403 03:37:00.215484 28786 sgd_solver.cpp:106] Iteration 2305, lr = 5e-05
I0403 03:37:03.681418 28786 solver.cpp:228] Iteration 2310, loss = 0.00198308
I0403 03:37:03.681521 28786 solver.cpp:244]     Train net output #0: loss = 0.0019831 (* 1 = 0.0019831 loss)
I0403 03:37:03.897807 28786 sgd_solver.cpp:106] Iteration 2310, lr = 5e-05
I0403 03:37:07.420832 28786 solver.cpp:228] Iteration 2315, loss = 0.0052812
I0403 03:37:07.421136 28786 solver.cpp:244]     Train net output #0: loss = 0.00528122 (* 1 = 0.00528122 loss)
I0403 03:37:07.606817 28786 sgd_solver.cpp:106] Iteration 2315, lr = 5e-05
I0403 03:37:10.995251 28786 solver.cpp:228] Iteration 2320, loss = 0.00515217
I0403 03:37:10.995352 28786 solver.cpp:244]     Train net output #0: loss = 0.00515219 (* 1 = 0.00515219 loss)
I0403 03:37:11.247521 28786 sgd_solver.cpp:106] Iteration 2320, lr = 5e-05
I0403 03:37:14.663219 28786 solver.cpp:228] Iteration 2325, loss = 0.00312822
I0403 03:37:14.663307 28786 solver.cpp:244]     Train net output #0: loss = 0.00312824 (* 1 = 0.00312824 loss)
I0403 03:37:14.840153 28786 sgd_solver.cpp:106] Iteration 2325, lr = 5e-05
I0403 03:37:18.348731 28786 solver.cpp:228] Iteration 2330, loss = 0.00222986
I0403 03:37:18.348816 28786 solver.cpp:244]     Train net output #0: loss = 0.00222988 (* 1 = 0.00222988 loss)
I0403 03:37:18.496875 28786 sgd_solver.cpp:106] Iteration 2330, lr = 5e-05
I0403 03:37:19.296176 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2332.caffemodel
I0403 03:37:22.006328 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2332.solverstate
I0403 03:37:23.795436 28786 solver.cpp:337] Iteration 2332, Testing net (#0)
I0403 03:39:02.990231 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972891
I0403 03:39:02.990591 28786 solver.cpp:404]     Test net output #1: loss = 0.112008 (* 1 = 0.112008 loss)
I0403 03:39:05.670075 28786 solver.cpp:228] Iteration 2335, loss = 9.47847e-05
I0403 03:39:05.670171 28786 solver.cpp:244]     Train net output #0: loss = 9.48031e-05 (* 1 = 9.48031e-05 loss)
I0403 03:39:05.888149 28786 sgd_solver.cpp:106] Iteration 2335, lr = 5e-05
I0403 03:39:09.376009 28786 solver.cpp:228] Iteration 2340, loss = 0.00112641
I0403 03:39:09.376107 28786 solver.cpp:244]     Train net output #0: loss = 0.00112643 (* 1 = 0.00112643 loss)
I0403 03:39:09.610816 28786 sgd_solver.cpp:106] Iteration 2340, lr = 5e-05
I0403 03:39:13.070082 28786 solver.cpp:228] Iteration 2345, loss = 0.000228015
I0403 03:39:13.070183 28786 solver.cpp:244]     Train net output #0: loss = 0.000228033 (* 1 = 0.000228033 loss)
I0403 03:39:13.290243 28786 sgd_solver.cpp:106] Iteration 2345, lr = 5e-05
I0403 03:39:16.731911 28786 solver.cpp:228] Iteration 2350, loss = 0.000929874
I0403 03:39:16.731998 28786 solver.cpp:244]     Train net output #0: loss = 0.000929892 (* 1 = 0.000929892 loss)
I0403 03:39:16.896824 28786 sgd_solver.cpp:106] Iteration 2350, lr = 5e-05
I0403 03:39:20.376051 28786 solver.cpp:228] Iteration 2355, loss = 0.00175186
I0403 03:39:20.376137 28786 solver.cpp:244]     Train net output #0: loss = 0.00175188 (* 1 = 0.00175188 loss)
I0403 03:39:20.532573 28786 sgd_solver.cpp:106] Iteration 2355, lr = 5e-05
I0403 03:39:24.101714 28786 solver.cpp:228] Iteration 2360, loss = 0.00166385
I0403 03:39:24.101814 28786 solver.cpp:244]     Train net output #0: loss = 0.00166387 (* 1 = 0.00166387 loss)
I0403 03:39:24.287768 28786 sgd_solver.cpp:106] Iteration 2360, lr = 5e-05
I0403 03:39:27.683388 28786 solver.cpp:228] Iteration 2365, loss = 0.000777052
I0403 03:39:27.683481 28786 solver.cpp:244]     Train net output #0: loss = 0.000777071 (* 1 = 0.000777071 loss)
I0403 03:39:27.878597 28786 sgd_solver.cpp:106] Iteration 2365, lr = 5e-05
I0403 03:39:31.326546 28786 solver.cpp:228] Iteration 2370, loss = 0.000358991
I0403 03:39:31.326643 28786 solver.cpp:244]     Train net output #0: loss = 0.00035901 (* 1 = 0.00035901 loss)
I0403 03:39:31.523658 28786 sgd_solver.cpp:106] Iteration 2370, lr = 5e-05
I0403 03:39:34.966261 28786 solver.cpp:228] Iteration 2375, loss = 0.000417313
I0403 03:39:34.966580 28786 solver.cpp:244]     Train net output #0: loss = 0.000417331 (* 1 = 0.000417331 loss)
I0403 03:39:35.145378 28786 sgd_solver.cpp:106] Iteration 2375, lr = 5e-05
I0403 03:39:38.614867 28786 solver.cpp:228] Iteration 2380, loss = 0.00122346
I0403 03:39:38.614966 28786 solver.cpp:244]     Train net output #0: loss = 0.00122348 (* 1 = 0.00122348 loss)
I0403 03:39:38.838114 28786 sgd_solver.cpp:106] Iteration 2380, lr = 5e-05
I0403 03:39:42.265277 28786 solver.cpp:228] Iteration 2385, loss = 0.000455862
I0403 03:39:42.265374 28786 solver.cpp:244]     Train net output #0: loss = 0.000455881 (* 1 = 0.000455881 loss)
I0403 03:39:42.453129 28786 sgd_solver.cpp:106] Iteration 2385, lr = 5e-05
I0403 03:39:46.041584 28786 solver.cpp:228] Iteration 2390, loss = 0.000346715
I0403 03:39:46.041688 28786 solver.cpp:244]     Train net output #0: loss = 0.000346734 (* 1 = 0.000346734 loss)
I0403 03:39:46.238822 28786 sgd_solver.cpp:106] Iteration 2390, lr = 5e-05
I0403 03:39:49.726217 28786 solver.cpp:228] Iteration 2395, loss = 0.00263182
I0403 03:39:49.726303 28786 solver.cpp:244]     Train net output #0: loss = 0.00263184 (* 1 = 0.00263184 loss)
I0403 03:39:49.869838 28786 sgd_solver.cpp:106] Iteration 2395, lr = 5e-05
I0403 03:39:53.734657 28786 solver.cpp:228] Iteration 2400, loss = 0.00031572
I0403 03:39:53.734743 28786 solver.cpp:244]     Train net output #0: loss = 0.000315739 (* 1 = 0.000315739 loss)
I0403 03:39:53.900709 28786 sgd_solver.cpp:106] Iteration 2400, lr = 5e-05
I0403 03:39:57.505431 28786 solver.cpp:228] Iteration 2405, loss = 0.00225874
I0403 03:39:57.505529 28786 solver.cpp:244]     Train net output #0: loss = 0.00225876 (* 1 = 0.00225876 loss)
I0403 03:39:57.700593 28786 sgd_solver.cpp:106] Iteration 2405, lr = 5e-05
I0403 03:40:01.224777 28786 solver.cpp:228] Iteration 2410, loss = 0.0011151
I0403 03:40:01.224865 28786 solver.cpp:244]     Train net output #0: loss = 0.00111511 (* 1 = 0.00111511 loss)
I0403 03:40:01.403344 28786 sgd_solver.cpp:106] Iteration 2410, lr = 5e-05
I0403 03:40:04.833626 28786 solver.cpp:228] Iteration 2415, loss = 0.000792572
I0403 03:40:04.833720 28786 solver.cpp:244]     Train net output #0: loss = 0.00079259 (* 1 = 0.00079259 loss)
I0403 03:40:05.041379 28786 sgd_solver.cpp:106] Iteration 2415, lr = 5e-05
I0403 03:40:08.463846 28786 solver.cpp:228] Iteration 2420, loss = 5.9628e-05
I0403 03:40:08.463943 28786 solver.cpp:244]     Train net output #0: loss = 5.96466e-05 (* 1 = 5.96466e-05 loss)
I0403 03:40:08.662806 28786 sgd_solver.cpp:106] Iteration 2420, lr = 5e-05
I0403 03:40:12.036523 28786 solver.cpp:228] Iteration 2425, loss = 0.00112566
I0403 03:40:12.036623 28786 solver.cpp:244]     Train net output #0: loss = 0.00112568 (* 1 = 0.00112568 loss)
I0403 03:40:12.242930 28786 sgd_solver.cpp:106] Iteration 2425, lr = 5e-05
I0403 03:40:15.705379 28786 solver.cpp:228] Iteration 2430, loss = 0.000242306
I0403 03:40:15.705463 28786 solver.cpp:244]     Train net output #0: loss = 0.000242325 (* 1 = 0.000242325 loss)
I0403 03:40:15.894366 28786 sgd_solver.cpp:106] Iteration 2430, lr = 5e-05
I0403 03:40:19.345542 28786 solver.cpp:228] Iteration 2435, loss = 0.000362456
I0403 03:40:19.345633 28786 solver.cpp:244]     Train net output #0: loss = 0.000362475 (* 1 = 0.000362475 loss)
I0403 03:40:19.557574 28786 sgd_solver.cpp:106] Iteration 2435, lr = 5e-05
I0403 03:40:20.965981 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2438.caffemodel
I0403 03:40:23.626912 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2438.solverstate
I0403 03:40:25.376366 28786 solver.cpp:337] Iteration 2438, Testing net (#0)
I0403 03:42:04.570029 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972914
I0403 03:42:04.570340 28786 solver.cpp:404]     Test net output #1: loss = 0.11151 (* 1 = 0.11151 loss)
I0403 03:42:06.689172 28786 solver.cpp:228] Iteration 2440, loss = 0.000112103
I0403 03:42:06.689254 28786 solver.cpp:244]     Train net output #0: loss = 0.000112122 (* 1 = 0.000112122 loss)
I0403 03:42:06.833307 28786 sgd_solver.cpp:106] Iteration 2440, lr = 5e-05
I0403 03:42:10.431807 28786 solver.cpp:228] Iteration 2445, loss = 0.000263347
I0403 03:42:10.431893 28786 solver.cpp:244]     Train net output #0: loss = 0.000263365 (* 1 = 0.000263365 loss)
I0403 03:42:10.603952 28786 sgd_solver.cpp:106] Iteration 2445, lr = 5e-05
I0403 03:42:14.169390 28786 solver.cpp:228] Iteration 2450, loss = 0.00269708
I0403 03:42:14.169481 28786 solver.cpp:244]     Train net output #0: loss = 0.0026971 (* 1 = 0.0026971 loss)
I0403 03:42:14.293175 28786 sgd_solver.cpp:106] Iteration 2450, lr = 5e-05
I0403 03:42:17.902875 28786 solver.cpp:228] Iteration 2455, loss = 0.00134085
I0403 03:42:17.902974 28786 solver.cpp:244]     Train net output #0: loss = 0.00134087 (* 1 = 0.00134087 loss)
I0403 03:42:18.118260 28786 sgd_solver.cpp:106] Iteration 2455, lr = 5e-05
I0403 03:42:21.709336 28786 solver.cpp:228] Iteration 2460, loss = 0.000733599
I0403 03:42:21.709414 28786 solver.cpp:244]     Train net output #0: loss = 0.000733618 (* 1 = 0.000733618 loss)
I0403 03:42:21.865357 28786 sgd_solver.cpp:106] Iteration 2460, lr = 5e-05
I0403 03:42:25.386580 28786 solver.cpp:228] Iteration 2465, loss = 0.00168818
I0403 03:42:25.386668 28786 solver.cpp:244]     Train net output #0: loss = 0.0016882 (* 1 = 0.0016882 loss)
I0403 03:42:25.566855 28786 sgd_solver.cpp:106] Iteration 2465, lr = 5e-05
I0403 03:42:29.063370 28786 solver.cpp:228] Iteration 2470, loss = 0.000323842
I0403 03:42:29.063472 28786 solver.cpp:244]     Train net output #0: loss = 0.000323862 (* 1 = 0.000323862 loss)
I0403 03:42:29.271471 28786 sgd_solver.cpp:106] Iteration 2470, lr = 5e-05
I0403 03:42:32.751566 28786 solver.cpp:228] Iteration 2475, loss = 0.00310564
I0403 03:42:32.751670 28786 solver.cpp:244]     Train net output #0: loss = 0.00310566 (* 1 = 0.00310566 loss)
I0403 03:42:32.988164 28786 sgd_solver.cpp:106] Iteration 2475, lr = 5e-05
I0403 03:42:36.461642 28786 solver.cpp:228] Iteration 2480, loss = 0.00139178
I0403 03:42:36.461993 28786 solver.cpp:244]     Train net output #0: loss = 0.0013918 (* 1 = 0.0013918 loss)
I0403 03:42:36.594208 28786 sgd_solver.cpp:106] Iteration 2480, lr = 5e-05
I0403 03:42:40.236600 28786 solver.cpp:228] Iteration 2485, loss = 0.00281809
I0403 03:42:40.236693 28786 solver.cpp:244]     Train net output #0: loss = 0.0028181 (* 1 = 0.0028181 loss)
I0403 03:42:40.421039 28786 sgd_solver.cpp:106] Iteration 2485, lr = 5e-05
I0403 03:42:43.945340 28786 solver.cpp:228] Iteration 2490, loss = 0.000773624
I0403 03:42:43.945426 28786 solver.cpp:244]     Train net output #0: loss = 0.000773643 (* 1 = 0.000773643 loss)
I0403 03:42:44.123392 28786 sgd_solver.cpp:106] Iteration 2490, lr = 5e-05
I0403 03:42:47.703299 28786 solver.cpp:228] Iteration 2495, loss = 0.00508604
I0403 03:42:47.703387 28786 solver.cpp:244]     Train net output #0: loss = 0.00508606 (* 1 = 0.00508606 loss)
I0403 03:42:47.867301 28786 sgd_solver.cpp:106] Iteration 2495, lr = 5e-05
I0403 03:42:51.451210 28786 solver.cpp:228] Iteration 2500, loss = 0.00039673
I0403 03:42:51.451306 28786 solver.cpp:244]     Train net output #0: loss = 0.00039675 (* 1 = 0.00039675 loss)
I0403 03:42:51.634129 28786 sgd_solver.cpp:106] Iteration 2500, lr = 5e-05
I0403 03:42:55.074569 28786 solver.cpp:228] Iteration 2505, loss = 0.0032651
I0403 03:42:55.074672 28786 solver.cpp:244]     Train net output #0: loss = 0.00326512 (* 1 = 0.00326512 loss)
I0403 03:42:55.314684 28786 sgd_solver.cpp:106] Iteration 2505, lr = 5e-05
I0403 03:42:58.751055 28786 solver.cpp:228] Iteration 2510, loss = 0.000313016
I0403 03:42:58.751152 28786 solver.cpp:244]     Train net output #0: loss = 0.000313035 (* 1 = 0.000313035 loss)
I0403 03:42:58.935598 28786 sgd_solver.cpp:106] Iteration 2510, lr = 5e-05
I0403 03:43:02.426542 28786 solver.cpp:228] Iteration 2515, loss = 0.000181959
I0403 03:43:02.426640 28786 solver.cpp:244]     Train net output #0: loss = 0.000181978 (* 1 = 0.000181978 loss)
I0403 03:43:02.610972 28786 sgd_solver.cpp:106] Iteration 2515, lr = 5e-05
I0403 03:43:06.041501 28786 solver.cpp:228] Iteration 2520, loss = 0.00167634
I0403 03:43:06.041606 28786 solver.cpp:244]     Train net output #0: loss = 0.00167636 (* 1 = 0.00167636 loss)
I0403 03:43:06.240298 28786 sgd_solver.cpp:106] Iteration 2520, lr = 5e-05
I0403 03:43:09.756564 28786 solver.cpp:228] Iteration 2525, loss = 0.000694664
I0403 03:43:09.756850 28786 solver.cpp:244]     Train net output #0: loss = 0.000694683 (* 1 = 0.000694683 loss)
I0403 03:43:09.936761 28786 sgd_solver.cpp:106] Iteration 2525, lr = 5e-05
I0403 03:43:13.465112 28786 solver.cpp:228] Iteration 2530, loss = 0.000734391
I0403 03:43:13.465211 28786 solver.cpp:244]     Train net output #0: loss = 0.00073441 (* 1 = 0.00073441 loss)
I0403 03:43:13.650882 28786 sgd_solver.cpp:106] Iteration 2530, lr = 5e-05
I0403 03:43:17.153065 28786 solver.cpp:228] Iteration 2535, loss = 0.00407092
I0403 03:43:17.153910 28786 solver.cpp:244]     Train net output #0: loss = 0.00407094 (* 1 = 0.00407094 loss)
I0403 03:43:17.365653 28786 sgd_solver.cpp:106] Iteration 2535, lr = 5e-05
I0403 03:43:20.866343 28786 solver.cpp:228] Iteration 2540, loss = 0.000192507
I0403 03:43:20.866441 28786 solver.cpp:244]     Train net output #0: loss = 0.000192528 (* 1 = 0.000192528 loss)
I0403 03:43:21.074760 28786 sgd_solver.cpp:106] Iteration 2540, lr = 5e-05
I0403 03:43:23.232759 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2544.caffemodel
I0403 03:43:26.010303 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2544.solverstate
I0403 03:43:27.929533 28786 solver.cpp:337] Iteration 2544, Testing net (#0)
I0403 03:45:07.112051 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972937
I0403 03:45:07.112403 28786 solver.cpp:404]     Test net output #1: loss = 0.110965 (* 1 = 0.110965 loss)
I0403 03:45:08.381752 28786 solver.cpp:228] Iteration 2545, loss = 0.000561835
I0403 03:45:08.381839 28786 solver.cpp:244]     Train net output #0: loss = 0.000561856 (* 1 = 0.000561856 loss)
I0403 03:45:08.560523 28786 sgd_solver.cpp:106] Iteration 2545, lr = 5e-05
I0403 03:45:11.991441 28786 solver.cpp:228] Iteration 2550, loss = 0.00202657
I0403 03:45:11.991544 28786 solver.cpp:244]     Train net output #0: loss = 0.00202659 (* 1 = 0.00202659 loss)
I0403 03:45:12.173936 28786 sgd_solver.cpp:106] Iteration 2550, lr = 5e-05
I0403 03:45:15.676442 28786 solver.cpp:228] Iteration 2555, loss = 0.00121092
I0403 03:45:15.676545 28786 solver.cpp:244]     Train net output #0: loss = 0.00121094 (* 1 = 0.00121094 loss)
I0403 03:45:15.869640 28786 sgd_solver.cpp:106] Iteration 2555, lr = 5e-05
I0403 03:45:19.340864 28786 solver.cpp:228] Iteration 2560, loss = 0.00112095
I0403 03:45:19.340951 28786 solver.cpp:244]     Train net output #0: loss = 0.00112097 (* 1 = 0.00112097 loss)
I0403 03:45:19.520449 28786 sgd_solver.cpp:106] Iteration 2560, lr = 5e-05
I0403 03:45:22.972002 28786 solver.cpp:228] Iteration 2565, loss = 0.000116458
I0403 03:45:22.972100 28786 solver.cpp:244]     Train net output #0: loss = 0.000116479 (* 1 = 0.000116479 loss)
I0403 03:45:23.155344 28786 sgd_solver.cpp:106] Iteration 2565, lr = 5e-05
I0403 03:45:26.666470 28786 solver.cpp:228] Iteration 2570, loss = 0.000481867
I0403 03:45:26.666582 28786 solver.cpp:244]     Train net output #0: loss = 0.000481888 (* 1 = 0.000481888 loss)
I0403 03:45:26.862416 28786 sgd_solver.cpp:106] Iteration 2570, lr = 5e-05
I0403 03:45:30.261924 28786 solver.cpp:228] Iteration 2575, loss = 0.000447227
I0403 03:45:30.262020 28786 solver.cpp:244]     Train net output #0: loss = 0.000447249 (* 1 = 0.000447249 loss)
I0403 03:45:30.444931 28786 sgd_solver.cpp:106] Iteration 2575, lr = 5e-05
I0403 03:45:33.871795 28786 solver.cpp:228] Iteration 2580, loss = 0.000241064
I0403 03:45:33.871878 28786 solver.cpp:244]     Train net output #0: loss = 0.000241086 (* 1 = 0.000241086 loss)
I0403 03:45:34.045714 28786 sgd_solver.cpp:106] Iteration 2580, lr = 5e-05
I0403 03:45:37.470736 28786 solver.cpp:228] Iteration 2585, loss = 0.000369634
I0403 03:45:37.471032 28786 solver.cpp:244]     Train net output #0: loss = 0.000369656 (* 1 = 0.000369656 loss)
I0403 03:45:37.645928 28786 sgd_solver.cpp:106] Iteration 2585, lr = 5e-05
I0403 03:45:41.070965 28786 solver.cpp:228] Iteration 2590, loss = 0.000203941
I0403 03:45:41.071063 28786 solver.cpp:244]     Train net output #0: loss = 0.000203963 (* 1 = 0.000203963 loss)
I0403 03:45:41.261071 28786 sgd_solver.cpp:106] Iteration 2590, lr = 5e-05
I0403 03:45:44.671552 28786 solver.cpp:228] Iteration 2595, loss = 0.00203297
I0403 03:45:44.671638 28786 solver.cpp:244]     Train net output #0: loss = 0.00203299 (* 1 = 0.00203299 loss)
I0403 03:45:44.845247 28786 sgd_solver.cpp:106] Iteration 2595, lr = 5e-05
I0403 03:45:48.304251 28786 solver.cpp:228] Iteration 2600, loss = 0.038558
I0403 03:45:48.305120 28786 solver.cpp:244]     Train net output #0: loss = 0.038558 (* 1 = 0.038558 loss)
I0403 03:45:48.485082 28786 sgd_solver.cpp:106] Iteration 2600, lr = 5e-05
I0403 03:45:51.916767 28786 solver.cpp:228] Iteration 2605, loss = 0.000463308
I0403 03:45:51.916847 28786 solver.cpp:244]     Train net output #0: loss = 0.000463331 (* 1 = 0.000463331 loss)
I0403 03:45:52.095298 28786 sgd_solver.cpp:106] Iteration 2605, lr = 5e-05
I0403 03:45:55.503674 28786 solver.cpp:228] Iteration 2610, loss = 0.000117008
I0403 03:45:55.503765 28786 solver.cpp:244]     Train net output #0: loss = 0.000117031 (* 1 = 0.000117031 loss)
I0403 03:45:55.685751 28786 sgd_solver.cpp:106] Iteration 2610, lr = 5e-05
I0403 03:45:59.116118 28786 solver.cpp:228] Iteration 2615, loss = 0.000284574
I0403 03:45:59.116205 28786 solver.cpp:244]     Train net output #0: loss = 0.000284597 (* 1 = 0.000284597 loss)
I0403 03:45:59.294728 28786 sgd_solver.cpp:106] Iteration 2615, lr = 5e-05
I0403 03:46:02.766654 28786 solver.cpp:228] Iteration 2620, loss = 0.000552827
I0403 03:46:02.766742 28786 solver.cpp:244]     Train net output #0: loss = 0.000552851 (* 1 = 0.000552851 loss)
I0403 03:46:02.945621 28786 sgd_solver.cpp:106] Iteration 2620, lr = 5e-05
I0403 03:46:06.408148 28786 solver.cpp:228] Iteration 2625, loss = 0.00100538
I0403 03:46:06.408246 28786 solver.cpp:244]     Train net output #0: loss = 0.00100541 (* 1 = 0.00100541 loss)
I0403 03:46:06.591656 28786 sgd_solver.cpp:106] Iteration 2625, lr = 5e-05
I0403 03:46:10.064327 28786 solver.cpp:228] Iteration 2630, loss = 0.000663503
I0403 03:46:10.064693 28786 solver.cpp:244]     Train net output #0: loss = 0.000663527 (* 1 = 0.000663527 loss)
I0403 03:46:10.257930 28786 sgd_solver.cpp:106] Iteration 2630, lr = 5e-05
I0403 03:46:13.775275 28786 solver.cpp:228] Iteration 2635, loss = 0.000965064
I0403 03:46:13.775362 28786 solver.cpp:244]     Train net output #0: loss = 0.000965087 (* 1 = 0.000965087 loss)
I0403 03:46:13.955437 28786 sgd_solver.cpp:106] Iteration 2635, lr = 5e-05
I0403 03:46:17.427786 28786 solver.cpp:228] Iteration 2640, loss = 0.00663422
I0403 03:46:17.427883 28786 solver.cpp:244]     Train net output #0: loss = 0.00663425 (* 1 = 0.00663425 loss)
I0403 03:46:17.631088 28786 sgd_solver.cpp:106] Iteration 2640, lr = 5e-05
I0403 03:46:21.111822 28786 solver.cpp:228] Iteration 2645, loss = 0.00637214
I0403 03:46:21.111912 28786 solver.cpp:244]     Train net output #0: loss = 0.00637217 (* 1 = 0.00637217 loss)
I0403 03:46:21.271178 28786 sgd_solver.cpp:106] Iteration 2645, lr = 5e-05
I0403 03:46:24.246183 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2650.caffemodel
I0403 03:46:27.081202 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2650.solverstate
I0403 03:46:28.997884 28786 solver.cpp:337] Iteration 2650, Testing net (#0)
I0403 03:48:08.177620 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972708
I0403 03:48:08.177947 28786 solver.cpp:404]     Test net output #1: loss = 0.111084 (* 1 = 0.111084 loss)
I0403 03:48:08.710707 28786 solver.cpp:228] Iteration 2650, loss = 0.000179739
I0403 03:48:08.710793 28786 solver.cpp:244]     Train net output #0: loss = 0.000179763 (* 1 = 0.000179763 loss)
I0403 03:48:08.861500 28786 sgd_solver.cpp:106] Iteration 2650, lr = 5e-05
I0403 03:48:12.386057 28786 solver.cpp:228] Iteration 2655, loss = 0.000435439
I0403 03:48:12.386155 28786 solver.cpp:244]     Train net output #0: loss = 0.000435462 (* 1 = 0.000435462 loss)
I0403 03:48:12.576869 28786 sgd_solver.cpp:106] Iteration 2655, lr = 5e-05
I0403 03:48:16.053021 28786 solver.cpp:228] Iteration 2660, loss = 0.0081186
I0403 03:48:16.053112 28786 solver.cpp:244]     Train net output #0: loss = 0.00811862 (* 1 = 0.00811862 loss)
I0403 03:48:16.204476 28786 sgd_solver.cpp:106] Iteration 2660, lr = 5e-05
I0403 03:48:19.701619 28786 solver.cpp:228] Iteration 2665, loss = 4.23891e-05
I0403 03:48:19.702730 28786 solver.cpp:244]     Train net output #0: loss = 4.24124e-05 (* 1 = 4.24124e-05 loss)
I0403 03:48:19.885229 28786 sgd_solver.cpp:106] Iteration 2665, lr = 5e-05
I0403 03:48:23.328105 28786 solver.cpp:228] Iteration 2670, loss = 0.000426442
I0403 03:48:23.328204 28786 solver.cpp:244]     Train net output #0: loss = 0.000426465 (* 1 = 0.000426465 loss)
I0403 03:48:23.542356 28786 sgd_solver.cpp:106] Iteration 2670, lr = 5e-05
I0403 03:48:27.098397 28786 solver.cpp:228] Iteration 2675, loss = 5.62363e-05
I0403 03:48:27.098508 28786 solver.cpp:244]     Train net output #0: loss = 5.62597e-05 (* 1 = 5.62597e-05 loss)
I0403 03:48:27.217520 28786 sgd_solver.cpp:106] Iteration 2675, lr = 5e-05
I0403 03:48:30.777432 28786 solver.cpp:228] Iteration 2680, loss = 0.000484117
I0403 03:48:30.777534 28786 solver.cpp:244]     Train net output #0: loss = 0.000484141 (* 1 = 0.000484141 loss)
I0403 03:48:31.025599 28786 sgd_solver.cpp:106] Iteration 2680, lr = 5e-05
I0403 03:48:34.544211 28786 solver.cpp:228] Iteration 2685, loss = 0.000461236
I0403 03:48:34.544322 28786 solver.cpp:244]     Train net output #0: loss = 0.000461259 (* 1 = 0.000461259 loss)
I0403 03:48:34.748044 28786 sgd_solver.cpp:106] Iteration 2685, lr = 5e-05
I0403 03:48:38.188889 28786 solver.cpp:228] Iteration 2690, loss = 0.000409807
I0403 03:48:38.189249 28786 solver.cpp:244]     Train net output #0: loss = 0.000409831 (* 1 = 0.000409831 loss)
I0403 03:48:38.379948 28786 sgd_solver.cpp:106] Iteration 2690, lr = 5e-05
I0403 03:48:41.927054 28786 solver.cpp:228] Iteration 2695, loss = 0.00148278
I0403 03:48:41.927144 28786 solver.cpp:244]     Train net output #0: loss = 0.0014828 (* 1 = 0.0014828 loss)
I0403 03:48:42.084642 28786 sgd_solver.cpp:106] Iteration 2695, lr = 5e-05
I0403 03:48:45.735852 28786 solver.cpp:228] Iteration 2700, loss = 0.000195193
I0403 03:48:45.735931 28786 solver.cpp:244]     Train net output #0: loss = 0.000195216 (* 1 = 0.000195216 loss)
I0403 03:48:45.897251 28786 sgd_solver.cpp:106] Iteration 2700, lr = 5e-05
I0403 03:48:49.586318 28786 solver.cpp:228] Iteration 2705, loss = 0.000486446
I0403 03:48:49.586416 28786 solver.cpp:244]     Train net output #0: loss = 0.000486469 (* 1 = 0.000486469 loss)
I0403 03:48:49.770763 28786 sgd_solver.cpp:106] Iteration 2705, lr = 5e-05
I0403 03:48:53.196156 28786 solver.cpp:228] Iteration 2710, loss = 0.00201834
I0403 03:48:53.196254 28786 solver.cpp:244]     Train net output #0: loss = 0.00201836 (* 1 = 0.00201836 loss)
I0403 03:48:53.385262 28786 sgd_solver.cpp:106] Iteration 2710, lr = 5e-05
I0403 03:48:56.961534 28786 solver.cpp:228] Iteration 2715, loss = 0.00155188
I0403 03:48:56.961630 28786 solver.cpp:244]     Train net output #0: loss = 0.00155191 (* 1 = 0.00155191 loss)
I0403 03:48:57.177222 28786 sgd_solver.cpp:106] Iteration 2715, lr = 5e-05
I0403 03:49:00.627378 28786 solver.cpp:228] Iteration 2720, loss = 0.00322633
I0403 03:49:00.627475 28786 solver.cpp:244]     Train net output #0: loss = 0.00322636 (* 1 = 0.00322636 loss)
I0403 03:49:00.815099 28786 sgd_solver.cpp:106] Iteration 2720, lr = 5e-05
I0403 03:49:04.251248 28786 solver.cpp:228] Iteration 2725, loss = 0.0031308
I0403 03:49:04.251349 28786 solver.cpp:244]     Train net output #0: loss = 0.00313082 (* 1 = 0.00313082 loss)
I0403 03:49:04.458214 28786 sgd_solver.cpp:106] Iteration 2725, lr = 5e-05
I0403 03:49:07.878300 28786 solver.cpp:228] Iteration 2730, loss = 0.00145431
I0403 03:49:07.878401 28786 solver.cpp:244]     Train net output #0: loss = 0.00145433 (* 1 = 0.00145433 loss)
I0403 03:49:08.080978 28786 sgd_solver.cpp:106] Iteration 2730, lr = 5e-05
I0403 03:49:11.580204 28786 solver.cpp:228] Iteration 2735, loss = 0.000946666
I0403 03:49:11.580540 28786 solver.cpp:244]     Train net output #0: loss = 0.000946689 (* 1 = 0.000946689 loss)
I0403 03:49:11.805402 28786 sgd_solver.cpp:106] Iteration 2735, lr = 5e-05
I0403 03:49:15.309021 28786 solver.cpp:228] Iteration 2740, loss = 0.000961169
I0403 03:49:15.309109 28786 solver.cpp:244]     Train net output #0: loss = 0.000961192 (* 1 = 0.000961192 loss)
I0403 03:49:15.460048 28786 sgd_solver.cpp:106] Iteration 2740, lr = 5e-05
I0403 03:49:18.975714 28786 solver.cpp:228] Iteration 2745, loss = 0.000790047
I0403 03:49:18.975800 28786 solver.cpp:244]     Train net output #0: loss = 0.000790071 (* 1 = 0.000790071 loss)
I0403 03:49:19.153278 28786 sgd_solver.cpp:106] Iteration 2745, lr = 5e-05
I0403 03:49:22.632331 28786 solver.cpp:228] Iteration 2750, loss = 0.000131502
I0403 03:49:22.632431 28786 solver.cpp:244]     Train net output #0: loss = 0.000131526 (* 1 = 0.000131526 loss)
I0403 03:49:22.868420 28786 sgd_solver.cpp:106] Iteration 2750, lr = 5e-05
I0403 03:49:26.328452 28786 solver.cpp:228] Iteration 2755, loss = 0.00464265
I0403 03:49:26.328553 28786 solver.cpp:244]     Train net output #0: loss = 0.00464268 (* 1 = 0.00464268 loss)
I0403 03:49:26.531719 28786 sgd_solver.cpp:106] Iteration 2755, lr = 5e-05
I0403 03:49:26.531966 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2756.caffemodel
I0403 03:49:29.210858 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2756.solverstate
I0403 03:49:30.998908 28786 solver.cpp:337] Iteration 2756, Testing net (#0)
I0403 03:51:10.185127 28786 solver.cpp:404]     Test net output #0: accuracy = 0.97273
I0403 03:51:10.185483 28786 solver.cpp:404]     Test net output #1: loss = 0.110751 (* 1 = 0.110751 loss)
I0403 03:51:13.759929 28786 solver.cpp:228] Iteration 2760, loss = 8.0559e-05
I0403 03:51:13.760023 28786 solver.cpp:244]     Train net output #0: loss = 8.05823e-05 (* 1 = 8.05823e-05 loss)
I0403 03:51:13.948573 28786 sgd_solver.cpp:106] Iteration 2760, lr = 5e-05
I0403 03:51:17.443634 28786 solver.cpp:228] Iteration 2765, loss = 3.72195e-05
I0403 03:51:17.443732 28786 solver.cpp:244]     Train net output #0: loss = 3.72429e-05 (* 1 = 3.72429e-05 loss)
I0403 03:51:17.669569 28786 sgd_solver.cpp:106] Iteration 2765, lr = 5e-05
I0403 03:51:21.131371 28786 solver.cpp:228] Iteration 2770, loss = 0.000335134
I0403 03:51:21.131464 28786 solver.cpp:244]     Train net output #0: loss = 0.000335157 (* 1 = 0.000335157 loss)
I0403 03:51:21.284638 28786 sgd_solver.cpp:106] Iteration 2770, lr = 5e-05
I0403 03:51:24.789961 28786 solver.cpp:228] Iteration 2775, loss = 0.00167285
I0403 03:51:24.790060 28786 solver.cpp:244]     Train net output #0: loss = 0.00167288 (* 1 = 0.00167288 loss)
I0403 03:51:24.978034 28786 sgd_solver.cpp:106] Iteration 2775, lr = 5e-05
I0403 03:51:28.414211 28786 solver.cpp:228] Iteration 2780, loss = 0.000522733
I0403 03:51:28.414309 28786 solver.cpp:244]     Train net output #0: loss = 0.000522756 (* 1 = 0.000522756 loss)
I0403 03:51:28.600230 28786 sgd_solver.cpp:106] Iteration 2780, lr = 5e-05
I0403 03:51:32.085438 28786 solver.cpp:228] Iteration 2785, loss = 0.00498274
I0403 03:51:32.085532 28786 solver.cpp:244]     Train net output #0: loss = 0.00498276 (* 1 = 0.00498276 loss)
I0403 03:51:32.289799 28786 sgd_solver.cpp:106] Iteration 2785, lr = 5e-05
I0403 03:51:35.760037 28786 solver.cpp:228] Iteration 2790, loss = 0.00173142
I0403 03:51:35.760136 28786 solver.cpp:244]     Train net output #0: loss = 0.00173144 (* 1 = 0.00173144 loss)
I0403 03:51:35.959190 28786 sgd_solver.cpp:106] Iteration 2790, lr = 5e-05
I0403 03:51:39.426380 28786 solver.cpp:228] Iteration 2795, loss = 0.00861986
I0403 03:51:39.426466 28786 solver.cpp:244]     Train net output #0: loss = 0.00861988 (* 1 = 0.00861988 loss)
I0403 03:51:39.605523 28786 sgd_solver.cpp:106] Iteration 2795, lr = 5e-05
I0403 03:51:43.091034 28786 solver.cpp:228] Iteration 2800, loss = 0.00447851
I0403 03:51:43.091357 28786 solver.cpp:244]     Train net output #0: loss = 0.00447853 (* 1 = 0.00447853 loss)
I0403 03:51:43.284848 28786 sgd_solver.cpp:106] Iteration 2800, lr = 5e-05
I0403 03:51:46.925627 28786 solver.cpp:228] Iteration 2805, loss = 0.000911202
I0403 03:51:46.925724 28786 solver.cpp:244]     Train net output #0: loss = 0.000911225 (* 1 = 0.000911225 loss)
I0403 03:51:47.107916 28786 sgd_solver.cpp:106] Iteration 2805, lr = 5e-05
I0403 03:51:50.602411 28786 solver.cpp:228] Iteration 2810, loss = 0.000754978
I0403 03:51:50.602509 28786 solver.cpp:244]     Train net output #0: loss = 0.000755001 (* 1 = 0.000755001 loss)
I0403 03:51:50.814535 28786 sgd_solver.cpp:106] Iteration 2810, lr = 5e-05
I0403 03:51:54.336830 28786 solver.cpp:228] Iteration 2815, loss = 0.000307938
I0403 03:51:54.336917 28786 solver.cpp:244]     Train net output #0: loss = 0.00030796 (* 1 = 0.00030796 loss)
I0403 03:51:54.517853 28786 sgd_solver.cpp:106] Iteration 2815, lr = 5e-05
I0403 03:51:58.000819 28786 solver.cpp:228] Iteration 2820, loss = 0.000193502
I0403 03:51:58.000917 28786 solver.cpp:244]     Train net output #0: loss = 0.000193524 (* 1 = 0.000193524 loss)
I0403 03:51:58.194582 28786 sgd_solver.cpp:106] Iteration 2820, lr = 5e-05
I0403 03:52:01.775071 28786 solver.cpp:228] Iteration 2825, loss = 0.000170012
I0403 03:52:01.775166 28786 solver.cpp:244]     Train net output #0: loss = 0.000170034 (* 1 = 0.000170034 loss)
I0403 03:52:01.976886 28786 sgd_solver.cpp:106] Iteration 2825, lr = 5e-05
I0403 03:52:05.438437 28786 solver.cpp:228] Iteration 2830, loss = 0.000708596
I0403 03:52:05.438524 28786 solver.cpp:244]     Train net output #0: loss = 0.000708618 (* 1 = 0.000708618 loss)
I0403 03:52:05.601224 28786 sgd_solver.cpp:106] Iteration 2830, lr = 5e-05
I0403 03:52:09.300015 28786 solver.cpp:228] Iteration 2835, loss = 9.05948e-05
I0403 03:52:09.300104 28786 solver.cpp:244]     Train net output #0: loss = 9.06169e-05 (* 1 = 9.06169e-05 loss)
I0403 03:52:09.404031 28786 sgd_solver.cpp:106] Iteration 2835, lr = 5e-05
I0403 03:52:13.054709 28786 solver.cpp:228] Iteration 2840, loss = 0.000200232
I0403 03:52:13.054800 28786 solver.cpp:244]     Train net output #0: loss = 0.000200254 (* 1 = 0.000200254 loss)
I0403 03:52:13.206521 28786 sgd_solver.cpp:106] Iteration 2840, lr = 5e-05
I0403 03:52:16.734946 28786 solver.cpp:228] Iteration 2845, loss = 0.00111688
I0403 03:52:16.735036 28786 solver.cpp:244]     Train net output #0: loss = 0.0011169 (* 1 = 0.0011169 loss)
I0403 03:52:16.914821 28786 sgd_solver.cpp:106] Iteration 2845, lr = 5e-05
I0403 03:52:20.388531 28786 solver.cpp:228] Iteration 2850, loss = 0.000175195
I0403 03:52:20.388635 28786 solver.cpp:244]     Train net output #0: loss = 0.000175217 (* 1 = 0.000175217 loss)
I0403 03:52:20.590243 28786 sgd_solver.cpp:106] Iteration 2850, lr = 5e-05
I0403 03:52:24.022370 28786 solver.cpp:228] Iteration 2855, loss = 0.000240193
I0403 03:52:24.022474 28786 solver.cpp:244]     Train net output #0: loss = 0.000240215 (* 1 = 0.000240215 loss)
I0403 03:52:24.217744 28786 sgd_solver.cpp:106] Iteration 2855, lr = 5e-05
I0403 03:52:27.697487 28786 solver.cpp:228] Iteration 2860, loss = 0.000270201
I0403 03:52:27.697577 28786 solver.cpp:244]     Train net output #0: loss = 0.000270224 (* 1 = 0.000270224 loss)
I0403 03:52:27.922109 28786 sgd_solver.cpp:106] Iteration 2860, lr = 5e-05
I0403 03:52:28.715833 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2862.caffemodel
I0403 03:52:31.335620 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2862.solverstate
I0403 03:52:33.171645 28786 solver.cpp:337] Iteration 2862, Testing net (#0)
I0403 03:54:12.376902 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972661
I0403 03:54:12.377235 28786 solver.cpp:404]     Test net output #1: loss = 0.111551 (* 1 = 0.111551 loss)
I0403 03:54:15.120707 28786 solver.cpp:228] Iteration 2865, loss = 9.34312e-05
I0403 03:54:15.120791 28786 solver.cpp:244]     Train net output #0: loss = 9.34537e-05 (* 1 = 9.34537e-05 loss)
I0403 03:54:15.298002 28786 sgd_solver.cpp:106] Iteration 2865, lr = 5e-05
I0403 03:54:18.825739 28786 solver.cpp:228] Iteration 2870, loss = 0.00300181
I0403 03:54:18.826756 28786 solver.cpp:244]     Train net output #0: loss = 0.00300183 (* 1 = 0.00300183 loss)
I0403 03:54:18.999464 28786 sgd_solver.cpp:106] Iteration 2870, lr = 5e-05
I0403 03:54:22.635680 28786 solver.cpp:228] Iteration 2875, loss = 0.000573464
I0403 03:54:22.635781 28786 solver.cpp:244]     Train net output #0: loss = 0.000573486 (* 1 = 0.000573486 loss)
I0403 03:54:22.841513 28786 sgd_solver.cpp:106] Iteration 2875, lr = 5e-05
I0403 03:54:26.317353 28786 solver.cpp:228] Iteration 2880, loss = 0.00161418
I0403 03:54:26.317448 28786 solver.cpp:244]     Train net output #0: loss = 0.0016142 (* 1 = 0.0016142 loss)
I0403 03:54:26.505360 28786 sgd_solver.cpp:106] Iteration 2880, lr = 5e-05
I0403 03:54:29.967342 28786 solver.cpp:228] Iteration 2885, loss = 0.00029227
I0403 03:54:29.967430 28786 solver.cpp:244]     Train net output #0: loss = 0.000292292 (* 1 = 0.000292292 loss)
I0403 03:54:30.146183 28786 sgd_solver.cpp:106] Iteration 2885, lr = 5e-05
I0403 03:54:33.556561 28786 solver.cpp:228] Iteration 2890, loss = 0.000628426
I0403 03:54:33.556658 28786 solver.cpp:244]     Train net output #0: loss = 0.000628448 (* 1 = 0.000628448 loss)
I0403 03:54:33.749286 28786 sgd_solver.cpp:106] Iteration 2890, lr = 5e-05
I0403 03:54:37.177698 28786 solver.cpp:228] Iteration 2895, loss = 0.00224984
I0403 03:54:37.177798 28786 solver.cpp:244]     Train net output #0: loss = 0.00224986 (* 1 = 0.00224986 loss)
I0403 03:54:37.378116 28786 sgd_solver.cpp:106] Iteration 2895, lr = 5e-05
I0403 03:54:40.846226 28786 solver.cpp:228] Iteration 2900, loss = 0.00087968
I0403 03:54:40.846313 28786 solver.cpp:244]     Train net output #0: loss = 0.000879702 (* 1 = 0.000879702 loss)
I0403 03:54:41.025367 28786 sgd_solver.cpp:106] Iteration 2900, lr = 5e-05
I0403 03:54:44.482086 28786 solver.cpp:228] Iteration 2905, loss = 0.00385368
I0403 03:54:44.482440 28786 solver.cpp:244]     Train net output #0: loss = 0.0038537 (* 1 = 0.0038537 loss)
I0403 03:54:44.657457 28786 sgd_solver.cpp:106] Iteration 2905, lr = 5e-05
I0403 03:54:48.071854 28786 solver.cpp:228] Iteration 2910, loss = 0.000305709
I0403 03:54:48.071948 28786 solver.cpp:244]     Train net output #0: loss = 0.000305731 (* 1 = 0.000305731 loss)
I0403 03:54:48.268121 28786 sgd_solver.cpp:106] Iteration 2910, lr = 5e-05
I0403 03:54:51.733896 28786 solver.cpp:228] Iteration 2915, loss = 0.00526332
I0403 03:54:51.733973 28786 solver.cpp:244]     Train net output #0: loss = 0.00526334 (* 1 = 0.00526334 loss)
I0403 03:54:51.916124 28786 sgd_solver.cpp:106] Iteration 2915, lr = 5e-05
I0403 03:54:55.323438 28786 solver.cpp:228] Iteration 2920, loss = 0.000265988
I0403 03:54:55.323552 28786 solver.cpp:244]     Train net output #0: loss = 0.00026601 (* 1 = 0.00026601 loss)
I0403 03:54:55.525972 28786 sgd_solver.cpp:106] Iteration 2920, lr = 5e-05
I0403 03:54:58.957938 28786 solver.cpp:228] Iteration 2925, loss = 0.000440143
I0403 03:54:58.958027 28786 solver.cpp:244]     Train net output #0: loss = 0.000440165 (* 1 = 0.000440165 loss)
I0403 03:54:59.133540 28786 sgd_solver.cpp:106] Iteration 2925, lr = 5e-05
I0403 03:55:02.574199 28786 solver.cpp:228] Iteration 2930, loss = 0.00056364
I0403 03:55:02.574295 28786 solver.cpp:244]     Train net output #0: loss = 0.000563664 (* 1 = 0.000563664 loss)
I0403 03:55:02.757341 28786 sgd_solver.cpp:106] Iteration 2930, lr = 5e-05
I0403 03:55:06.195296 28786 solver.cpp:228] Iteration 2935, loss = 0.000725552
I0403 03:55:06.201117 28786 solver.cpp:244]     Train net output #0: loss = 0.000725576 (* 1 = 0.000725576 loss)
I0403 03:55:06.373159 28786 sgd_solver.cpp:106] Iteration 2935, lr = 5e-05
I0403 03:55:09.869900 28786 solver.cpp:228] Iteration 2940, loss = 0.000626233
I0403 03:55:09.869978 28786 solver.cpp:244]     Train net output #0: loss = 0.000626257 (* 1 = 0.000626257 loss)
I0403 03:55:10.039947 28786 sgd_solver.cpp:106] Iteration 2940, lr = 5e-05
I0403 03:55:13.492410 28786 solver.cpp:228] Iteration 2945, loss = 0.00332563
I0403 03:55:13.492499 28786 solver.cpp:244]     Train net output #0: loss = 0.00332565 (* 1 = 0.00332565 loss)
I0403 03:55:13.665714 28786 sgd_solver.cpp:106] Iteration 2945, lr = 5e-05
I0403 03:55:17.158373 28786 solver.cpp:228] Iteration 2950, loss = 0.00256629
I0403 03:55:17.162626 28786 solver.cpp:244]     Train net output #0: loss = 0.00256631 (* 1 = 0.00256631 loss)
I0403 03:55:17.409193 28786 sgd_solver.cpp:106] Iteration 2950, lr = 5e-05
I0403 03:55:20.883050 28786 solver.cpp:228] Iteration 2955, loss = 0.00093764
I0403 03:55:20.889070 28786 solver.cpp:244]     Train net output #0: loss = 0.000937664 (* 1 = 0.000937664 loss)
I0403 03:55:21.098356 28786 sgd_solver.cpp:106] Iteration 2955, lr = 5e-05
I0403 03:55:24.542224 28786 solver.cpp:228] Iteration 2960, loss = 0.0177786
I0403 03:55:24.548658 28786 solver.cpp:244]     Train net output #0: loss = 0.0177786 (* 1 = 0.0177786 loss)
I0403 03:55:24.734834 28786 sgd_solver.cpp:106] Iteration 2960, lr = 5e-05
I0403 03:55:28.156265 28786 solver.cpp:228] Iteration 2965, loss = 0.0129297
I0403 03:55:28.162924 28786 solver.cpp:244]     Train net output #0: loss = 0.0129298 (* 1 = 0.0129298 loss)
I0403 03:55:28.337062 28786 sgd_solver.cpp:106] Iteration 2965, lr = 5e-05
I0403 03:55:29.778462 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2968.caffemodel
I0403 03:55:32.539252 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_2968.solverstate
I0403 03:55:34.437116 28786 solver.cpp:337] Iteration 2968, Testing net (#0)
I0403 03:57:13.609639 28786 solver.cpp:404]     Test net output #0: accuracy = 0.97257
I0403 03:57:13.609963 28786 solver.cpp:404]     Test net output #1: loss = 0.111485 (* 1 = 0.111485 loss)
I0403 03:57:15.556938 28786 solver.cpp:228] Iteration 2970, loss = 0.000208676
I0403 03:57:15.557019 28786 solver.cpp:244]     Train net output #0: loss = 0.0002087 (* 1 = 0.0002087 loss)
I0403 03:57:15.734401 28786 sgd_solver.cpp:106] Iteration 2970, lr = 5e-05
I0403 03:57:19.201681 28786 solver.cpp:228] Iteration 2975, loss = 0.000197528
I0403 03:57:19.201781 28786 solver.cpp:244]     Train net output #0: loss = 0.000197551 (* 1 = 0.000197551 loss)
I0403 03:57:19.386811 28786 sgd_solver.cpp:106] Iteration 2975, lr = 5e-05
I0403 03:57:22.937414 28786 solver.cpp:228] Iteration 2980, loss = 0.00609774
I0403 03:57:22.937517 28786 solver.cpp:244]     Train net output #0: loss = 0.00609776 (* 1 = 0.00609776 loss)
I0403 03:57:23.128126 28786 sgd_solver.cpp:106] Iteration 2980, lr = 5e-05
I0403 03:57:26.600685 28786 solver.cpp:228] Iteration 2985, loss = 0.000428974
I0403 03:57:26.600772 28786 solver.cpp:244]     Train net output #0: loss = 0.000428997 (* 1 = 0.000428997 loss)
I0403 03:57:26.775331 28786 sgd_solver.cpp:106] Iteration 2985, lr = 5e-05
I0403 03:57:30.272300 28786 solver.cpp:228] Iteration 2990, loss = 0.000623429
I0403 03:57:30.272387 28786 solver.cpp:244]     Train net output #0: loss = 0.000623452 (* 1 = 0.000623452 loss)
I0403 03:57:30.423871 28786 sgd_solver.cpp:106] Iteration 2990, lr = 5e-05
I0403 03:57:33.951481 28786 solver.cpp:228] Iteration 2995, loss = 0.000142608
I0403 03:57:33.951575 28786 solver.cpp:244]     Train net output #0: loss = 0.000142631 (* 1 = 0.000142631 loss)
I0403 03:57:34.141376 28786 sgd_solver.cpp:106] Iteration 2995, lr = 5e-05
I0403 03:57:37.628237 28786 solver.cpp:228] Iteration 3000, loss = 0.0284069
I0403 03:57:37.628335 28786 solver.cpp:244]     Train net output #0: loss = 0.0284069 (* 1 = 0.0284069 loss)
I0403 03:57:37.867377 28786 sgd_solver.cpp:106] Iteration 3000, lr = 5e-05
I0403 03:57:41.335153 28786 solver.cpp:228] Iteration 3005, loss = 0.000142672
I0403 03:57:41.335249 28786 solver.cpp:244]     Train net output #0: loss = 0.000142697 (* 1 = 0.000142697 loss)
I0403 03:57:41.531203 28786 sgd_solver.cpp:106] Iteration 3005, lr = 5e-05
I0403 03:57:44.964691 28786 solver.cpp:228] Iteration 3010, loss = 5.4351e-05
I0403 03:57:44.965042 28786 solver.cpp:244]     Train net output #0: loss = 5.43752e-05 (* 1 = 5.43752e-05 loss)
I0403 03:57:45.145182 28786 sgd_solver.cpp:106] Iteration 3010, lr = 5e-05
I0403 03:57:48.606640 28786 solver.cpp:228] Iteration 3015, loss = 0.000720333
I0403 03:57:48.606729 28786 solver.cpp:244]     Train net output #0: loss = 0.000720358 (* 1 = 0.000720358 loss)
I0403 03:57:48.786301 28786 sgd_solver.cpp:106] Iteration 3015, lr = 5e-05
I0403 03:57:52.236635 28786 solver.cpp:228] Iteration 3020, loss = 0.00193303
I0403 03:57:52.236732 28786 solver.cpp:244]     Train net output #0: loss = 0.00193306 (* 1 = 0.00193306 loss)
I0403 03:57:52.415529 28786 sgd_solver.cpp:106] Iteration 3020, lr = 5e-05
I0403 03:57:55.845626 28786 solver.cpp:228] Iteration 3025, loss = 0.000356135
I0403 03:57:55.845713 28786 solver.cpp:244]     Train net output #0: loss = 0.000356159 (* 1 = 0.000356159 loss)
I0403 03:57:56.019821 28786 sgd_solver.cpp:106] Iteration 3025, lr = 5e-05
I0403 03:57:59.436828 28786 solver.cpp:228] Iteration 3030, loss = 0.00188957
I0403 03:57:59.436925 28786 solver.cpp:244]     Train net output #0: loss = 0.0018896 (* 1 = 0.0018896 loss)
I0403 03:57:59.619961 28786 sgd_solver.cpp:106] Iteration 3030, lr = 5e-05
I0403 03:58:03.041365 28786 solver.cpp:228] Iteration 3035, loss = 0.00118773
I0403 03:58:03.041463 28786 solver.cpp:244]     Train net output #0: loss = 0.00118776 (* 1 = 0.00118776 loss)
I0403 03:58:03.223604 28786 sgd_solver.cpp:106] Iteration 3035, lr = 5e-05
I0403 03:58:06.659600 28786 solver.cpp:228] Iteration 3040, loss = 0.00452341
I0403 03:58:06.659699 28786 solver.cpp:244]     Train net output #0: loss = 0.00452343 (* 1 = 0.00452343 loss)
I0403 03:58:06.844749 28786 sgd_solver.cpp:106] Iteration 3040, lr = 5e-05
I0403 03:58:10.267622 28786 solver.cpp:228] Iteration 3045, loss = 0.00336933
I0403 03:58:10.267724 28786 solver.cpp:244]     Train net output #0: loss = 0.00336936 (* 1 = 0.00336936 loss)
I0403 03:58:10.451385 28786 sgd_solver.cpp:106] Iteration 3045, lr = 5e-05
I0403 03:58:13.905050 28786 solver.cpp:228] Iteration 3050, loss = 0.00146002
I0403 03:58:13.905136 28786 solver.cpp:244]     Train net output #0: loss = 0.00146004 (* 1 = 0.00146004 loss)
I0403 03:58:14.066022 28786 sgd_solver.cpp:106] Iteration 3050, lr = 5e-05
I0403 03:58:17.598129 28786 solver.cpp:228] Iteration 3055, loss = 0.00272976
I0403 03:58:17.598448 28786 solver.cpp:244]     Train net output #0: loss = 0.00272979 (* 1 = 0.00272979 loss)
I0403 03:58:17.784343 28786 sgd_solver.cpp:106] Iteration 3055, lr = 5e-05
I0403 03:58:21.190982 28786 solver.cpp:228] Iteration 3060, loss = 0.00775706
I0403 03:58:21.191063 28786 solver.cpp:244]     Train net output #0: loss = 0.00775708 (* 1 = 0.00775708 loss)
I0403 03:58:21.370324 28786 sgd_solver.cpp:106] Iteration 3060, lr = 5e-05
I0403 03:58:24.785733 28786 solver.cpp:228] Iteration 3065, loss = 0.000107023
I0403 03:58:24.785821 28786 solver.cpp:244]     Train net output #0: loss = 0.000107047 (* 1 = 0.000107047 loss)
I0403 03:58:24.955790 28786 sgd_solver.cpp:106] Iteration 3065, lr = 5e-05
I0403 03:58:28.400660 28786 solver.cpp:228] Iteration 3070, loss = 0.00203148
I0403 03:58:28.400748 28786 solver.cpp:244]     Train net output #0: loss = 0.00203151 (* 1 = 0.00203151 loss)
I0403 03:58:28.571007 28786 sgd_solver.cpp:106] Iteration 3070, lr = 5e-05
I0403 03:58:30.763265 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_3074.caffemodel
I0403 03:58:33.511838 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_3074.solverstate
I0403 03:58:35.431169 28786 solver.cpp:337] Iteration 3074, Testing net (#0)
I0403 04:00:14.607686 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972547
I0403 04:00:14.608011 28786 solver.cpp:404]     Test net output #1: loss = 0.111564 (* 1 = 0.111564 loss)
I0403 04:00:15.851824 28786 solver.cpp:228] Iteration 3075, loss = 0.0106341
I0403 04:00:15.851902 28786 solver.cpp:244]     Train net output #0: loss = 0.0106341 (* 1 = 0.0106341 loss)
I0403 04:00:16.020823 28786 sgd_solver.cpp:106] Iteration 3075, lr = 5e-05
I0403 04:00:19.549340 28786 solver.cpp:228] Iteration 3080, loss = 0.00110131
I0403 04:00:19.549439 28786 solver.cpp:244]     Train net output #0: loss = 0.00110133 (* 1 = 0.00110133 loss)
I0403 04:00:19.783470 28786 sgd_solver.cpp:106] Iteration 3080, lr = 5e-05
I0403 04:00:23.215205 28786 solver.cpp:228] Iteration 3085, loss = 0.000703769
I0403 04:00:23.215306 28786 solver.cpp:244]     Train net output #0: loss = 0.000703792 (* 1 = 0.000703792 loss)
I0403 04:00:23.447469 28786 sgd_solver.cpp:106] Iteration 3085, lr = 5e-05
I0403 04:00:26.902861 28786 solver.cpp:228] Iteration 3090, loss = 0.000860994
I0403 04:00:26.902942 28786 solver.cpp:244]     Train net output #0: loss = 0.000861018 (* 1 = 0.000861018 loss)
I0403 04:00:27.073748 28786 sgd_solver.cpp:106] Iteration 3090, lr = 5e-05
I0403 04:00:30.551393 28786 solver.cpp:228] Iteration 3095, loss = 0.00197118
I0403 04:00:30.551491 28786 solver.cpp:244]     Train net output #0: loss = 0.0019712 (* 1 = 0.0019712 loss)
I0403 04:00:30.764426 28786 sgd_solver.cpp:106] Iteration 3095, lr = 5e-05
I0403 04:00:34.184527 28786 solver.cpp:228] Iteration 3100, loss = 0.000506052
I0403 04:00:34.184622 28786 solver.cpp:244]     Train net output #0: loss = 0.000506076 (* 1 = 0.000506076 loss)
I0403 04:00:34.364017 28786 sgd_solver.cpp:106] Iteration 3100, lr = 5e-05
I0403 04:00:37.842257 28786 solver.cpp:228] Iteration 3105, loss = 0.000521765
I0403 04:00:37.842355 28786 solver.cpp:244]     Train net output #0: loss = 0.000521789 (* 1 = 0.000521789 loss)
I0403 04:00:38.030261 28786 sgd_solver.cpp:106] Iteration 3105, lr = 5e-05
I0403 04:00:41.477990 28786 solver.cpp:228] Iteration 3110, loss = 0.000946222
I0403 04:00:41.478087 28786 solver.cpp:244]     Train net output #0: loss = 0.000946247 (* 1 = 0.000946247 loss)
I0403 04:00:41.661901 28786 sgd_solver.cpp:106] Iteration 3110, lr = 5e-05
I0403 04:00:45.122314 28786 solver.cpp:228] Iteration 3115, loss = 0.00318997
I0403 04:00:45.122655 28786 solver.cpp:244]     Train net output #0: loss = 0.00318999 (* 1 = 0.00318999 loss)
I0403 04:00:45.290297 28786 sgd_solver.cpp:106] Iteration 3115, lr = 5e-05
I0403 04:00:48.830394 28786 solver.cpp:228] Iteration 3120, loss = 0.000355277
I0403 04:00:48.830492 28786 solver.cpp:244]     Train net output #0: loss = 0.000355303 (* 1 = 0.000355303 loss)
I0403 04:00:49.058997 28786 sgd_solver.cpp:106] Iteration 3120, lr = 5e-05
I0403 04:00:52.505007 28786 solver.cpp:228] Iteration 3125, loss = 0.00259374
I0403 04:00:52.505103 28786 solver.cpp:244]     Train net output #0: loss = 0.00259376 (* 1 = 0.00259376 loss)
I0403 04:00:52.690014 28786 sgd_solver.cpp:106] Iteration 3125, lr = 5e-05
I0403 04:00:56.119019 28786 solver.cpp:228] Iteration 3130, loss = 0.00328798
I0403 04:00:56.119115 28786 solver.cpp:244]     Train net output #0: loss = 0.003288 (* 1 = 0.003288 loss)
I0403 04:00:56.311110 28786 sgd_solver.cpp:106] Iteration 3130, lr = 5e-05
I0403 04:00:59.763622 28786 solver.cpp:228] Iteration 3135, loss = 0.000149886
I0403 04:00:59.763710 28786 solver.cpp:244]     Train net output #0: loss = 0.000149911 (* 1 = 0.000149911 loss)
I0403 04:00:59.914393 28786 sgd_solver.cpp:106] Iteration 3135, lr = 5e-05
I0403 04:01:03.433763 28786 solver.cpp:228] Iteration 3140, loss = 0.000640353
I0403 04:01:03.433871 28786 solver.cpp:244]     Train net output #0: loss = 0.000640378 (* 1 = 0.000640378 loss)
I0403 04:01:03.665738 28786 sgd_solver.cpp:106] Iteration 3140, lr = 5e-05
I0403 04:01:07.127192 28786 solver.cpp:228] Iteration 3145, loss = 0.00133751
I0403 04:01:07.127297 28786 solver.cpp:244]     Train net output #0: loss = 0.00133753 (* 1 = 0.00133753 loss)
I0403 04:01:07.313653 28786 sgd_solver.cpp:106] Iteration 3145, lr = 5e-05
I0403 04:01:10.778930 28786 solver.cpp:228] Iteration 3150, loss = 9.8229e-05
I0403 04:01:10.779017 28786 solver.cpp:244]     Train net output #0: loss = 9.82542e-05 (* 1 = 9.82542e-05 loss)
I0403 04:01:10.945780 28786 sgd_solver.cpp:106] Iteration 3150, lr = 5e-05
I0403 04:01:14.407372 28786 solver.cpp:228] Iteration 3155, loss = 0.000222495
I0403 04:01:14.407459 28786 solver.cpp:244]     Train net output #0: loss = 0.00022252 (* 1 = 0.00022252 loss)
I0403 04:01:14.585484 28786 sgd_solver.cpp:106] Iteration 3155, lr = 5e-05
I0403 04:01:18.021729 28786 solver.cpp:228] Iteration 3160, loss = 0.000462492
I0403 04:01:18.022050 28786 solver.cpp:244]     Train net output #0: loss = 0.000462517 (* 1 = 0.000462517 loss)
I0403 04:01:18.191972 28786 sgd_solver.cpp:106] Iteration 3160, lr = 5e-05
I0403 04:01:21.614759 28786 solver.cpp:228] Iteration 3165, loss = 0.000332959
I0403 04:01:21.614846 28786 solver.cpp:244]     Train net output #0: loss = 0.000332984 (* 1 = 0.000332984 loss)
I0403 04:01:21.784530 28786 sgd_solver.cpp:106] Iteration 3165, lr = 5e-05
I0403 04:01:25.264765 28786 solver.cpp:228] Iteration 3170, loss = 0.000141094
I0403 04:01:25.264847 28786 solver.cpp:244]     Train net output #0: loss = 0.000141119 (* 1 = 0.000141119 loss)
I0403 04:01:25.441748 28786 sgd_solver.cpp:106] Iteration 3170, lr = 5e-05
I0403 04:01:28.850687 28786 solver.cpp:228] Iteration 3175, loss = 0.00997949
I0403 04:01:28.850783 28786 solver.cpp:244]     Train net output #0: loss = 0.00997951 (* 1 = 0.00997951 loss)
I0403 04:01:29.117573 28786 sgd_solver.cpp:106] Iteration 3175, lr = 5e-05
I0403 04:01:32.141052 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_3180.caffemodel
I0403 04:01:34.802156 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_3180.solverstate
I0403 04:01:36.605103 28786 solver.cpp:337] Iteration 3180, Testing net (#0)
I0403 04:03:15.768376 28786 solver.cpp:404]     Test net output #0: accuracy = 0.972616
I0403 04:03:15.768682 28786 solver.cpp:404]     Test net output #1: loss = 0.112055 (* 1 = 0.112055 loss)
I0403 04:03:16.288338 28786 solver.cpp:228] Iteration 3180, loss = 0.00047512
I0403 04:03:16.288420 28786 solver.cpp:244]     Train net output #0: loss = 0.000475145 (* 1 = 0.000475145 loss)
I0403 04:03:16.456632 28786 sgd_solver.cpp:106] Iteration 3180, lr = 5e-05
I0403 04:03:19.936046 28786 solver.cpp:228] Iteration 3185, loss = 0.00116375
I0403 04:03:19.936143 28786 solver.cpp:244]     Train net output #0: loss = 0.00116377 (* 1 = 0.00116377 loss)
I0403 04:03:20.119689 28786 sgd_solver.cpp:106] Iteration 3185, lr = 5e-05
I0403 04:03:23.581501 28786 solver.cpp:228] Iteration 3190, loss = 0.000395636
I0403 04:03:23.581605 28786 solver.cpp:244]     Train net output #0: loss = 0.000395661 (* 1 = 0.000395661 loss)
I0403 04:03:23.790210 28786 sgd_solver.cpp:106] Iteration 3190, lr = 5e-05
I0403 04:03:27.213218 28786 solver.cpp:228] Iteration 3195, loss = 0.00204202
I0403 04:03:27.213320 28786 solver.cpp:244]     Train net output #0: loss = 0.00204205 (* 1 = 0.00204205 loss)
I0403 04:03:27.418062 28786 sgd_solver.cpp:106] Iteration 3195, lr = 5e-05
I0403 04:03:29.577569 28786 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_3199.caffemodel
I0403 04:03:32.224293 28786 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-20-80_finetune/snapshots__iter_3199.solverstate
I0403 04:03:34.023464 28786 solver.cpp:322] Optimization Done.
I0403 04:03:34.132030 28786 caffe.cpp:222] Optimization Done.
