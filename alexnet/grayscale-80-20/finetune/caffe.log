I0403 02:30:28.015636  2203 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:28.018873  2203 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:28.018906  2203 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.235110  2203 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.236737  2203 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.238245  2203 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.003212  2203 solver.cpp:48] Initializing solver from parameters: 
test_iter: 106
test_interval: 436
base_lr: 0.005
display: 21
max_iter: 13085
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 4361
snapshot: 436
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.031016  2203 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.041334  2203 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.041473  2203 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.043162  2203 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-80-20/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.044287  2203 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.046223  2203 net.cpp:91] Creating Layer data
I0403 02:30:37.046342  2203 net.cpp:399] data -> data
I0403 02:30:37.046464  2203 net.cpp:399] data -> label
I0403 02:30:37.046561  2203 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-80-20/mean.binaryproto
I0403 02:30:37.068290  2211 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-80-20/train_db
I0403 02:30:37.093698  2203 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.231467  2203 net.cpp:141] Setting up data
I0403 02:30:37.231602  2203 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.231659  2203 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.231698  2203 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.231791  2203 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.231858  2203 net.cpp:91] Creating Layer conv1
I0403 02:30:37.231931  2203 net.cpp:425] conv1 <- data
I0403 02:30:37.231972  2203 net.cpp:399] conv1 -> conv1
I0403 02:30:37.235337  2203 net.cpp:141] Setting up conv1
I0403 02:30:37.235374  2203 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.235396  2203 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.235468  2203 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.235530  2203 net.cpp:91] Creating Layer relu1
I0403 02:30:37.235558  2203 net.cpp:425] relu1 <- conv1
I0403 02:30:37.235580  2203 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.235630  2203 net.cpp:141] Setting up relu1
I0403 02:30:37.235656  2203 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.235672  2203 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.235689  2203 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.235713  2203 net.cpp:91] Creating Layer norm1
I0403 02:30:37.235770  2203 net.cpp:425] norm1 <- conv1
I0403 02:30:37.235795  2203 net.cpp:399] norm1 -> norm1
I0403 02:30:37.241263  2203 net.cpp:141] Setting up norm1
I0403 02:30:37.241312  2203 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.241334  2203 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.241363  2203 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.241408  2203 net.cpp:91] Creating Layer pool1
I0403 02:30:37.241441  2203 net.cpp:425] pool1 <- norm1
I0403 02:30:37.241463  2203 net.cpp:399] pool1 -> pool1
I0403 02:30:37.241575  2203 net.cpp:141] Setting up pool1
I0403 02:30:37.241607  2203 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.241627  2203 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.241665  2203 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.241720  2203 net.cpp:91] Creating Layer conv2
I0403 02:30:37.241804  2203 net.cpp:425] conv2 <- pool1
I0403 02:30:37.241870  2203 net.cpp:399] conv2 -> conv2
I0403 02:30:37.243433  2213 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.262420  2203 net.cpp:141] Setting up conv2
I0403 02:30:37.262459  2203 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.262480  2203 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.262504  2203 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.262538  2203 net.cpp:91] Creating Layer relu2
I0403 02:30:37.262559  2203 net.cpp:425] relu2 <- conv2
I0403 02:30:37.262581  2203 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.262604  2203 net.cpp:141] Setting up relu2
I0403 02:30:37.262626  2203 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.262644  2203 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.262660  2203 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.262682  2203 net.cpp:91] Creating Layer norm2
I0403 02:30:37.262702  2203 net.cpp:425] norm2 <- conv2
I0403 02:30:37.262723  2203 net.cpp:399] norm2 -> norm2
I0403 02:30:37.262780  2203 net.cpp:141] Setting up norm2
I0403 02:30:37.262806  2203 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.262825  2203 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.262843  2203 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.262869  2203 net.cpp:91] Creating Layer pool2
I0403 02:30:37.262889  2203 net.cpp:425] pool2 <- norm2
I0403 02:30:37.262912  2203 net.cpp:399] pool2 -> pool2
I0403 02:30:37.262966  2203 net.cpp:141] Setting up pool2
I0403 02:30:37.262994  2203 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.263011  2203 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.263030  2203 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.263056  2203 net.cpp:91] Creating Layer conv3
I0403 02:30:37.263077  2203 net.cpp:425] conv3 <- pool2
I0403 02:30:37.263101  2203 net.cpp:399] conv3 -> conv3
I0403 02:30:37.304880  2203 net.cpp:141] Setting up conv3
I0403 02:30:37.304920  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.304940  2203 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.304966  2203 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.304991  2203 net.cpp:91] Creating Layer relu3
I0403 02:30:37.305013  2203 net.cpp:425] relu3 <- conv3
I0403 02:30:37.305035  2203 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.305059  2203 net.cpp:141] Setting up relu3
I0403 02:30:37.305081  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.305099  2203 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.305117  2203 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.305143  2203 net.cpp:91] Creating Layer conv4
I0403 02:30:37.305166  2203 net.cpp:425] conv4 <- conv3
I0403 02:30:37.305189  2203 net.cpp:399] conv4 -> conv4
I0403 02:30:37.336655  2203 net.cpp:141] Setting up conv4
I0403 02:30:37.336695  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.336715  2203 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.336758  2203 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.336786  2203 net.cpp:91] Creating Layer relu4
I0403 02:30:37.336807  2203 net.cpp:425] relu4 <- conv4
I0403 02:30:37.336829  2203 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.336854  2203 net.cpp:141] Setting up relu4
I0403 02:30:37.336874  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.336892  2203 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.336910  2203 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.336935  2203 net.cpp:91] Creating Layer conv5
I0403 02:30:37.336958  2203 net.cpp:425] conv5 <- conv4
I0403 02:30:37.336982  2203 net.cpp:399] conv5 -> conv5
I0403 02:30:37.358042  2203 net.cpp:141] Setting up conv5
I0403 02:30:37.358081  2203 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.358100  2203 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.358126  2203 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.358151  2203 net.cpp:91] Creating Layer relu5
I0403 02:30:37.358171  2203 net.cpp:425] relu5 <- conv5
I0403 02:30:37.358193  2203 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.358216  2203 net.cpp:141] Setting up relu5
I0403 02:30:37.358237  2203 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.358254  2203 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.358273  2203 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.358295  2203 net.cpp:91] Creating Layer pool5
I0403 02:30:37.358314  2203 net.cpp:425] pool5 <- conv5
I0403 02:30:37.358336  2203 net.cpp:399] pool5 -> pool5
I0403 02:30:37.358394  2203 net.cpp:141] Setting up pool5
I0403 02:30:37.358423  2203 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.358441  2203 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.358459  2203 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.358492  2203 net.cpp:91] Creating Layer fc6
I0403 02:30:37.358521  2203 net.cpp:425] fc6 <- pool5
I0403 02:30:37.358547  2203 net.cpp:399] fc6 -> fc6
I0403 02:30:39.132417  2203 net.cpp:141] Setting up fc6
I0403 02:30:39.132520  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.132544  2203 net.cpp:156] Memory required for data: 823332800
I0403 02:30:39.132571  2203 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:39.132601  2203 net.cpp:91] Creating Layer relu6
I0403 02:30:39.132623  2203 net.cpp:425] relu6 <- fc6
I0403 02:30:39.132650  2203 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:39.132679  2203 net.cpp:141] Setting up relu6
I0403 02:30:39.132700  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.132719  2203 net.cpp:156] Memory required for data: 824971200
I0403 02:30:39.132735  2203 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:39.132766  2203 net.cpp:91] Creating Layer drop6
I0403 02:30:39.132786  2203 net.cpp:425] drop6 <- fc6
I0403 02:30:39.132807  2203 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:39.132865  2203 net.cpp:141] Setting up drop6
I0403 02:30:39.132892  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.132910  2203 net.cpp:156] Memory required for data: 826609600
I0403 02:30:39.132928  2203 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:39.132957  2203 net.cpp:91] Creating Layer fc7
I0403 02:30:39.132978  2203 net.cpp:425] fc7 <- fc6
I0403 02:30:39.133000  2203 net.cpp:399] fc7 -> fc7
I0403 02:30:39.784626  2203 net.cpp:141] Setting up fc7
I0403 02:30:39.784710  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.784729  2203 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.784751  2203 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.784777  2203 net.cpp:91] Creating Layer relu7
I0403 02:30:39.784796  2203 net.cpp:425] relu7 <- fc7
I0403 02:30:39.784816  2203 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.784839  2203 net.cpp:141] Setting up relu7
I0403 02:30:39.784857  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.784870  2203 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.784884  2203 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.784936  2203 net.cpp:91] Creating Layer drop7
I0403 02:30:39.784953  2203 net.cpp:425] drop7 <- fc7
I0403 02:30:39.784973  2203 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.785014  2203 net.cpp:141] Setting up drop7
I0403 02:30:39.785037  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.785053  2203 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.785068  2203 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.785090  2203 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.785105  2203 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.785123  2203 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.791261  2203 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.791290  2203 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.791306  2203 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.791324  2203 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.791350  2203 net.cpp:91] Creating Layer loss
I0403 02:30:39.791368  2203 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.791384  2203 net.cpp:425] loss <- label
I0403 02:30:39.791407  2203 net.cpp:399] loss -> loss
I0403 02:30:39.791436  2203 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.791545  2203 net.cpp:141] Setting up loss
I0403 02:30:39.791570  2203 net.cpp:148] Top shape: (1)
I0403 02:30:39.791585  2203 net.cpp:151]     with loss weight 1
I0403 02:30:39.791642  2203 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.791658  2203 net.cpp:217] loss needs backward computation.
I0403 02:30:39.791673  2203 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.791687  2203 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.791700  2203 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.791713  2203 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.791728  2203 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.791741  2203 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.791754  2203 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.791769  2203 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.791781  2203 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.791795  2203 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.791810  2203 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.791824  2203 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.791839  2203 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.791853  2203 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.791867  2203 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.791882  2203 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.791895  2203 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.791909  2203 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.791923  2203 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.791936  2203 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.791950  2203 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.791963  2203 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.791977  2203 net.cpp:219] data does not need backward computation.
I0403 02:30:39.791991  2203 net.cpp:261] This network produces output loss
I0403 02:30:39.792018  2203 net.cpp:274] Network initialization done.
I0403 02:30:39.793138  2203 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.793198  2203 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.793828  2203 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-80-20/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.793987  2203 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.794144  2203 net.cpp:91] Creating Layer data
I0403 02:30:39.794173  2203 net.cpp:399] data -> data
I0403 02:30:39.794198  2203 net.cpp:399] data -> label
I0403 02:30:39.794222  2203 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-80-20/mean.binaryproto
I0403 02:30:39.815356  2217 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-80-20/test_db
I0403 02:30:39.822700  2203 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.965425  2203 net.cpp:141] Setting up data
I0403 02:30:39.965500  2203 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.965528  2203 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.965544  2203 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.965564  2203 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.965593  2203 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.965611  2203 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.965632  2203 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.965658  2203 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.965718  2203 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.965740  2203 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.965757  2203 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.965772  2203 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.965787  2203 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.965816  2203 net.cpp:91] Creating Layer conv1
I0403 02:30:39.965833  2203 net.cpp:425] conv1 <- data
I0403 02:30:39.965852  2203 net.cpp:399] conv1 -> conv1
I0403 02:30:39.967456  2203 net.cpp:141] Setting up conv1
I0403 02:30:39.967485  2203 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.967501  2203 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.967531  2203 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.967555  2203 net.cpp:91] Creating Layer relu1
I0403 02:30:39.967571  2203 net.cpp:425] relu1 <- conv1
I0403 02:30:39.967588  2203 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.967607  2203 net.cpp:141] Setting up relu1
I0403 02:30:39.967624  2203 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.967638  2203 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.967653  2203 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.967674  2203 net.cpp:91] Creating Layer norm1
I0403 02:30:39.967689  2203 net.cpp:425] norm1 <- conv1
I0403 02:30:39.967707  2203 net.cpp:399] norm1 -> norm1
I0403 02:30:39.967757  2203 net.cpp:141] Setting up norm1
I0403 02:30:39.967780  2203 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.967794  2203 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.967809  2203 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.967828  2203 net.cpp:91] Creating Layer pool1
I0403 02:30:39.967844  2203 net.cpp:425] pool1 <- norm1
I0403 02:30:39.967864  2203 net.cpp:399] pool1 -> pool1
I0403 02:30:39.973824  2203 net.cpp:141] Setting up pool1
I0403 02:30:39.995460  2203 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.995621  2203 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.995669  2203 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.995698  2203 net.cpp:91] Creating Layer conv2
I0403 02:30:39.995718  2203 net.cpp:425] conv2 <- pool1
I0403 02:30:39.995739  2203 net.cpp:399] conv2 -> conv2
I0403 02:30:40.009265  2203 net.cpp:141] Setting up conv2
I0403 02:30:40.009297  2203 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:40.009315  2203 net.cpp:156] Memory required for data: 512959200
I0403 02:30:40.009337  2203 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:40.009358  2203 net.cpp:91] Creating Layer relu2
I0403 02:30:40.009376  2203 net.cpp:425] relu2 <- conv2
I0403 02:30:40.009393  2203 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:40.009413  2203 net.cpp:141] Setting up relu2
I0403 02:30:40.009431  2203 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:40.009445  2203 net.cpp:156] Memory required for data: 587608800
I0403 02:30:40.009460  2203 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:40.009480  2203 net.cpp:91] Creating Layer norm2
I0403 02:30:40.009496  2203 net.cpp:425] norm2 <- conv2
I0403 02:30:40.009519  2203 net.cpp:399] norm2 -> norm2
I0403 02:30:40.009574  2203 net.cpp:141] Setting up norm2
I0403 02:30:40.009598  2203 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:40.009611  2203 net.cpp:156] Memory required for data: 662258400
I0403 02:30:40.009626  2203 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:40.009646  2203 net.cpp:91] Creating Layer pool2
I0403 02:30:40.009663  2203 net.cpp:425] pool2 <- norm2
I0403 02:30:40.009680  2203 net.cpp:399] pool2 -> pool2
I0403 02:30:40.009728  2203 net.cpp:141] Setting up pool2
I0403 02:30:40.009752  2203 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.009768  2203 net.cpp:156] Memory required for data: 679564000
I0403 02:30:40.009781  2203 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:40.009804  2203 net.cpp:91] Creating Layer conv3
I0403 02:30:40.009824  2203 net.cpp:425] conv3 <- pool2
I0403 02:30:40.009842  2203 net.cpp:399] conv3 -> conv3
I0403 02:30:40.048086  2203 net.cpp:141] Setting up conv3
I0403 02:30:40.048141  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.048161  2203 net.cpp:156] Memory required for data: 705522400
I0403 02:30:40.048187  2203 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:40.048212  2203 net.cpp:91] Creating Layer relu3
I0403 02:30:40.048228  2203 net.cpp:425] relu3 <- conv3
I0403 02:30:40.048250  2203 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:40.048274  2203 net.cpp:141] Setting up relu3
I0403 02:30:40.048291  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.048306  2203 net.cpp:156] Memory required for data: 731480800
I0403 02:30:40.048321  2203 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:40.048346  2203 net.cpp:91] Creating Layer conv4
I0403 02:30:40.048363  2203 net.cpp:425] conv4 <- conv3
I0403 02:30:40.048383  2203 net.cpp:399] conv4 -> conv4
I0403 02:30:40.076084  2203 net.cpp:141] Setting up conv4
I0403 02:30:40.076124  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.076140  2203 net.cpp:156] Memory required for data: 757439200
I0403 02:30:40.076159  2203 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:40.076179  2203 net.cpp:91] Creating Layer relu4
I0403 02:30:40.076195  2203 net.cpp:425] relu4 <- conv4
I0403 02:30:40.076213  2203 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:40.076331  2203 net.cpp:141] Setting up relu4
I0403 02:30:40.076350  2203 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:40.076365  2203 net.cpp:156] Memory required for data: 783397600
I0403 02:30:40.076378  2203 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:40.076400  2203 net.cpp:91] Creating Layer conv5
I0403 02:30:40.076417  2203 net.cpp:425] conv5 <- conv4
I0403 02:30:40.076436  2203 net.cpp:399] conv5 -> conv5
I0403 02:30:40.094383  2203 net.cpp:141] Setting up conv5
I0403 02:30:40.094413  2203 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.094460  2203 net.cpp:156] Memory required for data: 800703200
I0403 02:30:40.094482  2203 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:40.094502  2203 net.cpp:91] Creating Layer relu5
I0403 02:30:40.094532  2203 net.cpp:425] relu5 <- conv5
I0403 02:30:40.094552  2203 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:40.094573  2203 net.cpp:141] Setting up relu5
I0403 02:30:40.094589  2203 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:40.094604  2203 net.cpp:156] Memory required for data: 818008800
I0403 02:30:40.094617  2203 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:40.094640  2203 net.cpp:91] Creating Layer pool5
I0403 02:30:40.094655  2203 net.cpp:425] pool5 <- conv5
I0403 02:30:40.094676  2203 net.cpp:399] pool5 -> pool5
I0403 02:30:40.094728  2203 net.cpp:141] Setting up pool5
I0403 02:30:40.094750  2203 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:40.094765  2203 net.cpp:156] Memory required for data: 821695200
I0403 02:30:40.094779  2203 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:40.094804  2203 net.cpp:91] Creating Layer fc6
I0403 02:30:40.094821  2203 net.cpp:425] fc6 <- pool5
I0403 02:30:40.094841  2203 net.cpp:399] fc6 -> fc6
I0403 02:30:41.505254  2203 net.cpp:141] Setting up fc6
I0403 02:30:41.505342  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.505358  2203 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.505380  2203 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.505406  2203 net.cpp:91] Creating Layer relu6
I0403 02:30:41.505424  2203 net.cpp:425] relu6 <- fc6
I0403 02:30:41.505445  2203 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.505468  2203 net.cpp:141] Setting up relu6
I0403 02:30:41.505486  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.505498  2203 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.505517  2203 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.505538  2203 net.cpp:91] Creating Layer drop6
I0403 02:30:41.505554  2203 net.cpp:425] drop6 <- fc6
I0403 02:30:41.505571  2203 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.505611  2203 net.cpp:141] Setting up drop6
I0403 02:30:41.505632  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.505646  2203 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.505661  2203 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.505686  2203 net.cpp:91] Creating Layer fc7
I0403 02:30:41.505703  2203 net.cpp:425] fc7 <- fc6
I0403 02:30:41.505722  2203 net.cpp:399] fc7 -> fc7
I0403 02:30:42.153810  2203 net.cpp:141] Setting up fc7
I0403 02:30:42.153893  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.153913  2203 net.cpp:156] Memory required for data: 828248800
I0403 02:30:42.153937  2203 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:42.153967  2203 net.cpp:91] Creating Layer relu7
I0403 02:30:42.153988  2203 net.cpp:425] relu7 <- fc7
I0403 02:30:42.154011  2203 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:42.154036  2203 net.cpp:141] Setting up relu7
I0403 02:30:42.154054  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.154069  2203 net.cpp:156] Memory required for data: 829887200
I0403 02:30:42.154084  2203 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:42.154105  2203 net.cpp:91] Creating Layer drop7
I0403 02:30:42.154122  2203 net.cpp:425] drop7 <- fc7
I0403 02:30:42.154146  2203 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:42.154189  2203 net.cpp:141] Setting up drop7
I0403 02:30:42.154213  2203 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:42.154229  2203 net.cpp:156] Memory required for data: 831525600
I0403 02:30:42.154244  2203 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:42.154271  2203 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:42.154289  2203 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:42.154310  2203 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:42.161052  2203 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:42.161085  2203 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.161124  2203 net.cpp:156] Memory required for data: 831540800
I0403 02:30:42.161145  2203 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.161166  2203 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.161185  2203 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:42.161206  2203 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.161229  2203 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.161283  2203 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:42.161309  2203 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.161329  2203 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:42.161344  2203 net.cpp:156] Memory required for data: 831571200
I0403 02:30:42.161358  2203 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.161378  2203 net.cpp:91] Creating Layer loss
I0403 02:30:42.161394  2203 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:42.161412  2203 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:42.161432  2203 net.cpp:399] loss -> loss
I0403 02:30:42.161456  2203 layer_factory.hpp:77] Creating layer loss
I0403 02:30:42.161568  2203 net.cpp:141] Setting up loss
I0403 02:30:42.161594  2203 net.cpp:148] Top shape: (1)
I0403 02:30:42.161612  2203 net.cpp:151]     with loss weight 1
I0403 02:30:42.161635  2203 net.cpp:156] Memory required for data: 831571204
I0403 02:30:42.161656  2203 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:42.161679  2203 net.cpp:91] Creating Layer accuracy
I0403 02:30:42.161695  2203 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:42.161713  2203 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:42.161734  2203 net.cpp:399] accuracy -> accuracy
I0403 02:30:42.161772  2203 net.cpp:141] Setting up accuracy
I0403 02:30:42.161793  2203 net.cpp:148] Top shape: (1)
I0403 02:30:42.161809  2203 net.cpp:156] Memory required for data: 831571208
I0403 02:30:42.161824  2203 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:42.161840  2203 net.cpp:217] loss needs backward computation.
I0403 02:30:42.161856  2203 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:42.161871  2203 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:42.161887  2203 net.cpp:217] drop7 needs backward computation.
I0403 02:30:42.161902  2203 net.cpp:217] relu7 needs backward computation.
I0403 02:30:42.161921  2203 net.cpp:217] fc7 needs backward computation.
I0403 02:30:42.161936  2203 net.cpp:217] drop6 needs backward computation.
I0403 02:30:42.161952  2203 net.cpp:217] relu6 needs backward computation.
I0403 02:30:42.161967  2203 net.cpp:217] fc6 needs backward computation.
I0403 02:30:42.161983  2203 net.cpp:217] pool5 needs backward computation.
I0403 02:30:42.161998  2203 net.cpp:217] relu5 needs backward computation.
I0403 02:30:42.162012  2203 net.cpp:217] conv5 needs backward computation.
I0403 02:30:42.162027  2203 net.cpp:217] relu4 needs backward computation.
I0403 02:30:42.162044  2203 net.cpp:217] conv4 needs backward computation.
I0403 02:30:42.162058  2203 net.cpp:217] relu3 needs backward computation.
I0403 02:30:42.162075  2203 net.cpp:217] conv3 needs backward computation.
I0403 02:30:42.162094  2203 net.cpp:217] pool2 needs backward computation.
I0403 02:30:42.162111  2203 net.cpp:217] norm2 needs backward computation.
I0403 02:30:42.162125  2203 net.cpp:217] relu2 needs backward computation.
I0403 02:30:42.162140  2203 net.cpp:217] conv2 needs backward computation.
I0403 02:30:42.162155  2203 net.cpp:217] pool1 needs backward computation.
I0403 02:30:42.162170  2203 net.cpp:217] norm1 needs backward computation.
I0403 02:30:42.162185  2203 net.cpp:217] relu1 needs backward computation.
I0403 02:30:42.162201  2203 net.cpp:217] conv1 needs backward computation.
I0403 02:30:42.162231  2203 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:42.162250  2203 net.cpp:219] data does not need backward computation.
I0403 02:30:42.162266  2203 net.cpp:261] This network produces output accuracy
I0403 02:30:42.162281  2203 net.cpp:261] This network produces output loss
I0403 02:30:42.162313  2203 net.cpp:274] Network initialization done.
I0403 02:30:42.162423  2203 solver.cpp:60] Solver scaffolding done.
I0403 02:30:42.162932  2203 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.277792  2203 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.277916  2203 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.277957  2203 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.278024  2203 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.716850  2203 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.759251  2203 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.547762  2203 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.547876  2203 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.547914  2203 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.547977  2203 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.020516  2203 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.062201  2203 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.088943  2203 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.373423  2203 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:47.998890  2203 parallel.cpp:425] Starting Optimization
I0403 02:30:47.999388  2203 solver.cpp:279] Solving 
I0403 02:30:47.999413  2203 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:47.999562  2203 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:12.541636  2203 solver.cpp:404]     Test net output #0: accuracy = 0.0149057
I0403 02:31:12.541844  2203 solver.cpp:404]     Test net output #1: loss = 3.98789 (* 1 = 3.98789 loss)
I0403 02:31:13.120115  2203 solver.cpp:228] Iteration 0, loss = 4.15849
I0403 02:31:13.120189  2203 solver.cpp:244]     Train net output #0: loss = 4.15849 (* 1 = 4.15849 loss)
I0403 02:31:13.321739  2203 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:31:28.663141  2203 solver.cpp:228] Iteration 21, loss = 1.5132
I0403 02:31:28.669224  2203 solver.cpp:244]     Train net output #0: loss = 1.5132 (* 1 = 1.5132 loss)
I0403 02:31:28.833843  2203 sgd_solver.cpp:106] Iteration 21, lr = 0.005
I0403 02:31:43.997926  2203 solver.cpp:228] Iteration 42, loss = 1.12021
I0403 02:31:44.004314  2203 solver.cpp:244]     Train net output #0: loss = 1.12021 (* 1 = 1.12021 loss)
I0403 02:31:44.174474  2203 sgd_solver.cpp:106] Iteration 42, lr = 0.005
I0403 02:31:59.369228  2203 solver.cpp:228] Iteration 63, loss = 0.656298
I0403 02:31:59.375893  2203 solver.cpp:244]     Train net output #0: loss = 0.656298 (* 1 = 0.656298 loss)
I0403 02:31:59.578585  2203 sgd_solver.cpp:106] Iteration 63, lr = 0.005
I0403 02:32:14.744527  2203 solver.cpp:228] Iteration 84, loss = 0.526476
I0403 02:32:14.755846  2203 solver.cpp:244]     Train net output #0: loss = 0.526476 (* 1 = 0.526476 loss)
I0403 02:32:14.928599  2203 sgd_solver.cpp:106] Iteration 84, lr = 0.005
I0403 02:32:30.088600  2203 solver.cpp:228] Iteration 105, loss = 0.476449
I0403 02:32:30.096231  2203 solver.cpp:244]     Train net output #0: loss = 0.476449 (* 1 = 0.476449 loss)
I0403 02:32:30.265997  2203 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 02:32:45.331897  2203 solver.cpp:228] Iteration 126, loss = 0.482786
I0403 02:32:45.338457  2203 solver.cpp:244]     Train net output #0: loss = 0.482786 (* 1 = 0.482786 loss)
I0403 02:32:45.508533  2203 sgd_solver.cpp:106] Iteration 126, lr = 0.005
I0403 02:33:00.772569  2203 solver.cpp:228] Iteration 147, loss = 0.422031
I0403 02:33:00.779145  2203 solver.cpp:244]     Train net output #0: loss = 0.422031 (* 1 = 0.422031 loss)
I0403 02:33:00.891382  2203 sgd_solver.cpp:106] Iteration 147, lr = 0.005
I0403 02:33:16.103499  2203 solver.cpp:228] Iteration 168, loss = 0.494837
I0403 02:33:16.109876  2203 solver.cpp:244]     Train net output #0: loss = 0.494837 (* 1 = 0.494837 loss)
I0403 02:33:16.266099  2203 sgd_solver.cpp:106] Iteration 168, lr = 0.005
I0403 02:33:31.368001  2203 solver.cpp:228] Iteration 189, loss = 0.431904
I0403 02:33:31.375905  2203 solver.cpp:244]     Train net output #0: loss = 0.431904 (* 1 = 0.431904 loss)
I0403 02:33:31.554672  2203 sgd_solver.cpp:106] Iteration 189, lr = 0.005
I0403 02:33:46.687018  2203 solver.cpp:228] Iteration 210, loss = 0.39902
I0403 02:33:46.693557  2203 solver.cpp:244]     Train net output #0: loss = 0.39902 (* 1 = 0.39902 loss)
I0403 02:33:46.853837  2203 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:34:02.112316  2203 solver.cpp:228] Iteration 231, loss = 0.439462
I0403 02:34:02.117602  2203 solver.cpp:244]     Train net output #0: loss = 0.439462 (* 1 = 0.439462 loss)
I0403 02:34:02.304265  2203 sgd_solver.cpp:106] Iteration 231, lr = 0.005
I0403 02:34:17.444393  2203 solver.cpp:228] Iteration 252, loss = 0.506077
I0403 02:34:17.453649  2203 solver.cpp:244]     Train net output #0: loss = 0.506077 (* 1 = 0.506077 loss)
I0403 02:34:17.607722  2203 sgd_solver.cpp:106] Iteration 252, lr = 0.005
I0403 02:34:33.003018  2203 solver.cpp:228] Iteration 273, loss = 0.260397
I0403 02:34:33.009671  2203 solver.cpp:244]     Train net output #0: loss = 0.260397 (* 1 = 0.260397 loss)
I0403 02:34:33.180244  2203 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 02:34:48.352210  2203 solver.cpp:228] Iteration 294, loss = 0.3101
I0403 02:34:48.357637  2203 solver.cpp:244]     Train net output #0: loss = 0.3101 (* 1 = 0.3101 loss)
I0403 02:34:48.502070  2203 sgd_solver.cpp:106] Iteration 294, lr = 0.005
I0403 02:35:03.918320  2203 solver.cpp:228] Iteration 315, loss = 0.46708
I0403 02:35:03.925146  2203 solver.cpp:244]     Train net output #0: loss = 0.46708 (* 1 = 0.46708 loss)
I0403 02:35:04.102671  2203 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 02:35:19.674578  2203 solver.cpp:228] Iteration 336, loss = 0.313663
I0403 02:35:19.681056  2203 solver.cpp:244]     Train net output #0: loss = 0.313663 (* 1 = 0.313663 loss)
I0403 02:35:19.826293  2203 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 02:35:35.172322  2203 solver.cpp:228] Iteration 357, loss = 0.20025
I0403 02:35:35.178771  2203 solver.cpp:244]     Train net output #0: loss = 0.20025 (* 1 = 0.20025 loss)
I0403 02:35:35.356254  2203 sgd_solver.cpp:106] Iteration 357, lr = 0.005
I0403 02:35:50.920397  2203 solver.cpp:228] Iteration 378, loss = 0.248283
I0403 02:35:50.926980  2203 solver.cpp:244]     Train net output #0: loss = 0.248283 (* 1 = 0.248283 loss)
I0403 02:35:51.067383  2203 sgd_solver.cpp:106] Iteration 378, lr = 0.005
I0403 02:36:06.454125  2203 solver.cpp:228] Iteration 399, loss = 0.239212
I0403 02:36:06.460465  2203 solver.cpp:244]     Train net output #0: loss = 0.239212 (* 1 = 0.239212 loss)
I0403 02:36:06.643920  2203 sgd_solver.cpp:106] Iteration 399, lr = 0.005
I0403 02:36:21.992408  2203 solver.cpp:228] Iteration 420, loss = 0.336497
I0403 02:36:21.998852  2203 solver.cpp:244]     Train net output #0: loss = 0.336497 (* 1 = 0.336497 loss)
I0403 02:36:22.206459  2203 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:36:33.425086  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_436.caffemodel
I0403 02:36:36.382076  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_436.solverstate
I0403 02:36:38.624753  2203 solver.cpp:337] Iteration 436, Testing net (#0)
I0403 02:37:02.933058  2203 solver.cpp:404]     Test net output #0: accuracy = 0.91
I0403 02:37:02.940819  2203 solver.cpp:404]     Test net output #1: loss = 0.270077 (* 1 = 0.270077 loss)
I0403 02:37:07.194311  2203 solver.cpp:228] Iteration 441, loss = 0.293919
I0403 02:37:07.200672  2203 solver.cpp:244]     Train net output #0: loss = 0.293919 (* 1 = 0.293919 loss)
I0403 02:37:07.369900  2203 sgd_solver.cpp:106] Iteration 441, lr = 0.005
I0403 02:37:22.622892  2203 solver.cpp:228] Iteration 462, loss = 0.452571
I0403 02:37:22.628885  2203 solver.cpp:244]     Train net output #0: loss = 0.452571 (* 1 = 0.452571 loss)
I0403 02:37:22.806777  2203 sgd_solver.cpp:106] Iteration 462, lr = 0.005
I0403 02:37:38.148299  2203 solver.cpp:228] Iteration 483, loss = 0.439171
I0403 02:37:38.154505  2203 solver.cpp:244]     Train net output #0: loss = 0.439171 (* 1 = 0.439171 loss)
I0403 02:37:38.332574  2203 sgd_solver.cpp:106] Iteration 483, lr = 0.005
I0403 02:37:53.649410  2203 solver.cpp:228] Iteration 504, loss = 0.231324
I0403 02:37:53.655303  2203 solver.cpp:244]     Train net output #0: loss = 0.231324 (* 1 = 0.231324 loss)
I0403 02:37:53.851755  2203 sgd_solver.cpp:106] Iteration 504, lr = 0.005
I0403 02:38:09.223330  2203 solver.cpp:228] Iteration 525, loss = 0.293177
I0403 02:38:09.228595  2203 solver.cpp:244]     Train net output #0: loss = 0.293177 (* 1 = 0.293177 loss)
I0403 02:38:09.392135  2203 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 02:38:24.829221  2203 solver.cpp:228] Iteration 546, loss = 0.15707
I0403 02:38:24.835961  2203 solver.cpp:244]     Train net output #0: loss = 0.157071 (* 1 = 0.157071 loss)
I0403 02:38:24.954586  2203 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 02:38:40.465957  2203 solver.cpp:228] Iteration 567, loss = 0.186918
I0403 02:38:40.472594  2203 solver.cpp:244]     Train net output #0: loss = 0.186918 (* 1 = 0.186918 loss)
I0403 02:38:40.669625  2203 sgd_solver.cpp:106] Iteration 567, lr = 0.005
I0403 02:38:56.076006  2203 solver.cpp:228] Iteration 588, loss = 0.329927
I0403 02:38:56.076091  2203 solver.cpp:244]     Train net output #0: loss = 0.329927 (* 1 = 0.329927 loss)
I0403 02:38:56.251410  2203 sgd_solver.cpp:106] Iteration 588, lr = 0.005
I0403 02:39:11.519083  2203 solver.cpp:228] Iteration 609, loss = 0.240174
I0403 02:39:11.519382  2203 solver.cpp:244]     Train net output #0: loss = 0.240174 (* 1 = 0.240174 loss)
I0403 02:39:11.705929  2203 sgd_solver.cpp:106] Iteration 609, lr = 0.005
I0403 02:39:26.669572  2203 solver.cpp:228] Iteration 630, loss = 0.200551
I0403 02:39:26.678272  2203 solver.cpp:244]     Train net output #0: loss = 0.200551 (* 1 = 0.200551 loss)
I0403 02:39:26.879528  2203 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:39:42.374860  2203 solver.cpp:228] Iteration 651, loss = 0.263098
I0403 02:39:42.375133  2203 solver.cpp:244]     Train net output #0: loss = 0.263098 (* 1 = 0.263098 loss)
I0403 02:39:42.550555  2203 sgd_solver.cpp:106] Iteration 651, lr = 0.005
I0403 02:39:58.128976  2203 solver.cpp:228] Iteration 672, loss = 0.330451
I0403 02:39:58.129073  2203 solver.cpp:244]     Train net output #0: loss = 0.330451 (* 1 = 0.330451 loss)
I0403 02:39:58.319581  2203 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 02:40:13.559597  2203 solver.cpp:228] Iteration 693, loss = 0.192082
I0403 02:40:13.559900  2203 solver.cpp:244]     Train net output #0: loss = 0.192082 (* 1 = 0.192082 loss)
I0403 02:40:13.663622  2203 sgd_solver.cpp:106] Iteration 693, lr = 0.005
I0403 02:40:29.047837  2203 solver.cpp:228] Iteration 714, loss = 0.190064
I0403 02:40:29.047935  2203 solver.cpp:244]     Train net output #0: loss = 0.190064 (* 1 = 0.190064 loss)
I0403 02:40:29.240505  2203 sgd_solver.cpp:106] Iteration 714, lr = 0.005
I0403 02:40:44.360255  2203 solver.cpp:228] Iteration 735, loss = 0.124915
I0403 02:40:44.366943  2203 solver.cpp:244]     Train net output #0: loss = 0.124915 (* 1 = 0.124915 loss)
I0403 02:40:44.536957  2203 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 02:40:59.732702  2203 solver.cpp:228] Iteration 756, loss = 0.232668
I0403 02:40:59.739321  2203 solver.cpp:244]     Train net output #0: loss = 0.232668 (* 1 = 0.232668 loss)
I0403 02:40:59.910076  2203 sgd_solver.cpp:106] Iteration 756, lr = 0.005
I0403 02:41:15.128448  2203 solver.cpp:228] Iteration 777, loss = 0.148777
I0403 02:41:15.135457  2203 solver.cpp:244]     Train net output #0: loss = 0.148777 (* 1 = 0.148777 loss)
I0403 02:41:15.382819  2203 sgd_solver.cpp:106] Iteration 777, lr = 0.005
I0403 02:41:30.629339  2203 solver.cpp:228] Iteration 798, loss = 0.121013
I0403 02:41:30.635036  2203 solver.cpp:244]     Train net output #0: loss = 0.121013 (* 1 = 0.121013 loss)
I0403 02:41:30.777066  2203 sgd_solver.cpp:106] Iteration 798, lr = 0.005
I0403 02:41:45.945327  2203 solver.cpp:228] Iteration 819, loss = 0.110173
I0403 02:41:45.951230  2203 solver.cpp:244]     Train net output #0: loss = 0.110173 (* 1 = 0.110173 loss)
I0403 02:41:46.135074  2203 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 02:42:01.373392  2203 solver.cpp:228] Iteration 840, loss = 0.330659
I0403 02:42:01.378921  2203 solver.cpp:244]     Train net output #0: loss = 0.330659 (* 1 = 0.330659 loss)
I0403 02:42:01.523447  2203 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:42:16.956528  2203 solver.cpp:228] Iteration 861, loss = 0.288969
I0403 02:42:16.962275  2203 solver.cpp:244]     Train net output #0: loss = 0.288969 (* 1 = 0.288969 loss)
I0403 02:42:17.087452  2203 sgd_solver.cpp:106] Iteration 861, lr = 0.005
I0403 02:42:24.694638  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_872.caffemodel
I0403 02:42:27.582396  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_872.solverstate
I0403 02:42:29.500654  2203 solver.cpp:337] Iteration 872, Testing net (#0)
I0403 02:42:53.818645  2203 solver.cpp:404]     Test net output #0: accuracy = 0.940943
I0403 02:42:53.824715  2203 solver.cpp:404]     Test net output #1: loss = 0.187926 (* 1 = 0.187926 loss)
I0403 02:43:01.718578  2203 solver.cpp:228] Iteration 882, loss = 0.113364
I0403 02:43:01.724539  2203 solver.cpp:244]     Train net output #0: loss = 0.113364 (* 1 = 0.113364 loss)
I0403 02:43:01.905457  2203 sgd_solver.cpp:106] Iteration 882, lr = 0.005
I0403 02:43:17.666287  2203 solver.cpp:228] Iteration 903, loss = 0.0859397
I0403 02:43:17.673183  2203 solver.cpp:244]     Train net output #0: loss = 0.0859397 (* 1 = 0.0859397 loss)
I0403 02:43:17.851979  2203 sgd_solver.cpp:106] Iteration 903, lr = 0.005
I0403 02:43:33.489200  2203 solver.cpp:228] Iteration 924, loss = 0.102098
I0403 02:43:33.495995  2203 solver.cpp:244]     Train net output #0: loss = 0.102098 (* 1 = 0.102098 loss)
I0403 02:43:33.600117  2203 sgd_solver.cpp:106] Iteration 924, lr = 0.005
I0403 02:43:49.131840  2203 solver.cpp:228] Iteration 945, loss = 0.136077
I0403 02:43:49.155490  2203 solver.cpp:244]     Train net output #0: loss = 0.136077 (* 1 = 0.136077 loss)
I0403 02:43:49.293900  2203 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 02:44:04.500090  2203 solver.cpp:228] Iteration 966, loss = 0.259267
I0403 02:44:04.507182  2203 solver.cpp:244]     Train net output #0: loss = 0.259267 (* 1 = 0.259267 loss)
I0403 02:44:04.717820  2203 sgd_solver.cpp:106] Iteration 966, lr = 0.005
I0403 02:44:19.996539  2203 solver.cpp:228] Iteration 987, loss = 0.168291
I0403 02:44:20.003571  2203 solver.cpp:244]     Train net output #0: loss = 0.168291 (* 1 = 0.168291 loss)
I0403 02:44:20.163555  2203 sgd_solver.cpp:106] Iteration 987, lr = 0.005
I0403 02:44:35.675981  2203 solver.cpp:228] Iteration 1008, loss = 0.120509
I0403 02:44:35.682009  2203 solver.cpp:244]     Train net output #0: loss = 0.120509 (* 1 = 0.120509 loss)
I0403 02:44:35.825810  2203 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 02:44:51.173055  2203 solver.cpp:228] Iteration 1029, loss = 0.243037
I0403 02:44:51.179352  2203 solver.cpp:244]     Train net output #0: loss = 0.243037 (* 1 = 0.243037 loss)
I0403 02:44:51.345070  2203 sgd_solver.cpp:106] Iteration 1029, lr = 0.005
I0403 02:45:06.641623  2203 solver.cpp:228] Iteration 1050, loss = 0.131723
I0403 02:45:06.666260  2203 solver.cpp:244]     Train net output #0: loss = 0.131723 (* 1 = 0.131723 loss)
I0403 02:45:06.831356  2203 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 02:45:22.083132  2203 solver.cpp:228] Iteration 1071, loss = 0.0701421
I0403 02:45:22.089342  2203 solver.cpp:244]     Train net output #0: loss = 0.070142 (* 1 = 0.070142 loss)
I0403 02:45:22.249029  2203 sgd_solver.cpp:106] Iteration 1071, lr = 0.005
I0403 02:45:37.593094  2203 solver.cpp:228] Iteration 1092, loss = 0.218814
I0403 02:45:37.598906  2203 solver.cpp:244]     Train net output #0: loss = 0.218814 (* 1 = 0.218814 loss)
I0403 02:45:37.792043  2203 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 02:45:53.158103  2203 solver.cpp:228] Iteration 1113, loss = 0.0861825
I0403 02:45:53.163094  2203 solver.cpp:244]     Train net output #0: loss = 0.0861825 (* 1 = 0.0861825 loss)
I0403 02:45:53.318151  2203 sgd_solver.cpp:106] Iteration 1113, lr = 0.005
I0403 02:46:08.612454  2203 solver.cpp:228] Iteration 1134, loss = 0.276054
I0403 02:46:08.622067  2203 solver.cpp:244]     Train net output #0: loss = 0.276053 (* 1 = 0.276053 loss)
I0403 02:46:08.759850  2203 sgd_solver.cpp:106] Iteration 1134, lr = 0.005
I0403 02:46:24.262785  2203 solver.cpp:228] Iteration 1155, loss = 0.281578
I0403 02:46:24.268954  2203 solver.cpp:244]     Train net output #0: loss = 0.281577 (* 1 = 0.281577 loss)
I0403 02:46:24.425058  2203 sgd_solver.cpp:106] Iteration 1155, lr = 0.005
I0403 02:46:39.773334  2203 solver.cpp:228] Iteration 1176, loss = 0.151763
I0403 02:46:39.779825  2203 solver.cpp:244]     Train net output #0: loss = 0.151763 (* 1 = 0.151763 loss)
I0403 02:46:39.942847  2203 sgd_solver.cpp:106] Iteration 1176, lr = 0.005
I0403 02:46:55.509356  2203 solver.cpp:228] Iteration 1197, loss = 0.0882027
I0403 02:46:55.515568  2203 solver.cpp:244]     Train net output #0: loss = 0.0882026 (* 1 = 0.0882026 loss)
I0403 02:46:55.702481  2203 sgd_solver.cpp:106] Iteration 1197, lr = 0.005
I0403 02:47:11.218673  2203 solver.cpp:228] Iteration 1218, loss = 0.156365
I0403 02:47:11.224884  2203 solver.cpp:244]     Train net output #0: loss = 0.156365 (* 1 = 0.156365 loss)
I0403 02:47:11.405854  2203 sgd_solver.cpp:106] Iteration 1218, lr = 0.005
I0403 02:47:26.746808  2203 solver.cpp:228] Iteration 1239, loss = 0.22108
I0403 02:47:26.752255  2203 solver.cpp:244]     Train net output #0: loss = 0.22108 (* 1 = 0.22108 loss)
I0403 02:47:26.906882  2203 sgd_solver.cpp:106] Iteration 1239, lr = 0.005
I0403 02:47:42.618343  2203 solver.cpp:228] Iteration 1260, loss = 0.129741
I0403 02:47:42.623661  2203 solver.cpp:244]     Train net output #0: loss = 0.129741 (* 1 = 0.129741 loss)
I0403 02:47:42.788403  2203 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 02:47:58.259570  2203 solver.cpp:228] Iteration 1281, loss = 0.276522
I0403 02:47:58.265820  2203 solver.cpp:244]     Train net output #0: loss = 0.276522 (* 1 = 0.276522 loss)
I0403 02:47:58.429704  2203 sgd_solver.cpp:106] Iteration 1281, lr = 0.005
I0403 02:48:13.759346  2203 solver.cpp:228] Iteration 1302, loss = 0.115265
I0403 02:48:13.769687  2203 solver.cpp:244]     Train net output #0: loss = 0.115265 (* 1 = 0.115265 loss)
I0403 02:48:13.934952  2203 sgd_solver.cpp:106] Iteration 1302, lr = 0.005
I0403 02:48:17.665819  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_1308.caffemodel
I0403 02:48:20.366304  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_1308.solverstate
I0403 02:48:22.203222  2203 solver.cpp:337] Iteration 1308, Testing net (#0)
I0403 02:48:46.504940  2203 solver.cpp:404]     Test net output #0: accuracy = 0.94717
I0403 02:48:46.512812  2203 solver.cpp:404]     Test net output #1: loss = 0.160315 (* 1 = 0.160315 loss)
I0403 02:48:58.159292  2203 solver.cpp:228] Iteration 1323, loss = 0.115097
I0403 02:48:58.166020  2203 solver.cpp:244]     Train net output #0: loss = 0.115097 (* 1 = 0.115097 loss)
I0403 02:48:58.340939  2203 sgd_solver.cpp:106] Iteration 1323, lr = 0.005
I0403 02:49:13.817965  2203 solver.cpp:228] Iteration 1344, loss = 0.118044
I0403 02:49:13.824023  2203 solver.cpp:244]     Train net output #0: loss = 0.118044 (* 1 = 0.118044 loss)
I0403 02:49:14.004324  2203 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 02:49:29.235430  2203 solver.cpp:228] Iteration 1365, loss = 0.160633
I0403 02:49:29.242056  2203 solver.cpp:244]     Train net output #0: loss = 0.160633 (* 1 = 0.160633 loss)
I0403 02:49:29.399621  2203 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 02:49:44.923178  2203 solver.cpp:228] Iteration 1386, loss = 0.0623346
I0403 02:49:44.930603  2203 solver.cpp:244]     Train net output #0: loss = 0.0623345 (* 1 = 0.0623345 loss)
I0403 02:49:45.099795  2203 sgd_solver.cpp:106] Iteration 1386, lr = 0.005
I0403 02:50:00.807199  2203 solver.cpp:228] Iteration 1407, loss = 0.0548194
I0403 02:50:00.812893  2203 solver.cpp:244]     Train net output #0: loss = 0.0548193 (* 1 = 0.0548193 loss)
I0403 02:50:00.981693  2203 sgd_solver.cpp:106] Iteration 1407, lr = 0.005
I0403 02:50:16.284790  2203 solver.cpp:228] Iteration 1428, loss = 0.115947
I0403 02:50:16.291200  2203 solver.cpp:244]     Train net output #0: loss = 0.115947 (* 1 = 0.115947 loss)
I0403 02:50:16.470803  2203 sgd_solver.cpp:106] Iteration 1428, lr = 0.005
I0403 02:50:31.705076  2203 solver.cpp:228] Iteration 1449, loss = 0.105854
I0403 02:50:31.711025  2203 solver.cpp:244]     Train net output #0: loss = 0.105854 (* 1 = 0.105854 loss)
I0403 02:50:31.868258  2203 sgd_solver.cpp:106] Iteration 1449, lr = 0.005
I0403 02:50:47.255746  2203 solver.cpp:228] Iteration 1470, loss = 0.120539
I0403 02:50:47.262436  2203 solver.cpp:244]     Train net output #0: loss = 0.120539 (* 1 = 0.120539 loss)
I0403 02:50:47.445708  2203 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 02:51:02.705919  2203 solver.cpp:228] Iteration 1491, loss = 0.0816039
I0403 02:51:02.711480  2203 solver.cpp:244]     Train net output #0: loss = 0.0816038 (* 1 = 0.0816038 loss)
I0403 02:51:02.871614  2203 sgd_solver.cpp:106] Iteration 1491, lr = 0.005
I0403 02:51:18.155051  2203 solver.cpp:228] Iteration 1512, loss = 0.123733
I0403 02:51:18.160934  2203 solver.cpp:244]     Train net output #0: loss = 0.123733 (* 1 = 0.123733 loss)
I0403 02:51:18.338843  2203 sgd_solver.cpp:106] Iteration 1512, lr = 0.005
I0403 02:51:33.707321  2203 solver.cpp:228] Iteration 1533, loss = 0.0510507
I0403 02:51:33.713492  2203 solver.cpp:244]     Train net output #0: loss = 0.0510506 (* 1 = 0.0510506 loss)
I0403 02:51:33.893033  2203 sgd_solver.cpp:106] Iteration 1533, lr = 0.005
I0403 02:51:49.116179  2203 solver.cpp:228] Iteration 1554, loss = 0.117409
I0403 02:51:49.122313  2203 solver.cpp:244]     Train net output #0: loss = 0.117409 (* 1 = 0.117409 loss)
I0403 02:51:49.290431  2203 sgd_solver.cpp:106] Iteration 1554, lr = 0.005
I0403 02:52:04.563864  2203 solver.cpp:228] Iteration 1575, loss = 0.0663526
I0403 02:52:04.570011  2203 solver.cpp:244]     Train net output #0: loss = 0.0663525 (* 1 = 0.0663525 loss)
I0403 02:52:04.749168  2203 sgd_solver.cpp:106] Iteration 1575, lr = 0.005
I0403 02:52:19.849941  2203 solver.cpp:228] Iteration 1596, loss = 0.113995
I0403 02:52:19.855981  2203 solver.cpp:244]     Train net output #0: loss = 0.113995 (* 1 = 0.113995 loss)
I0403 02:52:20.025313  2203 sgd_solver.cpp:106] Iteration 1596, lr = 0.005
I0403 02:52:35.349184  2203 solver.cpp:228] Iteration 1617, loss = 0.199781
I0403 02:52:35.361006  2203 solver.cpp:244]     Train net output #0: loss = 0.199781 (* 1 = 0.199781 loss)
I0403 02:52:35.521425  2203 sgd_solver.cpp:106] Iteration 1617, lr = 0.005
I0403 02:52:50.952049  2203 solver.cpp:228] Iteration 1638, loss = 0.245687
I0403 02:52:50.957800  2203 solver.cpp:244]     Train net output #0: loss = 0.245687 (* 1 = 0.245687 loss)
I0403 02:52:51.169859  2203 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 02:53:06.906827  2203 solver.cpp:228] Iteration 1659, loss = 0.114921
I0403 02:53:06.913164  2203 solver.cpp:244]     Train net output #0: loss = 0.114921 (* 1 = 0.114921 loss)
I0403 02:53:07.067148  2203 sgd_solver.cpp:106] Iteration 1659, lr = 0.005
I0403 02:53:22.327953  2203 solver.cpp:228] Iteration 1680, loss = 0.136289
I0403 02:53:22.334059  2203 solver.cpp:244]     Train net output #0: loss = 0.136289 (* 1 = 0.136289 loss)
I0403 02:53:22.505096  2203 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 02:53:37.928130  2203 solver.cpp:228] Iteration 1701, loss = 0.0846307
I0403 02:53:37.934847  2203 solver.cpp:244]     Train net output #0: loss = 0.0846306 (* 1 = 0.0846306 loss)
I0403 02:53:38.132866  2203 sgd_solver.cpp:106] Iteration 1701, lr = 0.005
I0403 02:53:53.762971  2203 solver.cpp:228] Iteration 1722, loss = 0.0304573
I0403 02:53:53.769539  2203 solver.cpp:244]     Train net output #0: loss = 0.0304572 (* 1 = 0.0304572 loss)
I0403 02:53:53.911522  2203 sgd_solver.cpp:106] Iteration 1722, lr = 0.005
I0403 02:54:09.389055  2203 solver.cpp:228] Iteration 1743, loss = 0.0708676
I0403 02:54:09.395566  2203 solver.cpp:244]     Train net output #0: loss = 0.0708675 (* 1 = 0.0708675 loss)
I0403 02:54:09.582314  2203 sgd_solver.cpp:106] Iteration 1743, lr = 0.005
I0403 02:54:09.588974  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_1744.caffemodel
I0403 02:54:12.353668  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_1744.solverstate
I0403 02:54:14.258610  2203 solver.cpp:337] Iteration 1744, Testing net (#0)
I0403 02:54:38.572661  2203 solver.cpp:404]     Test net output #0: accuracy = 0.936509
I0403 02:54:38.579476  2203 solver.cpp:404]     Test net output #1: loss = 0.196502 (* 1 = 0.196502 loss)
I0403 02:54:53.684829  2203 solver.cpp:228] Iteration 1764, loss = 0.0340262
I0403 02:54:53.690836  2203 solver.cpp:244]     Train net output #0: loss = 0.0340261 (* 1 = 0.0340261 loss)
I0403 02:54:53.909783  2203 sgd_solver.cpp:106] Iteration 1764, lr = 0.005
I0403 02:55:09.256943  2203 solver.cpp:228] Iteration 1785, loss = 0.102676
I0403 02:55:09.262645  2203 solver.cpp:244]     Train net output #0: loss = 0.102676 (* 1 = 0.102676 loss)
I0403 02:55:09.424798  2203 sgd_solver.cpp:106] Iteration 1785, lr = 0.005
I0403 02:55:24.983405  2203 solver.cpp:228] Iteration 1806, loss = 0.0617242
I0403 02:55:24.990175  2203 solver.cpp:244]     Train net output #0: loss = 0.0617241 (* 1 = 0.0617241 loss)
I0403 02:55:25.139379  2203 sgd_solver.cpp:106] Iteration 1806, lr = 0.005
I0403 02:55:40.637529  2203 solver.cpp:228] Iteration 1827, loss = 0.0649405
I0403 02:55:40.647328  2203 solver.cpp:244]     Train net output #0: loss = 0.0649405 (* 1 = 0.0649405 loss)
I0403 02:55:40.790026  2203 sgd_solver.cpp:106] Iteration 1827, lr = 0.005
I0403 02:55:55.972251  2203 solver.cpp:228] Iteration 1848, loss = 0.134813
I0403 02:55:55.978662  2203 solver.cpp:244]     Train net output #0: loss = 0.134813 (* 1 = 0.134813 loss)
I0403 02:55:56.136703  2203 sgd_solver.cpp:106] Iteration 1848, lr = 0.005
I0403 02:56:11.376438  2203 solver.cpp:228] Iteration 1869, loss = 0.0890595
I0403 02:56:11.383704  2203 solver.cpp:244]     Train net output #0: loss = 0.0890594 (* 1 = 0.0890594 loss)
I0403 02:56:11.553542  2203 sgd_solver.cpp:106] Iteration 1869, lr = 0.005
I0403 02:56:27.097892  2203 solver.cpp:228] Iteration 1890, loss = 0.0991711
I0403 02:56:27.114820  2203 solver.cpp:244]     Train net output #0: loss = 0.0991711 (* 1 = 0.0991711 loss)
I0403 02:56:27.300294  2203 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 02:56:42.650041  2203 solver.cpp:228] Iteration 1911, loss = 0.124939
I0403 02:56:42.656493  2203 solver.cpp:244]     Train net output #0: loss = 0.124939 (* 1 = 0.124939 loss)
I0403 02:56:42.754053  2203 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 02:56:58.249613  2203 solver.cpp:228] Iteration 1932, loss = 0.0638555
I0403 02:56:58.256216  2203 solver.cpp:244]     Train net output #0: loss = 0.0638554 (* 1 = 0.0638554 loss)
I0403 02:56:58.424929  2203 sgd_solver.cpp:106] Iteration 1932, lr = 0.005
I0403 02:57:13.543473  2203 solver.cpp:228] Iteration 1953, loss = 0.111611
I0403 02:57:13.549880  2203 solver.cpp:244]     Train net output #0: loss = 0.111611 (* 1 = 0.111611 loss)
I0403 02:57:13.713862  2203 sgd_solver.cpp:106] Iteration 1953, lr = 0.005
I0403 02:57:28.980285  2203 solver.cpp:228] Iteration 1974, loss = 0.0355009
I0403 02:57:28.986294  2203 solver.cpp:244]     Train net output #0: loss = 0.0355008 (* 1 = 0.0355008 loss)
I0403 02:57:29.082739  2203 sgd_solver.cpp:106] Iteration 1974, lr = 0.005
I0403 02:57:44.800966  2203 solver.cpp:228] Iteration 1995, loss = 0.14328
I0403 02:57:44.807375  2203 solver.cpp:244]     Train net output #0: loss = 0.14328 (* 1 = 0.14328 loss)
I0403 02:57:45.038202  2203 sgd_solver.cpp:106] Iteration 1995, lr = 0.005
I0403 02:58:00.184279  2203 solver.cpp:228] Iteration 2016, loss = 0.0879062
I0403 02:58:00.189828  2203 solver.cpp:244]     Train net output #0: loss = 0.0879062 (* 1 = 0.0879062 loss)
I0403 02:58:00.381536  2203 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 02:58:15.696271  2203 solver.cpp:228] Iteration 2037, loss = 0.106675
I0403 02:58:15.702883  2203 solver.cpp:244]     Train net output #0: loss = 0.106675 (* 1 = 0.106675 loss)
I0403 02:58:15.879165  2203 sgd_solver.cpp:106] Iteration 2037, lr = 0.005
I0403 02:58:31.527470  2203 solver.cpp:228] Iteration 2058, loss = 0.087618
I0403 02:58:31.533459  2203 solver.cpp:244]     Train net output #0: loss = 0.0876179 (* 1 = 0.0876179 loss)
I0403 02:58:31.651937  2203 sgd_solver.cpp:106] Iteration 2058, lr = 0.005
I0403 02:58:46.963130  2203 solver.cpp:228] Iteration 2079, loss = 0.156669
I0403 02:58:46.969238  2203 solver.cpp:244]     Train net output #0: loss = 0.156669 (* 1 = 0.156669 loss)
I0403 02:58:47.152182  2203 sgd_solver.cpp:106] Iteration 2079, lr = 0.005
I0403 02:59:02.433990  2203 solver.cpp:228] Iteration 2100, loss = 0.0445229
I0403 02:59:02.440474  2203 solver.cpp:244]     Train net output #0: loss = 0.0445228 (* 1 = 0.0445228 loss)
I0403 02:59:02.601346  2203 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 02:59:18.033231  2203 solver.cpp:228] Iteration 2121, loss = 0.0472528
I0403 02:59:18.038959  2203 solver.cpp:244]     Train net output #0: loss = 0.0472527 (* 1 = 0.0472527 loss)
I0403 02:59:18.183830  2203 sgd_solver.cpp:106] Iteration 2121, lr = 0.005
I0403 02:59:33.663206  2203 solver.cpp:228] Iteration 2142, loss = 0.0386573
I0403 02:59:33.668898  2203 solver.cpp:244]     Train net output #0: loss = 0.0386572 (* 1 = 0.0386572 loss)
I0403 02:59:33.846906  2203 sgd_solver.cpp:106] Iteration 2142, lr = 0.005
I0403 02:59:49.008687  2203 solver.cpp:228] Iteration 2163, loss = 0.16936
I0403 02:59:49.014788  2203 solver.cpp:244]     Train net output #0: loss = 0.16936 (* 1 = 0.16936 loss)
I0403 02:59:49.181573  2203 sgd_solver.cpp:106] Iteration 2163, lr = 0.005
I0403 03:00:01.262773  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_2180.caffemodel
I0403 03:00:04.047335  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_2180.solverstate
I0403 03:00:05.843071  2203 solver.cpp:337] Iteration 2180, Testing net (#0)
I0403 03:00:30.180578  2203 solver.cpp:404]     Test net output #0: accuracy = 0.953208
I0403 03:00:30.186167  2203 solver.cpp:404]     Test net output #1: loss = 0.155638 (* 1 = 0.155638 loss)
I0403 03:00:33.668428  2203 solver.cpp:228] Iteration 2184, loss = 0.107153
I0403 03:00:33.678273  2203 solver.cpp:244]     Train net output #0: loss = 0.107153 (* 1 = 0.107153 loss)
I0403 03:00:33.866267  2203 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 03:00:49.108156  2203 solver.cpp:228] Iteration 2205, loss = 0.107984
I0403 03:00:49.114234  2203 solver.cpp:244]     Train net output #0: loss = 0.107984 (* 1 = 0.107984 loss)
I0403 03:00:49.303319  2203 sgd_solver.cpp:106] Iteration 2205, lr = 0.005
I0403 03:01:04.803871  2203 solver.cpp:228] Iteration 2226, loss = 0.05126
I0403 03:01:04.811753  2203 solver.cpp:244]     Train net output #0: loss = 0.0512599 (* 1 = 0.0512599 loss)
I0403 03:01:04.961506  2203 sgd_solver.cpp:106] Iteration 2226, lr = 0.005
I0403 03:01:20.308583  2203 solver.cpp:228] Iteration 2247, loss = 0.0774273
I0403 03:01:20.314103  2203 solver.cpp:244]     Train net output #0: loss = 0.0774272 (* 1 = 0.0774272 loss)
I0403 03:01:20.479766  2203 sgd_solver.cpp:106] Iteration 2247, lr = 0.005
I0403 03:01:35.956800  2203 solver.cpp:228] Iteration 2268, loss = 0.069901
I0403 03:01:35.962234  2203 solver.cpp:244]     Train net output #0: loss = 0.0699009 (* 1 = 0.0699009 loss)
I0403 03:01:36.140557  2203 sgd_solver.cpp:106] Iteration 2268, lr = 0.005
I0403 03:01:51.359885  2203 solver.cpp:228] Iteration 2289, loss = 0.0952986
I0403 03:01:51.365582  2203 solver.cpp:244]     Train net output #0: loss = 0.0952985 (* 1 = 0.0952985 loss)
I0403 03:01:51.588181  2203 sgd_solver.cpp:106] Iteration 2289, lr = 0.005
I0403 03:02:06.877064  2203 solver.cpp:228] Iteration 2310, loss = 0.135008
I0403 03:02:06.882773  2203 solver.cpp:244]     Train net output #0: loss = 0.135008 (* 1 = 0.135008 loss)
I0403 03:02:07.061329  2203 sgd_solver.cpp:106] Iteration 2310, lr = 0.005
I0403 03:02:22.244581  2203 solver.cpp:228] Iteration 2331, loss = 0.173498
I0403 03:02:22.250833  2203 solver.cpp:244]     Train net output #0: loss = 0.173498 (* 1 = 0.173498 loss)
I0403 03:02:22.427494  2203 sgd_solver.cpp:106] Iteration 2331, lr = 0.005
I0403 03:02:37.773046  2203 solver.cpp:228] Iteration 2352, loss = 0.0744457
I0403 03:02:37.778493  2203 solver.cpp:244]     Train net output #0: loss = 0.0744457 (* 1 = 0.0744457 loss)
I0403 03:02:37.957044  2203 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 03:02:53.102246  2203 solver.cpp:228] Iteration 2373, loss = 0.0774198
I0403 03:02:53.108134  2203 solver.cpp:244]     Train net output #0: loss = 0.0774197 (* 1 = 0.0774197 loss)
I0403 03:02:53.247375  2203 sgd_solver.cpp:106] Iteration 2373, lr = 0.005
I0403 03:03:08.822490  2203 solver.cpp:228] Iteration 2394, loss = 0.149089
I0403 03:03:08.830292  2203 solver.cpp:244]     Train net output #0: loss = 0.149089 (* 1 = 0.149089 loss)
I0403 03:03:09.006557  2203 sgd_solver.cpp:106] Iteration 2394, lr = 0.005
I0403 03:03:24.255348  2203 solver.cpp:228] Iteration 2415, loss = 0.0773189
I0403 03:03:24.261782  2203 solver.cpp:244]     Train net output #0: loss = 0.0773188 (* 1 = 0.0773188 loss)
I0403 03:03:24.426761  2203 sgd_solver.cpp:106] Iteration 2415, lr = 0.005
I0403 03:03:40.117570  2203 solver.cpp:228] Iteration 2436, loss = 0.227211
I0403 03:03:40.122238  2203 solver.cpp:244]     Train net output #0: loss = 0.227211 (* 1 = 0.227211 loss)
I0403 03:03:40.293021  2203 sgd_solver.cpp:106] Iteration 2436, lr = 0.005
I0403 03:03:55.495976  2203 solver.cpp:228] Iteration 2457, loss = 0.0253805
I0403 03:03:55.501341  2203 solver.cpp:244]     Train net output #0: loss = 0.0253805 (* 1 = 0.0253805 loss)
I0403 03:03:55.667299  2203 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 03:04:11.067948  2203 solver.cpp:228] Iteration 2478, loss = 0.0491872
I0403 03:04:11.073910  2203 solver.cpp:244]     Train net output #0: loss = 0.0491872 (* 1 = 0.0491872 loss)
I0403 03:04:11.228601  2203 sgd_solver.cpp:106] Iteration 2478, lr = 0.005
I0403 03:04:26.662614  2203 solver.cpp:228] Iteration 2499, loss = 0.08634
I0403 03:04:26.668758  2203 solver.cpp:244]     Train net output #0: loss = 0.0863399 (* 1 = 0.0863399 loss)
I0403 03:04:26.861013  2203 sgd_solver.cpp:106] Iteration 2499, lr = 0.005
I0403 03:04:42.095896  2203 solver.cpp:228] Iteration 2520, loss = 0.0243572
I0403 03:04:42.107723  2203 solver.cpp:244]     Train net output #0: loss = 0.0243571 (* 1 = 0.0243571 loss)
I0403 03:04:42.270018  2203 sgd_solver.cpp:106] Iteration 2520, lr = 0.005
I0403 03:04:57.843276  2203 solver.cpp:228] Iteration 2541, loss = 0.0380444
I0403 03:04:57.850042  2203 solver.cpp:244]     Train net output #0: loss = 0.0380443 (* 1 = 0.0380443 loss)
I0403 03:04:57.972785  2203 sgd_solver.cpp:106] Iteration 2541, lr = 0.005
I0403 03:05:13.451426  2203 solver.cpp:228] Iteration 2562, loss = 0.0888544
I0403 03:05:13.457777  2203 solver.cpp:244]     Train net output #0: loss = 0.0888543 (* 1 = 0.0888543 loss)
I0403 03:05:13.649180  2203 sgd_solver.cpp:106] Iteration 2562, lr = 0.005
I0403 03:05:28.898485  2203 solver.cpp:228] Iteration 2583, loss = 0.0530566
I0403 03:05:28.905001  2203 solver.cpp:244]     Train net output #0: loss = 0.0530565 (* 1 = 0.0530565 loss)
I0403 03:05:29.064141  2203 sgd_solver.cpp:106] Iteration 2583, lr = 0.005
I0403 03:05:44.256136  2203 solver.cpp:228] Iteration 2604, loss = 0.151899
I0403 03:05:44.262136  2203 solver.cpp:244]     Train net output #0: loss = 0.151899 (* 1 = 0.151899 loss)
I0403 03:05:44.517004  2203 sgd_solver.cpp:106] Iteration 2604, lr = 0.005
I0403 03:05:52.585357  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_2616.caffemodel
I0403 03:05:55.388025  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_2616.solverstate
I0403 03:05:57.309562  2203 solver.cpp:337] Iteration 2616, Testing net (#0)
I0403 03:06:21.636065  2203 solver.cpp:404]     Test net output #0: accuracy = 0.951698
I0403 03:06:21.642671  2203 solver.cpp:404]     Test net output #1: loss = 0.151058 (* 1 = 0.151058 loss)
I0403 03:06:28.770913  2203 solver.cpp:228] Iteration 2625, loss = 0.081875
I0403 03:06:28.776357  2203 solver.cpp:244]     Train net output #0: loss = 0.0818749 (* 1 = 0.0818749 loss)
I0403 03:06:28.968309  2203 sgd_solver.cpp:106] Iteration 2625, lr = 0.005
I0403 03:06:44.215811  2203 solver.cpp:228] Iteration 2646, loss = 0.0880953
I0403 03:06:44.221235  2203 solver.cpp:244]     Train net output #0: loss = 0.0880952 (* 1 = 0.0880952 loss)
I0403 03:06:44.392009  2203 sgd_solver.cpp:106] Iteration 2646, lr = 0.005
I0403 03:06:59.610930  2203 solver.cpp:228] Iteration 2667, loss = 0.0108769
I0403 03:06:59.616565  2203 solver.cpp:244]     Train net output #0: loss = 0.0108768 (* 1 = 0.0108768 loss)
I0403 03:06:59.763404  2203 sgd_solver.cpp:106] Iteration 2667, lr = 0.005
I0403 03:07:15.028781  2203 solver.cpp:228] Iteration 2688, loss = 0.0660406
I0403 03:07:15.034690  2203 solver.cpp:244]     Train net output #0: loss = 0.0660405 (* 1 = 0.0660405 loss)
I0403 03:07:15.192596  2203 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 03:07:30.450306  2203 solver.cpp:228] Iteration 2709, loss = 0.109833
I0403 03:07:30.455375  2203 solver.cpp:244]     Train net output #0: loss = 0.109833 (* 1 = 0.109833 loss)
I0403 03:07:30.620404  2203 sgd_solver.cpp:106] Iteration 2709, lr = 0.005
I0403 03:07:45.881433  2203 solver.cpp:228] Iteration 2730, loss = 0.107502
I0403 03:07:45.886593  2203 solver.cpp:244]     Train net output #0: loss = 0.107502 (* 1 = 0.107502 loss)
I0403 03:07:46.039342  2203 sgd_solver.cpp:106] Iteration 2730, lr = 0.005
I0403 03:08:01.337165  2203 solver.cpp:228] Iteration 2751, loss = 0.0891347
I0403 03:08:01.342772  2203 solver.cpp:244]     Train net output #0: loss = 0.0891346 (* 1 = 0.0891346 loss)
I0403 03:08:01.521178  2203 sgd_solver.cpp:106] Iteration 2751, lr = 0.005
I0403 03:08:16.823926  2203 solver.cpp:228] Iteration 2772, loss = 0.121291
I0403 03:08:16.829236  2203 solver.cpp:244]     Train net output #0: loss = 0.121291 (* 1 = 0.121291 loss)
I0403 03:08:16.972546  2203 sgd_solver.cpp:106] Iteration 2772, lr = 0.005
I0403 03:08:32.222967  2203 solver.cpp:228] Iteration 2793, loss = 0.026126
I0403 03:08:32.229105  2203 solver.cpp:244]     Train net output #0: loss = 0.0261259 (* 1 = 0.0261259 loss)
I0403 03:08:32.383915  2203 sgd_solver.cpp:106] Iteration 2793, lr = 0.005
I0403 03:08:47.860625  2203 solver.cpp:228] Iteration 2814, loss = 0.0250802
I0403 03:08:47.868662  2203 solver.cpp:244]     Train net output #0: loss = 0.0250801 (* 1 = 0.0250801 loss)
I0403 03:08:48.069516  2203 sgd_solver.cpp:106] Iteration 2814, lr = 0.005
I0403 03:09:03.410831  2203 solver.cpp:228] Iteration 2835, loss = 0.0492305
I0403 03:09:03.417448  2203 solver.cpp:244]     Train net output #0: loss = 0.0492304 (* 1 = 0.0492304 loss)
I0403 03:09:03.640708  2203 sgd_solver.cpp:106] Iteration 2835, lr = 0.005
I0403 03:09:18.974135  2203 solver.cpp:228] Iteration 2856, loss = 0.0109014
I0403 03:09:18.980245  2203 solver.cpp:244]     Train net output #0: loss = 0.0109013 (* 1 = 0.0109013 loss)
I0403 03:09:19.139204  2203 sgd_solver.cpp:106] Iteration 2856, lr = 0.005
I0403 03:09:34.551223  2203 solver.cpp:228] Iteration 2877, loss = 0.0779582
I0403 03:09:34.558092  2203 solver.cpp:244]     Train net output #0: loss = 0.0779581 (* 1 = 0.0779581 loss)
I0403 03:09:34.792707  2203 sgd_solver.cpp:106] Iteration 2877, lr = 0.005
I0403 03:09:50.301105  2203 solver.cpp:228] Iteration 2898, loss = 0.0477943
I0403 03:09:50.306689  2203 solver.cpp:244]     Train net output #0: loss = 0.0477942 (* 1 = 0.0477942 loss)
I0403 03:09:50.481919  2203 sgd_solver.cpp:106] Iteration 2898, lr = 0.005
I0403 03:10:05.725857  2203 solver.cpp:228] Iteration 2919, loss = 0.0420537
I0403 03:10:05.732185  2203 solver.cpp:244]     Train net output #0: loss = 0.0420536 (* 1 = 0.0420536 loss)
I0403 03:10:05.880628  2203 sgd_solver.cpp:106] Iteration 2919, lr = 0.005
I0403 03:10:21.246366  2203 solver.cpp:228] Iteration 2940, loss = 0.0202182
I0403 03:10:21.251605  2203 solver.cpp:244]     Train net output #0: loss = 0.0202181 (* 1 = 0.0202181 loss)
I0403 03:10:21.399617  2203 sgd_solver.cpp:106] Iteration 2940, lr = 0.005
I0403 03:10:36.770023  2203 solver.cpp:228] Iteration 2961, loss = 0.0300412
I0403 03:10:36.775663  2203 solver.cpp:244]     Train net output #0: loss = 0.0300411 (* 1 = 0.0300411 loss)
I0403 03:10:36.915174  2203 sgd_solver.cpp:106] Iteration 2961, lr = 0.005
I0403 03:10:52.368847  2203 solver.cpp:228] Iteration 2982, loss = 0.0419421
I0403 03:10:52.374424  2203 solver.cpp:244]     Train net output #0: loss = 0.041942 (* 1 = 0.041942 loss)
I0403 03:10:52.544328  2203 sgd_solver.cpp:106] Iteration 2982, lr = 0.005
I0403 03:11:07.707690  2203 solver.cpp:228] Iteration 3003, loss = 0.0286481
I0403 03:11:07.713436  2203 solver.cpp:244]     Train net output #0: loss = 0.028648 (* 1 = 0.028648 loss)
I0403 03:11:07.916718  2203 sgd_solver.cpp:106] Iteration 3003, lr = 0.005
I0403 03:11:22.995259  2203 solver.cpp:228] Iteration 3024, loss = 0.101758
I0403 03:11:23.001699  2203 solver.cpp:244]     Train net output #0: loss = 0.101758 (* 1 = 0.101758 loss)
I0403 03:11:23.169890  2203 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 03:11:38.378757  2203 solver.cpp:228] Iteration 3045, loss = 0.114558
I0403 03:11:38.384830  2203 solver.cpp:244]     Train net output #0: loss = 0.114558 (* 1 = 0.114558 loss)
I0403 03:11:38.582887  2203 sgd_solver.cpp:106] Iteration 3045, lr = 0.005
I0403 03:11:43.160245  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_3052.caffemodel
I0403 03:11:45.870813  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_3052.solverstate
I0403 03:11:47.705332  2203 solver.cpp:337] Iteration 3052, Testing net (#0)
I0403 03:12:12.052376  2203 solver.cpp:404]     Test net output #0: accuracy = 0.948113
I0403 03:12:12.060144  2203 solver.cpp:404]     Test net output #1: loss = 0.172858 (* 1 = 0.172858 loss)
I0403 03:12:22.873625  2203 solver.cpp:228] Iteration 3066, loss = 0.0785578
I0403 03:12:22.879467  2203 solver.cpp:244]     Train net output #0: loss = 0.0785577 (* 1 = 0.0785577 loss)
I0403 03:12:23.030679  2203 sgd_solver.cpp:106] Iteration 3066, lr = 0.005
I0403 03:12:38.358418  2203 solver.cpp:228] Iteration 3087, loss = 0.0313245
I0403 03:12:38.363294  2203 solver.cpp:244]     Train net output #0: loss = 0.0313244 (* 1 = 0.0313244 loss)
I0403 03:12:38.532305  2203 sgd_solver.cpp:106] Iteration 3087, lr = 0.005
I0403 03:12:53.929551  2203 solver.cpp:228] Iteration 3108, loss = 0.0609552
I0403 03:12:53.936705  2203 solver.cpp:244]     Train net output #0: loss = 0.0609551 (* 1 = 0.0609551 loss)
I0403 03:12:54.091457  2203 sgd_solver.cpp:106] Iteration 3108, lr = 0.005
I0403 03:13:09.561769  2203 solver.cpp:228] Iteration 3129, loss = 0.0444905
I0403 03:13:09.568115  2203 solver.cpp:244]     Train net output #0: loss = 0.0444904 (* 1 = 0.0444904 loss)
I0403 03:13:09.710078  2203 sgd_solver.cpp:106] Iteration 3129, lr = 0.005
I0403 03:13:25.123244  2203 solver.cpp:228] Iteration 3150, loss = 0.0637035
I0403 03:13:25.128741  2203 solver.cpp:244]     Train net output #0: loss = 0.0637034 (* 1 = 0.0637034 loss)
I0403 03:13:25.309558  2203 sgd_solver.cpp:106] Iteration 3150, lr = 0.005
I0403 03:13:40.405113  2203 solver.cpp:228] Iteration 3171, loss = 0.100255
I0403 03:13:40.411131  2203 solver.cpp:244]     Train net output #0: loss = 0.100255 (* 1 = 0.100255 loss)
I0403 03:13:40.553948  2203 sgd_solver.cpp:106] Iteration 3171, lr = 0.005
I0403 03:13:56.025241  2203 solver.cpp:228] Iteration 3192, loss = 0.0299065
I0403 03:13:56.030339  2203 solver.cpp:244]     Train net output #0: loss = 0.0299064 (* 1 = 0.0299064 loss)
I0403 03:13:56.208920  2203 sgd_solver.cpp:106] Iteration 3192, lr = 0.005
I0403 03:14:11.875244  2203 solver.cpp:228] Iteration 3213, loss = 0.0255832
I0403 03:14:11.881078  2203 solver.cpp:244]     Train net output #0: loss = 0.0255831 (* 1 = 0.0255831 loss)
I0403 03:14:12.006918  2203 sgd_solver.cpp:106] Iteration 3213, lr = 0.005
I0403 03:14:27.342933  2203 solver.cpp:228] Iteration 3234, loss = 0.0244024
I0403 03:14:27.347800  2203 solver.cpp:244]     Train net output #0: loss = 0.0244023 (* 1 = 0.0244023 loss)
I0403 03:14:27.518045  2203 sgd_solver.cpp:106] Iteration 3234, lr = 0.005
I0403 03:14:42.952149  2203 solver.cpp:228] Iteration 3255, loss = 0.0776677
I0403 03:14:42.957887  2203 solver.cpp:244]     Train net output #0: loss = 0.0776676 (* 1 = 0.0776676 loss)
I0403 03:14:43.144536  2203 sgd_solver.cpp:106] Iteration 3255, lr = 0.005
I0403 03:14:58.603094  2203 solver.cpp:228] Iteration 3276, loss = 0.0625128
I0403 03:14:58.609925  2203 solver.cpp:244]     Train net output #0: loss = 0.0625127 (* 1 = 0.0625127 loss)
I0403 03:14:58.813452  2203 sgd_solver.cpp:106] Iteration 3276, lr = 0.005
I0403 03:15:13.987854  2203 solver.cpp:228] Iteration 3297, loss = 0.08534
I0403 03:15:13.994460  2203 solver.cpp:244]     Train net output #0: loss = 0.0853399 (* 1 = 0.0853399 loss)
I0403 03:15:14.172016  2203 sgd_solver.cpp:106] Iteration 3297, lr = 0.005
I0403 03:15:29.787191  2203 solver.cpp:228] Iteration 3318, loss = 0.0388567
I0403 03:15:29.792721  2203 solver.cpp:244]     Train net output #0: loss = 0.0388566 (* 1 = 0.0388566 loss)
I0403 03:15:29.971403  2203 sgd_solver.cpp:106] Iteration 3318, lr = 0.005
I0403 03:15:45.679986  2203 solver.cpp:228] Iteration 3339, loss = 0.0419343
I0403 03:15:45.685590  2203 solver.cpp:244]     Train net output #0: loss = 0.0419342 (* 1 = 0.0419342 loss)
I0403 03:15:45.797153  2203 sgd_solver.cpp:106] Iteration 3339, lr = 0.005
I0403 03:16:01.171895  2203 solver.cpp:228] Iteration 3360, loss = 0.0125444
I0403 03:16:01.182507  2203 solver.cpp:244]     Train net output #0: loss = 0.0125443 (* 1 = 0.0125443 loss)
I0403 03:16:01.358471  2203 sgd_solver.cpp:106] Iteration 3360, lr = 0.005
I0403 03:16:16.727895  2203 solver.cpp:228] Iteration 3381, loss = 0.0616494
I0403 03:16:16.733942  2203 solver.cpp:244]     Train net output #0: loss = 0.0616493 (* 1 = 0.0616493 loss)
I0403 03:16:16.933496  2203 sgd_solver.cpp:106] Iteration 3381, lr = 0.005
I0403 03:16:32.261286  2203 solver.cpp:228] Iteration 3402, loss = 0.0852169
I0403 03:16:32.266957  2203 solver.cpp:244]     Train net output #0: loss = 0.0852168 (* 1 = 0.0852168 loss)
I0403 03:16:32.437850  2203 sgd_solver.cpp:106] Iteration 3402, lr = 0.005
I0403 03:16:47.692503  2203 solver.cpp:228] Iteration 3423, loss = 0.0260318
I0403 03:16:47.697587  2203 solver.cpp:244]     Train net output #0: loss = 0.0260317 (* 1 = 0.0260317 loss)
I0403 03:16:47.907536  2203 sgd_solver.cpp:106] Iteration 3423, lr = 0.005
I0403 03:17:03.445269  2203 solver.cpp:228] Iteration 3444, loss = 0.0353097
I0403 03:17:03.455842  2203 solver.cpp:244]     Train net output #0: loss = 0.0353096 (* 1 = 0.0353096 loss)
I0403 03:17:03.619350  2203 sgd_solver.cpp:106] Iteration 3444, lr = 0.005
I0403 03:17:18.840229  2203 solver.cpp:228] Iteration 3465, loss = 0.024064
I0403 03:17:18.847175  2203 solver.cpp:244]     Train net output #0: loss = 0.0240639 (* 1 = 0.0240639 loss)
I0403 03:17:18.987216  2203 sgd_solver.cpp:106] Iteration 3465, lr = 0.005
I0403 03:17:34.469163  2203 solver.cpp:228] Iteration 3486, loss = 0.0446214
I0403 03:17:34.475781  2203 solver.cpp:244]     Train net output #0: loss = 0.0446212 (* 1 = 0.0446212 loss)
I0403 03:17:34.651285  2203 sgd_solver.cpp:106] Iteration 3486, lr = 0.005
I0403 03:17:35.368798  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_3488.caffemodel
I0403 03:17:38.184603  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_3488.solverstate
I0403 03:17:39.996680  2203 solver.cpp:337] Iteration 3488, Testing net (#0)
I0403 03:18:04.336416  2203 solver.cpp:404]     Test net output #0: accuracy = 0.949057
I0403 03:18:04.342624  2203 solver.cpp:404]     Test net output #1: loss = 0.171053 (* 1 = 0.171053 loss)
I0403 03:18:18.921128  2203 solver.cpp:228] Iteration 3507, loss = 0.0536511
I0403 03:18:18.927026  2203 solver.cpp:244]     Train net output #0: loss = 0.053651 (* 1 = 0.053651 loss)
I0403 03:18:19.093523  2203 sgd_solver.cpp:106] Iteration 3507, lr = 0.005
I0403 03:18:34.227226  2203 solver.cpp:228] Iteration 3528, loss = 0.0512192
I0403 03:18:34.233542  2203 solver.cpp:244]     Train net output #0: loss = 0.0512191 (* 1 = 0.0512191 loss)
I0403 03:18:34.411449  2203 sgd_solver.cpp:106] Iteration 3528, lr = 0.005
I0403 03:18:49.621816  2203 solver.cpp:228] Iteration 3549, loss = 0.0467997
I0403 03:18:49.628718  2203 solver.cpp:244]     Train net output #0: loss = 0.0467996 (* 1 = 0.0467996 loss)
I0403 03:18:49.773408  2203 sgd_solver.cpp:106] Iteration 3549, lr = 0.005
I0403 03:19:05.029849  2203 solver.cpp:228] Iteration 3570, loss = 0.0416398
I0403 03:19:05.035859  2203 solver.cpp:244]     Train net output #0: loss = 0.0416397 (* 1 = 0.0416397 loss)
I0403 03:19:05.165179  2203 sgd_solver.cpp:106] Iteration 3570, lr = 0.005
I0403 03:19:20.599548  2203 solver.cpp:228] Iteration 3591, loss = 0.0968934
I0403 03:19:20.605640  2203 solver.cpp:244]     Train net output #0: loss = 0.0968932 (* 1 = 0.0968932 loss)
I0403 03:19:20.754003  2203 sgd_solver.cpp:106] Iteration 3591, lr = 0.005
I0403 03:19:36.239722  2203 solver.cpp:228] Iteration 3612, loss = 0.0193621
I0403 03:19:36.245880  2203 solver.cpp:244]     Train net output #0: loss = 0.0193619 (* 1 = 0.0193619 loss)
I0403 03:19:36.402833  2203 sgd_solver.cpp:106] Iteration 3612, lr = 0.005
I0403 03:19:51.647258  2203 solver.cpp:228] Iteration 3633, loss = 0.00805882
I0403 03:19:51.653561  2203 solver.cpp:244]     Train net output #0: loss = 0.00805869 (* 1 = 0.00805869 loss)
I0403 03:19:51.823364  2203 sgd_solver.cpp:106] Iteration 3633, lr = 0.005
I0403 03:20:07.106462  2203 solver.cpp:228] Iteration 3654, loss = 0.109906
I0403 03:20:07.110757  2203 solver.cpp:244]     Train net output #0: loss = 0.109906 (* 1 = 0.109906 loss)
I0403 03:20:07.314888  2203 sgd_solver.cpp:106] Iteration 3654, lr = 0.005
I0403 03:20:22.552800  2203 solver.cpp:228] Iteration 3675, loss = 0.0567361
I0403 03:20:22.559458  2203 solver.cpp:244]     Train net output #0: loss = 0.056736 (* 1 = 0.056736 loss)
I0403 03:20:22.695579  2203 sgd_solver.cpp:106] Iteration 3675, lr = 0.005
I0403 03:20:38.042328  2203 solver.cpp:228] Iteration 3696, loss = 0.0239025
I0403 03:20:38.048032  2203 solver.cpp:244]     Train net output #0: loss = 0.0239023 (* 1 = 0.0239023 loss)
I0403 03:20:38.223007  2203 sgd_solver.cpp:106] Iteration 3696, lr = 0.005
I0403 03:20:53.484098  2203 solver.cpp:228] Iteration 3717, loss = 0.0703144
I0403 03:20:53.490195  2203 solver.cpp:244]     Train net output #0: loss = 0.0703142 (* 1 = 0.0703142 loss)
I0403 03:20:53.651895  2203 sgd_solver.cpp:106] Iteration 3717, lr = 0.005
I0403 03:21:08.898833  2203 solver.cpp:228] Iteration 3738, loss = 0.027151
I0403 03:21:08.904923  2203 solver.cpp:244]     Train net output #0: loss = 0.0271508 (* 1 = 0.0271508 loss)
I0403 03:21:09.082788  2203 sgd_solver.cpp:106] Iteration 3738, lr = 0.005
I0403 03:21:24.300643  2203 solver.cpp:228] Iteration 3759, loss = 0.0287732
I0403 03:21:24.306548  2203 solver.cpp:244]     Train net output #0: loss = 0.0287731 (* 1 = 0.0287731 loss)
I0403 03:21:24.511936  2203 sgd_solver.cpp:106] Iteration 3759, lr = 0.005
I0403 03:21:39.987821  2203 solver.cpp:228] Iteration 3780, loss = 0.0395512
I0403 03:21:39.993719  2203 solver.cpp:244]     Train net output #0: loss = 0.0395511 (* 1 = 0.0395511 loss)
I0403 03:21:40.224591  2203 sgd_solver.cpp:106] Iteration 3780, lr = 0.005
I0403 03:21:55.462487  2203 solver.cpp:228] Iteration 3801, loss = 0.0758641
I0403 03:21:55.467814  2203 solver.cpp:244]     Train net output #0: loss = 0.075864 (* 1 = 0.075864 loss)
I0403 03:21:55.618948  2203 sgd_solver.cpp:106] Iteration 3801, lr = 0.005
I0403 03:22:10.965646  2203 solver.cpp:228] Iteration 3822, loss = 0.0306835
I0403 03:22:10.971892  2203 solver.cpp:244]     Train net output #0: loss = 0.0306833 (* 1 = 0.0306833 loss)
I0403 03:22:11.150427  2203 sgd_solver.cpp:106] Iteration 3822, lr = 0.005
I0403 03:22:26.408910  2203 solver.cpp:228] Iteration 3843, loss = 0.0491169
I0403 03:22:26.414141  2203 solver.cpp:244]     Train net output #0: loss = 0.0491167 (* 1 = 0.0491167 loss)
I0403 03:22:26.595778  2203 sgd_solver.cpp:106] Iteration 3843, lr = 0.005
I0403 03:22:42.173722  2203 solver.cpp:228] Iteration 3864, loss = 0.0302263
I0403 03:22:42.179056  2203 solver.cpp:244]     Train net output #0: loss = 0.0302262 (* 1 = 0.0302262 loss)
I0403 03:22:42.327442  2203 sgd_solver.cpp:106] Iteration 3864, lr = 0.005
I0403 03:22:57.722101  2203 solver.cpp:228] Iteration 3885, loss = 0.0310571
I0403 03:22:57.730146  2203 solver.cpp:244]     Train net output #0: loss = 0.031057 (* 1 = 0.031057 loss)
I0403 03:22:57.935901  2203 sgd_solver.cpp:106] Iteration 3885, lr = 0.005
I0403 03:23:13.125845  2203 solver.cpp:228] Iteration 3906, loss = 0.0455477
I0403 03:23:13.130918  2203 solver.cpp:244]     Train net output #0: loss = 0.0455476 (* 1 = 0.0455476 loss)
I0403 03:23:13.309995  2203 sgd_solver.cpp:106] Iteration 3906, lr = 0.005
I0403 03:23:25.818614  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_3924.caffemodel
I0403 03:23:28.567989  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_3924.solverstate
I0403 03:23:30.396225  2203 solver.cpp:337] Iteration 3924, Testing net (#0)
I0403 03:23:54.715553  2203 solver.cpp:404]     Test net output #0: accuracy = 0.956981
I0403 03:23:54.723765  2203 solver.cpp:404]     Test net output #1: loss = 0.138043 (* 1 = 0.138043 loss)
I0403 03:23:57.452713  2203 solver.cpp:228] Iteration 3927, loss = 0.0495186
I0403 03:23:57.457903  2203 solver.cpp:244]     Train net output #0: loss = 0.0495185 (* 1 = 0.0495185 loss)
I0403 03:23:57.625648  2203 sgd_solver.cpp:106] Iteration 3927, lr = 0.005
I0403 03:24:12.759599  2203 solver.cpp:228] Iteration 3948, loss = 0.0342931
I0403 03:24:12.766113  2203 solver.cpp:244]     Train net output #0: loss = 0.0342929 (* 1 = 0.0342929 loss)
I0403 03:24:12.942291  2203 sgd_solver.cpp:106] Iteration 3948, lr = 0.005
I0403 03:24:28.151293  2203 solver.cpp:228] Iteration 3969, loss = 0.0183906
I0403 03:24:28.158191  2203 solver.cpp:244]     Train net output #0: loss = 0.0183905 (* 1 = 0.0183905 loss)
I0403 03:24:28.342545  2203 sgd_solver.cpp:106] Iteration 3969, lr = 0.005
I0403 03:24:43.709278  2203 solver.cpp:228] Iteration 3990, loss = 0.0831028
I0403 03:24:43.714385  2203 solver.cpp:244]     Train net output #0: loss = 0.0831027 (* 1 = 0.0831027 loss)
I0403 03:24:43.925228  2203 sgd_solver.cpp:106] Iteration 3990, lr = 0.005
I0403 03:24:59.191365  2203 solver.cpp:228] Iteration 4011, loss = 0.0682293
I0403 03:24:59.197751  2203 solver.cpp:244]     Train net output #0: loss = 0.0682292 (* 1 = 0.0682292 loss)
I0403 03:24:59.375927  2203 sgd_solver.cpp:106] Iteration 4011, lr = 0.005
I0403 03:25:14.912878  2203 solver.cpp:228] Iteration 4032, loss = 0.0805846
I0403 03:25:14.920039  2203 solver.cpp:244]     Train net output #0: loss = 0.0805845 (* 1 = 0.0805845 loss)
I0403 03:25:15.102339  2203 sgd_solver.cpp:106] Iteration 4032, lr = 0.005
I0403 03:25:30.268086  2203 solver.cpp:228] Iteration 4053, loss = 0.0239576
I0403 03:25:30.274547  2203 solver.cpp:244]     Train net output #0: loss = 0.0239574 (* 1 = 0.0239574 loss)
I0403 03:25:30.443892  2203 sgd_solver.cpp:106] Iteration 4053, lr = 0.005
I0403 03:25:45.655261  2203 solver.cpp:228] Iteration 4074, loss = 0.025219
I0403 03:25:45.661653  2203 solver.cpp:244]     Train net output #0: loss = 0.0252189 (* 1 = 0.0252189 loss)
I0403 03:25:45.839226  2203 sgd_solver.cpp:106] Iteration 4074, lr = 0.005
I0403 03:26:01.007468  2203 solver.cpp:228] Iteration 4095, loss = 0.0725064
I0403 03:26:01.012913  2203 solver.cpp:244]     Train net output #0: loss = 0.0725063 (* 1 = 0.0725063 loss)
I0403 03:26:01.175922  2203 sgd_solver.cpp:106] Iteration 4095, lr = 0.005
I0403 03:26:16.669077  2203 solver.cpp:228] Iteration 4116, loss = 0.045168
I0403 03:26:16.675230  2203 solver.cpp:244]     Train net output #0: loss = 0.0451679 (* 1 = 0.0451679 loss)
I0403 03:26:16.849256  2203 sgd_solver.cpp:106] Iteration 4116, lr = 0.005
I0403 03:26:31.986047  2203 solver.cpp:228] Iteration 4137, loss = 0.00782431
I0403 03:26:31.991467  2203 solver.cpp:244]     Train net output #0: loss = 0.00782418 (* 1 = 0.00782418 loss)
I0403 03:26:32.176029  2203 sgd_solver.cpp:106] Iteration 4137, lr = 0.005
I0403 03:26:47.588245  2203 solver.cpp:228] Iteration 4158, loss = 0.0110539
I0403 03:26:47.593694  2203 solver.cpp:244]     Train net output #0: loss = 0.0110538 (* 1 = 0.0110538 loss)
I0403 03:26:47.760424  2203 sgd_solver.cpp:106] Iteration 4158, lr = 0.005
I0403 03:27:02.974341  2203 solver.cpp:228] Iteration 4179, loss = 0.0181932
I0403 03:27:02.980455  2203 solver.cpp:244]     Train net output #0: loss = 0.0181931 (* 1 = 0.0181931 loss)
I0403 03:27:03.127777  2203 sgd_solver.cpp:106] Iteration 4179, lr = 0.005
I0403 03:27:18.455945  2203 solver.cpp:228] Iteration 4200, loss = 0.0254414
I0403 03:27:18.462330  2203 solver.cpp:244]     Train net output #0: loss = 0.0254413 (* 1 = 0.0254413 loss)
I0403 03:27:18.626461  2203 sgd_solver.cpp:106] Iteration 4200, lr = 0.005
I0403 03:27:33.931180  2203 solver.cpp:228] Iteration 4221, loss = 0.0322574
I0403 03:27:33.940598  2203 solver.cpp:244]     Train net output #0: loss = 0.0322573 (* 1 = 0.0322573 loss)
I0403 03:27:34.110128  2203 sgd_solver.cpp:106] Iteration 4221, lr = 0.005
I0403 03:27:49.403558  2203 solver.cpp:228] Iteration 4242, loss = 0.00981188
I0403 03:27:49.411226  2203 solver.cpp:244]     Train net output #0: loss = 0.00981176 (* 1 = 0.00981176 loss)
I0403 03:27:49.579664  2203 sgd_solver.cpp:106] Iteration 4242, lr = 0.005
I0403 03:28:04.742976  2203 solver.cpp:228] Iteration 4263, loss = 0.0128587
I0403 03:28:04.748263  2203 solver.cpp:244]     Train net output #0: loss = 0.0128586 (* 1 = 0.0128586 loss)
I0403 03:28:04.935137  2203 sgd_solver.cpp:106] Iteration 4263, lr = 0.005
I0403 03:28:20.242182  2203 solver.cpp:228] Iteration 4284, loss = 0.0709607
I0403 03:28:20.248370  2203 solver.cpp:244]     Train net output #0: loss = 0.0709606 (* 1 = 0.0709606 loss)
I0403 03:28:20.426513  2203 sgd_solver.cpp:106] Iteration 4284, lr = 0.005
I0403 03:28:36.087308  2203 solver.cpp:228] Iteration 4305, loss = 0.0604282
I0403 03:28:36.093097  2203 solver.cpp:244]     Train net output #0: loss = 0.0604281 (* 1 = 0.0604281 loss)
I0403 03:28:36.251545  2203 sgd_solver.cpp:106] Iteration 4305, lr = 0.005
I0403 03:28:52.038633  2203 solver.cpp:228] Iteration 4326, loss = 0.0384196
I0403 03:28:52.044940  2203 solver.cpp:244]     Train net output #0: loss = 0.0384195 (* 1 = 0.0384195 loss)
I0403 03:28:52.230461  2203 sgd_solver.cpp:106] Iteration 4326, lr = 0.005
I0403 03:29:07.459786  2203 solver.cpp:228] Iteration 4347, loss = 0.0491131
I0403 03:29:07.466135  2203 solver.cpp:244]     Train net output #0: loss = 0.049113 (* 1 = 0.049113 loss)
I0403 03:29:07.651866  2203 sgd_solver.cpp:106] Iteration 4347, lr = 0.005
I0403 03:29:16.646158  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_4360.caffemodel
I0403 03:29:19.415295  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_4360.solverstate
I0403 03:29:21.326611  2203 solver.cpp:337] Iteration 4360, Testing net (#0)
I0403 03:29:45.639721  2203 solver.cpp:404]     Test net output #0: accuracy = 0.949623
I0403 03:29:45.649523  2203 solver.cpp:404]     Test net output #1: loss = 0.185769 (* 1 = 0.185769 loss)
I0403 03:29:51.993320  2203 solver.cpp:228] Iteration 4368, loss = 0.229576
I0403 03:29:52.001477  2203 solver.cpp:244]     Train net output #0: loss = 0.229576 (* 1 = 0.229576 loss)
I0403 03:29:52.169996  2203 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:30:07.329107  2203 solver.cpp:228] Iteration 4389, loss = 0.0582516
I0403 03:30:07.336537  2203 solver.cpp:244]     Train net output #0: loss = 0.0582515 (* 1 = 0.0582515 loss)
I0403 03:30:07.546375  2203 sgd_solver.cpp:106] Iteration 4389, lr = 0.0005
I0403 03:30:22.858592  2203 solver.cpp:228] Iteration 4410, loss = 0.0221428
I0403 03:30:22.865419  2203 solver.cpp:244]     Train net output #0: loss = 0.0221427 (* 1 = 0.0221427 loss)
I0403 03:30:23.052681  2203 sgd_solver.cpp:106] Iteration 4410, lr = 0.0005
I0403 03:30:38.552700  2203 solver.cpp:228] Iteration 4431, loss = 0.0266667
I0403 03:30:38.559278  2203 solver.cpp:244]     Train net output #0: loss = 0.0266666 (* 1 = 0.0266666 loss)
I0403 03:30:38.727733  2203 sgd_solver.cpp:106] Iteration 4431, lr = 0.0005
I0403 03:30:54.385797  2203 solver.cpp:228] Iteration 4452, loss = 0.0347119
I0403 03:30:54.394680  2203 solver.cpp:244]     Train net output #0: loss = 0.0347118 (* 1 = 0.0347118 loss)
I0403 03:30:54.554157  2203 sgd_solver.cpp:106] Iteration 4452, lr = 0.0005
I0403 03:31:09.803673  2203 solver.cpp:228] Iteration 4473, loss = 0.0191675
I0403 03:31:09.809818  2203 solver.cpp:244]     Train net output #0: loss = 0.0191674 (* 1 = 0.0191674 loss)
I0403 03:31:09.959987  2203 sgd_solver.cpp:106] Iteration 4473, lr = 0.0005
I0403 03:31:25.619501  2203 solver.cpp:228] Iteration 4494, loss = 0.0117613
I0403 03:31:25.629385  2203 solver.cpp:244]     Train net output #0: loss = 0.0117613 (* 1 = 0.0117613 loss)
I0403 03:31:25.769752  2203 sgd_solver.cpp:106] Iteration 4494, lr = 0.0005
I0403 03:31:41.070770  2203 solver.cpp:228] Iteration 4515, loss = 0.0172321
I0403 03:31:41.076545  2203 solver.cpp:244]     Train net output #0: loss = 0.017232 (* 1 = 0.017232 loss)
I0403 03:31:41.260200  2203 sgd_solver.cpp:106] Iteration 4515, lr = 0.0005
I0403 03:31:56.458122  2203 solver.cpp:228] Iteration 4536, loss = 0.00945844
I0403 03:31:56.463691  2203 solver.cpp:244]     Train net output #0: loss = 0.00945836 (* 1 = 0.00945836 loss)
I0403 03:31:56.694759  2203 sgd_solver.cpp:106] Iteration 4536, lr = 0.0005
I0403 03:32:11.963459  2203 solver.cpp:228] Iteration 4557, loss = 0.0189686
I0403 03:32:11.969182  2203 solver.cpp:244]     Train net output #0: loss = 0.0189685 (* 1 = 0.0189685 loss)
I0403 03:32:12.156299  2203 sgd_solver.cpp:106] Iteration 4557, lr = 0.0005
I0403 03:32:27.371081  2203 solver.cpp:228] Iteration 4578, loss = 0.0194075
I0403 03:32:27.377595  2203 solver.cpp:244]     Train net output #0: loss = 0.0194074 (* 1 = 0.0194074 loss)
I0403 03:32:27.532613  2203 sgd_solver.cpp:106] Iteration 4578, lr = 0.0005
I0403 03:32:42.902470  2203 solver.cpp:228] Iteration 4599, loss = 0.00548233
I0403 03:32:42.909250  2203 solver.cpp:244]     Train net output #0: loss = 0.00548224 (* 1 = 0.00548224 loss)
I0403 03:32:43.079175  2203 sgd_solver.cpp:106] Iteration 4599, lr = 0.0005
I0403 03:32:58.314893  2203 solver.cpp:228] Iteration 4620, loss = 0.0582691
I0403 03:32:58.321916  2203 solver.cpp:244]     Train net output #0: loss = 0.058269 (* 1 = 0.058269 loss)
I0403 03:32:58.510047  2203 sgd_solver.cpp:106] Iteration 4620, lr = 0.0005
I0403 03:33:13.944386  2203 solver.cpp:228] Iteration 4641, loss = 0.0168845
I0403 03:33:13.952108  2203 solver.cpp:244]     Train net output #0: loss = 0.0168844 (* 1 = 0.0168844 loss)
I0403 03:33:14.105355  2203 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 03:33:29.512832  2203 solver.cpp:228] Iteration 4662, loss = 0.00905996
I0403 03:33:29.519564  2203 solver.cpp:244]     Train net output #0: loss = 0.00905986 (* 1 = 0.00905986 loss)
I0403 03:33:29.682111  2203 sgd_solver.cpp:106] Iteration 4662, lr = 0.0005
I0403 03:33:44.979817  2203 solver.cpp:228] Iteration 4683, loss = 0.0121968
I0403 03:33:44.986296  2203 solver.cpp:244]     Train net output #0: loss = 0.0121967 (* 1 = 0.0121967 loss)
I0403 03:33:45.158905  2203 sgd_solver.cpp:106] Iteration 4683, lr = 0.0005
I0403 03:34:00.447473  2203 solver.cpp:228] Iteration 4704, loss = 0.00282244
I0403 03:34:00.452965  2203 solver.cpp:244]     Train net output #0: loss = 0.00282234 (* 1 = 0.00282234 loss)
I0403 03:34:00.607923  2203 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 03:34:16.150851  2203 solver.cpp:228] Iteration 4725, loss = 0.0155205
I0403 03:34:16.150939  2203 solver.cpp:244]     Train net output #0: loss = 0.0155204 (* 1 = 0.0155204 loss)
I0403 03:34:16.315140  2203 sgd_solver.cpp:106] Iteration 4725, lr = 0.0005
I0403 03:34:31.667551  2203 solver.cpp:228] Iteration 4746, loss = 0.0497114
I0403 03:34:31.667847  2203 solver.cpp:244]     Train net output #0: loss = 0.0497113 (* 1 = 0.0497113 loss)
I0403 03:34:31.820672  2203 sgd_solver.cpp:106] Iteration 4746, lr = 0.0005
I0403 03:34:47.553891  2203 solver.cpp:228] Iteration 4767, loss = 0.00938627
I0403 03:34:47.553982  2203 solver.cpp:244]     Train net output #0: loss = 0.00938617 (* 1 = 0.00938617 loss)
I0403 03:34:47.707334  2203 sgd_solver.cpp:106] Iteration 4767, lr = 0.0005
I0403 03:35:03.454756  2203 solver.cpp:228] Iteration 4788, loss = 0.0179039
I0403 03:35:03.454993  2203 solver.cpp:244]     Train net output #0: loss = 0.0179038 (* 1 = 0.0179038 loss)
I0403 03:35:03.630537  2203 sgd_solver.cpp:106] Iteration 4788, lr = 0.0005
I0403 03:35:08.804636  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_4796.caffemodel
I0403 03:35:11.569736  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_4796.solverstate
I0403 03:35:13.476785  2203 solver.cpp:337] Iteration 4796, Testing net (#0)
I0403 03:35:37.800863  2203 solver.cpp:404]     Test net output #0: accuracy = 0.969434
I0403 03:35:37.801184  2203 solver.cpp:404]     Test net output #1: loss = 0.108652 (* 1 = 0.108652 loss)
I0403 03:35:48.090391  2203 solver.cpp:228] Iteration 4809, loss = 0.00809362
I0403 03:35:48.090478  2203 solver.cpp:244]     Train net output #0: loss = 0.00809352 (* 1 = 0.00809352 loss)
I0403 03:35:48.204649  2203 sgd_solver.cpp:106] Iteration 4809, lr = 0.0005
I0403 03:36:03.493862  2203 solver.cpp:228] Iteration 4830, loss = 0.00733509
I0403 03:36:03.493953  2203 solver.cpp:244]     Train net output #0: loss = 0.00733498 (* 1 = 0.00733498 loss)
I0403 03:36:03.670169  2203 sgd_solver.cpp:106] Iteration 4830, lr = 0.0005
I0403 03:36:18.980912  2203 solver.cpp:228] Iteration 4851, loss = 0.00267024
I0403 03:36:18.981235  2203 solver.cpp:244]     Train net output #0: loss = 0.00267013 (* 1 = 0.00267013 loss)
I0403 03:36:19.142627  2203 sgd_solver.cpp:106] Iteration 4851, lr = 0.0005
I0403 03:36:34.515681  2203 solver.cpp:228] Iteration 4872, loss = 0.0134291
I0403 03:36:34.515777  2203 solver.cpp:244]     Train net output #0: loss = 0.013429 (* 1 = 0.013429 loss)
I0403 03:36:34.718137  2203 sgd_solver.cpp:106] Iteration 4872, lr = 0.0005
I0403 03:36:50.068581  2203 solver.cpp:228] Iteration 4893, loss = 0.00616757
I0403 03:36:50.068877  2203 solver.cpp:244]     Train net output #0: loss = 0.00616746 (* 1 = 0.00616746 loss)
I0403 03:36:50.235275  2203 sgd_solver.cpp:106] Iteration 4893, lr = 0.0005
I0403 03:37:05.505038  2203 solver.cpp:228] Iteration 4914, loss = 0.0120228
I0403 03:37:05.505138  2203 solver.cpp:244]     Train net output #0: loss = 0.0120227 (* 1 = 0.0120227 loss)
I0403 03:37:05.704736  2203 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 03:37:21.030884  2203 solver.cpp:228] Iteration 4935, loss = 0.0194419
I0403 03:37:21.031163  2203 solver.cpp:244]     Train net output #0: loss = 0.0194418 (* 1 = 0.0194418 loss)
I0403 03:37:21.212038  2203 sgd_solver.cpp:106] Iteration 4935, lr = 0.0005
I0403 03:37:36.498893  2203 solver.cpp:228] Iteration 4956, loss = 0.0175741
I0403 03:37:36.498987  2203 solver.cpp:244]     Train net output #0: loss = 0.017574 (* 1 = 0.017574 loss)
I0403 03:37:36.683517  2203 sgd_solver.cpp:106] Iteration 4956, lr = 0.0005
I0403 03:37:51.997678  2203 solver.cpp:228] Iteration 4977, loss = 0.00767935
I0403 03:37:51.997973  2203 solver.cpp:244]     Train net output #0: loss = 0.00767924 (* 1 = 0.00767924 loss)
I0403 03:37:52.105516  2203 sgd_solver.cpp:106] Iteration 4977, lr = 0.0005
I0403 03:38:07.472771  2203 solver.cpp:228] Iteration 4998, loss = 0.0207758
I0403 03:38:07.472861  2203 solver.cpp:244]     Train net output #0: loss = 0.0207757 (* 1 = 0.0207757 loss)
I0403 03:38:07.638164  2203 sgd_solver.cpp:106] Iteration 4998, lr = 0.0005
I0403 03:38:22.911428  2203 solver.cpp:228] Iteration 5019, loss = 0.0092571
I0403 03:38:22.911737  2203 solver.cpp:244]     Train net output #0: loss = 0.00925699 (* 1 = 0.00925699 loss)
I0403 03:38:23.124483  2203 sgd_solver.cpp:106] Iteration 5019, lr = 0.0005
I0403 03:38:38.372205  2203 solver.cpp:228] Iteration 5040, loss = 0.0329278
I0403 03:38:38.372293  2203 solver.cpp:244]     Train net output #0: loss = 0.0329277 (* 1 = 0.0329277 loss)
I0403 03:38:38.546768  2203 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 03:38:54.028815  2203 solver.cpp:228] Iteration 5061, loss = 0.0305673
I0403 03:38:54.029095  2203 solver.cpp:244]     Train net output #0: loss = 0.0305672 (* 1 = 0.0305672 loss)
I0403 03:38:54.178128  2203 sgd_solver.cpp:106] Iteration 5061, lr = 0.0005
I0403 03:39:09.695328  2203 solver.cpp:228] Iteration 5082, loss = 0.0125628
I0403 03:39:09.695415  2203 solver.cpp:244]     Train net output #0: loss = 0.0125627 (* 1 = 0.0125627 loss)
I0403 03:39:09.864234  2203 sgd_solver.cpp:106] Iteration 5082, lr = 0.0005
I0403 03:39:25.083390  2203 solver.cpp:228] Iteration 5103, loss = 0.00857603
I0403 03:39:25.083717  2203 solver.cpp:244]     Train net output #0: loss = 0.00857591 (* 1 = 0.00857591 loss)
I0403 03:39:25.233768  2203 sgd_solver.cpp:106] Iteration 5103, lr = 0.0005
I0403 03:39:40.513619  2203 solver.cpp:228] Iteration 5124, loss = 0.0131153
I0403 03:39:40.513710  2203 solver.cpp:244]     Train net output #0: loss = 0.0131152 (* 1 = 0.0131152 loss)
I0403 03:39:40.683135  2203 sgd_solver.cpp:106] Iteration 5124, lr = 0.0005
I0403 03:39:55.995870  2203 solver.cpp:228] Iteration 5145, loss = 0.00359648
I0403 03:39:55.996189  2203 solver.cpp:244]     Train net output #0: loss = 0.00359636 (* 1 = 0.00359636 loss)
I0403 03:39:56.173929  2203 sgd_solver.cpp:106] Iteration 5145, lr = 0.0005
I0403 03:40:11.628077  2203 solver.cpp:228] Iteration 5166, loss = 0.0332274
I0403 03:40:11.628180  2203 solver.cpp:244]     Train net output #0: loss = 0.0332272 (* 1 = 0.0332272 loss)
I0403 03:40:11.848886  2203 sgd_solver.cpp:106] Iteration 5166, lr = 0.0005
I0403 03:40:27.328460  2203 solver.cpp:228] Iteration 5187, loss = 0.00409382
I0403 03:40:27.328753  2203 solver.cpp:244]     Train net output #0: loss = 0.00409369 (* 1 = 0.00409369 loss)
I0403 03:40:27.504060  2203 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 03:40:42.726972  2203 solver.cpp:228] Iteration 5208, loss = 0.0023523
I0403 03:40:42.727054  2203 solver.cpp:244]     Train net output #0: loss = 0.00235218 (* 1 = 0.00235218 loss)
I0403 03:40:42.879079  2203 sgd_solver.cpp:106] Iteration 5208, lr = 0.0005
I0403 03:40:58.194988  2203 solver.cpp:228] Iteration 5229, loss = 0.00857408
I0403 03:40:58.195273  2203 solver.cpp:244]     Train net output #0: loss = 0.00857395 (* 1 = 0.00857395 loss)
I0403 03:40:58.350100  2203 sgd_solver.cpp:106] Iteration 5229, lr = 0.0005
I0403 03:40:59.839404  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_5232.caffemodel
I0403 03:41:02.641069  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_5232.solverstate
I0403 03:41:04.539044  2203 solver.cpp:337] Iteration 5232, Testing net (#0)
I0403 03:41:28.854287  2203 solver.cpp:404]     Test net output #0: accuracy = 0.968491
I0403 03:41:28.854632  2203 solver.cpp:404]     Test net output #1: loss = 0.109064 (* 1 = 0.109064 loss)
I0403 03:41:42.816691  2203 solver.cpp:228] Iteration 5250, loss = 0.00222832
I0403 03:41:42.816783  2203 solver.cpp:244]     Train net output #0: loss = 0.0022282 (* 1 = 0.0022282 loss)
I0403 03:41:43.006248  2203 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0403 03:41:58.143394  2203 solver.cpp:228] Iteration 5271, loss = 0.0223068
I0403 03:41:58.143491  2203 solver.cpp:244]     Train net output #0: loss = 0.0223067 (* 1 = 0.0223067 loss)
I0403 03:41:58.327551  2203 sgd_solver.cpp:106] Iteration 5271, lr = 0.0005
I0403 03:42:13.815332  2203 solver.cpp:228] Iteration 5292, loss = 0.0213808
I0403 03:42:13.815615  2203 solver.cpp:244]     Train net output #0: loss = 0.0213806 (* 1 = 0.0213806 loss)
I0403 03:42:13.958478  2203 sgd_solver.cpp:106] Iteration 5292, lr = 0.0005
I0403 03:42:29.441865  2203 solver.cpp:228] Iteration 5313, loss = 0.00542401
I0403 03:42:29.441956  2203 solver.cpp:244]     Train net output #0: loss = 0.00542388 (* 1 = 0.00542388 loss)
I0403 03:42:29.616596  2203 sgd_solver.cpp:106] Iteration 5313, lr = 0.0005
I0403 03:42:45.327952  2203 solver.cpp:228] Iteration 5334, loss = 0.0130647
I0403 03:42:45.328244  2203 solver.cpp:244]     Train net output #0: loss = 0.0130646 (* 1 = 0.0130646 loss)
I0403 03:42:45.491303  2203 sgd_solver.cpp:106] Iteration 5334, lr = 0.0005
I0403 03:43:01.049712  2203 solver.cpp:228] Iteration 5355, loss = 0.00351879
I0403 03:43:01.049813  2203 solver.cpp:244]     Train net output #0: loss = 0.00351866 (* 1 = 0.00351866 loss)
I0403 03:43:01.233919  2203 sgd_solver.cpp:106] Iteration 5355, lr = 0.0005
I0403 03:43:16.553640  2203 solver.cpp:228] Iteration 5376, loss = 0.00521687
I0403 03:43:16.553978  2203 solver.cpp:244]     Train net output #0: loss = 0.00521675 (* 1 = 0.00521675 loss)
I0403 03:43:16.779968  2203 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 03:43:32.087009  2203 solver.cpp:228] Iteration 5397, loss = 0.0100825
I0403 03:43:32.087107  2203 solver.cpp:244]     Train net output #0: loss = 0.0100824 (* 1 = 0.0100824 loss)
I0403 03:43:32.304313  2203 sgd_solver.cpp:106] Iteration 5397, lr = 0.0005
I0403 03:43:47.303813  2203 solver.cpp:228] Iteration 5418, loss = 0.00314573
I0403 03:43:47.304100  2203 solver.cpp:244]     Train net output #0: loss = 0.0031456 (* 1 = 0.0031456 loss)
I0403 03:43:47.473951  2203 sgd_solver.cpp:106] Iteration 5418, lr = 0.0005
I0403 03:44:02.769255  2203 solver.cpp:228] Iteration 5439, loss = 0.00674778
I0403 03:44:02.769345  2203 solver.cpp:244]     Train net output #0: loss = 0.00674766 (* 1 = 0.00674766 loss)
I0403 03:44:02.943033  2203 sgd_solver.cpp:106] Iteration 5439, lr = 0.0005
I0403 03:44:18.170055  2203 solver.cpp:228] Iteration 5460, loss = 0.029552
I0403 03:44:18.170349  2203 solver.cpp:244]     Train net output #0: loss = 0.0295519 (* 1 = 0.0295519 loss)
I0403 03:44:18.356067  2203 sgd_solver.cpp:106] Iteration 5460, lr = 0.0005
I0403 03:44:33.638301  2203 solver.cpp:228] Iteration 5481, loss = 0.00401455
I0403 03:44:33.638399  2203 solver.cpp:244]     Train net output #0: loss = 0.00401443 (* 1 = 0.00401443 loss)
I0403 03:44:33.822309  2203 sgd_solver.cpp:106] Iteration 5481, lr = 0.0005
I0403 03:44:49.229431  2203 solver.cpp:228] Iteration 5502, loss = 0.00772574
I0403 03:44:49.229717  2203 solver.cpp:244]     Train net output #0: loss = 0.00772562 (* 1 = 0.00772562 loss)
I0403 03:44:49.389765  2203 sgd_solver.cpp:106] Iteration 5502, lr = 0.0005
I0403 03:45:05.083019  2203 solver.cpp:228] Iteration 5523, loss = 0.0074771
I0403 03:45:05.083106  2203 solver.cpp:244]     Train net output #0: loss = 0.00747698 (* 1 = 0.00747698 loss)
I0403 03:45:05.256760  2203 sgd_solver.cpp:106] Iteration 5523, lr = 0.0005
I0403 03:45:20.633781  2203 solver.cpp:228] Iteration 5544, loss = 0.00436308
I0403 03:45:20.634060  2203 solver.cpp:244]     Train net output #0: loss = 0.00436296 (* 1 = 0.00436296 loss)
I0403 03:45:20.812069  2203 sgd_solver.cpp:106] Iteration 5544, lr = 0.0005
I0403 03:45:36.338567  2203 solver.cpp:228] Iteration 5565, loss = 0.00580581
I0403 03:45:36.338666  2203 solver.cpp:244]     Train net output #0: loss = 0.00580569 (* 1 = 0.00580569 loss)
I0403 03:45:36.540962  2203 sgd_solver.cpp:106] Iteration 5565, lr = 0.0005
I0403 03:45:51.649687  2203 solver.cpp:228] Iteration 5586, loss = 0.00372716
I0403 03:45:51.649992  2203 solver.cpp:244]     Train net output #0: loss = 0.00372704 (* 1 = 0.00372704 loss)
I0403 03:45:51.864787  2203 sgd_solver.cpp:106] Iteration 5586, lr = 0.0005
I0403 03:46:07.437088  2203 solver.cpp:228] Iteration 5607, loss = 0.023791
I0403 03:46:07.437185  2203 solver.cpp:244]     Train net output #0: loss = 0.0237909 (* 1 = 0.0237909 loss)
I0403 03:46:07.580942  2203 sgd_solver.cpp:106] Iteration 5607, lr = 0.0005
I0403 03:46:22.961400  2203 solver.cpp:228] Iteration 5628, loss = 0.00338921
I0403 03:46:22.961695  2203 solver.cpp:244]     Train net output #0: loss = 0.00338909 (* 1 = 0.00338909 loss)
I0403 03:46:23.137797  2203 sgd_solver.cpp:106] Iteration 5628, lr = 0.0005
I0403 03:46:38.580375  2203 solver.cpp:228] Iteration 5649, loss = 0.000938311
I0403 03:46:38.580466  2203 solver.cpp:244]     Train net output #0: loss = 0.000938187 (* 1 = 0.000938187 loss)
I0403 03:46:38.738571  2203 sgd_solver.cpp:106] Iteration 5649, lr = 0.0005
I0403 03:46:51.973101  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_5668.caffemodel
I0403 03:46:54.832392  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_5668.solverstate
I0403 03:46:56.734503  2203 solver.cpp:337] Iteration 5668, Testing net (#0)
I0403 03:47:21.056715  2203 solver.cpp:404]     Test net output #0: accuracy = 0.971227
I0403 03:47:21.056802  2203 solver.cpp:404]     Test net output #1: loss = 0.105782 (* 1 = 0.105782 loss)
I0403 03:47:23.020068  2203 solver.cpp:228] Iteration 5670, loss = 0.0206015
I0403 03:47:23.020154  2203 solver.cpp:244]     Train net output #0: loss = 0.0206014 (* 1 = 0.0206014 loss)
I0403 03:47:23.186411  2203 sgd_solver.cpp:106] Iteration 5670, lr = 0.0005
I0403 03:47:38.513357  2203 solver.cpp:228] Iteration 5691, loss = 0.0209248
I0403 03:47:38.513676  2203 solver.cpp:244]     Train net output #0: loss = 0.0209247 (* 1 = 0.0209247 loss)
I0403 03:47:38.697329  2203 sgd_solver.cpp:106] Iteration 5691, lr = 0.0005
I0403 03:47:53.841895  2203 solver.cpp:228] Iteration 5712, loss = 0.0023453
I0403 03:47:53.841990  2203 solver.cpp:244]     Train net output #0: loss = 0.00234517 (* 1 = 0.00234517 loss)
I0403 03:47:54.039852  2203 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 03:48:09.357107  2203 solver.cpp:228] Iteration 5733, loss = 0.0116969
I0403 03:48:09.357394  2203 solver.cpp:244]     Train net output #0: loss = 0.0116968 (* 1 = 0.0116968 loss)
I0403 03:48:09.539172  2203 sgd_solver.cpp:106] Iteration 5733, lr = 0.0005
I0403 03:48:24.953361  2203 solver.cpp:228] Iteration 5754, loss = 0.00197411
I0403 03:48:24.953451  2203 solver.cpp:244]     Train net output #0: loss = 0.00197399 (* 1 = 0.00197399 loss)
I0403 03:48:25.122184  2203 sgd_solver.cpp:106] Iteration 5754, lr = 0.0005
I0403 03:48:40.364794  2203 solver.cpp:228] Iteration 5775, loss = 0.00587321
I0403 03:48:40.365093  2203 solver.cpp:244]     Train net output #0: loss = 0.00587309 (* 1 = 0.00587309 loss)
I0403 03:48:40.548753  2203 sgd_solver.cpp:106] Iteration 5775, lr = 0.0005
I0403 03:48:55.798049  2203 solver.cpp:228] Iteration 5796, loss = 0.00338265
I0403 03:48:55.798135  2203 solver.cpp:244]     Train net output #0: loss = 0.00338253 (* 1 = 0.00338253 loss)
I0403 03:48:55.973815  2203 sgd_solver.cpp:106] Iteration 5796, lr = 0.0005
I0403 03:49:11.483492  2203 solver.cpp:228] Iteration 5817, loss = 0.00655697
I0403 03:49:11.483803  2203 solver.cpp:244]     Train net output #0: loss = 0.00655685 (* 1 = 0.00655685 loss)
I0403 03:49:11.574267  2203 sgd_solver.cpp:106] Iteration 5817, lr = 0.0005
I0403 03:49:27.200182  2203 solver.cpp:228] Iteration 5838, loss = 0.00522225
I0403 03:49:27.200281  2203 solver.cpp:244]     Train net output #0: loss = 0.00522213 (* 1 = 0.00522213 loss)
I0403 03:49:27.384230  2203 sgd_solver.cpp:106] Iteration 5838, lr = 0.0005
I0403 03:49:42.703640  2203 solver.cpp:228] Iteration 5859, loss = 0.00172035
I0403 03:49:42.703920  2203 solver.cpp:244]     Train net output #0: loss = 0.00172023 (* 1 = 0.00172023 loss)
I0403 03:49:42.878262  2203 sgd_solver.cpp:106] Iteration 5859, lr = 0.0005
I0403 03:49:58.787864  2203 solver.cpp:228] Iteration 5880, loss = 0.00996621
I0403 03:49:58.787950  2203 solver.cpp:244]     Train net output #0: loss = 0.0099661 (* 1 = 0.0099661 loss)
I0403 03:49:58.958673  2203 sgd_solver.cpp:106] Iteration 5880, lr = 0.0005
I0403 03:50:14.478996  2203 solver.cpp:228] Iteration 5901, loss = 0.00606615
I0403 03:50:14.479295  2203 solver.cpp:244]     Train net output #0: loss = 0.00606604 (* 1 = 0.00606604 loss)
I0403 03:50:14.662997  2203 sgd_solver.cpp:106] Iteration 5901, lr = 0.0005
I0403 03:50:30.020545  2203 solver.cpp:228] Iteration 5922, loss = 0.00342738
I0403 03:50:30.020633  2203 solver.cpp:244]     Train net output #0: loss = 0.00342727 (* 1 = 0.00342727 loss)
I0403 03:50:30.179899  2203 sgd_solver.cpp:106] Iteration 5922, lr = 0.0005
I0403 03:50:45.426199  2203 solver.cpp:228] Iteration 5943, loss = 0.00687484
I0403 03:50:45.426491  2203 solver.cpp:244]     Train net output #0: loss = 0.00687472 (* 1 = 0.00687472 loss)
I0403 03:50:45.594914  2203 sgd_solver.cpp:106] Iteration 5943, lr = 0.0005
I0403 03:51:00.692842  2203 solver.cpp:228] Iteration 5964, loss = 0.000798242
I0403 03:51:00.692944  2203 solver.cpp:244]     Train net output #0: loss = 0.00079812 (* 1 = 0.00079812 loss)
I0403 03:51:00.876900  2203 sgd_solver.cpp:106] Iteration 5964, lr = 0.0005
I0403 03:51:16.195190  2203 solver.cpp:228] Iteration 5985, loss = 0.043938
I0403 03:51:16.195530  2203 solver.cpp:244]     Train net output #0: loss = 0.0439378 (* 1 = 0.0439378 loss)
I0403 03:51:16.401933  2203 sgd_solver.cpp:106] Iteration 5985, lr = 0.0005
I0403 03:51:31.690573  2203 solver.cpp:228] Iteration 6006, loss = 0.00333645
I0403 03:51:31.690665  2203 solver.cpp:244]     Train net output #0: loss = 0.00333633 (* 1 = 0.00333633 loss)
I0403 03:51:31.865536  2203 sgd_solver.cpp:106] Iteration 6006, lr = 0.0005
I0403 03:51:47.055883  2203 solver.cpp:228] Iteration 6027, loss = 0.00937632
I0403 03:51:47.056171  2203 solver.cpp:244]     Train net output #0: loss = 0.0093762 (* 1 = 0.0093762 loss)
I0403 03:51:47.249677  2203 sgd_solver.cpp:106] Iteration 6027, lr = 0.0005
I0403 03:52:02.483659  2203 solver.cpp:228] Iteration 6048, loss = 0.000609818
I0403 03:52:02.483762  2203 solver.cpp:244]     Train net output #0: loss = 0.0006097 (* 1 = 0.0006097 loss)
I0403 03:52:02.668855  2203 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 03:52:17.702527  2203 solver.cpp:228] Iteration 6069, loss = 0.00107469
I0403 03:52:17.702822  2203 solver.cpp:244]     Train net output #0: loss = 0.00107458 (* 1 = 0.00107458 loss)
I0403 03:52:17.907975  2203 sgd_solver.cpp:106] Iteration 6069, lr = 0.0005
I0403 03:52:33.542269  2203 solver.cpp:228] Iteration 6090, loss = 0.0109285
I0403 03:52:33.542367  2203 solver.cpp:244]     Train net output #0: loss = 0.0109283 (* 1 = 0.0109283 loss)
I0403 03:52:33.728490  2203 sgd_solver.cpp:106] Iteration 6090, lr = 0.0005
I0403 03:52:43.329598  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_6104.caffemodel
I0403 03:52:46.160349  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_6104.solverstate
I0403 03:52:48.050912  2203 solver.cpp:337] Iteration 6104, Testing net (#0)
I0403 03:53:12.351006  2203 solver.cpp:404]     Test net output #0: accuracy = 0.970755
I0403 03:53:12.351099  2203 solver.cpp:404]     Test net output #1: loss = 0.107989 (* 1 = 0.107989 loss)
I0403 03:53:17.987172  2203 solver.cpp:228] Iteration 6111, loss = 0.00254996
I0403 03:53:17.987269  2203 solver.cpp:244]     Train net output #0: loss = 0.00254985 (* 1 = 0.00254985 loss)
I0403 03:53:18.171262  2203 sgd_solver.cpp:106] Iteration 6111, lr = 0.0005
I0403 03:53:33.397893  2203 solver.cpp:228] Iteration 6132, loss = 0.00363581
I0403 03:53:33.397981  2203 solver.cpp:244]     Train net output #0: loss = 0.0036357 (* 1 = 0.0036357 loss)
I0403 03:53:33.561889  2203 sgd_solver.cpp:106] Iteration 6132, lr = 0.0005
I0403 03:53:48.960041  2203 solver.cpp:228] Iteration 6153, loss = 0.024338
I0403 03:53:48.960290  2203 solver.cpp:244]     Train net output #0: loss = 0.0243379 (* 1 = 0.0243379 loss)
I0403 03:53:49.110957  2203 sgd_solver.cpp:106] Iteration 6153, lr = 0.0005
I0403 03:54:04.723505  2203 solver.cpp:228] Iteration 6174, loss = 0.00159165
I0403 03:54:04.723598  2203 solver.cpp:244]     Train net output #0: loss = 0.00159155 (* 1 = 0.00159155 loss)
I0403 03:54:04.889317  2203 sgd_solver.cpp:106] Iteration 6174, lr = 0.0005
I0403 03:54:20.184429  2203 solver.cpp:228] Iteration 6195, loss = 0.000987784
I0403 03:54:20.188524  2203 solver.cpp:244]     Train net output #0: loss = 0.000987676 (* 1 = 0.000987676 loss)
I0403 03:54:20.356487  2203 sgd_solver.cpp:106] Iteration 6195, lr = 0.0005
I0403 03:54:35.616401  2203 solver.cpp:228] Iteration 6216, loss = 0.00546349
I0403 03:54:35.616488  2203 solver.cpp:244]     Train net output #0: loss = 0.00546338 (* 1 = 0.00546338 loss)
I0403 03:54:35.792055  2203 sgd_solver.cpp:106] Iteration 6216, lr = 0.0005
I0403 03:54:51.032289  2203 solver.cpp:228] Iteration 6237, loss = 0.0112573
I0403 03:54:51.032589  2203 solver.cpp:244]     Train net output #0: loss = 0.0112572 (* 1 = 0.0112572 loss)
I0403 03:54:51.229310  2203 sgd_solver.cpp:106] Iteration 6237, lr = 0.0005
I0403 03:55:06.463906  2203 solver.cpp:228] Iteration 6258, loss = 0.00343459
I0403 03:55:06.469965  2203 solver.cpp:244]     Train net output #0: loss = 0.00343449 (* 1 = 0.00343449 loss)
I0403 03:55:06.665030  2203 sgd_solver.cpp:106] Iteration 6258, lr = 0.0005
I0403 03:55:22.014029  2203 solver.cpp:228] Iteration 6279, loss = 0.000338271
I0403 03:55:22.020586  2203 solver.cpp:244]     Train net output #0: loss = 0.000338169 (* 1 = 0.000338169 loss)
I0403 03:55:22.185582  2203 sgd_solver.cpp:106] Iteration 6279, lr = 0.0005
I0403 03:55:37.685377  2203 solver.cpp:228] Iteration 6300, loss = 0.00364943
I0403 03:55:37.691697  2203 solver.cpp:244]     Train net output #0: loss = 0.00364933 (* 1 = 0.00364933 loss)
I0403 03:55:37.915379  2203 sgd_solver.cpp:106] Iteration 6300, lr = 0.0005
I0403 03:55:53.318804  2203 solver.cpp:228] Iteration 6321, loss = 0.0133669
I0403 03:55:53.319113  2203 solver.cpp:244]     Train net output #0: loss = 0.0133668 (* 1 = 0.0133668 loss)
I0403 03:55:53.524272  2203 sgd_solver.cpp:106] Iteration 6321, lr = 0.0005
I0403 03:56:09.156119  2203 solver.cpp:228] Iteration 6342, loss = 0.00304935
I0403 03:56:09.156218  2203 solver.cpp:244]     Train net output #0: loss = 0.00304925 (* 1 = 0.00304925 loss)
I0403 03:56:09.340641  2203 sgd_solver.cpp:106] Iteration 6342, lr = 0.0005
I0403 03:56:24.489197  2203 solver.cpp:228] Iteration 6363, loss = 0.00639422
I0403 03:56:24.489502  2203 solver.cpp:244]     Train net output #0: loss = 0.00639412 (* 1 = 0.00639412 loss)
I0403 03:56:24.724305  2203 sgd_solver.cpp:106] Iteration 6363, lr = 0.0005
I0403 03:56:40.100075  2203 solver.cpp:228] Iteration 6384, loss = 0.058347
I0403 03:56:40.100177  2203 solver.cpp:244]     Train net output #0: loss = 0.0583469 (* 1 = 0.0583469 loss)
I0403 03:56:40.284386  2203 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 03:56:55.485405  2203 solver.cpp:228] Iteration 6405, loss = 0.00154596
I0403 03:56:55.485703  2203 solver.cpp:244]     Train net output #0: loss = 0.00154585 (* 1 = 0.00154585 loss)
I0403 03:56:55.651126  2203 sgd_solver.cpp:106] Iteration 6405, lr = 0.0005
I0403 03:57:10.905978  2203 solver.cpp:228] Iteration 6426, loss = 0.0352193
I0403 03:57:10.906069  2203 solver.cpp:244]     Train net output #0: loss = 0.0352192 (* 1 = 0.0352192 loss)
I0403 03:57:11.084861  2203 sgd_solver.cpp:106] Iteration 6426, lr = 0.0005
I0403 03:57:26.331169  2203 solver.cpp:228] Iteration 6447, loss = 0.0067083
I0403 03:57:26.331439  2203 solver.cpp:244]     Train net output #0: loss = 0.00670819 (* 1 = 0.00670819 loss)
I0403 03:57:26.509735  2203 sgd_solver.cpp:106] Iteration 6447, lr = 0.0005
I0403 03:57:41.928469  2203 solver.cpp:228] Iteration 6468, loss = 0.0013414
I0403 03:57:41.928580  2203 solver.cpp:244]     Train net output #0: loss = 0.00134129 (* 1 = 0.00134129 loss)
I0403 03:57:42.123024  2203 sgd_solver.cpp:106] Iteration 6468, lr = 0.0005
I0403 03:57:57.213492  2203 solver.cpp:228] Iteration 6489, loss = 0.00280293
I0403 03:57:57.213785  2203 solver.cpp:244]     Train net output #0: loss = 0.00280282 (* 1 = 0.00280282 loss)
I0403 03:57:57.389305  2203 sgd_solver.cpp:106] Iteration 6489, lr = 0.0005
I0403 03:58:12.411756  2203 solver.cpp:228] Iteration 6510, loss = 0.00184738
I0403 03:58:12.411844  2203 solver.cpp:244]     Train net output #0: loss = 0.00184727 (* 1 = 0.00184727 loss)
I0403 03:58:12.586067  2203 sgd_solver.cpp:106] Iteration 6510, lr = 0.0005
I0403 03:58:27.911206  2203 solver.cpp:228] Iteration 6531, loss = 0.0285817
I0403 03:58:27.911492  2203 solver.cpp:244]     Train net output #0: loss = 0.0285816 (* 1 = 0.0285816 loss)
I0403 03:58:28.083499  2203 sgd_solver.cpp:106] Iteration 6531, lr = 0.0005
I0403 03:58:33.980628  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_6540.caffemodel
I0403 03:58:36.732683  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_6540.solverstate
I0403 03:58:38.542909  2203 solver.cpp:337] Iteration 6540, Testing net (#0)
I0403 03:59:02.864079  2203 solver.cpp:404]     Test net output #0: accuracy = 0.970283
I0403 03:59:02.864385  2203 solver.cpp:404]     Test net output #1: loss = 0.10901 (* 1 = 0.10901 loss)
I0403 03:59:12.336061  2203 solver.cpp:228] Iteration 6552, loss = 0.0566131
I0403 03:59:12.336160  2203 solver.cpp:244]     Train net output #0: loss = 0.056613 (* 1 = 0.056613 loss)
I0403 03:59:12.526821  2203 sgd_solver.cpp:106] Iteration 6552, lr = 0.0005
I0403 03:59:27.663152  2203 solver.cpp:228] Iteration 6573, loss = 0.00331021
I0403 03:59:27.663250  2203 solver.cpp:244]     Train net output #0: loss = 0.00331009 (* 1 = 0.00331009 loss)
I0403 03:59:27.849020  2203 sgd_solver.cpp:106] Iteration 6573, lr = 0.0005
I0403 03:59:43.022613  2203 solver.cpp:228] Iteration 6594, loss = 0.00212914
I0403 03:59:43.022924  2203 solver.cpp:244]     Train net output #0: loss = 0.00212903 (* 1 = 0.00212903 loss)
I0403 03:59:43.234694  2203 sgd_solver.cpp:106] Iteration 6594, lr = 0.0005
I0403 03:59:58.581591  2203 solver.cpp:228] Iteration 6615, loss = 0.00425353
I0403 03:59:58.581679  2203 solver.cpp:244]     Train net output #0: loss = 0.00425342 (* 1 = 0.00425342 loss)
I0403 03:59:58.750947  2203 sgd_solver.cpp:106] Iteration 6615, lr = 0.0005
I0403 04:00:14.168624  2203 solver.cpp:228] Iteration 6636, loss = 0.0175544
I0403 04:00:14.168943  2203 solver.cpp:244]     Train net output #0: loss = 0.0175543 (* 1 = 0.0175543 loss)
I0403 04:00:14.375811  2203 sgd_solver.cpp:106] Iteration 6636, lr = 0.0005
I0403 04:00:29.504040  2203 solver.cpp:228] Iteration 6657, loss = 0.0320744
I0403 04:00:29.504135  2203 solver.cpp:244]     Train net output #0: loss = 0.0320743 (* 1 = 0.0320743 loss)
I0403 04:00:29.711791  2203 sgd_solver.cpp:106] Iteration 6657, lr = 0.0005
I0403 04:00:44.937726  2203 solver.cpp:228] Iteration 6678, loss = 0.00297953
I0403 04:00:44.938022  2203 solver.cpp:244]     Train net output #0: loss = 0.00297942 (* 1 = 0.00297942 loss)
I0403 04:00:45.112655  2203 sgd_solver.cpp:106] Iteration 6678, lr = 0.0005
I0403 04:01:00.419936  2203 solver.cpp:228] Iteration 6699, loss = 0.00545336
I0403 04:01:00.420023  2203 solver.cpp:244]     Train net output #0: loss = 0.00545325 (* 1 = 0.00545325 loss)
I0403 04:01:00.537946  2203 sgd_solver.cpp:106] Iteration 6699, lr = 0.0005
I0403 04:01:15.916445  2203 solver.cpp:228] Iteration 6720, loss = 0.0039788
I0403 04:01:15.916741  2203 solver.cpp:244]     Train net output #0: loss = 0.00397869 (* 1 = 0.00397869 loss)
I0403 04:01:16.067751  2203 sgd_solver.cpp:106] Iteration 6720, lr = 0.0005
I0403 04:01:31.557488  2203 solver.cpp:228] Iteration 6741, loss = 0.00480894
I0403 04:01:31.557590  2203 solver.cpp:244]     Train net output #0: loss = 0.00480883 (* 1 = 0.00480883 loss)
I0403 04:01:31.759706  2203 sgd_solver.cpp:106] Iteration 6741, lr = 0.0005
I0403 04:01:47.029729  2203 solver.cpp:228] Iteration 6762, loss = 0.0212586
I0403 04:01:47.030035  2203 solver.cpp:244]     Train net output #0: loss = 0.0212585 (* 1 = 0.0212585 loss)
I0403 04:01:47.216781  2203 sgd_solver.cpp:106] Iteration 6762, lr = 0.0005
I0403 04:02:02.327566  2203 solver.cpp:228] Iteration 6783, loss = 0.00109036
I0403 04:02:02.327666  2203 solver.cpp:244]     Train net output #0: loss = 0.00109024 (* 1 = 0.00109024 loss)
I0403 04:02:02.511822  2203 sgd_solver.cpp:106] Iteration 6783, lr = 0.0005
I0403 04:02:17.980149  2203 solver.cpp:228] Iteration 6804, loss = 0.00725926
I0403 04:02:17.980458  2203 solver.cpp:244]     Train net output #0: loss = 0.00725915 (* 1 = 0.00725915 loss)
I0403 04:02:18.187330  2203 sgd_solver.cpp:106] Iteration 6804, lr = 0.0005
I0403 04:02:33.218139  2203 solver.cpp:228] Iteration 6825, loss = 0.0346263
I0403 04:02:33.218225  2203 solver.cpp:244]     Train net output #0: loss = 0.0346262 (* 1 = 0.0346262 loss)
I0403 04:02:33.384213  2203 sgd_solver.cpp:106] Iteration 6825, lr = 0.0005
I0403 04:02:48.431861  2203 solver.cpp:228] Iteration 6846, loss = 0.0042447
I0403 04:02:48.432180  2203 solver.cpp:244]     Train net output #0: loss = 0.00424459 (* 1 = 0.00424459 loss)
I0403 04:02:48.614843  2203 sgd_solver.cpp:106] Iteration 6846, lr = 0.0005
I0403 04:03:03.828634  2203 solver.cpp:228] Iteration 6867, loss = 0.00165897
I0403 04:03:03.828730  2203 solver.cpp:244]     Train net output #0: loss = 0.00165886 (* 1 = 0.00165886 loss)
I0403 04:03:04.016083  2203 sgd_solver.cpp:106] Iteration 6867, lr = 0.0005
I0403 04:03:19.377519  2203 solver.cpp:228] Iteration 6888, loss = 0.00312917
I0403 04:03:19.377849  2203 solver.cpp:244]     Train net output #0: loss = 0.00312906 (* 1 = 0.00312906 loss)
I0403 04:03:19.548873  2203 sgd_solver.cpp:106] Iteration 6888, lr = 0.0005
I0403 04:03:35.116179  2203 solver.cpp:228] Iteration 6909, loss = 0.0027368
I0403 04:03:35.116273  2203 solver.cpp:244]     Train net output #0: loss = 0.00273669 (* 1 = 0.00273669 loss)
I0403 04:03:35.292836  2203 sgd_solver.cpp:106] Iteration 6909, lr = 0.0005
I0403 04:03:50.836812  2203 solver.cpp:228] Iteration 6930, loss = 0.00393295
I0403 04:03:50.837967  2203 solver.cpp:244]     Train net output #0: loss = 0.00393284 (* 1 = 0.00393284 loss)
I0403 04:03:50.993093  2203 sgd_solver.cpp:106] Iteration 6930, lr = 0.0005
I0403 04:04:06.415343  2203 solver.cpp:228] Iteration 6951, loss = 0.00800479
I0403 04:04:06.415432  2203 solver.cpp:244]     Train net output #0: loss = 0.00800468 (* 1 = 0.00800468 loss)
I0403 04:04:06.590335  2203 sgd_solver.cpp:106] Iteration 6951, lr = 0.0005
I0403 04:04:21.939489  2203 solver.cpp:228] Iteration 6972, loss = 0.00220544
I0403 04:04:21.939795  2203 solver.cpp:244]     Train net output #0: loss = 0.00220533 (* 1 = 0.00220533 loss)
I0403 04:04:22.155760  2203 sgd_solver.cpp:106] Iteration 6972, lr = 0.0005
I0403 04:04:24.347654  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_6976.caffemodel
I0403 04:04:27.148615  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_6976.solverstate
I0403 04:04:29.034267  2203 solver.cpp:337] Iteration 6976, Testing net (#0)
I0403 04:04:53.340070  2203 solver.cpp:404]     Test net output #0: accuracy = 0.971604
I0403 04:04:53.340365  2203 solver.cpp:404]     Test net output #1: loss = 0.1079 (* 1 = 0.1079 loss)
I0403 04:05:06.353943  2203 solver.cpp:228] Iteration 6993, loss = 0.00579611
I0403 04:05:06.354043  2203 solver.cpp:244]     Train net output #0: loss = 0.005796 (* 1 = 0.005796 loss)
I0403 04:05:06.565289  2203 sgd_solver.cpp:106] Iteration 6993, lr = 0.0005
I0403 04:05:21.800153  2203 solver.cpp:228] Iteration 7014, loss = 0.00414916
I0403 04:05:21.800237  2203 solver.cpp:244]     Train net output #0: loss = 0.00414905 (* 1 = 0.00414905 loss)
I0403 04:05:21.916853  2203 sgd_solver.cpp:106] Iteration 7014, lr = 0.0005
I0403 04:05:37.625803  2203 solver.cpp:228] Iteration 7035, loss = 0.0020962
I0403 04:05:37.626085  2203 solver.cpp:244]     Train net output #0: loss = 0.0020961 (* 1 = 0.0020961 loss)
I0403 04:05:37.800412  2203 sgd_solver.cpp:106] Iteration 7035, lr = 0.0005
I0403 04:05:53.153816  2203 solver.cpp:228] Iteration 7056, loss = 0.00295366
I0403 04:05:53.153918  2203 solver.cpp:244]     Train net output #0: loss = 0.00295356 (* 1 = 0.00295356 loss)
I0403 04:05:53.352835  2203 sgd_solver.cpp:106] Iteration 7056, lr = 0.0005
I0403 04:06:08.666575  2203 solver.cpp:228] Iteration 7077, loss = 0.00575257
I0403 04:06:08.666890  2203 solver.cpp:244]     Train net output #0: loss = 0.00575247 (* 1 = 0.00575247 loss)
I0403 04:06:08.833082  2203 sgd_solver.cpp:106] Iteration 7077, lr = 0.0005
I0403 04:06:24.143695  2203 solver.cpp:228] Iteration 7098, loss = 0.00196776
I0403 04:06:24.143790  2203 solver.cpp:244]     Train net output #0: loss = 0.00196766 (* 1 = 0.00196766 loss)
I0403 04:06:24.334588  2203 sgd_solver.cpp:106] Iteration 7098, lr = 0.0005
I0403 04:06:39.569803  2203 solver.cpp:228] Iteration 7119, loss = 0.00105525
I0403 04:06:39.570082  2203 solver.cpp:244]     Train net output #0: loss = 0.00105515 (* 1 = 0.00105515 loss)
I0403 04:06:39.753815  2203 sgd_solver.cpp:106] Iteration 7119, lr = 0.0005
I0403 04:06:54.847048  2203 solver.cpp:228] Iteration 7140, loss = 0.0149911
I0403 04:06:54.847131  2203 solver.cpp:244]     Train net output #0: loss = 0.014991 (* 1 = 0.014991 loss)
I0403 04:06:55.012291  2203 sgd_solver.cpp:106] Iteration 7140, lr = 0.0005
I0403 04:07:10.259569  2203 solver.cpp:228] Iteration 7161, loss = 0.000659354
I0403 04:07:10.259825  2203 solver.cpp:244]     Train net output #0: loss = 0.000659253 (* 1 = 0.000659253 loss)
I0403 04:07:10.445914  2203 sgd_solver.cpp:106] Iteration 7161, lr = 0.0005
I0403 04:07:25.478247  2203 solver.cpp:228] Iteration 7182, loss = 0.010283
I0403 04:07:25.478334  2203 solver.cpp:244]     Train net output #0: loss = 0.0102829 (* 1 = 0.0102829 loss)
I0403 04:07:25.637217  2203 sgd_solver.cpp:106] Iteration 7182, lr = 0.0005
I0403 04:07:41.127285  2203 solver.cpp:228] Iteration 7203, loss = 0.00102507
I0403 04:07:41.127560  2203 solver.cpp:244]     Train net output #0: loss = 0.00102497 (* 1 = 0.00102497 loss)
I0403 04:07:41.272496  2203 sgd_solver.cpp:106] Iteration 7203, lr = 0.0005
I0403 04:07:56.867889  2203 solver.cpp:228] Iteration 7224, loss = 0.00835973
I0403 04:07:56.867976  2203 solver.cpp:244]     Train net output #0: loss = 0.00835963 (* 1 = 0.00835963 loss)
I0403 04:07:57.038985  2203 sgd_solver.cpp:106] Iteration 7224, lr = 0.0005
I0403 04:08:12.562307  2203 solver.cpp:228] Iteration 7245, loss = 0.00156041
I0403 04:08:12.562551  2203 solver.cpp:244]     Train net output #0: loss = 0.0015603 (* 1 = 0.0015603 loss)
I0403 04:08:12.694051  2203 sgd_solver.cpp:106] Iteration 7245, lr = 0.0005
I0403 04:08:27.943059  2203 solver.cpp:228] Iteration 7266, loss = 0.0195047
I0403 04:08:27.943158  2203 solver.cpp:244]     Train net output #0: loss = 0.0195046 (* 1 = 0.0195046 loss)
I0403 04:08:28.148219  2203 sgd_solver.cpp:106] Iteration 7266, lr = 0.0005
I0403 04:08:43.520175  2203 solver.cpp:228] Iteration 7287, loss = 0.0151974
I0403 04:08:43.520442  2203 solver.cpp:244]     Train net output #0: loss = 0.0151973 (* 1 = 0.0151973 loss)
I0403 04:08:43.670022  2203 sgd_solver.cpp:106] Iteration 7287, lr = 0.0005
I0403 04:08:59.192142  2203 solver.cpp:228] Iteration 7308, loss = 0.00710494
I0403 04:08:59.192242  2203 solver.cpp:244]     Train net output #0: loss = 0.00710483 (* 1 = 0.00710483 loss)
I0403 04:08:59.401383  2203 sgd_solver.cpp:106] Iteration 7308, lr = 0.0005
I0403 04:09:14.712298  2203 solver.cpp:228] Iteration 7329, loss = 0.00118614
I0403 04:09:14.712586  2203 solver.cpp:244]     Train net output #0: loss = 0.00118602 (* 1 = 0.00118602 loss)
I0403 04:09:14.888723  2203 sgd_solver.cpp:106] Iteration 7329, lr = 0.0005
I0403 04:09:30.299036  2203 solver.cpp:228] Iteration 7350, loss = 0.00602575
I0403 04:09:30.299132  2203 solver.cpp:244]     Train net output #0: loss = 0.00602564 (* 1 = 0.00602564 loss)
I0403 04:09:30.527762  2203 sgd_solver.cpp:106] Iteration 7350, lr = 0.0005
I0403 04:09:45.774708  2203 solver.cpp:228] Iteration 7371, loss = 0.0316439
I0403 04:09:45.774976  2203 solver.cpp:244]     Train net output #0: loss = 0.0316438 (* 1 = 0.0316438 loss)
I0403 04:09:45.949132  2203 sgd_solver.cpp:106] Iteration 7371, lr = 0.0005
I0403 04:10:01.119245  2203 solver.cpp:228] Iteration 7392, loss = 0.00176798
I0403 04:10:01.119340  2203 solver.cpp:244]     Train net output #0: loss = 0.00176786 (* 1 = 0.00176786 loss)
I0403 04:10:01.315644  2203 sgd_solver.cpp:106] Iteration 7392, lr = 0.0005
I0403 04:10:15.438107  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_7412.caffemodel
I0403 04:10:18.180867  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_7412.solverstate
I0403 04:10:20.066653  2203 solver.cpp:337] Iteration 7412, Testing net (#0)
I0403 04:10:44.369046  2203 solver.cpp:404]     Test net output #0: accuracy = 0.971321
I0403 04:10:44.369151  2203 solver.cpp:404]     Test net output #1: loss = 0.106547 (* 1 = 0.106547 loss)
I0403 04:10:45.625569  2203 solver.cpp:228] Iteration 7413, loss = 0.00116262
I0403 04:10:45.625669  2203 solver.cpp:244]     Train net output #0: loss = 0.00116251 (* 1 = 0.00116251 loss)
I0403 04:10:45.865067  2203 sgd_solver.cpp:106] Iteration 7413, lr = 0.0005
I0403 04:11:01.154506  2203 solver.cpp:228] Iteration 7434, loss = 0.000941953
I0403 04:11:01.156167  2203 solver.cpp:244]     Train net output #0: loss = 0.000941838 (* 1 = 0.000941838 loss)
I0403 04:11:01.328899  2203 sgd_solver.cpp:106] Iteration 7434, lr = 0.0005
I0403 04:11:16.719372  2203 solver.cpp:228] Iteration 7455, loss = 0.0010022
I0403 04:11:16.719458  2203 solver.cpp:244]     Train net output #0: loss = 0.00100208 (* 1 = 0.00100208 loss)
I0403 04:11:16.882598  2203 sgd_solver.cpp:106] Iteration 7455, lr = 0.0005
I0403 04:11:32.010386  2203 solver.cpp:228] Iteration 7476, loss = 0.0258401
I0403 04:11:32.010630  2203 solver.cpp:244]     Train net output #0: loss = 0.02584 (* 1 = 0.02584 loss)
I0403 04:11:32.170308  2203 sgd_solver.cpp:106] Iteration 7476, lr = 0.0005
I0403 04:11:47.515980  2203 solver.cpp:228] Iteration 7497, loss = 0.00132748
I0403 04:11:47.516091  2203 solver.cpp:244]     Train net output #0: loss = 0.00132737 (* 1 = 0.00132737 loss)
I0403 04:11:47.695214  2203 sgd_solver.cpp:106] Iteration 7497, lr = 0.0005
I0403 04:12:03.130651  2203 solver.cpp:228] Iteration 7518, loss = 0.00296693
I0403 04:12:03.130921  2203 solver.cpp:244]     Train net output #0: loss = 0.00296682 (* 1 = 0.00296682 loss)
I0403 04:12:03.279706  2203 sgd_solver.cpp:106] Iteration 7518, lr = 0.0005
I0403 04:12:18.917778  2203 solver.cpp:228] Iteration 7539, loss = 0.00381512
I0403 04:12:18.917881  2203 solver.cpp:244]     Train net output #0: loss = 0.003815 (* 1 = 0.003815 loss)
I0403 04:12:19.112689  2203 sgd_solver.cpp:106] Iteration 7539, lr = 0.0005
I0403 04:12:34.377243  2203 solver.cpp:228] Iteration 7560, loss = 0.00129969
I0403 04:12:34.377540  2203 solver.cpp:244]     Train net output #0: loss = 0.00129957 (* 1 = 0.00129957 loss)
I0403 04:12:34.551903  2203 sgd_solver.cpp:106] Iteration 7560, lr = 0.0005
I0403 04:12:49.802700  2203 solver.cpp:228] Iteration 7581, loss = 0.0171388
I0403 04:12:49.802791  2203 solver.cpp:244]     Train net output #0: loss = 0.0171387 (* 1 = 0.0171387 loss)
I0403 04:12:50.026693  2203 sgd_solver.cpp:106] Iteration 7581, lr = 0.0005
I0403 04:13:05.144557  2203 solver.cpp:228] Iteration 7602, loss = 0.0037816
I0403 04:13:05.144840  2203 solver.cpp:244]     Train net output #0: loss = 0.00378147 (* 1 = 0.00378147 loss)
I0403 04:13:05.323318  2203 sgd_solver.cpp:106] Iteration 7602, lr = 0.0005
I0403 04:13:20.548544  2203 solver.cpp:228] Iteration 7623, loss = 0.00407065
I0403 04:13:20.548630  2203 solver.cpp:244]     Train net output #0: loss = 0.00407053 (* 1 = 0.00407053 loss)
I0403 04:13:20.718971  2203 sgd_solver.cpp:106] Iteration 7623, lr = 0.0005
I0403 04:13:35.963435  2203 solver.cpp:228] Iteration 7644, loss = 0.0025666
I0403 04:13:35.963755  2203 solver.cpp:244]     Train net output #0: loss = 0.00256648 (* 1 = 0.00256648 loss)
I0403 04:13:36.185243  2203 sgd_solver.cpp:106] Iteration 7644, lr = 0.0005
I0403 04:13:51.773509  2203 solver.cpp:228] Iteration 7665, loss = 0.0201968
I0403 04:13:51.773600  2203 solver.cpp:244]     Train net output #0: loss = 0.0201967 (* 1 = 0.0201967 loss)
I0403 04:13:51.923187  2203 sgd_solver.cpp:106] Iteration 7665, lr = 0.0005
I0403 04:14:07.468911  2203 solver.cpp:228] Iteration 7686, loss = 0.00517778
I0403 04:14:07.469187  2203 solver.cpp:244]     Train net output #0: loss = 0.00517767 (* 1 = 0.00517767 loss)
I0403 04:14:07.653235  2203 sgd_solver.cpp:106] Iteration 7686, lr = 0.0005
I0403 04:14:23.152842  2203 solver.cpp:228] Iteration 7707, loss = 0.00316546
I0403 04:14:23.152938  2203 solver.cpp:244]     Train net output #0: loss = 0.00316535 (* 1 = 0.00316535 loss)
I0403 04:14:23.341284  2203 sgd_solver.cpp:106] Iteration 7707, lr = 0.0005
I0403 04:14:38.707388  2203 solver.cpp:228] Iteration 7728, loss = 0.000838453
I0403 04:14:38.707705  2203 solver.cpp:244]     Train net output #0: loss = 0.000838335 (* 1 = 0.000838335 loss)
I0403 04:14:38.891623  2203 sgd_solver.cpp:106] Iteration 7728, lr = 0.0005
I0403 04:14:54.393745  2203 solver.cpp:228] Iteration 7749, loss = 0.00928377
I0403 04:14:54.393834  2203 solver.cpp:244]     Train net output #0: loss = 0.00928365 (* 1 = 0.00928365 loss)
I0403 04:14:54.567526  2203 sgd_solver.cpp:106] Iteration 7749, lr = 0.0005
I0403 04:15:10.260253  2203 solver.cpp:228] Iteration 7770, loss = 0.0094326
I0403 04:15:10.260567  2203 solver.cpp:244]     Train net output #0: loss = 0.00943248 (* 1 = 0.00943248 loss)
I0403 04:15:10.485703  2203 sgd_solver.cpp:106] Iteration 7770, lr = 0.0005
I0403 04:15:25.768126  2203 solver.cpp:228] Iteration 7791, loss = 0.00441201
I0403 04:15:25.768223  2203 solver.cpp:244]     Train net output #0: loss = 0.0044119 (* 1 = 0.0044119 loss)
I0403 04:15:25.959082  2203 sgd_solver.cpp:106] Iteration 7791, lr = 0.0005
I0403 04:15:41.096115  2203 solver.cpp:228] Iteration 7812, loss = 0.0102617
I0403 04:15:41.096405  2203 solver.cpp:244]     Train net output #0: loss = 0.0102616 (* 1 = 0.0102616 loss)
I0403 04:15:41.263559  2203 sgd_solver.cpp:106] Iteration 7812, lr = 0.0005
I0403 04:15:56.997887  2203 solver.cpp:228] Iteration 7833, loss = 0.00538149
I0403 04:15:56.997988  2203 solver.cpp:244]     Train net output #0: loss = 0.00538138 (* 1 = 0.00538138 loss)
I0403 04:15:57.185920  2203 sgd_solver.cpp:106] Iteration 7833, lr = 0.0005
I0403 04:16:07.409373  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_7848.caffemodel
I0403 04:16:10.091456  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_7848.solverstate
I0403 04:16:11.882800  2203 solver.cpp:337] Iteration 7848, Testing net (#0)
I0403 04:16:36.205116  2203 solver.cpp:404]     Test net output #0: accuracy = 0.970944
I0403 04:16:36.205209  2203 solver.cpp:404]     Test net output #1: loss = 0.109074 (* 1 = 0.109074 loss)
I0403 04:16:41.145341  2203 solver.cpp:228] Iteration 7854, loss = 0.00402263
I0403 04:16:41.145427  2203 solver.cpp:244]     Train net output #0: loss = 0.00402252 (* 1 = 0.00402252 loss)
I0403 04:16:41.325608  2203 sgd_solver.cpp:106] Iteration 7854, lr = 0.0005
I0403 04:16:56.761530  2203 solver.cpp:228] Iteration 7875, loss = 0.00198521
I0403 04:16:56.761813  2203 solver.cpp:244]     Train net output #0: loss = 0.0019851 (* 1 = 0.0019851 loss)
I0403 04:16:56.903262  2203 sgd_solver.cpp:106] Iteration 7875, lr = 0.0005
I0403 04:17:12.518864  2203 solver.cpp:228] Iteration 7896, loss = 0.00825059
I0403 04:17:12.518954  2203 solver.cpp:244]     Train net output #0: loss = 0.00825048 (* 1 = 0.00825048 loss)
I0403 04:17:12.693920  2203 sgd_solver.cpp:106] Iteration 7896, lr = 0.0005
I0403 04:17:27.946264  2203 solver.cpp:228] Iteration 7917, loss = 0.00166334
I0403 04:17:27.946593  2203 solver.cpp:244]     Train net output #0: loss = 0.00166323 (* 1 = 0.00166323 loss)
I0403 04:17:28.130579  2203 sgd_solver.cpp:106] Iteration 7917, lr = 0.0005
I0403 04:17:43.763221  2203 solver.cpp:228] Iteration 7938, loss = 0.00168772
I0403 04:17:43.763312  2203 solver.cpp:244]     Train net output #0: loss = 0.00168762 (* 1 = 0.00168762 loss)
I0403 04:17:43.905884  2203 sgd_solver.cpp:106] Iteration 7938, lr = 0.0005
I0403 04:17:59.312809  2203 solver.cpp:228] Iteration 7959, loss = 0.000749216
I0403 04:17:59.313683  2203 solver.cpp:244]     Train net output #0: loss = 0.000749104 (* 1 = 0.000749104 loss)
I0403 04:17:59.489995  2203 sgd_solver.cpp:106] Iteration 7959, lr = 0.0005
I0403 04:18:14.929615  2203 solver.cpp:228] Iteration 7980, loss = 0.000816934
I0403 04:18:14.929703  2203 solver.cpp:244]     Train net output #0: loss = 0.000816826 (* 1 = 0.000816826 loss)
I0403 04:18:15.079676  2203 sgd_solver.cpp:106] Iteration 7980, lr = 0.0005
I0403 04:18:30.579143  2203 solver.cpp:228] Iteration 8001, loss = 0.00412974
I0403 04:18:30.584617  2203 solver.cpp:244]     Train net output #0: loss = 0.00412963 (* 1 = 0.00412963 loss)
I0403 04:18:30.781100  2203 sgd_solver.cpp:106] Iteration 8001, lr = 0.0005
I0403 04:18:46.067980  2203 solver.cpp:228] Iteration 8022, loss = 0.00542673
I0403 04:18:46.068068  2203 solver.cpp:244]     Train net output #0: loss = 0.00542662 (* 1 = 0.00542662 loss)
I0403 04:18:46.240214  2203 sgd_solver.cpp:106] Iteration 8022, lr = 0.0005
I0403 04:19:01.715888  2203 solver.cpp:228] Iteration 8043, loss = 0.00616715
I0403 04:19:01.716179  2203 solver.cpp:244]     Train net output #0: loss = 0.00616705 (* 1 = 0.00616705 loss)
I0403 04:19:01.878352  2203 sgd_solver.cpp:106] Iteration 8043, lr = 0.0005
I0403 04:19:17.278832  2203 solver.cpp:228] Iteration 8064, loss = 0.0102926
I0403 04:19:17.278929  2203 solver.cpp:244]     Train net output #0: loss = 0.0102925 (* 1 = 0.0102925 loss)
I0403 04:19:17.484920  2203 sgd_solver.cpp:106] Iteration 8064, lr = 0.0005
I0403 04:19:33.103802  2203 solver.cpp:228] Iteration 8085, loss = 0.00250136
I0403 04:19:33.104089  2203 solver.cpp:244]     Train net output #0: loss = 0.00250125 (* 1 = 0.00250125 loss)
I0403 04:19:33.263993  2203 sgd_solver.cpp:106] Iteration 8085, lr = 0.0005
I0403 04:19:48.775733  2203 solver.cpp:228] Iteration 8106, loss = 0.0185445
I0403 04:19:48.775817  2203 solver.cpp:244]     Train net output #0: loss = 0.0185444 (* 1 = 0.0185444 loss)
I0403 04:19:48.951885  2203 sgd_solver.cpp:106] Iteration 8106, lr = 0.0005
I0403 04:20:04.184206  2203 solver.cpp:228] Iteration 8127, loss = 0.00263223
I0403 04:20:04.184471  2203 solver.cpp:244]     Train net output #0: loss = 0.00263212 (* 1 = 0.00263212 loss)
I0403 04:20:04.352797  2203 sgd_solver.cpp:106] Iteration 8127, lr = 0.0005
I0403 04:20:19.578565  2203 solver.cpp:228] Iteration 8148, loss = 0.0246426
I0403 04:20:19.578667  2203 solver.cpp:244]     Train net output #0: loss = 0.0246425 (* 1 = 0.0246425 loss)
I0403 04:20:19.816164  2203 sgd_solver.cpp:106] Iteration 8148, lr = 0.0005
I0403 04:20:35.126719  2203 solver.cpp:228] Iteration 8169, loss = 0.00268766
I0403 04:20:35.127007  2203 solver.cpp:244]     Train net output #0: loss = 0.00268755 (* 1 = 0.00268755 loss)
I0403 04:20:35.303372  2203 sgd_solver.cpp:106] Iteration 8169, lr = 0.0005
I0403 04:20:50.566144  2203 solver.cpp:228] Iteration 8190, loss = 0.0156561
I0403 04:20:50.566232  2203 solver.cpp:244]     Train net output #0: loss = 0.015656 (* 1 = 0.015656 loss)
I0403 04:20:50.733782  2203 sgd_solver.cpp:106] Iteration 8190, lr = 0.0005
I0403 04:21:06.154400  2203 solver.cpp:228] Iteration 8211, loss = 0.00509268
I0403 04:21:06.154688  2203 solver.cpp:244]     Train net output #0: loss = 0.00509257 (* 1 = 0.00509257 loss)
I0403 04:21:06.329187  2203 sgd_solver.cpp:106] Iteration 8211, lr = 0.0005
I0403 04:21:21.656967  2203 solver.cpp:228] Iteration 8232, loss = 0.00514003
I0403 04:21:21.657066  2203 solver.cpp:244]     Train net output #0: loss = 0.00513993 (* 1 = 0.00513993 loss)
I0403 04:21:21.863731  2203 sgd_solver.cpp:106] Iteration 8232, lr = 0.0005
I0403 04:21:37.203897  2203 solver.cpp:228] Iteration 8253, loss = 0.00108512
I0403 04:21:37.204190  2203 solver.cpp:244]     Train net output #0: loss = 0.00108501 (* 1 = 0.00108501 loss)
I0403 04:21:37.412667  2203 sgd_solver.cpp:106] Iteration 8253, lr = 0.0005
I0403 04:21:52.620682  2203 solver.cpp:228] Iteration 8274, loss = 0.0110723
I0403 04:21:52.620779  2203 solver.cpp:244]     Train net output #0: loss = 0.0110722 (* 1 = 0.0110722 loss)
I0403 04:21:52.822794  2203 sgd_solver.cpp:106] Iteration 8274, lr = 0.0005
I0403 04:21:59.593077  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_8284.caffemodel
I0403 04:22:02.465523  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_8284.solverstate
I0403 04:22:04.254374  2203 solver.cpp:337] Iteration 8284, Testing net (#0)
I0403 04:22:28.580384  2203 solver.cpp:404]     Test net output #0: accuracy = 0.971698
I0403 04:22:28.580729  2203 solver.cpp:404]     Test net output #1: loss = 0.108871 (* 1 = 0.108871 loss)
I0403 04:22:37.217952  2203 solver.cpp:228] Iteration 8295, loss = 0.00228164
I0403 04:22:37.218042  2203 solver.cpp:244]     Train net output #0: loss = 0.00228153 (* 1 = 0.00228153 loss)
I0403 04:22:37.389952  2203 sgd_solver.cpp:106] Iteration 8295, lr = 0.0005
I0403 04:22:52.732506  2203 solver.cpp:228] Iteration 8316, loss = 0.0399058
I0403 04:22:52.732596  2203 solver.cpp:244]     Train net output #0: loss = 0.0399056 (* 1 = 0.0399056 loss)
I0403 04:22:52.908058  2203 sgd_solver.cpp:106] Iteration 8316, lr = 0.0005
I0403 04:23:08.282655  2203 solver.cpp:228] Iteration 8337, loss = 0.00428647
I0403 04:23:08.282977  2203 solver.cpp:244]     Train net output #0: loss = 0.00428637 (* 1 = 0.00428637 loss)
I0403 04:23:08.512210  2203 sgd_solver.cpp:106] Iteration 8337, lr = 0.0005
I0403 04:23:24.225766  2203 solver.cpp:228] Iteration 8358, loss = 0.00291164
I0403 04:23:24.225867  2203 solver.cpp:244]     Train net output #0: loss = 0.00291153 (* 1 = 0.00291153 loss)
I0403 04:23:24.409859  2203 sgd_solver.cpp:106] Iteration 8358, lr = 0.0005
I0403 04:23:39.919544  2203 solver.cpp:228] Iteration 8379, loss = 0.0274283
I0403 04:23:39.919831  2203 solver.cpp:244]     Train net output #0: loss = 0.0274282 (* 1 = 0.0274282 loss)
I0403 04:23:40.090986  2203 sgd_solver.cpp:106] Iteration 8379, lr = 0.0005
I0403 04:23:55.380774  2203 solver.cpp:228] Iteration 8400, loss = 0.00201683
I0403 04:23:55.380872  2203 solver.cpp:244]     Train net output #0: loss = 0.00201673 (* 1 = 0.00201673 loss)
I0403 04:23:55.579988  2203 sgd_solver.cpp:106] Iteration 8400, lr = 0.0005
I0403 04:24:10.699700  2203 solver.cpp:228] Iteration 8421, loss = 0.00145899
I0403 04:24:10.699985  2203 solver.cpp:244]     Train net output #0: loss = 0.00145889 (* 1 = 0.00145889 loss)
I0403 04:24:10.808653  2203 sgd_solver.cpp:106] Iteration 8421, lr = 0.0005
I0403 04:24:26.311465  2203 solver.cpp:228] Iteration 8442, loss = 0.00224704
I0403 04:24:26.311560  2203 solver.cpp:244]     Train net output #0: loss = 0.00224694 (* 1 = 0.00224694 loss)
I0403 04:24:26.474256  2203 sgd_solver.cpp:106] Iteration 8442, lr = 0.0005
I0403 04:24:41.849146  2203 solver.cpp:228] Iteration 8463, loss = 0.00199506
I0403 04:24:41.849432  2203 solver.cpp:244]     Train net output #0: loss = 0.00199496 (* 1 = 0.00199496 loss)
I0403 04:24:41.967494  2203 sgd_solver.cpp:106] Iteration 8463, lr = 0.0005
I0403 04:24:57.328752  2203 solver.cpp:228] Iteration 8484, loss = 0.00241149
I0403 04:24:57.328851  2203 solver.cpp:244]     Train net output #0: loss = 0.00241139 (* 1 = 0.00241139 loss)
I0403 04:24:57.501585  2203 sgd_solver.cpp:106] Iteration 8484, lr = 0.0005
I0403 04:25:12.715140  2203 solver.cpp:228] Iteration 8505, loss = 0.000547039
I0403 04:25:12.715418  2203 solver.cpp:244]     Train net output #0: loss = 0.000546947 (* 1 = 0.000546947 loss)
I0403 04:25:12.899188  2203 sgd_solver.cpp:106] Iteration 8505, lr = 0.0005
I0403 04:25:28.138226  2203 solver.cpp:228] Iteration 8526, loss = 0.0146627
I0403 04:25:28.138312  2203 solver.cpp:244]     Train net output #0: loss = 0.0146627 (* 1 = 0.0146627 loss)
I0403 04:25:28.313410  2203 sgd_solver.cpp:106] Iteration 8526, lr = 0.0005
I0403 04:25:43.681372  2203 solver.cpp:228] Iteration 8547, loss = 0.00376636
I0403 04:25:43.681681  2203 solver.cpp:244]     Train net output #0: loss = 0.00376628 (* 1 = 0.00376628 loss)
I0403 04:25:43.848871  2203 sgd_solver.cpp:106] Iteration 8547, lr = 0.0005
I0403 04:25:59.042171  2203 solver.cpp:228] Iteration 8568, loss = 0.00418296
I0403 04:25:59.042269  2203 solver.cpp:244]     Train net output #0: loss = 0.00418287 (* 1 = 0.00418287 loss)
I0403 04:25:59.226171  2203 sgd_solver.cpp:106] Iteration 8568, lr = 0.0005
I0403 04:26:14.526947  2203 solver.cpp:228] Iteration 8589, loss = 0.00295476
I0403 04:26:14.527268  2203 solver.cpp:244]     Train net output #0: loss = 0.00295468 (* 1 = 0.00295468 loss)
I0403 04:26:14.701879  2203 sgd_solver.cpp:106] Iteration 8589, lr = 0.0005
I0403 04:26:30.020354  2203 solver.cpp:228] Iteration 8610, loss = 0.00116715
I0403 04:26:30.020448  2203 solver.cpp:244]     Train net output #0: loss = 0.00116706 (* 1 = 0.00116706 loss)
I0403 04:26:30.161505  2203 sgd_solver.cpp:106] Iteration 8610, lr = 0.0005
I0403 04:26:45.431592  2203 solver.cpp:228] Iteration 8631, loss = 0.00980441
I0403 04:26:45.431898  2203 solver.cpp:244]     Train net output #0: loss = 0.00980432 (* 1 = 0.00980432 loss)
I0403 04:26:45.624981  2203 sgd_solver.cpp:106] Iteration 8631, lr = 0.0005
I0403 04:27:01.238864  2203 solver.cpp:228] Iteration 8652, loss = 0.0011347
I0403 04:27:01.238955  2203 solver.cpp:244]     Train net output #0: loss = 0.00113461 (* 1 = 0.00113461 loss)
I0403 04:27:01.339027  2203 sgd_solver.cpp:106] Iteration 8652, lr = 0.0005
I0403 04:27:16.968932  2203 solver.cpp:228] Iteration 8673, loss = 0.00546969
I0403 04:27:16.969223  2203 solver.cpp:244]     Train net output #0: loss = 0.00546961 (* 1 = 0.00546961 loss)
I0403 04:27:17.146489  2203 sgd_solver.cpp:106] Iteration 8673, lr = 0.0005
I0403 04:27:32.746279  2203 solver.cpp:228] Iteration 8694, loss = 0.0193333
I0403 04:27:32.751888  2203 solver.cpp:244]     Train net output #0: loss = 0.0193332 (* 1 = 0.0193332 loss)
I0403 04:27:32.923810  2203 sgd_solver.cpp:106] Iteration 8694, lr = 0.0005
I0403 04:27:48.313365  2203 solver.cpp:228] Iteration 8715, loss = 0.00535066
I0403 04:27:48.313663  2203 solver.cpp:244]     Train net output #0: loss = 0.00535058 (* 1 = 0.00535058 loss)
I0403 04:27:48.464053  2203 sgd_solver.cpp:106] Iteration 8715, lr = 0.0005
I0403 04:27:51.581111  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_8720.caffemodel
I0403 04:27:54.257767  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_8720.solverstate
I0403 04:27:56.080844  2203 solver.cpp:337] Iteration 8720, Testing net (#0)
I0403 04:28:20.392711  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972264
I0403 04:28:20.393007  2203 solver.cpp:404]     Test net output #1: loss = 0.109322 (* 1 = 0.109322 loss)
I0403 04:28:32.883750  2203 solver.cpp:228] Iteration 8736, loss = 0.000698151
I0403 04:28:32.883838  2203 solver.cpp:244]     Train net output #0: loss = 0.000698068 (* 1 = 0.000698068 loss)
I0403 04:28:33.044325  2203 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 04:28:48.305896  2203 solver.cpp:228] Iteration 8757, loss = 0.000493037
I0403 04:28:48.305994  2203 solver.cpp:244]     Train net output #0: loss = 0.000492964 (* 1 = 0.000492964 loss)
I0403 04:28:48.498869  2203 sgd_solver.cpp:106] Iteration 8757, lr = 5e-05
I0403 04:29:03.863311  2203 solver.cpp:228] Iteration 8778, loss = 0.0116039
I0403 04:29:03.863582  2203 solver.cpp:244]     Train net output #0: loss = 0.0116039 (* 1 = 0.0116039 loss)
I0403 04:29:04.031208  2203 sgd_solver.cpp:106] Iteration 8778, lr = 5e-05
I0403 04:29:19.469581  2203 solver.cpp:228] Iteration 8799, loss = 0.00462737
I0403 04:29:19.469669  2203 solver.cpp:244]     Train net output #0: loss = 0.0046273 (* 1 = 0.0046273 loss)
I0403 04:29:19.631587  2203 sgd_solver.cpp:106] Iteration 8799, lr = 5e-05
I0403 04:29:34.927685  2203 solver.cpp:228] Iteration 8820, loss = 0.000212123
I0403 04:29:34.927975  2203 solver.cpp:244]     Train net output #0: loss = 0.000212049 (* 1 = 0.000212049 loss)
I0403 04:29:35.102668  2203 sgd_solver.cpp:106] Iteration 8820, lr = 5e-05
I0403 04:29:50.568415  2203 solver.cpp:228] Iteration 8841, loss = 0.0032477
I0403 04:29:50.568503  2203 solver.cpp:244]     Train net output #0: loss = 0.00324763 (* 1 = 0.00324763 loss)
I0403 04:29:50.749546  2203 sgd_solver.cpp:106] Iteration 8841, lr = 5e-05
I0403 04:30:06.085793  2203 solver.cpp:228] Iteration 8862, loss = 0.0010887
I0403 04:30:06.086113  2203 solver.cpp:244]     Train net output #0: loss = 0.00108863 (* 1 = 0.00108863 loss)
I0403 04:30:06.263165  2203 sgd_solver.cpp:106] Iteration 8862, lr = 5e-05
I0403 04:30:21.482548  2203 solver.cpp:228] Iteration 8883, loss = 0.00664617
I0403 04:30:21.482647  2203 solver.cpp:244]     Train net output #0: loss = 0.0066461 (* 1 = 0.0066461 loss)
I0403 04:30:21.668972  2203 sgd_solver.cpp:106] Iteration 8883, lr = 5e-05
I0403 04:30:36.995561  2203 solver.cpp:228] Iteration 8904, loss = 0.00137315
I0403 04:30:36.997433  2203 solver.cpp:244]     Train net output #0: loss = 0.00137308 (* 1 = 0.00137308 loss)
I0403 04:30:37.184448  2203 sgd_solver.cpp:106] Iteration 8904, lr = 5e-05
I0403 04:30:52.286859  2203 solver.cpp:228] Iteration 8925, loss = 0.00122144
I0403 04:30:52.286958  2203 solver.cpp:244]     Train net output #0: loss = 0.00122137 (* 1 = 0.00122137 loss)
I0403 04:30:52.484752  2203 sgd_solver.cpp:106] Iteration 8925, lr = 5e-05
I0403 04:31:07.782510  2203 solver.cpp:228] Iteration 8946, loss = 0.0310924
I0403 04:31:07.782809  2203 solver.cpp:244]     Train net output #0: loss = 0.0310924 (* 1 = 0.0310924 loss)
I0403 04:31:07.949472  2203 sgd_solver.cpp:106] Iteration 8946, lr = 5e-05
I0403 04:31:23.306722  2203 solver.cpp:228] Iteration 8967, loss = 0.000901642
I0403 04:31:23.306823  2203 solver.cpp:244]     Train net output #0: loss = 0.000901566 (* 1 = 0.000901566 loss)
I0403 04:31:23.526222  2203 sgd_solver.cpp:106] Iteration 8967, lr = 5e-05
I0403 04:31:38.879848  2203 solver.cpp:228] Iteration 8988, loss = 0.0115112
I0403 04:31:38.880086  2203 solver.cpp:244]     Train net output #0: loss = 0.0115112 (* 1 = 0.0115112 loss)
I0403 04:31:39.049499  2203 sgd_solver.cpp:106] Iteration 8988, lr = 5e-05
I0403 04:31:54.595296  2203 solver.cpp:228] Iteration 9009, loss = 0.0355623
I0403 04:31:54.595396  2203 solver.cpp:244]     Train net output #0: loss = 0.0355622 (* 1 = 0.0355622 loss)
I0403 04:31:54.784183  2203 sgd_solver.cpp:106] Iteration 9009, lr = 5e-05
I0403 04:32:10.181159  2203 solver.cpp:228] Iteration 9030, loss = 0.00671355
I0403 04:32:10.181457  2203 solver.cpp:244]     Train net output #0: loss = 0.00671349 (* 1 = 0.00671349 loss)
I0403 04:32:10.340745  2203 sgd_solver.cpp:106] Iteration 9030, lr = 5e-05
I0403 04:32:25.729470  2203 solver.cpp:228] Iteration 9051, loss = 0.00198765
I0403 04:32:25.729580  2203 solver.cpp:244]     Train net output #0: loss = 0.00198758 (* 1 = 0.00198758 loss)
I0403 04:32:25.899983  2203 sgd_solver.cpp:106] Iteration 9051, lr = 5e-05
I0403 04:32:41.326246  2203 solver.cpp:228] Iteration 9072, loss = 0.000904411
I0403 04:32:41.326534  2203 solver.cpp:244]     Train net output #0: loss = 0.000904346 (* 1 = 0.000904346 loss)
I0403 04:32:41.544427  2203 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 04:32:56.779062  2203 solver.cpp:228] Iteration 9093, loss = 0.000793274
I0403 04:32:56.798130  2203 solver.cpp:244]     Train net output #0: loss = 0.000793212 (* 1 = 0.000793212 loss)
I0403 04:32:56.949826  2203 sgd_solver.cpp:106] Iteration 9093, lr = 5e-05
I0403 04:33:12.354151  2203 solver.cpp:228] Iteration 9114, loss = 0.0267396
I0403 04:33:12.354440  2203 solver.cpp:244]     Train net output #0: loss = 0.0267395 (* 1 = 0.0267395 loss)
I0403 04:33:12.522099  2203 sgd_solver.cpp:106] Iteration 9114, lr = 5e-05
I0403 04:33:27.847580  2203 solver.cpp:228] Iteration 9135, loss = 0.00244224
I0403 04:33:27.847664  2203 solver.cpp:244]     Train net output #0: loss = 0.00244218 (* 1 = 0.00244218 loss)
I0403 04:33:28.021152  2203 sgd_solver.cpp:106] Iteration 9135, lr = 5e-05
I0403 04:33:42.739327  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_9156.caffemodel
I0403 04:33:45.450062  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_9156.solverstate
I0403 04:33:47.281921  2203 solver.cpp:337] Iteration 9156, Testing net (#0)
I0403 04:34:11.630338  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972642
I0403 04:34:11.630432  2203 solver.cpp:404]     Test net output #1: loss = 0.108058 (* 1 = 0.108058 loss)
I0403 04:34:12.140619  2203 solver.cpp:228] Iteration 9156, loss = 0.00431598
I0403 04:34:12.140712  2203 solver.cpp:244]     Train net output #0: loss = 0.00431592 (* 1 = 0.00431592 loss)
I0403 04:34:12.326100  2203 sgd_solver.cpp:106] Iteration 9156, lr = 5e-05
I0403 04:34:27.646752  2203 solver.cpp:228] Iteration 9177, loss = 0.000318815
I0403 04:34:27.647073  2203 solver.cpp:244]     Train net output #0: loss = 0.000318751 (* 1 = 0.000318751 loss)
I0403 04:34:27.821017  2203 sgd_solver.cpp:106] Iteration 9177, lr = 5e-05
I0403 04:34:43.259634  2203 solver.cpp:228] Iteration 9198, loss = 0.017336
I0403 04:34:43.259729  2203 solver.cpp:244]     Train net output #0: loss = 0.0173359 (* 1 = 0.0173359 loss)
I0403 04:34:43.443696  2203 sgd_solver.cpp:106] Iteration 9198, lr = 5e-05
I0403 04:34:58.771231  2203 solver.cpp:228] Iteration 9219, loss = 0.00112294
I0403 04:34:58.771518  2203 solver.cpp:244]     Train net output #0: loss = 0.00112287 (* 1 = 0.00112287 loss)
I0403 04:34:58.986214  2203 sgd_solver.cpp:106] Iteration 9219, lr = 5e-05
I0403 04:35:14.244870  2203 solver.cpp:228] Iteration 9240, loss = 0.000687951
I0403 04:35:14.244973  2203 solver.cpp:244]     Train net output #0: loss = 0.000687887 (* 1 = 0.000687887 loss)
I0403 04:35:14.470639  2203 sgd_solver.cpp:106] Iteration 9240, lr = 5e-05
I0403 04:35:29.750718  2203 solver.cpp:228] Iteration 9261, loss = 0.00771094
I0403 04:35:29.750984  2203 solver.cpp:244]     Train net output #0: loss = 0.00771088 (* 1 = 0.00771088 loss)
I0403 04:35:29.850739  2203 sgd_solver.cpp:106] Iteration 9261, lr = 5e-05
I0403 04:35:45.267601  2203 solver.cpp:228] Iteration 9282, loss = 0.0433641
I0403 04:35:45.267689  2203 solver.cpp:244]     Train net output #0: loss = 0.043364 (* 1 = 0.043364 loss)
I0403 04:35:45.416692  2203 sgd_solver.cpp:106] Iteration 9282, lr = 5e-05
I0403 04:36:00.766089  2203 solver.cpp:228] Iteration 9303, loss = 0.00147647
I0403 04:36:00.767912  2203 solver.cpp:244]     Train net output #0: loss = 0.0014764 (* 1 = 0.0014764 loss)
I0403 04:36:00.923873  2203 sgd_solver.cpp:106] Iteration 9303, lr = 5e-05
I0403 04:36:16.200930  2203 solver.cpp:228] Iteration 9324, loss = 0.000875304
I0403 04:36:16.201019  2203 solver.cpp:244]     Train net output #0: loss = 0.000875236 (* 1 = 0.000875236 loss)
I0403 04:36:16.349444  2203 sgd_solver.cpp:106] Iteration 9324, lr = 5e-05
I0403 04:36:31.624722  2203 solver.cpp:228] Iteration 9345, loss = 0.000928004
I0403 04:36:31.625008  2203 solver.cpp:244]     Train net output #0: loss = 0.000927935 (* 1 = 0.000927935 loss)
I0403 04:36:31.783531  2203 sgd_solver.cpp:106] Iteration 9345, lr = 5e-05
I0403 04:36:47.117866  2203 solver.cpp:228] Iteration 9366, loss = 0.0027206
I0403 04:36:47.117961  2203 solver.cpp:244]     Train net output #0: loss = 0.00272053 (* 1 = 0.00272053 loss)
I0403 04:36:47.276463  2203 sgd_solver.cpp:106] Iteration 9366, lr = 5e-05
I0403 04:37:02.959271  2203 solver.cpp:228] Iteration 9387, loss = 0.0147777
I0403 04:37:02.959580  2203 solver.cpp:244]     Train net output #0: loss = 0.0147776 (* 1 = 0.0147776 loss)
I0403 04:37:03.171838  2203 sgd_solver.cpp:106] Iteration 9387, lr = 5e-05
I0403 04:37:18.275424  2203 solver.cpp:228] Iteration 9408, loss = 0.00388872
I0403 04:37:18.275518  2203 solver.cpp:244]     Train net output #0: loss = 0.00388865 (* 1 = 0.00388865 loss)
I0403 04:37:18.496491  2203 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 04:37:33.706516  2203 solver.cpp:228] Iteration 9429, loss = 0.00188489
I0403 04:37:33.706809  2203 solver.cpp:244]     Train net output #0: loss = 0.00188482 (* 1 = 0.00188482 loss)
I0403 04:37:33.857889  2203 sgd_solver.cpp:106] Iteration 9429, lr = 5e-05
I0403 04:37:49.267541  2203 solver.cpp:228] Iteration 9450, loss = 0.0211987
I0403 04:37:49.267628  2203 solver.cpp:244]     Train net output #0: loss = 0.0211986 (* 1 = 0.0211986 loss)
I0403 04:37:49.442697  2203 sgd_solver.cpp:106] Iteration 9450, lr = 5e-05
I0403 04:38:04.717205  2203 solver.cpp:228] Iteration 9471, loss = 0.00109228
I0403 04:38:04.717525  2203 solver.cpp:244]     Train net output #0: loss = 0.00109221 (* 1 = 0.00109221 loss)
I0403 04:38:04.915808  2203 sgd_solver.cpp:106] Iteration 9471, lr = 5e-05
I0403 04:38:20.410379  2203 solver.cpp:228] Iteration 9492, loss = 0.000710164
I0403 04:38:20.410465  2203 solver.cpp:244]     Train net output #0: loss = 0.0007101 (* 1 = 0.0007101 loss)
I0403 04:38:20.591182  2203 sgd_solver.cpp:106] Iteration 9492, lr = 5e-05
I0403 04:38:35.793203  2203 solver.cpp:228] Iteration 9513, loss = 0.00161168
I0403 04:38:35.793473  2203 solver.cpp:244]     Train net output #0: loss = 0.00161162 (* 1 = 0.00161162 loss)
I0403 04:38:35.969493  2203 sgd_solver.cpp:106] Iteration 9513, lr = 5e-05
I0403 04:38:51.522315  2203 solver.cpp:228] Iteration 9534, loss = 0.000114836
I0403 04:38:51.522406  2203 solver.cpp:244]     Train net output #0: loss = 0.000114775 (* 1 = 0.000114775 loss)
I0403 04:38:51.685122  2203 sgd_solver.cpp:106] Iteration 9534, lr = 5e-05
I0403 04:39:07.083886  2203 solver.cpp:228] Iteration 9555, loss = 0.000313315
I0403 04:39:07.084182  2203 solver.cpp:244]     Train net output #0: loss = 0.000313255 (* 1 = 0.000313255 loss)
I0403 04:39:07.258155  2203 sgd_solver.cpp:106] Iteration 9555, lr = 5e-05
I0403 04:39:22.658435  2203 solver.cpp:228] Iteration 9576, loss = 0.000269997
I0403 04:39:22.658526  2203 solver.cpp:244]     Train net output #0: loss = 0.000269935 (* 1 = 0.000269935 loss)
I0403 04:39:22.822536  2203 sgd_solver.cpp:106] Iteration 9576, lr = 5e-05
I0403 04:39:34.023015  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_9592.caffemodel
I0403 04:39:36.751873  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_9592.solverstate
I0403 04:39:38.551363  2203 solver.cpp:337] Iteration 9592, Testing net (#0)
I0403 04:40:02.874771  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972453
I0403 04:40:02.874866  2203 solver.cpp:404]     Test net output #1: loss = 0.108527 (* 1 = 0.108527 loss)
I0403 04:40:07.244215  2203 solver.cpp:228] Iteration 9597, loss = 0.0030684
I0403 04:40:07.244312  2203 solver.cpp:244]     Train net output #0: loss = 0.00306834 (* 1 = 0.00306834 loss)
I0403 04:40:07.430053  2203 sgd_solver.cpp:106] Iteration 9597, lr = 5e-05
I0403 04:40:22.717103  2203 solver.cpp:228] Iteration 9618, loss = 0.000472086
I0403 04:40:22.717392  2203 solver.cpp:244]     Train net output #0: loss = 0.000472022 (* 1 = 0.000472022 loss)
I0403 04:40:22.895815  2203 sgd_solver.cpp:106] Iteration 9618, lr = 5e-05
I0403 04:40:38.483531  2203 solver.cpp:228] Iteration 9639, loss = 0.00533093
I0403 04:40:38.483625  2203 solver.cpp:244]     Train net output #0: loss = 0.00533087 (* 1 = 0.00533087 loss)
I0403 04:40:38.649583  2203 sgd_solver.cpp:106] Iteration 9639, lr = 5e-05
I0403 04:40:54.029404  2203 solver.cpp:228] Iteration 9660, loss = 0.01139
I0403 04:40:54.029685  2203 solver.cpp:244]     Train net output #0: loss = 0.0113899 (* 1 = 0.0113899 loss)
I0403 04:40:54.200603  2203 sgd_solver.cpp:106] Iteration 9660, lr = 5e-05
I0403 04:41:09.517477  2203 solver.cpp:228] Iteration 9681, loss = 0.0048738
I0403 04:41:09.517565  2203 solver.cpp:244]     Train net output #0: loss = 0.00487374 (* 1 = 0.00487374 loss)
I0403 04:41:09.691102  2203 sgd_solver.cpp:106] Iteration 9681, lr = 5e-05
I0403 04:41:25.216977  2203 solver.cpp:228] Iteration 9702, loss = 0.00156689
I0403 04:41:25.217273  2203 solver.cpp:244]     Train net output #0: loss = 0.00156682 (* 1 = 0.00156682 loss)
I0403 04:41:25.391502  2203 sgd_solver.cpp:106] Iteration 9702, lr = 5e-05
I0403 04:41:40.606925  2203 solver.cpp:228] Iteration 9723, loss = 0.0118758
I0403 04:41:40.607017  2203 solver.cpp:244]     Train net output #0: loss = 0.0118757 (* 1 = 0.0118757 loss)
I0403 04:41:40.789968  2203 sgd_solver.cpp:106] Iteration 9723, lr = 5e-05
I0403 04:41:56.051259  2203 solver.cpp:228] Iteration 9744, loss = 0.032908
I0403 04:41:56.051584  2203 solver.cpp:244]     Train net output #0: loss = 0.032908 (* 1 = 0.032908 loss)
I0403 04:41:56.240077  2203 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 04:42:11.575714  2203 solver.cpp:228] Iteration 9765, loss = 0.00247039
I0403 04:42:11.575806  2203 solver.cpp:244]     Train net output #0: loss = 0.00247033 (* 1 = 0.00247033 loss)
I0403 04:42:11.744778  2203 sgd_solver.cpp:106] Iteration 9765, lr = 5e-05
I0403 04:42:27.293015  2203 solver.cpp:228] Iteration 9786, loss = 0.0129678
I0403 04:42:27.293289  2203 solver.cpp:244]     Train net output #0: loss = 0.0129677 (* 1 = 0.0129677 loss)
I0403 04:42:27.462292  2203 sgd_solver.cpp:106] Iteration 9786, lr = 5e-05
I0403 04:42:42.696204  2203 solver.cpp:228] Iteration 9807, loss = 0.00144212
I0403 04:42:42.696298  2203 solver.cpp:244]     Train net output #0: loss = 0.00144206 (* 1 = 0.00144206 loss)
I0403 04:42:42.884948  2203 sgd_solver.cpp:106] Iteration 9807, lr = 5e-05
I0403 04:42:58.278172  2203 solver.cpp:228] Iteration 9828, loss = 0.00395068
I0403 04:42:58.278463  2203 solver.cpp:244]     Train net output #0: loss = 0.00395062 (* 1 = 0.00395062 loss)
I0403 04:42:58.481858  2203 sgd_solver.cpp:106] Iteration 9828, lr = 5e-05
I0403 04:43:13.880198  2203 solver.cpp:228] Iteration 9849, loss = 0.0315694
I0403 04:43:13.880287  2203 solver.cpp:244]     Train net output #0: loss = 0.0315694 (* 1 = 0.0315694 loss)
I0403 04:43:14.052134  2203 sgd_solver.cpp:106] Iteration 9849, lr = 5e-05
I0403 04:43:29.235153  2203 solver.cpp:228] Iteration 9870, loss = 0.00447135
I0403 04:43:29.235443  2203 solver.cpp:244]     Train net output #0: loss = 0.00447129 (* 1 = 0.00447129 loss)
I0403 04:43:29.420099  2203 sgd_solver.cpp:106] Iteration 9870, lr = 5e-05
I0403 04:43:44.690958  2203 solver.cpp:228] Iteration 9891, loss = 0.000921845
I0403 04:43:44.691061  2203 solver.cpp:244]     Train net output #0: loss = 0.000921781 (* 1 = 0.000921781 loss)
I0403 04:43:44.945482  2203 sgd_solver.cpp:106] Iteration 9891, lr = 5e-05
I0403 04:44:00.288169  2203 solver.cpp:228] Iteration 9912, loss = 0.00417454
I0403 04:44:00.288481  2203 solver.cpp:244]     Train net output #0: loss = 0.00417447 (* 1 = 0.00417447 loss)
I0403 04:44:00.461366  2203 sgd_solver.cpp:106] Iteration 9912, lr = 5e-05
I0403 04:44:15.708796  2203 solver.cpp:228] Iteration 9933, loss = 0.00241669
I0403 04:44:15.708884  2203 solver.cpp:244]     Train net output #0: loss = 0.00241663 (* 1 = 0.00241663 loss)
I0403 04:44:15.882310  2203 sgd_solver.cpp:106] Iteration 9933, lr = 5e-05
I0403 04:44:31.547618  2203 solver.cpp:228] Iteration 9954, loss = 0.000802432
I0403 04:44:31.547901  2203 solver.cpp:244]     Train net output #0: loss = 0.000802371 (* 1 = 0.000802371 loss)
I0403 04:44:31.731739  2203 sgd_solver.cpp:106] Iteration 9954, lr = 5e-05
I0403 04:44:47.053827  2203 solver.cpp:228] Iteration 9975, loss = 0.0074672
I0403 04:44:47.053917  2203 solver.cpp:244]     Train net output #0: loss = 0.00746714 (* 1 = 0.00746714 loss)
I0403 04:44:47.220576  2203 sgd_solver.cpp:106] Iteration 9975, lr = 5e-05
I0403 04:45:02.514969  2203 solver.cpp:228] Iteration 9996, loss = 0.00122157
I0403 04:45:02.515241  2203 solver.cpp:244]     Train net output #0: loss = 0.00122151 (* 1 = 0.00122151 loss)
I0403 04:45:02.699184  2203 sgd_solver.cpp:106] Iteration 9996, lr = 5e-05
I0403 04:45:17.946440  2203 solver.cpp:228] Iteration 10017, loss = 0.0101208
I0403 04:45:17.946534  2203 solver.cpp:244]     Train net output #0: loss = 0.0101207 (* 1 = 0.0101207 loss)
I0403 04:45:18.104920  2203 sgd_solver.cpp:106] Iteration 10017, lr = 5e-05
I0403 04:45:25.609949  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_10028.caffemodel
I0403 04:45:28.477058  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_10028.solverstate
I0403 04:45:30.427507  2203 solver.cpp:337] Iteration 10028, Testing net (#0)
I0403 04:45:54.738631  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972547
I0403 04:45:54.738967  2203 solver.cpp:404]     Test net output #1: loss = 0.106755 (* 1 = 0.106755 loss)
I0403 04:46:02.829576  2203 solver.cpp:228] Iteration 10038, loss = 0.00535889
I0403 04:46:02.829665  2203 solver.cpp:244]     Train net output #0: loss = 0.00535883 (* 1 = 0.00535883 loss)
I0403 04:46:03.004360  2203 sgd_solver.cpp:106] Iteration 10038, lr = 5e-05
I0403 04:46:18.263761  2203 solver.cpp:228] Iteration 10059, loss = 0.00462394
I0403 04:46:18.263850  2203 solver.cpp:244]     Train net output #0: loss = 0.00462388 (* 1 = 0.00462388 loss)
I0403 04:46:18.438541  2203 sgd_solver.cpp:106] Iteration 10059, lr = 5e-05
I0403 04:46:33.688908  2203 solver.cpp:228] Iteration 10080, loss = 0.0169127
I0403 04:46:33.689209  2203 solver.cpp:244]     Train net output #0: loss = 0.0169127 (* 1 = 0.0169127 loss)
I0403 04:46:33.898108  2203 sgd_solver.cpp:106] Iteration 10080, lr = 5e-05
I0403 04:46:49.231516  2203 solver.cpp:228] Iteration 10101, loss = 0.00524656
I0403 04:46:49.231613  2203 solver.cpp:244]     Train net output #0: loss = 0.00524649 (* 1 = 0.00524649 loss)
I0403 04:46:49.421756  2203 sgd_solver.cpp:106] Iteration 10101, lr = 5e-05
I0403 04:47:04.779088  2203 solver.cpp:228] Iteration 10122, loss = 0.011582
I0403 04:47:04.779343  2203 solver.cpp:244]     Train net output #0: loss = 0.0115819 (* 1 = 0.0115819 loss)
I0403 04:47:04.955274  2203 sgd_solver.cpp:106] Iteration 10122, lr = 5e-05
I0403 04:47:20.061142  2203 solver.cpp:228] Iteration 10143, loss = 0.00613439
I0403 04:47:20.061229  2203 solver.cpp:244]     Train net output #0: loss = 0.00613432 (* 1 = 0.00613432 loss)
I0403 04:47:20.241816  2203 sgd_solver.cpp:106] Iteration 10143, lr = 5e-05
I0403 04:47:35.564630  2203 solver.cpp:228] Iteration 10164, loss = 0.00137705
I0403 04:47:35.566799  2203 solver.cpp:244]     Train net output #0: loss = 0.00137698 (* 1 = 0.00137698 loss)
I0403 04:47:35.736253  2203 sgd_solver.cpp:106] Iteration 10164, lr = 5e-05
I0403 04:47:51.015449  2203 solver.cpp:228] Iteration 10185, loss = 0.0173318
I0403 04:47:51.015558  2203 solver.cpp:244]     Train net output #0: loss = 0.0173317 (* 1 = 0.0173317 loss)
I0403 04:47:51.201109  2203 sgd_solver.cpp:106] Iteration 10185, lr = 5e-05
I0403 04:48:06.542291  2203 solver.cpp:228] Iteration 10206, loss = 0.00624177
I0403 04:48:06.542604  2203 solver.cpp:244]     Train net output #0: loss = 0.0062417 (* 1 = 0.0062417 loss)
I0403 04:48:06.729435  2203 sgd_solver.cpp:106] Iteration 10206, lr = 5e-05
I0403 04:48:21.870404  2203 solver.cpp:228] Iteration 10227, loss = 0.00222132
I0403 04:48:21.870491  2203 solver.cpp:244]     Train net output #0: loss = 0.00222125 (* 1 = 0.00222125 loss)
I0403 04:48:21.987679  2203 sgd_solver.cpp:106] Iteration 10227, lr = 5e-05
I0403 04:48:37.376116  2203 solver.cpp:228] Iteration 10248, loss = 0.000208933
I0403 04:48:37.376356  2203 solver.cpp:244]     Train net output #0: loss = 0.00020886 (* 1 = 0.00020886 loss)
I0403 04:48:37.568814  2203 sgd_solver.cpp:106] Iteration 10248, lr = 5e-05
I0403 04:48:52.722853  2203 solver.cpp:228] Iteration 10269, loss = 0.00110213
I0403 04:48:52.722954  2203 solver.cpp:244]     Train net output #0: loss = 0.00110206 (* 1 = 0.00110206 loss)
I0403 04:48:52.909237  2203 sgd_solver.cpp:106] Iteration 10269, lr = 5e-05
I0403 04:49:08.339263  2203 solver.cpp:228] Iteration 10290, loss = 0.00427933
I0403 04:49:08.339593  2203 solver.cpp:244]     Train net output #0: loss = 0.00427926 (* 1 = 0.00427926 loss)
I0403 04:49:08.501929  2203 sgd_solver.cpp:106] Iteration 10290, lr = 5e-05
I0403 04:49:23.947290  2203 solver.cpp:228] Iteration 10311, loss = 0.0162078
I0403 04:49:23.947377  2203 solver.cpp:244]     Train net output #0: loss = 0.0162078 (* 1 = 0.0162078 loss)
I0403 04:49:24.089637  2203 sgd_solver.cpp:106] Iteration 10311, lr = 5e-05
I0403 04:49:39.583022  2203 solver.cpp:228] Iteration 10332, loss = 0.000878325
I0403 04:49:39.583380  2203 solver.cpp:244]     Train net output #0: loss = 0.000878254 (* 1 = 0.000878254 loss)
I0403 04:49:39.825423  2203 sgd_solver.cpp:106] Iteration 10332, lr = 5e-05
I0403 04:49:55.032908  2203 solver.cpp:228] Iteration 10353, loss = 0.00185172
I0403 04:49:55.032994  2203 solver.cpp:244]     Train net output #0: loss = 0.00185164 (* 1 = 0.00185164 loss)
I0403 04:49:55.162273  2203 sgd_solver.cpp:106] Iteration 10353, lr = 5e-05
I0403 04:50:10.646787  2203 solver.cpp:228] Iteration 10374, loss = 0.000863657
I0403 04:50:10.647042  2203 solver.cpp:244]     Train net output #0: loss = 0.000863584 (* 1 = 0.000863584 loss)
I0403 04:50:10.799890  2203 sgd_solver.cpp:106] Iteration 10374, lr = 5e-05
I0403 04:50:26.070261  2203 solver.cpp:228] Iteration 10395, loss = 0.000165548
I0403 04:50:26.070349  2203 solver.cpp:244]     Train net output #0: loss = 0.000165475 (* 1 = 0.000165475 loss)
I0403 04:50:26.208452  2203 sgd_solver.cpp:106] Iteration 10395, lr = 5e-05
I0403 04:50:41.639940  2203 solver.cpp:228] Iteration 10416, loss = 0.00939564
I0403 04:50:41.640226  2203 solver.cpp:244]     Train net output #0: loss = 0.00939557 (* 1 = 0.00939557 loss)
I0403 04:50:41.783715  2203 sgd_solver.cpp:106] Iteration 10416, lr = 5e-05
I0403 04:50:57.250186  2203 solver.cpp:228] Iteration 10437, loss = 0.0078795
I0403 04:50:57.250286  2203 solver.cpp:244]     Train net output #0: loss = 0.00787942 (* 1 = 0.00787942 loss)
I0403 04:50:57.420408  2203 sgd_solver.cpp:106] Iteration 10437, lr = 5e-05
I0403 04:51:12.605422  2203 solver.cpp:228] Iteration 10458, loss = 0.00366517
I0403 04:51:12.605725  2203 solver.cpp:244]     Train net output #0: loss = 0.00366509 (* 1 = 0.00366509 loss)
I0403 04:51:12.763025  2203 sgd_solver.cpp:106] Iteration 10458, lr = 5e-05
I0403 04:51:16.488879  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_10464.caffemodel
I0403 04:51:19.274672  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_10464.solverstate
I0403 04:51:21.137162  2203 solver.cpp:337] Iteration 10464, Testing net (#0)
I0403 04:51:45.452304  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972359
I0403 04:51:45.452572  2203 solver.cpp:404]     Test net output #1: loss = 0.107797 (* 1 = 0.107797 loss)
I0403 04:51:56.837873  2203 solver.cpp:228] Iteration 10479, loss = 0.00513457
I0403 04:51:56.837972  2203 solver.cpp:244]     Train net output #0: loss = 0.00513449 (* 1 = 0.00513449 loss)
I0403 04:51:57.068125  2203 sgd_solver.cpp:106] Iteration 10479, lr = 5e-05
I0403 04:52:12.275245  2203 solver.cpp:228] Iteration 10500, loss = 0.0103371
I0403 04:52:12.275338  2203 solver.cpp:244]     Train net output #0: loss = 0.010337 (* 1 = 0.010337 loss)
I0403 04:52:12.431098  2203 sgd_solver.cpp:106] Iteration 10500, lr = 5e-05
I0403 04:52:27.806979  2203 solver.cpp:228] Iteration 10521, loss = 0.00150007
I0403 04:52:27.807267  2203 solver.cpp:244]     Train net output #0: loss = 0.00149999 (* 1 = 0.00149999 loss)
I0403 04:52:27.984560  2203 sgd_solver.cpp:106] Iteration 10521, lr = 5e-05
I0403 04:52:43.230207  2203 solver.cpp:228] Iteration 10542, loss = 0.000518081
I0403 04:52:43.230304  2203 solver.cpp:244]     Train net output #0: loss = 0.000518005 (* 1 = 0.000518005 loss)
I0403 04:52:43.421622  2203 sgd_solver.cpp:106] Iteration 10542, lr = 5e-05
I0403 04:52:58.665058  2203 solver.cpp:228] Iteration 10563, loss = 0.00172322
I0403 04:52:58.665338  2203 solver.cpp:244]     Train net output #0: loss = 0.00172315 (* 1 = 0.00172315 loss)
I0403 04:52:58.841104  2203 sgd_solver.cpp:106] Iteration 10563, lr = 5e-05
I0403 04:53:14.292361  2203 solver.cpp:228] Iteration 10584, loss = 0.000327656
I0403 04:53:14.292451  2203 solver.cpp:244]     Train net output #0: loss = 0.000327583 (* 1 = 0.000327583 loss)
I0403 04:53:14.454625  2203 sgd_solver.cpp:106] Iteration 10584, lr = 5e-05
I0403 04:53:29.871184  2203 solver.cpp:228] Iteration 10605, loss = 0.00844489
I0403 04:53:29.871503  2203 solver.cpp:244]     Train net output #0: loss = 0.00844482 (* 1 = 0.00844482 loss)
I0403 04:53:30.051471  2203 sgd_solver.cpp:106] Iteration 10605, lr = 5e-05
I0403 04:53:45.213311  2203 solver.cpp:228] Iteration 10626, loss = 0.00247376
I0403 04:53:45.213408  2203 solver.cpp:244]     Train net output #0: loss = 0.00247369 (* 1 = 0.00247369 loss)
I0403 04:53:45.426595  2203 sgd_solver.cpp:106] Iteration 10626, lr = 5e-05
I0403 04:54:00.653753  2203 solver.cpp:228] Iteration 10647, loss = 0.00169774
I0403 04:54:00.654052  2203 solver.cpp:244]     Train net output #0: loss = 0.00169767 (* 1 = 0.00169767 loss)
I0403 04:54:00.828945  2203 sgd_solver.cpp:106] Iteration 10647, lr = 5e-05
I0403 04:54:16.110839  2203 solver.cpp:228] Iteration 10668, loss = 0.000757636
I0403 04:54:16.110937  2203 solver.cpp:244]     Train net output #0: loss = 0.000757566 (* 1 = 0.000757566 loss)
I0403 04:54:16.302860  2203 sgd_solver.cpp:106] Iteration 10668, lr = 5e-05
I0403 04:54:31.580369  2203 solver.cpp:228] Iteration 10689, loss = 0.00628831
I0403 04:54:31.580672  2203 solver.cpp:244]     Train net output #0: loss = 0.00628824 (* 1 = 0.00628824 loss)
I0403 04:54:31.794312  2203 sgd_solver.cpp:106] Iteration 10689, lr = 5e-05
I0403 04:54:47.066759  2203 solver.cpp:228] Iteration 10710, loss = 0.00309973
I0403 04:54:47.066856  2203 solver.cpp:244]     Train net output #0: loss = 0.00309966 (* 1 = 0.00309966 loss)
I0403 04:54:47.263901  2203 sgd_solver.cpp:106] Iteration 10710, lr = 5e-05
I0403 04:55:02.640936  2203 solver.cpp:228] Iteration 10731, loss = 0.000409163
I0403 04:55:02.641225  2203 solver.cpp:244]     Train net output #0: loss = 0.000409099 (* 1 = 0.000409099 loss)
I0403 04:55:02.818961  2203 sgd_solver.cpp:106] Iteration 10731, lr = 5e-05
I0403 04:55:17.970137  2203 solver.cpp:228] Iteration 10752, loss = 0.00190387
I0403 04:55:17.970222  2203 solver.cpp:244]     Train net output #0: loss = 0.00190381 (* 1 = 0.00190381 loss)
I0403 04:55:18.110584  2203 sgd_solver.cpp:106] Iteration 10752, lr = 5e-05
I0403 04:55:33.575840  2203 solver.cpp:228] Iteration 10773, loss = 0.00149025
I0403 04:55:33.576133  2203 solver.cpp:244]     Train net output #0: loss = 0.00149019 (* 1 = 0.00149019 loss)
I0403 04:55:33.732437  2203 sgd_solver.cpp:106] Iteration 10773, lr = 5e-05
I0403 04:55:49.507189  2203 solver.cpp:228] Iteration 10794, loss = 0.0053862
I0403 04:55:49.507277  2203 solver.cpp:244]     Train net output #0: loss = 0.00538614 (* 1 = 0.00538614 loss)
I0403 04:55:49.656580  2203 sgd_solver.cpp:106] Iteration 10794, lr = 5e-05
I0403 04:56:04.935550  2203 solver.cpp:228] Iteration 10815, loss = 0.000397066
I0403 04:56:04.935829  2203 solver.cpp:244]     Train net output #0: loss = 0.000397007 (* 1 = 0.000397007 loss)
I0403 04:56:05.098681  2203 sgd_solver.cpp:106] Iteration 10815, lr = 5e-05
I0403 04:56:20.516068  2203 solver.cpp:228] Iteration 10836, loss = 0.0161011
I0403 04:56:20.516157  2203 solver.cpp:244]     Train net output #0: loss = 0.0161011 (* 1 = 0.0161011 loss)
I0403 04:56:20.681282  2203 sgd_solver.cpp:106] Iteration 10836, lr = 5e-05
I0403 04:56:36.183610  2203 solver.cpp:228] Iteration 10857, loss = 0.00313881
I0403 04:56:36.183900  2203 solver.cpp:244]     Train net output #0: loss = 0.00313875 (* 1 = 0.00313875 loss)
I0403 04:56:36.358338  2203 sgd_solver.cpp:106] Iteration 10857, lr = 5e-05
I0403 04:56:51.646064  2203 solver.cpp:228] Iteration 10878, loss = 0.00245761
I0403 04:56:51.646162  2203 solver.cpp:244]     Train net output #0: loss = 0.00245754 (* 1 = 0.00245754 loss)
I0403 04:56:51.838737  2203 sgd_solver.cpp:106] Iteration 10878, lr = 5e-05
I0403 04:57:07.390873  2203 solver.cpp:228] Iteration 10899, loss = 0.00156488
I0403 04:57:07.391147  2203 solver.cpp:244]     Train net output #0: loss = 0.00156482 (* 1 = 0.00156482 loss)
I0403 04:57:07.551965  2203 sgd_solver.cpp:106] Iteration 10899, lr = 5e-05
I0403 04:57:07.552198  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_10900.caffemodel
I0403 04:57:10.281961  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_10900.solverstate
I0403 04:57:12.101327  2203 solver.cpp:337] Iteration 10900, Testing net (#0)
I0403 04:57:36.413856  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972925
I0403 04:57:36.413949  2203 solver.cpp:404]     Test net output #1: loss = 0.107263 (* 1 = 0.107263 loss)
I0403 04:57:51.878355  2203 solver.cpp:228] Iteration 10920, loss = 0.0170709
I0403 04:57:51.878664  2203 solver.cpp:244]     Train net output #0: loss = 0.0170708 (* 1 = 0.0170708 loss)
I0403 04:57:52.057566  2203 sgd_solver.cpp:106] Iteration 10920, lr = 5e-05
I0403 04:58:07.295784  2203 solver.cpp:228] Iteration 10941, loss = 0.00988651
I0403 04:58:07.295872  2203 solver.cpp:244]     Train net output #0: loss = 0.00988645 (* 1 = 0.00988645 loss)
I0403 04:58:07.469699  2203 sgd_solver.cpp:106] Iteration 10941, lr = 5e-05
I0403 04:58:22.763497  2203 solver.cpp:228] Iteration 10962, loss = 0.0016434
I0403 04:58:22.763783  2203 solver.cpp:244]     Train net output #0: loss = 0.00164333 (* 1 = 0.00164333 loss)
I0403 04:58:22.951593  2203 sgd_solver.cpp:106] Iteration 10962, lr = 5e-05
I0403 04:58:38.435855  2203 solver.cpp:228] Iteration 10983, loss = 0.0297411
I0403 04:58:38.435943  2203 solver.cpp:244]     Train net output #0: loss = 0.0297411 (* 1 = 0.0297411 loss)
I0403 04:58:38.584197  2203 sgd_solver.cpp:106] Iteration 10983, lr = 5e-05
I0403 04:58:53.886288  2203 solver.cpp:228] Iteration 11004, loss = 0.00677585
I0403 04:58:53.886575  2203 solver.cpp:244]     Train net output #0: loss = 0.00677578 (* 1 = 0.00677578 loss)
I0403 04:58:54.072147  2203 sgd_solver.cpp:106] Iteration 11004, lr = 5e-05
I0403 04:59:09.477095  2203 solver.cpp:228] Iteration 11025, loss = 0.00327276
I0403 04:59:09.477183  2203 solver.cpp:244]     Train net output #0: loss = 0.00327269 (* 1 = 0.00327269 loss)
I0403 04:59:09.649224  2203 sgd_solver.cpp:106] Iteration 11025, lr = 5e-05
I0403 04:59:24.980268  2203 solver.cpp:228] Iteration 11046, loss = 0.000850787
I0403 04:59:24.980564  2203 solver.cpp:244]     Train net output #0: loss = 0.00085072 (* 1 = 0.00085072 loss)
I0403 04:59:25.152830  2203 sgd_solver.cpp:106] Iteration 11046, lr = 5e-05
I0403 04:59:40.346838  2203 solver.cpp:228] Iteration 11067, loss = 0.00104593
I0403 04:59:40.346925  2203 solver.cpp:244]     Train net output #0: loss = 0.00104587 (* 1 = 0.00104587 loss)
I0403 04:59:40.502532  2203 sgd_solver.cpp:106] Iteration 11067, lr = 5e-05
I0403 04:59:56.185736  2203 solver.cpp:228] Iteration 11088, loss = 0.00837388
I0403 04:59:56.186022  2203 solver.cpp:244]     Train net output #0: loss = 0.00837382 (* 1 = 0.00837382 loss)
I0403 04:59:56.328240  2203 sgd_solver.cpp:106] Iteration 11088, lr = 5e-05
I0403 05:00:11.715639  2203 solver.cpp:228] Iteration 11109, loss = 0.00629214
I0403 05:00:11.715728  2203 solver.cpp:244]     Train net output #0: loss = 0.00629208 (* 1 = 0.00629208 loss)
I0403 05:00:11.891072  2203 sgd_solver.cpp:106] Iteration 11109, lr = 5e-05
I0403 05:00:27.274055  2203 solver.cpp:228] Iteration 11130, loss = 0.00389987
I0403 05:00:27.274341  2203 solver.cpp:244]     Train net output #0: loss = 0.00389981 (* 1 = 0.00389981 loss)
I0403 05:00:27.444833  2203 sgd_solver.cpp:106] Iteration 11130, lr = 5e-05
I0403 05:00:42.724226  2203 solver.cpp:228] Iteration 11151, loss = 0.000936029
I0403 05:00:42.724318  2203 solver.cpp:244]     Train net output #0: loss = 0.000935966 (* 1 = 0.000935966 loss)
I0403 05:00:42.899516  2203 sgd_solver.cpp:106] Iteration 11151, lr = 5e-05
I0403 05:00:58.113003  2203 solver.cpp:228] Iteration 11172, loss = 0.00112439
I0403 05:00:58.113302  2203 solver.cpp:244]     Train net output #0: loss = 0.00112433 (* 1 = 0.00112433 loss)
I0403 05:00:58.341210  2203 sgd_solver.cpp:106] Iteration 11172, lr = 5e-05
I0403 05:01:13.914443  2203 solver.cpp:228] Iteration 11193, loss = 0.00633443
I0403 05:01:13.914551  2203 solver.cpp:244]     Train net output #0: loss = 0.00633436 (* 1 = 0.00633436 loss)
I0403 05:01:14.126909  2203 sgd_solver.cpp:106] Iteration 11193, lr = 5e-05
I0403 05:01:29.415217  2203 solver.cpp:228] Iteration 11214, loss = 0.00139223
I0403 05:01:29.415529  2203 solver.cpp:244]     Train net output #0: loss = 0.00139217 (* 1 = 0.00139217 loss)
I0403 05:01:29.568503  2203 sgd_solver.cpp:106] Iteration 11214, lr = 5e-05
I0403 05:01:44.892886  2203 solver.cpp:228] Iteration 11235, loss = 0.00295166
I0403 05:01:44.892973  2203 solver.cpp:244]     Train net output #0: loss = 0.0029516 (* 1 = 0.0029516 loss)
I0403 05:01:45.069030  2203 sgd_solver.cpp:106] Iteration 11235, lr = 5e-05
I0403 05:02:00.456017  2203 solver.cpp:228] Iteration 11256, loss = 0.00263503
I0403 05:02:00.456313  2203 solver.cpp:244]     Train net output #0: loss = 0.00263497 (* 1 = 0.00263497 loss)
I0403 05:02:00.592823  2203 sgd_solver.cpp:106] Iteration 11256, lr = 5e-05
I0403 05:02:16.085607  2203 solver.cpp:228] Iteration 11277, loss = 0.000268294
I0403 05:02:16.085693  2203 solver.cpp:244]     Train net output #0: loss = 0.000268234 (* 1 = 0.000268234 loss)
I0403 05:02:16.263200  2203 sgd_solver.cpp:106] Iteration 11277, lr = 5e-05
I0403 05:02:31.589121  2203 solver.cpp:228] Iteration 11298, loss = 0.00152881
I0403 05:02:31.589457  2203 solver.cpp:244]     Train net output #0: loss = 0.00152875 (* 1 = 0.00152875 loss)
I0403 05:02:31.761749  2203 sgd_solver.cpp:106] Iteration 11298, lr = 5e-05
I0403 05:02:46.809448  2203 solver.cpp:228] Iteration 11319, loss = 0.000500677
I0403 05:02:46.809535  2203 solver.cpp:244]     Train net output #0: loss = 0.000500616 (* 1 = 0.000500616 loss)
I0403 05:02:46.981904  2203 sgd_solver.cpp:106] Iteration 11319, lr = 5e-05
I0403 05:02:58.770764  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_11336.caffemodel
I0403 05:03:01.572882  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_11336.solverstate
I0403 05:03:03.459610  2203 solver.cpp:337] Iteration 11336, Testing net (#0)
I0403 05:03:27.777003  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972925
I0403 05:03:27.777092  2203 solver.cpp:404]     Test net output #1: loss = 0.106292 (* 1 = 0.106292 loss)
I0403 05:03:31.323887  2203 solver.cpp:228] Iteration 11340, loss = 0.000869457
I0403 05:03:31.323976  2203 solver.cpp:244]     Train net output #0: loss = 0.000869397 (* 1 = 0.000869397 loss)
I0403 05:03:31.469218  2203 sgd_solver.cpp:106] Iteration 11340, lr = 5e-05
I0403 05:03:46.770588  2203 solver.cpp:228] Iteration 11361, loss = 0.00620384
I0403 05:03:46.770854  2203 solver.cpp:244]     Train net output #0: loss = 0.00620378 (* 1 = 0.00620378 loss)
I0403 05:03:46.932924  2203 sgd_solver.cpp:106] Iteration 11361, lr = 5e-05
I0403 05:04:02.038069  2203 solver.cpp:228] Iteration 11382, loss = 0.000834346
I0403 05:04:02.038156  2203 solver.cpp:244]     Train net output #0: loss = 0.000834288 (* 1 = 0.000834288 loss)
I0403 05:04:02.199894  2203 sgd_solver.cpp:106] Iteration 11382, lr = 5e-05
I0403 05:04:17.374487  2203 solver.cpp:228] Iteration 11403, loss = 0.00476378
I0403 05:04:17.374712  2203 solver.cpp:244]     Train net output #0: loss = 0.00476371 (* 1 = 0.00476371 loss)
I0403 05:04:17.549571  2203 sgd_solver.cpp:106] Iteration 11403, lr = 5e-05
I0403 05:04:32.847126  2203 solver.cpp:228] Iteration 11424, loss = 0.00338204
I0403 05:04:32.847213  2203 solver.cpp:244]     Train net output #0: loss = 0.00338198 (* 1 = 0.00338198 loss)
I0403 05:04:32.990124  2203 sgd_solver.cpp:106] Iteration 11424, lr = 5e-05
I0403 05:04:48.269937  2203 solver.cpp:228] Iteration 11445, loss = 0.00205506
I0403 05:04:48.270169  2203 solver.cpp:244]     Train net output #0: loss = 0.00205499 (* 1 = 0.00205499 loss)
I0403 05:04:48.441709  2203 sgd_solver.cpp:106] Iteration 11445, lr = 5e-05
I0403 05:05:03.706389  2203 solver.cpp:228] Iteration 11466, loss = 0.00113335
I0403 05:05:03.706477  2203 solver.cpp:244]     Train net output #0: loss = 0.00113329 (* 1 = 0.00113329 loss)
I0403 05:05:03.858796  2203 sgd_solver.cpp:106] Iteration 11466, lr = 5e-05
I0403 05:05:19.363463  2203 solver.cpp:228] Iteration 11487, loss = 0.00161098
I0403 05:05:19.363767  2203 solver.cpp:244]     Train net output #0: loss = 0.00161091 (* 1 = 0.00161091 loss)
I0403 05:05:19.502996  2203 sgd_solver.cpp:106] Iteration 11487, lr = 5e-05
I0403 05:05:35.208361  2203 solver.cpp:228] Iteration 11508, loss = 0.00278301
I0403 05:05:35.208457  2203 solver.cpp:244]     Train net output #0: loss = 0.00278295 (* 1 = 0.00278295 loss)
I0403 05:05:35.393362  2203 sgd_solver.cpp:106] Iteration 11508, lr = 5e-05
I0403 05:05:50.904376  2203 solver.cpp:228] Iteration 11529, loss = 0.00317552
I0403 05:05:50.908234  2203 solver.cpp:244]     Train net output #0: loss = 0.00317545 (* 1 = 0.00317545 loss)
I0403 05:05:51.061902  2203 sgd_solver.cpp:106] Iteration 11529, lr = 5e-05
I0403 05:06:06.528527  2203 solver.cpp:228] Iteration 11550, loss = 0.001617
I0403 05:06:06.528622  2203 solver.cpp:244]     Train net output #0: loss = 0.00161693 (* 1 = 0.00161693 loss)
I0403 05:06:06.703630  2203 sgd_solver.cpp:106] Iteration 11550, lr = 5e-05
I0403 05:06:21.882593  2203 solver.cpp:228] Iteration 11571, loss = 0.00223005
I0403 05:06:21.882879  2203 solver.cpp:244]     Train net output #0: loss = 0.00222998 (* 1 = 0.00222998 loss)
I0403 05:06:22.039944  2203 sgd_solver.cpp:106] Iteration 11571, lr = 5e-05
I0403 05:06:37.528515  2203 solver.cpp:228] Iteration 11592, loss = 0.000848837
I0403 05:06:37.528612  2203 solver.cpp:244]     Train net output #0: loss = 0.000848775 (* 1 = 0.000848775 loss)
I0403 05:06:37.683071  2203 sgd_solver.cpp:106] Iteration 11592, lr = 5e-05
I0403 05:06:52.860376  2203 solver.cpp:228] Iteration 11613, loss = 0.00133525
I0403 05:06:52.860610  2203 solver.cpp:244]     Train net output #0: loss = 0.00133519 (* 1 = 0.00133519 loss)
I0403 05:06:52.994634  2203 sgd_solver.cpp:106] Iteration 11613, lr = 5e-05
I0403 05:07:08.419554  2203 solver.cpp:228] Iteration 11634, loss = 0.00246119
I0403 05:07:08.419643  2203 solver.cpp:244]     Train net output #0: loss = 0.00246112 (* 1 = 0.00246112 loss)
I0403 05:07:08.582777  2203 sgd_solver.cpp:106] Iteration 11634, lr = 5e-05
I0403 05:07:23.921715  2203 solver.cpp:228] Iteration 11655, loss = 0.0130634
I0403 05:07:23.922008  2203 solver.cpp:244]     Train net output #0: loss = 0.0130633 (* 1 = 0.0130633 loss)
I0403 05:07:24.100307  2203 sgd_solver.cpp:106] Iteration 11655, lr = 5e-05
I0403 05:07:39.347338  2203 solver.cpp:228] Iteration 11676, loss = 0.00255891
I0403 05:07:39.347435  2203 solver.cpp:244]     Train net output #0: loss = 0.00255884 (* 1 = 0.00255884 loss)
I0403 05:07:39.534906  2203 sgd_solver.cpp:106] Iteration 11676, lr = 5e-05
I0403 05:07:54.694628  2203 solver.cpp:228] Iteration 11697, loss = 0.00382155
I0403 05:07:54.694916  2203 solver.cpp:244]     Train net output #0: loss = 0.00382148 (* 1 = 0.00382148 loss)
I0403 05:07:54.862692  2203 sgd_solver.cpp:106] Iteration 11697, lr = 5e-05
I0403 05:08:10.257498  2203 solver.cpp:228] Iteration 11718, loss = 0.000535826
I0403 05:08:10.257592  2203 solver.cpp:244]     Train net output #0: loss = 0.000535754 (* 1 = 0.000535754 loss)
I0403 05:08:10.423240  2203 sgd_solver.cpp:106] Iteration 11718, lr = 5e-05
I0403 05:08:25.983953  2203 solver.cpp:228] Iteration 11739, loss = 0.00176683
I0403 05:08:25.984184  2203 solver.cpp:244]     Train net output #0: loss = 0.00176676 (* 1 = 0.00176676 loss)
I0403 05:08:26.149881  2203 sgd_solver.cpp:106] Iteration 11739, lr = 5e-05
I0403 05:08:41.817443  2203 solver.cpp:228] Iteration 11760, loss = 0.00235082
I0403 05:08:41.817538  2203 solver.cpp:244]     Train net output #0: loss = 0.00235075 (* 1 = 0.00235075 loss)
I0403 05:08:41.992921  2203 sgd_solver.cpp:106] Iteration 11760, lr = 5e-05
I0403 05:08:50.060770  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_11772.caffemodel
I0403 05:08:52.821884  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_11772.solverstate
I0403 05:08:54.653790  2203 solver.cpp:337] Iteration 11772, Testing net (#0)
I0403 05:09:18.964735  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972453
I0403 05:09:18.965067  2203 solver.cpp:404]     Test net output #1: loss = 0.107283 (* 1 = 0.107283 loss)
I0403 05:09:26.137130  2203 solver.cpp:228] Iteration 11781, loss = 0.00467476
I0403 05:09:26.137228  2203 solver.cpp:244]     Train net output #0: loss = 0.0046747 (* 1 = 0.0046747 loss)
I0403 05:09:26.378980  2203 sgd_solver.cpp:106] Iteration 11781, lr = 5e-05
I0403 05:09:41.765468  2203 solver.cpp:228] Iteration 11802, loss = 0.00997524
I0403 05:09:41.765563  2203 solver.cpp:244]     Train net output #0: loss = 0.00997518 (* 1 = 0.00997518 loss)
I0403 05:09:41.914186  2203 sgd_solver.cpp:106] Iteration 11802, lr = 5e-05
I0403 05:09:57.021962  2203 solver.cpp:228] Iteration 11823, loss = 0.0037314
I0403 05:09:57.022210  2203 solver.cpp:244]     Train net output #0: loss = 0.00373133 (* 1 = 0.00373133 loss)
I0403 05:09:57.218096  2203 sgd_solver.cpp:106] Iteration 11823, lr = 5e-05
I0403 05:10:12.613337  2203 solver.cpp:228] Iteration 11844, loss = 7.47656e-05
I0403 05:10:12.613423  2203 solver.cpp:244]     Train net output #0: loss = 7.47035e-05 (* 1 = 7.47035e-05 loss)
I0403 05:10:12.778880  2203 sgd_solver.cpp:106] Iteration 11844, lr = 5e-05
I0403 05:10:28.163210  2203 solver.cpp:228] Iteration 11865, loss = 0.00188355
I0403 05:10:28.163519  2203 solver.cpp:244]     Train net output #0: loss = 0.00188349 (* 1 = 0.00188349 loss)
I0403 05:10:28.351697  2203 sgd_solver.cpp:106] Iteration 11865, lr = 5e-05
I0403 05:10:43.585541  2203 solver.cpp:228] Iteration 11886, loss = 0.00997489
I0403 05:10:43.585630  2203 solver.cpp:244]     Train net output #0: loss = 0.00997483 (* 1 = 0.00997483 loss)
I0403 05:10:43.760128  2203 sgd_solver.cpp:106] Iteration 11886, lr = 5e-05
I0403 05:10:59.093987  2203 solver.cpp:228] Iteration 11907, loss = 0.00428754
I0403 05:10:59.094271  2203 solver.cpp:244]     Train net output #0: loss = 0.00428748 (* 1 = 0.00428748 loss)
I0403 05:10:59.248055  2203 sgd_solver.cpp:106] Iteration 11907, lr = 5e-05
I0403 05:11:14.460719  2203 solver.cpp:228] Iteration 11928, loss = 0.000979599
I0403 05:11:14.460816  2203 solver.cpp:244]     Train net output #0: loss = 0.000979535 (* 1 = 0.000979535 loss)
I0403 05:11:14.644876  2203 sgd_solver.cpp:106] Iteration 11928, lr = 5e-05
I0403 05:11:29.779707  2203 solver.cpp:228] Iteration 11949, loss = 0.00141836
I0403 05:11:29.779973  2203 solver.cpp:244]     Train net output #0: loss = 0.00141829 (* 1 = 0.00141829 loss)
I0403 05:11:29.950290  2203 sgd_solver.cpp:106] Iteration 11949, lr = 5e-05
I0403 05:11:45.397297  2203 solver.cpp:228] Iteration 11970, loss = 0.00567388
I0403 05:11:45.397385  2203 solver.cpp:244]     Train net output #0: loss = 0.00567381 (* 1 = 0.00567381 loss)
I0403 05:11:45.563459  2203 sgd_solver.cpp:106] Iteration 11970, lr = 5e-05
I0403 05:12:00.904884  2203 solver.cpp:228] Iteration 11991, loss = 0.00383823
I0403 05:12:00.905169  2203 solver.cpp:244]     Train net output #0: loss = 0.00383817 (* 1 = 0.00383817 loss)
I0403 05:12:01.081423  2203 sgd_solver.cpp:106] Iteration 11991, lr = 5e-05
I0403 05:12:16.396085  2203 solver.cpp:228] Iteration 12012, loss = 0.011291
I0403 05:12:16.396170  2203 solver.cpp:244]     Train net output #0: loss = 0.011291 (* 1 = 0.011291 loss)
I0403 05:12:16.568534  2203 sgd_solver.cpp:106] Iteration 12012, lr = 5e-05
I0403 05:12:31.975410  2203 solver.cpp:228] Iteration 12033, loss = 0.0426954
I0403 05:12:31.975703  2203 solver.cpp:244]     Train net output #0: loss = 0.0426953 (* 1 = 0.0426953 loss)
I0403 05:12:32.135125  2203 sgd_solver.cpp:106] Iteration 12033, lr = 5e-05
I0403 05:12:47.442486  2203 solver.cpp:228] Iteration 12054, loss = 0.00558779
I0403 05:12:47.442579  2203 solver.cpp:244]     Train net output #0: loss = 0.00558773 (* 1 = 0.00558773 loss)
I0403 05:12:47.593407  2203 sgd_solver.cpp:106] Iteration 12054, lr = 5e-05
I0403 05:13:02.965503  2203 solver.cpp:228] Iteration 12075, loss = 0.0019211
I0403 05:13:02.965823  2203 solver.cpp:244]     Train net output #0: loss = 0.00192103 (* 1 = 0.00192103 loss)
I0403 05:13:03.162870  2203 sgd_solver.cpp:106] Iteration 12075, lr = 5e-05
I0403 05:13:18.379361  2203 solver.cpp:228] Iteration 12096, loss = 0.00171637
I0403 05:13:18.379448  2203 solver.cpp:244]     Train net output #0: loss = 0.0017163 (* 1 = 0.0017163 loss)
I0403 05:13:18.555088  2203 sgd_solver.cpp:106] Iteration 12096, lr = 5e-05
I0403 05:13:33.739182  2203 solver.cpp:228] Iteration 12117, loss = 0.0431897
I0403 05:13:33.739483  2203 solver.cpp:244]     Train net output #0: loss = 0.0431897 (* 1 = 0.0431897 loss)
I0403 05:13:33.950438  2203 sgd_solver.cpp:106] Iteration 12117, lr = 5e-05
I0403 05:13:49.346884  2203 solver.cpp:228] Iteration 12138, loss = 0.000522453
I0403 05:13:49.346971  2203 solver.cpp:244]     Train net output #0: loss = 0.000522392 (* 1 = 0.000522392 loss)
I0403 05:13:49.512230  2203 sgd_solver.cpp:106] Iteration 12138, lr = 5e-05
I0403 05:14:04.758127  2203 solver.cpp:228] Iteration 12159, loss = 0.00236066
I0403 05:14:04.758422  2203 solver.cpp:244]     Train net output #0: loss = 0.0023606 (* 1 = 0.0023606 loss)
I0403 05:14:04.942306  2203 sgd_solver.cpp:106] Iteration 12159, lr = 5e-05
I0403 05:14:20.074256  2203 solver.cpp:228] Iteration 12180, loss = 0.00523224
I0403 05:14:20.074354  2203 solver.cpp:244]     Train net output #0: loss = 0.00523217 (* 1 = 0.00523217 loss)
I0403 05:14:20.267768  2203 sgd_solver.cpp:106] Iteration 12180, lr = 5e-05
I0403 05:14:35.415920  2203 solver.cpp:228] Iteration 12201, loss = 0.0007558
I0403 05:14:35.416211  2203 solver.cpp:244]     Train net output #0: loss = 0.00075574 (* 1 = 0.00075574 loss)
I0403 05:14:35.599797  2203 sgd_solver.cpp:106] Iteration 12201, lr = 5e-05
I0403 05:14:40.046093  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_12208.caffemodel
I0403 05:14:42.703894  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_12208.solverstate
I0403 05:14:44.500902  2203 solver.cpp:337] Iteration 12208, Testing net (#0)
I0403 05:15:08.811436  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972547
I0403 05:15:08.811712  2203 solver.cpp:404]     Test net output #1: loss = 0.107428 (* 1 = 0.107428 loss)
I0403 05:15:19.731133  2203 solver.cpp:228] Iteration 12222, loss = 0.00496862
I0403 05:15:19.731231  2203 solver.cpp:244]     Train net output #0: loss = 0.00496856 (* 1 = 0.00496856 loss)
I0403 05:15:19.946769  2203 sgd_solver.cpp:106] Iteration 12222, lr = 5e-05
I0403 05:15:35.294178  2203 solver.cpp:228] Iteration 12243, loss = 0.00214759
I0403 05:15:35.294265  2203 solver.cpp:244]     Train net output #0: loss = 0.00214753 (* 1 = 0.00214753 loss)
I0403 05:15:35.448051  2203 sgd_solver.cpp:106] Iteration 12243, lr = 5e-05
I0403 05:15:50.852890  2203 solver.cpp:228] Iteration 12264, loss = 0.000593722
I0403 05:15:50.853174  2203 solver.cpp:244]     Train net output #0: loss = 0.000593664 (* 1 = 0.000593664 loss)
I0403 05:15:51.029125  2203 sgd_solver.cpp:106] Iteration 12264, lr = 5e-05
I0403 05:16:06.480629  2203 solver.cpp:228] Iteration 12285, loss = 0.00245374
I0403 05:16:06.480718  2203 solver.cpp:244]     Train net output #0: loss = 0.00245369 (* 1 = 0.00245369 loss)
I0403 05:16:06.625969  2203 sgd_solver.cpp:106] Iteration 12285, lr = 5e-05
I0403 05:16:22.215875  2203 solver.cpp:228] Iteration 12306, loss = 0.00138407
I0403 05:16:22.216179  2203 solver.cpp:244]     Train net output #0: loss = 0.00138401 (* 1 = 0.00138401 loss)
I0403 05:16:22.406383  2203 sgd_solver.cpp:106] Iteration 12306, lr = 5e-05
I0403 05:16:37.682446  2203 solver.cpp:228] Iteration 12327, loss = 0.00539228
I0403 05:16:37.682540  2203 solver.cpp:244]     Train net output #0: loss = 0.00539222 (* 1 = 0.00539222 loss)
I0403 05:16:37.853216  2203 sgd_solver.cpp:106] Iteration 12327, lr = 5e-05
I0403 05:16:53.103225  2203 solver.cpp:228] Iteration 12348, loss = 0.0019357
I0403 05:16:53.103569  2203 solver.cpp:244]     Train net output #0: loss = 0.00193564 (* 1 = 0.00193564 loss)
I0403 05:16:53.292393  2203 sgd_solver.cpp:106] Iteration 12348, lr = 5e-05
I0403 05:17:08.652124  2203 solver.cpp:228] Iteration 12369, loss = 0.0004429
I0403 05:17:08.652211  2203 solver.cpp:244]     Train net output #0: loss = 0.000442839 (* 1 = 0.000442839 loss)
I0403 05:17:08.799233  2203 sgd_solver.cpp:106] Iteration 12369, lr = 5e-05
I0403 05:17:24.179265  2203 solver.cpp:228] Iteration 12390, loss = 0.00426967
I0403 05:17:24.179504  2203 solver.cpp:244]     Train net output #0: loss = 0.00426961 (* 1 = 0.00426961 loss)
I0403 05:17:24.335036  2203 sgd_solver.cpp:106] Iteration 12390, lr = 5e-05
I0403 05:17:39.630792  2203 solver.cpp:228] Iteration 12411, loss = 0.000359638
I0403 05:17:39.630892  2203 solver.cpp:244]     Train net output #0: loss = 0.000359579 (* 1 = 0.000359579 loss)
I0403 05:17:39.826565  2203 sgd_solver.cpp:106] Iteration 12411, lr = 5e-05
I0403 05:17:55.062894  2203 solver.cpp:228] Iteration 12432, loss = 0.0304341
I0403 05:17:55.063177  2203 solver.cpp:244]     Train net output #0: loss = 0.030434 (* 1 = 0.030434 loss)
I0403 05:17:55.238741  2203 sgd_solver.cpp:106] Iteration 12432, lr = 5e-05
I0403 05:18:10.663426  2203 solver.cpp:228] Iteration 12453, loss = 0.00777122
I0403 05:18:10.663523  2203 solver.cpp:244]     Train net output #0: loss = 0.00777116 (* 1 = 0.00777116 loss)
I0403 05:18:10.849268  2203 sgd_solver.cpp:106] Iteration 12453, lr = 5e-05
I0403 05:18:26.038617  2203 solver.cpp:228] Iteration 12474, loss = 0.00531628
I0403 05:18:26.038861  2203 solver.cpp:244]     Train net output #0: loss = 0.00531623 (* 1 = 0.00531623 loss)
I0403 05:18:26.222729  2203 sgd_solver.cpp:106] Iteration 12474, lr = 5e-05
I0403 05:18:41.649652  2203 solver.cpp:228] Iteration 12495, loss = 0.00461947
I0403 05:18:41.649742  2203 solver.cpp:244]     Train net output #0: loss = 0.00461942 (* 1 = 0.00461942 loss)
I0403 05:18:41.775497  2203 sgd_solver.cpp:106] Iteration 12495, lr = 5e-05
I0403 05:18:57.245321  2203 solver.cpp:228] Iteration 12516, loss = 0.00407065
I0403 05:18:57.245604  2203 solver.cpp:244]     Train net output #0: loss = 0.0040706 (* 1 = 0.0040706 loss)
I0403 05:18:57.410765  2203 sgd_solver.cpp:106] Iteration 12516, lr = 5e-05
I0403 05:19:12.653205  2203 solver.cpp:228] Iteration 12537, loss = 0.00040612
I0403 05:19:12.653307  2203 solver.cpp:244]     Train net output #0: loss = 0.000406069 (* 1 = 0.000406069 loss)
I0403 05:19:12.860088  2203 sgd_solver.cpp:106] Iteration 12537, lr = 5e-05
I0403 05:19:28.106806  2203 solver.cpp:228] Iteration 12558, loss = 0.00503402
I0403 05:19:28.107089  2203 solver.cpp:244]     Train net output #0: loss = 0.00503397 (* 1 = 0.00503397 loss)
I0403 05:19:28.291899  2203 sgd_solver.cpp:106] Iteration 12558, lr = 5e-05
I0403 05:19:43.634778  2203 solver.cpp:228] Iteration 12579, loss = 0.0040239
I0403 05:19:43.634865  2203 solver.cpp:244]     Train net output #0: loss = 0.00402385 (* 1 = 0.00402385 loss)
I0403 05:19:43.803467  2203 sgd_solver.cpp:106] Iteration 12579, lr = 5e-05
I0403 05:19:59.337754  2203 solver.cpp:228] Iteration 12600, loss = 0.002167
I0403 05:19:59.338018  2203 solver.cpp:244]     Train net output #0: loss = 0.00216694 (* 1 = 0.00216694 loss)
I0403 05:19:59.521950  2203 sgd_solver.cpp:106] Iteration 12600, lr = 5e-05
I0403 05:20:14.644745  2203 solver.cpp:228] Iteration 12621, loss = 0.036144
I0403 05:20:14.644843  2203 solver.cpp:244]     Train net output #0: loss = 0.036144 (* 1 = 0.036144 loss)
I0403 05:20:14.828841  2203 sgd_solver.cpp:106] Iteration 12621, lr = 5e-05
I0403 05:20:30.106891  2203 solver.cpp:228] Iteration 12642, loss = 0.000816462
I0403 05:20:30.107192  2203 solver.cpp:244]     Train net output #0: loss = 0.000816414 (* 1 = 0.000816414 loss)
I0403 05:20:30.298878  2203 sgd_solver.cpp:106] Iteration 12642, lr = 5e-05
I0403 05:20:31.013882  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_12644.caffemodel
I0403 05:20:33.703197  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_12644.solverstate
I0403 05:20:35.540069  2203 solver.cpp:337] Iteration 12644, Testing net (#0)
I0403 05:20:59.868630  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972547
I0403 05:20:59.868721  2203 solver.cpp:404]     Test net output #1: loss = 0.106735 (* 1 = 0.106735 loss)
I0403 05:21:14.507704  2203 solver.cpp:228] Iteration 12663, loss = 0.00576629
I0403 05:21:14.508034  2203 solver.cpp:244]     Train net output #0: loss = 0.00576624 (* 1 = 0.00576624 loss)
I0403 05:21:14.691932  2203 sgd_solver.cpp:106] Iteration 12663, lr = 5e-05
I0403 05:21:30.023720  2203 solver.cpp:228] Iteration 12684, loss = 0.00261359
I0403 05:21:30.023808  2203 solver.cpp:244]     Train net output #0: loss = 0.00261354 (* 1 = 0.00261354 loss)
I0403 05:21:30.199569  2203 sgd_solver.cpp:106] Iteration 12684, lr = 5e-05
I0403 05:21:45.367609  2203 solver.cpp:228] Iteration 12705, loss = 0.00509662
I0403 05:21:45.367848  2203 solver.cpp:244]     Train net output #0: loss = 0.00509657 (* 1 = 0.00509657 loss)
I0403 05:21:45.520676  2203 sgd_solver.cpp:106] Iteration 12705, lr = 5e-05
I0403 05:22:00.997009  2203 solver.cpp:228] Iteration 12726, loss = 0.00131392
I0403 05:22:00.997097  2203 solver.cpp:244]     Train net output #0: loss = 0.00131387 (* 1 = 0.00131387 loss)
I0403 05:22:01.165345  2203 sgd_solver.cpp:106] Iteration 12726, lr = 5e-05
I0403 05:22:16.460692  2203 solver.cpp:228] Iteration 12747, loss = 0.00129357
I0403 05:22:16.460932  2203 solver.cpp:244]     Train net output #0: loss = 0.00129352 (* 1 = 0.00129352 loss)
I0403 05:22:16.625757  2203 sgd_solver.cpp:106] Iteration 12747, lr = 5e-05
I0403 05:22:31.910300  2203 solver.cpp:228] Iteration 12768, loss = 0.00266382
I0403 05:22:31.910388  2203 solver.cpp:244]     Train net output #0: loss = 0.00266378 (* 1 = 0.00266378 loss)
I0403 05:22:32.079197  2203 sgd_solver.cpp:106] Iteration 12768, lr = 5e-05
I0403 05:22:47.573335  2203 solver.cpp:228] Iteration 12789, loss = 0.00585445
I0403 05:22:47.573647  2203 solver.cpp:244]     Train net output #0: loss = 0.0058544 (* 1 = 0.0058544 loss)
I0403 05:22:47.741731  2203 sgd_solver.cpp:106] Iteration 12789, lr = 5e-05
I0403 05:23:03.253628  2203 solver.cpp:228] Iteration 12810, loss = 0.0120228
I0403 05:23:03.253721  2203 solver.cpp:244]     Train net output #0: loss = 0.0120228 (* 1 = 0.0120228 loss)
I0403 05:23:03.437976  2203 sgd_solver.cpp:106] Iteration 12810, lr = 5e-05
I0403 05:23:18.763221  2203 solver.cpp:228] Iteration 12831, loss = 0.0149933
I0403 05:23:18.763485  2203 solver.cpp:244]     Train net output #0: loss = 0.0149933 (* 1 = 0.0149933 loss)
I0403 05:23:18.935015  2203 sgd_solver.cpp:106] Iteration 12831, lr = 5e-05
I0403 05:23:34.530386  2203 solver.cpp:228] Iteration 12852, loss = 0.0112676
I0403 05:23:34.530489  2203 solver.cpp:244]     Train net output #0: loss = 0.0112676 (* 1 = 0.0112676 loss)
I0403 05:23:34.743867  2203 sgd_solver.cpp:106] Iteration 12852, lr = 5e-05
I0403 05:23:50.259901  2203 solver.cpp:228] Iteration 12873, loss = 0.00724722
I0403 05:23:50.260188  2203 solver.cpp:244]     Train net output #0: loss = 0.00724718 (* 1 = 0.00724718 loss)
I0403 05:23:50.411801  2203 sgd_solver.cpp:106] Iteration 12873, lr = 5e-05
I0403 05:24:05.656390  2203 solver.cpp:228] Iteration 12894, loss = 0.00102866
I0403 05:24:05.656478  2203 solver.cpp:244]     Train net output #0: loss = 0.00102862 (* 1 = 0.00102862 loss)
I0403 05:24:05.825947  2203 sgd_solver.cpp:106] Iteration 12894, lr = 5e-05
I0403 05:24:21.051090  2203 solver.cpp:228] Iteration 12915, loss = 0.00235145
I0403 05:24:21.051394  2203 solver.cpp:244]     Train net output #0: loss = 0.00235141 (* 1 = 0.00235141 loss)
I0403 05:24:21.257001  2203 sgd_solver.cpp:106] Iteration 12915, lr = 5e-05
I0403 05:24:36.472648  2203 solver.cpp:228] Iteration 12936, loss = 0.0264874
I0403 05:24:36.472741  2203 solver.cpp:244]     Train net output #0: loss = 0.0264873 (* 1 = 0.0264873 loss)
I0403 05:24:36.658609  2203 sgd_solver.cpp:106] Iteration 12936, lr = 5e-05
I0403 05:24:51.963258  2203 solver.cpp:228] Iteration 12957, loss = 0.00190645
I0403 05:24:51.963574  2203 solver.cpp:244]     Train net output #0: loss = 0.00190641 (* 1 = 0.00190641 loss)
I0403 05:24:52.139732  2203 sgd_solver.cpp:106] Iteration 12957, lr = 5e-05
I0403 05:25:07.415685  2203 solver.cpp:228] Iteration 12978, loss = 0.00166891
I0403 05:25:07.415783  2203 solver.cpp:244]     Train net output #0: loss = 0.00166888 (* 1 = 0.00166888 loss)
I0403 05:25:07.620596  2203 sgd_solver.cpp:106] Iteration 12978, lr = 5e-05
I0403 05:25:22.816608  2203 solver.cpp:228] Iteration 12999, loss = 0.000783879
I0403 05:25:22.816910  2203 solver.cpp:244]     Train net output #0: loss = 0.000783841 (* 1 = 0.000783841 loss)
I0403 05:25:22.958459  2203 sgd_solver.cpp:106] Iteration 12999, lr = 5e-05
I0403 05:25:38.325019  2203 solver.cpp:228] Iteration 13020, loss = 0.0140525
I0403 05:25:38.325115  2203 solver.cpp:244]     Train net output #0: loss = 0.0140525 (* 1 = 0.0140525 loss)
I0403 05:25:38.531033  2203 sgd_solver.cpp:106] Iteration 13020, lr = 5e-05
I0403 05:25:53.898180  2203 solver.cpp:228] Iteration 13041, loss = 0.000477279
I0403 05:25:53.900357  2203 solver.cpp:244]     Train net output #0: loss = 0.000477242 (* 1 = 0.000477242 loss)
I0403 05:25:54.088706  2203 sgd_solver.cpp:106] Iteration 13041, lr = 5e-05
I0403 05:26:09.314187  2203 solver.cpp:228] Iteration 13062, loss = 0.00103843
I0403 05:26:09.314273  2203 solver.cpp:244]     Train net output #0: loss = 0.00103839 (* 1 = 0.00103839 loss)
I0403 05:26:09.489131  2203 sgd_solver.cpp:106] Iteration 13062, lr = 5e-05
I0403 05:26:21.957448  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_13080.caffemodel
I0403 05:26:24.802948  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_13080.solverstate
I0403 05:26:26.670361  2203 solver.cpp:337] Iteration 13080, Testing net (#0)
I0403 05:26:50.990644  2203 solver.cpp:404]     Test net output #0: accuracy = 0.972547
I0403 05:26:50.990741  2203 solver.cpp:404]     Test net output #1: loss = 0.107458 (* 1 = 0.107458 loss)
I0403 05:26:53.703565  2203 solver.cpp:228] Iteration 13083, loss = 0.0010609
I0403 05:26:53.703652  2203 solver.cpp:244]     Train net output #0: loss = 0.00106086 (* 1 = 0.00106086 loss)
I0403 05:26:53.873142  2203 sgd_solver.cpp:106] Iteration 13083, lr = 5e-06
I0403 05:26:54.621176  2203 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_13085.caffemodel
I0403 05:26:57.350314  2203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-80-20_finetune/snapshots__iter_13085.solverstate
I0403 05:26:59.127599  2203 solver.cpp:322] Optimization Done.
I0403 05:26:59.229737  2203 caffe.cpp:222] Optimization Done.
