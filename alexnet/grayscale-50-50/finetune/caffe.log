I0403 02:30:27.998694 23741 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:27.999302 23741 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:27.999336 23741 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:36.155987 23741 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:36.157605 23741 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:36.159111 23741 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.079721 23741 solver.cpp:48] Initializing solver from parameters: 
test_iter: 275
test_interval: 267
base_lr: 0.005
display: 13
max_iter: 8023
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2674
snapshot: 267
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.094666 23741 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.104140 23741 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.104280 23741 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.105991 23741 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.107110 23741 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.108934 23741 net.cpp:91] Creating Layer data
I0403 02:30:37.109031 23741 net.cpp:399] data -> data
I0403 02:30:37.109153 23741 net.cpp:399] data -> label
I0403 02:30:37.109244 23741 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto
I0403 02:30:37.141445 23748 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/train_db
I0403 02:30:37.147161 23741 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.288169 23741 net.cpp:141] Setting up data
I0403 02:30:37.288272 23741 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.288300 23741 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.288319 23741 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.288353 23741 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.288403 23741 net.cpp:91] Creating Layer conv1
I0403 02:30:37.288430 23741 net.cpp:425] conv1 <- data
I0403 02:30:37.288492 23741 net.cpp:399] conv1 -> conv1
I0403 02:30:37.291708 23741 net.cpp:141] Setting up conv1
I0403 02:30:37.291745 23741 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.291766 23741 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.291832 23741 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.291882 23741 net.cpp:91] Creating Layer relu1
I0403 02:30:37.291908 23741 net.cpp:425] relu1 <- conv1
I0403 02:30:37.291929 23741 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.291975 23741 net.cpp:141] Setting up relu1
I0403 02:30:37.292001 23741 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.292018 23741 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.292037 23741 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.292059 23741 net.cpp:91] Creating Layer norm1
I0403 02:30:37.292124 23741 net.cpp:425] norm1 <- conv1
I0403 02:30:37.292150 23741 net.cpp:399] norm1 -> norm1
I0403 02:30:37.297699 23741 net.cpp:141] Setting up norm1
I0403 02:30:37.297744 23741 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.297766 23741 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.297785 23741 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.297812 23741 net.cpp:91] Creating Layer pool1
I0403 02:30:37.297834 23741 net.cpp:425] pool1 <- norm1
I0403 02:30:37.297858 23741 net.cpp:399] pool1 -> pool1
I0403 02:30:37.297937 23741 net.cpp:141] Setting up pool1
I0403 02:30:37.297979 23741 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.298001 23741 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.298020 23741 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.298048 23741 net.cpp:91] Creating Layer conv2
I0403 02:30:37.298068 23741 net.cpp:425] conv2 <- pool1
I0403 02:30:37.298092 23741 net.cpp:399] conv2 -> conv2
I0403 02:30:37.299814 23750 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.316004 23741 net.cpp:141] Setting up conv2
I0403 02:30:37.316043 23741 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.316064 23741 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.316090 23741 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.316115 23741 net.cpp:91] Creating Layer relu2
I0403 02:30:37.316135 23741 net.cpp:425] relu2 <- conv2
I0403 02:30:37.316157 23741 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.316189 23741 net.cpp:141] Setting up relu2
I0403 02:30:37.316213 23741 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.316231 23741 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.316248 23741 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.316270 23741 net.cpp:91] Creating Layer norm2
I0403 02:30:37.316289 23741 net.cpp:425] norm2 <- conv2
I0403 02:30:37.316313 23741 net.cpp:399] norm2 -> norm2
I0403 02:30:37.316368 23741 net.cpp:141] Setting up norm2
I0403 02:30:37.316397 23741 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.316416 23741 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.316433 23741 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.316458 23741 net.cpp:91] Creating Layer pool2
I0403 02:30:37.316478 23741 net.cpp:425] pool2 <- norm2
I0403 02:30:37.316501 23741 net.cpp:399] pool2 -> pool2
I0403 02:30:37.316557 23741 net.cpp:141] Setting up pool2
I0403 02:30:37.316586 23741 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.316604 23741 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.316622 23741 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.316649 23741 net.cpp:91] Creating Layer conv3
I0403 02:30:37.316669 23741 net.cpp:425] conv3 <- pool2
I0403 02:30:37.316694 23741 net.cpp:399] conv3 -> conv3
I0403 02:30:37.358295 23741 net.cpp:141] Setting up conv3
I0403 02:30:37.358337 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.358358 23741 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.358384 23741 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.358410 23741 net.cpp:91] Creating Layer relu3
I0403 02:30:37.358429 23741 net.cpp:425] relu3 <- conv3
I0403 02:30:37.358453 23741 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.358475 23741 net.cpp:141] Setting up relu3
I0403 02:30:37.358497 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.358515 23741 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.358532 23741 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.358558 23741 net.cpp:91] Creating Layer conv4
I0403 02:30:37.358579 23741 net.cpp:425] conv4 <- conv3
I0403 02:30:37.358603 23741 net.cpp:399] conv4 -> conv4
I0403 02:30:37.389940 23741 net.cpp:141] Setting up conv4
I0403 02:30:37.389981 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.390003 23741 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.390048 23741 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.390074 23741 net.cpp:91] Creating Layer relu4
I0403 02:30:37.390094 23741 net.cpp:425] relu4 <- conv4
I0403 02:30:37.390117 23741 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.390139 23741 net.cpp:141] Setting up relu4
I0403 02:30:37.390161 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.390184 23741 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.390203 23741 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.390231 23741 net.cpp:91] Creating Layer conv5
I0403 02:30:37.390251 23741 net.cpp:425] conv5 <- conv4
I0403 02:30:37.390277 23741 net.cpp:399] conv5 -> conv5
I0403 02:30:37.411314 23741 net.cpp:141] Setting up conv5
I0403 02:30:37.411351 23741 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.411371 23741 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.411401 23741 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.411425 23741 net.cpp:91] Creating Layer relu5
I0403 02:30:37.411447 23741 net.cpp:425] relu5 <- conv5
I0403 02:30:37.411468 23741 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.411491 23741 net.cpp:141] Setting up relu5
I0403 02:30:37.411512 23741 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.411530 23741 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.411548 23741 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.411569 23741 net.cpp:91] Creating Layer pool5
I0403 02:30:37.411587 23741 net.cpp:425] pool5 <- conv5
I0403 02:30:37.411607 23741 net.cpp:399] pool5 -> pool5
I0403 02:30:37.411669 23741 net.cpp:141] Setting up pool5
I0403 02:30:37.411696 23741 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.411715 23741 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.411732 23741 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.411767 23741 net.cpp:91] Creating Layer fc6
I0403 02:30:37.411790 23741 net.cpp:425] fc6 <- pool5
I0403 02:30:37.411813 23741 net.cpp:399] fc6 -> fc6
I0403 02:30:38.943058 23741 net.cpp:141] Setting up fc6
I0403 02:30:38.943159 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.943181 23741 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.943204 23741 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.943229 23741 net.cpp:91] Creating Layer relu6
I0403 02:30:38.943246 23741 net.cpp:425] relu6 <- fc6
I0403 02:30:38.943265 23741 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.943289 23741 net.cpp:141] Setting up relu6
I0403 02:30:38.943305 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.943320 23741 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.943333 23741 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.943390 23741 net.cpp:91] Creating Layer drop6
I0403 02:30:38.943409 23741 net.cpp:425] drop6 <- fc6
I0403 02:30:38.943426 23741 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.943485 23741 net.cpp:141] Setting up drop6
I0403 02:30:38.943506 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.943521 23741 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.943534 23741 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.943554 23741 net.cpp:91] Creating Layer fc7
I0403 02:30:38.943568 23741 net.cpp:425] fc7 <- fc6
I0403 02:30:38.943588 23741 net.cpp:399] fc7 -> fc7
I0403 02:30:39.546146 23741 net.cpp:141] Setting up fc7
I0403 02:30:39.546249 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.546267 23741 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.546289 23741 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.546314 23741 net.cpp:91] Creating Layer relu7
I0403 02:30:39.546330 23741 net.cpp:425] relu7 <- fc7
I0403 02:30:39.546352 23741 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.546376 23741 net.cpp:141] Setting up relu7
I0403 02:30:39.546393 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.546406 23741 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.546419 23741 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.550482 23741 net.cpp:91] Creating Layer drop7
I0403 02:30:39.550503 23741 net.cpp:425] drop7 <- fc7
I0403 02:30:39.550521 23741 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.550570 23741 net.cpp:141] Setting up drop7
I0403 02:30:39.550592 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.550606 23741 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.550619 23741 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.550642 23741 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.550668 23741 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.550686 23741 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.556651 23741 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.556680 23741 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.556695 23741 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.556713 23741 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.556761 23741 net.cpp:91] Creating Layer loss
I0403 02:30:39.556779 23741 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.556795 23741 net.cpp:425] loss <- label
I0403 02:30:39.556816 23741 net.cpp:399] loss -> loss
I0403 02:30:39.556859 23741 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.556989 23741 net.cpp:141] Setting up loss
I0403 02:30:39.557013 23741 net.cpp:148] Top shape: (1)
I0403 02:30:39.557027 23741 net.cpp:151]     with loss weight 1
I0403 02:30:39.557107 23741 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.557123 23741 net.cpp:217] loss needs backward computation.
I0403 02:30:39.557137 23741 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.557152 23741 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.557165 23741 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.557188 23741 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.557205 23741 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.557219 23741 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.557231 23741 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.557245 23741 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.557258 23741 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.557272 23741 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.557286 23741 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.557299 23741 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.557312 23741 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.557327 23741 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.557340 23741 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.557354 23741 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.557368 23741 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.557381 23741 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.557394 23741 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.557407 23741 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.557422 23741 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.557436 23741 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.557451 23741 net.cpp:219] data does not need backward computation.
I0403 02:30:39.557466 23741 net.cpp:261] This network produces output loss
I0403 02:30:39.557488 23741 net.cpp:274] Network initialization done.
I0403 02:30:39.558574 23741 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.558634 23741 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.559258 23741 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.559429 23741 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.559594 23741 net.cpp:91] Creating Layer data
I0403 02:30:39.559620 23741 net.cpp:399] data -> data
I0403 02:30:39.559643 23741 net.cpp:399] data -> label
I0403 02:30:39.559665 23741 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto
I0403 02:30:39.572471 23751 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/test_db
I0403 02:30:39.575705 23741 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.762537 23741 net.cpp:141] Setting up data
I0403 02:30:39.762658 23741 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.762694 23741 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.762780 23741 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.762850 23741 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.762954 23741 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.763036 23741 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.763094 23741 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.763183 23741 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.763408 23741 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.763564 23741 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.763715 23741 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.763849 23741 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.764011 23741 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.764199 23741 net.cpp:91] Creating Layer conv1
I0403 02:30:39.764384 23741 net.cpp:425] conv1 <- data
I0403 02:30:39.764538 23741 net.cpp:399] conv1 -> conv1
I0403 02:30:39.767817 23741 net.cpp:141] Setting up conv1
I0403 02:30:39.767902 23741 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.767956 23741 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.768044 23741 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.768134 23741 net.cpp:91] Creating Layer relu1
I0403 02:30:39.768174 23741 net.cpp:425] relu1 <- conv1
I0403 02:30:39.768265 23741 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.768354 23741 net.cpp:141] Setting up relu1
I0403 02:30:39.768395 23741 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.768481 23741 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.768566 23741 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.768658 23741 net.cpp:91] Creating Layer norm1
I0403 02:30:39.768738 23741 net.cpp:425] norm1 <- conv1
I0403 02:30:39.768829 23741 net.cpp:399] norm1 -> norm1
I0403 02:30:39.768949 23741 net.cpp:141] Setting up norm1
I0403 02:30:39.769027 23741 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.769083 23741 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.769167 23741 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.769228 23741 net.cpp:91] Creating Layer pool1
I0403 02:30:39.769302 23741 net.cpp:425] pool1 <- norm1
I0403 02:30:39.769389 23741 net.cpp:399] pool1 -> pool1
I0403 02:30:39.769443 23741 net.cpp:141] Setting up pool1
I0403 02:30:39.769469 23741 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.769484 23741 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.769526 23741 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.769551 23741 net.cpp:91] Creating Layer conv2
I0403 02:30:39.769568 23741 net.cpp:425] conv2 <- pool1
I0403 02:30:39.769588 23741 net.cpp:399] conv2 -> conv2
I0403 02:30:39.795457 23741 net.cpp:141] Setting up conv2
I0403 02:30:39.805383 23741 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.805456 23741 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.805543 23741 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.805618 23741 net.cpp:91] Creating Layer relu2
I0403 02:30:39.805711 23741 net.cpp:425] relu2 <- conv2
I0403 02:30:39.805796 23741 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.805891 23741 net.cpp:141] Setting up relu2
I0403 02:30:39.805994 23741 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.806071 23741 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.806150 23741 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.806254 23741 net.cpp:91] Creating Layer norm2
I0403 02:30:39.806329 23741 net.cpp:425] norm2 <- conv2
I0403 02:30:39.806411 23741 net.cpp:399] norm2 -> norm2
I0403 02:30:39.806587 23741 net.cpp:141] Setting up norm2
I0403 02:30:39.806661 23741 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.806730 23741 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.806802 23741 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.806880 23741 net.cpp:91] Creating Layer pool2
I0403 02:30:39.806960 23741 net.cpp:425] pool2 <- norm2
I0403 02:30:39.807044 23741 net.cpp:399] pool2 -> pool2
I0403 02:30:39.807201 23741 net.cpp:141] Setting up pool2
I0403 02:30:39.807417 23741 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.807435 23741 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.807449 23741 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.807472 23741 net.cpp:91] Creating Layer conv3
I0403 02:30:39.807490 23741 net.cpp:425] conv3 <- pool2
I0403 02:30:39.807510 23741 net.cpp:399] conv3 -> conv3
I0403 02:30:39.844969 23741 net.cpp:141] Setting up conv3
I0403 02:30:39.853525 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.853585 23741 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.853668 23741 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.853762 23741 net.cpp:91] Creating Layer relu3
I0403 02:30:39.853826 23741 net.cpp:425] relu3 <- conv3
I0403 02:30:39.853899 23741 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.853996 23741 net.cpp:141] Setting up relu3
I0403 02:30:39.854063 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.854145 23741 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.854252 23741 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.854343 23741 net.cpp:91] Creating Layer conv4
I0403 02:30:39.854426 23741 net.cpp:425] conv4 <- conv3
I0403 02:30:39.854509 23741 net.cpp:399] conv4 -> conv4
I0403 02:30:39.909308 23741 net.cpp:141] Setting up conv4
I0403 02:30:39.909356 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.909373 23741 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.909392 23741 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.909414 23741 net.cpp:91] Creating Layer relu4
I0403 02:30:39.909430 23741 net.cpp:425] relu4 <- conv4
I0403 02:30:39.909449 23741 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.909469 23741 net.cpp:141] Setting up relu4
I0403 02:30:39.909487 23741 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.909499 23741 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.909513 23741 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.909534 23741 net.cpp:91] Creating Layer conv5
I0403 02:30:39.909550 23741 net.cpp:425] conv5 <- conv4
I0403 02:30:39.909569 23741 net.cpp:399] conv5 -> conv5
I0403 02:30:39.935716 23741 net.cpp:141] Setting up conv5
I0403 02:30:39.935750 23741 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.935791 23741 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.935816 23741 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.935835 23741 net.cpp:91] Creating Layer relu5
I0403 02:30:39.935852 23741 net.cpp:425] relu5 <- conv5
I0403 02:30:39.935868 23741 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.935889 23741 net.cpp:141] Setting up relu5
I0403 02:30:39.935907 23741 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.935921 23741 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.935936 23741 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.935958 23741 net.cpp:91] Creating Layer pool5
I0403 02:30:39.935976 23741 net.cpp:425] pool5 <- conv5
I0403 02:30:39.935997 23741 net.cpp:399] pool5 -> pool5
I0403 02:30:39.936050 23741 net.cpp:141] Setting up pool5
I0403 02:30:39.936072 23741 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.936089 23741 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.936101 23741 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.936125 23741 net.cpp:91] Creating Layer fc6
I0403 02:30:39.936142 23741 net.cpp:425] fc6 <- pool5
I0403 02:30:39.936164 23741 net.cpp:399] fc6 -> fc6
I0403 02:30:41.331457 23741 net.cpp:141] Setting up fc6
I0403 02:30:41.331557 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.331573 23741 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.331596 23741 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.331621 23741 net.cpp:91] Creating Layer relu6
I0403 02:30:41.331637 23741 net.cpp:425] relu6 <- fc6
I0403 02:30:41.331657 23741 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.331681 23741 net.cpp:141] Setting up relu6
I0403 02:30:41.331697 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.331713 23741 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.331727 23741 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.331748 23741 net.cpp:91] Creating Layer drop6
I0403 02:30:41.331764 23741 net.cpp:425] drop6 <- fc6
I0403 02:30:41.331781 23741 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.331825 23741 net.cpp:141] Setting up drop6
I0403 02:30:41.331847 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.331861 23741 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.331876 23741 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.331895 23741 net.cpp:91] Creating Layer fc7
I0403 02:30:41.331912 23741 net.cpp:425] fc7 <- fc6
I0403 02:30:41.331931 23741 net.cpp:399] fc7 -> fc7
I0403 02:30:41.933315 23741 net.cpp:141] Setting up fc7
I0403 02:30:41.933413 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.933429 23741 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.933451 23741 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.933476 23741 net.cpp:91] Creating Layer relu7
I0403 02:30:41.933495 23741 net.cpp:425] relu7 <- fc7
I0403 02:30:41.933516 23741 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.933540 23741 net.cpp:141] Setting up relu7
I0403 02:30:41.933557 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.933571 23741 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.933585 23741 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.933604 23741 net.cpp:91] Creating Layer drop7
I0403 02:30:41.933617 23741 net.cpp:425] drop7 <- fc7
I0403 02:30:41.933634 23741 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.933673 23741 net.cpp:141] Setting up drop7
I0403 02:30:41.933696 23741 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.933711 23741 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.933724 23741 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.933748 23741 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.933765 23741 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.933784 23741 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.939759 23741 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.939788 23741 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.939842 23741 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.939862 23741 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.939882 23741 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.939896 23741 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.939915 23741 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.939936 23741 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.939985 23741 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.940008 23741 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.940024 23741 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.940038 23741 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.940052 23741 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.940069 23741 net.cpp:91] Creating Layer loss
I0403 02:30:41.940083 23741 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.940099 23741 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.940116 23741 net.cpp:399] loss -> loss
I0403 02:30:41.940138 23741 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.940233 23741 net.cpp:141] Setting up loss
I0403 02:30:41.940258 23741 net.cpp:148] Top shape: (1)
I0403 02:30:41.940271 23741 net.cpp:151]     with loss weight 1
I0403 02:30:41.940296 23741 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.940311 23741 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.940330 23741 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.940346 23741 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.940361 23741 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.940379 23741 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.940435 23741 net.cpp:141] Setting up accuracy
I0403 02:30:41.940456 23741 net.cpp:148] Top shape: (1)
I0403 02:30:41.940469 23741 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.940484 23741 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.940497 23741 net.cpp:217] loss needs backward computation.
I0403 02:30:41.940512 23741 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.940526 23741 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.940539 23741 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.940552 23741 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.940564 23741 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.940577 23741 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.940590 23741 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.940604 23741 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.940618 23741 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.940631 23741 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.940645 23741 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.940659 23741 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.940673 23741 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.940687 23741 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.940701 23741 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.940714 23741 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.940727 23741 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.940742 23741 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.940754 23741 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.940769 23741 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.940783 23741 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.940796 23741 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.940809 23741 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.940840 23741 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.940855 23741 net.cpp:219] data does not need backward computation.
I0403 02:30:41.940870 23741 net.cpp:261] This network produces output accuracy
I0403 02:30:41.940883 23741 net.cpp:261] This network produces output loss
I0403 02:30:41.940912 23741 net.cpp:274] Network initialization done.
I0403 02:30:41.941015 23741 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.941468 23741 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:42.950570 23741 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:42.950651 23741 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:42.950672 23741 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:42.950723 23741 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.354044 23741 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.390347 23741 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.398318 23741 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.398372 23741 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.398388 23741 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.398427 23741 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.774049 23741 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:44.808503 23741 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.834449 23741 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.049543 23741 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:47.953529 23741 parallel.cpp:425] Starting Optimization
I0403 02:30:47.953723 23741 solver.cpp:279] Solving 
I0403 02:30:47.953747 23741 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:47.953891 23741 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:50.338291 23741 solver.cpp:404]     Test net output #0: accuracy = 0.0242546
I0403 02:31:50.346297 23741 solver.cpp:404]     Test net output #1: loss = 3.82569 (* 1 = 3.82569 loss)
I0403 02:31:50.920102 23741 solver.cpp:228] Iteration 0, loss = 4.26829
I0403 02:31:50.926260 23741 solver.cpp:244]     Train net output #0: loss = 4.26829 (* 1 = 4.26829 loss)
I0403 02:31:51.096294 23741 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:32:00.342726 23741 solver.cpp:228] Iteration 13, loss = 1.98231
I0403 02:32:00.349047 23741 solver.cpp:244]     Train net output #0: loss = 1.98231 (* 1 = 1.98231 loss)
I0403 02:32:00.522023 23741 sgd_solver.cpp:106] Iteration 13, lr = 0.005
I0403 02:32:09.763653 23741 solver.cpp:228] Iteration 26, loss = 1.52401
I0403 02:32:09.770822 23741 solver.cpp:244]     Train net output #0: loss = 1.52401 (* 1 = 1.52401 loss)
I0403 02:32:09.943253 23741 sgd_solver.cpp:106] Iteration 26, lr = 0.005
I0403 02:32:19.197279 23741 solver.cpp:228] Iteration 39, loss = 1.07142
I0403 02:32:19.209458 23741 solver.cpp:244]     Train net output #0: loss = 1.07142 (* 1 = 1.07142 loss)
I0403 02:32:19.357138 23741 sgd_solver.cpp:106] Iteration 39, lr = 0.005
I0403 02:32:28.607233 23741 solver.cpp:228] Iteration 52, loss = 1.13767
I0403 02:32:28.612298 23741 solver.cpp:244]     Train net output #0: loss = 1.13767 (* 1 = 1.13767 loss)
I0403 02:32:28.808807 23741 sgd_solver.cpp:106] Iteration 52, lr = 0.005
I0403 02:32:38.036093 23741 solver.cpp:228] Iteration 65, loss = 0.59567
I0403 02:32:38.041812 23741 solver.cpp:244]     Train net output #0: loss = 0.59567 (* 1 = 0.59567 loss)
I0403 02:32:38.247434 23741 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 02:32:47.510996 23741 solver.cpp:228] Iteration 78, loss = 0.781491
I0403 02:32:47.516919 23741 solver.cpp:244]     Train net output #0: loss = 0.781491 (* 1 = 0.781491 loss)
I0403 02:32:47.689856 23741 sgd_solver.cpp:106] Iteration 78, lr = 0.005
I0403 02:32:56.980835 23741 solver.cpp:228] Iteration 91, loss = 0.790175
I0403 02:32:56.988541 23741 solver.cpp:244]     Train net output #0: loss = 0.790175 (* 1 = 0.790175 loss)
I0403 02:32:57.181571 23741 sgd_solver.cpp:106] Iteration 91, lr = 0.005
I0403 02:33:06.410110 23741 solver.cpp:228] Iteration 104, loss = 0.554033
I0403 02:33:06.416513 23741 solver.cpp:244]     Train net output #0: loss = 0.554033 (* 1 = 0.554033 loss)
I0403 02:33:06.580920 23741 sgd_solver.cpp:106] Iteration 104, lr = 0.005
I0403 02:33:15.955001 23741 solver.cpp:228] Iteration 117, loss = 0.723549
I0403 02:33:15.961570 23741 solver.cpp:244]     Train net output #0: loss = 0.723549 (* 1 = 0.723549 loss)
I0403 02:33:16.111074 23741 sgd_solver.cpp:106] Iteration 117, lr = 0.005
I0403 02:33:25.478247 23741 solver.cpp:228] Iteration 130, loss = 0.43846
I0403 02:33:25.484469 23741 solver.cpp:244]     Train net output #0: loss = 0.43846 (* 1 = 0.43846 loss)
I0403 02:33:25.678575 23741 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 02:33:35.024559 23741 solver.cpp:228] Iteration 143, loss = 0.486807
I0403 02:33:35.029104 23741 solver.cpp:244]     Train net output #0: loss = 0.486807 (* 1 = 0.486807 loss)
I0403 02:33:35.219970 23741 sgd_solver.cpp:106] Iteration 143, lr = 0.005
I0403 02:33:44.487062 23741 solver.cpp:228] Iteration 156, loss = 0.496196
I0403 02:33:44.493576 23741 solver.cpp:244]     Train net output #0: loss = 0.496196 (* 1 = 0.496196 loss)
I0403 02:33:44.721952 23741 sgd_solver.cpp:106] Iteration 156, lr = 0.005
I0403 02:33:54.016249 23741 solver.cpp:228] Iteration 169, loss = 0.372551
I0403 02:33:54.022781 23741 solver.cpp:244]     Train net output #0: loss = 0.372551 (* 1 = 0.372551 loss)
I0403 02:33:54.208631 23741 sgd_solver.cpp:106] Iteration 169, lr = 0.005
I0403 02:34:03.528376 23741 solver.cpp:228] Iteration 182, loss = 0.395815
I0403 02:34:03.533958 23741 solver.cpp:244]     Train net output #0: loss = 0.395815 (* 1 = 0.395815 loss)
I0403 02:34:03.714704 23741 sgd_solver.cpp:106] Iteration 182, lr = 0.005
I0403 02:34:13.031589 23741 solver.cpp:228] Iteration 195, loss = 0.445363
I0403 02:34:13.031677 23741 solver.cpp:244]     Train net output #0: loss = 0.445363 (* 1 = 0.445363 loss)
I0403 02:34:13.214848 23741 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 02:34:22.542505 23741 solver.cpp:228] Iteration 208, loss = 0.298554
I0403 02:34:22.577502 23741 solver.cpp:244]     Train net output #0: loss = 0.298554 (* 1 = 0.298554 loss)
I0403 02:34:22.758173 23741 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 02:34:32.064862 23741 solver.cpp:228] Iteration 221, loss = 0.483497
I0403 02:34:32.075230 23741 solver.cpp:244]     Train net output #0: loss = 0.483497 (* 1 = 0.483497 loss)
I0403 02:34:32.271024 23741 sgd_solver.cpp:106] Iteration 221, lr = 0.005
I0403 02:34:41.551069 23741 solver.cpp:228] Iteration 234, loss = 0.236727
I0403 02:34:41.557042 23741 solver.cpp:244]     Train net output #0: loss = 0.236727 (* 1 = 0.236727 loss)
I0403 02:34:41.729540 23741 sgd_solver.cpp:106] Iteration 234, lr = 0.005
I0403 02:34:51.014726 23741 solver.cpp:228] Iteration 247, loss = 0.434646
I0403 02:34:51.101258 23741 solver.cpp:244]     Train net output #0: loss = 0.434646 (* 1 = 0.434646 loss)
I0403 02:34:51.205952 23741 sgd_solver.cpp:106] Iteration 247, lr = 0.005
I0403 02:35:00.415747 23741 solver.cpp:228] Iteration 260, loss = 0.438528
I0403 02:35:00.422634 23741 solver.cpp:244]     Train net output #0: loss = 0.438528 (* 1 = 0.438528 loss)
I0403 02:35:00.595314 23741 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 02:35:04.955888 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_267.caffemodel
I0403 02:35:07.825919 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_267.solverstate
I0403 02:35:09.765403 23741 solver.cpp:337] Iteration 267, Testing net (#0)
I0403 02:36:12.040247 23741 solver.cpp:404]     Test net output #0: accuracy = 0.896073
I0403 02:36:12.047677 23741 solver.cpp:404]     Test net output #1: loss = 0.314763 (* 1 = 0.314763 loss)
I0403 02:36:16.915771 23741 solver.cpp:228] Iteration 273, loss = 0.375595
I0403 02:36:16.920920 23741 solver.cpp:244]     Train net output #0: loss = 0.375595 (* 1 = 0.375595 loss)
I0403 02:36:17.094722 23741 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 02:36:26.435382 23741 solver.cpp:228] Iteration 286, loss = 0.237445
I0403 02:36:26.441220 23741 solver.cpp:244]     Train net output #0: loss = 0.237445 (* 1 = 0.237445 loss)
I0403 02:36:26.658545 23741 sgd_solver.cpp:106] Iteration 286, lr = 0.005
I0403 02:36:36.045529 23741 solver.cpp:228] Iteration 299, loss = 0.252082
I0403 02:36:36.052968 23741 solver.cpp:244]     Train net output #0: loss = 0.252082 (* 1 = 0.252082 loss)
I0403 02:36:36.229779 23741 sgd_solver.cpp:106] Iteration 299, lr = 0.005
I0403 02:36:45.544610 23741 solver.cpp:228] Iteration 312, loss = 0.149346
I0403 02:36:45.550909 23741 solver.cpp:244]     Train net output #0: loss = 0.149346 (* 1 = 0.149346 loss)
I0403 02:36:45.754937 23741 sgd_solver.cpp:106] Iteration 312, lr = 0.005
I0403 02:36:55.039921 23741 solver.cpp:228] Iteration 325, loss = 0.301901
I0403 02:36:55.045346 23741 solver.cpp:244]     Train net output #0: loss = 0.301901 (* 1 = 0.301901 loss)
I0403 02:36:55.199437 23741 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 02:37:04.605924 23741 solver.cpp:228] Iteration 338, loss = 0.261667
I0403 02:37:04.612298 23741 solver.cpp:244]     Train net output #0: loss = 0.261667 (* 1 = 0.261667 loss)
I0403 02:37:04.806951 23741 sgd_solver.cpp:106] Iteration 338, lr = 0.005
I0403 02:37:14.225078 23741 solver.cpp:228] Iteration 351, loss = 0.312689
I0403 02:37:14.230721 23741 solver.cpp:244]     Train net output #0: loss = 0.312689 (* 1 = 0.312689 loss)
I0403 02:37:14.404106 23741 sgd_solver.cpp:106] Iteration 351, lr = 0.005
I0403 02:37:23.697461 23741 solver.cpp:228] Iteration 364, loss = 0.136498
I0403 02:37:23.703699 23741 solver.cpp:244]     Train net output #0: loss = 0.136498 (* 1 = 0.136498 loss)
I0403 02:37:23.888738 23741 sgd_solver.cpp:106] Iteration 364, lr = 0.005
I0403 02:37:33.267959 23741 solver.cpp:228] Iteration 377, loss = 0.36037
I0403 02:37:33.273916 23741 solver.cpp:244]     Train net output #0: loss = 0.36037 (* 1 = 0.36037 loss)
I0403 02:37:33.361203 23741 sgd_solver.cpp:106] Iteration 377, lr = 0.005
I0403 02:37:42.758818 23741 solver.cpp:228] Iteration 390, loss = 0.278642
I0403 02:37:42.764947 23741 solver.cpp:244]     Train net output #0: loss = 0.278642 (* 1 = 0.278642 loss)
I0403 02:37:42.930106 23741 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 02:37:52.437602 23741 solver.cpp:228] Iteration 403, loss = 0.313215
I0403 02:37:52.444375 23741 solver.cpp:244]     Train net output #0: loss = 0.313215 (* 1 = 0.313215 loss)
I0403 02:37:52.597338 23741 sgd_solver.cpp:106] Iteration 403, lr = 0.005
I0403 02:38:01.923368 23741 solver.cpp:228] Iteration 416, loss = 0.282871
I0403 02:38:01.923704 23741 solver.cpp:244]     Train net output #0: loss = 0.282871 (* 1 = 0.282871 loss)
I0403 02:38:02.108548 23741 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 02:38:11.447582 23741 solver.cpp:228] Iteration 429, loss = 0.336043
I0403 02:38:11.454218 23741 solver.cpp:244]     Train net output #0: loss = 0.336043 (* 1 = 0.336043 loss)
I0403 02:38:11.664309 23741 sgd_solver.cpp:106] Iteration 429, lr = 0.005
I0403 02:38:21.008329 23741 solver.cpp:228] Iteration 442, loss = 0.189379
I0403 02:38:21.014531 23741 solver.cpp:244]     Train net output #0: loss = 0.189379 (* 1 = 0.189379 loss)
I0403 02:38:21.211920 23741 sgd_solver.cpp:106] Iteration 442, lr = 0.005
I0403 02:38:30.689818 23741 solver.cpp:228] Iteration 455, loss = 0.242509
I0403 02:38:30.696254 23741 solver.cpp:244]     Train net output #0: loss = 0.242509 (* 1 = 0.242509 loss)
I0403 02:38:30.864044 23741 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 02:38:40.126678 23741 solver.cpp:228] Iteration 468, loss = 0.303163
I0403 02:38:40.127039 23741 solver.cpp:244]     Train net output #0: loss = 0.303163 (* 1 = 0.303163 loss)
I0403 02:38:40.327345 23741 sgd_solver.cpp:106] Iteration 468, lr = 0.005
I0403 02:38:49.846431 23741 solver.cpp:228] Iteration 481, loss = 0.257654
I0403 02:38:49.846527 23741 solver.cpp:244]     Train net output #0: loss = 0.257654 (* 1 = 0.257654 loss)
I0403 02:38:50.019445 23741 sgd_solver.cpp:106] Iteration 481, lr = 0.005
I0403 02:38:59.297596 23741 solver.cpp:228] Iteration 494, loss = 0.294877
I0403 02:38:59.297685 23741 solver.cpp:244]     Train net output #0: loss = 0.294877 (* 1 = 0.294877 loss)
I0403 02:38:59.466238 23741 sgd_solver.cpp:106] Iteration 494, lr = 0.005
I0403 02:39:08.805722 23741 solver.cpp:228] Iteration 507, loss = 0.190797
I0403 02:39:08.805824 23741 solver.cpp:244]     Train net output #0: loss = 0.190797 (* 1 = 0.190797 loss)
I0403 02:39:08.967223 23741 sgd_solver.cpp:106] Iteration 507, lr = 0.005
I0403 02:39:18.289324 23741 solver.cpp:228] Iteration 520, loss = 0.122952
I0403 02:39:18.289635 23741 solver.cpp:244]     Train net output #0: loss = 0.122952 (* 1 = 0.122952 loss)
I0403 02:39:18.471047 23741 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 02:39:27.725950 23741 solver.cpp:228] Iteration 533, loss = 0.237906
I0403 02:39:27.726052 23741 solver.cpp:244]     Train net output #0: loss = 0.237906 (* 1 = 0.237906 loss)
I0403 02:39:27.862329 23741 sgd_solver.cpp:106] Iteration 533, lr = 0.005
I0403 02:39:27.862583 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_534.caffemodel
I0403 02:39:30.749400 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_534.solverstate
I0403 02:39:32.675760 23741 solver.cpp:337] Iteration 534, Testing net (#0)
I0403 02:40:34.949529 23741 solver.cpp:404]     Test net output #0: accuracy = 0.896909
I0403 02:40:34.956151 23741 solver.cpp:404]     Test net output #1: loss = 0.331006 (* 1 = 0.331006 loss)
I0403 02:40:44.233736 23741 solver.cpp:228] Iteration 546, loss = 0.284482
I0403 02:40:44.239964 23741 solver.cpp:244]     Train net output #0: loss = 0.284482 (* 1 = 0.284482 loss)
I0403 02:40:44.399819 23741 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 02:40:53.718847 23741 solver.cpp:228] Iteration 559, loss = 0.380746
I0403 02:40:53.725026 23741 solver.cpp:244]     Train net output #0: loss = 0.380745 (* 1 = 0.380745 loss)
I0403 02:40:53.900069 23741 sgd_solver.cpp:106] Iteration 559, lr = 0.005
I0403 02:41:03.201581 23741 solver.cpp:228] Iteration 572, loss = 0.179455
I0403 02:41:03.207257 23741 solver.cpp:244]     Train net output #0: loss = 0.179455 (* 1 = 0.179455 loss)
I0403 02:41:03.378116 23741 sgd_solver.cpp:106] Iteration 572, lr = 0.005
I0403 02:41:12.768839 23741 solver.cpp:228] Iteration 585, loss = 0.260907
I0403 02:41:12.774371 23741 solver.cpp:244]     Train net output #0: loss = 0.260907 (* 1 = 0.260907 loss)
I0403 02:41:12.949129 23741 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 02:41:22.199359 23741 solver.cpp:228] Iteration 598, loss = 0.175943
I0403 02:41:22.206364 23741 solver.cpp:244]     Train net output #0: loss = 0.175943 (* 1 = 0.175943 loss)
I0403 02:41:22.390444 23741 sgd_solver.cpp:106] Iteration 598, lr = 0.005
I0403 02:41:31.649890 23741 solver.cpp:228] Iteration 611, loss = 0.204046
I0403 02:41:31.656656 23741 solver.cpp:244]     Train net output #0: loss = 0.204046 (* 1 = 0.204046 loss)
I0403 02:41:31.858501 23741 sgd_solver.cpp:106] Iteration 611, lr = 0.005
I0403 02:41:41.215893 23741 solver.cpp:228] Iteration 624, loss = 0.261684
I0403 02:41:41.221935 23741 solver.cpp:244]     Train net output #0: loss = 0.261683 (* 1 = 0.261683 loss)
I0403 02:41:41.428865 23741 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 02:41:50.635601 23741 solver.cpp:228] Iteration 637, loss = 0.256347
I0403 02:41:50.642632 23741 solver.cpp:244]     Train net output #0: loss = 0.256347 (* 1 = 0.256347 loss)
I0403 02:41:50.818564 23741 sgd_solver.cpp:106] Iteration 637, lr = 0.005
I0403 02:42:00.163215 23741 solver.cpp:228] Iteration 650, loss = 0.221229
I0403 02:42:00.169966 23741 solver.cpp:244]     Train net output #0: loss = 0.221229 (* 1 = 0.221229 loss)
I0403 02:42:00.340735 23741 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 02:42:09.751544 23741 solver.cpp:228] Iteration 663, loss = 0.195267
I0403 02:42:09.758468 23741 solver.cpp:244]     Train net output #0: loss = 0.195267 (* 1 = 0.195267 loss)
I0403 02:42:09.905086 23741 sgd_solver.cpp:106] Iteration 663, lr = 0.005
I0403 02:42:19.434659 23741 solver.cpp:228] Iteration 676, loss = 0.23499
I0403 02:42:19.441087 23741 solver.cpp:244]     Train net output #0: loss = 0.23499 (* 1 = 0.23499 loss)
I0403 02:42:19.590373 23741 sgd_solver.cpp:106] Iteration 676, lr = 0.005
I0403 02:42:28.926784 23741 solver.cpp:228] Iteration 689, loss = 0.208683
I0403 02:42:28.933830 23741 solver.cpp:244]     Train net output #0: loss = 0.208683 (* 1 = 0.208683 loss)
I0403 02:42:29.087713 23741 sgd_solver.cpp:106] Iteration 689, lr = 0.005
I0403 02:42:38.469418 23741 solver.cpp:228] Iteration 702, loss = 0.120003
I0403 02:42:38.476274 23741 solver.cpp:244]     Train net output #0: loss = 0.120003 (* 1 = 0.120003 loss)
I0403 02:42:38.664090 23741 sgd_solver.cpp:106] Iteration 702, lr = 0.005
I0403 02:42:47.986554 23741 solver.cpp:228] Iteration 715, loss = 0.0876747
I0403 02:42:47.993813 23741 solver.cpp:244]     Train net output #0: loss = 0.0876747 (* 1 = 0.0876747 loss)
I0403 02:42:48.178968 23741 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 02:42:57.619158 23741 solver.cpp:228] Iteration 728, loss = 0.106164
I0403 02:42:57.624750 23741 solver.cpp:244]     Train net output #0: loss = 0.106164 (* 1 = 0.106164 loss)
I0403 02:42:57.784744 23741 sgd_solver.cpp:106] Iteration 728, lr = 0.005
I0403 02:43:07.084458 23741 solver.cpp:228] Iteration 741, loss = 0.121869
I0403 02:43:07.090989 23741 solver.cpp:244]     Train net output #0: loss = 0.121869 (* 1 = 0.121869 loss)
I0403 02:43:07.267566 23741 sgd_solver.cpp:106] Iteration 741, lr = 0.005
I0403 02:43:16.689445 23741 solver.cpp:228] Iteration 754, loss = 0.198733
I0403 02:43:16.696460 23741 solver.cpp:244]     Train net output #0: loss = 0.198733 (* 1 = 0.198733 loss)
I0403 02:43:16.896894 23741 sgd_solver.cpp:106] Iteration 754, lr = 0.005
I0403 02:43:26.184470 23741 solver.cpp:228] Iteration 767, loss = 0.265938
I0403 02:43:26.191232 23741 solver.cpp:244]     Train net output #0: loss = 0.265938 (* 1 = 0.265938 loss)
I0403 02:43:26.359246 23741 sgd_solver.cpp:106] Iteration 767, lr = 0.005
I0403 02:43:35.730949 23741 solver.cpp:228] Iteration 780, loss = 0.156268
I0403 02:43:35.736140 23741 solver.cpp:244]     Train net output #0: loss = 0.156268 (* 1 = 0.156268 loss)
I0403 02:43:35.912852 23741 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 02:43:45.184628 23741 solver.cpp:228] Iteration 793, loss = 0.101582
I0403 02:43:45.190980 23741 solver.cpp:244]     Train net output #0: loss = 0.101582 (* 1 = 0.101582 loss)
I0403 02:43:45.371351 23741 sgd_solver.cpp:106] Iteration 793, lr = 0.005
I0403 02:43:50.400655 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_801.caffemodel
I0403 02:43:53.196771 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_801.solverstate
I0403 02:43:55.130707 23741 solver.cpp:337] Iteration 801, Testing net (#0)
I0403 02:44:57.418637 23741 solver.cpp:404]     Test net output #0: accuracy = 0.929491
I0403 02:44:57.425220 23741 solver.cpp:404]     Test net output #1: loss = 0.213449 (* 1 = 0.213449 loss)
I0403 02:45:01.565275 23741 solver.cpp:228] Iteration 806, loss = 0.0984439
I0403 02:45:01.571430 23741 solver.cpp:244]     Train net output #0: loss = 0.0984438 (* 1 = 0.0984438 loss)
I0403 02:45:01.738500 23741 sgd_solver.cpp:106] Iteration 806, lr = 0.005
I0403 02:45:10.985770 23741 solver.cpp:228] Iteration 819, loss = 0.120507
I0403 02:45:10.997246 23741 solver.cpp:244]     Train net output #0: loss = 0.120507 (* 1 = 0.120507 loss)
I0403 02:45:11.182759 23741 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 02:45:20.554340 23741 solver.cpp:228] Iteration 832, loss = 0.158975
I0403 02:45:20.560541 23741 solver.cpp:244]     Train net output #0: loss = 0.158975 (* 1 = 0.158975 loss)
I0403 02:45:20.727367 23741 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 02:45:30.016511 23741 solver.cpp:228] Iteration 845, loss = 0.164233
I0403 02:45:30.023429 23741 solver.cpp:244]     Train net output #0: loss = 0.164233 (* 1 = 0.164233 loss)
I0403 02:45:30.195235 23741 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 02:45:39.588554 23741 solver.cpp:228] Iteration 858, loss = 0.124385
I0403 02:45:39.594905 23741 solver.cpp:244]     Train net output #0: loss = 0.124385 (* 1 = 0.124385 loss)
I0403 02:45:39.769305 23741 sgd_solver.cpp:106] Iteration 858, lr = 0.005
I0403 02:45:49.053449 23741 solver.cpp:228] Iteration 871, loss = 0.137879
I0403 02:45:49.060410 23741 solver.cpp:244]     Train net output #0: loss = 0.137879 (* 1 = 0.137879 loss)
I0403 02:45:49.254808 23741 sgd_solver.cpp:106] Iteration 871, lr = 0.005
I0403 02:45:58.628757 23741 solver.cpp:228] Iteration 884, loss = 0.268283
I0403 02:45:58.634348 23741 solver.cpp:244]     Train net output #0: loss = 0.268283 (* 1 = 0.268283 loss)
I0403 02:45:58.808351 23741 sgd_solver.cpp:106] Iteration 884, lr = 0.005
I0403 02:46:08.046895 23741 solver.cpp:228] Iteration 897, loss = 0.109981
I0403 02:46:08.052335 23741 solver.cpp:244]     Train net output #0: loss = 0.109981 (* 1 = 0.109981 loss)
I0403 02:46:08.252296 23741 sgd_solver.cpp:106] Iteration 897, lr = 0.005
I0403 02:46:17.573240 23741 solver.cpp:228] Iteration 910, loss = 0.366422
I0403 02:46:17.579764 23741 solver.cpp:244]     Train net output #0: loss = 0.366422 (* 1 = 0.366422 loss)
I0403 02:46:17.772195 23741 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 02:46:27.201577 23741 solver.cpp:228] Iteration 923, loss = 0.190762
I0403 02:46:27.208020 23741 solver.cpp:244]     Train net output #0: loss = 0.190762 (* 1 = 0.190762 loss)
I0403 02:46:27.398412 23741 sgd_solver.cpp:106] Iteration 923, lr = 0.005
I0403 02:46:36.754539 23741 solver.cpp:228] Iteration 936, loss = 0.125004
I0403 02:46:36.760097 23741 solver.cpp:244]     Train net output #0: loss = 0.125004 (* 1 = 0.125004 loss)
I0403 02:46:36.956051 23741 sgd_solver.cpp:106] Iteration 936, lr = 0.005
I0403 02:46:46.311053 23741 solver.cpp:228] Iteration 949, loss = 0.227555
I0403 02:46:46.318569 23741 solver.cpp:244]     Train net output #0: loss = 0.227555 (* 1 = 0.227555 loss)
I0403 02:46:46.487560 23741 sgd_solver.cpp:106] Iteration 949, lr = 0.005
I0403 02:46:55.856820 23741 solver.cpp:228] Iteration 962, loss = 0.208255
I0403 02:46:55.862735 23741 solver.cpp:244]     Train net output #0: loss = 0.208255 (* 1 = 0.208255 loss)
I0403 02:46:56.034801 23741 sgd_solver.cpp:106] Iteration 962, lr = 0.005
I0403 02:47:05.292775 23741 solver.cpp:228] Iteration 975, loss = 0.190588
I0403 02:47:05.299372 23741 solver.cpp:244]     Train net output #0: loss = 0.190588 (* 1 = 0.190588 loss)
I0403 02:47:05.519309 23741 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 02:47:14.780411 23741 solver.cpp:228] Iteration 988, loss = 0.13631
I0403 02:47:14.786957 23741 solver.cpp:244]     Train net output #0: loss = 0.136309 (* 1 = 0.136309 loss)
I0403 02:47:15.004114 23741 sgd_solver.cpp:106] Iteration 988, lr = 0.005
I0403 02:47:24.474969 23741 solver.cpp:228] Iteration 1001, loss = 0.212642
I0403 02:47:24.481573 23741 solver.cpp:244]     Train net output #0: loss = 0.212642 (* 1 = 0.212642 loss)
I0403 02:47:24.646468 23741 sgd_solver.cpp:106] Iteration 1001, lr = 0.005
I0403 02:47:34.053902 23741 solver.cpp:228] Iteration 1014, loss = 0.102286
I0403 02:47:34.059900 23741 solver.cpp:244]     Train net output #0: loss = 0.102286 (* 1 = 0.102286 loss)
I0403 02:47:34.256194 23741 sgd_solver.cpp:106] Iteration 1014, lr = 0.005
I0403 02:47:43.664584 23741 solver.cpp:228] Iteration 1027, loss = 0.0636723
I0403 02:47:43.670897 23741 solver.cpp:244]     Train net output #0: loss = 0.0636723 (* 1 = 0.0636723 loss)
I0403 02:47:43.855365 23741 sgd_solver.cpp:106] Iteration 1027, lr = 0.005
I0403 02:47:53.199564 23741 solver.cpp:228] Iteration 1040, loss = 0.367054
I0403 02:47:53.205256 23741 solver.cpp:244]     Train net output #0: loss = 0.367054 (* 1 = 0.367054 loss)
I0403 02:47:53.442813 23741 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 02:48:02.635763 23741 solver.cpp:228] Iteration 1053, loss = 0.16378
I0403 02:48:02.642400 23741 solver.cpp:244]     Train net output #0: loss = 0.16378 (* 1 = 0.16378 loss)
I0403 02:48:02.825058 23741 sgd_solver.cpp:106] Iteration 1053, lr = 0.005
I0403 02:48:12.141126 23741 solver.cpp:228] Iteration 1066, loss = 0.132654
I0403 02:48:12.147140 23741 solver.cpp:244]     Train net output #0: loss = 0.132654 (* 1 = 0.132654 loss)
I0403 02:48:12.313626 23741 sgd_solver.cpp:106] Iteration 1066, lr = 0.005
I0403 02:48:13.038544 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1068.caffemodel
I0403 02:48:15.880913 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1068.solverstate
I0403 02:48:17.797719 23741 solver.cpp:337] Iteration 1068, Testing net (#0)
I0403 02:49:20.077210 23741 solver.cpp:404]     Test net output #0: accuracy = 0.934909
I0403 02:49:20.083740 23741 solver.cpp:404]     Test net output #1: loss = 0.199941 (* 1 = 0.199941 loss)
I0403 02:49:28.698971 23741 solver.cpp:228] Iteration 1079, loss = 0.0862503
I0403 02:49:28.704661 23741 solver.cpp:244]     Train net output #0: loss = 0.0862503 (* 1 = 0.0862503 loss)
I0403 02:49:28.897375 23741 sgd_solver.cpp:106] Iteration 1079, lr = 0.005
I0403 02:49:38.146003 23741 solver.cpp:228] Iteration 1092, loss = 0.131266
I0403 02:49:38.151114 23741 solver.cpp:244]     Train net output #0: loss = 0.131266 (* 1 = 0.131266 loss)
I0403 02:49:38.381994 23741 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 02:49:47.688627 23741 solver.cpp:228] Iteration 1105, loss = 0.0818887
I0403 02:49:47.695055 23741 solver.cpp:244]     Train net output #0: loss = 0.0818887 (* 1 = 0.0818887 loss)
I0403 02:49:47.930064 23741 sgd_solver.cpp:106] Iteration 1105, lr = 0.005
I0403 02:49:57.195670 23741 solver.cpp:228] Iteration 1118, loss = 0.121728
I0403 02:49:57.202103 23741 solver.cpp:244]     Train net output #0: loss = 0.121728 (* 1 = 0.121728 loss)
I0403 02:49:57.363813 23741 sgd_solver.cpp:106] Iteration 1118, lr = 0.005
I0403 02:50:06.846667 23741 solver.cpp:228] Iteration 1131, loss = 0.137319
I0403 02:50:06.852433 23741 solver.cpp:244]     Train net output #0: loss = 0.137319 (* 1 = 0.137319 loss)
I0403 02:50:07.054872 23741 sgd_solver.cpp:106] Iteration 1131, lr = 0.005
I0403 02:50:16.249033 23741 solver.cpp:228] Iteration 1144, loss = 0.135585
I0403 02:50:16.255213 23741 solver.cpp:244]     Train net output #0: loss = 0.135585 (* 1 = 0.135585 loss)
I0403 02:50:16.453831 23741 sgd_solver.cpp:106] Iteration 1144, lr = 0.005
I0403 02:50:25.904700 23741 solver.cpp:228] Iteration 1157, loss = 0.0292331
I0403 02:50:25.911253 23741 solver.cpp:244]     Train net output #0: loss = 0.0292331 (* 1 = 0.0292331 loss)
I0403 02:50:26.086494 23741 sgd_solver.cpp:106] Iteration 1157, lr = 0.005
I0403 02:50:35.418818 23741 solver.cpp:228] Iteration 1170, loss = 0.143455
I0403 02:50:35.426182 23741 solver.cpp:244]     Train net output #0: loss = 0.143455 (* 1 = 0.143455 loss)
I0403 02:50:35.599866 23741 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 02:50:44.898959 23741 solver.cpp:228] Iteration 1183, loss = 0.0518762
I0403 02:50:44.905733 23741 solver.cpp:244]     Train net output #0: loss = 0.0518762 (* 1 = 0.0518762 loss)
I0403 02:50:45.110736 23741 sgd_solver.cpp:106] Iteration 1183, lr = 0.005
I0403 02:50:54.424522 23741 solver.cpp:228] Iteration 1196, loss = 0.153244
I0403 02:50:54.430598 23741 solver.cpp:244]     Train net output #0: loss = 0.153244 (* 1 = 0.153244 loss)
I0403 02:50:54.635126 23741 sgd_solver.cpp:106] Iteration 1196, lr = 0.005
I0403 02:51:03.966260 23741 solver.cpp:228] Iteration 1209, loss = 0.112411
I0403 02:51:03.972806 23741 solver.cpp:244]     Train net output #0: loss = 0.112411 (* 1 = 0.112411 loss)
I0403 02:51:04.167659 23741 sgd_solver.cpp:106] Iteration 1209, lr = 0.005
I0403 02:51:13.404364 23741 solver.cpp:228] Iteration 1222, loss = 0.162736
I0403 02:51:13.416896 23741 solver.cpp:244]     Train net output #0: loss = 0.162736 (* 1 = 0.162736 loss)
I0403 02:51:13.594519 23741 sgd_solver.cpp:106] Iteration 1222, lr = 0.005
I0403 02:51:22.799561 23741 solver.cpp:228] Iteration 1235, loss = 0.100412
I0403 02:51:22.806565 23741 solver.cpp:244]     Train net output #0: loss = 0.100412 (* 1 = 0.100412 loss)
I0403 02:51:22.996762 23741 sgd_solver.cpp:106] Iteration 1235, lr = 0.005
I0403 02:51:32.240788 23741 solver.cpp:228] Iteration 1248, loss = 0.126748
I0403 02:51:32.246508 23741 solver.cpp:244]     Train net output #0: loss = 0.126748 (* 1 = 0.126748 loss)
I0403 02:51:32.442900 23741 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 02:51:41.749701 23741 solver.cpp:228] Iteration 1261, loss = 0.0867699
I0403 02:51:41.756120 23741 solver.cpp:244]     Train net output #0: loss = 0.08677 (* 1 = 0.08677 loss)
I0403 02:51:41.929172 23741 sgd_solver.cpp:106] Iteration 1261, lr = 0.005
I0403 02:51:51.144419 23741 solver.cpp:228] Iteration 1274, loss = 0.0659596
I0403 02:51:51.150727 23741 solver.cpp:244]     Train net output #0: loss = 0.0659596 (* 1 = 0.0659596 loss)
I0403 02:51:51.339895 23741 sgd_solver.cpp:106] Iteration 1274, lr = 0.005
I0403 02:52:00.618402 23741 solver.cpp:228] Iteration 1287, loss = 0.118846
I0403 02:52:00.623270 23741 solver.cpp:244]     Train net output #0: loss = 0.118846 (* 1 = 0.118846 loss)
I0403 02:52:00.808845 23741 sgd_solver.cpp:106] Iteration 1287, lr = 0.005
I0403 02:52:10.155875 23741 solver.cpp:228] Iteration 1300, loss = 0.14238
I0403 02:52:10.162426 23741 solver.cpp:244]     Train net output #0: loss = 0.14238 (* 1 = 0.14238 loss)
I0403 02:52:10.338858 23741 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 02:52:19.513310 23741 solver.cpp:228] Iteration 1313, loss = 0.152681
I0403 02:52:19.519250 23741 solver.cpp:244]     Train net output #0: loss = 0.152681 (* 1 = 0.152681 loss)
I0403 02:52:19.695344 23741 sgd_solver.cpp:106] Iteration 1313, lr = 0.005
I0403 02:52:28.909442 23741 solver.cpp:228] Iteration 1326, loss = 0.152848
I0403 02:52:28.916568 23741 solver.cpp:244]     Train net output #0: loss = 0.152848 (* 1 = 0.152848 loss)
I0403 02:52:29.106919 23741 sgd_solver.cpp:106] Iteration 1326, lr = 0.005
I0403 02:52:34.880112 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1335.caffemodel
I0403 02:52:37.652681 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1335.solverstate
I0403 02:52:39.681097 23741 solver.cpp:337] Iteration 1335, Testing net (#0)
I0403 02:53:41.978588 23741 solver.cpp:404]     Test net output #0: accuracy = 0.942145
I0403 02:53:41.984921 23741 solver.cpp:404]     Test net output #1: loss = 0.181735 (* 1 = 0.181735 loss)
I0403 02:53:45.404909 23741 solver.cpp:228] Iteration 1339, loss = 0.0996143
I0403 02:53:45.411639 23741 solver.cpp:244]     Train net output #0: loss = 0.0996143 (* 1 = 0.0996143 loss)
I0403 02:53:45.621235 23741 sgd_solver.cpp:106] Iteration 1339, lr = 0.005
I0403 02:53:54.927675 23741 solver.cpp:228] Iteration 1352, loss = 0.0636061
I0403 02:53:54.934759 23741 solver.cpp:244]     Train net output #0: loss = 0.0636062 (* 1 = 0.0636062 loss)
I0403 02:53:55.106622 23741 sgd_solver.cpp:106] Iteration 1352, lr = 0.005
I0403 02:54:04.384687 23741 solver.cpp:228] Iteration 1365, loss = 0.195208
I0403 02:54:04.391343 23741 solver.cpp:244]     Train net output #0: loss = 0.195208 (* 1 = 0.195208 loss)
I0403 02:54:04.561635 23741 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 02:54:13.891311 23741 solver.cpp:228] Iteration 1378, loss = 0.0709602
I0403 02:54:13.896275 23741 solver.cpp:244]     Train net output #0: loss = 0.0709602 (* 1 = 0.0709602 loss)
I0403 02:54:14.090839 23741 sgd_solver.cpp:106] Iteration 1378, lr = 0.005
I0403 02:54:23.307683 23741 solver.cpp:228] Iteration 1391, loss = 0.175661
I0403 02:54:23.313973 23741 solver.cpp:244]     Train net output #0: loss = 0.175661 (* 1 = 0.175661 loss)
I0403 02:54:23.559018 23741 sgd_solver.cpp:106] Iteration 1391, lr = 0.005
I0403 02:54:32.807360 23741 solver.cpp:228] Iteration 1404, loss = 0.11283
I0403 02:54:32.814173 23741 solver.cpp:244]     Train net output #0: loss = 0.11283 (* 1 = 0.11283 loss)
I0403 02:54:32.994753 23741 sgd_solver.cpp:106] Iteration 1404, lr = 0.005
I0403 02:54:42.173913 23741 solver.cpp:228] Iteration 1417, loss = 0.0584054
I0403 02:54:42.180886 23741 solver.cpp:244]     Train net output #0: loss = 0.0584054 (* 1 = 0.0584054 loss)
I0403 02:54:42.353262 23741 sgd_solver.cpp:106] Iteration 1417, lr = 0.005
I0403 02:54:51.593570 23741 solver.cpp:228] Iteration 1430, loss = 0.0659624
I0403 02:54:51.598920 23741 solver.cpp:244]     Train net output #0: loss = 0.0659624 (* 1 = 0.0659624 loss)
I0403 02:54:51.773118 23741 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 02:55:01.200456 23741 solver.cpp:228] Iteration 1443, loss = 0.0793245
I0403 02:55:01.207116 23741 solver.cpp:244]     Train net output #0: loss = 0.0793246 (* 1 = 0.0793246 loss)
I0403 02:55:01.396916 23741 sgd_solver.cpp:106] Iteration 1443, lr = 0.005
I0403 02:55:10.814916 23741 solver.cpp:228] Iteration 1456, loss = 0.21404
I0403 02:55:10.822203 23741 solver.cpp:244]     Train net output #0: loss = 0.21404 (* 1 = 0.21404 loss)
I0403 02:55:10.997588 23741 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 02:55:20.383360 23741 solver.cpp:228] Iteration 1469, loss = 0.0802526
I0403 02:55:20.388975 23741 solver.cpp:244]     Train net output #0: loss = 0.0802526 (* 1 = 0.0802526 loss)
I0403 02:55:20.560603 23741 sgd_solver.cpp:106] Iteration 1469, lr = 0.005
I0403 02:55:29.891415 23741 solver.cpp:228] Iteration 1482, loss = 0.0477425
I0403 02:55:29.898258 23741 solver.cpp:244]     Train net output #0: loss = 0.0477426 (* 1 = 0.0477426 loss)
I0403 02:55:30.078366 23741 sgd_solver.cpp:106] Iteration 1482, lr = 0.005
I0403 02:55:39.506640 23741 solver.cpp:228] Iteration 1495, loss = 0.12468
I0403 02:55:39.597143 23741 solver.cpp:244]     Train net output #0: loss = 0.12468 (* 1 = 0.12468 loss)
I0403 02:55:39.670507 23741 sgd_solver.cpp:106] Iteration 1495, lr = 0.005
I0403 02:55:49.002655 23741 solver.cpp:228] Iteration 1508, loss = 0.117774
I0403 02:55:49.010113 23741 solver.cpp:244]     Train net output #0: loss = 0.117774 (* 1 = 0.117774 loss)
I0403 02:55:49.202864 23741 sgd_solver.cpp:106] Iteration 1508, lr = 0.005
I0403 02:55:58.503096 23741 solver.cpp:228] Iteration 1521, loss = 0.0496574
I0403 02:55:58.509968 23741 solver.cpp:244]     Train net output #0: loss = 0.0496574 (* 1 = 0.0496574 loss)
I0403 02:55:58.704236 23741 sgd_solver.cpp:106] Iteration 1521, lr = 0.005
I0403 02:56:08.017551 23741 solver.cpp:228] Iteration 1534, loss = 0.0742743
I0403 02:56:08.023084 23741 solver.cpp:244]     Train net output #0: loss = 0.0742743 (* 1 = 0.0742743 loss)
I0403 02:56:08.226356 23741 sgd_solver.cpp:106] Iteration 1534, lr = 0.005
I0403 02:56:17.475414 23741 solver.cpp:228] Iteration 1547, loss = 0.0480721
I0403 02:56:17.482348 23741 solver.cpp:244]     Train net output #0: loss = 0.0480722 (* 1 = 0.0480722 loss)
I0403 02:56:17.677199 23741 sgd_solver.cpp:106] Iteration 1547, lr = 0.005
I0403 02:56:26.993223 23741 solver.cpp:228] Iteration 1560, loss = 0.219215
I0403 02:56:26.999112 23741 solver.cpp:244]     Train net output #0: loss = 0.219215 (* 1 = 0.219215 loss)
I0403 02:56:27.145448 23741 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 02:56:36.674846 23741 solver.cpp:228] Iteration 1573, loss = 0.0976934
I0403 02:56:36.681331 23741 solver.cpp:244]     Train net output #0: loss = 0.0976934 (* 1 = 0.0976934 loss)
I0403 02:56:36.838053 23741 sgd_solver.cpp:106] Iteration 1573, lr = 0.005
I0403 02:56:46.229423 23741 solver.cpp:228] Iteration 1586, loss = 0.0378013
I0403 02:56:46.235409 23741 solver.cpp:244]     Train net output #0: loss = 0.0378014 (* 1 = 0.0378014 loss)
I0403 02:56:46.428613 23741 sgd_solver.cpp:106] Iteration 1586, lr = 0.005
I0403 02:56:55.721746 23741 solver.cpp:228] Iteration 1599, loss = 0.127492
I0403 02:56:55.727810 23741 solver.cpp:244]     Train net output #0: loss = 0.127492 (* 1 = 0.127492 loss)
I0403 02:56:55.877202 23741 sgd_solver.cpp:106] Iteration 1599, lr = 0.005
I0403 02:56:57.407677 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1602.caffemodel
I0403 02:57:00.055197 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1602.solverstate
I0403 02:57:01.858863 23741 solver.cpp:337] Iteration 1602, Testing net (#0)
I0403 02:58:04.144938 23741 solver.cpp:404]     Test net output #0: accuracy = 0.9448
I0403 02:58:04.151480 23741 solver.cpp:404]     Test net output #1: loss = 0.173788 (* 1 = 0.173788 loss)
I0403 02:58:12.047893 23741 solver.cpp:228] Iteration 1612, loss = 0.0533056
I0403 02:58:12.053817 23741 solver.cpp:244]     Train net output #0: loss = 0.0533056 (* 1 = 0.0533056 loss)
I0403 02:58:12.244441 23741 sgd_solver.cpp:106] Iteration 1612, lr = 0.005
I0403 02:58:21.553539 23741 solver.cpp:228] Iteration 1625, loss = 0.0523266
I0403 02:58:21.558982 23741 solver.cpp:244]     Train net output #0: loss = 0.0523266 (* 1 = 0.0523266 loss)
I0403 02:58:21.704259 23741 sgd_solver.cpp:106] Iteration 1625, lr = 0.005
I0403 02:58:31.027781 23741 solver.cpp:228] Iteration 1638, loss = 0.0499572
I0403 02:58:31.034554 23741 solver.cpp:244]     Train net output #0: loss = 0.0499573 (* 1 = 0.0499573 loss)
I0403 02:58:31.248914 23741 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 02:58:40.502184 23741 solver.cpp:228] Iteration 1651, loss = 0.115937
I0403 02:58:40.507694 23741 solver.cpp:244]     Train net output #0: loss = 0.115937 (* 1 = 0.115937 loss)
I0403 02:58:40.718750 23741 sgd_solver.cpp:106] Iteration 1651, lr = 0.005
I0403 02:58:49.987372 23741 solver.cpp:228] Iteration 1664, loss = 0.113382
I0403 02:58:50.001206 23741 solver.cpp:244]     Train net output #0: loss = 0.113382 (* 1 = 0.113382 loss)
I0403 02:58:50.188365 23741 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 02:58:59.348913 23741 solver.cpp:228] Iteration 1677, loss = 0.0913779
I0403 02:58:59.355362 23741 solver.cpp:244]     Train net output #0: loss = 0.091378 (* 1 = 0.091378 loss)
I0403 02:58:59.540519 23741 sgd_solver.cpp:106] Iteration 1677, lr = 0.005
I0403 02:59:08.810351 23741 solver.cpp:228] Iteration 1690, loss = 0.0588307
I0403 02:59:08.815683 23741 solver.cpp:244]     Train net output #0: loss = 0.0588307 (* 1 = 0.0588307 loss)
I0403 02:59:08.970417 23741 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 02:59:18.450073 23741 solver.cpp:228] Iteration 1703, loss = 0.0487129
I0403 02:59:18.456399 23741 solver.cpp:244]     Train net output #0: loss = 0.0487129 (* 1 = 0.0487129 loss)
I0403 02:59:18.617332 23741 sgd_solver.cpp:106] Iteration 1703, lr = 0.005
I0403 02:59:27.827122 23741 solver.cpp:228] Iteration 1716, loss = 0.104607
I0403 02:59:27.846560 23741 solver.cpp:244]     Train net output #0: loss = 0.104607 (* 1 = 0.104607 loss)
I0403 02:59:28.102562 23741 sgd_solver.cpp:106] Iteration 1716, lr = 0.005
I0403 02:59:37.342224 23741 solver.cpp:228] Iteration 1729, loss = 0.0922192
I0403 02:59:37.348482 23741 solver.cpp:244]     Train net output #0: loss = 0.0922193 (* 1 = 0.0922193 loss)
I0403 02:59:37.541015 23741 sgd_solver.cpp:106] Iteration 1729, lr = 0.005
I0403 02:59:46.883883 23741 solver.cpp:228] Iteration 1742, loss = 0.0441949
I0403 02:59:46.890424 23741 solver.cpp:244]     Train net output #0: loss = 0.0441949 (* 1 = 0.0441949 loss)
I0403 02:59:47.057781 23741 sgd_solver.cpp:106] Iteration 1742, lr = 0.005
I0403 02:59:56.701360 23741 solver.cpp:228] Iteration 1755, loss = 0.0400424
I0403 02:59:56.708696 23741 solver.cpp:244]     Train net output #0: loss = 0.0400424 (* 1 = 0.0400424 loss)
I0403 02:59:56.837811 23741 sgd_solver.cpp:106] Iteration 1755, lr = 0.005
I0403 03:00:06.217795 23741 solver.cpp:228] Iteration 1768, loss = 0.0250453
I0403 03:00:06.224015 23741 solver.cpp:244]     Train net output #0: loss = 0.0250453 (* 1 = 0.0250453 loss)
I0403 03:00:06.397812 23741 sgd_solver.cpp:106] Iteration 1768, lr = 0.005
I0403 03:00:15.769006 23741 solver.cpp:228] Iteration 1781, loss = 0.0684941
I0403 03:00:15.774094 23741 solver.cpp:244]     Train net output #0: loss = 0.0684942 (* 1 = 0.0684942 loss)
I0403 03:00:15.961657 23741 sgd_solver.cpp:106] Iteration 1781, lr = 0.005
I0403 03:00:25.290865 23741 solver.cpp:228] Iteration 1794, loss = 0.0815834
I0403 03:00:25.297806 23741 solver.cpp:244]     Train net output #0: loss = 0.0815835 (* 1 = 0.0815835 loss)
I0403 03:00:25.452854 23741 sgd_solver.cpp:106] Iteration 1794, lr = 0.005
I0403 03:00:34.931494 23741 solver.cpp:228] Iteration 1807, loss = 0.100283
I0403 03:00:34.937978 23741 solver.cpp:244]     Train net output #0: loss = 0.100283 (* 1 = 0.100283 loss)
I0403 03:00:35.104533 23741 sgd_solver.cpp:106] Iteration 1807, lr = 0.005
I0403 03:00:44.428277 23741 solver.cpp:228] Iteration 1820, loss = 0.0824509
I0403 03:00:44.433841 23741 solver.cpp:244]     Train net output #0: loss = 0.0824509 (* 1 = 0.0824509 loss)
I0403 03:00:44.609719 23741 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 03:00:53.978032 23741 solver.cpp:228] Iteration 1833, loss = 0.0308959
I0403 03:00:53.984683 23741 solver.cpp:244]     Train net output #0: loss = 0.0308958 (* 1 = 0.0308958 loss)
I0403 03:00:54.175297 23741 sgd_solver.cpp:106] Iteration 1833, lr = 0.005
I0403 03:01:03.440313 23741 solver.cpp:228] Iteration 1846, loss = 0.0719528
I0403 03:01:03.446046 23741 solver.cpp:244]     Train net output #0: loss = 0.0719528 (* 1 = 0.0719528 loss)
I0403 03:01:03.619928 23741 sgd_solver.cpp:106] Iteration 1846, lr = 0.005
I0403 03:01:12.980123 23741 solver.cpp:228] Iteration 1859, loss = 0.0836993
I0403 03:01:12.986789 23741 solver.cpp:244]     Train net output #0: loss = 0.0836993 (* 1 = 0.0836993 loss)
I0403 03:01:13.154700 23741 sgd_solver.cpp:106] Iteration 1859, lr = 0.005
I0403 03:01:19.806977 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1869.caffemodel
I0403 03:01:22.460736 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_1869.solverstate
I0403 03:01:24.232019 23741 solver.cpp:337] Iteration 1869, Testing net (#0)
I0403 03:02:26.524094 23741 solver.cpp:404]     Test net output #0: accuracy = 0.945818
I0403 03:02:26.530573 23741 solver.cpp:404]     Test net output #1: loss = 0.174925 (* 1 = 0.174925 loss)
I0403 03:02:29.236178 23741 solver.cpp:228] Iteration 1872, loss = 0.0831002
I0403 03:02:29.242275 23741 solver.cpp:244]     Train net output #0: loss = 0.0831002 (* 1 = 0.0831002 loss)
I0403 03:02:29.418023 23741 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 03:02:38.613035 23741 solver.cpp:228] Iteration 1885, loss = 0.0929955
I0403 03:02:38.619485 23741 solver.cpp:244]     Train net output #0: loss = 0.0929955 (* 1 = 0.0929955 loss)
I0403 03:02:38.813124 23741 sgd_solver.cpp:106] Iteration 1885, lr = 0.005
I0403 03:02:48.117118 23741 solver.cpp:228] Iteration 1898, loss = 0.0245311
I0403 03:02:48.122835 23741 solver.cpp:244]     Train net output #0: loss = 0.024531 (* 1 = 0.024531 loss)
I0403 03:02:48.306483 23741 sgd_solver.cpp:106] Iteration 1898, lr = 0.005
I0403 03:02:57.727242 23741 solver.cpp:228] Iteration 1911, loss = 0.0984975
I0403 03:02:57.733847 23741 solver.cpp:244]     Train net output #0: loss = 0.0984975 (* 1 = 0.0984975 loss)
I0403 03:02:57.951865 23741 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 03:03:07.318532 23741 solver.cpp:228] Iteration 1924, loss = 0.135424
I0403 03:03:07.324285 23741 solver.cpp:244]     Train net output #0: loss = 0.135424 (* 1 = 0.135424 loss)
I0403 03:03:07.528707 23741 sgd_solver.cpp:106] Iteration 1924, lr = 0.005
I0403 03:03:16.991735 23741 solver.cpp:228] Iteration 1937, loss = 0.0277825
I0403 03:03:16.997766 23741 solver.cpp:244]     Train net output #0: loss = 0.0277825 (* 1 = 0.0277825 loss)
I0403 03:03:17.181233 23741 sgd_solver.cpp:106] Iteration 1937, lr = 0.005
I0403 03:03:26.575101 23741 solver.cpp:228] Iteration 1950, loss = 0.11219
I0403 03:03:26.581351 23741 solver.cpp:244]     Train net output #0: loss = 0.11219 (* 1 = 0.11219 loss)
I0403 03:03:26.726131 23741 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 03:03:36.100704 23741 solver.cpp:228] Iteration 1963, loss = 0.0437311
I0403 03:03:36.107954 23741 solver.cpp:244]     Train net output #0: loss = 0.0437311 (* 1 = 0.0437311 loss)
I0403 03:03:36.264946 23741 sgd_solver.cpp:106] Iteration 1963, lr = 0.005
I0403 03:03:45.582099 23741 solver.cpp:228] Iteration 1976, loss = 0.0732195
I0403 03:03:45.588270 23741 solver.cpp:244]     Train net output #0: loss = 0.0732195 (* 1 = 0.0732195 loss)
I0403 03:03:45.784065 23741 sgd_solver.cpp:106] Iteration 1976, lr = 0.005
I0403 03:03:55.110585 23741 solver.cpp:228] Iteration 1989, loss = 0.14221
I0403 03:03:55.116642 23741 solver.cpp:244]     Train net output #0: loss = 0.14221 (* 1 = 0.14221 loss)
I0403 03:03:55.288903 23741 sgd_solver.cpp:106] Iteration 1989, lr = 0.005
I0403 03:04:04.579998 23741 solver.cpp:228] Iteration 2002, loss = 0.0984706
I0403 03:04:04.585746 23741 solver.cpp:244]     Train net output #0: loss = 0.0984706 (* 1 = 0.0984706 loss)
I0403 03:04:04.764075 23741 sgd_solver.cpp:106] Iteration 2002, lr = 0.005
I0403 03:04:13.946416 23741 solver.cpp:228] Iteration 2015, loss = 0.0410077
I0403 03:04:13.953429 23741 solver.cpp:244]     Train net output #0: loss = 0.0410077 (* 1 = 0.0410077 loss)
I0403 03:04:14.126909 23741 sgd_solver.cpp:106] Iteration 2015, lr = 0.005
I0403 03:04:23.379757 23741 solver.cpp:228] Iteration 2028, loss = 0.0945413
I0403 03:04:23.384925 23741 solver.cpp:244]     Train net output #0: loss = 0.0945413 (* 1 = 0.0945413 loss)
I0403 03:04:23.562866 23741 sgd_solver.cpp:106] Iteration 2028, lr = 0.005
I0403 03:04:32.785583 23741 solver.cpp:228] Iteration 2041, loss = 0.0441014
I0403 03:04:32.792831 23741 solver.cpp:244]     Train net output #0: loss = 0.0441014 (* 1 = 0.0441014 loss)
I0403 03:04:32.969660 23741 sgd_solver.cpp:106] Iteration 2041, lr = 0.005
I0403 03:04:42.176481 23741 solver.cpp:228] Iteration 2054, loss = 0.0562923
I0403 03:04:42.182584 23741 solver.cpp:244]     Train net output #0: loss = 0.0562923 (* 1 = 0.0562923 loss)
I0403 03:04:42.355214 23741 sgd_solver.cpp:106] Iteration 2054, lr = 0.005
I0403 03:04:51.613229 23741 solver.cpp:228] Iteration 2067, loss = 0.0300278
I0403 03:04:51.620234 23741 solver.cpp:244]     Train net output #0: loss = 0.0300278 (* 1 = 0.0300278 loss)
I0403 03:04:51.809631 23741 sgd_solver.cpp:106] Iteration 2067, lr = 0.005
I0403 03:05:01.012414 23741 solver.cpp:228] Iteration 2080, loss = 0.0828861
I0403 03:05:01.018878 23741 solver.cpp:244]     Train net output #0: loss = 0.082886 (* 1 = 0.082886 loss)
I0403 03:05:01.272872 23741 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 03:05:10.524817 23741 solver.cpp:228] Iteration 2093, loss = 0.107763
I0403 03:05:10.530791 23741 solver.cpp:244]     Train net output #0: loss = 0.107763 (* 1 = 0.107763 loss)
I0403 03:05:10.735352 23741 sgd_solver.cpp:106] Iteration 2093, lr = 0.005
I0403 03:05:20.107712 23741 solver.cpp:228] Iteration 2106, loss = 0.0887687
I0403 03:05:20.113224 23741 solver.cpp:244]     Train net output #0: loss = 0.0887686 (* 1 = 0.0887686 loss)
I0403 03:05:20.318276 23741 sgd_solver.cpp:106] Iteration 2106, lr = 0.005
I0403 03:05:29.635671 23741 solver.cpp:228] Iteration 2119, loss = 0.147721
I0403 03:05:29.641654 23741 solver.cpp:244]     Train net output #0: loss = 0.147721 (* 1 = 0.147721 loss)
I0403 03:05:29.814523 23741 sgd_solver.cpp:106] Iteration 2119, lr = 0.005
I0403 03:05:39.214395 23741 solver.cpp:228] Iteration 2132, loss = 0.0273146
I0403 03:05:39.219663 23741 solver.cpp:244]     Train net output #0: loss = 0.0273146 (* 1 = 0.0273146 loss)
I0403 03:05:39.412708 23741 sgd_solver.cpp:106] Iteration 2132, lr = 0.005
I0403 03:05:41.595846 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2136.caffemodel
I0403 03:05:44.305991 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2136.solverstate
I0403 03:05:46.120838 23741 solver.cpp:337] Iteration 2136, Testing net (#0)
I0403 03:06:48.414871 23741 solver.cpp:404]     Test net output #0: accuracy = 0.941018
I0403 03:06:48.421336 23741 solver.cpp:404]     Test net output #1: loss = 0.187748 (* 1 = 0.187748 loss)
I0403 03:06:55.574332 23741 solver.cpp:228] Iteration 2145, loss = 0.0561055
I0403 03:06:55.581038 23741 solver.cpp:244]     Train net output #0: loss = 0.0561055 (* 1 = 0.0561055 loss)
I0403 03:06:55.757033 23741 sgd_solver.cpp:106] Iteration 2145, lr = 0.005
I0403 03:07:05.116127 23741 solver.cpp:228] Iteration 2158, loss = 0.119294
I0403 03:07:05.122678 23741 solver.cpp:244]     Train net output #0: loss = 0.119294 (* 1 = 0.119294 loss)
I0403 03:07:05.315475 23741 sgd_solver.cpp:106] Iteration 2158, lr = 0.005
I0403 03:07:14.753669 23741 solver.cpp:228] Iteration 2171, loss = 0.0420546
I0403 03:07:14.768736 23741 solver.cpp:244]     Train net output #0: loss = 0.0420546 (* 1 = 0.0420546 loss)
I0403 03:07:14.937736 23741 sgd_solver.cpp:106] Iteration 2171, lr = 0.005
I0403 03:07:24.222692 23741 solver.cpp:228] Iteration 2184, loss = 0.0180641
I0403 03:07:24.228600 23741 solver.cpp:244]     Train net output #0: loss = 0.0180641 (* 1 = 0.0180641 loss)
I0403 03:07:24.502184 23741 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 03:07:33.744590 23741 solver.cpp:228] Iteration 2197, loss = 0.0627632
I0403 03:07:33.750998 23741 solver.cpp:244]     Train net output #0: loss = 0.0627632 (* 1 = 0.0627632 loss)
I0403 03:07:33.917502 23741 sgd_solver.cpp:106] Iteration 2197, lr = 0.005
I0403 03:07:43.150342 23741 solver.cpp:228] Iteration 2210, loss = 0.0509457
I0403 03:07:43.156369 23741 solver.cpp:244]     Train net output #0: loss = 0.0509457 (* 1 = 0.0509457 loss)
I0403 03:07:43.329898 23741 sgd_solver.cpp:106] Iteration 2210, lr = 0.005
I0403 03:07:52.589447 23741 solver.cpp:228] Iteration 2223, loss = 0.0243522
I0403 03:07:52.595588 23741 solver.cpp:244]     Train net output #0: loss = 0.0243522 (* 1 = 0.0243522 loss)
I0403 03:07:52.784566 23741 sgd_solver.cpp:106] Iteration 2223, lr = 0.005
I0403 03:08:01.915922 23741 solver.cpp:228] Iteration 2236, loss = 0.0708648
I0403 03:08:01.923616 23741 solver.cpp:244]     Train net output #0: loss = 0.0708648 (* 1 = 0.0708648 loss)
I0403 03:08:02.101654 23741 sgd_solver.cpp:106] Iteration 2236, lr = 0.005
I0403 03:08:11.318539 23741 solver.cpp:228] Iteration 2249, loss = 0.031322
I0403 03:08:11.324717 23741 solver.cpp:244]     Train net output #0: loss = 0.031322 (* 1 = 0.031322 loss)
I0403 03:08:11.507607 23741 sgd_solver.cpp:106] Iteration 2249, lr = 0.005
I0403 03:08:20.876428 23741 solver.cpp:228] Iteration 2262, loss = 0.0493399
I0403 03:08:20.882051 23741 solver.cpp:244]     Train net output #0: loss = 0.0493399 (* 1 = 0.0493399 loss)
I0403 03:08:21.049623 23741 sgd_solver.cpp:106] Iteration 2262, lr = 0.005
I0403 03:08:30.522135 23741 solver.cpp:228] Iteration 2275, loss = 0.0551183
I0403 03:08:30.527963 23741 solver.cpp:244]     Train net output #0: loss = 0.0551183 (* 1 = 0.0551183 loss)
I0403 03:08:30.724702 23741 sgd_solver.cpp:106] Iteration 2275, lr = 0.005
I0403 03:08:40.085469 23741 solver.cpp:228] Iteration 2288, loss = 0.0157443
I0403 03:08:40.090950 23741 solver.cpp:244]     Train net output #0: loss = 0.0157443 (* 1 = 0.0157443 loss)
I0403 03:08:40.309588 23741 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 03:08:49.497830 23741 solver.cpp:228] Iteration 2301, loss = 0.0790556
I0403 03:08:49.503952 23741 solver.cpp:244]     Train net output #0: loss = 0.0790556 (* 1 = 0.0790556 loss)
I0403 03:08:49.684911 23741 sgd_solver.cpp:106] Iteration 2301, lr = 0.005
I0403 03:08:58.909379 23741 solver.cpp:228] Iteration 2314, loss = 0.123769
I0403 03:08:58.916013 23741 solver.cpp:244]     Train net output #0: loss = 0.123769 (* 1 = 0.123769 loss)
I0403 03:08:59.119567 23741 sgd_solver.cpp:106] Iteration 2314, lr = 0.005
I0403 03:09:08.393700 23741 solver.cpp:228] Iteration 2327, loss = 0.035592
I0403 03:09:08.399603 23741 solver.cpp:244]     Train net output #0: loss = 0.035592 (* 1 = 0.035592 loss)
I0403 03:09:08.569582 23741 sgd_solver.cpp:106] Iteration 2327, lr = 0.005
I0403 03:09:17.913785 23741 solver.cpp:228] Iteration 2340, loss = 0.0236491
I0403 03:09:17.919455 23741 solver.cpp:244]     Train net output #0: loss = 0.0236491 (* 1 = 0.0236491 loss)
I0403 03:09:18.076033 23741 sgd_solver.cpp:106] Iteration 2340, lr = 0.005
I0403 03:09:27.414631 23741 solver.cpp:228] Iteration 2353, loss = 0.0096151
I0403 03:09:27.420438 23741 solver.cpp:244]     Train net output #0: loss = 0.00961511 (* 1 = 0.00961511 loss)
I0403 03:09:27.588250 23741 sgd_solver.cpp:106] Iteration 2353, lr = 0.005
I0403 03:09:36.975666 23741 solver.cpp:228] Iteration 2366, loss = 0.0591277
I0403 03:09:36.981734 23741 solver.cpp:244]     Train net output #0: loss = 0.0591277 (* 1 = 0.0591277 loss)
I0403 03:09:37.155367 23741 sgd_solver.cpp:106] Iteration 2366, lr = 0.005
I0403 03:09:46.491119 23741 solver.cpp:228] Iteration 2379, loss = 0.0329874
I0403 03:09:46.497033 23741 solver.cpp:244]     Train net output #0: loss = 0.0329875 (* 1 = 0.0329875 loss)
I0403 03:09:46.676121 23741 sgd_solver.cpp:106] Iteration 2379, lr = 0.005
I0403 03:09:56.070668 23741 solver.cpp:228] Iteration 2392, loss = 0.107952
I0403 03:09:56.077755 23741 solver.cpp:244]     Train net output #0: loss = 0.107952 (* 1 = 0.107952 loss)
I0403 03:09:56.265430 23741 sgd_solver.cpp:106] Iteration 2392, lr = 0.005
I0403 03:10:03.546221 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2403.caffemodel
I0403 03:10:06.299615 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2403.solverstate
I0403 03:10:08.146694 23741 solver.cpp:337] Iteration 2403, Testing net (#0)
I0403 03:11:10.428351 23741 solver.cpp:404]     Test net output #0: accuracy = 0.938836
I0403 03:11:10.435103 23741 solver.cpp:404]     Test net output #1: loss = 0.204889 (* 1 = 0.204889 loss)
I0403 03:11:12.394104 23741 solver.cpp:228] Iteration 2405, loss = 0.0784487
I0403 03:11:12.400234 23741 solver.cpp:244]     Train net output #0: loss = 0.0784487 (* 1 = 0.0784487 loss)
I0403 03:11:12.587625 23741 sgd_solver.cpp:106] Iteration 2405, lr = 0.005
I0403 03:11:21.964306 23741 solver.cpp:228] Iteration 2418, loss = 0.102022
I0403 03:11:21.969988 23741 solver.cpp:244]     Train net output #0: loss = 0.102022 (* 1 = 0.102022 loss)
I0403 03:11:22.147366 23741 sgd_solver.cpp:106] Iteration 2418, lr = 0.005
I0403 03:11:31.613910 23741 solver.cpp:228] Iteration 2431, loss = 0.0287269
I0403 03:11:31.619200 23741 solver.cpp:244]     Train net output #0: loss = 0.0287269 (* 1 = 0.0287269 loss)
I0403 03:11:31.821524 23741 sgd_solver.cpp:106] Iteration 2431, lr = 0.005
I0403 03:11:41.102907 23741 solver.cpp:228] Iteration 2444, loss = 0.0333246
I0403 03:11:41.108502 23741 solver.cpp:244]     Train net output #0: loss = 0.0333246 (* 1 = 0.0333246 loss)
I0403 03:11:41.301337 23741 sgd_solver.cpp:106] Iteration 2444, lr = 0.005
I0403 03:11:50.696135 23741 solver.cpp:228] Iteration 2457, loss = 0.0637554
I0403 03:11:50.700775 23741 solver.cpp:244]     Train net output #0: loss = 0.0637554 (* 1 = 0.0637554 loss)
I0403 03:11:50.874171 23741 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 03:12:00.184150 23741 solver.cpp:228] Iteration 2470, loss = 0.063562
I0403 03:12:00.190279 23741 solver.cpp:244]     Train net output #0: loss = 0.063562 (* 1 = 0.063562 loss)
I0403 03:12:00.375155 23741 sgd_solver.cpp:106] Iteration 2470, lr = 0.005
I0403 03:12:09.879400 23741 solver.cpp:228] Iteration 2483, loss = 0.0280069
I0403 03:12:09.885855 23741 solver.cpp:244]     Train net output #0: loss = 0.0280069 (* 1 = 0.0280069 loss)
I0403 03:12:10.061229 23741 sgd_solver.cpp:106] Iteration 2483, lr = 0.005
I0403 03:12:19.283270 23741 solver.cpp:228] Iteration 2496, loss = 0.0738639
I0403 03:12:19.290346 23741 solver.cpp:244]     Train net output #0: loss = 0.0738639 (* 1 = 0.0738639 loss)
I0403 03:12:19.465517 23741 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 03:12:28.874200 23741 solver.cpp:228] Iteration 2509, loss = 0.0674697
I0403 03:12:28.880554 23741 solver.cpp:244]     Train net output #0: loss = 0.0674697 (* 1 = 0.0674697 loss)
I0403 03:12:29.072069 23741 sgd_solver.cpp:106] Iteration 2509, lr = 0.005
I0403 03:12:38.323842 23741 solver.cpp:228] Iteration 2522, loss = 0.0857428
I0403 03:12:38.329799 23741 solver.cpp:244]     Train net output #0: loss = 0.0857428 (* 1 = 0.0857428 loss)
I0403 03:12:38.515348 23741 sgd_solver.cpp:106] Iteration 2522, lr = 0.005
I0403 03:12:47.916353 23741 solver.cpp:228] Iteration 2535, loss = 0.0618179
I0403 03:12:47.924213 23741 solver.cpp:244]     Train net output #0: loss = 0.061818 (* 1 = 0.061818 loss)
I0403 03:12:48.107553 23741 sgd_solver.cpp:106] Iteration 2535, lr = 0.005
I0403 03:12:57.655920 23741 solver.cpp:228] Iteration 2548, loss = 0.0836691
I0403 03:12:57.662233 23741 solver.cpp:244]     Train net output #0: loss = 0.0836692 (* 1 = 0.0836692 loss)
I0403 03:12:57.836544 23741 sgd_solver.cpp:106] Iteration 2548, lr = 0.005
I0403 03:13:07.174736 23741 solver.cpp:228] Iteration 2561, loss = 0.0305257
I0403 03:13:07.180575 23741 solver.cpp:244]     Train net output #0: loss = 0.0305258 (* 1 = 0.0305258 loss)
I0403 03:13:07.374903 23741 sgd_solver.cpp:106] Iteration 2561, lr = 0.005
I0403 03:13:16.798831 23741 solver.cpp:228] Iteration 2574, loss = 0.0112792
I0403 03:13:16.804850 23741 solver.cpp:244]     Train net output #0: loss = 0.0112792 (* 1 = 0.0112792 loss)
I0403 03:13:16.979599 23741 sgd_solver.cpp:106] Iteration 2574, lr = 0.005
I0403 03:13:26.456248 23741 solver.cpp:228] Iteration 2587, loss = 0.0168973
I0403 03:13:26.480873 23741 solver.cpp:244]     Train net output #0: loss = 0.0168973 (* 1 = 0.0168973 loss)
I0403 03:13:26.646435 23741 sgd_solver.cpp:106] Iteration 2587, lr = 0.005
I0403 03:13:36.037521 23741 solver.cpp:228] Iteration 2600, loss = 0.0580431
I0403 03:13:36.043473 23741 solver.cpp:244]     Train net output #0: loss = 0.0580431 (* 1 = 0.0580431 loss)
I0403 03:13:36.250411 23741 sgd_solver.cpp:106] Iteration 2600, lr = 0.005
I0403 03:13:45.738364 23741 solver.cpp:228] Iteration 2613, loss = 0.155249
I0403 03:13:45.743821 23741 solver.cpp:244]     Train net output #0: loss = 0.155249 (* 1 = 0.155249 loss)
I0403 03:13:45.939952 23741 sgd_solver.cpp:106] Iteration 2613, lr = 0.005
I0403 03:13:55.303829 23741 solver.cpp:228] Iteration 2626, loss = 0.0191156
I0403 03:13:55.310536 23741 solver.cpp:244]     Train net output #0: loss = 0.0191156 (* 1 = 0.0191156 loss)
I0403 03:13:55.495074 23741 sgd_solver.cpp:106] Iteration 2626, lr = 0.005
I0403 03:14:04.741291 23741 solver.cpp:228] Iteration 2639, loss = 0.051684
I0403 03:14:04.748126 23741 solver.cpp:244]     Train net output #0: loss = 0.051684 (* 1 = 0.051684 loss)
I0403 03:14:04.944983 23741 sgd_solver.cpp:106] Iteration 2639, lr = 0.005
I0403 03:14:14.215416 23741 solver.cpp:228] Iteration 2652, loss = 0.03353
I0403 03:14:14.221998 23741 solver.cpp:244]     Train net output #0: loss = 0.03353 (* 1 = 0.03353 loss)
I0403 03:14:14.411942 23741 sgd_solver.cpp:106] Iteration 2652, lr = 0.005
I0403 03:14:23.718606 23741 solver.cpp:228] Iteration 2665, loss = 0.0290218
I0403 03:14:23.724355 23741 solver.cpp:244]     Train net output #0: loss = 0.0290218 (* 1 = 0.0290218 loss)
I0403 03:14:23.878669 23741 sgd_solver.cpp:106] Iteration 2665, lr = 0.005
I0403 03:14:26.893725 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2670.caffemodel
I0403 03:14:29.663332 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2670.solverstate
I0403 03:14:31.586051 23741 solver.cpp:337] Iteration 2670, Testing net (#0)
I0403 03:15:33.882808 23741 solver.cpp:404]     Test net output #0: accuracy = 0.949273
I0403 03:15:33.889947 23741 solver.cpp:404]     Test net output #1: loss = 0.170899 (* 1 = 0.170899 loss)
I0403 03:15:40.242771 23741 solver.cpp:228] Iteration 2678, loss = 0.0927046
I0403 03:15:40.248059 23741 solver.cpp:244]     Train net output #0: loss = 0.0927046 (* 1 = 0.0927046 loss)
I0403 03:15:40.444797 23741 sgd_solver.cpp:106] Iteration 2678, lr = 0.0005
I0403 03:15:49.795621 23741 solver.cpp:228] Iteration 2691, loss = 0.0518148
I0403 03:15:49.815986 23741 solver.cpp:244]     Train net output #0: loss = 0.0518148 (* 1 = 0.0518148 loss)
I0403 03:15:49.967018 23741 sgd_solver.cpp:106] Iteration 2691, lr = 0.0005
I0403 03:15:59.289178 23741 solver.cpp:228] Iteration 2704, loss = 0.00900182
I0403 03:15:59.294356 23741 solver.cpp:244]     Train net output #0: loss = 0.00900182 (* 1 = 0.00900182 loss)
I0403 03:15:59.513278 23741 sgd_solver.cpp:106] Iteration 2704, lr = 0.0005
I0403 03:16:09.005673 23741 solver.cpp:228] Iteration 2717, loss = 0.0138682
I0403 03:16:09.012269 23741 solver.cpp:244]     Train net output #0: loss = 0.0138682 (* 1 = 0.0138682 loss)
I0403 03:16:09.194295 23741 sgd_solver.cpp:106] Iteration 2717, lr = 0.0005
I0403 03:16:18.728226 23741 solver.cpp:228] Iteration 2730, loss = 0.0226037
I0403 03:16:18.735800 23741 solver.cpp:244]     Train net output #0: loss = 0.0226037 (* 1 = 0.0226037 loss)
I0403 03:16:18.920220 23741 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 03:16:28.407630 23741 solver.cpp:228] Iteration 2743, loss = 0.0153411
I0403 03:16:28.413334 23741 solver.cpp:244]     Train net output #0: loss = 0.0153411 (* 1 = 0.0153411 loss)
I0403 03:16:28.560343 23741 sgd_solver.cpp:106] Iteration 2743, lr = 0.0005
I0403 03:16:37.856238 23741 solver.cpp:228] Iteration 2756, loss = 0.0163238
I0403 03:16:37.862884 23741 solver.cpp:244]     Train net output #0: loss = 0.0163238 (* 1 = 0.0163238 loss)
I0403 03:16:38.074383 23741 sgd_solver.cpp:106] Iteration 2756, lr = 0.0005
I0403 03:16:47.295130 23741 solver.cpp:228] Iteration 2769, loss = 0.0262014
I0403 03:16:47.302333 23741 solver.cpp:244]     Train net output #0: loss = 0.0262014 (* 1 = 0.0262014 loss)
I0403 03:16:47.489362 23741 sgd_solver.cpp:106] Iteration 2769, lr = 0.0005
I0403 03:16:56.801569 23741 solver.cpp:228] Iteration 2782, loss = 0.013499
I0403 03:16:56.807893 23741 solver.cpp:244]     Train net output #0: loss = 0.013499 (* 1 = 0.013499 loss)
I0403 03:16:57.018347 23741 sgd_solver.cpp:106] Iteration 2782, lr = 0.0005
I0403 03:17:06.376472 23741 solver.cpp:228] Iteration 2795, loss = 0.0506095
I0403 03:17:06.382447 23741 solver.cpp:244]     Train net output #0: loss = 0.0506095 (* 1 = 0.0506095 loss)
I0403 03:17:06.557881 23741 sgd_solver.cpp:106] Iteration 2795, lr = 0.0005
I0403 03:17:15.833505 23741 solver.cpp:228] Iteration 2808, loss = 0.0287345
I0403 03:17:15.839038 23741 solver.cpp:244]     Train net output #0: loss = 0.0287345 (* 1 = 0.0287345 loss)
I0403 03:17:16.091514 23741 sgd_solver.cpp:106] Iteration 2808, lr = 0.0005
I0403 03:17:25.456964 23741 solver.cpp:228] Iteration 2821, loss = 0.010119
I0403 03:17:25.463672 23741 solver.cpp:244]     Train net output #0: loss = 0.010119 (* 1 = 0.010119 loss)
I0403 03:17:25.656997 23741 sgd_solver.cpp:106] Iteration 2821, lr = 0.0005
I0403 03:17:35.185585 23741 solver.cpp:228] Iteration 2834, loss = 0.0645386
I0403 03:17:35.191483 23741 solver.cpp:244]     Train net output #0: loss = 0.0645386 (* 1 = 0.0645386 loss)
I0403 03:17:35.373410 23741 sgd_solver.cpp:106] Iteration 2834, lr = 0.0005
I0403 03:17:44.937602 23741 solver.cpp:228] Iteration 2847, loss = 0.0494675
I0403 03:17:44.945343 23741 solver.cpp:244]     Train net output #0: loss = 0.0494675 (* 1 = 0.0494675 loss)
I0403 03:17:45.121999 23741 sgd_solver.cpp:106] Iteration 2847, lr = 0.0005
I0403 03:17:54.530838 23741 solver.cpp:228] Iteration 2860, loss = 0.040095
I0403 03:17:54.536424 23741 solver.cpp:244]     Train net output #0: loss = 0.040095 (* 1 = 0.040095 loss)
I0403 03:17:54.725724 23741 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 03:18:04.083894 23741 solver.cpp:228] Iteration 2873, loss = 0.00827006
I0403 03:18:04.091085 23741 solver.cpp:244]     Train net output #0: loss = 0.00827007 (* 1 = 0.00827007 loss)
I0403 03:18:04.295847 23741 sgd_solver.cpp:106] Iteration 2873, lr = 0.0005
I0403 03:18:13.566109 23741 solver.cpp:228] Iteration 2886, loss = 0.0390236
I0403 03:18:13.573814 23741 solver.cpp:244]     Train net output #0: loss = 0.0390236 (* 1 = 0.0390236 loss)
I0403 03:18:13.725431 23741 sgd_solver.cpp:106] Iteration 2886, lr = 0.0005
I0403 03:18:23.099305 23741 solver.cpp:228] Iteration 2899, loss = 0.00193301
I0403 03:18:23.105108 23741 solver.cpp:244]     Train net output #0: loss = 0.00193301 (* 1 = 0.00193301 loss)
I0403 03:18:23.285167 23741 sgd_solver.cpp:106] Iteration 2899, lr = 0.0005
I0403 03:18:32.598359 23741 solver.cpp:228] Iteration 2912, loss = 0.0120997
I0403 03:18:32.605342 23741 solver.cpp:244]     Train net output #0: loss = 0.0120997 (* 1 = 0.0120997 loss)
I0403 03:18:32.806076 23741 sgd_solver.cpp:106] Iteration 2912, lr = 0.0005
I0403 03:18:42.161381 23741 solver.cpp:228] Iteration 2925, loss = 0.00751963
I0403 03:18:42.167361 23741 solver.cpp:244]     Train net output #0: loss = 0.00751963 (* 1 = 0.00751963 loss)
I0403 03:18:42.354127 23741 sgd_solver.cpp:106] Iteration 2925, lr = 0.0005
I0403 03:18:50.427815 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2937.caffemodel
I0403 03:18:53.142302 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_2937.solverstate
I0403 03:18:54.995677 23741 solver.cpp:337] Iteration 2937, Testing net (#0)
I0403 03:19:57.306766 23741 solver.cpp:404]     Test net output #0: accuracy = 0.962837
I0403 03:19:57.315038 23741 solver.cpp:404]     Test net output #1: loss = 0.124353 (* 1 = 0.124353 loss)
I0403 03:19:58.605100 23741 solver.cpp:228] Iteration 2938, loss = 0.0101243
I0403 03:19:58.612280 23741 solver.cpp:244]     Train net output #0: loss = 0.0101243 (* 1 = 0.0101243 loss)
I0403 03:19:58.785440 23741 sgd_solver.cpp:106] Iteration 2938, lr = 0.0005
I0403 03:20:08.066637 23741 solver.cpp:228] Iteration 2951, loss = 0.00462129
I0403 03:20:08.072728 23741 solver.cpp:244]     Train net output #0: loss = 0.00462129 (* 1 = 0.00462129 loss)
I0403 03:20:08.255995 23741 sgd_solver.cpp:106] Iteration 2951, lr = 0.0005
I0403 03:20:17.624624 23741 solver.cpp:228] Iteration 2964, loss = 0.021524
I0403 03:20:17.631580 23741 solver.cpp:244]     Train net output #0: loss = 0.021524 (* 1 = 0.021524 loss)
I0403 03:20:17.815094 23741 sgd_solver.cpp:106] Iteration 2964, lr = 0.0005
I0403 03:20:27.048164 23741 solver.cpp:228] Iteration 2977, loss = 0.00999386
I0403 03:20:27.053277 23741 solver.cpp:244]     Train net output #0: loss = 0.00999386 (* 1 = 0.00999386 loss)
I0403 03:20:27.235761 23741 sgd_solver.cpp:106] Iteration 2977, lr = 0.0005
I0403 03:20:36.595227 23741 solver.cpp:228] Iteration 2990, loss = 0.0120343
I0403 03:20:36.602494 23741 solver.cpp:244]     Train net output #0: loss = 0.0120343 (* 1 = 0.0120343 loss)
I0403 03:20:36.720420 23741 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 03:20:46.134028 23741 solver.cpp:228] Iteration 3003, loss = 0.00615093
I0403 03:20:46.140745 23741 solver.cpp:244]     Train net output #0: loss = 0.00615093 (* 1 = 0.00615093 loss)
I0403 03:20:46.330057 23741 sgd_solver.cpp:106] Iteration 3003, lr = 0.0005
I0403 03:20:55.708873 23741 solver.cpp:228] Iteration 3016, loss = 0.00918248
I0403 03:20:55.715462 23741 solver.cpp:244]     Train net output #0: loss = 0.00918248 (* 1 = 0.00918248 loss)
I0403 03:20:55.901049 23741 sgd_solver.cpp:106] Iteration 3016, lr = 0.0005
I0403 03:21:05.185776 23741 solver.cpp:228] Iteration 3029, loss = 0.00637347
I0403 03:21:05.191882 23741 solver.cpp:244]     Train net output #0: loss = 0.00637347 (* 1 = 0.00637347 loss)
I0403 03:21:05.401655 23741 sgd_solver.cpp:106] Iteration 3029, lr = 0.0005
I0403 03:21:14.872797 23741 solver.cpp:228] Iteration 3042, loss = 0.0106812
I0403 03:21:14.878835 23741 solver.cpp:244]     Train net output #0: loss = 0.0106812 (* 1 = 0.0106812 loss)
I0403 03:21:15.054816 23741 sgd_solver.cpp:106] Iteration 3042, lr = 0.0005
I0403 03:21:24.395601 23741 solver.cpp:228] Iteration 3055, loss = 0.00188106
I0403 03:21:24.401876 23741 solver.cpp:244]     Train net output #0: loss = 0.00188105 (* 1 = 0.00188105 loss)
I0403 03:21:24.571028 23741 sgd_solver.cpp:106] Iteration 3055, lr = 0.0005
I0403 03:21:33.889248 23741 solver.cpp:228] Iteration 3068, loss = 0.0278
I0403 03:21:33.894188 23741 solver.cpp:244]     Train net output #0: loss = 0.0277999 (* 1 = 0.0277999 loss)
I0403 03:21:34.055399 23741 sgd_solver.cpp:106] Iteration 3068, lr = 0.0005
I0403 03:21:43.452520 23741 solver.cpp:228] Iteration 3081, loss = 0.00200678
I0403 03:21:43.459022 23741 solver.cpp:244]     Train net output #0: loss = 0.00200676 (* 1 = 0.00200676 loss)
I0403 03:21:43.635406 23741 sgd_solver.cpp:106] Iteration 3081, lr = 0.0005
I0403 03:21:53.045761 23741 solver.cpp:228] Iteration 3094, loss = 0.00518821
I0403 03:21:53.052244 23741 solver.cpp:244]     Train net output #0: loss = 0.0051882 (* 1 = 0.0051882 loss)
I0403 03:21:53.241246 23741 sgd_solver.cpp:106] Iteration 3094, lr = 0.0005
I0403 03:22:02.681354 23741 solver.cpp:228] Iteration 3107, loss = 0.00429649
I0403 03:22:02.686601 23741 solver.cpp:244]     Train net output #0: loss = 0.00429647 (* 1 = 0.00429647 loss)
I0403 03:22:02.796584 23741 sgd_solver.cpp:106] Iteration 3107, lr = 0.0005
I0403 03:22:12.170418 23741 solver.cpp:228] Iteration 3120, loss = 0.0195248
I0403 03:22:12.176298 23741 solver.cpp:244]     Train net output #0: loss = 0.0195248 (* 1 = 0.0195248 loss)
I0403 03:22:12.369494 23741 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 03:22:21.840657 23741 solver.cpp:228] Iteration 3133, loss = 0.04972
I0403 03:22:21.846698 23741 solver.cpp:244]     Train net output #0: loss = 0.0497199 (* 1 = 0.0497199 loss)
I0403 03:22:21.992218 23741 sgd_solver.cpp:106] Iteration 3133, lr = 0.0005
I0403 03:22:31.534709 23741 solver.cpp:228] Iteration 3146, loss = 0.0065871
I0403 03:22:31.541671 23741 solver.cpp:244]     Train net output #0: loss = 0.00658707 (* 1 = 0.00658707 loss)
I0403 03:22:31.716624 23741 sgd_solver.cpp:106] Iteration 3146, lr = 0.0005
I0403 03:22:40.960366 23741 solver.cpp:228] Iteration 3159, loss = 0.0212698
I0403 03:22:40.965917 23741 solver.cpp:244]     Train net output #0: loss = 0.0212698 (* 1 = 0.0212698 loss)
I0403 03:22:41.159785 23741 sgd_solver.cpp:106] Iteration 3159, lr = 0.0005
I0403 03:22:50.388039 23741 solver.cpp:228] Iteration 3172, loss = 0.00780547
I0403 03:22:50.394466 23741 solver.cpp:244]     Train net output #0: loss = 0.00780544 (* 1 = 0.00780544 loss)
I0403 03:22:50.578470 23741 sgd_solver.cpp:106] Iteration 3172, lr = 0.0005
I0403 03:22:59.875886 23741 solver.cpp:228] Iteration 3185, loss = 0.0121893
I0403 03:22:59.887598 23741 solver.cpp:244]     Train net output #0: loss = 0.0121893 (* 1 = 0.0121893 loss)
I0403 03:23:00.071662 23741 sgd_solver.cpp:106] Iteration 3185, lr = 0.0005
I0403 03:23:09.327900 23741 solver.cpp:228] Iteration 3198, loss = 0.0569597
I0403 03:23:09.334362 23741 solver.cpp:244]     Train net output #0: loss = 0.0569597 (* 1 = 0.0569597 loss)
I0403 03:23:09.519201 23741 sgd_solver.cpp:106] Iteration 3198, lr = 0.0005
I0403 03:23:13.196970 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_3204.caffemodel
I0403 03:23:16.007531 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_3204.solverstate
I0403 03:23:17.932616 23741 solver.cpp:337] Iteration 3204, Testing net (#0)
I0403 03:24:20.211534 23741 solver.cpp:404]     Test net output #0: accuracy = 0.963928
I0403 03:24:20.217774 23741 solver.cpp:404]     Test net output #1: loss = 0.12197 (* 1 = 0.12197 loss)
I0403 03:24:25.808179 23741 solver.cpp:228] Iteration 3211, loss = 0.0127002
I0403 03:24:25.813518 23741 solver.cpp:244]     Train net output #0: loss = 0.0127002 (* 1 = 0.0127002 loss)
I0403 03:24:25.991394 23741 sgd_solver.cpp:106] Iteration 3211, lr = 0.0005
I0403 03:24:35.129655 23741 solver.cpp:228] Iteration 3224, loss = 0.0217194
I0403 03:24:35.136275 23741 solver.cpp:244]     Train net output #0: loss = 0.0217194 (* 1 = 0.0217194 loss)
I0403 03:24:35.382853 23741 sgd_solver.cpp:106] Iteration 3224, lr = 0.0005
I0403 03:24:44.797693 23741 solver.cpp:228] Iteration 3237, loss = 0.000263304
I0403 03:24:44.803592 23741 solver.cpp:244]     Train net output #0: loss = 0.00026328 (* 1 = 0.00026328 loss)
I0403 03:24:44.964488 23741 sgd_solver.cpp:106] Iteration 3237, lr = 0.0005
I0403 03:24:54.254542 23741 solver.cpp:228] Iteration 3250, loss = 0.00191901
I0403 03:24:54.260749 23741 solver.cpp:244]     Train net output #0: loss = 0.00191899 (* 1 = 0.00191899 loss)
I0403 03:24:54.460568 23741 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 03:25:03.950620 23741 solver.cpp:228] Iteration 3263, loss = 0.0266504
I0403 03:25:03.956228 23741 solver.cpp:244]     Train net output #0: loss = 0.0266504 (* 1 = 0.0266504 loss)
I0403 03:25:04.136399 23741 sgd_solver.cpp:106] Iteration 3263, lr = 0.0005
I0403 03:25:13.393074 23741 solver.cpp:228] Iteration 3276, loss = 0.0042497
I0403 03:25:13.398392 23741 solver.cpp:244]     Train net output #0: loss = 0.00424968 (* 1 = 0.00424968 loss)
I0403 03:25:13.565376 23741 sgd_solver.cpp:106] Iteration 3276, lr = 0.0005
I0403 03:25:22.996362 23741 solver.cpp:228] Iteration 3289, loss = 0.00444672
I0403 03:25:23.002903 23741 solver.cpp:244]     Train net output #0: loss = 0.0044467 (* 1 = 0.0044467 loss)
I0403 03:25:23.176301 23741 sgd_solver.cpp:106] Iteration 3289, lr = 0.0005
I0403 03:25:32.465373 23741 solver.cpp:228] Iteration 3302, loss = 0.00354249
I0403 03:25:32.471844 23741 solver.cpp:244]     Train net output #0: loss = 0.00354247 (* 1 = 0.00354247 loss)
I0403 03:25:32.671711 23741 sgd_solver.cpp:106] Iteration 3302, lr = 0.0005
I0403 03:25:41.940731 23741 solver.cpp:228] Iteration 3315, loss = 0.0067186
I0403 03:25:41.946013 23741 solver.cpp:244]     Train net output #0: loss = 0.00671858 (* 1 = 0.00671858 loss)
I0403 03:25:42.125123 23741 sgd_solver.cpp:106] Iteration 3315, lr = 0.0005
I0403 03:25:51.517962 23741 solver.cpp:228] Iteration 3328, loss = 0.0107231
I0403 03:25:51.523982 23741 solver.cpp:244]     Train net output #0: loss = 0.0107231 (* 1 = 0.0107231 loss)
I0403 03:25:51.716225 23741 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 03:26:01.019040 23741 solver.cpp:228] Iteration 3341, loss = 0.000965832
I0403 03:26:01.023551 23741 solver.cpp:244]     Train net output #0: loss = 0.000965804 (* 1 = 0.000965804 loss)
I0403 03:26:01.200461 23741 sgd_solver.cpp:106] Iteration 3341, lr = 0.0005
I0403 03:26:10.446140 23741 solver.cpp:228] Iteration 3354, loss = 0.0427062
I0403 03:26:10.452903 23741 solver.cpp:244]     Train net output #0: loss = 0.0427061 (* 1 = 0.0427061 loss)
I0403 03:26:10.619177 23741 sgd_solver.cpp:106] Iteration 3354, lr = 0.0005
I0403 03:26:19.935185 23741 solver.cpp:228] Iteration 3367, loss = 0.0184625
I0403 03:26:19.941828 23741 solver.cpp:244]     Train net output #0: loss = 0.0184625 (* 1 = 0.0184625 loss)
I0403 03:26:20.080782 23741 sgd_solver.cpp:106] Iteration 3367, lr = 0.0005
I0403 03:26:29.499735 23741 solver.cpp:228] Iteration 3380, loss = 0.0233467
I0403 03:26:29.506173 23741 solver.cpp:244]     Train net output #0: loss = 0.0233467 (* 1 = 0.0233467 loss)
I0403 03:26:29.684623 23741 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 03:26:38.989305 23741 solver.cpp:228] Iteration 3393, loss = 0.00422841
I0403 03:26:38.995179 23741 solver.cpp:244]     Train net output #0: loss = 0.00422838 (* 1 = 0.00422838 loss)
I0403 03:26:39.167759 23741 sgd_solver.cpp:106] Iteration 3393, lr = 0.0005
I0403 03:26:48.573694 23741 solver.cpp:228] Iteration 3406, loss = 0.00157398
I0403 03:26:48.579699 23741 solver.cpp:244]     Train net output #0: loss = 0.00157395 (* 1 = 0.00157395 loss)
I0403 03:26:48.733595 23741 sgd_solver.cpp:106] Iteration 3406, lr = 0.0005
I0403 03:26:58.200697 23741 solver.cpp:228] Iteration 3419, loss = 0.0114484
I0403 03:26:58.209246 23741 solver.cpp:244]     Train net output #0: loss = 0.0114483 (* 1 = 0.0114483 loss)
I0403 03:26:58.356231 23741 sgd_solver.cpp:106] Iteration 3419, lr = 0.0005
I0403 03:27:07.707753 23741 solver.cpp:228] Iteration 3432, loss = 0.00587236
I0403 03:27:07.715644 23741 solver.cpp:244]     Train net output #0: loss = 0.00587232 (* 1 = 0.00587232 loss)
I0403 03:27:07.901494 23741 sgd_solver.cpp:106] Iteration 3432, lr = 0.0005
I0403 03:27:17.240207 23741 solver.cpp:228] Iteration 3445, loss = 0.0328032
I0403 03:27:17.245239 23741 solver.cpp:244]     Train net output #0: loss = 0.0328031 (* 1 = 0.0328031 loss)
I0403 03:27:17.440310 23741 sgd_solver.cpp:106] Iteration 3445, lr = 0.0005
I0403 03:27:26.683104 23741 solver.cpp:228] Iteration 3458, loss = 0.00816179
I0403 03:27:26.690022 23741 solver.cpp:244]     Train net output #0: loss = 0.00816175 (* 1 = 0.00816175 loss)
I0403 03:27:26.881671 23741 sgd_solver.cpp:106] Iteration 3458, lr = 0.0005
I0403 03:27:35.751556 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_3471.caffemodel
I0403 03:27:38.536583 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_3471.solverstate
I0403 03:27:40.459172 23741 solver.cpp:337] Iteration 3471, Testing net (#0)
I0403 03:28:42.752490 23741 solver.cpp:404]     Test net output #0: accuracy = 0.96451
I0403 03:28:42.762419 23741 solver.cpp:404]     Test net output #1: loss = 0.123482 (* 1 = 0.123482 loss)
I0403 03:28:43.281680 23741 solver.cpp:228] Iteration 3471, loss = 0.00512663
I0403 03:28:43.287987 23741 solver.cpp:244]     Train net output #0: loss = 0.00512659 (* 1 = 0.00512659 loss)
I0403 03:28:43.476646 23741 sgd_solver.cpp:106] Iteration 3471, lr = 0.0005
I0403 03:28:52.816011 23741 solver.cpp:228] Iteration 3484, loss = 0.0311954
I0403 03:28:52.822935 23741 solver.cpp:244]     Train net output #0: loss = 0.0311953 (* 1 = 0.0311953 loss)
I0403 03:28:53.001317 23741 sgd_solver.cpp:106] Iteration 3484, lr = 0.0005
I0403 03:29:02.259055 23741 solver.cpp:228] Iteration 3497, loss = 0.00911517
I0403 03:29:02.265615 23741 solver.cpp:244]     Train net output #0: loss = 0.00911514 (* 1 = 0.00911514 loss)
I0403 03:29:02.445225 23741 sgd_solver.cpp:106] Iteration 3497, lr = 0.0005
I0403 03:29:11.737004 23741 solver.cpp:228] Iteration 3510, loss = 0.00362286
I0403 03:29:11.743968 23741 solver.cpp:244]     Train net output #0: loss = 0.00362282 (* 1 = 0.00362282 loss)
I0403 03:29:11.957386 23741 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 03:29:21.267083 23741 solver.cpp:228] Iteration 3523, loss = 0.00149614
I0403 03:29:21.272938 23741 solver.cpp:244]     Train net output #0: loss = 0.0014961 (* 1 = 0.0014961 loss)
I0403 03:29:21.446635 23741 sgd_solver.cpp:106] Iteration 3523, lr = 0.0005
I0403 03:29:30.713407 23741 solver.cpp:228] Iteration 3536, loss = 0.0319192
I0403 03:29:30.719116 23741 solver.cpp:244]     Train net output #0: loss = 0.0319192 (* 1 = 0.0319192 loss)
I0403 03:29:30.917759 23741 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 03:29:40.405292 23741 solver.cpp:228] Iteration 3549, loss = 0.00899133
I0403 03:29:40.411523 23741 solver.cpp:244]     Train net output #0: loss = 0.00899129 (* 1 = 0.00899129 loss)
I0403 03:29:40.556264 23741 sgd_solver.cpp:106] Iteration 3549, lr = 0.0005
I0403 03:29:50.036806 23741 solver.cpp:228] Iteration 3562, loss = 0.00655807
I0403 03:29:50.042459 23741 solver.cpp:244]     Train net output #0: loss = 0.00655802 (* 1 = 0.00655802 loss)
I0403 03:29:50.225062 23741 sgd_solver.cpp:106] Iteration 3562, lr = 0.0005
I0403 03:29:59.572898 23741 solver.cpp:228] Iteration 3575, loss = 0.0142438
I0403 03:29:59.579036 23741 solver.cpp:244]     Train net output #0: loss = 0.0142437 (* 1 = 0.0142437 loss)
I0403 03:29:59.753599 23741 sgd_solver.cpp:106] Iteration 3575, lr = 0.0005
I0403 03:30:09.081063 23741 solver.cpp:228] Iteration 3588, loss = 0.00464254
I0403 03:30:09.087345 23741 solver.cpp:244]     Train net output #0: loss = 0.0046425 (* 1 = 0.0046425 loss)
I0403 03:30:09.270516 23741 sgd_solver.cpp:106] Iteration 3588, lr = 0.0005
I0403 03:30:18.563835 23741 solver.cpp:228] Iteration 3601, loss = 0.00420943
I0403 03:30:18.569072 23741 solver.cpp:244]     Train net output #0: loss = 0.0042094 (* 1 = 0.0042094 loss)
I0403 03:30:18.745905 23741 sgd_solver.cpp:106] Iteration 3601, lr = 0.0005
I0403 03:30:27.983747 23741 solver.cpp:228] Iteration 3614, loss = 0.0227819
I0403 03:30:27.991468 23741 solver.cpp:244]     Train net output #0: loss = 0.0227818 (* 1 = 0.0227818 loss)
I0403 03:30:28.171617 23741 sgd_solver.cpp:106] Iteration 3614, lr = 0.0005
I0403 03:30:37.446750 23741 solver.cpp:228] Iteration 3627, loss = 0.0310514
I0403 03:30:37.452713 23741 solver.cpp:244]     Train net output #0: loss = 0.0310514 (* 1 = 0.0310514 loss)
I0403 03:30:37.620549 23741 sgd_solver.cpp:106] Iteration 3627, lr = 0.0005
I0403 03:30:46.936385 23741 solver.cpp:228] Iteration 3640, loss = 0.00545775
I0403 03:30:46.942423 23741 solver.cpp:244]     Train net output #0: loss = 0.00545771 (* 1 = 0.00545771 loss)
I0403 03:30:47.132156 23741 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 03:30:56.322789 23741 solver.cpp:228] Iteration 3653, loss = 0.00224742
I0403 03:30:56.330781 23741 solver.cpp:244]     Train net output #0: loss = 0.00224738 (* 1 = 0.00224738 loss)
I0403 03:30:56.510903 23741 sgd_solver.cpp:106] Iteration 3653, lr = 0.0005
I0403 03:31:05.904502 23741 solver.cpp:228] Iteration 3666, loss = 0.00639649
I0403 03:31:05.911136 23741 solver.cpp:244]     Train net output #0: loss = 0.00639645 (* 1 = 0.00639645 loss)
I0403 03:31:06.056536 23741 sgd_solver.cpp:106] Iteration 3666, lr = 0.0005
I0403 03:31:15.530927 23741 solver.cpp:228] Iteration 3679, loss = 0.00577184
I0403 03:31:15.536659 23741 solver.cpp:244]     Train net output #0: loss = 0.00577179 (* 1 = 0.00577179 loss)
I0403 03:31:15.703047 23741 sgd_solver.cpp:106] Iteration 3679, lr = 0.0005
I0403 03:31:25.034401 23741 solver.cpp:228] Iteration 3692, loss = 0.00605824
I0403 03:31:25.040623 23741 solver.cpp:244]     Train net output #0: loss = 0.0060582 (* 1 = 0.0060582 loss)
I0403 03:31:25.225361 23741 sgd_solver.cpp:106] Iteration 3692, lr = 0.0005
I0403 03:31:34.563609 23741 solver.cpp:228] Iteration 3705, loss = 0.0273348
I0403 03:31:34.568843 23741 solver.cpp:244]     Train net output #0: loss = 0.0273347 (* 1 = 0.0273347 loss)
I0403 03:31:34.755347 23741 sgd_solver.cpp:106] Iteration 3705, lr = 0.0005
I0403 03:31:44.175552 23741 solver.cpp:228] Iteration 3718, loss = 0.0034497
I0403 03:31:44.180843 23741 solver.cpp:244]     Train net output #0: loss = 0.00344966 (* 1 = 0.00344966 loss)
I0403 03:31:44.442719 23741 sgd_solver.cpp:106] Iteration 3718, lr = 0.0005
I0403 03:31:53.829243 23741 solver.cpp:228] Iteration 3731, loss = 0.0189187
I0403 03:31:53.835101 23741 solver.cpp:244]     Train net output #0: loss = 0.0189187 (* 1 = 0.0189187 loss)
I0403 03:31:54.028439 23741 sgd_solver.cpp:106] Iteration 3731, lr = 0.0005
I0403 03:31:58.372493 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_3738.caffemodel
I0403 03:32:01.153475 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_3738.solverstate
I0403 03:32:03.073601 23741 solver.cpp:337] Iteration 3738, Testing net (#0)
I0403 03:33:05.368351 23741 solver.cpp:404]     Test net output #0: accuracy = 0.964801
I0403 03:33:05.374466 23741 solver.cpp:404]     Test net output #1: loss = 0.122561 (* 1 = 0.122561 loss)
I0403 03:33:10.345209 23741 solver.cpp:228] Iteration 3744, loss = 0.0035936
I0403 03:33:10.350251 23741 solver.cpp:244]     Train net output #0: loss = 0.00359356 (* 1 = 0.00359356 loss)
I0403 03:33:10.535943 23741 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 03:33:19.924444 23741 solver.cpp:228] Iteration 3757, loss = 0.00627196
I0403 03:33:19.931253 23741 solver.cpp:244]     Train net output #0: loss = 0.00627192 (* 1 = 0.00627192 loss)
I0403 03:33:20.087918 23741 sgd_solver.cpp:106] Iteration 3757, lr = 0.0005
I0403 03:33:29.374155 23741 solver.cpp:228] Iteration 3770, loss = 0.00715109
I0403 03:33:29.380836 23741 solver.cpp:244]     Train net output #0: loss = 0.00715105 (* 1 = 0.00715105 loss)
I0403 03:33:29.566479 23741 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 03:33:38.940186 23741 solver.cpp:228] Iteration 3783, loss = 0.00889836
I0403 03:33:38.946229 23741 solver.cpp:244]     Train net output #0: loss = 0.00889831 (* 1 = 0.00889831 loss)
I0403 03:33:39.092813 23741 sgd_solver.cpp:106] Iteration 3783, lr = 0.0005
I0403 03:33:48.658380 23741 solver.cpp:228] Iteration 3796, loss = 0.0377609
I0403 03:33:48.664180 23741 solver.cpp:244]     Train net output #0: loss = 0.0377608 (* 1 = 0.0377608 loss)
I0403 03:33:48.763159 23741 sgd_solver.cpp:106] Iteration 3796, lr = 0.0005
I0403 03:33:58.398569 23741 solver.cpp:228] Iteration 3809, loss = 0.0107162
I0403 03:33:58.404959 23741 solver.cpp:244]     Train net output #0: loss = 0.0107162 (* 1 = 0.0107162 loss)
I0403 03:33:58.599850 23741 sgd_solver.cpp:106] Iteration 3809, lr = 0.0005
I0403 03:34:08.096467 23741 solver.cpp:228] Iteration 3822, loss = 0.00294798
I0403 03:34:08.096573 23741 solver.cpp:244]     Train net output #0: loss = 0.00294793 (* 1 = 0.00294793 loss)
I0403 03:34:08.281625 23741 sgd_solver.cpp:106] Iteration 3822, lr = 0.0005
I0403 03:34:17.473223 23741 solver.cpp:228] Iteration 3835, loss = 0.00106446
I0403 03:34:17.473551 23741 solver.cpp:244]     Train net output #0: loss = 0.00106441 (* 1 = 0.00106441 loss)
I0403 03:34:17.627701 23741 sgd_solver.cpp:106] Iteration 3835, lr = 0.0005
I0403 03:34:27.206266 23741 solver.cpp:228] Iteration 3848, loss = 0.00218484
I0403 03:34:27.206368 23741 solver.cpp:244]     Train net output #0: loss = 0.00218478 (* 1 = 0.00218478 loss)
I0403 03:34:27.386293 23741 sgd_solver.cpp:106] Iteration 3848, lr = 0.0005
I0403 03:34:36.733034 23741 solver.cpp:228] Iteration 3861, loss = 0.00149747
I0403 03:34:36.733124 23741 solver.cpp:244]     Train net output #0: loss = 0.00149742 (* 1 = 0.00149742 loss)
I0403 03:34:36.904572 23741 sgd_solver.cpp:106] Iteration 3861, lr = 0.0005
I0403 03:34:46.287863 23741 solver.cpp:228] Iteration 3874, loss = 0.00909443
I0403 03:34:46.287974 23741 solver.cpp:244]     Train net output #0: loss = 0.00909438 (* 1 = 0.00909438 loss)
I0403 03:34:46.482327 23741 sgd_solver.cpp:106] Iteration 3874, lr = 0.0005
I0403 03:34:56.027704 23741 solver.cpp:228] Iteration 3887, loss = 0.0190204
I0403 03:34:56.028035 23741 solver.cpp:244]     Train net output #0: loss = 0.0190203 (* 1 = 0.0190203 loss)
I0403 03:34:56.172802 23741 sgd_solver.cpp:106] Iteration 3887, lr = 0.0005
I0403 03:35:05.606987 23741 solver.cpp:228] Iteration 3900, loss = 0.0076222
I0403 03:35:05.607094 23741 solver.cpp:244]     Train net output #0: loss = 0.00762216 (* 1 = 0.00762216 loss)
I0403 03:35:05.818269 23741 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 03:35:15.339433 23741 solver.cpp:228] Iteration 3913, loss = 0.00901337
I0403 03:35:15.339535 23741 solver.cpp:244]     Train net output #0: loss = 0.00901332 (* 1 = 0.00901332 loss)
I0403 03:35:15.520589 23741 sgd_solver.cpp:106] Iteration 3913, lr = 0.0005
I0403 03:35:24.785194 23741 solver.cpp:228] Iteration 3926, loss = 0.0118927
I0403 03:35:24.785289 23741 solver.cpp:244]     Train net output #0: loss = 0.0118927 (* 1 = 0.0118927 loss)
I0403 03:35:24.975731 23741 sgd_solver.cpp:106] Iteration 3926, lr = 0.0005
I0403 03:35:34.241729 23741 solver.cpp:228] Iteration 3939, loss = 0.0257494
I0403 03:35:34.242014 23741 solver.cpp:244]     Train net output #0: loss = 0.0257494 (* 1 = 0.0257494 loss)
I0403 03:35:34.413944 23741 sgd_solver.cpp:106] Iteration 3939, lr = 0.0005
I0403 03:35:43.809106 23741 solver.cpp:228] Iteration 3952, loss = 0.010483
I0403 03:35:43.809212 23741 solver.cpp:244]     Train net output #0: loss = 0.010483 (* 1 = 0.010483 loss)
I0403 03:35:43.977427 23741 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 03:35:53.238039 23741 solver.cpp:228] Iteration 3965, loss = 0.00918124
I0403 03:35:53.238149 23741 solver.cpp:244]     Train net output #0: loss = 0.00918119 (* 1 = 0.00918119 loss)
I0403 03:35:53.428490 23741 sgd_solver.cpp:106] Iteration 3965, lr = 0.0005
I0403 03:36:02.703634 23741 solver.cpp:228] Iteration 3978, loss = 0.0079102
I0403 03:36:02.703742 23741 solver.cpp:244]     Train net output #0: loss = 0.00791016 (* 1 = 0.00791016 loss)
I0403 03:36:02.922951 23741 sgd_solver.cpp:106] Iteration 3978, lr = 0.0005
I0403 03:36:12.221056 23741 solver.cpp:228] Iteration 3991, loss = 0.0132063
I0403 03:36:12.221408 23741 solver.cpp:244]     Train net output #0: loss = 0.0132063 (* 1 = 0.0132063 loss)
I0403 03:36:12.416982 23741 sgd_solver.cpp:106] Iteration 3991, lr = 0.0005
I0403 03:36:21.662462 23741 solver.cpp:228] Iteration 4004, loss = 0.00837088
I0403 03:36:21.662570 23741 solver.cpp:244]     Train net output #0: loss = 0.00837083 (* 1 = 0.00837083 loss)
I0403 03:36:21.878264 23741 sgd_solver.cpp:106] Iteration 4004, lr = 0.0005
I0403 03:36:21.878501 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4005.caffemodel
I0403 03:36:24.571482 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4005.solverstate
I0403 03:36:26.396888 23741 solver.cpp:337] Iteration 4005, Testing net (#0)
I0403 03:37:28.677664 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965019
I0403 03:37:28.678009 23741 solver.cpp:404]     Test net output #1: loss = 0.12274 (* 1 = 0.12274 loss)
I0403 03:37:37.988220 23741 solver.cpp:228] Iteration 4017, loss = 0.00459391
I0403 03:37:37.988329 23741 solver.cpp:244]     Train net output #0: loss = 0.00459386 (* 1 = 0.00459386 loss)
I0403 03:37:38.170444 23741 sgd_solver.cpp:106] Iteration 4017, lr = 0.0005
I0403 03:37:47.506780 23741 solver.cpp:228] Iteration 4030, loss = 0.0168296
I0403 03:37:47.506886 23741 solver.cpp:244]     Train net output #0: loss = 0.0168295 (* 1 = 0.0168295 loss)
I0403 03:37:47.707895 23741 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 03:37:57.026515 23741 solver.cpp:228] Iteration 4043, loss = 0.00422967
I0403 03:37:57.026629 23741 solver.cpp:244]     Train net output #0: loss = 0.00422962 (* 1 = 0.00422962 loss)
I0403 03:37:57.211292 23741 sgd_solver.cpp:106] Iteration 4043, lr = 0.0005
I0403 03:38:06.497560 23741 solver.cpp:228] Iteration 4056, loss = 0.00673886
I0403 03:38:06.497918 23741 solver.cpp:244]     Train net output #0: loss = 0.00673881 (* 1 = 0.00673881 loss)
I0403 03:38:06.702126 23741 sgd_solver.cpp:106] Iteration 4056, lr = 0.0005
I0403 03:38:15.917832 23741 solver.cpp:228] Iteration 4069, loss = 0.0389518
I0403 03:38:15.917932 23741 solver.cpp:244]     Train net output #0: loss = 0.0389517 (* 1 = 0.0389517 loss)
I0403 03:38:16.072000 23741 sgd_solver.cpp:106] Iteration 4069, lr = 0.0005
I0403 03:38:25.339330 23741 solver.cpp:228] Iteration 4082, loss = 0.0194959
I0403 03:38:25.339440 23741 solver.cpp:244]     Train net output #0: loss = 0.0194958 (* 1 = 0.0194958 loss)
I0403 03:38:25.533711 23741 sgd_solver.cpp:106] Iteration 4082, lr = 0.0005
I0403 03:38:34.834203 23741 solver.cpp:228] Iteration 4095, loss = 0.0187908
I0403 03:38:34.834302 23741 solver.cpp:244]     Train net output #0: loss = 0.0187907 (* 1 = 0.0187907 loss)
I0403 03:38:35.014806 23741 sgd_solver.cpp:106] Iteration 4095, lr = 0.0005
I0403 03:38:44.174608 23741 solver.cpp:228] Iteration 4108, loss = 0.0106213
I0403 03:38:44.174931 23741 solver.cpp:244]     Train net output #0: loss = 0.0106213 (* 1 = 0.0106213 loss)
I0403 03:38:44.354789 23741 sgd_solver.cpp:106] Iteration 4108, lr = 0.0005
I0403 03:38:53.649345 23741 solver.cpp:228] Iteration 4121, loss = 0.0169357
I0403 03:38:53.649449 23741 solver.cpp:244]     Train net output #0: loss = 0.0169357 (* 1 = 0.0169357 loss)
I0403 03:38:53.879343 23741 sgd_solver.cpp:106] Iteration 4121, lr = 0.0005
I0403 03:39:03.259992 23741 solver.cpp:228] Iteration 4134, loss = 0.00521764
I0403 03:39:03.260109 23741 solver.cpp:244]     Train net output #0: loss = 0.00521758 (* 1 = 0.00521758 loss)
I0403 03:39:03.446990 23741 sgd_solver.cpp:106] Iteration 4134, lr = 0.0005
I0403 03:39:12.729847 23741 solver.cpp:228] Iteration 4147, loss = 0.0407804
I0403 03:39:12.729943 23741 solver.cpp:244]     Train net output #0: loss = 0.0407803 (* 1 = 0.0407803 loss)
I0403 03:39:12.921358 23741 sgd_solver.cpp:106] Iteration 4147, lr = 0.0005
I0403 03:39:22.279475 23741 solver.cpp:228] Iteration 4160, loss = 0.00116566
I0403 03:39:22.279811 23741 solver.cpp:244]     Train net output #0: loss = 0.00116561 (* 1 = 0.00116561 loss)
I0403 03:39:22.464395 23741 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 03:39:31.714391 23741 solver.cpp:228] Iteration 4173, loss = 0.000582173
I0403 03:39:31.714500 23741 solver.cpp:244]     Train net output #0: loss = 0.000582121 (* 1 = 0.000582121 loss)
I0403 03:39:31.941442 23741 sgd_solver.cpp:106] Iteration 4173, lr = 0.0005
I0403 03:39:41.171319 23741 solver.cpp:228] Iteration 4186, loss = 0.00261641
I0403 03:39:41.171428 23741 solver.cpp:244]     Train net output #0: loss = 0.00261635 (* 1 = 0.00261635 loss)
I0403 03:39:41.393775 23741 sgd_solver.cpp:106] Iteration 4186, lr = 0.0005
I0403 03:39:50.614579 23741 solver.cpp:228] Iteration 4199, loss = 0.013439
I0403 03:39:50.614686 23741 solver.cpp:244]     Train net output #0: loss = 0.0134389 (* 1 = 0.0134389 loss)
I0403 03:39:50.795243 23741 sgd_solver.cpp:106] Iteration 4199, lr = 0.0005
I0403 03:40:00.028121 23741 solver.cpp:228] Iteration 4212, loss = 0.00300645
I0403 03:40:00.028493 23741 solver.cpp:244]     Train net output #0: loss = 0.00300639 (* 1 = 0.00300639 loss)
I0403 03:40:00.208737 23741 sgd_solver.cpp:106] Iteration 4212, lr = 0.0005
I0403 03:40:09.519327 23741 solver.cpp:228] Iteration 4225, loss = 0.00910188
I0403 03:40:09.519430 23741 solver.cpp:244]     Train net output #0: loss = 0.00910182 (* 1 = 0.00910182 loss)
I0403 03:40:09.689115 23741 sgd_solver.cpp:106] Iteration 4225, lr = 0.0005
I0403 03:40:18.929638 23741 solver.cpp:228] Iteration 4238, loss = 0.00168694
I0403 03:40:18.929738 23741 solver.cpp:244]     Train net output #0: loss = 0.00168689 (* 1 = 0.00168689 loss)
I0403 03:40:19.111120 23741 sgd_solver.cpp:106] Iteration 4238, lr = 0.0005
I0403 03:40:28.369691 23741 solver.cpp:228] Iteration 4251, loss = 0.00108823
I0403 03:40:28.369792 23741 solver.cpp:244]     Train net output #0: loss = 0.00108818 (* 1 = 0.00108818 loss)
I0403 03:40:28.548756 23741 sgd_solver.cpp:106] Iteration 4251, lr = 0.0005
I0403 03:40:37.893844 23741 solver.cpp:228] Iteration 4264, loss = 0.000687262
I0403 03:40:37.894187 23741 solver.cpp:244]     Train net output #0: loss = 0.00068721 (* 1 = 0.00068721 loss)
I0403 03:40:38.076197 23741 sgd_solver.cpp:106] Iteration 4264, lr = 0.0005
I0403 03:40:43.151566 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4272.caffemodel
I0403 03:40:45.859534 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4272.solverstate
I0403 03:40:47.671499 23741 solver.cpp:337] Iteration 4272, Testing net (#0)
I0403 03:41:49.962971 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965564
I0403 03:41:49.967092 23741 solver.cpp:404]     Test net output #1: loss = 0.121826 (* 1 = 0.121826 loss)
I0403 03:41:54.276736 23741 solver.cpp:228] Iteration 4277, loss = 0.00487409
I0403 03:41:54.276837 23741 solver.cpp:244]     Train net output #0: loss = 0.00487404 (* 1 = 0.00487404 loss)
I0403 03:41:54.446714 23741 sgd_solver.cpp:106] Iteration 4277, lr = 0.0005
I0403 03:42:03.819452 23741 solver.cpp:228] Iteration 4290, loss = 0.0129286
I0403 03:42:03.819553 23741 solver.cpp:244]     Train net output #0: loss = 0.0129285 (* 1 = 0.0129285 loss)
I0403 03:42:03.973686 23741 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 03:42:13.620182 23741 solver.cpp:228] Iteration 4303, loss = 0.00208326
I0403 03:42:13.620296 23741 solver.cpp:244]     Train net output #0: loss = 0.00208321 (* 1 = 0.00208321 loss)
I0403 03:42:13.851256 23741 sgd_solver.cpp:106] Iteration 4303, lr = 0.0005
I0403 03:42:23.262192 23741 solver.cpp:228] Iteration 4316, loss = 0.00307997
I0403 03:42:23.262507 23741 solver.cpp:244]     Train net output #0: loss = 0.00307991 (* 1 = 0.00307991 loss)
I0403 03:42:23.448910 23741 sgd_solver.cpp:106] Iteration 4316, lr = 0.0005
I0403 03:42:32.743419 23741 solver.cpp:228] Iteration 4329, loss = 0.00790808
I0403 03:42:32.743517 23741 solver.cpp:244]     Train net output #0: loss = 0.00790802 (* 1 = 0.00790802 loss)
I0403 03:42:32.896800 23741 sgd_solver.cpp:106] Iteration 4329, lr = 0.0005
I0403 03:42:42.214354 23741 solver.cpp:228] Iteration 4342, loss = 0.00599605
I0403 03:42:42.214457 23741 solver.cpp:244]     Train net output #0: loss = 0.00599599 (* 1 = 0.00599599 loss)
I0403 03:42:42.380827 23741 sgd_solver.cpp:106] Iteration 4342, lr = 0.0005
I0403 03:42:51.745503 23741 solver.cpp:228] Iteration 4355, loss = 0.0316833
I0403 03:42:51.745620 23741 solver.cpp:244]     Train net output #0: loss = 0.0316832 (* 1 = 0.0316832 loss)
I0403 03:42:51.939761 23741 sgd_solver.cpp:106] Iteration 4355, lr = 0.0005
I0403 03:43:01.209704 23741 solver.cpp:228] Iteration 4368, loss = 0.00332182
I0403 03:43:01.213701 23741 solver.cpp:244]     Train net output #0: loss = 0.00332177 (* 1 = 0.00332177 loss)
I0403 03:43:01.416342 23741 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:43:10.590323 23741 solver.cpp:228] Iteration 4381, loss = 0.0074292
I0403 03:43:10.590492 23741 solver.cpp:244]     Train net output #0: loss = 0.00742916 (* 1 = 0.00742916 loss)
I0403 03:43:10.756490 23741 sgd_solver.cpp:106] Iteration 4381, lr = 0.0005
I0403 03:43:20.283074 23741 solver.cpp:228] Iteration 4394, loss = 0.0134123
I0403 03:43:20.283185 23741 solver.cpp:244]     Train net output #0: loss = 0.0134122 (* 1 = 0.0134122 loss)
I0403 03:43:20.466136 23741 sgd_solver.cpp:106] Iteration 4394, lr = 0.0005
I0403 03:43:29.733597 23741 solver.cpp:228] Iteration 4407, loss = 0.00185992
I0403 03:43:29.733693 23741 solver.cpp:244]     Train net output #0: loss = 0.00185987 (* 1 = 0.00185987 loss)
I0403 03:43:29.915444 23741 sgd_solver.cpp:106] Iteration 4407, lr = 0.0005
I0403 03:43:39.212923 23741 solver.cpp:228] Iteration 4420, loss = 0.0064281
I0403 03:43:39.213277 23741 solver.cpp:244]     Train net output #0: loss = 0.00642806 (* 1 = 0.00642806 loss)
I0403 03:43:39.390161 23741 sgd_solver.cpp:106] Iteration 4420, lr = 0.0005
I0403 03:43:48.711103 23741 solver.cpp:228] Iteration 4433, loss = 0.00198778
I0403 03:43:48.711206 23741 solver.cpp:244]     Train net output #0: loss = 0.00198774 (* 1 = 0.00198774 loss)
I0403 03:43:48.931604 23741 sgd_solver.cpp:106] Iteration 4433, lr = 0.0005
I0403 03:43:58.169633 23741 solver.cpp:228] Iteration 4446, loss = 0.00525799
I0403 03:43:58.169741 23741 solver.cpp:244]     Train net output #0: loss = 0.00525795 (* 1 = 0.00525795 loss)
I0403 03:43:58.357265 23741 sgd_solver.cpp:106] Iteration 4446, lr = 0.0005
I0403 03:44:07.703603 23741 solver.cpp:228] Iteration 4459, loss = 0.0109374
I0403 03:44:07.703702 23741 solver.cpp:244]     Train net output #0: loss = 0.0109374 (* 1 = 0.0109374 loss)
I0403 03:44:07.878063 23741 sgd_solver.cpp:106] Iteration 4459, lr = 0.0005
I0403 03:44:17.276731 23741 solver.cpp:228] Iteration 4472, loss = 0.00428599
I0403 03:44:17.277076 23741 solver.cpp:244]     Train net output #0: loss = 0.00428595 (* 1 = 0.00428595 loss)
I0403 03:44:17.465596 23741 sgd_solver.cpp:106] Iteration 4472, lr = 0.0005
I0403 03:44:26.859835 23741 solver.cpp:228] Iteration 4485, loss = 0.0194097
I0403 03:44:26.859935 23741 solver.cpp:244]     Train net output #0: loss = 0.0194096 (* 1 = 0.0194096 loss)
I0403 03:44:27.017222 23741 sgd_solver.cpp:106] Iteration 4485, lr = 0.0005
I0403 03:44:36.454324 23741 solver.cpp:228] Iteration 4498, loss = 0.0520764
I0403 03:44:36.454423 23741 solver.cpp:244]     Train net output #0: loss = 0.0520764 (* 1 = 0.0520764 loss)
I0403 03:44:36.612313 23741 sgd_solver.cpp:106] Iteration 4498, lr = 0.0005
I0403 03:44:46.028038 23741 solver.cpp:228] Iteration 4511, loss = 0.000896623
I0403 03:44:46.028148 23741 solver.cpp:244]     Train net output #0: loss = 0.000896582 (* 1 = 0.000896582 loss)
I0403 03:44:46.217145 23741 sgd_solver.cpp:106] Iteration 4511, lr = 0.0005
I0403 03:44:55.620169 23741 solver.cpp:228] Iteration 4524, loss = 0.0122184
I0403 03:44:55.620512 23741 solver.cpp:244]     Train net output #0: loss = 0.0122184 (* 1 = 0.0122184 loss)
I0403 03:44:55.785854 23741 sgd_solver.cpp:106] Iteration 4524, lr = 0.0005
I0403 03:45:05.173022 23741 solver.cpp:228] Iteration 4537, loss = 0.00478547
I0403 03:45:05.173133 23741 solver.cpp:244]     Train net output #0: loss = 0.00478542 (* 1 = 0.00478542 loss)
I0403 03:45:05.373131 23741 sgd_solver.cpp:106] Iteration 4537, lr = 0.0005
I0403 03:45:06.092422 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4539.caffemodel
I0403 03:45:08.887006 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4539.solverstate
I0403 03:45:10.667141 23741 solver.cpp:337] Iteration 4539, Testing net (#0)
I0403 03:46:12.944371 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966219
I0403 03:46:12.944720 23741 solver.cpp:404]     Test net output #1: loss = 0.120858 (* 1 = 0.120858 loss)
I0403 03:46:21.477267 23741 solver.cpp:228] Iteration 4550, loss = 0.00487009
I0403 03:46:21.477375 23741 solver.cpp:244]     Train net output #0: loss = 0.00487005 (* 1 = 0.00487005 loss)
I0403 03:46:21.675261 23741 sgd_solver.cpp:106] Iteration 4550, lr = 0.0005
I0403 03:46:30.989476 23741 solver.cpp:228] Iteration 4563, loss = 0.013273
I0403 03:46:30.989574 23741 solver.cpp:244]     Train net output #0: loss = 0.013273 (* 1 = 0.013273 loss)
I0403 03:46:31.166471 23741 sgd_solver.cpp:106] Iteration 4563, lr = 0.0005
I0403 03:46:40.604089 23741 solver.cpp:228] Iteration 4576, loss = 0.00113931
I0403 03:46:40.604189 23741 solver.cpp:244]     Train net output #0: loss = 0.00113927 (* 1 = 0.00113927 loss)
I0403 03:46:40.779260 23741 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 03:46:50.072994 23741 solver.cpp:228] Iteration 4589, loss = 0.0070625
I0403 03:46:50.073336 23741 solver.cpp:244]     Train net output #0: loss = 0.00706245 (* 1 = 0.00706245 loss)
I0403 03:46:50.256847 23741 sgd_solver.cpp:106] Iteration 4589, lr = 0.0005
I0403 03:46:59.578027 23741 solver.cpp:228] Iteration 4602, loss = 0.00311697
I0403 03:46:59.578135 23741 solver.cpp:244]     Train net output #0: loss = 0.00311692 (* 1 = 0.00311692 loss)
I0403 03:46:59.772660 23741 sgd_solver.cpp:106] Iteration 4602, lr = 0.0005
I0403 03:47:09.023278 23741 solver.cpp:228] Iteration 4615, loss = 0.00492042
I0403 03:47:09.023376 23741 solver.cpp:244]     Train net output #0: loss = 0.00492037 (* 1 = 0.00492037 loss)
I0403 03:47:09.198878 23741 sgd_solver.cpp:106] Iteration 4615, lr = 0.0005
I0403 03:47:18.541755 23741 solver.cpp:228] Iteration 4628, loss = 0.00242198
I0403 03:47:18.541862 23741 solver.cpp:244]     Train net output #0: loss = 0.00242193 (* 1 = 0.00242193 loss)
I0403 03:47:18.724853 23741 sgd_solver.cpp:106] Iteration 4628, lr = 0.0005
I0403 03:47:28.053436 23741 solver.cpp:228] Iteration 4641, loss = 0.0012055
I0403 03:47:28.053798 23741 solver.cpp:244]     Train net output #0: loss = 0.00120544 (* 1 = 0.00120544 loss)
I0403 03:47:28.248383 23741 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 03:47:37.574196 23741 solver.cpp:228] Iteration 4654, loss = 0.00234935
I0403 03:47:37.574306 23741 solver.cpp:244]     Train net output #0: loss = 0.00234929 (* 1 = 0.00234929 loss)
I0403 03:47:37.757290 23741 sgd_solver.cpp:106] Iteration 4654, lr = 0.0005
I0403 03:47:47.106931 23741 solver.cpp:228] Iteration 4667, loss = 0.00870954
I0403 03:47:47.107025 23741 solver.cpp:244]     Train net output #0: loss = 0.00870948 (* 1 = 0.00870948 loss)
I0403 03:47:47.274648 23741 sgd_solver.cpp:106] Iteration 4667, lr = 0.0005
I0403 03:47:56.618890 23741 solver.cpp:228] Iteration 4680, loss = 0.00222202
I0403 03:47:56.618994 23741 solver.cpp:244]     Train net output #0: loss = 0.00222196 (* 1 = 0.00222196 loss)
I0403 03:47:56.794041 23741 sgd_solver.cpp:106] Iteration 4680, lr = 0.0005
I0403 03:48:05.978273 23741 solver.cpp:228] Iteration 4693, loss = 0.000983397
I0403 03:48:05.978595 23741 solver.cpp:244]     Train net output #0: loss = 0.000983338 (* 1 = 0.000983338 loss)
I0403 03:48:06.171444 23741 sgd_solver.cpp:106] Iteration 4693, lr = 0.0005
I0403 03:48:15.593498 23741 solver.cpp:228] Iteration 4706, loss = 0.00332616
I0403 03:48:15.593608 23741 solver.cpp:244]     Train net output #0: loss = 0.00332611 (* 1 = 0.00332611 loss)
I0403 03:48:15.796423 23741 sgd_solver.cpp:106] Iteration 4706, lr = 0.0005
I0403 03:48:25.068888 23741 solver.cpp:228] Iteration 4719, loss = 0.00180924
I0403 03:48:25.068996 23741 solver.cpp:244]     Train net output #0: loss = 0.00180918 (* 1 = 0.00180918 loss)
I0403 03:48:25.292620 23741 sgd_solver.cpp:106] Iteration 4719, lr = 0.0005
I0403 03:48:34.673823 23741 solver.cpp:228] Iteration 4732, loss = 0.00364683
I0403 03:48:34.673928 23741 solver.cpp:244]     Train net output #0: loss = 0.00364677 (* 1 = 0.00364677 loss)
I0403 03:48:34.838277 23741 sgd_solver.cpp:106] Iteration 4732, lr = 0.0005
I0403 03:48:44.091634 23741 solver.cpp:228] Iteration 4745, loss = 0.0172884
I0403 03:48:44.091980 23741 solver.cpp:244]     Train net output #0: loss = 0.0172884 (* 1 = 0.0172884 loss)
I0403 03:48:44.288966 23741 sgd_solver.cpp:106] Iteration 4745, lr = 0.0005
I0403 03:48:53.507714 23741 solver.cpp:228] Iteration 4758, loss = 0.00370884
I0403 03:48:53.507822 23741 solver.cpp:244]     Train net output #0: loss = 0.00370878 (* 1 = 0.00370878 loss)
I0403 03:48:53.762243 23741 sgd_solver.cpp:106] Iteration 4758, lr = 0.0005
I0403 03:49:03.044278 23741 solver.cpp:228] Iteration 4771, loss = 0.00835126
I0403 03:49:03.044387 23741 solver.cpp:244]     Train net output #0: loss = 0.0083512 (* 1 = 0.0083512 loss)
I0403 03:49:03.234299 23741 sgd_solver.cpp:106] Iteration 4771, lr = 0.0005
I0403 03:49:12.558140 23741 solver.cpp:228] Iteration 4784, loss = 0.0415187
I0403 03:49:12.558253 23741 solver.cpp:244]     Train net output #0: loss = 0.0415187 (* 1 = 0.0415187 loss)
I0403 03:49:12.748234 23741 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 03:49:22.111575 23741 solver.cpp:228] Iteration 4797, loss = 0.0235097
I0403 03:49:22.111948 23741 solver.cpp:244]     Train net output #0: loss = 0.0235096 (* 1 = 0.0235096 loss)
I0403 03:49:22.261020 23741 sgd_solver.cpp:106] Iteration 4797, lr = 0.0005
I0403 03:49:28.195015 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4806.caffemodel
I0403 03:49:30.961645 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_4806.solverstate
I0403 03:49:32.852279 23741 solver.cpp:337] Iteration 4806, Testing net (#0)
I0403 03:50:35.140058 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965019
I0403 03:50:35.140403 23741 solver.cpp:404]     Test net output #1: loss = 0.125347 (* 1 = 0.125347 loss)
I0403 03:50:38.566820 23741 solver.cpp:228] Iteration 4810, loss = 0.00296714
I0403 03:50:38.566927 23741 solver.cpp:244]     Train net output #0: loss = 0.00296708 (* 1 = 0.00296708 loss)
I0403 03:50:38.765708 23741 sgd_solver.cpp:106] Iteration 4810, lr = 0.0005
I0403 03:50:48.165758 23741 solver.cpp:228] Iteration 4823, loss = 0.00614283
I0403 03:50:48.165868 23741 solver.cpp:244]     Train net output #0: loss = 0.00614277 (* 1 = 0.00614277 loss)
I0403 03:50:48.370942 23741 sgd_solver.cpp:106] Iteration 4823, lr = 0.0005
I0403 03:50:57.598119 23741 solver.cpp:228] Iteration 4836, loss = 0.00354841
I0403 03:50:57.598234 23741 solver.cpp:244]     Train net output #0: loss = 0.00354835 (* 1 = 0.00354835 loss)
I0403 03:50:57.794347 23741 sgd_solver.cpp:106] Iteration 4836, lr = 0.0005
I0403 03:51:07.015125 23741 solver.cpp:228] Iteration 4849, loss = 0.00697809
I0403 03:51:07.015440 23741 solver.cpp:244]     Train net output #0: loss = 0.00697803 (* 1 = 0.00697803 loss)
I0403 03:51:07.226492 23741 sgd_solver.cpp:106] Iteration 4849, lr = 0.0005
I0403 03:51:16.501565 23741 solver.cpp:228] Iteration 4862, loss = 0.00976071
I0403 03:51:16.501667 23741 solver.cpp:244]     Train net output #0: loss = 0.00976065 (* 1 = 0.00976065 loss)
I0403 03:51:16.656908 23741 sgd_solver.cpp:106] Iteration 4862, lr = 0.0005
I0403 03:51:26.064601 23741 solver.cpp:228] Iteration 4875, loss = 0.0132634
I0403 03:51:26.064713 23741 solver.cpp:244]     Train net output #0: loss = 0.0132634 (* 1 = 0.0132634 loss)
I0403 03:51:26.255630 23741 sgd_solver.cpp:106] Iteration 4875, lr = 0.0005
I0403 03:51:35.497983 23741 solver.cpp:228] Iteration 4888, loss = 0.00903292
I0403 03:51:35.498091 23741 solver.cpp:244]     Train net output #0: loss = 0.00903286 (* 1 = 0.00903286 loss)
I0403 03:51:35.688601 23741 sgd_solver.cpp:106] Iteration 4888, lr = 0.0005
I0403 03:51:45.038213 23741 solver.cpp:228] Iteration 4901, loss = 0.00113809
I0403 03:51:45.038504 23741 solver.cpp:244]     Train net output #0: loss = 0.00113803 (* 1 = 0.00113803 loss)
I0403 03:51:45.233315 23741 sgd_solver.cpp:106] Iteration 4901, lr = 0.0005
I0403 03:51:54.555078 23741 solver.cpp:228] Iteration 4914, loss = 0.00295575
I0403 03:51:54.555193 23741 solver.cpp:244]     Train net output #0: loss = 0.0029557 (* 1 = 0.0029557 loss)
I0403 03:51:54.744493 23741 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 03:52:03.984786 23741 solver.cpp:228] Iteration 4927, loss = 0.00828138
I0403 03:52:03.984894 23741 solver.cpp:244]     Train net output #0: loss = 0.00828132 (* 1 = 0.00828132 loss)
I0403 03:52:04.169574 23741 sgd_solver.cpp:106] Iteration 4927, lr = 0.0005
I0403 03:52:13.405048 23741 solver.cpp:228] Iteration 4940, loss = 0.00454692
I0403 03:52:13.405149 23741 solver.cpp:244]     Train net output #0: loss = 0.00454687 (* 1 = 0.00454687 loss)
I0403 03:52:13.560812 23741 sgd_solver.cpp:106] Iteration 4940, lr = 0.0005
I0403 03:52:22.940105 23741 solver.cpp:228] Iteration 4953, loss = 0.00926184
I0403 03:52:22.940433 23741 solver.cpp:244]     Train net output #0: loss = 0.00926178 (* 1 = 0.00926178 loss)
I0403 03:52:23.182344 23741 sgd_solver.cpp:106] Iteration 4953, lr = 0.0005
I0403 03:52:32.356411 23741 solver.cpp:228] Iteration 4966, loss = 0.00322281
I0403 03:52:32.356528 23741 solver.cpp:244]     Train net output #0: loss = 0.00322275 (* 1 = 0.00322275 loss)
I0403 03:52:32.541391 23741 sgd_solver.cpp:106] Iteration 4966, lr = 0.0005
I0403 03:52:41.960170 23741 solver.cpp:228] Iteration 4979, loss = 0.00510501
I0403 03:52:41.960281 23741 solver.cpp:244]     Train net output #0: loss = 0.00510496 (* 1 = 0.00510496 loss)
I0403 03:52:42.183874 23741 sgd_solver.cpp:106] Iteration 4979, lr = 0.0005
I0403 03:52:51.530474 23741 solver.cpp:228] Iteration 4992, loss = 0.0127347
I0403 03:52:51.530588 23741 solver.cpp:244]     Train net output #0: loss = 0.0127347 (* 1 = 0.0127347 loss)
I0403 03:52:51.741772 23741 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 03:53:01.118608 23741 solver.cpp:228] Iteration 5005, loss = 0.00132353
I0403 03:53:01.118940 23741 solver.cpp:244]     Train net output #0: loss = 0.00132348 (* 1 = 0.00132348 loss)
I0403 03:53:01.292387 23741 sgd_solver.cpp:106] Iteration 5005, lr = 0.0005
I0403 03:53:10.787847 23741 solver.cpp:228] Iteration 5018, loss = 0.00268373
I0403 03:53:10.787950 23741 solver.cpp:244]     Train net output #0: loss = 0.00268367 (* 1 = 0.00268367 loss)
I0403 03:53:10.940975 23741 sgd_solver.cpp:106] Iteration 5018, lr = 0.0005
I0403 03:53:20.674314 23741 solver.cpp:228] Iteration 5031, loss = 0.00380834
I0403 03:53:20.674424 23741 solver.cpp:244]     Train net output #0: loss = 0.00380829 (* 1 = 0.00380829 loss)
I0403 03:53:20.859424 23741 sgd_solver.cpp:106] Iteration 5031, lr = 0.0005
I0403 03:53:30.115608 23741 solver.cpp:228] Iteration 5044, loss = 0.0131855
I0403 03:53:30.115720 23741 solver.cpp:244]     Train net output #0: loss = 0.0131854 (* 1 = 0.0131854 loss)
I0403 03:53:30.304499 23741 sgd_solver.cpp:106] Iteration 5044, lr = 0.0005
I0403 03:53:39.718821 23741 solver.cpp:228] Iteration 5057, loss = 0.00252197
I0403 03:53:39.719147 23741 solver.cpp:244]     Train net output #0: loss = 0.00252191 (* 1 = 0.00252191 loss)
I0403 03:53:39.901935 23741 sgd_solver.cpp:106] Iteration 5057, lr = 0.0005
I0403 03:53:49.406213 23741 solver.cpp:228] Iteration 5070, loss = 0.0087875
I0403 03:53:49.406311 23741 solver.cpp:244]     Train net output #0: loss = 0.00878744 (* 1 = 0.00878744 loss)
I0403 03:53:49.574440 23741 sgd_solver.cpp:106] Iteration 5070, lr = 0.0005
I0403 03:53:51.045323 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5073.caffemodel
I0403 03:53:53.725170 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5073.solverstate
I0403 03:53:55.520807 23741 solver.cpp:337] Iteration 5073, Testing net (#0)
I0403 03:54:57.802404 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965673
I0403 03:54:57.802691 23741 solver.cpp:404]     Test net output #1: loss = 0.123171 (* 1 = 0.123171 loss)
I0403 03:55:05.783018 23741 solver.cpp:228] Iteration 5083, loss = 0.00819733
I0403 03:55:05.789831 23741 solver.cpp:244]     Train net output #0: loss = 0.00819727 (* 1 = 0.00819727 loss)
I0403 03:55:05.944145 23741 sgd_solver.cpp:106] Iteration 5083, lr = 0.0005
I0403 03:55:15.440423 23741 solver.cpp:228] Iteration 5096, loss = 0.0340929
I0403 03:55:15.440531 23741 solver.cpp:244]     Train net output #0: loss = 0.0340929 (* 1 = 0.0340929 loss)
I0403 03:55:15.660552 23741 sgd_solver.cpp:106] Iteration 5096, lr = 0.0005
I0403 03:55:25.009630 23741 solver.cpp:228] Iteration 5109, loss = 0.00220828
I0403 03:55:25.014312 23741 solver.cpp:244]     Train net output #0: loss = 0.00220822 (* 1 = 0.00220822 loss)
I0403 03:55:25.211436 23741 sgd_solver.cpp:106] Iteration 5109, lr = 0.0005
I0403 03:55:34.643859 23741 solver.cpp:228] Iteration 5122, loss = 0.00449088
I0403 03:55:34.650724 23741 solver.cpp:244]     Train net output #0: loss = 0.00449082 (* 1 = 0.00449082 loss)
I0403 03:55:34.820528 23741 sgd_solver.cpp:106] Iteration 5122, lr = 0.0005
I0403 03:55:44.082638 23741 solver.cpp:228] Iteration 5135, loss = 0.00155232
I0403 03:55:44.082737 23741 solver.cpp:244]     Train net output #0: loss = 0.00155225 (* 1 = 0.00155225 loss)
I0403 03:55:44.260567 23741 sgd_solver.cpp:106] Iteration 5135, lr = 0.0005
I0403 03:55:53.613993 23741 solver.cpp:228] Iteration 5148, loss = 0.010448
I0403 03:55:53.614104 23741 solver.cpp:244]     Train net output #0: loss = 0.010448 (* 1 = 0.010448 loss)
I0403 03:55:53.808513 23741 sgd_solver.cpp:106] Iteration 5148, lr = 0.0005
I0403 03:56:03.067215 23741 solver.cpp:228] Iteration 5161, loss = 0.00145965
I0403 03:56:03.067315 23741 solver.cpp:244]     Train net output #0: loss = 0.00145959 (* 1 = 0.00145959 loss)
I0403 03:56:03.246793 23741 sgd_solver.cpp:106] Iteration 5161, lr = 0.0005
I0403 03:56:12.987186 23741 solver.cpp:228] Iteration 5174, loss = 0.00993938
I0403 03:56:12.987545 23741 solver.cpp:244]     Train net output #0: loss = 0.00993931 (* 1 = 0.00993931 loss)
I0403 03:56:13.181465 23741 sgd_solver.cpp:106] Iteration 5174, lr = 0.0005
I0403 03:56:22.639721 23741 solver.cpp:228] Iteration 5187, loss = 0.00213659
I0403 03:56:22.639832 23741 solver.cpp:244]     Train net output #0: loss = 0.00213653 (* 1 = 0.00213653 loss)
I0403 03:56:22.825544 23741 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 03:56:32.195471 23741 solver.cpp:228] Iteration 5200, loss = 0.0126215
I0403 03:56:32.195579 23741 solver.cpp:244]     Train net output #0: loss = 0.0126214 (* 1 = 0.0126214 loss)
I0403 03:56:32.390214 23741 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 03:56:41.704560 23741 solver.cpp:228] Iteration 5213, loss = 0.00662592
I0403 03:56:41.704668 23741 solver.cpp:244]     Train net output #0: loss = 0.00662586 (* 1 = 0.00662586 loss)
I0403 03:56:41.918929 23741 sgd_solver.cpp:106] Iteration 5213, lr = 0.0005
I0403 03:56:51.088721 23741 solver.cpp:228] Iteration 5226, loss = 0.00924713
I0403 03:56:51.089047 23741 solver.cpp:244]     Train net output #0: loss = 0.00924707 (* 1 = 0.00924707 loss)
I0403 03:56:51.268751 23741 sgd_solver.cpp:106] Iteration 5226, lr = 0.0005
I0403 03:57:00.413396 23741 solver.cpp:228] Iteration 5239, loss = 0.0177656
I0403 03:57:00.413504 23741 solver.cpp:244]     Train net output #0: loss = 0.0177656 (* 1 = 0.0177656 loss)
I0403 03:57:00.692755 23741 sgd_solver.cpp:106] Iteration 5239, lr = 0.0005
I0403 03:57:09.945574 23741 solver.cpp:228] Iteration 5252, loss = 0.0549896
I0403 03:57:09.945683 23741 solver.cpp:244]     Train net output #0: loss = 0.0549895 (* 1 = 0.0549895 loss)
I0403 03:57:10.136226 23741 sgd_solver.cpp:106] Iteration 5252, lr = 0.0005
I0403 03:57:19.481021 23741 solver.cpp:228] Iteration 5265, loss = 0.00515932
I0403 03:57:19.481128 23741 solver.cpp:244]     Train net output #0: loss = 0.00515927 (* 1 = 0.00515927 loss)
I0403 03:57:19.672638 23741 sgd_solver.cpp:106] Iteration 5265, lr = 0.0005
I0403 03:57:28.933939 23741 solver.cpp:228] Iteration 5278, loss = 0.000751821
I0403 03:57:28.934274 23741 solver.cpp:244]     Train net output #0: loss = 0.000751768 (* 1 = 0.000751768 loss)
I0403 03:57:29.135583 23741 sgd_solver.cpp:106] Iteration 5278, lr = 0.0005
I0403 03:57:38.496893 23741 solver.cpp:228] Iteration 5291, loss = 0.00102112
I0403 03:57:38.496994 23741 solver.cpp:244]     Train net output #0: loss = 0.00102107 (* 1 = 0.00102107 loss)
I0403 03:57:38.678025 23741 sgd_solver.cpp:106] Iteration 5291, lr = 0.0005
I0403 03:57:47.958638 23741 solver.cpp:228] Iteration 5304, loss = 0.00486487
I0403 03:57:47.958746 23741 solver.cpp:244]     Train net output #0: loss = 0.00486481 (* 1 = 0.00486481 loss)
I0403 03:57:48.155257 23741 sgd_solver.cpp:106] Iteration 5304, lr = 0.0005
I0403 03:57:57.459540 23741 solver.cpp:228] Iteration 5317, loss = 0.00462582
I0403 03:57:57.459645 23741 solver.cpp:244]     Train net output #0: loss = 0.00462577 (* 1 = 0.00462577 loss)
I0403 03:57:57.641440 23741 sgd_solver.cpp:106] Iteration 5317, lr = 0.0005
I0403 03:58:06.917086 23741 solver.cpp:228] Iteration 5330, loss = 0.0063809
I0403 03:58:06.917444 23741 solver.cpp:244]     Train net output #0: loss = 0.00638085 (* 1 = 0.00638085 loss)
I0403 03:58:07.114977 23741 sgd_solver.cpp:106] Iteration 5330, lr = 0.0005
I0403 03:58:13.647176 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5340.caffemodel
I0403 03:58:16.395552 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5340.solverstate
I0403 03:58:18.218152 23741 solver.cpp:337] Iteration 5340, Testing net (#0)
I0403 03:59:20.507601 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966328
I0403 03:59:20.508096 23741 solver.cpp:404]     Test net output #1: loss = 0.121422 (* 1 = 0.121422 loss)
I0403 03:59:23.198637 23741 solver.cpp:228] Iteration 5343, loss = 0.00233215
I0403 03:59:23.198734 23741 solver.cpp:244]     Train net output #0: loss = 0.0023321 (* 1 = 0.0023321 loss)
I0403 03:59:23.370923 23741 sgd_solver.cpp:106] Iteration 5343, lr = 0.0005
I0403 03:59:32.753484 23741 solver.cpp:228] Iteration 5356, loss = 0.00704865
I0403 03:59:32.753582 23741 solver.cpp:244]     Train net output #0: loss = 0.00704859 (* 1 = 0.00704859 loss)
I0403 03:59:32.926616 23741 sgd_solver.cpp:106] Iteration 5356, lr = 5e-05
I0403 03:59:42.287153 23741 solver.cpp:228] Iteration 5369, loss = 0.00655412
I0403 03:59:42.287252 23741 solver.cpp:244]     Train net output #0: loss = 0.00655406 (* 1 = 0.00655406 loss)
I0403 03:59:42.487617 23741 sgd_solver.cpp:106] Iteration 5369, lr = 5e-05
I0403 03:59:51.830807 23741 solver.cpp:228] Iteration 5382, loss = 0.00114199
I0403 03:59:51.831135 23741 solver.cpp:244]     Train net output #0: loss = 0.00114194 (* 1 = 0.00114194 loss)
I0403 03:59:52.011327 23741 sgd_solver.cpp:106] Iteration 5382, lr = 5e-05
I0403 04:00:01.447027 23741 solver.cpp:228] Iteration 5395, loss = 0.00458902
I0403 04:00:01.447140 23741 solver.cpp:244]     Train net output #0: loss = 0.00458897 (* 1 = 0.00458897 loss)
I0403 04:00:01.655025 23741 sgd_solver.cpp:106] Iteration 5395, lr = 5e-05
I0403 04:00:10.906539 23741 solver.cpp:228] Iteration 5408, loss = 0.00192742
I0403 04:00:10.906652 23741 solver.cpp:244]     Train net output #0: loss = 0.00192737 (* 1 = 0.00192737 loss)
I0403 04:00:11.097342 23741 sgd_solver.cpp:106] Iteration 5408, lr = 5e-05
I0403 04:00:20.406100 23741 solver.cpp:228] Iteration 5421, loss = 0.0064891
I0403 04:00:20.406195 23741 solver.cpp:244]     Train net output #0: loss = 0.00648905 (* 1 = 0.00648905 loss)
I0403 04:00:20.591480 23741 sgd_solver.cpp:106] Iteration 5421, lr = 5e-05
I0403 04:00:29.953397 23741 solver.cpp:228] Iteration 5434, loss = 0.00205923
I0403 04:00:29.953711 23741 solver.cpp:244]     Train net output #0: loss = 0.00205918 (* 1 = 0.00205918 loss)
I0403 04:00:30.139449 23741 sgd_solver.cpp:106] Iteration 5434, lr = 5e-05
I0403 04:00:39.435246 23741 solver.cpp:228] Iteration 5447, loss = 0.00271253
I0403 04:00:39.435340 23741 solver.cpp:244]     Train net output #0: loss = 0.00271248 (* 1 = 0.00271248 loss)
I0403 04:00:39.617311 23741 sgd_solver.cpp:106] Iteration 5447, lr = 5e-05
I0403 04:00:48.981854 23741 solver.cpp:228] Iteration 5460, loss = 0.00277797
I0403 04:00:48.981967 23741 solver.cpp:244]     Train net output #0: loss = 0.00277792 (* 1 = 0.00277792 loss)
I0403 04:00:49.175436 23741 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 04:00:58.624516 23741 solver.cpp:228] Iteration 5473, loss = 0.00121063
I0403 04:00:58.624617 23741 solver.cpp:244]     Train net output #0: loss = 0.00121058 (* 1 = 0.00121058 loss)
I0403 04:00:58.795022 23741 sgd_solver.cpp:106] Iteration 5473, lr = 5e-05
I0403 04:01:08.185613 23741 solver.cpp:228] Iteration 5486, loss = 0.0242012
I0403 04:01:08.185940 23741 solver.cpp:244]     Train net output #0: loss = 0.0242011 (* 1 = 0.0242011 loss)
I0403 04:01:08.366603 23741 sgd_solver.cpp:106] Iteration 5486, lr = 5e-05
I0403 04:01:17.777575 23741 solver.cpp:228] Iteration 5499, loss = 0.00106941
I0403 04:01:17.777684 23741 solver.cpp:244]     Train net output #0: loss = 0.00106935 (* 1 = 0.00106935 loss)
I0403 04:01:17.976662 23741 sgd_solver.cpp:106] Iteration 5499, lr = 5e-05
I0403 04:01:27.337288 23741 solver.cpp:228] Iteration 5512, loss = 0.00111503
I0403 04:01:27.337401 23741 solver.cpp:244]     Train net output #0: loss = 0.00111498 (* 1 = 0.00111498 loss)
I0403 04:01:27.531635 23741 sgd_solver.cpp:106] Iteration 5512, lr = 5e-05
I0403 04:01:36.904585 23741 solver.cpp:228] Iteration 5525, loss = 0.000822296
I0403 04:01:36.904702 23741 solver.cpp:244]     Train net output #0: loss = 0.000822243 (* 1 = 0.000822243 loss)
I0403 04:01:37.129354 23741 sgd_solver.cpp:106] Iteration 5525, lr = 5e-05
I0403 04:01:46.412690 23741 solver.cpp:228] Iteration 5538, loss = 0.00153877
I0403 04:01:46.413079 23741 solver.cpp:244]     Train net output #0: loss = 0.00153872 (* 1 = 0.00153872 loss)
I0403 04:01:46.661384 23741 sgd_solver.cpp:106] Iteration 5538, lr = 5e-05
I0403 04:01:56.093418 23741 solver.cpp:228] Iteration 5551, loss = 0.00661067
I0403 04:01:56.093528 23741 solver.cpp:244]     Train net output #0: loss = 0.00661062 (* 1 = 0.00661062 loss)
I0403 04:01:56.302103 23741 sgd_solver.cpp:106] Iteration 5551, lr = 5e-05
I0403 04:02:05.672425 23741 solver.cpp:228] Iteration 5564, loss = 0.00425925
I0403 04:02:05.672534 23741 solver.cpp:244]     Train net output #0: loss = 0.0042592 (* 1 = 0.0042592 loss)
I0403 04:02:05.855708 23741 sgd_solver.cpp:106] Iteration 5564, lr = 5e-05
I0403 04:02:15.179246 23741 solver.cpp:228] Iteration 5577, loss = 0.00031807
I0403 04:02:15.179361 23741 solver.cpp:244]     Train net output #0: loss = 0.000318018 (* 1 = 0.000318018 loss)
I0403 04:02:15.377113 23741 sgd_solver.cpp:106] Iteration 5577, lr = 5e-05
I0403 04:02:24.704932 23741 solver.cpp:228] Iteration 5590, loss = 0.00636431
I0403 04:02:24.705200 23741 solver.cpp:244]     Train net output #0: loss = 0.00636426 (* 1 = 0.00636426 loss)
I0403 04:02:24.856806 23741 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 04:02:34.200072 23741 solver.cpp:228] Iteration 5603, loss = 0.0131751
I0403 04:02:34.200170 23741 solver.cpp:244]     Train net output #0: loss = 0.013175 (* 1 = 0.013175 loss)
I0403 04:02:34.379542 23741 sgd_solver.cpp:106] Iteration 5603, lr = 5e-05
I0403 04:02:36.530822 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5607.caffemodel
I0403 04:02:39.317605 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5607.solverstate
I0403 04:02:41.220338 23741 solver.cpp:337] Iteration 5607, Testing net (#0)
I0403 04:03:43.517515 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965964
I0403 04:03:43.517853 23741 solver.cpp:404]     Test net output #1: loss = 0.121021 (* 1 = 0.121021 loss)
I0403 04:03:50.626921 23741 solver.cpp:228] Iteration 5616, loss = 0.00149287
I0403 04:03:50.627033 23741 solver.cpp:244]     Train net output #0: loss = 0.00149281 (* 1 = 0.00149281 loss)
I0403 04:03:50.834868 23741 sgd_solver.cpp:106] Iteration 5616, lr = 5e-05
I0403 04:04:00.089620 23741 solver.cpp:228] Iteration 5629, loss = 0.00190489
I0403 04:04:00.089727 23741 solver.cpp:244]     Train net output #0: loss = 0.00190484 (* 1 = 0.00190484 loss)
I0403 04:04:00.275260 23741 sgd_solver.cpp:106] Iteration 5629, lr = 5e-05
I0403 04:04:09.426179 23741 solver.cpp:228] Iteration 5642, loss = 0.00197799
I0403 04:04:09.426303 23741 solver.cpp:244]     Train net output #0: loss = 0.00197793 (* 1 = 0.00197793 loss)
I0403 04:04:09.617678 23741 sgd_solver.cpp:106] Iteration 5642, lr = 5e-05
I0403 04:04:19.015730 23741 solver.cpp:228] Iteration 5655, loss = 0.0336858
I0403 04:04:19.016053 23741 solver.cpp:244]     Train net output #0: loss = 0.0336857 (* 1 = 0.0336857 loss)
I0403 04:04:19.237893 23741 sgd_solver.cpp:106] Iteration 5655, lr = 5e-05
I0403 04:04:28.510040 23741 solver.cpp:228] Iteration 5668, loss = 0.0567459
I0403 04:04:28.510139 23741 solver.cpp:244]     Train net output #0: loss = 0.0567458 (* 1 = 0.0567458 loss)
I0403 04:04:28.673450 23741 sgd_solver.cpp:106] Iteration 5668, lr = 5e-05
I0403 04:04:38.065094 23741 solver.cpp:228] Iteration 5681, loss = 0.00882439
I0403 04:04:38.065208 23741 solver.cpp:244]     Train net output #0: loss = 0.00882434 (* 1 = 0.00882434 loss)
I0403 04:04:38.254498 23741 sgd_solver.cpp:106] Iteration 5681, lr = 5e-05
I0403 04:04:47.607798 23741 solver.cpp:228] Iteration 5694, loss = 0.00103488
I0403 04:04:47.607908 23741 solver.cpp:244]     Train net output #0: loss = 0.00103483 (* 1 = 0.00103483 loss)
I0403 04:04:47.811060 23741 sgd_solver.cpp:106] Iteration 5694, lr = 5e-05
I0403 04:04:57.010083 23741 solver.cpp:228] Iteration 5707, loss = 0.00162671
I0403 04:04:57.017328 23741 solver.cpp:244]     Train net output #0: loss = 0.00162666 (* 1 = 0.00162666 loss)
I0403 04:04:57.193297 23741 sgd_solver.cpp:106] Iteration 5707, lr = 5e-05
I0403 04:05:06.578058 23741 solver.cpp:228] Iteration 5720, loss = 0.00734027
I0403 04:05:06.578167 23741 solver.cpp:244]     Train net output #0: loss = 0.00734022 (* 1 = 0.00734022 loss)
I0403 04:05:06.769583 23741 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 04:05:16.045398 23741 solver.cpp:228] Iteration 5733, loss = 0.00312035
I0403 04:05:16.045509 23741 solver.cpp:244]     Train net output #0: loss = 0.0031203 (* 1 = 0.0031203 loss)
I0403 04:05:16.228137 23741 sgd_solver.cpp:106] Iteration 5733, lr = 5e-05
I0403 04:05:25.602916 23741 solver.cpp:228] Iteration 5746, loss = 0.00353124
I0403 04:05:25.603029 23741 solver.cpp:244]     Train net output #0: loss = 0.00353119 (* 1 = 0.00353119 loss)
I0403 04:05:25.812571 23741 sgd_solver.cpp:106] Iteration 5746, lr = 5e-05
I0403 04:05:35.184859 23741 solver.cpp:228] Iteration 5759, loss = 0.0195997
I0403 04:05:35.185194 23741 solver.cpp:244]     Train net output #0: loss = 0.0195996 (* 1 = 0.0195996 loss)
I0403 04:05:35.379210 23741 sgd_solver.cpp:106] Iteration 5759, lr = 5e-05
I0403 04:05:44.608691 23741 solver.cpp:228] Iteration 5772, loss = 0.000858878
I0403 04:05:44.608800 23741 solver.cpp:244]     Train net output #0: loss = 0.000858831 (* 1 = 0.000858831 loss)
I0403 04:05:44.794523 23741 sgd_solver.cpp:106] Iteration 5772, lr = 5e-05
I0403 04:05:54.048899 23741 solver.cpp:228] Iteration 5785, loss = 0.012573
I0403 04:05:54.049005 23741 solver.cpp:244]     Train net output #0: loss = 0.012573 (* 1 = 0.012573 loss)
I0403 04:05:54.234532 23741 sgd_solver.cpp:106] Iteration 5785, lr = 5e-05
I0403 04:06:03.526854 23741 solver.cpp:228] Iteration 5798, loss = 0.000831718
I0403 04:06:03.526960 23741 solver.cpp:244]     Train net output #0: loss = 0.000831673 (* 1 = 0.000831673 loss)
I0403 04:06:03.724736 23741 sgd_solver.cpp:106] Iteration 5798, lr = 5e-05
I0403 04:06:13.192723 23741 solver.cpp:228] Iteration 5811, loss = 0.00121561
I0403 04:06:13.193045 23741 solver.cpp:244]     Train net output #0: loss = 0.00121557 (* 1 = 0.00121557 loss)
I0403 04:06:13.377804 23741 sgd_solver.cpp:106] Iteration 5811, lr = 5e-05
I0403 04:06:22.630761 23741 solver.cpp:228] Iteration 5824, loss = 0.00256111
I0403 04:06:22.630867 23741 solver.cpp:244]     Train net output #0: loss = 0.00256107 (* 1 = 0.00256107 loss)
I0403 04:06:22.810214 23741 sgd_solver.cpp:106] Iteration 5824, lr = 5e-05
I0403 04:06:32.032980 23741 solver.cpp:228] Iteration 5837, loss = 0.00167896
I0403 04:06:32.033088 23741 solver.cpp:244]     Train net output #0: loss = 0.00167891 (* 1 = 0.00167891 loss)
I0403 04:06:32.236088 23741 sgd_solver.cpp:106] Iteration 5837, lr = 5e-05
I0403 04:06:41.578594 23741 solver.cpp:228] Iteration 5850, loss = 0.00108934
I0403 04:06:41.578697 23741 solver.cpp:244]     Train net output #0: loss = 0.0010893 (* 1 = 0.0010893 loss)
I0403 04:06:41.759225 23741 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 04:06:51.024896 23741 solver.cpp:228] Iteration 5863, loss = 0.00221384
I0403 04:06:51.025257 23741 solver.cpp:244]     Train net output #0: loss = 0.0022138 (* 1 = 0.0022138 loss)
I0403 04:06:51.191238 23741 sgd_solver.cpp:106] Iteration 5863, lr = 5e-05
I0403 04:06:58.490150 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5874.caffemodel
I0403 04:07:01.298928 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_5874.solverstate
I0403 04:07:03.214448 23741 solver.cpp:337] Iteration 5874, Testing net (#0)
I0403 04:08:05.498453 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965891
I0403 04:08:05.498782 23741 solver.cpp:404]     Test net output #1: loss = 0.12149 (* 1 = 0.12149 loss)
I0403 04:08:07.531903 23741 solver.cpp:228] Iteration 5876, loss = 0.00235709
I0403 04:08:07.532009 23741 solver.cpp:244]     Train net output #0: loss = 0.00235705 (* 1 = 0.00235705 loss)
I0403 04:08:07.719625 23741 sgd_solver.cpp:106] Iteration 5876, lr = 5e-05
I0403 04:08:16.983358 23741 solver.cpp:228] Iteration 5889, loss = 0.0138468
I0403 04:08:16.983474 23741 solver.cpp:244]     Train net output #0: loss = 0.0138468 (* 1 = 0.0138468 loss)
I0403 04:08:17.165583 23741 sgd_solver.cpp:106] Iteration 5889, lr = 5e-05
I0403 04:08:26.390408 23741 solver.cpp:228] Iteration 5902, loss = 0.00955808
I0403 04:08:26.390517 23741 solver.cpp:244]     Train net output #0: loss = 0.00955803 (* 1 = 0.00955803 loss)
I0403 04:08:26.612529 23741 sgd_solver.cpp:106] Iteration 5902, lr = 5e-05
I0403 04:08:36.025997 23741 solver.cpp:228] Iteration 5915, loss = 0.00116306
I0403 04:08:36.026309 23741 solver.cpp:244]     Train net output #0: loss = 0.00116302 (* 1 = 0.00116302 loss)
I0403 04:08:36.228801 23741 sgd_solver.cpp:106] Iteration 5915, lr = 5e-05
I0403 04:08:45.484280 23741 solver.cpp:228] Iteration 5928, loss = 0.00234385
I0403 04:08:45.484392 23741 solver.cpp:244]     Train net output #0: loss = 0.00234381 (* 1 = 0.00234381 loss)
I0403 04:08:45.741791 23741 sgd_solver.cpp:106] Iteration 5928, lr = 5e-05
I0403 04:08:54.974977 23741 solver.cpp:228] Iteration 5941, loss = 0.00428694
I0403 04:08:54.975085 23741 solver.cpp:244]     Train net output #0: loss = 0.00428689 (* 1 = 0.00428689 loss)
I0403 04:08:55.178345 23741 sgd_solver.cpp:106] Iteration 5941, lr = 5e-05
I0403 04:09:04.470494 23741 solver.cpp:228] Iteration 5954, loss = 0.0138165
I0403 04:09:04.483047 23741 solver.cpp:244]     Train net output #0: loss = 0.0138165 (* 1 = 0.0138165 loss)
I0403 04:09:04.649437 23741 sgd_solver.cpp:106] Iteration 5954, lr = 5e-05
I0403 04:09:13.847298 23741 solver.cpp:228] Iteration 5967, loss = 0.00263004
I0403 04:09:13.847609 23741 solver.cpp:244]     Train net output #0: loss = 0.00263 (* 1 = 0.00263 loss)
I0403 04:09:14.038849 23741 sgd_solver.cpp:106] Iteration 5967, lr = 5e-05
I0403 04:09:23.327918 23741 solver.cpp:228] Iteration 5980, loss = 0.021463
I0403 04:09:23.328027 23741 solver.cpp:244]     Train net output #0: loss = 0.0214629 (* 1 = 0.0214629 loss)
I0403 04:09:23.514576 23741 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 04:09:32.813671 23741 solver.cpp:228] Iteration 5993, loss = 0.012801
I0403 04:09:32.813771 23741 solver.cpp:244]     Train net output #0: loss = 0.0128009 (* 1 = 0.0128009 loss)
I0403 04:09:32.986296 23741 sgd_solver.cpp:106] Iteration 5993, lr = 5e-05
I0403 04:09:42.315395 23741 solver.cpp:228] Iteration 6006, loss = 0.0184513
I0403 04:09:42.315507 23741 solver.cpp:244]     Train net output #0: loss = 0.0184512 (* 1 = 0.0184512 loss)
I0403 04:09:42.512385 23741 sgd_solver.cpp:106] Iteration 6006, lr = 5e-05
I0403 04:09:51.852596 23741 solver.cpp:228] Iteration 6019, loss = 0.0080425
I0403 04:09:51.852921 23741 solver.cpp:244]     Train net output #0: loss = 0.00804245 (* 1 = 0.00804245 loss)
I0403 04:09:52.033486 23741 sgd_solver.cpp:106] Iteration 6019, lr = 5e-05
I0403 04:10:01.303167 23741 solver.cpp:228] Iteration 6032, loss = 0.00245823
I0403 04:10:01.303282 23741 solver.cpp:244]     Train net output #0: loss = 0.00245818 (* 1 = 0.00245818 loss)
I0403 04:10:01.527606 23741 sgd_solver.cpp:106] Iteration 6032, lr = 5e-05
I0403 04:10:10.803230 23741 solver.cpp:228] Iteration 6045, loss = 0.0140535
I0403 04:10:10.803336 23741 solver.cpp:244]     Train net output #0: loss = 0.0140535 (* 1 = 0.0140535 loss)
I0403 04:10:10.997095 23741 sgd_solver.cpp:106] Iteration 6045, lr = 5e-05
I0403 04:10:20.350622 23741 solver.cpp:228] Iteration 6058, loss = 0.00398292
I0403 04:10:20.350731 23741 solver.cpp:244]     Train net output #0: loss = 0.00398288 (* 1 = 0.00398288 loss)
I0403 04:10:20.558697 23741 sgd_solver.cpp:106] Iteration 6058, lr = 5e-05
I0403 04:10:30.021638 23741 solver.cpp:228] Iteration 6071, loss = 0.00756732
I0403 04:10:30.022006 23741 solver.cpp:244]     Train net output #0: loss = 0.00756728 (* 1 = 0.00756728 loss)
I0403 04:10:30.182618 23741 sgd_solver.cpp:106] Iteration 6071, lr = 5e-05
I0403 04:10:39.638591 23741 solver.cpp:228] Iteration 6084, loss = 0.00434313
I0403 04:10:39.638700 23741 solver.cpp:244]     Train net output #0: loss = 0.00434309 (* 1 = 0.00434309 loss)
I0403 04:10:39.829836 23741 sgd_solver.cpp:106] Iteration 6084, lr = 5e-05
I0403 04:10:49.090405 23741 solver.cpp:228] Iteration 6097, loss = 0.00363234
I0403 04:10:49.090507 23741 solver.cpp:244]     Train net output #0: loss = 0.00363229 (* 1 = 0.00363229 loss)
I0403 04:10:49.271809 23741 sgd_solver.cpp:106] Iteration 6097, lr = 5e-05
I0403 04:10:58.521524 23741 solver.cpp:228] Iteration 6110, loss = 0.0170011
I0403 04:10:58.521631 23741 solver.cpp:244]     Train net output #0: loss = 0.0170011 (* 1 = 0.0170011 loss)
I0403 04:10:58.770920 23741 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 04:11:08.001353 23741 solver.cpp:228] Iteration 6123, loss = 0.0018244
I0403 04:11:08.001665 23741 solver.cpp:244]     Train net output #0: loss = 0.00182436 (* 1 = 0.00182436 loss)
I0403 04:11:08.214340 23741 sgd_solver.cpp:106] Iteration 6123, lr = 5e-05
I0403 04:11:17.654292 23741 solver.cpp:228] Iteration 6136, loss = 0.000692008
I0403 04:11:17.654407 23741 solver.cpp:244]     Train net output #0: loss = 0.000691964 (* 1 = 0.000691964 loss)
I0403 04:11:17.858489 23741 sgd_solver.cpp:106] Iteration 6136, lr = 5e-05
I0403 04:11:20.743391 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6141.caffemodel
I0403 04:11:23.472096 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6141.solverstate
I0403 04:11:25.372685 23741 solver.cpp:337] Iteration 6141, Testing net (#0)
I0403 04:12:27.660718 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966073
I0403 04:12:27.661047 23741 solver.cpp:404]     Test net output #1: loss = 0.121544 (* 1 = 0.121544 loss)
I0403 04:12:33.976675 23741 solver.cpp:228] Iteration 6149, loss = 0.000778249
I0403 04:12:33.976783 23741 solver.cpp:244]     Train net output #0: loss = 0.000778204 (* 1 = 0.000778204 loss)
I0403 04:12:34.168622 23741 sgd_solver.cpp:106] Iteration 6149, lr = 5e-05
I0403 04:12:43.593760 23741 solver.cpp:228] Iteration 6162, loss = 0.000634415
I0403 04:12:43.593873 23741 solver.cpp:244]     Train net output #0: loss = 0.00063437 (* 1 = 0.00063437 loss)
I0403 04:12:43.778599 23741 sgd_solver.cpp:106] Iteration 6162, lr = 5e-05
I0403 04:12:53.058091 23741 solver.cpp:228] Iteration 6175, loss = 0.010404
I0403 04:12:53.058202 23741 solver.cpp:244]     Train net output #0: loss = 0.0104039 (* 1 = 0.0104039 loss)
I0403 04:12:53.268223 23741 sgd_solver.cpp:106] Iteration 6175, lr = 5e-05
I0403 04:13:02.629513 23741 solver.cpp:228] Iteration 6188, loss = 0.00945204
I0403 04:13:02.629858 23741 solver.cpp:244]     Train net output #0: loss = 0.00945199 (* 1 = 0.00945199 loss)
I0403 04:13:02.817330 23741 sgd_solver.cpp:106] Iteration 6188, lr = 5e-05
I0403 04:13:12.212640 23741 solver.cpp:228] Iteration 6201, loss = 0.000621655
I0403 04:13:12.212750 23741 solver.cpp:244]     Train net output #0: loss = 0.000621608 (* 1 = 0.000621608 loss)
I0403 04:13:12.405354 23741 sgd_solver.cpp:106] Iteration 6201, lr = 5e-05
I0403 04:13:21.750299 23741 solver.cpp:228] Iteration 6214, loss = 0.000757812
I0403 04:13:21.750411 23741 solver.cpp:244]     Train net output #0: loss = 0.000757765 (* 1 = 0.000757765 loss)
I0403 04:13:21.937510 23741 sgd_solver.cpp:106] Iteration 6214, lr = 5e-05
I0403 04:13:31.189110 23741 solver.cpp:228] Iteration 6227, loss = 0.000514434
I0403 04:13:31.189215 23741 solver.cpp:244]     Train net output #0: loss = 0.000514385 (* 1 = 0.000514385 loss)
I0403 04:13:31.368257 23741 sgd_solver.cpp:106] Iteration 6227, lr = 5e-05
I0403 04:13:40.736186 23741 solver.cpp:228] Iteration 6240, loss = 0.00545686
I0403 04:13:40.736572 23741 solver.cpp:244]     Train net output #0: loss = 0.00545681 (* 1 = 0.00545681 loss)
I0403 04:13:40.962215 23741 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 04:13:50.207581 23741 solver.cpp:228] Iteration 6253, loss = 0.00800945
I0403 04:13:50.207690 23741 solver.cpp:244]     Train net output #0: loss = 0.0080094 (* 1 = 0.0080094 loss)
I0403 04:13:50.441658 23741 sgd_solver.cpp:106] Iteration 6253, lr = 5e-05
I0403 04:13:59.887262 23741 solver.cpp:228] Iteration 6266, loss = 0.0125035
I0403 04:13:59.887367 23741 solver.cpp:244]     Train net output #0: loss = 0.0125034 (* 1 = 0.0125034 loss)
I0403 04:14:00.077563 23741 sgd_solver.cpp:106] Iteration 6266, lr = 5e-05
I0403 04:14:09.394842 23741 solver.cpp:228] Iteration 6279, loss = 0.000427405
I0403 04:14:09.394950 23741 solver.cpp:244]     Train net output #0: loss = 0.000427357 (* 1 = 0.000427357 loss)
I0403 04:14:09.576822 23741 sgd_solver.cpp:106] Iteration 6279, lr = 5e-05
I0403 04:14:18.946661 23741 solver.cpp:228] Iteration 6292, loss = 0.00275772
I0403 04:14:18.947005 23741 solver.cpp:244]     Train net output #0: loss = 0.00275767 (* 1 = 0.00275767 loss)
I0403 04:14:19.136973 23741 sgd_solver.cpp:106] Iteration 6292, lr = 5e-05
I0403 04:14:28.441231 23741 solver.cpp:228] Iteration 6305, loss = 0.00445871
I0403 04:14:28.441324 23741 solver.cpp:244]     Train net output #0: loss = 0.00445866 (* 1 = 0.00445866 loss)
I0403 04:14:28.655951 23741 sgd_solver.cpp:106] Iteration 6305, lr = 5e-05
I0403 04:14:38.047519 23741 solver.cpp:228] Iteration 6318, loss = 0.0106842
I0403 04:14:38.047624 23741 solver.cpp:244]     Train net output #0: loss = 0.0106841 (* 1 = 0.0106841 loss)
I0403 04:14:38.228327 23741 sgd_solver.cpp:106] Iteration 6318, lr = 5e-05
I0403 04:14:47.598414 23741 solver.cpp:228] Iteration 6331, loss = 0.00551623
I0403 04:14:47.598523 23741 solver.cpp:244]     Train net output #0: loss = 0.00551618 (* 1 = 0.00551618 loss)
I0403 04:14:47.788934 23741 sgd_solver.cpp:106] Iteration 6331, lr = 5e-05
I0403 04:14:57.077030 23741 solver.cpp:228] Iteration 6344, loss = 0.00453948
I0403 04:14:57.077368 23741 solver.cpp:244]     Train net output #0: loss = 0.00453943 (* 1 = 0.00453943 loss)
I0403 04:14:57.276908 23741 sgd_solver.cpp:106] Iteration 6344, lr = 5e-05
I0403 04:15:06.617074 23741 solver.cpp:228] Iteration 6357, loss = 0.00180706
I0403 04:15:06.617166 23741 solver.cpp:244]     Train net output #0: loss = 0.00180701 (* 1 = 0.00180701 loss)
I0403 04:15:06.830420 23741 sgd_solver.cpp:106] Iteration 6357, lr = 5e-05
I0403 04:15:16.241575 23741 solver.cpp:228] Iteration 6370, loss = 0.00450797
I0403 04:15:16.241682 23741 solver.cpp:244]     Train net output #0: loss = 0.00450792 (* 1 = 0.00450792 loss)
I0403 04:15:16.428892 23741 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 04:15:25.883673 23741 solver.cpp:228] Iteration 6383, loss = 0.00075226
I0403 04:15:25.883780 23741 solver.cpp:244]     Train net output #0: loss = 0.000752211 (* 1 = 0.000752211 loss)
I0403 04:15:26.067883 23741 sgd_solver.cpp:106] Iteration 6383, lr = 5e-05
I0403 04:15:35.501269 23741 solver.cpp:228] Iteration 6396, loss = 0.00346382
I0403 04:15:35.501598 23741 solver.cpp:244]     Train net output #0: loss = 0.00346377 (* 1 = 0.00346377 loss)
I0403 04:15:35.649010 23741 sgd_solver.cpp:106] Iteration 6396, lr = 5e-05
I0403 04:15:43.819809 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6408.caffemodel
I0403 04:15:46.576357 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6408.solverstate
I0403 04:15:48.479198 23741 solver.cpp:337] Iteration 6408, Testing net (#0)
I0403 04:16:50.760188 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965928
I0403 04:16:50.760495 23741 solver.cpp:404]     Test net output #1: loss = 0.121157 (* 1 = 0.121157 loss)
I0403 04:16:51.996781 23741 solver.cpp:228] Iteration 6409, loss = 0.00349822
I0403 04:16:51.996886 23741 solver.cpp:244]     Train net output #0: loss = 0.00349816 (* 1 = 0.00349816 loss)
I0403 04:16:52.202994 23741 sgd_solver.cpp:106] Iteration 6409, lr = 5e-05
I0403 04:17:01.586724 23741 solver.cpp:228] Iteration 6422, loss = 0.000957675
I0403 04:17:01.586823 23741 solver.cpp:244]     Train net output #0: loss = 0.000957622 (* 1 = 0.000957622 loss)
I0403 04:17:01.766984 23741 sgd_solver.cpp:106] Iteration 6422, lr = 5e-05
I0403 04:17:11.112023 23741 solver.cpp:228] Iteration 6435, loss = 0.00835736
I0403 04:17:11.112126 23741 solver.cpp:244]     Train net output #0: loss = 0.00835731 (* 1 = 0.00835731 loss)
I0403 04:17:11.278687 23741 sgd_solver.cpp:106] Iteration 6435, lr = 5e-05
I0403 04:17:20.587476 23741 solver.cpp:228] Iteration 6448, loss = 0.00198802
I0403 04:17:20.587579 23741 solver.cpp:244]     Train net output #0: loss = 0.00198797 (* 1 = 0.00198797 loss)
I0403 04:17:20.760529 23741 sgd_solver.cpp:106] Iteration 6448, lr = 5e-05
I0403 04:17:30.064334 23741 solver.cpp:228] Iteration 6461, loss = 0.00252159
I0403 04:17:30.064442 23741 solver.cpp:244]     Train net output #0: loss = 0.00252154 (* 1 = 0.00252154 loss)
I0403 04:17:30.251262 23741 sgd_solver.cpp:106] Iteration 6461, lr = 5e-05
I0403 04:17:39.482182 23741 solver.cpp:228] Iteration 6474, loss = 0.000747978
I0403 04:17:39.482296 23741 solver.cpp:244]     Train net output #0: loss = 0.000747926 (* 1 = 0.000747926 loss)
I0403 04:17:39.684885 23741 sgd_solver.cpp:106] Iteration 6474, lr = 5e-05
I0403 04:17:48.964081 23741 solver.cpp:228] Iteration 6487, loss = 0.0032432
I0403 04:17:48.964187 23741 solver.cpp:244]     Train net output #0: loss = 0.00324315 (* 1 = 0.00324315 loss)
I0403 04:17:49.151621 23741 sgd_solver.cpp:106] Iteration 6487, lr = 5e-05
I0403 04:17:58.499402 23741 solver.cpp:228] Iteration 6500, loss = 0.00263235
I0403 04:17:58.499706 23741 solver.cpp:244]     Train net output #0: loss = 0.0026323 (* 1 = 0.0026323 loss)
I0403 04:17:58.680888 23741 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 04:18:07.957463 23741 solver.cpp:228] Iteration 6513, loss = 0.0041209
I0403 04:18:07.957562 23741 solver.cpp:244]     Train net output #0: loss = 0.00412085 (* 1 = 0.00412085 loss)
I0403 04:18:08.120451 23741 sgd_solver.cpp:106] Iteration 6513, lr = 5e-05
I0403 04:18:17.428262 23741 solver.cpp:228] Iteration 6526, loss = 0.00426018
I0403 04:18:17.428364 23741 solver.cpp:244]     Train net output #0: loss = 0.00426013 (* 1 = 0.00426013 loss)
I0403 04:18:17.599988 23741 sgd_solver.cpp:106] Iteration 6526, lr = 5e-05
I0403 04:18:26.836908 23741 solver.cpp:228] Iteration 6539, loss = 0.00238737
I0403 04:18:26.837005 23741 solver.cpp:244]     Train net output #0: loss = 0.00238732 (* 1 = 0.00238732 loss)
I0403 04:18:27.053055 23741 sgd_solver.cpp:106] Iteration 6539, lr = 5e-05
I0403 04:18:36.535430 23741 solver.cpp:228] Iteration 6552, loss = 0.000199756
I0403 04:18:36.535768 23741 solver.cpp:244]     Train net output #0: loss = 0.000199707 (* 1 = 0.000199707 loss)
I0403 04:18:36.713753 23741 sgd_solver.cpp:106] Iteration 6552, lr = 5e-05
I0403 04:18:46.029069 23741 solver.cpp:228] Iteration 6565, loss = 0.00222593
I0403 04:18:46.029186 23741 solver.cpp:244]     Train net output #0: loss = 0.00222588 (* 1 = 0.00222588 loss)
I0403 04:18:46.211545 23741 sgd_solver.cpp:106] Iteration 6565, lr = 5e-05
I0403 04:18:55.414415 23741 solver.cpp:228] Iteration 6578, loss = 0.0209449
I0403 04:18:55.414517 23741 solver.cpp:244]     Train net output #0: loss = 0.0209448 (* 1 = 0.0209448 loss)
I0403 04:18:55.595700 23741 sgd_solver.cpp:106] Iteration 6578, lr = 5e-05
I0403 04:19:04.875764 23741 solver.cpp:228] Iteration 6591, loss = 0.00214147
I0403 04:19:04.875872 23741 solver.cpp:244]     Train net output #0: loss = 0.00214142 (* 1 = 0.00214142 loss)
I0403 04:19:05.082522 23741 sgd_solver.cpp:106] Iteration 6591, lr = 5e-05
I0403 04:19:14.412056 23741 solver.cpp:228] Iteration 6604, loss = 0.000581041
I0403 04:19:14.412432 23741 solver.cpp:244]     Train net output #0: loss = 0.000580988 (* 1 = 0.000580988 loss)
I0403 04:19:14.603704 23741 sgd_solver.cpp:106] Iteration 6604, lr = 5e-05
I0403 04:19:23.940732 23741 solver.cpp:228] Iteration 6617, loss = 0.00447642
I0403 04:19:23.940840 23741 solver.cpp:244]     Train net output #0: loss = 0.00447637 (* 1 = 0.00447637 loss)
I0403 04:19:24.124459 23741 sgd_solver.cpp:106] Iteration 6617, lr = 5e-05
I0403 04:19:33.468364 23741 solver.cpp:228] Iteration 6630, loss = 0.000849459
I0403 04:19:33.468477 23741 solver.cpp:244]     Train net output #0: loss = 0.000849405 (* 1 = 0.000849405 loss)
I0403 04:19:33.650442 23741 sgd_solver.cpp:106] Iteration 6630, lr = 5e-05
I0403 04:19:43.055692 23741 solver.cpp:228] Iteration 6643, loss = 0.00272205
I0403 04:19:43.055815 23741 solver.cpp:244]     Train net output #0: loss = 0.002722 (* 1 = 0.002722 loss)
I0403 04:19:43.237704 23741 sgd_solver.cpp:106] Iteration 6643, lr = 5e-05
I0403 04:19:52.640982 23741 solver.cpp:228] Iteration 6656, loss = 0.00567661
I0403 04:19:52.641288 23741 solver.cpp:244]     Train net output #0: loss = 0.00567656 (* 1 = 0.00567656 loss)
I0403 04:19:52.821506 23741 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 04:20:02.076495 23741 solver.cpp:228] Iteration 6669, loss = 0.00715732
I0403 04:20:02.076598 23741 solver.cpp:244]     Train net output #0: loss = 0.00715727 (* 1 = 0.00715727 loss)
I0403 04:20:02.269959 23741 sgd_solver.cpp:106] Iteration 6669, lr = 5e-05
I0403 04:20:05.934571 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6675.caffemodel
I0403 04:20:08.708662 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6675.solverstate
I0403 04:20:10.603112 23741 solver.cpp:337] Iteration 6675, Testing net (#0)
I0403 04:21:12.901515 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966001
I0403 04:21:12.901835 23741 solver.cpp:404]     Test net output #1: loss = 0.12127 (* 1 = 0.12127 loss)
I0403 04:21:18.554198 23741 solver.cpp:228] Iteration 6682, loss = 0.00167632
I0403 04:21:18.558828 23741 solver.cpp:244]     Train net output #0: loss = 0.00167626 (* 1 = 0.00167626 loss)
I0403 04:21:18.740201 23741 sgd_solver.cpp:106] Iteration 6682, lr = 5e-05
I0403 04:21:28.106498 23741 solver.cpp:228] Iteration 6695, loss = 0.00181398
I0403 04:21:28.106607 23741 solver.cpp:244]     Train net output #0: loss = 0.00181393 (* 1 = 0.00181393 loss)
I0403 04:21:28.351992 23741 sgd_solver.cpp:106] Iteration 6695, lr = 5e-05
I0403 04:21:37.711024 23741 solver.cpp:228] Iteration 6708, loss = 0.00876842
I0403 04:21:37.711134 23741 solver.cpp:244]     Train net output #0: loss = 0.00876836 (* 1 = 0.00876836 loss)
I0403 04:21:37.935382 23741 sgd_solver.cpp:106] Iteration 6708, lr = 5e-05
I0403 04:21:47.111037 23741 solver.cpp:228] Iteration 6721, loss = 0.00395704
I0403 04:21:47.111379 23741 solver.cpp:244]     Train net output #0: loss = 0.00395698 (* 1 = 0.00395698 loss)
I0403 04:21:47.304535 23741 sgd_solver.cpp:106] Iteration 6721, lr = 5e-05
I0403 04:21:56.614608 23741 solver.cpp:228] Iteration 6734, loss = 0.0202606
I0403 04:21:56.614717 23741 solver.cpp:244]     Train net output #0: loss = 0.0202605 (* 1 = 0.0202605 loss)
I0403 04:21:56.824486 23741 sgd_solver.cpp:106] Iteration 6734, lr = 5e-05
I0403 04:22:06.180001 23741 solver.cpp:228] Iteration 6747, loss = 0.0009922
I0403 04:22:06.180111 23741 solver.cpp:244]     Train net output #0: loss = 0.000992141 (* 1 = 0.000992141 loss)
I0403 04:22:06.376720 23741 sgd_solver.cpp:106] Iteration 6747, lr = 5e-05
I0403 04:22:15.747959 23741 solver.cpp:228] Iteration 6760, loss = 0.001438
I0403 04:22:15.748070 23741 solver.cpp:244]     Train net output #0: loss = 0.00143794 (* 1 = 0.00143794 loss)
I0403 04:22:15.938551 23741 sgd_solver.cpp:106] Iteration 6760, lr = 5e-05
I0403 04:22:25.241338 23741 solver.cpp:228] Iteration 6773, loss = 0.0036205
I0403 04:22:25.241710 23741 solver.cpp:244]     Train net output #0: loss = 0.00362044 (* 1 = 0.00362044 loss)
I0403 04:22:25.458859 23741 sgd_solver.cpp:106] Iteration 6773, lr = 5e-05
I0403 04:22:34.683578 23741 solver.cpp:228] Iteration 6786, loss = 0.00396037
I0403 04:22:34.683681 23741 solver.cpp:244]     Train net output #0: loss = 0.00396031 (* 1 = 0.00396031 loss)
I0403 04:22:34.861474 23741 sgd_solver.cpp:106] Iteration 6786, lr = 5e-05
I0403 04:22:44.236532 23741 solver.cpp:228] Iteration 6799, loss = 0.000650056
I0403 04:22:44.236645 23741 solver.cpp:244]     Train net output #0: loss = 0.000649996 (* 1 = 0.000649996 loss)
I0403 04:22:44.435214 23741 sgd_solver.cpp:106] Iteration 6799, lr = 5e-05
I0403 04:22:53.838904 23741 solver.cpp:228] Iteration 6812, loss = 0.00983776
I0403 04:22:53.839020 23741 solver.cpp:244]     Train net output #0: loss = 0.00983769 (* 1 = 0.00983769 loss)
I0403 04:22:54.022058 23741 sgd_solver.cpp:106] Iteration 6812, lr = 5e-05
I0403 04:23:03.314410 23741 solver.cpp:228] Iteration 6825, loss = 0.00296546
I0403 04:23:03.314723 23741 solver.cpp:244]     Train net output #0: loss = 0.00296539 (* 1 = 0.00296539 loss)
I0403 04:23:03.484535 23741 sgd_solver.cpp:106] Iteration 6825, lr = 5e-05
I0403 04:23:12.749385 23741 solver.cpp:228] Iteration 6838, loss = 0.00859504
I0403 04:23:12.749488 23741 solver.cpp:244]     Train net output #0: loss = 0.00859498 (* 1 = 0.00859498 loss)
I0403 04:23:12.947574 23741 sgd_solver.cpp:106] Iteration 6838, lr = 5e-05
I0403 04:23:22.208398 23741 solver.cpp:228] Iteration 6851, loss = 0.00101392
I0403 04:23:22.208508 23741 solver.cpp:244]     Train net output #0: loss = 0.00101385 (* 1 = 0.00101385 loss)
I0403 04:23:22.404378 23741 sgd_solver.cpp:106] Iteration 6851, lr = 5e-05
I0403 04:23:31.937397 23741 solver.cpp:228] Iteration 6864, loss = 0.0122804
I0403 04:23:31.937505 23741 solver.cpp:244]     Train net output #0: loss = 0.0122804 (* 1 = 0.0122804 loss)
I0403 04:23:32.136071 23741 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 04:23:41.592969 23741 solver.cpp:228] Iteration 6877, loss = 0.0121427
I0403 04:23:41.593314 23741 solver.cpp:244]     Train net output #0: loss = 0.0121426 (* 1 = 0.0121426 loss)
I0403 04:23:41.784973 23741 sgd_solver.cpp:106] Iteration 6877, lr = 5e-05
I0403 04:23:51.186671 23741 solver.cpp:228] Iteration 6890, loss = 0.0144183
I0403 04:23:51.186780 23741 solver.cpp:244]     Train net output #0: loss = 0.0144183 (* 1 = 0.0144183 loss)
I0403 04:23:51.375087 23741 sgd_solver.cpp:106] Iteration 6890, lr = 5e-05
I0403 04:24:00.678408 23741 solver.cpp:228] Iteration 6903, loss = 0.0062931
I0403 04:24:00.678510 23741 solver.cpp:244]     Train net output #0: loss = 0.00629303 (* 1 = 0.00629303 loss)
I0403 04:24:00.856123 23741 sgd_solver.cpp:106] Iteration 6903, lr = 5e-05
I0403 04:24:10.170508 23741 solver.cpp:228] Iteration 6916, loss = 0.00159317
I0403 04:24:10.170608 23741 solver.cpp:244]     Train net output #0: loss = 0.0015931 (* 1 = 0.0015931 loss)
I0403 04:24:10.320987 23741 sgd_solver.cpp:106] Iteration 6916, lr = 5e-05
I0403 04:24:19.619433 23741 solver.cpp:228] Iteration 6929, loss = 0.00472049
I0403 04:24:19.619768 23741 solver.cpp:244]     Train net output #0: loss = 0.00472042 (* 1 = 0.00472042 loss)
I0403 04:24:19.816232 23741 sgd_solver.cpp:106] Iteration 6929, lr = 5e-05
I0403 04:24:28.542542 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6942.caffemodel
I0403 04:24:31.320597 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_6942.solverstate
I0403 04:24:33.216541 23741 solver.cpp:337] Iteration 6942, Testing net (#0)
I0403 04:25:35.523113 23741 solver.cpp:404]     Test net output #0: accuracy = 0.965891
I0403 04:25:35.523488 23741 solver.cpp:404]     Test net output #1: loss = 0.121788 (* 1 = 0.121788 loss)
I0403 04:25:36.028182 23741 solver.cpp:228] Iteration 6942, loss = 0.00657512
I0403 04:25:36.028280 23741 solver.cpp:244]     Train net output #0: loss = 0.00657505 (* 1 = 0.00657505 loss)
I0403 04:25:36.198374 23741 sgd_solver.cpp:106] Iteration 6942, lr = 5e-05
I0403 04:25:45.519208 23741 solver.cpp:228] Iteration 6955, loss = 0.0117983
I0403 04:25:45.519315 23741 solver.cpp:244]     Train net output #0: loss = 0.0117982 (* 1 = 0.0117982 loss)
I0403 04:25:45.721315 23741 sgd_solver.cpp:106] Iteration 6955, lr = 5e-05
I0403 04:25:55.078089 23741 solver.cpp:228] Iteration 6968, loss = 0.00163932
I0403 04:25:55.078203 23741 solver.cpp:244]     Train net output #0: loss = 0.00163926 (* 1 = 0.00163926 loss)
I0403 04:25:55.263386 23741 sgd_solver.cpp:106] Iteration 6968, lr = 5e-05
I0403 04:26:04.528766 23741 solver.cpp:228] Iteration 6981, loss = 0.00319016
I0403 04:26:04.528875 23741 solver.cpp:244]     Train net output #0: loss = 0.0031901 (* 1 = 0.0031901 loss)
I0403 04:26:04.725648 23741 sgd_solver.cpp:106] Iteration 6981, lr = 5e-05
I0403 04:26:14.156030 23741 solver.cpp:228] Iteration 6994, loss = 0.00117199
I0403 04:26:14.156368 23741 solver.cpp:244]     Train net output #0: loss = 0.00117193 (* 1 = 0.00117193 loss)
I0403 04:26:14.307344 23741 sgd_solver.cpp:106] Iteration 6994, lr = 5e-05
I0403 04:26:23.724776 23741 solver.cpp:228] Iteration 7007, loss = 0.00414215
I0403 04:26:23.724874 23741 solver.cpp:244]     Train net output #0: loss = 0.00414208 (* 1 = 0.00414208 loss)
I0403 04:26:23.884621 23741 sgd_solver.cpp:106] Iteration 7007, lr = 5e-05
I0403 04:26:33.137225 23741 solver.cpp:228] Iteration 7020, loss = 0.00108424
I0403 04:26:33.137327 23741 solver.cpp:244]     Train net output #0: loss = 0.00108417 (* 1 = 0.00108417 loss)
I0403 04:26:33.313663 23741 sgd_solver.cpp:106] Iteration 7020, lr = 5e-05
I0403 04:26:42.587095 23741 solver.cpp:228] Iteration 7033, loss = 0.000806121
I0403 04:26:42.587206 23741 solver.cpp:244]     Train net output #0: loss = 0.000806055 (* 1 = 0.000806055 loss)
I0403 04:26:42.767359 23741 sgd_solver.cpp:106] Iteration 7033, lr = 5e-05
I0403 04:26:52.128206 23741 solver.cpp:228] Iteration 7046, loss = 0.002747
I0403 04:26:52.128540 23741 solver.cpp:244]     Train net output #0: loss = 0.00274694 (* 1 = 0.00274694 loss)
I0403 04:26:52.339491 23741 sgd_solver.cpp:106] Iteration 7046, lr = 5e-05
I0403 04:27:01.598323 23741 solver.cpp:228] Iteration 7059, loss = 0.000588714
I0403 04:27:01.598424 23741 solver.cpp:244]     Train net output #0: loss = 0.000588647 (* 1 = 0.000588647 loss)
I0403 04:27:01.779403 23741 sgd_solver.cpp:106] Iteration 7059, lr = 5e-05
I0403 04:27:11.209667 23741 solver.cpp:228] Iteration 7072, loss = 0.0340502
I0403 04:27:11.209781 23741 solver.cpp:244]     Train net output #0: loss = 0.0340502 (* 1 = 0.0340502 loss)
I0403 04:27:11.396755 23741 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 04:27:20.634049 23741 solver.cpp:228] Iteration 7085, loss = 0.00690018
I0403 04:27:20.640298 23741 solver.cpp:244]     Train net output #0: loss = 0.00690012 (* 1 = 0.00690012 loss)
I0403 04:27:20.850167 23741 sgd_solver.cpp:106] Iteration 7085, lr = 5e-05
I0403 04:27:30.214370 23741 solver.cpp:228] Iteration 7098, loss = 0.0404426
I0403 04:27:30.214699 23741 solver.cpp:244]     Train net output #0: loss = 0.0404425 (* 1 = 0.0404425 loss)
I0403 04:27:30.347676 23741 sgd_solver.cpp:106] Iteration 7098, lr = 5e-05
I0403 04:27:39.834503 23741 solver.cpp:228] Iteration 7111, loss = 0.0036433
I0403 04:27:39.834604 23741 solver.cpp:244]     Train net output #0: loss = 0.00364323 (* 1 = 0.00364323 loss)
I0403 04:27:40.013494 23741 sgd_solver.cpp:106] Iteration 7111, lr = 5e-05
I0403 04:27:49.345401 23741 solver.cpp:228] Iteration 7124, loss = 0.010203
I0403 04:27:49.345499 23741 solver.cpp:244]     Train net output #0: loss = 0.010203 (* 1 = 0.010203 loss)
I0403 04:27:49.514691 23741 sgd_solver.cpp:106] Iteration 7124, lr = 5e-05
I0403 04:27:58.833264 23741 solver.cpp:228] Iteration 7137, loss = 0.0209802
I0403 04:27:58.833362 23741 solver.cpp:244]     Train net output #0: loss = 0.0209801 (* 1 = 0.0209801 loss)
I0403 04:27:59.014518 23741 sgd_solver.cpp:106] Iteration 7137, lr = 5e-05
I0403 04:28:08.312950 23741 solver.cpp:228] Iteration 7150, loss = 0.00144069
I0403 04:28:08.313293 23741 solver.cpp:244]     Train net output #0: loss = 0.00144062 (* 1 = 0.00144062 loss)
I0403 04:28:08.507740 23741 sgd_solver.cpp:106] Iteration 7150, lr = 5e-05
I0403 04:28:17.727722 23741 solver.cpp:228] Iteration 7163, loss = 0.00684398
I0403 04:28:17.727838 23741 solver.cpp:244]     Train net output #0: loss = 0.00684391 (* 1 = 0.00684391 loss)
I0403 04:28:17.928763 23741 sgd_solver.cpp:106] Iteration 7163, lr = 5e-05
I0403 04:28:27.248283 23741 solver.cpp:228] Iteration 7176, loss = 0.0116606
I0403 04:28:27.248373 23741 solver.cpp:244]     Train net output #0: loss = 0.0116605 (* 1 = 0.0116605 loss)
I0403 04:28:27.466120 23741 sgd_solver.cpp:106] Iteration 7176, lr = 5e-05
I0403 04:28:36.728181 23741 solver.cpp:228] Iteration 7189, loss = 0.00244073
I0403 04:28:36.728283 23741 solver.cpp:244]     Train net output #0: loss = 0.00244066 (* 1 = 0.00244066 loss)
I0403 04:28:36.920330 23741 sgd_solver.cpp:106] Iteration 7189, lr = 5e-05
I0403 04:28:46.195431 23741 solver.cpp:228] Iteration 7202, loss = 0.00328815
I0403 04:28:46.195752 23741 solver.cpp:244]     Train net output #0: loss = 0.00328808 (* 1 = 0.00328808 loss)
I0403 04:28:46.399147 23741 sgd_solver.cpp:106] Iteration 7202, lr = 5e-05
I0403 04:28:50.745750 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_7209.caffemodel
I0403 04:28:53.502534 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_7209.solverstate
I0403 04:28:55.400554 23741 solver.cpp:337] Iteration 7209, Testing net (#0)
I0403 04:29:57.695358 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966291
I0403 04:29:57.695683 23741 solver.cpp:404]     Test net output #1: loss = 0.122419 (* 1 = 0.122419 loss)
I0403 04:30:02.595978 23741 solver.cpp:228] Iteration 7215, loss = 0.00489565
I0403 04:30:02.596076 23741 solver.cpp:244]     Train net output #0: loss = 0.00489558 (* 1 = 0.00489558 loss)
I0403 04:30:02.760231 23741 sgd_solver.cpp:106] Iteration 7215, lr = 5e-05
I0403 04:30:12.039158 23741 solver.cpp:228] Iteration 7228, loss = 0.00732837
I0403 04:30:12.039274 23741 solver.cpp:244]     Train net output #0: loss = 0.0073283 (* 1 = 0.0073283 loss)
I0403 04:30:12.246402 23741 sgd_solver.cpp:106] Iteration 7228, lr = 5e-05
I0403 04:30:21.558511 23741 solver.cpp:228] Iteration 7241, loss = 0.00329763
I0403 04:30:21.558621 23741 solver.cpp:244]     Train net output #0: loss = 0.00329756 (* 1 = 0.00329756 loss)
I0403 04:30:21.745247 23741 sgd_solver.cpp:106] Iteration 7241, lr = 5e-05
I0403 04:30:31.023319 23741 solver.cpp:228] Iteration 7254, loss = 0.00373955
I0403 04:30:31.023651 23741 solver.cpp:244]     Train net output #0: loss = 0.00373947 (* 1 = 0.00373947 loss)
I0403 04:30:31.225366 23741 sgd_solver.cpp:106] Iteration 7254, lr = 5e-05
I0403 04:30:40.350965 23741 solver.cpp:228] Iteration 7267, loss = 0.00333847
I0403 04:30:40.351079 23741 solver.cpp:244]     Train net output #0: loss = 0.0033384 (* 1 = 0.0033384 loss)
I0403 04:30:40.555765 23741 sgd_solver.cpp:106] Iteration 7267, lr = 5e-05
I0403 04:30:49.757397 23741 solver.cpp:228] Iteration 7280, loss = 0.00130654
I0403 04:30:49.757509 23741 solver.cpp:244]     Train net output #0: loss = 0.00130647 (* 1 = 0.00130647 loss)
I0403 04:30:49.939898 23741 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 04:30:59.303869 23741 solver.cpp:228] Iteration 7293, loss = 0.0110713
I0403 04:30:59.303978 23741 solver.cpp:244]     Train net output #0: loss = 0.0110713 (* 1 = 0.0110713 loss)
I0403 04:30:59.491256 23741 sgd_solver.cpp:106] Iteration 7293, lr = 5e-05
I0403 04:31:08.995842 23741 solver.cpp:228] Iteration 7306, loss = 0.00704478
I0403 04:31:08.996211 23741 solver.cpp:244]     Train net output #0: loss = 0.00704471 (* 1 = 0.00704471 loss)
I0403 04:31:09.187528 23741 sgd_solver.cpp:106] Iteration 7306, lr = 5e-05
I0403 04:31:18.449795 23741 solver.cpp:228] Iteration 7319, loss = 0.00464039
I0403 04:31:18.449905 23741 solver.cpp:244]     Train net output #0: loss = 0.00464031 (* 1 = 0.00464031 loss)
I0403 04:31:18.648685 23741 sgd_solver.cpp:106] Iteration 7319, lr = 5e-05
I0403 04:31:28.034976 23741 solver.cpp:228] Iteration 7332, loss = 0.00894758
I0403 04:31:28.035080 23741 solver.cpp:244]     Train net output #0: loss = 0.00894751 (* 1 = 0.00894751 loss)
I0403 04:31:28.215317 23741 sgd_solver.cpp:106] Iteration 7332, lr = 5e-05
I0403 04:31:37.451347 23741 solver.cpp:228] Iteration 7345, loss = 0.0123014
I0403 04:31:37.451457 23741 solver.cpp:244]     Train net output #0: loss = 0.0123013 (* 1 = 0.0123013 loss)
I0403 04:31:37.655374 23741 sgd_solver.cpp:106] Iteration 7345, lr = 5e-05
I0403 04:31:46.909400 23741 solver.cpp:228] Iteration 7358, loss = 0.00491618
I0403 04:31:46.909745 23741 solver.cpp:244]     Train net output #0: loss = 0.00491611 (* 1 = 0.00491611 loss)
I0403 04:31:47.097671 23741 sgd_solver.cpp:106] Iteration 7358, lr = 5e-05
I0403 04:31:56.276182 23741 solver.cpp:228] Iteration 7371, loss = 0.00506506
I0403 04:31:56.276300 23741 solver.cpp:244]     Train net output #0: loss = 0.00506499 (* 1 = 0.00506499 loss)
I0403 04:31:56.490686 23741 sgd_solver.cpp:106] Iteration 7371, lr = 5e-05
I0403 04:32:05.853665 23741 solver.cpp:228] Iteration 7384, loss = 0.00118753
I0403 04:32:05.853780 23741 solver.cpp:244]     Train net output #0: loss = 0.00118745 (* 1 = 0.00118745 loss)
I0403 04:32:06.066906 23741 sgd_solver.cpp:106] Iteration 7384, lr = 5e-05
I0403 04:32:15.568449 23741 solver.cpp:228] Iteration 7397, loss = 0.000853998
I0403 04:32:15.568563 23741 solver.cpp:244]     Train net output #0: loss = 0.000853925 (* 1 = 0.000853925 loss)
I0403 04:32:15.755420 23741 sgd_solver.cpp:106] Iteration 7397, lr = 5e-05
I0403 04:32:25.177223 23741 solver.cpp:228] Iteration 7410, loss = 0.00736651
I0403 04:32:25.177533 23741 solver.cpp:244]     Train net output #0: loss = 0.00736643 (* 1 = 0.00736643 loss)
I0403 04:32:25.365013 23741 sgd_solver.cpp:106] Iteration 7410, lr = 5e-05
I0403 04:32:34.658910 23741 solver.cpp:228] Iteration 7423, loss = 0.00261742
I0403 04:32:34.659023 23741 solver.cpp:244]     Train net output #0: loss = 0.00261735 (* 1 = 0.00261735 loss)
I0403 04:32:34.847604 23741 sgd_solver.cpp:106] Iteration 7423, lr = 5e-05
I0403 04:32:44.153903 23741 solver.cpp:228] Iteration 7436, loss = 0.0209033
I0403 04:32:44.154017 23741 solver.cpp:244]     Train net output #0: loss = 0.0209033 (* 1 = 0.0209033 loss)
I0403 04:32:44.413206 23741 sgd_solver.cpp:106] Iteration 7436, lr = 5e-05
I0403 04:32:53.720722 23741 solver.cpp:228] Iteration 7449, loss = 0.000148535
I0403 04:32:53.720835 23741 solver.cpp:244]     Train net output #0: loss = 0.000148459 (* 1 = 0.000148459 loss)
I0403 04:32:53.942198 23741 sgd_solver.cpp:106] Iteration 7449, lr = 5e-05
I0403 04:33:03.333657 23741 solver.cpp:228] Iteration 7462, loss = 0.00111496
I0403 04:33:03.333979 23741 solver.cpp:244]     Train net output #0: loss = 0.00111488 (* 1 = 0.00111488 loss)
I0403 04:33:03.508296 23741 sgd_solver.cpp:106] Iteration 7462, lr = 5e-05
I0403 04:33:12.914825 23741 solver.cpp:228] Iteration 7475, loss = 0.00492977
I0403 04:33:12.914933 23741 solver.cpp:244]     Train net output #0: loss = 0.0049297 (* 1 = 0.0049297 loss)
I0403 04:33:13.097282 23741 sgd_solver.cpp:106] Iteration 7475, lr = 5e-05
I0403 04:33:13.097520 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_7476.caffemodel
I0403 04:33:15.833896 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_7476.solverstate
I0403 04:33:17.610112 23741 solver.cpp:337] Iteration 7476, Testing net (#0)
I0403 04:34:19.913444 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966401
I0403 04:34:19.913817 23741 solver.cpp:404]     Test net output #1: loss = 0.122704 (* 1 = 0.122704 loss)
I0403 04:34:29.158783 23741 solver.cpp:228] Iteration 7488, loss = 0.000688535
I0403 04:34:29.158893 23741 solver.cpp:244]     Train net output #0: loss = 0.000688463 (* 1 = 0.000688463 loss)
I0403 04:34:29.341531 23741 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 04:34:38.769469 23741 solver.cpp:228] Iteration 7501, loss = 0.00267097
I0403 04:34:38.769577 23741 solver.cpp:244]     Train net output #0: loss = 0.0026709 (* 1 = 0.0026709 loss)
I0403 04:34:38.956670 23741 sgd_solver.cpp:106] Iteration 7501, lr = 5e-05
I0403 04:34:48.319032 23741 solver.cpp:228] Iteration 7514, loss = 0.0121386
I0403 04:34:48.319135 23741 solver.cpp:244]     Train net output #0: loss = 0.0121385 (* 1 = 0.0121385 loss)
I0403 04:34:48.484910 23741 sgd_solver.cpp:106] Iteration 7514, lr = 5e-05
I0403 04:34:57.799182 23741 solver.cpp:228] Iteration 7527, loss = 0.0105799
I0403 04:34:57.812162 23741 solver.cpp:244]     Train net output #0: loss = 0.0105799 (* 1 = 0.0105799 loss)
I0403 04:34:57.984660 23741 sgd_solver.cpp:106] Iteration 7527, lr = 5e-05
I0403 04:35:07.349366 23741 solver.cpp:228] Iteration 7540, loss = 0.0192611
I0403 04:35:07.349488 23741 solver.cpp:244]     Train net output #0: loss = 0.019261 (* 1 = 0.019261 loss)
I0403 04:35:07.534241 23741 sgd_solver.cpp:106] Iteration 7540, lr = 5e-05
I0403 04:35:16.837548 23741 solver.cpp:228] Iteration 7553, loss = 0.032849
I0403 04:35:16.837649 23741 solver.cpp:244]     Train net output #0: loss = 0.0328489 (* 1 = 0.0328489 loss)
I0403 04:35:16.977632 23741 sgd_solver.cpp:106] Iteration 7553, lr = 5e-05
I0403 04:35:26.348775 23741 solver.cpp:228] Iteration 7566, loss = 0.000352241
I0403 04:35:26.348876 23741 solver.cpp:244]     Train net output #0: loss = 0.000352169 (* 1 = 0.000352169 loss)
I0403 04:35:26.529361 23741 sgd_solver.cpp:106] Iteration 7566, lr = 5e-05
I0403 04:35:35.967689 23741 solver.cpp:228] Iteration 7579, loss = 0.00252388
I0403 04:35:35.967998 23741 solver.cpp:244]     Train net output #0: loss = 0.00252381 (* 1 = 0.00252381 loss)
I0403 04:35:36.129277 23741 sgd_solver.cpp:106] Iteration 7579, lr = 5e-05
I0403 04:35:45.589586 23741 solver.cpp:228] Iteration 7592, loss = 0.0281832
I0403 04:35:45.589694 23741 solver.cpp:244]     Train net output #0: loss = 0.0281831 (* 1 = 0.0281831 loss)
I0403 04:35:45.772049 23741 sgd_solver.cpp:106] Iteration 7592, lr = 5e-05
I0403 04:35:55.097105 23741 solver.cpp:228] Iteration 7605, loss = 0.00160657
I0403 04:35:55.097210 23741 solver.cpp:244]     Train net output #0: loss = 0.00160649 (* 1 = 0.00160649 loss)
I0403 04:35:55.278904 23741 sgd_solver.cpp:106] Iteration 7605, lr = 5e-05
I0403 04:36:04.538156 23741 solver.cpp:228] Iteration 7618, loss = 0.00155699
I0403 04:36:04.538272 23741 solver.cpp:244]     Train net output #0: loss = 0.00155692 (* 1 = 0.00155692 loss)
I0403 04:36:04.718329 23741 sgd_solver.cpp:106] Iteration 7618, lr = 5e-05
I0403 04:36:14.108520 23741 solver.cpp:228] Iteration 7631, loss = 0.00120852
I0403 04:36:14.108847 23741 solver.cpp:244]     Train net output #0: loss = 0.00120844 (* 1 = 0.00120844 loss)
I0403 04:36:14.266240 23741 sgd_solver.cpp:106] Iteration 7631, lr = 5e-05
I0403 04:36:23.754333 23741 solver.cpp:228] Iteration 7644, loss = 0.0044926
I0403 04:36:23.754443 23741 solver.cpp:244]     Train net output #0: loss = 0.00449253 (* 1 = 0.00449253 loss)
I0403 04:36:23.939831 23741 sgd_solver.cpp:106] Iteration 7644, lr = 5e-05
I0403 04:36:33.407963 23741 solver.cpp:228] Iteration 7657, loss = 0.00308929
I0403 04:36:33.408063 23741 solver.cpp:244]     Train net output #0: loss = 0.00308921 (* 1 = 0.00308921 loss)
I0403 04:36:33.586571 23741 sgd_solver.cpp:106] Iteration 7657, lr = 5e-05
I0403 04:36:42.913739 23741 solver.cpp:228] Iteration 7670, loss = 0.00312458
I0403 04:36:42.913841 23741 solver.cpp:244]     Train net output #0: loss = 0.0031245 (* 1 = 0.0031245 loss)
I0403 04:36:43.094605 23741 sgd_solver.cpp:106] Iteration 7670, lr = 5e-05
I0403 04:36:52.667670 23741 solver.cpp:228] Iteration 7683, loss = 0.00288259
I0403 04:36:52.668038 23741 solver.cpp:244]     Train net output #0: loss = 0.00288252 (* 1 = 0.00288252 loss)
I0403 04:36:52.850742 23741 sgd_solver.cpp:106] Iteration 7683, lr = 5e-05
I0403 04:37:02.140434 23741 solver.cpp:228] Iteration 7696, loss = 0.00890277
I0403 04:37:02.140542 23741 solver.cpp:244]     Train net output #0: loss = 0.0089027 (* 1 = 0.0089027 loss)
I0403 04:37:02.325115 23741 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 04:37:11.709790 23741 solver.cpp:228] Iteration 7709, loss = 0.02003
I0403 04:37:11.709893 23741 solver.cpp:244]     Train net output #0: loss = 0.0200299 (* 1 = 0.0200299 loss)
I0403 04:37:11.887508 23741 sgd_solver.cpp:106] Iteration 7709, lr = 5e-05
I0403 04:37:21.185842 23741 solver.cpp:228] Iteration 7722, loss = 0.00527114
I0403 04:37:21.185955 23741 solver.cpp:244]     Train net output #0: loss = 0.00527106 (* 1 = 0.00527106 loss)
I0403 04:37:21.381664 23741 sgd_solver.cpp:106] Iteration 7722, lr = 5e-05
I0403 04:37:30.643265 23741 solver.cpp:228] Iteration 7735, loss = 0.0125275
I0403 04:37:30.643590 23741 solver.cpp:244]     Train net output #0: loss = 0.0125274 (* 1 = 0.0125274 loss)
I0403 04:37:30.810891 23741 sgd_solver.cpp:106] Iteration 7735, lr = 5e-05
I0403 04:37:36.056375 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_7743.caffemodel
I0403 04:37:38.916910 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_7743.solverstate
I0403 04:37:40.822649 23741 solver.cpp:337] Iteration 7743, Testing net (#0)
I0403 04:38:43.112263 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966328
I0403 04:38:43.112645 23741 solver.cpp:404]     Test net output #1: loss = 0.123063 (* 1 = 0.123063 loss)
I0403 04:38:47.339373 23741 solver.cpp:228] Iteration 7748, loss = 0.0031005
I0403 04:38:47.339491 23741 solver.cpp:244]     Train net output #0: loss = 0.00310042 (* 1 = 0.00310042 loss)
I0403 04:38:47.546419 23741 sgd_solver.cpp:106] Iteration 7748, lr = 5e-05
I0403 04:38:56.844523 23741 solver.cpp:228] Iteration 7761, loss = 0.00580031
I0403 04:38:56.844630 23741 solver.cpp:244]     Train net output #0: loss = 0.00580024 (* 1 = 0.00580024 loss)
I0403 04:38:57.032500 23741 sgd_solver.cpp:106] Iteration 7761, lr = 5e-05
I0403 04:39:06.404361 23741 solver.cpp:228] Iteration 7774, loss = 0.00343291
I0403 04:39:06.404463 23741 solver.cpp:244]     Train net output #0: loss = 0.00343283 (* 1 = 0.00343283 loss)
I0403 04:39:06.586115 23741 sgd_solver.cpp:106] Iteration 7774, lr = 5e-05
I0403 04:39:15.930037 23741 solver.cpp:228] Iteration 7787, loss = 0.0038005
I0403 04:39:15.930351 23741 solver.cpp:244]     Train net output #0: loss = 0.00380042 (* 1 = 0.00380042 loss)
I0403 04:39:16.120192 23741 sgd_solver.cpp:106] Iteration 7787, lr = 5e-05
I0403 04:39:25.323016 23741 solver.cpp:228] Iteration 7800, loss = 0.000468046
I0403 04:39:25.323115 23741 solver.cpp:244]     Train net output #0: loss = 0.000467968 (* 1 = 0.000467968 loss)
I0403 04:39:25.502776 23741 sgd_solver.cpp:106] Iteration 7800, lr = 5e-05
I0403 04:39:34.812079 23741 solver.cpp:228] Iteration 7813, loss = 0.0102188
I0403 04:39:34.812191 23741 solver.cpp:244]     Train net output #0: loss = 0.0102187 (* 1 = 0.0102187 loss)
I0403 04:39:35.033954 23741 sgd_solver.cpp:106] Iteration 7813, lr = 5e-05
I0403 04:39:44.383611 23741 solver.cpp:228] Iteration 7826, loss = 0.001794
I0403 04:39:44.383714 23741 solver.cpp:244]     Train net output #0: loss = 0.00179392 (* 1 = 0.00179392 loss)
I0403 04:39:44.563586 23741 sgd_solver.cpp:106] Iteration 7826, lr = 5e-05
I0403 04:39:53.761247 23741 solver.cpp:228] Iteration 7839, loss = 0.00176834
I0403 04:39:53.761775 23741 solver.cpp:244]     Train net output #0: loss = 0.00176826 (* 1 = 0.00176826 loss)
I0403 04:39:53.969949 23741 sgd_solver.cpp:106] Iteration 7839, lr = 5e-05
I0403 04:40:03.194352 23741 solver.cpp:228] Iteration 7852, loss = 0.00376465
I0403 04:40:03.194458 23741 solver.cpp:244]     Train net output #0: loss = 0.00376457 (* 1 = 0.00376457 loss)
I0403 04:40:03.378739 23741 sgd_solver.cpp:106] Iteration 7852, lr = 5e-05
I0403 04:40:12.680141 23741 solver.cpp:228] Iteration 7865, loss = 0.00394971
I0403 04:40:12.680291 23741 solver.cpp:244]     Train net output #0: loss = 0.00394963 (* 1 = 0.00394963 loss)
I0403 04:40:12.850781 23741 sgd_solver.cpp:106] Iteration 7865, lr = 5e-05
I0403 04:40:22.243958 23741 solver.cpp:228] Iteration 7878, loss = 0.0193524
I0403 04:40:22.244070 23741 solver.cpp:244]     Train net output #0: loss = 0.0193523 (* 1 = 0.0193523 loss)
I0403 04:40:22.441685 23741 sgd_solver.cpp:106] Iteration 7878, lr = 5e-05
I0403 04:40:31.798355 23741 solver.cpp:228] Iteration 7891, loss = 0.0022059
I0403 04:40:31.798673 23741 solver.cpp:244]     Train net output #0: loss = 0.00220583 (* 1 = 0.00220583 loss)
I0403 04:40:31.966938 23741 sgd_solver.cpp:106] Iteration 7891, lr = 5e-05
I0403 04:40:41.329223 23741 solver.cpp:228] Iteration 7904, loss = 0.00325725
I0403 04:40:41.329330 23741 solver.cpp:244]     Train net output #0: loss = 0.00325717 (* 1 = 0.00325717 loss)
I0403 04:40:41.509425 23741 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 04:40:50.812340 23741 solver.cpp:228] Iteration 7917, loss = 0.0409055
I0403 04:40:50.812445 23741 solver.cpp:244]     Train net output #0: loss = 0.0409054 (* 1 = 0.0409054 loss)
I0403 04:40:51.000740 23741 sgd_solver.cpp:106] Iteration 7917, lr = 5e-05
I0403 04:41:00.226963 23741 solver.cpp:228] Iteration 7930, loss = 0.00187584
I0403 04:41:00.227061 23741 solver.cpp:244]     Train net output #0: loss = 0.00187577 (* 1 = 0.00187577 loss)
I0403 04:41:00.398911 23741 sgd_solver.cpp:106] Iteration 7930, lr = 5e-05
I0403 04:41:09.673295 23741 solver.cpp:228] Iteration 7943, loss = 0.0189014
I0403 04:41:09.673622 23741 solver.cpp:244]     Train net output #0: loss = 0.0189013 (* 1 = 0.0189013 loss)
I0403 04:41:09.849447 23741 sgd_solver.cpp:106] Iteration 7943, lr = 5e-05
I0403 04:41:19.230201 23741 solver.cpp:228] Iteration 7956, loss = 0.000972514
I0403 04:41:19.230306 23741 solver.cpp:244]     Train net output #0: loss = 0.000972436 (* 1 = 0.000972436 loss)
I0403 04:41:19.422632 23741 sgd_solver.cpp:106] Iteration 7956, lr = 5e-05
I0403 04:41:28.816903 23741 solver.cpp:228] Iteration 7969, loss = 0.00239915
I0403 04:41:28.817011 23741 solver.cpp:244]     Train net output #0: loss = 0.00239908 (* 1 = 0.00239908 loss)
I0403 04:41:29.019583 23741 sgd_solver.cpp:106] Iteration 7969, lr = 5e-05
I0403 04:41:38.173974 23741 solver.cpp:228] Iteration 7982, loss = 0.0123484
I0403 04:41:38.174084 23741 solver.cpp:244]     Train net output #0: loss = 0.0123483 (* 1 = 0.0123483 loss)
I0403 04:41:38.369283 23741 sgd_solver.cpp:106] Iteration 7982, lr = 5e-05
I0403 04:41:47.630410 23741 solver.cpp:228] Iteration 7995, loss = 0.000485148
I0403 04:41:47.630736 23741 solver.cpp:244]     Train net output #0: loss = 0.000485068 (* 1 = 0.000485068 loss)
I0403 04:41:47.811908 23741 sgd_solver.cpp:106] Iteration 7995, lr = 5e-05
I0403 04:41:57.180371 23741 solver.cpp:228] Iteration 8008, loss = 0.000477278
I0403 04:41:57.180475 23741 solver.cpp:244]     Train net output #0: loss = 0.000477199 (* 1 = 0.000477199 loss)
I0403 04:41:57.374802 23741 sgd_solver.cpp:106] Iteration 8008, lr = 5e-05
I0403 04:41:58.136445 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_8010.caffemodel
I0403 04:42:00.893399 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_8010.solverstate
I0403 04:42:02.728464 23741 solver.cpp:337] Iteration 8010, Testing net (#0)
I0403 04:43:05.026939 23741 solver.cpp:404]     Test net output #0: accuracy = 0.966255
I0403 04:43:05.027328 23741 solver.cpp:404]     Test net output #1: loss = 0.12266 (* 1 = 0.12266 loss)
I0403 04:43:13.639026 23741 solver.cpp:228] Iteration 8021, loss = 0.00924423
I0403 04:43:13.639133 23741 solver.cpp:244]     Train net output #0: loss = 0.00924415 (* 1 = 0.00924415 loss)
I0403 04:43:13.827250 23741 sgd_solver.cpp:106] Iteration 8021, lr = 5e-05
I0403 04:43:14.558802 23741 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_8023.caffemodel
I0403 04:43:17.213181 23741 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_finetune/snapshots__iter_8023.solverstate
I0403 04:43:19.001792 23741 solver.cpp:322] Optimization Done.
I0403 04:43:19.083125 23741 caffe.cpp:222] Optimization Done.
