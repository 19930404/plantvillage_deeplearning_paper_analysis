I0403 08:23:11.196533  8106 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 08:23:11.196967  8106 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 08:23:11.196995  8106 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 08:23:15.722307  8106 caffe.cpp:185] Using GPUs 0, 1
I0403 08:23:15.722888  8106 caffe.cpp:190] GPU 0: Tesla K40m
I0403 08:23:15.723358  8106 caffe.cpp:190] GPU 1: Tesla K40m
I0403 08:23:15.975989  8106 solver.cpp:48] Initializing solver from parameters: 
test_iter: 275
test_interval: 267
base_lr: 0.005
display: 13
max_iter: 8023
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2674
snapshot: 267
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 08:23:15.989086  8106 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 08:23:16.000453  8106 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 08:23:16.000599  8106 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 08:23:16.002243  8106 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 08:23:16.003036  8106 layer_factory.hpp:77] Creating layer data
I0403 08:23:16.004714  8106 net.cpp:91] Creating Layer data
I0403 08:23:16.004802  8106 net.cpp:399] data -> data
I0403 08:23:16.004927  8106 net.cpp:399] data -> label
I0403 08:23:16.005012  8106 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto
I0403 08:23:16.069759  8109 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/train_db
I0403 08:23:16.074039  8106 data_layer.cpp:41] output data size: 100,3,227,227
I0403 08:23:16.212666  8106 net.cpp:141] Setting up data
I0403 08:23:16.212770  8106 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 08:23:16.212797  8106 net.cpp:148] Top shape: 100 (100)
I0403 08:23:16.212818  8106 net.cpp:156] Memory required for data: 61835200
I0403 08:23:16.212855  8106 layer_factory.hpp:77] Creating layer conv1
I0403 08:23:16.212908  8106 net.cpp:91] Creating Layer conv1
I0403 08:23:16.212936  8106 net.cpp:425] conv1 <- data
I0403 08:23:16.212975  8106 net.cpp:399] conv1 -> conv1
I0403 08:23:16.216130  8106 net.cpp:141] Setting up conv1
I0403 08:23:16.216167  8106 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:23:16.216187  8106 net.cpp:156] Memory required for data: 177995200
I0403 08:23:16.216230  8106 layer_factory.hpp:77] Creating layer relu1
I0403 08:23:16.216264  8106 net.cpp:91] Creating Layer relu1
I0403 08:23:16.216285  8106 net.cpp:425] relu1 <- conv1
I0403 08:23:16.216307  8106 net.cpp:386] relu1 -> conv1 (in-place)
I0403 08:23:16.216336  8106 net.cpp:141] Setting up relu1
I0403 08:23:16.216359  8106 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:23:16.216377  8106 net.cpp:156] Memory required for data: 294155200
I0403 08:23:16.216394  8106 layer_factory.hpp:77] Creating layer norm1
I0403 08:23:16.216455  8106 net.cpp:91] Creating Layer norm1
I0403 08:23:16.216476  8106 net.cpp:425] norm1 <- conv1
I0403 08:23:16.216500  8106 net.cpp:399] norm1 -> norm1
I0403 08:23:16.222056  8106 net.cpp:141] Setting up norm1
I0403 08:23:16.222087  8106 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:23:16.222105  8106 net.cpp:156] Memory required for data: 410315200
I0403 08:23:16.222123  8106 layer_factory.hpp:77] Creating layer pool1
I0403 08:23:16.222149  8106 net.cpp:91] Creating Layer pool1
I0403 08:23:16.222170  8106 net.cpp:425] pool1 <- norm1
I0403 08:23:16.222192  8106 net.cpp:399] pool1 -> pool1
I0403 08:23:16.222266  8106 net.cpp:141] Setting up pool1
I0403 08:23:16.222296  8106 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 08:23:16.222316  8106 net.cpp:156] Memory required for data: 438308800
I0403 08:23:16.222334  8106 layer_factory.hpp:77] Creating layer conv2
I0403 08:23:16.222362  8106 net.cpp:91] Creating Layer conv2
I0403 08:23:16.222383  8106 net.cpp:425] conv2 <- pool1
I0403 08:23:16.222407  8106 net.cpp:399] conv2 -> conv2
I0403 08:23:16.224184  8110 blocking_queue.cpp:50] Waiting for data
I0403 08:23:16.241509  8106 net.cpp:141] Setting up conv2
I0403 08:23:16.241550  8106 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:23:16.241572  8106 net.cpp:156] Memory required for data: 512958400
I0403 08:23:16.241598  8106 layer_factory.hpp:77] Creating layer relu2
I0403 08:23:16.241623  8106 net.cpp:91] Creating Layer relu2
I0403 08:23:16.241644  8106 net.cpp:425] relu2 <- conv2
I0403 08:23:16.241667  8106 net.cpp:386] relu2 -> conv2 (in-place)
I0403 08:23:16.241690  8106 net.cpp:141] Setting up relu2
I0403 08:23:16.241713  8106 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:23:16.241730  8106 net.cpp:156] Memory required for data: 587608000
I0403 08:23:16.241749  8106 layer_factory.hpp:77] Creating layer norm2
I0403 08:23:16.241772  8106 net.cpp:91] Creating Layer norm2
I0403 08:23:16.241791  8106 net.cpp:425] norm2 <- conv2
I0403 08:23:16.241813  8106 net.cpp:399] norm2 -> norm2
I0403 08:23:16.241870  8106 net.cpp:141] Setting up norm2
I0403 08:23:16.241897  8106 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:23:16.241915  8106 net.cpp:156] Memory required for data: 662257600
I0403 08:23:16.241932  8106 layer_factory.hpp:77] Creating layer pool2
I0403 08:23:16.241957  8106 net.cpp:91] Creating Layer pool2
I0403 08:23:16.241977  8106 net.cpp:425] pool2 <- norm2
I0403 08:23:16.242000  8106 net.cpp:399] pool2 -> pool2
I0403 08:23:16.242053  8106 net.cpp:141] Setting up pool2
I0403 08:23:16.242080  8106 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:23:16.242099  8106 net.cpp:156] Memory required for data: 679563200
I0403 08:23:16.242116  8106 layer_factory.hpp:77] Creating layer conv3
I0403 08:23:16.242143  8106 net.cpp:91] Creating Layer conv3
I0403 08:23:16.242164  8106 net.cpp:425] conv3 <- pool2
I0403 08:23:16.242189  8106 net.cpp:399] conv3 -> conv3
I0403 08:23:16.283956  8106 net.cpp:141] Setting up conv3
I0403 08:23:16.283993  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:16.284013  8106 net.cpp:156] Memory required for data: 705521600
I0403 08:23:16.284040  8106 layer_factory.hpp:77] Creating layer relu3
I0403 08:23:16.284065  8106 net.cpp:91] Creating Layer relu3
I0403 08:23:16.284085  8106 net.cpp:425] relu3 <- conv3
I0403 08:23:16.284106  8106 net.cpp:386] relu3 -> conv3 (in-place)
I0403 08:23:16.284128  8106 net.cpp:141] Setting up relu3
I0403 08:23:16.284149  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:16.284168  8106 net.cpp:156] Memory required for data: 731480000
I0403 08:23:16.284186  8106 layer_factory.hpp:77] Creating layer conv4
I0403 08:23:16.284214  8106 net.cpp:91] Creating Layer conv4
I0403 08:23:16.284235  8106 net.cpp:425] conv4 <- conv3
I0403 08:23:16.284260  8106 net.cpp:399] conv4 -> conv4
I0403 08:23:16.315706  8106 net.cpp:141] Setting up conv4
I0403 08:23:16.315743  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:16.315765  8106 net.cpp:156] Memory required for data: 757438400
I0403 08:23:16.315807  8106 layer_factory.hpp:77] Creating layer relu4
I0403 08:23:16.315834  8106 net.cpp:91] Creating Layer relu4
I0403 08:23:16.315853  8106 net.cpp:425] relu4 <- conv4
I0403 08:23:16.315876  8106 net.cpp:386] relu4 -> conv4 (in-place)
I0403 08:23:16.315899  8106 net.cpp:141] Setting up relu4
I0403 08:23:16.315922  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:16.315939  8106 net.cpp:156] Memory required for data: 783396800
I0403 08:23:16.315958  8106 layer_factory.hpp:77] Creating layer conv5
I0403 08:23:16.315986  8106 net.cpp:91] Creating Layer conv5
I0403 08:23:16.316006  8106 net.cpp:425] conv5 <- conv4
I0403 08:23:16.316030  8106 net.cpp:399] conv5 -> conv5
I0403 08:23:16.337119  8106 net.cpp:141] Setting up conv5
I0403 08:23:16.337157  8106 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:23:16.337178  8106 net.cpp:156] Memory required for data: 800702400
I0403 08:23:16.337204  8106 layer_factory.hpp:77] Creating layer relu5
I0403 08:23:16.337229  8106 net.cpp:91] Creating Layer relu5
I0403 08:23:16.337249  8106 net.cpp:425] relu5 <- conv5
I0403 08:23:16.337270  8106 net.cpp:386] relu5 -> conv5 (in-place)
I0403 08:23:16.337294  8106 net.cpp:141] Setting up relu5
I0403 08:23:16.337316  8106 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:23:16.337333  8106 net.cpp:156] Memory required for data: 818008000
I0403 08:23:16.337352  8106 layer_factory.hpp:77] Creating layer pool5
I0403 08:23:16.337373  8106 net.cpp:91] Creating Layer pool5
I0403 08:23:16.337393  8106 net.cpp:425] pool5 <- conv5
I0403 08:23:16.337417  8106 net.cpp:399] pool5 -> pool5
I0403 08:23:16.337476  8106 net.cpp:141] Setting up pool5
I0403 08:23:16.337505  8106 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 08:23:16.337523  8106 net.cpp:156] Memory required for data: 821694400
I0403 08:23:16.337545  8106 layer_factory.hpp:77] Creating layer fc6
I0403 08:23:16.337582  8106 net.cpp:91] Creating Layer fc6
I0403 08:23:16.337605  8106 net.cpp:425] fc6 <- pool5
I0403 08:23:16.337631  8106 net.cpp:399] fc6 -> fc6
I0403 08:23:17.878368  8106 net.cpp:141] Setting up fc6
I0403 08:23:17.878458  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:17.878474  8106 net.cpp:156] Memory required for data: 823332800
I0403 08:23:17.878497  8106 layer_factory.hpp:77] Creating layer relu6
I0403 08:23:17.878532  8106 net.cpp:91] Creating Layer relu6
I0403 08:23:17.878552  8106 net.cpp:425] relu6 <- fc6
I0403 08:23:17.878572  8106 net.cpp:386] relu6 -> fc6 (in-place)
I0403 08:23:17.878594  8106 net.cpp:141] Setting up relu6
I0403 08:23:17.878612  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:17.878625  8106 net.cpp:156] Memory required for data: 824971200
I0403 08:23:17.878640  8106 layer_factory.hpp:77] Creating layer drop6
I0403 08:23:17.878667  8106 net.cpp:91] Creating Layer drop6
I0403 08:23:17.878684  8106 net.cpp:425] drop6 <- fc6
I0403 08:23:17.878701  8106 net.cpp:386] drop6 -> fc6 (in-place)
I0403 08:23:17.878746  8106 net.cpp:141] Setting up drop6
I0403 08:23:17.878770  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:17.878787  8106 net.cpp:156] Memory required for data: 826609600
I0403 08:23:17.878800  8106 layer_factory.hpp:77] Creating layer fc7
I0403 08:23:17.878821  8106 net.cpp:91] Creating Layer fc7
I0403 08:23:17.878837  8106 net.cpp:425] fc7 <- fc6
I0403 08:23:17.878854  8106 net.cpp:399] fc7 -> fc7
I0403 08:23:18.484287  8106 net.cpp:141] Setting up fc7
I0403 08:23:18.484370  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:18.484387  8106 net.cpp:156] Memory required for data: 828248000
I0403 08:23:18.484410  8106 layer_factory.hpp:77] Creating layer relu7
I0403 08:23:18.484434  8106 net.cpp:91] Creating Layer relu7
I0403 08:23:18.484452  8106 net.cpp:425] relu7 <- fc7
I0403 08:23:18.484472  8106 net.cpp:386] relu7 -> fc7 (in-place)
I0403 08:23:18.484493  8106 net.cpp:141] Setting up relu7
I0403 08:23:18.484520  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:18.484539  8106 net.cpp:156] Memory required for data: 829886400
I0403 08:23:18.484588  8106 layer_factory.hpp:77] Creating layer drop7
I0403 08:23:18.484611  8106 net.cpp:91] Creating Layer drop7
I0403 08:23:18.484629  8106 net.cpp:425] drop7 <- fc7
I0403 08:23:18.484645  8106 net.cpp:386] drop7 -> fc7 (in-place)
I0403 08:23:18.484686  8106 net.cpp:141] Setting up drop7
I0403 08:23:18.484709  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:18.484724  8106 net.cpp:156] Memory required for data: 831524800
I0403 08:23:18.484736  8106 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 08:23:18.484756  8106 net.cpp:91] Creating Layer fc8_plantvillage
I0403 08:23:18.484771  8106 net.cpp:425] fc8_plantvillage <- fc7
I0403 08:23:18.484791  8106 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 08:23:18.490774  8106 net.cpp:141] Setting up fc8_plantvillage
I0403 08:23:18.490804  8106 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:23:18.490820  8106 net.cpp:156] Memory required for data: 831540000
I0403 08:23:18.490839  8106 layer_factory.hpp:77] Creating layer loss
I0403 08:23:18.490862  8106 net.cpp:91] Creating Layer loss
I0403 08:23:18.490880  8106 net.cpp:425] loss <- fc8_plantvillage
I0403 08:23:18.490896  8106 net.cpp:425] loss <- label
I0403 08:23:18.490917  8106 net.cpp:399] loss -> loss
I0403 08:23:18.490943  8106 layer_factory.hpp:77] Creating layer loss
I0403 08:23:18.491045  8106 net.cpp:141] Setting up loss
I0403 08:23:18.491070  8106 net.cpp:148] Top shape: (1)
I0403 08:23:18.491085  8106 net.cpp:151]     with loss weight 1
I0403 08:23:18.491140  8106 net.cpp:156] Memory required for data: 831540004
I0403 08:23:18.491156  8106 net.cpp:217] loss needs backward computation.
I0403 08:23:18.491171  8106 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 08:23:18.491185  8106 net.cpp:217] drop7 needs backward computation.
I0403 08:23:18.491199  8106 net.cpp:217] relu7 needs backward computation.
I0403 08:23:18.491211  8106 net.cpp:217] fc7 needs backward computation.
I0403 08:23:18.491225  8106 net.cpp:217] drop6 needs backward computation.
I0403 08:23:18.491238  8106 net.cpp:217] relu6 needs backward computation.
I0403 08:23:18.491252  8106 net.cpp:217] fc6 needs backward computation.
I0403 08:23:18.491267  8106 net.cpp:217] pool5 needs backward computation.
I0403 08:23:18.491281  8106 net.cpp:217] relu5 needs backward computation.
I0403 08:23:18.491296  8106 net.cpp:217] conv5 needs backward computation.
I0403 08:23:18.491309  8106 net.cpp:217] relu4 needs backward computation.
I0403 08:23:18.491323  8106 net.cpp:217] conv4 needs backward computation.
I0403 08:23:18.491338  8106 net.cpp:217] relu3 needs backward computation.
I0403 08:23:18.491351  8106 net.cpp:217] conv3 needs backward computation.
I0403 08:23:18.491365  8106 net.cpp:217] pool2 needs backward computation.
I0403 08:23:18.491379  8106 net.cpp:217] norm2 needs backward computation.
I0403 08:23:18.491394  8106 net.cpp:217] relu2 needs backward computation.
I0403 08:23:18.491406  8106 net.cpp:217] conv2 needs backward computation.
I0403 08:23:18.491420  8106 net.cpp:217] pool1 needs backward computation.
I0403 08:23:18.491435  8106 net.cpp:217] norm1 needs backward computation.
I0403 08:23:18.491448  8106 net.cpp:217] relu1 needs backward computation.
I0403 08:23:18.491462  8106 net.cpp:217] conv1 needs backward computation.
I0403 08:23:18.491477  8106 net.cpp:219] data does not need backward computation.
I0403 08:23:18.491490  8106 net.cpp:261] This network produces output loss
I0403 08:23:18.491523  8106 net.cpp:274] Network initialization done.
I0403 08:23:18.492527  8106 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 08:23:18.492588  8106 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 08:23:18.493183  8106 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/grayscale-50-50/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 08:23:18.493342  8106 layer_factory.hpp:77] Creating layer data
I0403 08:23:18.493502  8106 net.cpp:91] Creating Layer data
I0403 08:23:18.493537  8106 net.cpp:399] data -> data
I0403 08:23:18.493562  8106 net.cpp:399] data -> label
I0403 08:23:18.493587  8106 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/mean.binaryproto
I0403 08:23:18.556053  8111 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/grayscale-50-50/test_db
I0403 08:23:18.562553  8106 data_layer.cpp:41] output data size: 100,3,227,227
I0403 08:23:18.685838  8106 net.cpp:141] Setting up data
I0403 08:23:18.685925  8106 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 08:23:18.685946  8106 net.cpp:148] Top shape: 100 (100)
I0403 08:23:18.685962  8106 net.cpp:156] Memory required for data: 61835200
I0403 08:23:18.685981  8106 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 08:23:18.686012  8106 net.cpp:91] Creating Layer label_data_1_split
I0403 08:23:18.686029  8106 net.cpp:425] label_data_1_split <- label
I0403 08:23:18.686053  8106 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 08:23:18.686079  8106 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 08:23:18.686138  8106 net.cpp:141] Setting up label_data_1_split
I0403 08:23:18.686163  8106 net.cpp:148] Top shape: 100 (100)
I0403 08:23:18.686182  8106 net.cpp:148] Top shape: 100 (100)
I0403 08:23:18.686197  8106 net.cpp:156] Memory required for data: 61836000
I0403 08:23:18.686213  8106 layer_factory.hpp:77] Creating layer conv1
I0403 08:23:18.686244  8106 net.cpp:91] Creating Layer conv1
I0403 08:23:18.686262  8106 net.cpp:425] conv1 <- data
I0403 08:23:18.686283  8106 net.cpp:399] conv1 -> conv1
I0403 08:23:18.687882  8106 net.cpp:141] Setting up conv1
I0403 08:23:18.687911  8106 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:23:18.687928  8106 net.cpp:156] Memory required for data: 177996000
I0403 08:23:18.687953  8106 layer_factory.hpp:77] Creating layer relu1
I0403 08:23:18.687975  8106 net.cpp:91] Creating Layer relu1
I0403 08:23:18.687993  8106 net.cpp:425] relu1 <- conv1
I0403 08:23:18.688011  8106 net.cpp:386] relu1 -> conv1 (in-place)
I0403 08:23:18.688032  8106 net.cpp:141] Setting up relu1
I0403 08:23:18.688051  8106 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:23:18.688066  8106 net.cpp:156] Memory required for data: 294156000
I0403 08:23:18.688082  8106 layer_factory.hpp:77] Creating layer norm1
I0403 08:23:18.688103  8106 net.cpp:91] Creating Layer norm1
I0403 08:23:18.688120  8106 net.cpp:425] norm1 <- conv1
I0403 08:23:18.688139  8106 net.cpp:399] norm1 -> norm1
I0403 08:23:18.694330  8106 net.cpp:141] Setting up norm1
I0403 08:23:18.694365  8106 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:23:18.694383  8106 net.cpp:156] Memory required for data: 410316000
I0403 08:23:18.694399  8106 layer_factory.hpp:77] Creating layer pool1
I0403 08:23:18.694421  8106 net.cpp:91] Creating Layer pool1
I0403 08:23:18.694437  8106 net.cpp:425] pool1 <- norm1
I0403 08:23:18.694455  8106 net.cpp:399] pool1 -> pool1
I0403 08:23:18.694505  8106 net.cpp:141] Setting up pool1
I0403 08:23:18.694535  8106 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 08:23:18.694550  8106 net.cpp:156] Memory required for data: 438309600
I0403 08:23:18.694588  8106 layer_factory.hpp:77] Creating layer conv2
I0403 08:23:18.694726  8106 net.cpp:91] Creating Layer conv2
I0403 08:23:18.694747  8106 net.cpp:425] conv2 <- pool1
I0403 08:23:18.694769  8106 net.cpp:399] conv2 -> conv2
I0403 08:23:18.706923  8106 net.cpp:141] Setting up conv2
I0403 08:23:18.706954  8106 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:23:18.706970  8106 net.cpp:156] Memory required for data: 512959200
I0403 08:23:18.706991  8106 layer_factory.hpp:77] Creating layer relu2
I0403 08:23:18.707011  8106 net.cpp:91] Creating Layer relu2
I0403 08:23:18.707028  8106 net.cpp:425] relu2 <- conv2
I0403 08:23:18.707046  8106 net.cpp:386] relu2 -> conv2 (in-place)
I0403 08:23:18.707067  8106 net.cpp:141] Setting up relu2
I0403 08:23:18.707084  8106 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:23:18.707098  8106 net.cpp:156] Memory required for data: 587608800
I0403 08:23:18.707113  8106 layer_factory.hpp:77] Creating layer norm2
I0403 08:23:18.707131  8106 net.cpp:91] Creating Layer norm2
I0403 08:23:18.707149  8106 net.cpp:425] norm2 <- conv2
I0403 08:23:18.707167  8106 net.cpp:399] norm2 -> norm2
I0403 08:23:18.707216  8106 net.cpp:141] Setting up norm2
I0403 08:23:18.707238  8106 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:23:18.707253  8106 net.cpp:156] Memory required for data: 662258400
I0403 08:23:18.707268  8106 layer_factory.hpp:77] Creating layer pool2
I0403 08:23:18.707288  8106 net.cpp:91] Creating Layer pool2
I0403 08:23:18.707304  8106 net.cpp:425] pool2 <- norm2
I0403 08:23:18.707321  8106 net.cpp:399] pool2 -> pool2
I0403 08:23:18.707376  8106 net.cpp:141] Setting up pool2
I0403 08:23:18.707403  8106 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:23:18.707425  8106 net.cpp:156] Memory required for data: 679564000
I0403 08:23:18.707443  8106 layer_factory.hpp:77] Creating layer conv3
I0403 08:23:18.707474  8106 net.cpp:91] Creating Layer conv3
I0403 08:23:18.707500  8106 net.cpp:425] conv3 <- pool2
I0403 08:23:18.707536  8106 net.cpp:399] conv3 -> conv3
I0403 08:23:18.742657  8106 net.cpp:141] Setting up conv3
I0403 08:23:18.757766  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:18.757802  8106 net.cpp:156] Memory required for data: 705522400
I0403 08:23:18.757836  8106 layer_factory.hpp:77] Creating layer relu3
I0403 08:23:18.757863  8106 net.cpp:91] Creating Layer relu3
I0403 08:23:18.757882  8106 net.cpp:425] relu3 <- conv3
I0403 08:23:18.757905  8106 net.cpp:386] relu3 -> conv3 (in-place)
I0403 08:23:18.757930  8106 net.cpp:141] Setting up relu3
I0403 08:23:18.757948  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:18.757964  8106 net.cpp:156] Memory required for data: 731480800
I0403 08:23:18.757979  8106 layer_factory.hpp:77] Creating layer conv4
I0403 08:23:18.758007  8106 net.cpp:91] Creating Layer conv4
I0403 08:23:18.758023  8106 net.cpp:425] conv4 <- conv3
I0403 08:23:18.758044  8106 net.cpp:399] conv4 -> conv4
I0403 08:23:18.786252  8106 net.cpp:141] Setting up conv4
I0403 08:23:18.786299  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:18.786317  8106 net.cpp:156] Memory required for data: 757439200
I0403 08:23:18.786339  8106 layer_factory.hpp:77] Creating layer relu4
I0403 08:23:18.786360  8106 net.cpp:91] Creating Layer relu4
I0403 08:23:18.786377  8106 net.cpp:425] relu4 <- conv4
I0403 08:23:18.786398  8106 net.cpp:386] relu4 -> conv4 (in-place)
I0403 08:23:18.786420  8106 net.cpp:141] Setting up relu4
I0403 08:23:18.786440  8106 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:23:18.786455  8106 net.cpp:156] Memory required for data: 783397600
I0403 08:23:18.786471  8106 layer_factory.hpp:77] Creating layer conv5
I0403 08:23:18.786496  8106 net.cpp:91] Creating Layer conv5
I0403 08:23:18.786519  8106 net.cpp:425] conv5 <- conv4
I0403 08:23:18.786541  8106 net.cpp:399] conv5 -> conv5
I0403 08:23:18.805126  8106 net.cpp:141] Setting up conv5
I0403 08:23:18.805160  8106 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:23:18.805210  8106 net.cpp:156] Memory required for data: 800703200
I0403 08:23:18.805236  8106 layer_factory.hpp:77] Creating layer relu5
I0403 08:23:18.805259  8106 net.cpp:91] Creating Layer relu5
I0403 08:23:18.805277  8106 net.cpp:425] relu5 <- conv5
I0403 08:23:18.805297  8106 net.cpp:386] relu5 -> conv5 (in-place)
I0403 08:23:18.805320  8106 net.cpp:141] Setting up relu5
I0403 08:23:18.805340  8106 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:23:18.805356  8106 net.cpp:156] Memory required for data: 818008800
I0403 08:23:18.805371  8106 layer_factory.hpp:77] Creating layer pool5
I0403 08:23:18.805397  8106 net.cpp:91] Creating Layer pool5
I0403 08:23:18.805416  8106 net.cpp:425] pool5 <- conv5
I0403 08:23:18.805438  8106 net.cpp:399] pool5 -> pool5
I0403 08:23:18.805495  8106 net.cpp:141] Setting up pool5
I0403 08:23:18.805588  8106 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 08:23:18.805611  8106 net.cpp:156] Memory required for data: 821695200
I0403 08:23:18.805629  8106 layer_factory.hpp:77] Creating layer fc6
I0403 08:23:18.805655  8106 net.cpp:91] Creating Layer fc6
I0403 08:23:18.805675  8106 net.cpp:425] fc6 <- pool5
I0403 08:23:18.805696  8106 net.cpp:399] fc6 -> fc6
I0403 08:23:20.195515  8106 net.cpp:141] Setting up fc6
I0403 08:23:20.195601  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:20.195621  8106 net.cpp:156] Memory required for data: 823333600
I0403 08:23:20.195642  8106 layer_factory.hpp:77] Creating layer relu6
I0403 08:23:20.195670  8106 net.cpp:91] Creating Layer relu6
I0403 08:23:20.195689  8106 net.cpp:425] relu6 <- fc6
I0403 08:23:20.195709  8106 net.cpp:386] relu6 -> fc6 (in-place)
I0403 08:23:20.195732  8106 net.cpp:141] Setting up relu6
I0403 08:23:20.195749  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:20.195763  8106 net.cpp:156] Memory required for data: 824972000
I0403 08:23:20.195777  8106 layer_factory.hpp:77] Creating layer drop6
I0403 08:23:20.195802  8106 net.cpp:91] Creating Layer drop6
I0403 08:23:20.195819  8106 net.cpp:425] drop6 <- fc6
I0403 08:23:20.195837  8106 net.cpp:386] drop6 -> fc6 (in-place)
I0403 08:23:20.195874  8106 net.cpp:141] Setting up drop6
I0403 08:23:20.195899  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:20.195914  8106 net.cpp:156] Memory required for data: 826610400
I0403 08:23:20.195929  8106 layer_factory.hpp:77] Creating layer fc7
I0403 08:23:20.195950  8106 net.cpp:91] Creating Layer fc7
I0403 08:23:20.195966  8106 net.cpp:425] fc7 <- fc6
I0403 08:23:20.195983  8106 net.cpp:399] fc7 -> fc7
I0403 08:23:20.799024  8106 net.cpp:141] Setting up fc7
I0403 08:23:20.799108  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:20.799124  8106 net.cpp:156] Memory required for data: 828248800
I0403 08:23:20.799146  8106 layer_factory.hpp:77] Creating layer relu7
I0403 08:23:20.799171  8106 net.cpp:91] Creating Layer relu7
I0403 08:23:20.799190  8106 net.cpp:425] relu7 <- fc7
I0403 08:23:20.799211  8106 net.cpp:386] relu7 -> fc7 (in-place)
I0403 08:23:20.799233  8106 net.cpp:141] Setting up relu7
I0403 08:23:20.799250  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:20.799264  8106 net.cpp:156] Memory required for data: 829887200
I0403 08:23:20.799278  8106 layer_factory.hpp:77] Creating layer drop7
I0403 08:23:20.799299  8106 net.cpp:91] Creating Layer drop7
I0403 08:23:20.799316  8106 net.cpp:425] drop7 <- fc7
I0403 08:23:20.799332  8106 net.cpp:386] drop7 -> fc7 (in-place)
I0403 08:23:20.799374  8106 net.cpp:141] Setting up drop7
I0403 08:23:20.799396  8106 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:23:20.799410  8106 net.cpp:156] Memory required for data: 831525600
I0403 08:23:20.799425  8106 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 08:23:20.799446  8106 net.cpp:91] Creating Layer fc8_plantvillage
I0403 08:23:20.799461  8106 net.cpp:425] fc8_plantvillage <- fc7
I0403 08:23:20.799481  8106 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 08:23:20.805639  8106 net.cpp:141] Setting up fc8_plantvillage
I0403 08:23:20.805668  8106 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:23:20.805716  8106 net.cpp:156] Memory required for data: 831540800
I0403 08:23:20.805735  8106 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 08:23:20.805755  8106 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 08:23:20.805771  8106 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 08:23:20.805788  8106 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 08:23:20.805807  8106 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 08:23:20.805856  8106 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 08:23:20.805879  8106 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:23:20.805896  8106 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:23:20.805908  8106 net.cpp:156] Memory required for data: 831571200
I0403 08:23:20.805922  8106 layer_factory.hpp:77] Creating layer loss
I0403 08:23:20.805939  8106 net.cpp:91] Creating Layer loss
I0403 08:23:20.805955  8106 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 08:23:20.805971  8106 net.cpp:425] loss <- label_data_1_split_0
I0403 08:23:20.805990  8106 net.cpp:399] loss -> loss
I0403 08:23:20.806015  8106 layer_factory.hpp:77] Creating layer loss
I0403 08:23:20.806102  8106 net.cpp:141] Setting up loss
I0403 08:23:20.806125  8106 net.cpp:148] Top shape: (1)
I0403 08:23:20.806139  8106 net.cpp:151]     with loss weight 1
I0403 08:23:20.806164  8106 net.cpp:156] Memory required for data: 831571204
I0403 08:23:20.806179  8106 layer_factory.hpp:77] Creating layer accuracy
I0403 08:23:20.806200  8106 net.cpp:91] Creating Layer accuracy
I0403 08:23:20.806216  8106 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 08:23:20.806232  8106 net.cpp:425] accuracy <- label_data_1_split_1
I0403 08:23:20.806249  8106 net.cpp:399] accuracy -> accuracy
I0403 08:23:20.806280  8106 net.cpp:141] Setting up accuracy
I0403 08:23:20.806301  8106 net.cpp:148] Top shape: (1)
I0403 08:23:20.806315  8106 net.cpp:156] Memory required for data: 831571208
I0403 08:23:20.806329  8106 net.cpp:219] accuracy does not need backward computation.
I0403 08:23:20.806342  8106 net.cpp:217] loss needs backward computation.
I0403 08:23:20.806357  8106 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 08:23:20.806371  8106 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 08:23:20.806386  8106 net.cpp:217] drop7 needs backward computation.
I0403 08:23:20.806401  8106 net.cpp:217] relu7 needs backward computation.
I0403 08:23:20.806413  8106 net.cpp:217] fc7 needs backward computation.
I0403 08:23:20.806427  8106 net.cpp:217] drop6 needs backward computation.
I0403 08:23:20.806440  8106 net.cpp:217] relu6 needs backward computation.
I0403 08:23:20.806454  8106 net.cpp:217] fc6 needs backward computation.
I0403 08:23:20.806468  8106 net.cpp:217] pool5 needs backward computation.
I0403 08:23:20.806483  8106 net.cpp:217] relu5 needs backward computation.
I0403 08:23:20.806498  8106 net.cpp:217] conv5 needs backward computation.
I0403 08:23:20.806517  8106 net.cpp:217] relu4 needs backward computation.
I0403 08:23:20.806534  8106 net.cpp:217] conv4 needs backward computation.
I0403 08:23:20.806547  8106 net.cpp:217] relu3 needs backward computation.
I0403 08:23:20.806562  8106 net.cpp:217] conv3 needs backward computation.
I0403 08:23:20.806577  8106 net.cpp:217] pool2 needs backward computation.
I0403 08:23:20.806591  8106 net.cpp:217] norm2 needs backward computation.
I0403 08:23:20.806604  8106 net.cpp:217] relu2 needs backward computation.
I0403 08:23:20.806618  8106 net.cpp:217] conv2 needs backward computation.
I0403 08:23:20.806632  8106 net.cpp:217] pool1 needs backward computation.
I0403 08:23:20.806648  8106 net.cpp:217] norm1 needs backward computation.
I0403 08:23:20.806661  8106 net.cpp:217] relu1 needs backward computation.
I0403 08:23:20.806675  8106 net.cpp:217] conv1 needs backward computation.
I0403 08:23:20.806702  8106 net.cpp:219] label_data_1_split does not need backward computation.
I0403 08:23:20.806720  8106 net.cpp:219] data does not need backward computation.
I0403 08:23:20.806733  8106 net.cpp:261] This network produces output accuracy
I0403 08:23:20.806748  8106 net.cpp:261] This network produces output loss
I0403 08:23:20.806777  8106 net.cpp:274] Network initialization done.
I0403 08:23:20.806886  8106 solver.cpp:60] Solver scaffolding done.
I0403 08:23:20.830601  8106 parallel.cpp:392] GPUs pairs 0:1
I0403 08:23:21.033910  8106 data_layer.cpp:41] output data size: 100,3,227,227
I0403 08:23:23.305704  8106 parallel.cpp:425] Starting Optimization
I0403 08:23:23.305862  8106 solver.cpp:279] Solving 
I0403 08:23:23.305886  8106 solver.cpp:280] Learning Rate Policy: step
I0403 08:23:23.306038  8106 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 08:24:25.403601  8106 solver.cpp:404]     Test net output #0: accuracy = 0.00505454
I0403 08:24:25.403786  8106 solver.cpp:404]     Test net output #1: loss = 3.64719 (* 1 = 3.64719 loss)
I0403 08:24:25.966173  8106 solver.cpp:228] Iteration 0, loss = 3.65674
I0403 08:24:25.966255  8106 solver.cpp:244]     Train net output #0: loss = 3.65674 (* 1 = 3.65674 loss)
I0403 08:24:26.130231  8106 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 08:24:35.429273  8106 solver.cpp:228] Iteration 13, loss = 3.3838
I0403 08:24:35.429357  8106 solver.cpp:244]     Train net output #0: loss = 3.3838 (* 1 = 3.3838 loss)
I0403 08:24:35.607081  8106 sgd_solver.cpp:106] Iteration 13, lr = 0.005
I0403 08:24:44.969864  8106 solver.cpp:228] Iteration 26, loss = 3.32827
I0403 08:24:44.969949  8106 solver.cpp:244]     Train net output #0: loss = 3.32827 (* 1 = 3.32827 loss)
I0403 08:24:45.147893  8106 sgd_solver.cpp:106] Iteration 26, lr = 0.005
I0403 08:24:54.316287  8106 solver.cpp:228] Iteration 39, loss = 3.31891
I0403 08:24:54.316372  8106 solver.cpp:244]     Train net output #0: loss = 3.31891 (* 1 = 3.31891 loss)
I0403 08:24:54.484170  8106 sgd_solver.cpp:106] Iteration 39, lr = 0.005
I0403 08:25:03.682018  8106 solver.cpp:228] Iteration 52, loss = 3.2144
I0403 08:25:03.682322  8106 solver.cpp:244]     Train net output #0: loss = 3.2144 (* 1 = 3.2144 loss)
I0403 08:25:03.881379  8106 sgd_solver.cpp:106] Iteration 52, lr = 0.005
I0403 08:25:12.994066  8106 solver.cpp:228] Iteration 65, loss = 3.1683
I0403 08:25:12.994165  8106 solver.cpp:244]     Train net output #0: loss = 3.1683 (* 1 = 3.1683 loss)
I0403 08:25:13.177949  8106 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 08:25:22.442935  8106 solver.cpp:228] Iteration 78, loss = 3.12305
I0403 08:25:22.443032  8106 solver.cpp:244]     Train net output #0: loss = 3.12305 (* 1 = 3.12305 loss)
I0403 08:25:22.632047  8106 sgd_solver.cpp:106] Iteration 78, lr = 0.005
I0403 08:25:31.868728  8106 solver.cpp:228] Iteration 91, loss = 2.89951
I0403 08:25:31.868823  8106 solver.cpp:244]     Train net output #0: loss = 2.89951 (* 1 = 2.89951 loss)
I0403 08:25:32.060020  8106 sgd_solver.cpp:106] Iteration 91, lr = 0.005
I0403 08:25:41.267334  8106 solver.cpp:228] Iteration 104, loss = 2.75088
I0403 08:25:41.267601  8106 solver.cpp:244]     Train net output #0: loss = 2.75088 (* 1 = 2.75088 loss)
I0403 08:25:41.424775  8106 sgd_solver.cpp:106] Iteration 104, lr = 0.005
I0403 08:25:50.739205  8106 solver.cpp:228] Iteration 117, loss = 2.79953
I0403 08:25:50.739297  8106 solver.cpp:244]     Train net output #0: loss = 2.79953 (* 1 = 2.79953 loss)
I0403 08:25:50.938923  8106 sgd_solver.cpp:106] Iteration 117, lr = 0.005
I0403 08:26:00.193536  8106 solver.cpp:228] Iteration 130, loss = 2.74399
I0403 08:26:00.193627  8106 solver.cpp:244]     Train net output #0: loss = 2.74399 (* 1 = 2.74399 loss)
I0403 08:26:00.369801  8106 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 08:26:09.846905  8106 solver.cpp:228] Iteration 143, loss = 2.91983
I0403 08:26:09.846992  8106 solver.cpp:244]     Train net output #0: loss = 2.91983 (* 1 = 2.91983 loss)
I0403 08:26:09.991622  8106 sgd_solver.cpp:106] Iteration 143, lr = 0.005
I0403 08:26:19.315335  8106 solver.cpp:228] Iteration 156, loss = 2.77213
I0403 08:26:19.315657  8106 solver.cpp:244]     Train net output #0: loss = 2.77213 (* 1 = 2.77213 loss)
I0403 08:26:19.521584  8106 sgd_solver.cpp:106] Iteration 156, lr = 0.005
I0403 08:26:28.842558  8106 solver.cpp:228] Iteration 169, loss = 2.44171
I0403 08:26:28.842644  8106 solver.cpp:244]     Train net output #0: loss = 2.44171 (* 1 = 2.44171 loss)
I0403 08:26:29.007171  8106 sgd_solver.cpp:106] Iteration 169, lr = 0.005
I0403 08:26:38.479423  8106 solver.cpp:228] Iteration 182, loss = 2.38001
I0403 08:26:38.479512  8106 solver.cpp:244]     Train net output #0: loss = 2.38001 (* 1 = 2.38001 loss)
I0403 08:26:38.652741  8106 sgd_solver.cpp:106] Iteration 182, lr = 0.005
I0403 08:26:48.010488  8106 solver.cpp:228] Iteration 195, loss = 2.36172
I0403 08:26:48.010581  8106 solver.cpp:244]     Train net output #0: loss = 2.36172 (* 1 = 2.36172 loss)
I0403 08:26:48.187624  8106 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 08:26:57.554570  8106 solver.cpp:228] Iteration 208, loss = 2.13614
I0403 08:26:57.554847  8106 solver.cpp:244]     Train net output #0: loss = 2.13614 (* 1 = 2.13614 loss)
I0403 08:26:57.728600  8106 sgd_solver.cpp:106] Iteration 208, lr = 0.005
I0403 08:27:07.092149  8106 solver.cpp:228] Iteration 221, loss = 2.01433
I0403 08:27:07.092245  8106 solver.cpp:244]     Train net output #0: loss = 2.01433 (* 1 = 2.01433 loss)
I0403 08:27:07.280550  8106 sgd_solver.cpp:106] Iteration 221, lr = 0.005
I0403 08:27:16.468950  8106 solver.cpp:228] Iteration 234, loss = 2.05055
I0403 08:27:16.469039  8106 solver.cpp:244]     Train net output #0: loss = 2.05055 (* 1 = 2.05055 loss)
I0403 08:27:16.641861  8106 sgd_solver.cpp:106] Iteration 234, lr = 0.005
I0403 08:27:26.125916  8106 solver.cpp:228] Iteration 247, loss = 1.94013
I0403 08:27:26.126010  8106 solver.cpp:244]     Train net output #0: loss = 1.94013 (* 1 = 1.94013 loss)
I0403 08:27:26.320052  8106 sgd_solver.cpp:106] Iteration 247, lr = 0.005
I0403 08:27:35.494424  8106 solver.cpp:228] Iteration 260, loss = 1.73147
I0403 08:27:35.494737  8106 solver.cpp:244]     Train net output #0: loss = 1.73147 (* 1 = 1.73147 loss)
I0403 08:27:35.706078  8106 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 08:27:40.049994  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_267.caffemodel
I0403 08:27:42.902688  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_267.solverstate
I0403 08:27:46.928797  8106 solver.cpp:337] Iteration 267, Testing net (#0)
I0403 08:28:48.998463  8106 solver.cpp:404]     Test net output #0: accuracy = 0.526727
I0403 08:28:48.998740  8106 solver.cpp:404]     Test net output #1: loss = 1.68146 (* 1 = 1.68146 loss)
I0403 08:28:53.829907  8106 solver.cpp:228] Iteration 273, loss = 1.91622
I0403 08:28:53.830001  8106 solver.cpp:244]     Train net output #0: loss = 1.91622 (* 1 = 1.91622 loss)
I0403 08:28:54.038863  8106 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 08:29:03.228885  8106 solver.cpp:228] Iteration 286, loss = 1.62114
I0403 08:29:03.228972  8106 solver.cpp:244]     Train net output #0: loss = 1.62114 (* 1 = 1.62114 loss)
I0403 08:29:03.379186  8106 sgd_solver.cpp:106] Iteration 286, lr = 0.005
I0403 08:29:12.780836  8106 solver.cpp:228] Iteration 299, loss = 1.63599
I0403 08:29:12.780920  8106 solver.cpp:244]     Train net output #0: loss = 1.63599 (* 1 = 1.63599 loss)
I0403 08:29:12.929814  8106 sgd_solver.cpp:106] Iteration 299, lr = 0.005
I0403 08:29:22.201550  8106 solver.cpp:228] Iteration 312, loss = 1.45662
I0403 08:29:22.201866  8106 solver.cpp:244]     Train net output #0: loss = 1.45662 (* 1 = 1.45662 loss)
I0403 08:29:22.391057  8106 sgd_solver.cpp:106] Iteration 312, lr = 0.005
I0403 08:29:31.572721  8106 solver.cpp:228] Iteration 325, loss = 1.53971
I0403 08:29:31.572808  8106 solver.cpp:244]     Train net output #0: loss = 1.53971 (* 1 = 1.53971 loss)
I0403 08:29:31.750468  8106 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 08:29:40.988420  8106 solver.cpp:228] Iteration 338, loss = 1.36071
I0403 08:29:40.988518  8106 solver.cpp:244]     Train net output #0: loss = 1.36071 (* 1 = 1.36071 loss)
I0403 08:29:41.206192  8106 sgd_solver.cpp:106] Iteration 338, lr = 0.005
I0403 08:29:50.461982  8106 solver.cpp:228] Iteration 351, loss = 1.61291
I0403 08:29:50.462067  8106 solver.cpp:244]     Train net output #0: loss = 1.61291 (* 1 = 1.61291 loss)
I0403 08:29:50.640609  8106 sgd_solver.cpp:106] Iteration 351, lr = 0.005
I0403 08:30:00.002651  8106 solver.cpp:228] Iteration 364, loss = 1.25448
I0403 08:30:00.002924  8106 solver.cpp:244]     Train net output #0: loss = 1.25448 (* 1 = 1.25448 loss)
I0403 08:30:00.184298  8106 sgd_solver.cpp:106] Iteration 364, lr = 0.005
I0403 08:30:09.446363  8106 solver.cpp:228] Iteration 377, loss = 1.41428
I0403 08:30:09.446450  8106 solver.cpp:244]     Train net output #0: loss = 1.41428 (* 1 = 1.41428 loss)
I0403 08:30:09.619551  8106 sgd_solver.cpp:106] Iteration 377, lr = 0.005
I0403 08:30:19.032443  8106 solver.cpp:228] Iteration 390, loss = 1.54244
I0403 08:30:19.032529  8106 solver.cpp:244]     Train net output #0: loss = 1.54244 (* 1 = 1.54244 loss)
I0403 08:30:19.204429  8106 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 08:30:28.531941  8106 solver.cpp:228] Iteration 403, loss = 1.35841
I0403 08:30:28.532032  8106 solver.cpp:244]     Train net output #0: loss = 1.35841 (* 1 = 1.35841 loss)
I0403 08:30:28.710400  8106 sgd_solver.cpp:106] Iteration 403, lr = 0.005
I0403 08:30:38.040895  8106 solver.cpp:228] Iteration 416, loss = 1.21318
I0403 08:30:38.041198  8106 solver.cpp:244]     Train net output #0: loss = 1.21318 (* 1 = 1.21318 loss)
I0403 08:30:38.231664  8106 sgd_solver.cpp:106] Iteration 416, lr = 0.005
I0403 08:30:47.400482  8106 solver.cpp:228] Iteration 429, loss = 1.43541
I0403 08:30:47.400575  8106 solver.cpp:244]     Train net output #0: loss = 1.43541 (* 1 = 1.43541 loss)
I0403 08:30:47.578917  8106 sgd_solver.cpp:106] Iteration 429, lr = 0.005
I0403 08:30:57.010947  8106 solver.cpp:228] Iteration 442, loss = 1.41166
I0403 08:30:57.011047  8106 solver.cpp:244]     Train net output #0: loss = 1.41166 (* 1 = 1.41166 loss)
I0403 08:30:57.203697  8106 sgd_solver.cpp:106] Iteration 442, lr = 0.005
I0403 08:31:06.445435  8106 solver.cpp:228] Iteration 455, loss = 1.22111
I0403 08:31:06.445523  8106 solver.cpp:244]     Train net output #0: loss = 1.22111 (* 1 = 1.22111 loss)
I0403 08:31:06.621090  8106 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 08:31:15.905777  8106 solver.cpp:228] Iteration 468, loss = 1.07519
I0403 08:31:15.906062  8106 solver.cpp:244]     Train net output #0: loss = 1.07519 (* 1 = 1.07519 loss)
I0403 08:31:16.073899  8106 sgd_solver.cpp:106] Iteration 468, lr = 0.005
I0403 08:31:25.414710  8106 solver.cpp:228] Iteration 481, loss = 0.971474
I0403 08:31:25.414806  8106 solver.cpp:244]     Train net output #0: loss = 0.971474 (* 1 = 0.971474 loss)
I0403 08:31:25.616307  8106 sgd_solver.cpp:106] Iteration 481, lr = 0.005
I0403 08:31:34.745558  8106 solver.cpp:228] Iteration 494, loss = 1.0946
I0403 08:31:34.745653  8106 solver.cpp:244]     Train net output #0: loss = 1.0946 (* 1 = 1.0946 loss)
I0403 08:31:34.929641  8106 sgd_solver.cpp:106] Iteration 494, lr = 0.005
I0403 08:31:44.072005  8106 solver.cpp:228] Iteration 507, loss = 1.06501
I0403 08:31:44.072091  8106 solver.cpp:244]     Train net output #0: loss = 1.06501 (* 1 = 1.06501 loss)
I0403 08:31:44.239398  8106 sgd_solver.cpp:106] Iteration 507, lr = 0.005
I0403 08:31:53.434819  8106 solver.cpp:228] Iteration 520, loss = 1.10966
I0403 08:31:53.435124  8106 solver.cpp:244]     Train net output #0: loss = 1.10966 (* 1 = 1.10966 loss)
I0403 08:31:53.603813  8106 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 08:32:02.849411  8106 solver.cpp:228] Iteration 533, loss = 0.882361
I0403 08:32:02.849496  8106 solver.cpp:244]     Train net output #0: loss = 0.882361 (* 1 = 0.882361 loss)
I0403 08:32:03.027784  8106 sgd_solver.cpp:106] Iteration 533, lr = 0.005
I0403 08:32:03.028023  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_534.caffemodel
I0403 08:32:05.721833  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_534.solverstate
I0403 08:32:07.570507  8106 solver.cpp:337] Iteration 534, Testing net (#0)
I0403 08:33:09.659003  8106 solver.cpp:404]     Test net output #0: accuracy = 0.715637
I0403 08:33:09.659329  8106 solver.cpp:404]     Test net output #1: loss = 0.915778 (* 1 = 0.915778 loss)
I0403 08:33:19.125625  8106 solver.cpp:228] Iteration 546, loss = 0.973785
I0403 08:33:19.125715  8106 solver.cpp:244]     Train net output #0: loss = 0.973785 (* 1 = 0.973785 loss)
I0403 08:33:19.301172  8106 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 08:33:28.502986  8106 solver.cpp:228] Iteration 559, loss = 0.899741
I0403 08:33:28.503085  8106 solver.cpp:244]     Train net output #0: loss = 0.899741 (* 1 = 0.899741 loss)
I0403 08:33:28.704042  8106 sgd_solver.cpp:106] Iteration 559, lr = 0.005
I0403 08:33:38.052553  8106 solver.cpp:228] Iteration 572, loss = 1.03832
I0403 08:33:38.052641  8106 solver.cpp:244]     Train net output #0: loss = 1.03832 (* 1 = 1.03832 loss)
I0403 08:33:38.220494  8106 sgd_solver.cpp:106] Iteration 572, lr = 0.005
I0403 08:33:47.503628  8106 solver.cpp:228] Iteration 585, loss = 1.01451
I0403 08:33:47.503911  8106 solver.cpp:244]     Train net output #0: loss = 1.01451 (* 1 = 1.01451 loss)
I0403 08:33:47.679918  8106 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 08:33:56.984295  8106 solver.cpp:228] Iteration 598, loss = 0.943018
I0403 08:33:56.984381  8106 solver.cpp:244]     Train net output #0: loss = 0.943018 (* 1 = 0.943018 loss)
I0403 08:33:57.151335  8106 sgd_solver.cpp:106] Iteration 598, lr = 0.005
I0403 08:34:06.674588  8106 solver.cpp:228] Iteration 611, loss = 1.26191
I0403 08:34:06.674676  8106 solver.cpp:244]     Train net output #0: loss = 1.26191 (* 1 = 1.26191 loss)
I0403 08:34:06.851862  8106 sgd_solver.cpp:106] Iteration 611, lr = 0.005
I0403 08:34:16.163568  8106 solver.cpp:228] Iteration 624, loss = 1.22806
I0403 08:34:16.163666  8106 solver.cpp:244]     Train net output #0: loss = 1.22806 (* 1 = 1.22806 loss)
I0403 08:34:16.365165  8106 sgd_solver.cpp:106] Iteration 624, lr = 0.005
I0403 08:34:25.670558  8106 solver.cpp:228] Iteration 637, loss = 0.814281
I0403 08:34:25.670860  8106 solver.cpp:244]     Train net output #0: loss = 0.814281 (* 1 = 0.814281 loss)
I0403 08:34:25.852273  8106 sgd_solver.cpp:106] Iteration 637, lr = 0.005
I0403 08:34:35.101294  8106 solver.cpp:228] Iteration 650, loss = 0.964142
I0403 08:34:35.101382  8106 solver.cpp:244]     Train net output #0: loss = 0.964142 (* 1 = 0.964142 loss)
I0403 08:34:35.276309  8106 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 08:34:44.502912  8106 solver.cpp:228] Iteration 663, loss = 0.934611
I0403 08:34:44.503000  8106 solver.cpp:244]     Train net output #0: loss = 0.934611 (* 1 = 0.934611 loss)
I0403 08:34:44.679252  8106 sgd_solver.cpp:106] Iteration 663, lr = 0.005
I0403 08:34:54.048532  8106 solver.cpp:228] Iteration 676, loss = 0.857024
I0403 08:34:54.048624  8106 solver.cpp:244]     Train net output #0: loss = 0.857024 (* 1 = 0.857024 loss)
I0403 08:34:54.222714  8106 sgd_solver.cpp:106] Iteration 676, lr = 0.005
I0403 08:35:03.460228  8106 solver.cpp:228] Iteration 689, loss = 0.761725
I0403 08:35:03.460523  8106 solver.cpp:244]     Train net output #0: loss = 0.761725 (* 1 = 0.761725 loss)
I0403 08:35:03.638197  8106 sgd_solver.cpp:106] Iteration 689, lr = 0.005
I0403 08:35:12.822736  8106 solver.cpp:228] Iteration 702, loss = 0.824417
I0403 08:35:12.822834  8106 solver.cpp:244]     Train net output #0: loss = 0.824417 (* 1 = 0.824417 loss)
I0403 08:35:13.020073  8106 sgd_solver.cpp:106] Iteration 702, lr = 0.005
I0403 08:35:22.360960  8106 solver.cpp:228] Iteration 715, loss = 0.655546
I0403 08:35:22.361047  8106 solver.cpp:244]     Train net output #0: loss = 0.655546 (* 1 = 0.655546 loss)
I0403 08:35:22.531519  8106 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 08:35:31.788875  8106 solver.cpp:228] Iteration 728, loss = 0.655395
I0403 08:35:31.788975  8106 solver.cpp:244]     Train net output #0: loss = 0.655395 (* 1 = 0.655395 loss)
I0403 08:35:31.970298  8106 sgd_solver.cpp:106] Iteration 728, lr = 0.005
I0403 08:35:41.229763  8106 solver.cpp:228] Iteration 741, loss = 0.686975
I0403 08:35:41.230078  8106 solver.cpp:244]     Train net output #0: loss = 0.686975 (* 1 = 0.686975 loss)
I0403 08:35:41.416601  8106 sgd_solver.cpp:106] Iteration 741, lr = 0.005
I0403 08:35:50.647789  8106 solver.cpp:228] Iteration 754, loss = 0.79701
I0403 08:35:50.647886  8106 solver.cpp:244]     Train net output #0: loss = 0.79701 (* 1 = 0.79701 loss)
I0403 08:35:50.829316  8106 sgd_solver.cpp:106] Iteration 754, lr = 0.005
I0403 08:36:00.067159  8106 solver.cpp:228] Iteration 767, loss = 0.622559
I0403 08:36:00.067250  8106 solver.cpp:244]     Train net output #0: loss = 0.622559 (* 1 = 0.622559 loss)
I0403 08:36:00.265460  8106 sgd_solver.cpp:106] Iteration 767, lr = 0.005
I0403 08:36:09.460670  8106 solver.cpp:228] Iteration 780, loss = 0.787914
I0403 08:36:09.460759  8106 solver.cpp:244]     Train net output #0: loss = 0.787914 (* 1 = 0.787914 loss)
I0403 08:36:09.639580  8106 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 08:36:18.965492  8106 solver.cpp:228] Iteration 793, loss = 0.724174
I0403 08:36:18.965786  8106 solver.cpp:244]     Train net output #0: loss = 0.724174 (* 1 = 0.724174 loss)
I0403 08:36:19.132442  8106 sgd_solver.cpp:106] Iteration 793, lr = 0.005
I0403 08:36:24.194093  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_801.caffemodel
I0403 08:36:26.916000  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_801.solverstate
I0403 08:36:28.788923  8106 solver.cpp:337] Iteration 801, Testing net (#0)
I0403 08:37:30.836890  8106 solver.cpp:404]     Test net output #0: accuracy = 0.7716
I0403 08:37:30.837147  8106 solver.cpp:404]     Test net output #1: loss = 0.737138 (* 1 = 0.737138 loss)
I0403 08:37:34.960553  8106 solver.cpp:228] Iteration 806, loss = 0.803944
I0403 08:37:34.960647  8106 solver.cpp:244]     Train net output #0: loss = 0.803944 (* 1 = 0.803944 loss)
I0403 08:37:35.180441  8106 sgd_solver.cpp:106] Iteration 806, lr = 0.005
I0403 08:37:44.360054  8106 solver.cpp:228] Iteration 819, loss = 0.8873
I0403 08:37:44.360152  8106 solver.cpp:244]     Train net output #0: loss = 0.8873 (* 1 = 0.8873 loss)
I0403 08:37:44.593183  8106 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 08:37:53.882995  8106 solver.cpp:228] Iteration 832, loss = 0.693433
I0403 08:37:53.883095  8106 solver.cpp:244]     Train net output #0: loss = 0.693433 (* 1 = 0.693433 loss)
I0403 08:37:54.116034  8106 sgd_solver.cpp:106] Iteration 832, lr = 0.005
I0403 08:38:03.273515  8106 solver.cpp:228] Iteration 845, loss = 0.794956
I0403 08:38:03.273823  8106 solver.cpp:244]     Train net output #0: loss = 0.794956 (* 1 = 0.794956 loss)
I0403 08:38:03.496582  8106 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 08:38:12.788432  8106 solver.cpp:228] Iteration 858, loss = 0.644832
I0403 08:38:12.788521  8106 solver.cpp:244]     Train net output #0: loss = 0.644832 (* 1 = 0.644832 loss)
I0403 08:38:12.967635  8106 sgd_solver.cpp:106] Iteration 858, lr = 0.005
I0403 08:38:22.269791  8106 solver.cpp:228] Iteration 871, loss = 0.733485
I0403 08:38:22.269891  8106 solver.cpp:244]     Train net output #0: loss = 0.733485 (* 1 = 0.733485 loss)
I0403 08:38:22.467208  8106 sgd_solver.cpp:106] Iteration 871, lr = 0.005
I0403 08:38:31.672644  8106 solver.cpp:228] Iteration 884, loss = 0.696597
I0403 08:38:31.672744  8106 solver.cpp:244]     Train net output #0: loss = 0.696597 (* 1 = 0.696597 loss)
I0403 08:38:31.876976  8106 sgd_solver.cpp:106] Iteration 884, lr = 0.005
I0403 08:38:41.073740  8106 solver.cpp:228] Iteration 897, loss = 0.654368
I0403 08:38:41.074064  8106 solver.cpp:244]     Train net output #0: loss = 0.654368 (* 1 = 0.654368 loss)
I0403 08:38:41.278373  8106 sgd_solver.cpp:106] Iteration 897, lr = 0.005
I0403 08:38:50.861023  8106 solver.cpp:228] Iteration 910, loss = 0.617808
I0403 08:38:50.861124  8106 solver.cpp:244]     Train net output #0: loss = 0.617808 (* 1 = 0.617808 loss)
I0403 08:38:51.044687  8106 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 08:39:00.303629  8106 solver.cpp:228] Iteration 923, loss = 0.716337
I0403 08:39:00.303728  8106 solver.cpp:244]     Train net output #0: loss = 0.716337 (* 1 = 0.716337 loss)
I0403 08:39:00.509655  8106 sgd_solver.cpp:106] Iteration 923, lr = 0.005
I0403 08:39:09.758733  8106 solver.cpp:228] Iteration 936, loss = 0.688707
I0403 08:39:09.758821  8106 solver.cpp:244]     Train net output #0: loss = 0.688707 (* 1 = 0.688707 loss)
I0403 08:39:09.937571  8106 sgd_solver.cpp:106] Iteration 936, lr = 0.005
I0403 08:39:19.189723  8106 solver.cpp:228] Iteration 949, loss = 0.760297
I0403 08:39:19.190022  8106 solver.cpp:244]     Train net output #0: loss = 0.760297 (* 1 = 0.760297 loss)
I0403 08:39:19.369676  8106 sgd_solver.cpp:106] Iteration 949, lr = 0.005
I0403 08:39:28.685936  8106 solver.cpp:228] Iteration 962, loss = 0.646861
I0403 08:39:28.686023  8106 solver.cpp:244]     Train net output #0: loss = 0.646861 (* 1 = 0.646861 loss)
I0403 08:39:28.863634  8106 sgd_solver.cpp:106] Iteration 962, lr = 0.005
I0403 08:39:38.089606  8106 solver.cpp:228] Iteration 975, loss = 0.782983
I0403 08:39:38.089700  8106 solver.cpp:244]     Train net output #0: loss = 0.782983 (* 1 = 0.782983 loss)
I0403 08:39:38.279820  8106 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 08:39:47.454771  8106 solver.cpp:228] Iteration 988, loss = 0.451808
I0403 08:39:47.454870  8106 solver.cpp:244]     Train net output #0: loss = 0.451808 (* 1 = 0.451808 loss)
I0403 08:39:47.660254  8106 sgd_solver.cpp:106] Iteration 988, lr = 0.005
I0403 08:39:56.876335  8106 solver.cpp:228] Iteration 1001, loss = 0.712348
I0403 08:39:56.876622  8106 solver.cpp:244]     Train net output #0: loss = 0.712348 (* 1 = 0.712348 loss)
I0403 08:39:57.058886  8106 sgd_solver.cpp:106] Iteration 1001, lr = 0.005
I0403 08:40:06.274454  8106 solver.cpp:228] Iteration 1014, loss = 0.490138
I0403 08:40:06.274559  8106 solver.cpp:244]     Train net output #0: loss = 0.490138 (* 1 = 0.490138 loss)
I0403 08:40:06.445390  8106 sgd_solver.cpp:106] Iteration 1014, lr = 0.005
I0403 08:40:15.758963  8106 solver.cpp:228] Iteration 1027, loss = 0.432034
I0403 08:40:15.759063  8106 solver.cpp:244]     Train net output #0: loss = 0.432034 (* 1 = 0.432034 loss)
I0403 08:40:15.986174  8106 sgd_solver.cpp:106] Iteration 1027, lr = 0.005
I0403 08:40:25.208160  8106 solver.cpp:228] Iteration 1040, loss = 0.717548
I0403 08:40:25.208257  8106 solver.cpp:244]     Train net output #0: loss = 0.717548 (* 1 = 0.717548 loss)
I0403 08:40:25.430357  8106 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 08:40:34.679592  8106 solver.cpp:228] Iteration 1053, loss = 0.546315
I0403 08:40:34.679883  8106 solver.cpp:244]     Train net output #0: loss = 0.546315 (* 1 = 0.546315 loss)
I0403 08:40:34.860431  8106 sgd_solver.cpp:106] Iteration 1053, lr = 0.005
I0403 08:40:44.136992  8106 solver.cpp:228] Iteration 1066, loss = 0.447217
I0403 08:40:44.137089  8106 solver.cpp:244]     Train net output #0: loss = 0.447217 (* 1 = 0.447217 loss)
I0403 08:40:44.357491  8106 sgd_solver.cpp:106] Iteration 1066, lr = 0.005
I0403 08:40:45.055948  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1068.caffemodel
I0403 08:40:47.878751  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1068.solverstate
I0403 08:40:49.707051  8106 solver.cpp:337] Iteration 1068, Testing net (#0)
I0403 08:41:51.771632  8106 solver.cpp:404]     Test net output #0: accuracy = 0.830437
I0403 08:41:51.772009  8106 solver.cpp:404]     Test net output #1: loss = 0.528908 (* 1 = 0.528908 loss)
I0403 08:42:00.321746  8106 solver.cpp:228] Iteration 1079, loss = 0.557922
I0403 08:42:00.321847  8106 solver.cpp:244]     Train net output #0: loss = 0.557922 (* 1 = 0.557922 loss)
I0403 08:42:00.557487  8106 sgd_solver.cpp:106] Iteration 1079, lr = 0.005
I0403 08:42:09.760411  8106 solver.cpp:228] Iteration 1092, loss = 0.770106
I0403 08:42:09.760498  8106 solver.cpp:244]     Train net output #0: loss = 0.770106 (* 1 = 0.770106 loss)
I0403 08:42:09.910693  8106 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 08:42:19.378641  8106 solver.cpp:228] Iteration 1105, loss = 0.543902
I0403 08:42:19.378728  8106 solver.cpp:244]     Train net output #0: loss = 0.543902 (* 1 = 0.543902 loss)
I0403 08:42:19.541282  8106 sgd_solver.cpp:106] Iteration 1105, lr = 0.005
I0403 08:42:28.785467  8106 solver.cpp:228] Iteration 1118, loss = 0.554771
I0403 08:42:28.785758  8106 solver.cpp:244]     Train net output #0: loss = 0.554771 (* 1 = 0.554771 loss)
I0403 08:42:28.973419  8106 sgd_solver.cpp:106] Iteration 1118, lr = 0.005
I0403 08:42:38.129122  8106 solver.cpp:228] Iteration 1131, loss = 0.562594
I0403 08:42:38.129220  8106 solver.cpp:244]     Train net output #0: loss = 0.562594 (* 1 = 0.562594 loss)
I0403 08:42:38.372707  8106 sgd_solver.cpp:106] Iteration 1131, lr = 0.005
I0403 08:42:47.704241  8106 solver.cpp:228] Iteration 1144, loss = 0.549722
I0403 08:42:47.704337  8106 solver.cpp:244]     Train net output #0: loss = 0.549722 (* 1 = 0.549722 loss)
I0403 08:42:47.901633  8106 sgd_solver.cpp:106] Iteration 1144, lr = 0.005
I0403 08:42:57.264714  8106 solver.cpp:228] Iteration 1157, loss = 0.290019
I0403 08:42:57.264799  8106 solver.cpp:244]     Train net output #0: loss = 0.290019 (* 1 = 0.290019 loss)
I0403 08:42:57.431588  8106 sgd_solver.cpp:106] Iteration 1157, lr = 0.005
I0403 08:43:06.625800  8106 solver.cpp:228] Iteration 1170, loss = 0.457145
I0403 08:43:06.626087  8106 solver.cpp:244]     Train net output #0: loss = 0.457145 (* 1 = 0.457145 loss)
I0403 08:43:06.785581  8106 sgd_solver.cpp:106] Iteration 1170, lr = 0.005
I0403 08:43:16.106025  8106 solver.cpp:228] Iteration 1183, loss = 0.402724
I0403 08:43:16.106118  8106 solver.cpp:244]     Train net output #0: loss = 0.402724 (* 1 = 0.402724 loss)
I0403 08:43:16.302803  8106 sgd_solver.cpp:106] Iteration 1183, lr = 0.005
I0403 08:43:25.518573  8106 solver.cpp:228] Iteration 1196, loss = 0.543627
I0403 08:43:25.518657  8106 solver.cpp:244]     Train net output #0: loss = 0.543627 (* 1 = 0.543627 loss)
I0403 08:43:25.699093  8106 sgd_solver.cpp:106] Iteration 1196, lr = 0.005
I0403 08:43:35.137143  8106 solver.cpp:228] Iteration 1209, loss = 0.342571
I0403 08:43:35.137231  8106 solver.cpp:244]     Train net output #0: loss = 0.342571 (* 1 = 0.342571 loss)
I0403 08:43:35.286187  8106 sgd_solver.cpp:106] Iteration 1209, lr = 0.005
I0403 08:43:44.835988  8106 solver.cpp:228] Iteration 1222, loss = 0.460568
I0403 08:43:44.836221  8106 solver.cpp:244]     Train net output #0: loss = 0.460568 (* 1 = 0.460568 loss)
I0403 08:43:45.020712  8106 sgd_solver.cpp:106] Iteration 1222, lr = 0.005
I0403 08:43:54.424391  8106 solver.cpp:228] Iteration 1235, loss = 0.321606
I0403 08:43:54.424487  8106 solver.cpp:244]     Train net output #0: loss = 0.321606 (* 1 = 0.321606 loss)
I0403 08:43:54.612721  8106 sgd_solver.cpp:106] Iteration 1235, lr = 0.005
I0403 08:44:04.150414  8106 solver.cpp:228] Iteration 1248, loss = 0.356888
I0403 08:44:04.150501  8106 solver.cpp:244]     Train net output #0: loss = 0.356888 (* 1 = 0.356888 loss)
I0403 08:44:04.300788  8106 sgd_solver.cpp:106] Iteration 1248, lr = 0.005
I0403 08:44:13.685600  8106 solver.cpp:228] Iteration 1261, loss = 0.402608
I0403 08:44:13.685703  8106 solver.cpp:244]     Train net output #0: loss = 0.402608 (* 1 = 0.402608 loss)
I0403 08:44:13.871251  8106 sgd_solver.cpp:106] Iteration 1261, lr = 0.005
I0403 08:44:23.164727  8106 solver.cpp:228] Iteration 1274, loss = 0.550358
I0403 08:44:23.165017  8106 solver.cpp:244]     Train net output #0: loss = 0.550358 (* 1 = 0.550358 loss)
I0403 08:44:23.331320  8106 sgd_solver.cpp:106] Iteration 1274, lr = 0.005
I0403 08:44:32.786963  8106 solver.cpp:228] Iteration 1287, loss = 0.493108
I0403 08:44:32.787060  8106 solver.cpp:244]     Train net output #0: loss = 0.493108 (* 1 = 0.493108 loss)
I0403 08:44:32.945410  8106 sgd_solver.cpp:106] Iteration 1287, lr = 0.005
I0403 08:44:42.301846  8106 solver.cpp:228] Iteration 1300, loss = 0.335551
I0403 08:44:42.301935  8106 solver.cpp:244]     Train net output #0: loss = 0.335551 (* 1 = 0.335551 loss)
I0403 08:44:42.453871  8106 sgd_solver.cpp:106] Iteration 1300, lr = 0.005
I0403 08:44:51.843909  8106 solver.cpp:228] Iteration 1313, loss = 0.459082
I0403 08:44:51.843998  8106 solver.cpp:244]     Train net output #0: loss = 0.459082 (* 1 = 0.459082 loss)
I0403 08:44:52.022027  8106 sgd_solver.cpp:106] Iteration 1313, lr = 0.005
I0403 08:45:01.300324  8106 solver.cpp:228] Iteration 1326, loss = 0.374931
I0403 08:45:01.300619  8106 solver.cpp:244]     Train net output #0: loss = 0.374931 (* 1 = 0.374931 loss)
I0403 08:45:01.479388  8106 sgd_solver.cpp:106] Iteration 1326, lr = 0.005
I0403 08:45:07.290200  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1335.caffemodel
I0403 08:45:10.056972  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1335.solverstate
I0403 08:45:11.853272  8106 solver.cpp:337] Iteration 1335, Testing net (#0)
I0403 08:46:13.927947  8106 solver.cpp:404]     Test net output #0: accuracy = 0.85731
I0403 08:46:13.928232  8106 solver.cpp:404]     Test net output #1: loss = 0.447043 (* 1 = 0.447043 loss)
I0403 08:46:17.310484  8106 solver.cpp:228] Iteration 1339, loss = 0.489461
I0403 08:46:17.310583  8106 solver.cpp:244]     Train net output #0: loss = 0.489461 (* 1 = 0.489461 loss)
I0403 08:46:17.493934  8106 sgd_solver.cpp:106] Iteration 1339, lr = 0.005
I0403 08:46:26.830325  8106 solver.cpp:228] Iteration 1352, loss = 0.392557
I0403 08:46:26.830420  8106 solver.cpp:244]     Train net output #0: loss = 0.392557 (* 1 = 0.392557 loss)
I0403 08:46:27.024647  8106 sgd_solver.cpp:106] Iteration 1352, lr = 0.005
I0403 08:46:36.230561  8106 solver.cpp:228] Iteration 1365, loss = 0.400271
I0403 08:46:36.230657  8106 solver.cpp:244]     Train net output #0: loss = 0.400271 (* 1 = 0.400271 loss)
I0403 08:46:36.420872  8106 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 08:46:45.743837  8106 solver.cpp:228] Iteration 1378, loss = 0.391617
I0403 08:46:45.744096  8106 solver.cpp:244]     Train net output #0: loss = 0.391617 (* 1 = 0.391617 loss)
I0403 08:46:45.912986  8106 sgd_solver.cpp:106] Iteration 1378, lr = 0.005
I0403 08:46:55.215042  8106 solver.cpp:228] Iteration 1391, loss = 0.412989
I0403 08:46:55.215128  8106 solver.cpp:244]     Train net output #0: loss = 0.412989 (* 1 = 0.412989 loss)
I0403 08:46:55.382639  8106 sgd_solver.cpp:106] Iteration 1391, lr = 0.005
I0403 08:47:04.961341  8106 solver.cpp:228] Iteration 1404, loss = 0.508556
I0403 08:47:04.961438  8106 solver.cpp:244]     Train net output #0: loss = 0.508556 (* 1 = 0.508556 loss)
I0403 08:47:05.158591  8106 sgd_solver.cpp:106] Iteration 1404, lr = 0.005
I0403 08:47:14.304692  8106 solver.cpp:228] Iteration 1417, loss = 0.264364
I0403 08:47:14.304779  8106 solver.cpp:244]     Train net output #0: loss = 0.264364 (* 1 = 0.264364 loss)
I0403 08:47:14.483433  8106 sgd_solver.cpp:106] Iteration 1417, lr = 0.005
I0403 08:47:23.678589  8106 solver.cpp:228] Iteration 1430, loss = 0.392858
I0403 08:47:23.678908  8106 solver.cpp:244]     Train net output #0: loss = 0.392858 (* 1 = 0.392858 loss)
I0403 08:47:23.852010  8106 sgd_solver.cpp:106] Iteration 1430, lr = 0.005
I0403 08:47:33.183701  8106 solver.cpp:228] Iteration 1443, loss = 0.382665
I0403 08:47:33.183789  8106 solver.cpp:244]     Train net output #0: loss = 0.382665 (* 1 = 0.382665 loss)
I0403 08:47:33.321306  8106 sgd_solver.cpp:106] Iteration 1443, lr = 0.005
I0403 08:47:42.803560  8106 solver.cpp:228] Iteration 1456, loss = 0.364399
I0403 08:47:42.803659  8106 solver.cpp:244]     Train net output #0: loss = 0.364399 (* 1 = 0.364399 loss)
I0403 08:47:43.016643  8106 sgd_solver.cpp:106] Iteration 1456, lr = 0.005
I0403 08:47:52.502766  8106 solver.cpp:228] Iteration 1469, loss = 0.323262
I0403 08:47:52.502856  8106 solver.cpp:244]     Train net output #0: loss = 0.323262 (* 1 = 0.323262 loss)
I0403 08:47:52.681454  8106 sgd_solver.cpp:106] Iteration 1469, lr = 0.005
I0403 08:48:01.902009  8106 solver.cpp:228] Iteration 1482, loss = 0.449845
I0403 08:48:01.902310  8106 solver.cpp:244]     Train net output #0: loss = 0.449845 (* 1 = 0.449845 loss)
I0403 08:48:02.082717  8106 sgd_solver.cpp:106] Iteration 1482, lr = 0.005
I0403 08:48:11.289294  8106 solver.cpp:228] Iteration 1495, loss = 0.431785
I0403 08:48:11.289394  8106 solver.cpp:244]     Train net output #0: loss = 0.431785 (* 1 = 0.431785 loss)
I0403 08:48:11.473225  8106 sgd_solver.cpp:106] Iteration 1495, lr = 0.005
I0403 08:48:20.672864  8106 solver.cpp:228] Iteration 1508, loss = 0.425235
I0403 08:48:20.672960  8106 solver.cpp:244]     Train net output #0: loss = 0.425235 (* 1 = 0.425235 loss)
I0403 08:48:20.876123  8106 sgd_solver.cpp:106] Iteration 1508, lr = 0.005
I0403 08:48:30.111479  8106 solver.cpp:228] Iteration 1521, loss = 0.542962
I0403 08:48:30.117328  8106 solver.cpp:244]     Train net output #0: loss = 0.542962 (* 1 = 0.542962 loss)
I0403 08:48:30.312420  8106 sgd_solver.cpp:106] Iteration 1521, lr = 0.005
I0403 08:48:39.620735  8106 solver.cpp:228] Iteration 1534, loss = 0.315453
I0403 08:48:39.621039  8106 solver.cpp:244]     Train net output #0: loss = 0.315453 (* 1 = 0.315453 loss)
I0403 08:48:39.781108  8106 sgd_solver.cpp:106] Iteration 1534, lr = 0.005
I0403 08:48:49.248381  8106 solver.cpp:228] Iteration 1547, loss = 0.407551
I0403 08:48:49.248468  8106 solver.cpp:244]     Train net output #0: loss = 0.407551 (* 1 = 0.407551 loss)
I0403 08:48:49.427119  8106 sgd_solver.cpp:106] Iteration 1547, lr = 0.005
I0403 08:48:58.587090  8106 solver.cpp:228] Iteration 1560, loss = 0.474376
I0403 08:48:58.587189  8106 solver.cpp:244]     Train net output #0: loss = 0.474376 (* 1 = 0.474376 loss)
I0403 08:48:58.788333  8106 sgd_solver.cpp:106] Iteration 1560, lr = 0.005
I0403 08:49:07.970367  8106 solver.cpp:228] Iteration 1573, loss = 0.465791
I0403 08:49:07.970454  8106 solver.cpp:244]     Train net output #0: loss = 0.465791 (* 1 = 0.465791 loss)
I0403 08:49:08.139570  8106 sgd_solver.cpp:106] Iteration 1573, lr = 0.005
I0403 08:49:17.460544  8106 solver.cpp:228] Iteration 1586, loss = 0.214406
I0403 08:49:17.460858  8106 solver.cpp:244]     Train net output #0: loss = 0.214406 (* 1 = 0.214406 loss)
I0403 08:49:17.644232  8106 sgd_solver.cpp:106] Iteration 1586, lr = 0.005
I0403 08:49:27.094152  8106 solver.cpp:228] Iteration 1599, loss = 0.499696
I0403 08:49:27.094249  8106 solver.cpp:244]     Train net output #0: loss = 0.499696 (* 1 = 0.499696 loss)
I0403 08:49:27.283052  8106 sgd_solver.cpp:106] Iteration 1599, lr = 0.005
I0403 08:49:28.729681  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1602.caffemodel
I0403 08:49:31.517879  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1602.solverstate
I0403 08:49:33.404507  8106 solver.cpp:337] Iteration 1602, Testing net (#0)
I0403 08:50:35.460929  8106 solver.cpp:404]     Test net output #0: accuracy = 0.876073
I0403 08:50:35.461262  8106 solver.cpp:404]     Test net output #1: loss = 0.393009 (* 1 = 0.393009 loss)
I0403 08:50:43.211144  8106 solver.cpp:228] Iteration 1612, loss = 0.54635
I0403 08:50:43.211232  8106 solver.cpp:244]     Train net output #0: loss = 0.54635 (* 1 = 0.54635 loss)
I0403 08:50:43.390322  8106 sgd_solver.cpp:106] Iteration 1612, lr = 0.005
I0403 08:50:52.502285  8106 solver.cpp:228] Iteration 1625, loss = 0.558394
I0403 08:50:52.502385  8106 solver.cpp:244]     Train net output #0: loss = 0.558394 (* 1 = 0.558394 loss)
I0403 08:50:52.718549  8106 sgd_solver.cpp:106] Iteration 1625, lr = 0.005
I0403 08:51:02.011518  8106 solver.cpp:228] Iteration 1638, loss = 0.35468
I0403 08:51:02.011621  8106 solver.cpp:244]     Train net output #0: loss = 0.35468 (* 1 = 0.35468 loss)
I0403 08:51:02.198684  8106 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 08:51:11.417958  8106 solver.cpp:228] Iteration 1651, loss = 0.344399
I0403 08:51:11.418247  8106 solver.cpp:244]     Train net output #0: loss = 0.344399 (* 1 = 0.344399 loss)
I0403 08:51:11.591981  8106 sgd_solver.cpp:106] Iteration 1651, lr = 0.005
I0403 08:51:20.864032  8106 solver.cpp:228] Iteration 1664, loss = 0.298898
I0403 08:51:20.864122  8106 solver.cpp:244]     Train net output #0: loss = 0.298898 (* 1 = 0.298898 loss)
I0403 08:51:21.053225  8106 sgd_solver.cpp:106] Iteration 1664, lr = 0.005
I0403 08:51:30.486546  8106 solver.cpp:228] Iteration 1677, loss = 0.352069
I0403 08:51:30.486636  8106 solver.cpp:244]     Train net output #0: loss = 0.352069 (* 1 = 0.352069 loss)
I0403 08:51:30.620862  8106 sgd_solver.cpp:106] Iteration 1677, lr = 0.005
I0403 08:51:40.127218  8106 solver.cpp:228] Iteration 1690, loss = 0.383505
I0403 08:51:40.127307  8106 solver.cpp:244]     Train net output #0: loss = 0.383505 (* 1 = 0.383505 loss)
I0403 08:51:40.310216  8106 sgd_solver.cpp:106] Iteration 1690, lr = 0.005
I0403 08:51:49.445822  8106 solver.cpp:228] Iteration 1703, loss = 0.503579
I0403 08:51:49.446105  8106 solver.cpp:244]     Train net output #0: loss = 0.503579 (* 1 = 0.503579 loss)
I0403 08:51:49.622318  8106 sgd_solver.cpp:106] Iteration 1703, lr = 0.005
I0403 08:51:58.923260  8106 solver.cpp:228] Iteration 1716, loss = 0.359596
I0403 08:51:58.923358  8106 solver.cpp:244]     Train net output #0: loss = 0.359596 (* 1 = 0.359596 loss)
I0403 08:51:59.117944  8106 sgd_solver.cpp:106] Iteration 1716, lr = 0.005
I0403 08:52:08.324110  8106 solver.cpp:228] Iteration 1729, loss = 0.307482
I0403 08:52:08.324196  8106 solver.cpp:244]     Train net output #0: loss = 0.307482 (* 1 = 0.307482 loss)
I0403 08:52:08.501274  8106 sgd_solver.cpp:106] Iteration 1729, lr = 0.005
I0403 08:52:17.755296  8106 solver.cpp:228] Iteration 1742, loss = 0.286878
I0403 08:52:17.755394  8106 solver.cpp:244]     Train net output #0: loss = 0.286878 (* 1 = 0.286878 loss)
I0403 08:52:17.942137  8106 sgd_solver.cpp:106] Iteration 1742, lr = 0.005
I0403 08:52:27.229948  8106 solver.cpp:228] Iteration 1755, loss = 0.312521
I0403 08:52:27.230228  8106 solver.cpp:244]     Train net output #0: loss = 0.312521 (* 1 = 0.312521 loss)
I0403 08:52:27.387727  8106 sgd_solver.cpp:106] Iteration 1755, lr = 0.005
I0403 08:52:36.568536  8106 solver.cpp:228] Iteration 1768, loss = 0.198009
I0403 08:52:36.568634  8106 solver.cpp:244]     Train net output #0: loss = 0.198009 (* 1 = 0.198009 loss)
I0403 08:52:36.774710  8106 sgd_solver.cpp:106] Iteration 1768, lr = 0.005
I0403 08:52:46.239852  8106 solver.cpp:228] Iteration 1781, loss = 0.322671
I0403 08:52:46.239939  8106 solver.cpp:244]     Train net output #0: loss = 0.322671 (* 1 = 0.322671 loss)
I0403 08:52:46.394199  8106 sgd_solver.cpp:106] Iteration 1781, lr = 0.005
I0403 08:52:55.698164  8106 solver.cpp:228] Iteration 1794, loss = 0.26389
I0403 08:52:55.698263  8106 solver.cpp:244]     Train net output #0: loss = 0.26389 (* 1 = 0.26389 loss)
I0403 08:52:55.946962  8106 sgd_solver.cpp:106] Iteration 1794, lr = 0.005
I0403 08:53:05.286584  8106 solver.cpp:228] Iteration 1807, loss = 0.300109
I0403 08:53:05.286926  8106 solver.cpp:244]     Train net output #0: loss = 0.300109 (* 1 = 0.300109 loss)
I0403 08:53:05.468288  8106 sgd_solver.cpp:106] Iteration 1807, lr = 0.005
I0403 08:53:14.704661  8106 solver.cpp:228] Iteration 1820, loss = 0.3509
I0403 08:53:14.704759  8106 solver.cpp:244]     Train net output #0: loss = 0.3509 (* 1 = 0.3509 loss)
I0403 08:53:14.904053  8106 sgd_solver.cpp:106] Iteration 1820, lr = 0.005
I0403 08:53:24.179285  8106 solver.cpp:228] Iteration 1833, loss = 0.306614
I0403 08:53:24.179369  8106 solver.cpp:244]     Train net output #0: loss = 0.306614 (* 1 = 0.306614 loss)
I0403 08:53:24.332712  8106 sgd_solver.cpp:106] Iteration 1833, lr = 0.005
I0403 08:53:33.567870  8106 solver.cpp:228] Iteration 1846, loss = 0.183098
I0403 08:53:33.567970  8106 solver.cpp:244]     Train net output #0: loss = 0.183098 (* 1 = 0.183098 loss)
I0403 08:53:33.761003  8106 sgd_solver.cpp:106] Iteration 1846, lr = 0.005
I0403 08:53:42.991317  8106 solver.cpp:228] Iteration 1859, loss = 0.394619
I0403 08:53:42.991621  8106 solver.cpp:244]     Train net output #0: loss = 0.394619 (* 1 = 0.394619 loss)
I0403 08:53:43.205467  8106 sgd_solver.cpp:106] Iteration 1859, lr = 0.005
I0403 08:53:49.699774  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1869.caffemodel
I0403 08:53:52.477342  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_1869.solverstate
I0403 08:53:54.375169  8106 solver.cpp:337] Iteration 1869, Testing net (#0)
I0403 08:54:56.425642  8106 solver.cpp:404]     Test net output #0: accuracy = 0.885054
I0403 08:54:56.425954  8106 solver.cpp:404]     Test net output #1: loss = 0.355343 (* 1 = 0.355343 loss)
I0403 08:54:59.165410  8106 solver.cpp:228] Iteration 1872, loss = 0.183614
I0403 08:54:59.165494  8106 solver.cpp:244]     Train net output #0: loss = 0.183614 (* 1 = 0.183614 loss)
I0403 08:54:59.340980  8106 sgd_solver.cpp:106] Iteration 1872, lr = 0.005
I0403 08:55:08.526741  8106 solver.cpp:228] Iteration 1885, loss = 0.359806
I0403 08:55:08.526829  8106 solver.cpp:244]     Train net output #0: loss = 0.359806 (* 1 = 0.359806 loss)
I0403 08:55:08.704728  8106 sgd_solver.cpp:106] Iteration 1885, lr = 0.005
I0403 08:55:17.960062  8106 solver.cpp:228] Iteration 1898, loss = 0.27895
I0403 08:55:17.960161  8106 solver.cpp:244]     Train net output #0: loss = 0.27895 (* 1 = 0.27895 loss)
I0403 08:55:18.175601  8106 sgd_solver.cpp:106] Iteration 1898, lr = 0.005
I0403 08:55:27.391433  8106 solver.cpp:228] Iteration 1911, loss = 0.299865
I0403 08:55:27.391718  8106 solver.cpp:244]     Train net output #0: loss = 0.299865 (* 1 = 0.299865 loss)
I0403 08:55:27.573650  8106 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 08:55:36.860237  8106 solver.cpp:228] Iteration 1924, loss = 0.26553
I0403 08:55:36.860321  8106 solver.cpp:244]     Train net output #0: loss = 0.26553 (* 1 = 0.26553 loss)
I0403 08:55:37.038779  8106 sgd_solver.cpp:106] Iteration 1924, lr = 0.005
I0403 08:55:46.204748  8106 solver.cpp:228] Iteration 1937, loss = 0.200621
I0403 08:55:46.204846  8106 solver.cpp:244]     Train net output #0: loss = 0.200621 (* 1 = 0.200621 loss)
I0403 08:55:46.394111  8106 sgd_solver.cpp:106] Iteration 1937, lr = 0.005
I0403 08:55:55.481508  8106 solver.cpp:228] Iteration 1950, loss = 0.230966
I0403 08:55:55.481608  8106 solver.cpp:244]     Train net output #0: loss = 0.230966 (* 1 = 0.230966 loss)
I0403 08:55:55.686575  8106 sgd_solver.cpp:106] Iteration 1950, lr = 0.005
I0403 08:56:04.923192  8106 solver.cpp:228] Iteration 1963, loss = 0.382207
I0403 08:56:04.923486  8106 solver.cpp:244]     Train net output #0: loss = 0.382207 (* 1 = 0.382207 loss)
I0403 08:56:05.113687  8106 sgd_solver.cpp:106] Iteration 1963, lr = 0.005
I0403 08:56:14.351444  8106 solver.cpp:228] Iteration 1976, loss = 0.335067
I0403 08:56:14.351536  8106 solver.cpp:244]     Train net output #0: loss = 0.335067 (* 1 = 0.335067 loss)
I0403 08:56:14.530839  8106 sgd_solver.cpp:106] Iteration 1976, lr = 0.005
I0403 08:56:23.940649  8106 solver.cpp:228] Iteration 1989, loss = 0.271139
I0403 08:56:23.940745  8106 solver.cpp:244]     Train net output #0: loss = 0.271138 (* 1 = 0.271138 loss)
I0403 08:56:24.148572  8106 sgd_solver.cpp:106] Iteration 1989, lr = 0.005
I0403 08:56:33.530082  8106 solver.cpp:228] Iteration 2002, loss = 0.310506
I0403 08:56:33.530171  8106 solver.cpp:244]     Train net output #0: loss = 0.310506 (* 1 = 0.310506 loss)
I0403 08:56:33.701717  8106 sgd_solver.cpp:106] Iteration 2002, lr = 0.005
I0403 08:56:42.865183  8106 solver.cpp:228] Iteration 2015, loss = 0.354015
I0403 08:56:42.865456  8106 solver.cpp:244]     Train net output #0: loss = 0.354015 (* 1 = 0.354015 loss)
I0403 08:56:43.044666  8106 sgd_solver.cpp:106] Iteration 2015, lr = 0.005
I0403 08:56:52.260993  8106 solver.cpp:228] Iteration 2028, loss = 0.19271
I0403 08:56:52.261078  8106 solver.cpp:244]     Train net output #0: loss = 0.19271 (* 1 = 0.19271 loss)
I0403 08:56:52.442047  8106 sgd_solver.cpp:106] Iteration 2028, lr = 0.005
I0403 08:57:01.765082  8106 solver.cpp:228] Iteration 2041, loss = 0.191261
I0403 08:57:01.765182  8106 solver.cpp:244]     Train net output #0: loss = 0.191261 (* 1 = 0.191261 loss)
I0403 08:57:01.950891  8106 sgd_solver.cpp:106] Iteration 2041, lr = 0.005
I0403 08:57:11.103024  8106 solver.cpp:228] Iteration 2054, loss = 0.179376
I0403 08:57:11.103122  8106 solver.cpp:244]     Train net output #0: loss = 0.179376 (* 1 = 0.179376 loss)
I0403 08:57:11.290256  8106 sgd_solver.cpp:106] Iteration 2054, lr = 0.005
I0403 08:57:20.558768  8106 solver.cpp:228] Iteration 2067, loss = 0.243694
I0403 08:57:20.559069  8106 solver.cpp:244]     Train net output #0: loss = 0.243694 (* 1 = 0.243694 loss)
I0403 08:57:20.708497  8106 sgd_solver.cpp:106] Iteration 2067, lr = 0.005
I0403 08:57:30.027534  8106 solver.cpp:228] Iteration 2080, loss = 0.440737
I0403 08:57:30.027627  8106 solver.cpp:244]     Train net output #0: loss = 0.440737 (* 1 = 0.440737 loss)
I0403 08:57:30.199085  8106 sgd_solver.cpp:106] Iteration 2080, lr = 0.005
I0403 08:57:39.634763  8106 solver.cpp:228] Iteration 2093, loss = 0.272283
I0403 08:57:39.634853  8106 solver.cpp:244]     Train net output #0: loss = 0.272283 (* 1 = 0.272283 loss)
I0403 08:57:39.790922  8106 sgd_solver.cpp:106] Iteration 2093, lr = 0.005
I0403 08:57:49.127091  8106 solver.cpp:228] Iteration 2106, loss = 0.281705
I0403 08:57:49.127184  8106 solver.cpp:244]     Train net output #0: loss = 0.281705 (* 1 = 0.281705 loss)
I0403 08:57:49.319473  8106 sgd_solver.cpp:106] Iteration 2106, lr = 0.005
I0403 08:57:58.506665  8106 solver.cpp:228] Iteration 2119, loss = 0.337267
I0403 08:57:58.506955  8106 solver.cpp:244]     Train net output #0: loss = 0.337267 (* 1 = 0.337267 loss)
I0403 08:57:58.668462  8106 sgd_solver.cpp:106] Iteration 2119, lr = 0.005
I0403 08:58:08.075758  8106 solver.cpp:228] Iteration 2132, loss = 0.367994
I0403 08:58:08.075855  8106 solver.cpp:244]     Train net output #0: loss = 0.367994 (* 1 = 0.367994 loss)
I0403 08:58:08.272857  8106 sgd_solver.cpp:106] Iteration 2132, lr = 0.005
I0403 08:58:10.414187  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2136.caffemodel
I0403 08:58:13.224258  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2136.solverstate
I0403 08:58:15.101619  8106 solver.cpp:337] Iteration 2136, Testing net (#0)
I0403 08:59:17.143656  8106 solver.cpp:404]     Test net output #0: accuracy = 0.884654
I0403 08:59:17.143990  8106 solver.cpp:404]     Test net output #1: loss = 0.356413 (* 1 = 0.356413 loss)
I0403 08:59:24.098258  8106 solver.cpp:228] Iteration 2145, loss = 0.184248
I0403 08:59:24.098342  8106 solver.cpp:244]     Train net output #0: loss = 0.184247 (* 1 = 0.184247 loss)
I0403 08:59:24.258764  8106 sgd_solver.cpp:106] Iteration 2145, lr = 0.005
I0403 08:59:33.503057  8106 solver.cpp:228] Iteration 2158, loss = 0.152935
I0403 08:59:33.503146  8106 solver.cpp:244]     Train net output #0: loss = 0.152935 (* 1 = 0.152935 loss)
I0403 08:59:33.657151  8106 sgd_solver.cpp:106] Iteration 2158, lr = 0.005
I0403 08:59:43.030903  8106 solver.cpp:228] Iteration 2171, loss = 0.32176
I0403 08:59:43.030998  8106 solver.cpp:244]     Train net output #0: loss = 0.32176 (* 1 = 0.32176 loss)
I0403 08:59:43.215461  8106 sgd_solver.cpp:106] Iteration 2171, lr = 0.005
I0403 08:59:52.363417  8106 solver.cpp:228] Iteration 2184, loss = 0.227481
I0403 08:59:52.363754  8106 solver.cpp:244]     Train net output #0: loss = 0.227481 (* 1 = 0.227481 loss)
I0403 08:59:52.569768  8106 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 09:00:01.783148  8106 solver.cpp:228] Iteration 2197, loss = 0.22515
I0403 09:00:01.783247  8106 solver.cpp:244]     Train net output #0: loss = 0.22515 (* 1 = 0.22515 loss)
I0403 09:00:01.969872  8106 sgd_solver.cpp:106] Iteration 2197, lr = 0.005
I0403 09:00:11.149545  8106 solver.cpp:228] Iteration 2210, loss = 0.136764
I0403 09:00:11.149639  8106 solver.cpp:244]     Train net output #0: loss = 0.136764 (* 1 = 0.136764 loss)
I0403 09:00:11.355479  8106 sgd_solver.cpp:106] Iteration 2210, lr = 0.005
I0403 09:00:20.606956  8106 solver.cpp:228] Iteration 2223, loss = 0.283163
I0403 09:00:20.607043  8106 solver.cpp:244]     Train net output #0: loss = 0.283163 (* 1 = 0.283163 loss)
I0403 09:00:20.783746  8106 sgd_solver.cpp:106] Iteration 2223, lr = 0.005
I0403 09:00:30.123358  8106 solver.cpp:228] Iteration 2236, loss = 0.210606
I0403 09:00:30.123649  8106 solver.cpp:244]     Train net output #0: loss = 0.210606 (* 1 = 0.210606 loss)
I0403 09:00:30.305897  8106 sgd_solver.cpp:106] Iteration 2236, lr = 0.005
I0403 09:00:39.464591  8106 solver.cpp:228] Iteration 2249, loss = 0.369825
I0403 09:00:39.464680  8106 solver.cpp:244]     Train net output #0: loss = 0.369825 (* 1 = 0.369825 loss)
I0403 09:00:39.632355  8106 sgd_solver.cpp:106] Iteration 2249, lr = 0.005
I0403 09:00:48.953985  8106 solver.cpp:228] Iteration 2262, loss = 0.20878
I0403 09:00:48.954071  8106 solver.cpp:244]     Train net output #0: loss = 0.20878 (* 1 = 0.20878 loss)
I0403 09:00:49.103602  8106 sgd_solver.cpp:106] Iteration 2262, lr = 0.005
I0403 09:00:58.401546  8106 solver.cpp:228] Iteration 2275, loss = 0.374186
I0403 09:00:58.401643  8106 solver.cpp:244]     Train net output #0: loss = 0.374186 (* 1 = 0.374186 loss)
I0403 09:00:58.590750  8106 sgd_solver.cpp:106] Iteration 2275, lr = 0.005
I0403 09:01:08.006897  8106 solver.cpp:228] Iteration 2288, loss = 0.284214
I0403 09:01:08.007179  8106 solver.cpp:244]     Train net output #0: loss = 0.284214 (* 1 = 0.284214 loss)
I0403 09:01:08.163570  8106 sgd_solver.cpp:106] Iteration 2288, lr = 0.005
I0403 09:01:17.464849  8106 solver.cpp:228] Iteration 2301, loss = 0.189401
I0403 09:01:17.464934  8106 solver.cpp:244]     Train net output #0: loss = 0.1894 (* 1 = 0.1894 loss)
I0403 09:01:17.642626  8106 sgd_solver.cpp:106] Iteration 2301, lr = 0.005
I0403 09:01:26.896208  8106 solver.cpp:228] Iteration 2314, loss = 0.177233
I0403 09:01:26.896318  8106 solver.cpp:244]     Train net output #0: loss = 0.177233 (* 1 = 0.177233 loss)
I0403 09:01:27.155820  8106 sgd_solver.cpp:106] Iteration 2314, lr = 0.005
I0403 09:01:36.624420  8106 solver.cpp:228] Iteration 2327, loss = 0.22152
I0403 09:01:36.624508  8106 solver.cpp:244]     Train net output #0: loss = 0.22152 (* 1 = 0.22152 loss)
I0403 09:01:36.800825  8106 sgd_solver.cpp:106] Iteration 2327, lr = 0.005
I0403 09:01:46.112511  8106 solver.cpp:228] Iteration 2340, loss = 0.23193
I0403 09:01:46.112818  8106 solver.cpp:244]     Train net output #0: loss = 0.23193 (* 1 = 0.23193 loss)
I0403 09:01:46.309628  8106 sgd_solver.cpp:106] Iteration 2340, lr = 0.005
I0403 09:01:55.448335  8106 solver.cpp:228] Iteration 2353, loss = 0.316511
I0403 09:01:55.448436  8106 solver.cpp:244]     Train net output #0: loss = 0.316511 (* 1 = 0.316511 loss)
I0403 09:01:55.665740  8106 sgd_solver.cpp:106] Iteration 2353, lr = 0.005
I0403 09:02:05.058431  8106 solver.cpp:228] Iteration 2366, loss = 0.132777
I0403 09:02:05.058521  8106 solver.cpp:244]     Train net output #0: loss = 0.132777 (* 1 = 0.132777 loss)
I0403 09:02:05.198585  8106 sgd_solver.cpp:106] Iteration 2366, lr = 0.005
I0403 09:02:14.597467  8106 solver.cpp:228] Iteration 2379, loss = 0.228676
I0403 09:02:14.597571  8106 solver.cpp:244]     Train net output #0: loss = 0.228676 (* 1 = 0.228676 loss)
I0403 09:02:14.836987  8106 sgd_solver.cpp:106] Iteration 2379, lr = 0.005
I0403 09:02:24.073532  8106 solver.cpp:228] Iteration 2392, loss = 0.338534
I0403 09:02:24.073854  8106 solver.cpp:244]     Train net output #0: loss = 0.338534 (* 1 = 0.338534 loss)
I0403 09:02:24.275681  8106 sgd_solver.cpp:106] Iteration 2392, lr = 0.005
I0403 09:02:31.608764  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2403.caffemodel
I0403 09:02:34.379611  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2403.solverstate
I0403 09:02:36.258642  8106 solver.cpp:337] Iteration 2403, Testing net (#0)
I0403 09:03:38.319830  8106 solver.cpp:404]     Test net output #0: accuracy = 0.886728
I0403 09:03:38.320123  8106 solver.cpp:404]     Test net output #1: loss = 0.359498 (* 1 = 0.359498 loss)
I0403 09:03:40.273347  8106 solver.cpp:228] Iteration 2405, loss = 0.143546
I0403 09:03:40.273435  8106 solver.cpp:244]     Train net output #0: loss = 0.143546 (* 1 = 0.143546 loss)
I0403 09:03:40.460822  8106 sgd_solver.cpp:106] Iteration 2405, lr = 0.005
I0403 09:03:49.706264  8106 solver.cpp:228] Iteration 2418, loss = 0.225412
I0403 09:03:49.706360  8106 solver.cpp:244]     Train net output #0: loss = 0.225412 (* 1 = 0.225412 loss)
I0403 09:03:49.894917  8106 sgd_solver.cpp:106] Iteration 2418, lr = 0.005
I0403 09:03:59.088423  8106 solver.cpp:228] Iteration 2431, loss = 0.243239
I0403 09:03:59.088510  8106 solver.cpp:244]     Train net output #0: loss = 0.243239 (* 1 = 0.243239 loss)
I0403 09:03:59.253671  8106 sgd_solver.cpp:106] Iteration 2431, lr = 0.005
I0403 09:04:08.613956  8106 solver.cpp:228] Iteration 2444, loss = 0.237396
I0403 09:04:08.614233  8106 solver.cpp:244]     Train net output #0: loss = 0.237396 (* 1 = 0.237396 loss)
I0403 09:04:08.790580  8106 sgd_solver.cpp:106] Iteration 2444, lr = 0.005
I0403 09:04:17.999866  8106 solver.cpp:228] Iteration 2457, loss = 0.266008
I0403 09:04:17.999963  8106 solver.cpp:244]     Train net output #0: loss = 0.266008 (* 1 = 0.266008 loss)
I0403 09:04:18.190536  8106 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 09:04:27.528568  8106 solver.cpp:228] Iteration 2470, loss = 0.208436
I0403 09:04:27.528668  8106 solver.cpp:244]     Train net output #0: loss = 0.208436 (* 1 = 0.208436 loss)
I0403 09:04:27.716948  8106 sgd_solver.cpp:106] Iteration 2470, lr = 0.005
I0403 09:04:36.987548  8106 solver.cpp:228] Iteration 2483, loss = 0.237596
I0403 09:04:36.987645  8106 solver.cpp:244]     Train net output #0: loss = 0.237596 (* 1 = 0.237596 loss)
I0403 09:04:37.206604  8106 sgd_solver.cpp:106] Iteration 2483, lr = 0.005
I0403 09:04:46.418437  8106 solver.cpp:228] Iteration 2496, loss = 0.277514
I0403 09:04:46.418728  8106 solver.cpp:244]     Train net output #0: loss = 0.277514 (* 1 = 0.277514 loss)
I0403 09:04:46.591997  8106 sgd_solver.cpp:106] Iteration 2496, lr = 0.005
I0403 09:04:55.780864  8106 solver.cpp:228] Iteration 2509, loss = 0.160371
I0403 09:04:55.780951  8106 solver.cpp:244]     Train net output #0: loss = 0.160371 (* 1 = 0.160371 loss)
I0403 09:04:55.956231  8106 sgd_solver.cpp:106] Iteration 2509, lr = 0.005
I0403 09:05:05.356736  8106 solver.cpp:228] Iteration 2522, loss = 0.181452
I0403 09:05:05.356834  8106 solver.cpp:244]     Train net output #0: loss = 0.181452 (* 1 = 0.181452 loss)
I0403 09:05:05.541329  8106 sgd_solver.cpp:106] Iteration 2522, lr = 0.005
I0403 09:05:14.996651  8106 solver.cpp:228] Iteration 2535, loss = 0.219408
I0403 09:05:14.996742  8106 solver.cpp:244]     Train net output #0: loss = 0.219408 (* 1 = 0.219408 loss)
I0403 09:05:15.136776  8106 sgd_solver.cpp:106] Iteration 2535, lr = 0.005
I0403 09:05:24.525246  8106 solver.cpp:228] Iteration 2548, loss = 0.261738
I0403 09:05:24.525517  8106 solver.cpp:244]     Train net output #0: loss = 0.261738 (* 1 = 0.261738 loss)
I0403 09:05:24.709122  8106 sgd_solver.cpp:106] Iteration 2548, lr = 0.005
I0403 09:05:33.970249  8106 solver.cpp:228] Iteration 2561, loss = 0.147758
I0403 09:05:33.970340  8106 solver.cpp:244]     Train net output #0: loss = 0.147758 (* 1 = 0.147758 loss)
I0403 09:05:34.139464  8106 sgd_solver.cpp:106] Iteration 2561, lr = 0.005
I0403 09:05:43.492867  8106 solver.cpp:228] Iteration 2574, loss = 0.171782
I0403 09:05:43.492962  8106 solver.cpp:244]     Train net output #0: loss = 0.171782 (* 1 = 0.171782 loss)
I0403 09:05:43.679713  8106 sgd_solver.cpp:106] Iteration 2574, lr = 0.005
I0403 09:05:52.865957  8106 solver.cpp:228] Iteration 2587, loss = 0.148293
I0403 09:05:52.866060  8106 solver.cpp:244]     Train net output #0: loss = 0.148293 (* 1 = 0.148293 loss)
I0403 09:05:53.119870  8106 sgd_solver.cpp:106] Iteration 2587, lr = 0.005
I0403 09:06:02.500502  8106 solver.cpp:228] Iteration 2600, loss = 0.150339
I0403 09:06:02.500828  8106 solver.cpp:244]     Train net output #0: loss = 0.150339 (* 1 = 0.150339 loss)
I0403 09:06:02.662447  8106 sgd_solver.cpp:106] Iteration 2600, lr = 0.005
I0403 09:06:11.941593  8106 solver.cpp:228] Iteration 2613, loss = 0.118539
I0403 09:06:11.941687  8106 solver.cpp:244]     Train net output #0: loss = 0.118539 (* 1 = 0.118539 loss)
I0403 09:06:12.135068  8106 sgd_solver.cpp:106] Iteration 2613, lr = 0.005
I0403 09:06:21.362890  8106 solver.cpp:228] Iteration 2626, loss = 0.221867
I0403 09:06:21.362987  8106 solver.cpp:244]     Train net output #0: loss = 0.221867 (* 1 = 0.221867 loss)
I0403 09:06:21.566458  8106 sgd_solver.cpp:106] Iteration 2626, lr = 0.005
I0403 09:06:30.812286  8106 solver.cpp:228] Iteration 2639, loss = 0.225559
I0403 09:06:30.812386  8106 solver.cpp:244]     Train net output #0: loss = 0.225559 (* 1 = 0.225559 loss)
I0403 09:06:31.004958  8106 sgd_solver.cpp:106] Iteration 2639, lr = 0.005
I0403 09:06:40.316704  8106 solver.cpp:228] Iteration 2652, loss = 0.164432
I0403 09:06:40.317006  8106 solver.cpp:244]     Train net output #0: loss = 0.164432 (* 1 = 0.164432 loss)
I0403 09:06:40.457381  8106 sgd_solver.cpp:106] Iteration 2652, lr = 0.005
I0403 09:06:49.829380  8106 solver.cpp:228] Iteration 2665, loss = 0.171134
I0403 09:06:49.829475  8106 solver.cpp:244]     Train net output #0: loss = 0.171134 (* 1 = 0.171134 loss)
I0403 09:06:50.011759  8106 sgd_solver.cpp:106] Iteration 2665, lr = 0.005
I0403 09:06:52.874846  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2670.caffemodel
I0403 09:06:55.581693  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2670.solverstate
I0403 09:06:57.380482  8106 solver.cpp:337] Iteration 2670, Testing net (#0)
I0403 09:07:59.445399  8106 solver.cpp:404]     Test net output #0: accuracy = 0.878654
I0403 09:07:59.445670  8106 solver.cpp:404]     Test net output #1: loss = 0.383809 (* 1 = 0.383809 loss)
I0403 09:08:05.674916  8106 solver.cpp:228] Iteration 2678, loss = 0.214583
I0403 09:08:05.675004  8106 solver.cpp:244]     Train net output #0: loss = 0.214583 (* 1 = 0.214583 loss)
I0403 09:08:05.816341  8106 sgd_solver.cpp:106] Iteration 2678, lr = 0.0005
I0403 09:08:15.202945  8106 solver.cpp:228] Iteration 2691, loss = 0.261355
I0403 09:08:15.203039  8106 solver.cpp:244]     Train net output #0: loss = 0.261355 (* 1 = 0.261355 loss)
I0403 09:08:15.392213  8106 sgd_solver.cpp:106] Iteration 2691, lr = 0.0005
I0403 09:08:24.696328  8106 solver.cpp:228] Iteration 2704, loss = 0.163717
I0403 09:08:24.696424  8106 solver.cpp:244]     Train net output #0: loss = 0.163717 (* 1 = 0.163717 loss)
I0403 09:08:24.892818  8106 sgd_solver.cpp:106] Iteration 2704, lr = 0.0005
I0403 09:08:34.178822  8106 solver.cpp:228] Iteration 2717, loss = 0.188745
I0403 09:08:34.179142  8106 solver.cpp:244]     Train net output #0: loss = 0.188745 (* 1 = 0.188745 loss)
I0403 09:08:34.368126  8106 sgd_solver.cpp:106] Iteration 2717, lr = 0.0005
I0403 09:08:43.539378  8106 solver.cpp:228] Iteration 2730, loss = 0.159603
I0403 09:08:43.539468  8106 solver.cpp:244]     Train net output #0: loss = 0.159603 (* 1 = 0.159603 loss)
I0403 09:08:43.720886  8106 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I0403 09:08:52.978688  8106 solver.cpp:228] Iteration 2743, loss = 0.08335
I0403 09:08:52.978786  8106 solver.cpp:244]     Train net output #0: loss = 0.08335 (* 1 = 0.08335 loss)
I0403 09:08:53.169555  8106 sgd_solver.cpp:106] Iteration 2743, lr = 0.0005
I0403 09:09:02.327538  8106 solver.cpp:228] Iteration 2756, loss = 0.121888
I0403 09:09:02.327639  8106 solver.cpp:244]     Train net output #0: loss = 0.121888 (* 1 = 0.121888 loss)
I0403 09:09:02.511728  8106 sgd_solver.cpp:106] Iteration 2756, lr = 0.0005
I0403 09:09:11.705519  8106 solver.cpp:228] Iteration 2769, loss = 0.0984481
I0403 09:09:11.705822  8106 solver.cpp:244]     Train net output #0: loss = 0.0984481 (* 1 = 0.0984481 loss)
I0403 09:09:11.899646  8106 sgd_solver.cpp:106] Iteration 2769, lr = 0.0005
I0403 09:09:21.161983  8106 solver.cpp:228] Iteration 2782, loss = 0.13675
I0403 09:09:21.162072  8106 solver.cpp:244]     Train net output #0: loss = 0.13675 (* 1 = 0.13675 loss)
I0403 09:09:21.324405  8106 sgd_solver.cpp:106] Iteration 2782, lr = 0.0005
I0403 09:09:30.623270  8106 solver.cpp:228] Iteration 2795, loss = 0.127727
I0403 09:09:30.623370  8106 solver.cpp:244]     Train net output #0: loss = 0.127727 (* 1 = 0.127727 loss)
I0403 09:09:30.828416  8106 sgd_solver.cpp:106] Iteration 2795, lr = 0.0005
I0403 09:09:40.043753  8106 solver.cpp:228] Iteration 2808, loss = 0.119473
I0403 09:09:40.043849  8106 solver.cpp:244]     Train net output #0: loss = 0.119473 (* 1 = 0.119473 loss)
I0403 09:09:40.228952  8106 sgd_solver.cpp:106] Iteration 2808, lr = 0.0005
I0403 09:09:49.562984  8106 solver.cpp:228] Iteration 2821, loss = 0.147537
I0403 09:09:49.563292  8106 solver.cpp:244]     Train net output #0: loss = 0.147537 (* 1 = 0.147537 loss)
I0403 09:09:49.802919  8106 sgd_solver.cpp:106] Iteration 2821, lr = 0.0005
I0403 09:09:58.955018  8106 solver.cpp:228] Iteration 2834, loss = 0.081061
I0403 09:09:58.955117  8106 solver.cpp:244]     Train net output #0: loss = 0.081061 (* 1 = 0.081061 loss)
I0403 09:09:59.140400  8106 sgd_solver.cpp:106] Iteration 2834, lr = 0.0005
I0403 09:10:08.425731  8106 solver.cpp:228] Iteration 2847, loss = 0.0928915
I0403 09:10:08.425820  8106 solver.cpp:244]     Train net output #0: loss = 0.0928915 (* 1 = 0.0928915 loss)
I0403 09:10:08.598588  8106 sgd_solver.cpp:106] Iteration 2847, lr = 0.0005
I0403 09:10:17.837177  8106 solver.cpp:228] Iteration 2860, loss = 0.0792993
I0403 09:10:17.837275  8106 solver.cpp:244]     Train net output #0: loss = 0.0792993 (* 1 = 0.0792993 loss)
I0403 09:10:18.066583  8106 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I0403 09:10:27.233369  8106 solver.cpp:228] Iteration 2873, loss = 0.132624
I0403 09:10:27.233623  8106 solver.cpp:244]     Train net output #0: loss = 0.132624 (* 1 = 0.132624 loss)
I0403 09:10:27.430007  8106 sgd_solver.cpp:106] Iteration 2873, lr = 0.0005
I0403 09:10:36.777422  8106 solver.cpp:228] Iteration 2886, loss = 0.0859163
I0403 09:10:36.777526  8106 solver.cpp:244]     Train net output #0: loss = 0.0859163 (* 1 = 0.0859163 loss)
I0403 09:10:36.974673  8106 sgd_solver.cpp:106] Iteration 2886, lr = 0.0005
I0403 09:10:46.257763  8106 solver.cpp:228] Iteration 2899, loss = 0.153645
I0403 09:10:46.257851  8106 solver.cpp:244]     Train net output #0: loss = 0.153645 (* 1 = 0.153645 loss)
I0403 09:10:46.408041  8106 sgd_solver.cpp:106] Iteration 2899, lr = 0.0005
I0403 09:10:55.841367  8106 solver.cpp:228] Iteration 2912, loss = 0.108804
I0403 09:10:55.841456  8106 solver.cpp:244]     Train net output #0: loss = 0.108804 (* 1 = 0.108804 loss)
I0403 09:10:56.015662  8106 sgd_solver.cpp:106] Iteration 2912, lr = 0.0005
I0403 09:11:05.345623  8106 solver.cpp:228] Iteration 2925, loss = 0.0882392
I0403 09:11:05.345948  8106 solver.cpp:244]     Train net output #0: loss = 0.0882392 (* 1 = 0.0882392 loss)
I0403 09:11:05.531328  8106 sgd_solver.cpp:106] Iteration 2925, lr = 0.0005
I0403 09:11:13.474946  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2937.caffemodel
I0403 09:11:16.258038  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_2937.solverstate
I0403 09:11:18.124172  8106 solver.cpp:337] Iteration 2937, Testing net (#0)
I0403 09:12:20.159423  8106 solver.cpp:404]     Test net output #0: accuracy = 0.92189
I0403 09:12:20.159729  8106 solver.cpp:404]     Test net output #1: loss = 0.255979 (* 1 = 0.255979 loss)
I0403 09:12:21.411891  8106 solver.cpp:228] Iteration 2938, loss = 0.0550985
I0403 09:12:21.411988  8106 solver.cpp:244]     Train net output #0: loss = 0.0550985 (* 1 = 0.0550985 loss)
I0403 09:12:21.593938  8106 sgd_solver.cpp:106] Iteration 2938, lr = 0.0005
I0403 09:12:30.893723  8106 solver.cpp:228] Iteration 2951, loss = 0.0827594
I0403 09:12:30.893812  8106 solver.cpp:244]     Train net output #0: loss = 0.0827594 (* 1 = 0.0827594 loss)
I0403 09:12:31.078663  8106 sgd_solver.cpp:106] Iteration 2951, lr = 0.0005
I0403 09:12:40.263545  8106 solver.cpp:228] Iteration 2964, loss = 0.0827751
I0403 09:12:40.263635  8106 solver.cpp:244]     Train net output #0: loss = 0.0827752 (* 1 = 0.0827752 loss)
I0403 09:12:40.459627  8106 sgd_solver.cpp:106] Iteration 2964, lr = 0.0005
I0403 09:12:49.746954  8106 solver.cpp:228] Iteration 2977, loss = 0.101544
I0403 09:12:49.747053  8106 solver.cpp:244]     Train net output #0: loss = 0.101544 (* 1 = 0.101544 loss)
I0403 09:12:49.973466  8106 sgd_solver.cpp:106] Iteration 2977, lr = 0.0005
I0403 09:12:59.590284  8106 solver.cpp:228] Iteration 2990, loss = 0.181023
I0403 09:12:59.590548  8106 solver.cpp:244]     Train net output #0: loss = 0.181024 (* 1 = 0.181024 loss)
I0403 09:12:59.755331  8106 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I0403 09:13:09.132448  8106 solver.cpp:228] Iteration 3003, loss = 0.164488
I0403 09:13:09.132555  8106 solver.cpp:244]     Train net output #0: loss = 0.164488 (* 1 = 0.164488 loss)
I0403 09:13:09.324936  8106 sgd_solver.cpp:106] Iteration 3003, lr = 0.0005
I0403 09:13:18.595279  8106 solver.cpp:228] Iteration 3016, loss = 0.068043
I0403 09:13:18.595367  8106 solver.cpp:244]     Train net output #0: loss = 0.068043 (* 1 = 0.068043 loss)
I0403 09:13:18.766242  8106 sgd_solver.cpp:106] Iteration 3016, lr = 0.0005
I0403 09:13:28.247818  8106 solver.cpp:228] Iteration 3029, loss = 0.0430748
I0403 09:13:28.247905  8106 solver.cpp:244]     Train net output #0: loss = 0.0430748 (* 1 = 0.0430748 loss)
I0403 09:13:28.388156  8106 sgd_solver.cpp:106] Iteration 3029, lr = 0.0005
I0403 09:13:37.803987  8106 solver.cpp:228] Iteration 3042, loss = 0.0569005
I0403 09:13:37.804285  8106 solver.cpp:244]     Train net output #0: loss = 0.0569005 (* 1 = 0.0569005 loss)
I0403 09:13:37.989574  8106 sgd_solver.cpp:106] Iteration 3042, lr = 0.0005
I0403 09:13:47.390797  8106 solver.cpp:228] Iteration 3055, loss = 0.0558695
I0403 09:13:47.390892  8106 solver.cpp:244]     Train net output #0: loss = 0.0558695 (* 1 = 0.0558695 loss)
I0403 09:13:47.574391  8106 sgd_solver.cpp:106] Iteration 3055, lr = 0.0005
I0403 09:13:56.800626  8106 solver.cpp:228] Iteration 3068, loss = 0.0968324
I0403 09:13:56.800724  8106 solver.cpp:244]     Train net output #0: loss = 0.0968324 (* 1 = 0.0968324 loss)
I0403 09:13:56.982199  8106 sgd_solver.cpp:106] Iteration 3068, lr = 0.0005
I0403 09:14:06.238778  8106 solver.cpp:228] Iteration 3081, loss = 0.0326121
I0403 09:14:06.238860  8106 solver.cpp:244]     Train net output #0: loss = 0.0326121 (* 1 = 0.0326121 loss)
I0403 09:14:06.414635  8106 sgd_solver.cpp:106] Iteration 3081, lr = 0.0005
I0403 09:14:15.750804  8106 solver.cpp:228] Iteration 3094, loss = 0.083862
I0403 09:14:15.751067  8106 solver.cpp:244]     Train net output #0: loss = 0.083862 (* 1 = 0.083862 loss)
I0403 09:14:15.932699  8106 sgd_solver.cpp:106] Iteration 3094, lr = 0.0005
I0403 09:14:25.515298  8106 solver.cpp:228] Iteration 3107, loss = 0.091535
I0403 09:14:25.515388  8106 solver.cpp:244]     Train net output #0: loss = 0.091535 (* 1 = 0.091535 loss)
I0403 09:14:25.693789  8106 sgd_solver.cpp:106] Iteration 3107, lr = 0.0005
I0403 09:14:35.280133  8106 solver.cpp:228] Iteration 3120, loss = 0.129868
I0403 09:14:35.280218  8106 solver.cpp:244]     Train net output #0: loss = 0.129868 (* 1 = 0.129868 loss)
I0403 09:14:35.403686  8106 sgd_solver.cpp:106] Iteration 3120, lr = 0.0005
I0403 09:14:44.802866  8106 solver.cpp:228] Iteration 3133, loss = 0.137955
I0403 09:14:44.803010  8106 solver.cpp:244]     Train net output #0: loss = 0.137955 (* 1 = 0.137955 loss)
I0403 09:14:44.972882  8106 sgd_solver.cpp:106] Iteration 3133, lr = 0.0005
I0403 09:14:54.241432  8106 solver.cpp:228] Iteration 3146, loss = 0.059521
I0403 09:14:54.241726  8106 solver.cpp:244]     Train net output #0: loss = 0.059521 (* 1 = 0.059521 loss)
I0403 09:14:54.431109  8106 sgd_solver.cpp:106] Iteration 3146, lr = 0.0005
I0403 09:15:03.574764  8106 solver.cpp:228] Iteration 3159, loss = 0.0658094
I0403 09:15:03.574870  8106 solver.cpp:244]     Train net output #0: loss = 0.0658094 (* 1 = 0.0658094 loss)
I0403 09:15:03.795953  8106 sgd_solver.cpp:106] Iteration 3159, lr = 0.0005
I0403 09:15:12.995951  8106 solver.cpp:228] Iteration 3172, loss = 0.0640988
I0403 09:15:12.996047  8106 solver.cpp:244]     Train net output #0: loss = 0.0640988 (* 1 = 0.0640988 loss)
I0403 09:15:13.191709  8106 sgd_solver.cpp:106] Iteration 3172, lr = 0.0005
I0403 09:15:22.451448  8106 solver.cpp:228] Iteration 3185, loss = 0.0702655
I0403 09:15:22.451552  8106 solver.cpp:244]     Train net output #0: loss = 0.0702655 (* 1 = 0.0702655 loss)
I0403 09:15:22.638842  8106 sgd_solver.cpp:106] Iteration 3185, lr = 0.0005
I0403 09:15:31.822073  8106 solver.cpp:228] Iteration 3198, loss = 0.133099
I0403 09:15:31.822356  8106 solver.cpp:244]     Train net output #0: loss = 0.133099 (* 1 = 0.133099 loss)
I0403 09:15:32.009208  8106 sgd_solver.cpp:106] Iteration 3198, lr = 0.0005
I0403 09:15:35.631759  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_3204.caffemodel
I0403 09:15:39.457837  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_3204.solverstate
I0403 09:15:41.342167  8106 solver.cpp:337] Iteration 3204, Testing net (#0)
I0403 09:16:43.383919  8106 solver.cpp:404]     Test net output #0: accuracy = 0.925563
I0403 09:16:43.384248  8106 solver.cpp:404]     Test net output #1: loss = 0.247275 (* 1 = 0.247275 loss)
I0403 09:16:48.945379  8106 solver.cpp:228] Iteration 3211, loss = 0.158165
I0403 09:16:48.945462  8106 solver.cpp:244]     Train net output #0: loss = 0.158165 (* 1 = 0.158165 loss)
I0403 09:16:49.120455  8106 sgd_solver.cpp:106] Iteration 3211, lr = 0.0005
I0403 09:16:58.322178  8106 solver.cpp:228] Iteration 3224, loss = 0.110909
I0403 09:16:58.322274  8106 solver.cpp:244]     Train net output #0: loss = 0.110909 (* 1 = 0.110909 loss)
I0403 09:16:58.514394  8106 sgd_solver.cpp:106] Iteration 3224, lr = 0.0005
I0403 09:17:07.662659  8106 solver.cpp:228] Iteration 3237, loss = 0.0559045
I0403 09:17:07.662749  8106 solver.cpp:244]     Train net output #0: loss = 0.0559046 (* 1 = 0.0559046 loss)
I0403 09:17:07.839818  8106 sgd_solver.cpp:106] Iteration 3237, lr = 0.0005
I0403 09:17:17.226886  8106 solver.cpp:228] Iteration 3250, loss = 0.108998
I0403 09:17:17.227190  8106 solver.cpp:244]     Train net output #0: loss = 0.108998 (* 1 = 0.108998 loss)
I0403 09:17:17.402909  8106 sgd_solver.cpp:106] Iteration 3250, lr = 0.0005
I0403 09:17:26.691658  8106 solver.cpp:228] Iteration 3263, loss = 0.0599278
I0403 09:17:26.691756  8106 solver.cpp:244]     Train net output #0: loss = 0.0599279 (* 1 = 0.0599279 loss)
I0403 09:17:26.901464  8106 sgd_solver.cpp:106] Iteration 3263, lr = 0.0005
I0403 09:17:36.099450  8106 solver.cpp:228] Iteration 3276, loss = 0.124439
I0403 09:17:36.099537  8106 solver.cpp:244]     Train net output #0: loss = 0.124439 (* 1 = 0.124439 loss)
I0403 09:17:36.276404  8106 sgd_solver.cpp:106] Iteration 3276, lr = 0.0005
I0403 09:17:45.504629  8106 solver.cpp:228] Iteration 3289, loss = 0.0545839
I0403 09:17:45.504726  8106 solver.cpp:244]     Train net output #0: loss = 0.0545839 (* 1 = 0.0545839 loss)
I0403 09:17:45.691718  8106 sgd_solver.cpp:106] Iteration 3289, lr = 0.0005
I0403 09:17:55.030728  8106 solver.cpp:228] Iteration 3302, loss = 0.0752706
I0403 09:17:55.031034  8106 solver.cpp:244]     Train net output #0: loss = 0.0752706 (* 1 = 0.0752706 loss)
I0403 09:17:55.209815  8106 sgd_solver.cpp:106] Iteration 3302, lr = 0.0005
I0403 09:18:04.367557  8106 solver.cpp:228] Iteration 3315, loss = 0.111272
I0403 09:18:04.367655  8106 solver.cpp:244]     Train net output #0: loss = 0.111272 (* 1 = 0.111272 loss)
I0403 09:18:04.569430  8106 sgd_solver.cpp:106] Iteration 3315, lr = 0.0005
I0403 09:18:13.742075  8106 solver.cpp:228] Iteration 3328, loss = 0.0203066
I0403 09:18:13.742162  8106 solver.cpp:244]     Train net output #0: loss = 0.0203067 (* 1 = 0.0203067 loss)
I0403 09:18:13.921896  8106 sgd_solver.cpp:106] Iteration 3328, lr = 0.0005
I0403 09:18:23.162008  8106 solver.cpp:228] Iteration 3341, loss = 0.0586783
I0403 09:18:23.162094  8106 solver.cpp:244]     Train net output #0: loss = 0.0586784 (* 1 = 0.0586784 loss)
I0403 09:18:23.341318  8106 sgd_solver.cpp:106] Iteration 3341, lr = 0.0005
I0403 09:18:32.588526  8106 solver.cpp:228] Iteration 3354, loss = 0.0769699
I0403 09:18:32.588814  8106 solver.cpp:244]     Train net output #0: loss = 0.07697 (* 1 = 0.07697 loss)
I0403 09:18:32.764443  8106 sgd_solver.cpp:106] Iteration 3354, lr = 0.0005
I0403 09:18:42.052462  8106 solver.cpp:228] Iteration 3367, loss = 0.101336
I0403 09:18:42.052562  8106 solver.cpp:244]     Train net output #0: loss = 0.101336 (* 1 = 0.101336 loss)
I0403 09:18:42.263402  8106 sgd_solver.cpp:106] Iteration 3367, lr = 0.0005
I0403 09:18:51.530740  8106 solver.cpp:228] Iteration 3380, loss = 0.21508
I0403 09:18:51.530836  8106 solver.cpp:244]     Train net output #0: loss = 0.21508 (* 1 = 0.21508 loss)
I0403 09:18:51.744709  8106 sgd_solver.cpp:106] Iteration 3380, lr = 0.0005
I0403 09:19:01.170164  8106 solver.cpp:228] Iteration 3393, loss = 0.203662
I0403 09:19:01.170253  8106 solver.cpp:244]     Train net output #0: loss = 0.203662 (* 1 = 0.203662 loss)
I0403 09:19:01.351423  8106 sgd_solver.cpp:106] Iteration 3393, lr = 0.0005
I0403 09:19:10.590632  8106 solver.cpp:228] Iteration 3406, loss = 0.0662905
I0403 09:19:10.590914  8106 solver.cpp:244]     Train net output #0: loss = 0.0662905 (* 1 = 0.0662905 loss)
I0403 09:19:10.748908  8106 sgd_solver.cpp:106] Iteration 3406, lr = 0.0005
I0403 09:19:20.011407  8106 solver.cpp:228] Iteration 3419, loss = 0.0618452
I0403 09:19:20.011507  8106 solver.cpp:244]     Train net output #0: loss = 0.0618452 (* 1 = 0.0618452 loss)
I0403 09:19:20.196813  8106 sgd_solver.cpp:106] Iteration 3419, lr = 0.0005
I0403 09:19:29.518101  8106 solver.cpp:228] Iteration 3432, loss = 0.105333
I0403 09:19:29.518188  8106 solver.cpp:244]     Train net output #0: loss = 0.105333 (* 1 = 0.105333 loss)
I0403 09:19:29.684072  8106 sgd_solver.cpp:106] Iteration 3432, lr = 0.0005
I0403 09:19:38.861876  8106 solver.cpp:228] Iteration 3445, loss = 0.0741593
I0403 09:19:38.861991  8106 solver.cpp:244]     Train net output #0: loss = 0.0741594 (* 1 = 0.0741594 loss)
I0403 09:19:39.066009  8106 sgd_solver.cpp:106] Iteration 3445, lr = 0.0005
I0403 09:19:48.479975  8106 solver.cpp:228] Iteration 3458, loss = 0.0320121
I0403 09:19:48.486462  8106 solver.cpp:244]     Train net output #0: loss = 0.0320121 (* 1 = 0.0320121 loss)
I0403 09:19:48.706321  8106 sgd_solver.cpp:106] Iteration 3458, lr = 0.0005
I0403 09:19:57.515602  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_3471.caffemodel
I0403 09:20:00.328075  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_3471.solverstate
I0403 09:20:02.238658  8106 solver.cpp:337] Iteration 3471, Testing net (#0)
I0403 09:21:04.286190  8106 solver.cpp:404]     Test net output #0: accuracy = 0.925091
I0403 09:21:04.286484  8106 solver.cpp:404]     Test net output #1: loss = 0.249184 (* 1 = 0.249184 loss)
I0403 09:21:04.821578  8106 solver.cpp:228] Iteration 3471, loss = 0.0888678
I0403 09:21:04.821661  8106 solver.cpp:244]     Train net output #0: loss = 0.0888678 (* 1 = 0.0888678 loss)
I0403 09:21:04.960793  8106 sgd_solver.cpp:106] Iteration 3471, lr = 0.0005
I0403 09:21:14.232378  8106 solver.cpp:228] Iteration 3484, loss = 0.070202
I0403 09:21:14.232473  8106 solver.cpp:244]     Train net output #0: loss = 0.0702021 (* 1 = 0.0702021 loss)
I0403 09:21:14.419464  8106 sgd_solver.cpp:106] Iteration 3484, lr = 0.0005
I0403 09:21:23.651413  8106 solver.cpp:228] Iteration 3497, loss = 0.144634
I0403 09:21:23.651515  8106 solver.cpp:244]     Train net output #0: loss = 0.144634 (* 1 = 0.144634 loss)
I0403 09:21:23.849396  8106 sgd_solver.cpp:106] Iteration 3497, lr = 0.0005
I0403 09:21:33.211488  8106 solver.cpp:228] Iteration 3510, loss = 0.193894
I0403 09:21:33.211580  8106 solver.cpp:244]     Train net output #0: loss = 0.193894 (* 1 = 0.193894 loss)
I0403 09:21:33.372309  8106 sgd_solver.cpp:106] Iteration 3510, lr = 0.0005
I0403 09:21:42.731415  8106 solver.cpp:228] Iteration 3523, loss = 0.0373874
I0403 09:21:42.731705  8106 solver.cpp:244]     Train net output #0: loss = 0.0373874 (* 1 = 0.0373874 loss)
I0403 09:21:42.905961  8106 sgd_solver.cpp:106] Iteration 3523, lr = 0.0005
I0403 09:21:52.172441  8106 solver.cpp:228] Iteration 3536, loss = 0.0664478
I0403 09:21:52.172545  8106 solver.cpp:244]     Train net output #0: loss = 0.0664479 (* 1 = 0.0664479 loss)
I0403 09:21:52.366551  8106 sgd_solver.cpp:106] Iteration 3536, lr = 0.0005
I0403 09:22:01.540556  8106 solver.cpp:228] Iteration 3549, loss = 0.0930693
I0403 09:22:01.540657  8106 solver.cpp:244]     Train net output #0: loss = 0.0930693 (* 1 = 0.0930693 loss)
I0403 09:22:01.739195  8106 sgd_solver.cpp:106] Iteration 3549, lr = 0.0005
I0403 09:22:11.041918  8106 solver.cpp:228] Iteration 3562, loss = 0.0596188
I0403 09:22:11.042013  8106 solver.cpp:244]     Train net output #0: loss = 0.0596189 (* 1 = 0.0596189 loss)
I0403 09:22:11.254595  8106 sgd_solver.cpp:106] Iteration 3562, lr = 0.0005
I0403 09:22:20.508682  8106 solver.cpp:228] Iteration 3575, loss = 0.118548
I0403 09:22:20.508987  8106 solver.cpp:244]     Train net output #0: loss = 0.118548 (* 1 = 0.118548 loss)
I0403 09:22:20.722110  8106 sgd_solver.cpp:106] Iteration 3575, lr = 0.0005
I0403 09:22:30.074502  8106 solver.cpp:228] Iteration 3588, loss = 0.12997
I0403 09:22:30.074604  8106 solver.cpp:244]     Train net output #0: loss = 0.12997 (* 1 = 0.12997 loss)
I0403 09:22:30.283556  8106 sgd_solver.cpp:106] Iteration 3588, lr = 0.0005
I0403 09:22:39.492697  8106 solver.cpp:228] Iteration 3601, loss = 0.0458419
I0403 09:22:39.492784  8106 solver.cpp:244]     Train net output #0: loss = 0.045842 (* 1 = 0.045842 loss)
I0403 09:22:39.662312  8106 sgd_solver.cpp:106] Iteration 3601, lr = 0.0005
I0403 09:22:48.805554  8106 solver.cpp:228] Iteration 3614, loss = 0.0254168
I0403 09:22:48.805651  8106 solver.cpp:244]     Train net output #0: loss = 0.0254168 (* 1 = 0.0254168 loss)
I0403 09:22:48.997383  8106 sgd_solver.cpp:106] Iteration 3614, lr = 0.0005
I0403 09:22:58.302130  8106 solver.cpp:228] Iteration 3627, loss = 0.0633692
I0403 09:22:58.302429  8106 solver.cpp:244]     Train net output #0: loss = 0.0633692 (* 1 = 0.0633692 loss)
I0403 09:22:58.496345  8106 sgd_solver.cpp:106] Iteration 3627, lr = 0.0005
I0403 09:23:08.103302  8106 solver.cpp:228] Iteration 3640, loss = 0.0433005
I0403 09:23:08.103399  8106 solver.cpp:244]     Train net output #0: loss = 0.0433005 (* 1 = 0.0433005 loss)
I0403 09:23:08.291584  8106 sgd_solver.cpp:106] Iteration 3640, lr = 0.0005
I0403 09:23:17.620326  8106 solver.cpp:228] Iteration 3653, loss = 0.07137
I0403 09:23:17.620424  8106 solver.cpp:244]     Train net output #0: loss = 0.07137 (* 1 = 0.07137 loss)
I0403 09:23:17.830946  8106 sgd_solver.cpp:106] Iteration 3653, lr = 0.0005
I0403 09:23:27.149950  8106 solver.cpp:228] Iteration 3666, loss = 0.0931764
I0403 09:23:27.150038  8106 solver.cpp:244]     Train net output #0: loss = 0.0931764 (* 1 = 0.0931764 loss)
I0403 09:23:27.330278  8106 sgd_solver.cpp:106] Iteration 3666, lr = 0.0005
I0403 09:23:36.548966  8106 solver.cpp:228] Iteration 3679, loss = 0.0268236
I0403 09:23:36.549285  8106 solver.cpp:244]     Train net output #0: loss = 0.0268236 (* 1 = 0.0268236 loss)
I0403 09:23:36.766878  8106 sgd_solver.cpp:106] Iteration 3679, lr = 0.0005
I0403 09:23:45.977340  8106 solver.cpp:228] Iteration 3692, loss = 0.0487353
I0403 09:23:45.977429  8106 solver.cpp:244]     Train net output #0: loss = 0.0487353 (* 1 = 0.0487353 loss)
I0403 09:23:46.147258  8106 sgd_solver.cpp:106] Iteration 3692, lr = 0.0005
I0403 09:23:55.475608  8106 solver.cpp:228] Iteration 3705, loss = 0.0882059
I0403 09:23:55.475706  8106 solver.cpp:244]     Train net output #0: loss = 0.0882059 (* 1 = 0.0882059 loss)
I0403 09:23:55.659055  8106 sgd_solver.cpp:106] Iteration 3705, lr = 0.0005
I0403 09:24:05.280622  8106 solver.cpp:228] Iteration 3718, loss = 0.0250153
I0403 09:24:05.280711  8106 solver.cpp:244]     Train net output #0: loss = 0.0250153 (* 1 = 0.0250153 loss)
I0403 09:24:05.462446  8106 sgd_solver.cpp:106] Iteration 3718, lr = 0.0005
I0403 09:24:14.785099  8106 solver.cpp:228] Iteration 3731, loss = 0.0866983
I0403 09:24:14.785397  8106 solver.cpp:244]     Train net output #0: loss = 0.0866984 (* 1 = 0.0866984 loss)
I0403 09:24:15.000315  8106 sgd_solver.cpp:106] Iteration 3731, lr = 0.0005
I0403 09:24:19.333225  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_3738.caffemodel
I0403 09:24:22.095242  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_3738.solverstate
I0403 09:24:23.982630  8106 solver.cpp:337] Iteration 3738, Testing net (#0)
I0403 09:25:26.044085  8106 solver.cpp:404]     Test net output #0: accuracy = 0.926363
I0403 09:25:26.044379  8106 solver.cpp:404]     Test net output #1: loss = 0.246494 (* 1 = 0.246494 loss)
I0403 09:25:30.923715  8106 solver.cpp:228] Iteration 3744, loss = 0.0380262
I0403 09:25:30.923799  8106 solver.cpp:244]     Train net output #0: loss = 0.0380262 (* 1 = 0.0380262 loss)
I0403 09:25:31.094872  8106 sgd_solver.cpp:106] Iteration 3744, lr = 0.0005
I0403 09:25:40.325201  8106 solver.cpp:228] Iteration 3757, loss = 0.0695361
I0403 09:25:40.325284  8106 solver.cpp:244]     Train net output #0: loss = 0.0695361 (* 1 = 0.0695361 loss)
I0403 09:25:40.502324  8106 sgd_solver.cpp:106] Iteration 3757, lr = 0.0005
I0403 09:25:49.885236  8106 solver.cpp:228] Iteration 3770, loss = 0.0450942
I0403 09:25:49.885320  8106 solver.cpp:244]     Train net output #0: loss = 0.0450942 (* 1 = 0.0450942 loss)
I0403 09:25:50.063123  8106 sgd_solver.cpp:106] Iteration 3770, lr = 0.0005
I0403 09:25:59.253172  8106 solver.cpp:228] Iteration 3783, loss = 0.049239
I0403 09:25:59.253494  8106 solver.cpp:244]     Train net output #0: loss = 0.049239 (* 1 = 0.049239 loss)
I0403 09:25:59.417471  8106 sgd_solver.cpp:106] Iteration 3783, lr = 0.0005
I0403 09:26:08.797997  8106 solver.cpp:228] Iteration 3796, loss = 0.0863201
I0403 09:26:08.798084  8106 solver.cpp:244]     Train net output #0: loss = 0.0863201 (* 1 = 0.0863201 loss)
I0403 09:26:08.947357  8106 sgd_solver.cpp:106] Iteration 3796, lr = 0.0005
I0403 09:26:18.254112  8106 solver.cpp:228] Iteration 3809, loss = 0.048099
I0403 09:26:18.254210  8106 solver.cpp:244]     Train net output #0: loss = 0.048099 (* 1 = 0.048099 loss)
I0403 09:26:18.450078  8106 sgd_solver.cpp:106] Iteration 3809, lr = 0.0005
I0403 09:26:27.613179  8106 solver.cpp:228] Iteration 3822, loss = 0.0907939
I0403 09:26:27.613276  8106 solver.cpp:244]     Train net output #0: loss = 0.0907939 (* 1 = 0.0907939 loss)
I0403 09:26:27.795207  8106 sgd_solver.cpp:106] Iteration 3822, lr = 0.0005
I0403 09:26:37.130014  8106 solver.cpp:228] Iteration 3835, loss = 0.0334981
I0403 09:26:37.130316  8106 solver.cpp:244]     Train net output #0: loss = 0.0334982 (* 1 = 0.0334982 loss)
I0403 09:26:37.311731  8106 sgd_solver.cpp:106] Iteration 3835, lr = 0.0005
I0403 09:26:46.525261  8106 solver.cpp:228] Iteration 3848, loss = 0.0923797
I0403 09:26:46.525359  8106 solver.cpp:244]     Train net output #0: loss = 0.0923798 (* 1 = 0.0923798 loss)
I0403 09:26:46.722244  8106 sgd_solver.cpp:106] Iteration 3848, lr = 0.0005
I0403 09:26:55.956512  8106 solver.cpp:228] Iteration 3861, loss = 0.0580631
I0403 09:26:55.956599  8106 solver.cpp:244]     Train net output #0: loss = 0.0580631 (* 1 = 0.0580631 loss)
I0403 09:26:56.122412  8106 sgd_solver.cpp:106] Iteration 3861, lr = 0.0005
I0403 09:27:05.518581  8106 solver.cpp:228] Iteration 3874, loss = 0.0519551
I0403 09:27:05.518669  8106 solver.cpp:244]     Train net output #0: loss = 0.0519551 (* 1 = 0.0519551 loss)
I0403 09:27:05.693687  8106 sgd_solver.cpp:106] Iteration 3874, lr = 0.0005
I0403 09:27:14.880420  8106 solver.cpp:228] Iteration 3887, loss = 0.137298
I0403 09:27:14.880712  8106 solver.cpp:244]     Train net output #0: loss = 0.137298 (* 1 = 0.137298 loss)
I0403 09:27:15.067571  8106 sgd_solver.cpp:106] Iteration 3887, lr = 0.0005
I0403 09:27:24.323796  8106 solver.cpp:228] Iteration 3900, loss = 0.0559902
I0403 09:27:24.323882  8106 solver.cpp:244]     Train net output #0: loss = 0.0559902 (* 1 = 0.0559902 loss)
I0403 09:27:24.492130  8106 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0403 09:27:33.674932  8106 solver.cpp:228] Iteration 3913, loss = 0.0524813
I0403 09:27:33.675031  8106 solver.cpp:244]     Train net output #0: loss = 0.0524813 (* 1 = 0.0524813 loss)
I0403 09:27:33.881722  8106 sgd_solver.cpp:106] Iteration 3913, lr = 0.0005
I0403 09:27:43.130210  8106 solver.cpp:228] Iteration 3926, loss = 0.0236773
I0403 09:27:43.130306  8106 solver.cpp:244]     Train net output #0: loss = 0.0236774 (* 1 = 0.0236774 loss)
I0403 09:27:43.318055  8106 sgd_solver.cpp:106] Iteration 3926, lr = 0.0005
I0403 09:27:52.636171  8106 solver.cpp:228] Iteration 3939, loss = 0.0586303
I0403 09:27:52.636450  8106 solver.cpp:244]     Train net output #0: loss = 0.0586303 (* 1 = 0.0586303 loss)
I0403 09:27:52.809150  8106 sgd_solver.cpp:106] Iteration 3939, lr = 0.0005
I0403 09:28:02.206037  8106 solver.cpp:228] Iteration 3952, loss = 0.143827
I0403 09:28:02.206123  8106 solver.cpp:244]     Train net output #0: loss = 0.143827 (* 1 = 0.143827 loss)
I0403 09:28:02.356426  8106 sgd_solver.cpp:106] Iteration 3952, lr = 0.0005
I0403 09:28:11.598583  8106 solver.cpp:228] Iteration 3965, loss = 0.0511699
I0403 09:28:11.598670  8106 solver.cpp:244]     Train net output #0: loss = 0.0511699 (* 1 = 0.0511699 loss)
I0403 09:28:11.775733  8106 sgd_solver.cpp:106] Iteration 3965, lr = 0.0005
I0403 09:28:21.025838  8106 solver.cpp:228] Iteration 3978, loss = 0.041356
I0403 09:28:21.025939  8106 solver.cpp:244]     Train net output #0: loss = 0.041356 (* 1 = 0.041356 loss)
I0403 09:28:21.235134  8106 sgd_solver.cpp:106] Iteration 3978, lr = 0.0005
I0403 09:28:30.487251  8106 solver.cpp:228] Iteration 3991, loss = 0.118516
I0403 09:28:30.487561  8106 solver.cpp:244]     Train net output #0: loss = 0.118516 (* 1 = 0.118516 loss)
I0403 09:28:30.651733  8106 sgd_solver.cpp:106] Iteration 3991, lr = 0.0005
I0403 09:28:40.016058  8106 solver.cpp:228] Iteration 4004, loss = 0.0577928
I0403 09:28:40.016144  8106 solver.cpp:244]     Train net output #0: loss = 0.0577929 (* 1 = 0.0577929 loss)
I0403 09:28:40.174582  8106 sgd_solver.cpp:106] Iteration 4004, lr = 0.0005
I0403 09:28:40.174829  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4005.caffemodel
I0403 09:28:43.005126  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4005.solverstate
I0403 09:28:44.902137  8106 solver.cpp:337] Iteration 4005, Testing net (#0)
I0403 09:29:46.963511  8106 solver.cpp:404]     Test net output #0: accuracy = 0.925527
I0403 09:29:46.963852  8106 solver.cpp:404]     Test net output #1: loss = 0.255308 (* 1 = 0.255308 loss)
I0403 09:29:56.202056  8106 solver.cpp:228] Iteration 4017, loss = 0.0587647
I0403 09:29:56.202149  8106 solver.cpp:244]     Train net output #0: loss = 0.0587647 (* 1 = 0.0587647 loss)
I0403 09:29:56.393205  8106 sgd_solver.cpp:106] Iteration 4017, lr = 0.0005
I0403 09:30:05.655236  8106 solver.cpp:228] Iteration 4030, loss = 0.0658417
I0403 09:30:05.655323  8106 solver.cpp:244]     Train net output #0: loss = 0.0658418 (* 1 = 0.0658418 loss)
I0403 09:30:05.829468  8106 sgd_solver.cpp:106] Iteration 4030, lr = 0.0005
I0403 09:30:15.157250  8106 solver.cpp:228] Iteration 4043, loss = 0.0907698
I0403 09:30:15.157347  8106 solver.cpp:244]     Train net output #0: loss = 0.0907699 (* 1 = 0.0907699 loss)
I0403 09:30:15.351001  8106 sgd_solver.cpp:106] Iteration 4043, lr = 0.0005
I0403 09:30:24.608407  8106 solver.cpp:228] Iteration 4056, loss = 0.135799
I0403 09:30:24.608712  8106 solver.cpp:244]     Train net output #0: loss = 0.135799 (* 1 = 0.135799 loss)
I0403 09:30:24.789937  8106 sgd_solver.cpp:106] Iteration 4056, lr = 0.0005
I0403 09:30:33.963403  8106 solver.cpp:228] Iteration 4069, loss = 0.103063
I0403 09:30:33.963503  8106 solver.cpp:244]     Train net output #0: loss = 0.103063 (* 1 = 0.103063 loss)
I0403 09:30:34.151891  8106 sgd_solver.cpp:106] Iteration 4069, lr = 0.0005
I0403 09:30:43.583281  8106 solver.cpp:228] Iteration 4082, loss = 0.0902072
I0403 09:30:43.583367  8106 solver.cpp:244]     Train net output #0: loss = 0.0902072 (* 1 = 0.0902072 loss)
I0403 09:30:43.754200  8106 sgd_solver.cpp:106] Iteration 4082, lr = 0.0005
I0403 09:30:53.388633  8106 solver.cpp:228] Iteration 4095, loss = 0.0512569
I0403 09:30:53.388733  8106 solver.cpp:244]     Train net output #0: loss = 0.051257 (* 1 = 0.051257 loss)
I0403 09:30:53.570504  8106 sgd_solver.cpp:106] Iteration 4095, lr = 0.0005
I0403 09:31:02.813509  8106 solver.cpp:228] Iteration 4108, loss = 0.0230666
I0403 09:31:02.813796  8106 solver.cpp:244]     Train net output #0: loss = 0.0230666 (* 1 = 0.0230666 loss)
I0403 09:31:02.992045  8106 sgd_solver.cpp:106] Iteration 4108, lr = 0.0005
I0403 09:31:12.272071  8106 solver.cpp:228] Iteration 4121, loss = 0.0581038
I0403 09:31:12.272169  8106 solver.cpp:244]     Train net output #0: loss = 0.0581038 (* 1 = 0.0581038 loss)
I0403 09:31:12.459440  8106 sgd_solver.cpp:106] Iteration 4121, lr = 0.0005
I0403 09:31:21.716621  8106 solver.cpp:228] Iteration 4134, loss = 0.0680568
I0403 09:31:21.716722  8106 solver.cpp:244]     Train net output #0: loss = 0.0680568 (* 1 = 0.0680568 loss)
I0403 09:31:21.903434  8106 sgd_solver.cpp:106] Iteration 4134, lr = 0.0005
I0403 09:31:31.275354  8106 solver.cpp:228] Iteration 4147, loss = 0.0773391
I0403 09:31:31.275451  8106 solver.cpp:244]     Train net output #0: loss = 0.0773391 (* 1 = 0.0773391 loss)
I0403 09:31:31.464664  8106 sgd_solver.cpp:106] Iteration 4147, lr = 0.0005
I0403 09:31:40.744006  8106 solver.cpp:228] Iteration 4160, loss = 0.089005
I0403 09:31:40.744302  8106 solver.cpp:244]     Train net output #0: loss = 0.089005 (* 1 = 0.089005 loss)
I0403 09:31:40.880610  8106 sgd_solver.cpp:106] Iteration 4160, lr = 0.0005
I0403 09:31:50.164269  8106 solver.cpp:228] Iteration 4173, loss = 0.0372667
I0403 09:31:50.164366  8106 solver.cpp:244]     Train net output #0: loss = 0.0372667 (* 1 = 0.0372667 loss)
I0403 09:31:50.346281  8106 sgd_solver.cpp:106] Iteration 4173, lr = 0.0005
I0403 09:31:59.856997  8106 solver.cpp:228] Iteration 4186, loss = 0.0695209
I0403 09:31:59.857084  8106 solver.cpp:244]     Train net output #0: loss = 0.0695209 (* 1 = 0.0695209 loss)
I0403 09:31:59.996830  8106 sgd_solver.cpp:106] Iteration 4186, lr = 0.0005
I0403 09:32:09.449967  8106 solver.cpp:228] Iteration 4199, loss = 0.0690888
I0403 09:32:09.450054  8106 solver.cpp:244]     Train net output #0: loss = 0.0690888 (* 1 = 0.0690888 loss)
I0403 09:32:09.629678  8106 sgd_solver.cpp:106] Iteration 4199, lr = 0.0005
I0403 09:32:18.990396  8106 solver.cpp:228] Iteration 4212, loss = 0.03471
I0403 09:32:18.990707  8106 solver.cpp:244]     Train net output #0: loss = 0.03471 (* 1 = 0.03471 loss)
I0403 09:32:19.175130  8106 sgd_solver.cpp:106] Iteration 4212, lr = 0.0005
I0403 09:32:28.532819  8106 solver.cpp:228] Iteration 4225, loss = 0.121829
I0403 09:32:28.532917  8106 solver.cpp:244]     Train net output #0: loss = 0.121829 (* 1 = 0.121829 loss)
I0403 09:32:28.714787  8106 sgd_solver.cpp:106] Iteration 4225, lr = 0.0005
I0403 09:32:37.967707  8106 solver.cpp:228] Iteration 4238, loss = 0.0817188
I0403 09:32:37.967805  8106 solver.cpp:244]     Train net output #0: loss = 0.0817188 (* 1 = 0.0817188 loss)
I0403 09:32:38.165910  8106 sgd_solver.cpp:106] Iteration 4238, lr = 0.0005
I0403 09:32:47.458250  8106 solver.cpp:228] Iteration 4251, loss = 0.0305378
I0403 09:32:47.458348  8106 solver.cpp:244]     Train net output #0: loss = 0.0305379 (* 1 = 0.0305379 loss)
I0403 09:32:47.676888  8106 sgd_solver.cpp:106] Iteration 4251, lr = 0.0005
I0403 09:32:56.974882  8106 solver.cpp:228] Iteration 4264, loss = 0.0480324
I0403 09:32:56.975178  8106 solver.cpp:244]     Train net output #0: loss = 0.0480324 (* 1 = 0.0480324 loss)
I0403 09:32:57.169137  8106 sgd_solver.cpp:106] Iteration 4264, lr = 0.0005
I0403 09:33:02.379123  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4272.caffemodel
I0403 09:33:05.122148  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4272.solverstate
I0403 09:33:06.894194  8106 solver.cpp:337] Iteration 4272, Testing net (#0)
I0403 09:34:08.966933  8106 solver.cpp:404]     Test net output #0: accuracy = 0.927527
I0403 09:34:08.967212  8106 solver.cpp:404]     Test net output #1: loss = 0.249567 (* 1 = 0.249567 loss)
I0403 09:34:13.208747  8106 solver.cpp:228] Iteration 4277, loss = 0.0736666
I0403 09:34:13.208832  8106 solver.cpp:244]     Train net output #0: loss = 0.0736666 (* 1 = 0.0736666 loss)
I0403 09:34:13.382488  8106 sgd_solver.cpp:106] Iteration 4277, lr = 0.0005
I0403 09:34:22.565666  8106 solver.cpp:228] Iteration 4290, loss = 0.0918992
I0403 09:34:22.565764  8106 solver.cpp:244]     Train net output #0: loss = 0.0918993 (* 1 = 0.0918993 loss)
I0403 09:34:22.755440  8106 sgd_solver.cpp:106] Iteration 4290, lr = 0.0005
I0403 09:34:32.185288  8106 solver.cpp:228] Iteration 4303, loss = 0.0981216
I0403 09:34:32.185376  8106 solver.cpp:244]     Train net output #0: loss = 0.0981216 (* 1 = 0.0981216 loss)
I0403 09:34:32.290887  8106 sgd_solver.cpp:106] Iteration 4303, lr = 0.0005
I0403 09:34:41.651973  8106 solver.cpp:228] Iteration 4316, loss = 0.124165
I0403 09:34:41.652238  8106 solver.cpp:244]     Train net output #0: loss = 0.124165 (* 1 = 0.124165 loss)
I0403 09:34:41.829674  8106 sgd_solver.cpp:106] Iteration 4316, lr = 0.0005
I0403 09:34:51.014714  8106 solver.cpp:228] Iteration 4329, loss = 0.0627503
I0403 09:34:51.014813  8106 solver.cpp:244]     Train net output #0: loss = 0.0627504 (* 1 = 0.0627504 loss)
I0403 09:34:51.202774  8106 sgd_solver.cpp:106] Iteration 4329, lr = 0.0005
I0403 09:35:00.614893  8106 solver.cpp:228] Iteration 4342, loss = 0.0436681
I0403 09:35:00.614991  8106 solver.cpp:244]     Train net output #0: loss = 0.0436681 (* 1 = 0.0436681 loss)
I0403 09:35:00.826174  8106 sgd_solver.cpp:106] Iteration 4342, lr = 0.0005
I0403 09:35:09.943168  8106 solver.cpp:228] Iteration 4355, loss = 0.0720194
I0403 09:35:09.943265  8106 solver.cpp:244]     Train net output #0: loss = 0.0720195 (* 1 = 0.0720195 loss)
I0403 09:35:10.142581  8106 sgd_solver.cpp:106] Iteration 4355, lr = 0.0005
I0403 09:35:19.523386  8106 solver.cpp:228] Iteration 4368, loss = 0.14883
I0403 09:35:19.527634  8106 solver.cpp:244]     Train net output #0: loss = 0.14883 (* 1 = 0.14883 loss)
I0403 09:35:19.692698  8106 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 09:35:29.235100  8106 solver.cpp:228] Iteration 4381, loss = 0.149084
I0403 09:35:29.235195  8106 solver.cpp:244]     Train net output #0: loss = 0.149084 (* 1 = 0.149084 loss)
I0403 09:35:29.422405  8106 sgd_solver.cpp:106] Iteration 4381, lr = 0.0005
I0403 09:35:38.638561  8106 solver.cpp:228] Iteration 4394, loss = 0.0557843
I0403 09:35:38.638650  8106 solver.cpp:244]     Train net output #0: loss = 0.0557844 (* 1 = 0.0557844 loss)
I0403 09:35:38.811049  8106 sgd_solver.cpp:106] Iteration 4394, lr = 0.0005
I0403 09:35:48.456204  8106 solver.cpp:228] Iteration 4407, loss = 0.0168751
I0403 09:35:48.456293  8106 solver.cpp:244]     Train net output #0: loss = 0.0168751 (* 1 = 0.0168751 loss)
I0403 09:35:48.603772  8106 sgd_solver.cpp:106] Iteration 4407, lr = 0.0005
I0403 09:35:58.028337  8106 solver.cpp:228] Iteration 4420, loss = 0.105301
I0403 09:35:58.028627  8106 solver.cpp:244]     Train net output #0: loss = 0.105301 (* 1 = 0.105301 loss)
I0403 09:35:58.191629  8106 sgd_solver.cpp:106] Iteration 4420, lr = 0.0005
I0403 09:36:07.469048  8106 solver.cpp:228] Iteration 4433, loss = 0.0908319
I0403 09:36:07.469146  8106 solver.cpp:244]     Train net output #0: loss = 0.0908319 (* 1 = 0.0908319 loss)
I0403 09:36:07.685322  8106 sgd_solver.cpp:106] Iteration 4433, lr = 0.0005
I0403 09:36:16.873138  8106 solver.cpp:228] Iteration 4446, loss = 0.0245449
I0403 09:36:16.873237  8106 solver.cpp:244]     Train net output #0: loss = 0.024545 (* 1 = 0.024545 loss)
I0403 09:36:17.065795  8106 sgd_solver.cpp:106] Iteration 4446, lr = 0.0005
I0403 09:36:26.232748  8106 solver.cpp:228] Iteration 4459, loss = 0.0778311
I0403 09:36:26.232844  8106 solver.cpp:244]     Train net output #0: loss = 0.0778312 (* 1 = 0.0778312 loss)
I0403 09:36:26.419253  8106 sgd_solver.cpp:106] Iteration 4459, lr = 0.0005
I0403 09:36:35.667593  8106 solver.cpp:228] Iteration 4472, loss = 0.099592
I0403 09:36:35.667882  8106 solver.cpp:244]     Train net output #0: loss = 0.099592 (* 1 = 0.099592 loss)
I0403 09:36:35.845885  8106 sgd_solver.cpp:106] Iteration 4472, lr = 0.0005
I0403 09:36:45.025291  8106 solver.cpp:228] Iteration 4485, loss = 0.0599597
I0403 09:36:45.025389  8106 solver.cpp:244]     Train net output #0: loss = 0.0599598 (* 1 = 0.0599598 loss)
I0403 09:36:45.207095  8106 sgd_solver.cpp:106] Iteration 4485, lr = 0.0005
I0403 09:36:54.404463  8106 solver.cpp:228] Iteration 4498, loss = 0.0330947
I0403 09:36:54.404561  8106 solver.cpp:244]     Train net output #0: loss = 0.0330948 (* 1 = 0.0330948 loss)
I0403 09:36:54.582103  8106 sgd_solver.cpp:106] Iteration 4498, lr = 0.0005
I0403 09:37:03.731972  8106 solver.cpp:228] Iteration 4511, loss = 0.0749378
I0403 09:37:03.732084  8106 solver.cpp:244]     Train net output #0: loss = 0.0749378 (* 1 = 0.0749378 loss)
I0403 09:37:03.928243  8106 sgd_solver.cpp:106] Iteration 4511, lr = 0.0005
I0403 09:37:13.118186  8106 solver.cpp:228] Iteration 4524, loss = 0.0331466
I0403 09:37:13.118497  8106 solver.cpp:244]     Train net output #0: loss = 0.0331466 (* 1 = 0.0331466 loss)
I0403 09:37:13.311779  8106 sgd_solver.cpp:106] Iteration 4524, lr = 0.0005
I0403 09:37:22.640724  8106 solver.cpp:228] Iteration 4537, loss = 0.0196896
I0403 09:37:22.640822  8106 solver.cpp:244]     Train net output #0: loss = 0.0196897 (* 1 = 0.0196897 loss)
I0403 09:37:22.833261  8106 sgd_solver.cpp:106] Iteration 4537, lr = 0.0005
I0403 09:37:23.543855  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4539.caffemodel
I0403 09:37:26.267786  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4539.solverstate
I0403 09:37:28.116133  8106 solver.cpp:337] Iteration 4539, Testing net (#0)
I0403 09:38:30.172838  8106 solver.cpp:404]     Test net output #0: accuracy = 0.928509
I0403 09:38:30.173151  8106 solver.cpp:404]     Test net output #1: loss = 0.245837 (* 1 = 0.245837 loss)
I0403 09:38:38.806303  8106 solver.cpp:228] Iteration 4550, loss = 0.0419303
I0403 09:38:38.806391  8106 solver.cpp:244]     Train net output #0: loss = 0.0419303 (* 1 = 0.0419303 loss)
I0403 09:38:38.985929  8106 sgd_solver.cpp:106] Iteration 4550, lr = 0.0005
I0403 09:38:48.345125  8106 solver.cpp:228] Iteration 4563, loss = 0.124199
I0403 09:38:48.345226  8106 solver.cpp:244]     Train net output #0: loss = 0.124199 (* 1 = 0.124199 loss)
I0403 09:38:48.553195  8106 sgd_solver.cpp:106] Iteration 4563, lr = 0.0005
I0403 09:38:57.703162  8106 solver.cpp:228] Iteration 4576, loss = 0.0368542
I0403 09:38:57.703251  8106 solver.cpp:244]     Train net output #0: loss = 0.0368542 (* 1 = 0.0368542 loss)
I0403 09:38:57.879158  8106 sgd_solver.cpp:106] Iteration 4576, lr = 0.0005
I0403 09:39:07.100633  8106 solver.cpp:228] Iteration 4589, loss = 0.0272664
I0403 09:39:07.100925  8106 solver.cpp:244]     Train net output #0: loss = 0.0272664 (* 1 = 0.0272664 loss)
I0403 09:39:07.231819  8106 sgd_solver.cpp:106] Iteration 4589, lr = 0.0005
I0403 09:39:16.526619  8106 solver.cpp:228] Iteration 4602, loss = 0.0300075
I0403 09:39:16.526716  8106 solver.cpp:244]     Train net output #0: loss = 0.0300075 (* 1 = 0.0300075 loss)
I0403 09:39:16.711608  8106 sgd_solver.cpp:106] Iteration 4602, lr = 0.0005
I0403 09:39:25.970074  8106 solver.cpp:228] Iteration 4615, loss = 0.0718819
I0403 09:39:25.970171  8106 solver.cpp:244]     Train net output #0: loss = 0.071882 (* 1 = 0.071882 loss)
I0403 09:39:26.158532  8106 sgd_solver.cpp:106] Iteration 4615, lr = 0.0005
I0403 09:39:35.453462  8106 solver.cpp:228] Iteration 4628, loss = 0.0552536
I0403 09:39:35.453563  8106 solver.cpp:244]     Train net output #0: loss = 0.0552537 (* 1 = 0.0552537 loss)
I0403 09:39:35.644460  8106 sgd_solver.cpp:106] Iteration 4628, lr = 0.0005
I0403 09:39:44.969563  8106 solver.cpp:228] Iteration 4641, loss = 0.0624781
I0403 09:39:44.969859  8106 solver.cpp:244]     Train net output #0: loss = 0.0624781 (* 1 = 0.0624781 loss)
I0403 09:39:45.176252  8106 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 09:39:54.563606  8106 solver.cpp:228] Iteration 4654, loss = 0.0392881
I0403 09:39:54.563704  8106 solver.cpp:244]     Train net output #0: loss = 0.0392881 (* 1 = 0.0392881 loss)
I0403 09:39:54.749174  8106 sgd_solver.cpp:106] Iteration 4654, lr = 0.0005
I0403 09:40:04.016170  8106 solver.cpp:228] Iteration 4667, loss = 0.0445473
I0403 09:40:04.016265  8106 solver.cpp:244]     Train net output #0: loss = 0.0445473 (* 1 = 0.0445473 loss)
I0403 09:40:04.215955  8106 sgd_solver.cpp:106] Iteration 4667, lr = 0.0005
I0403 09:40:13.483105  8106 solver.cpp:228] Iteration 4680, loss = 0.0496551
I0403 09:40:13.483202  8106 solver.cpp:244]     Train net output #0: loss = 0.0496551 (* 1 = 0.0496551 loss)
I0403 09:40:13.712882  8106 sgd_solver.cpp:106] Iteration 4680, lr = 0.0005
I0403 09:40:22.975049  8106 solver.cpp:228] Iteration 4693, loss = 0.0556262
I0403 09:40:22.975340  8106 solver.cpp:244]     Train net output #0: loss = 0.0556262 (* 1 = 0.0556262 loss)
I0403 09:40:23.156193  8106 sgd_solver.cpp:106] Iteration 4693, lr = 0.0005
I0403 09:40:32.431897  8106 solver.cpp:228] Iteration 4706, loss = 0.0732498
I0403 09:40:32.431988  8106 solver.cpp:244]     Train net output #0: loss = 0.0732498 (* 1 = 0.0732498 loss)
I0403 09:40:32.603754  8106 sgd_solver.cpp:106] Iteration 4706, lr = 0.0005
I0403 09:40:42.020619  8106 solver.cpp:228] Iteration 4719, loss = 0.0662058
I0403 09:40:42.020709  8106 solver.cpp:244]     Train net output #0: loss = 0.0662058 (* 1 = 0.0662058 loss)
I0403 09:40:42.174991  8106 sgd_solver.cpp:106] Iteration 4719, lr = 0.0005
I0403 09:40:51.550359  8106 solver.cpp:228] Iteration 4732, loss = 0.0459867
I0403 09:40:51.550446  8106 solver.cpp:244]     Train net output #0: loss = 0.0459867 (* 1 = 0.0459867 loss)
I0403 09:40:51.718497  8106 sgd_solver.cpp:106] Iteration 4732, lr = 0.0005
I0403 09:41:01.084319  8106 solver.cpp:228] Iteration 4745, loss = 0.0895427
I0403 09:41:01.084651  8106 solver.cpp:244]     Train net output #0: loss = 0.0895427 (* 1 = 0.0895427 loss)
I0403 09:41:01.286305  8106 sgd_solver.cpp:106] Iteration 4745, lr = 0.0005
I0403 09:41:10.531297  8106 solver.cpp:228] Iteration 4758, loss = 0.0396788
I0403 09:41:10.531399  8106 solver.cpp:244]     Train net output #0: loss = 0.0396788 (* 1 = 0.0396788 loss)
I0403 09:41:10.716784  8106 sgd_solver.cpp:106] Iteration 4758, lr = 0.0005
I0403 09:41:19.925962  8106 solver.cpp:228] Iteration 4771, loss = 0.010782
I0403 09:41:19.926049  8106 solver.cpp:244]     Train net output #0: loss = 0.010782 (* 1 = 0.010782 loss)
I0403 09:41:20.103621  8106 sgd_solver.cpp:106] Iteration 4771, lr = 0.0005
I0403 09:41:29.377326  8106 solver.cpp:228] Iteration 4784, loss = 0.0977838
I0403 09:41:29.377413  8106 solver.cpp:244]     Train net output #0: loss = 0.0977838 (* 1 = 0.0977838 loss)
I0403 09:41:29.524246  8106 sgd_solver.cpp:106] Iteration 4784, lr = 0.0005
I0403 09:41:38.948340  8106 solver.cpp:228] Iteration 4797, loss = 0.0309741
I0403 09:41:38.948591  8106 solver.cpp:244]     Train net output #0: loss = 0.0309741 (* 1 = 0.0309741 loss)
I0403 09:41:39.133041  8106 sgd_solver.cpp:106] Iteration 4797, lr = 0.0005
I0403 09:41:45.016379  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4806.caffemodel
I0403 09:41:47.777799  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_4806.solverstate
I0403 09:41:49.643916  8106 solver.cpp:337] Iteration 4806, Testing net (#0)
I0403 09:42:51.703330  8106 solver.cpp:404]     Test net output #0: accuracy = 0.928618
I0403 09:42:51.703649  8106 solver.cpp:404]     Test net output #1: loss = 0.250282 (* 1 = 0.250282 loss)
I0403 09:42:55.115005  8106 solver.cpp:228] Iteration 4810, loss = 0.0300535
I0403 09:42:55.115103  8106 solver.cpp:244]     Train net output #0: loss = 0.0300535 (* 1 = 0.0300535 loss)
I0403 09:42:55.365452  8106 sgd_solver.cpp:106] Iteration 4810, lr = 0.0005
I0403 09:43:04.515305  8106 solver.cpp:228] Iteration 4823, loss = 0.0431815
I0403 09:43:04.515393  8106 solver.cpp:244]     Train net output #0: loss = 0.0431815 (* 1 = 0.0431815 loss)
I0403 09:43:04.665494  8106 sgd_solver.cpp:106] Iteration 4823, lr = 0.0005
I0403 09:43:13.989717  8106 solver.cpp:228] Iteration 4836, loss = 0.0174058
I0403 09:43:13.989814  8106 solver.cpp:244]     Train net output #0: loss = 0.0174059 (* 1 = 0.0174059 loss)
I0403 09:43:14.173337  8106 sgd_solver.cpp:106] Iteration 4836, lr = 0.0005
I0403 09:43:23.384235  8106 solver.cpp:228] Iteration 4849, loss = 0.109712
I0403 09:43:23.384511  8106 solver.cpp:244]     Train net output #0: loss = 0.109712 (* 1 = 0.109712 loss)
I0403 09:43:23.554811  8106 sgd_solver.cpp:106] Iteration 4849, lr = 0.0005
I0403 09:43:32.694749  8106 solver.cpp:228] Iteration 4862, loss = 0.0637233
I0403 09:43:32.694854  8106 solver.cpp:244]     Train net output #0: loss = 0.0637233 (* 1 = 0.0637233 loss)
I0403 09:43:32.916797  8106 sgd_solver.cpp:106] Iteration 4862, lr = 0.0005
I0403 09:43:42.126106  8106 solver.cpp:228] Iteration 4875, loss = 0.0763548
I0403 09:43:42.126194  8106 solver.cpp:244]     Train net output #0: loss = 0.0763549 (* 1 = 0.0763549 loss)
I0403 09:43:42.302258  8106 sgd_solver.cpp:106] Iteration 4875, lr = 0.0005
I0403 09:43:51.629487  8106 solver.cpp:228] Iteration 4888, loss = 0.0386127
I0403 09:43:51.629603  8106 solver.cpp:244]     Train net output #0: loss = 0.0386127 (* 1 = 0.0386127 loss)
I0403 09:43:51.811233  8106 sgd_solver.cpp:106] Iteration 4888, lr = 0.0005
I0403 09:44:01.203711  8106 solver.cpp:228] Iteration 4901, loss = 0.0296914
I0403 09:44:01.204036  8106 solver.cpp:244]     Train net output #0: loss = 0.0296914 (* 1 = 0.0296914 loss)
I0403 09:44:01.399186  8106 sgd_solver.cpp:106] Iteration 4901, lr = 0.0005
I0403 09:44:10.566705  8106 solver.cpp:228] Iteration 4914, loss = 0.0426927
I0403 09:44:10.566792  8106 solver.cpp:244]     Train net output #0: loss = 0.0426928 (* 1 = 0.0426928 loss)
I0403 09:44:10.743286  8106 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 09:44:19.900741  8106 solver.cpp:228] Iteration 4927, loss = 0.0170339
I0403 09:44:19.900842  8106 solver.cpp:244]     Train net output #0: loss = 0.0170339 (* 1 = 0.0170339 loss)
I0403 09:44:20.106027  8106 sgd_solver.cpp:106] Iteration 4927, lr = 0.0005
I0403 09:44:29.320864  8106 solver.cpp:228] Iteration 4940, loss = 0.0520081
I0403 09:44:29.320963  8106 solver.cpp:244]     Train net output #0: loss = 0.0520081 (* 1 = 0.0520081 loss)
I0403 09:44:29.512224  8106 sgd_solver.cpp:106] Iteration 4940, lr = 0.0005
I0403 09:44:38.730339  8106 solver.cpp:228] Iteration 4953, loss = 0.0626798
I0403 09:44:38.730614  8106 solver.cpp:244]     Train net output #0: loss = 0.0626799 (* 1 = 0.0626799 loss)
I0403 09:44:38.902235  8106 sgd_solver.cpp:106] Iteration 4953, lr = 0.0005
I0403 09:44:48.240923  8106 solver.cpp:228] Iteration 4966, loss = 0.0521384
I0403 09:44:48.241011  8106 solver.cpp:244]     Train net output #0: loss = 0.0521384 (* 1 = 0.0521384 loss)
I0403 09:44:48.386927  8106 sgd_solver.cpp:106] Iteration 4966, lr = 0.0005
I0403 09:44:57.621754  8106 solver.cpp:228] Iteration 4979, loss = 0.0609533
I0403 09:44:57.621845  8106 solver.cpp:244]     Train net output #0: loss = 0.0609534 (* 1 = 0.0609534 loss)
I0403 09:44:57.780975  8106 sgd_solver.cpp:106] Iteration 4979, lr = 0.0005
I0403 09:45:07.204356  8106 solver.cpp:228] Iteration 4992, loss = 0.0537726
I0403 09:45:07.204445  8106 solver.cpp:244]     Train net output #0: loss = 0.0537726 (* 1 = 0.0537726 loss)
I0403 09:45:07.373373  8106 sgd_solver.cpp:106] Iteration 4992, lr = 0.0005
I0403 09:45:16.701683  8106 solver.cpp:228] Iteration 5005, loss = 0.0518145
I0403 09:45:16.703631  8106 solver.cpp:244]     Train net output #0: loss = 0.0518145 (* 1 = 0.0518145 loss)
I0403 09:45:16.896446  8106 sgd_solver.cpp:106] Iteration 5005, lr = 0.0005
I0403 09:45:26.121170  8106 solver.cpp:228] Iteration 5018, loss = 0.0545524
I0403 09:45:26.121268  8106 solver.cpp:244]     Train net output #0: loss = 0.0545524 (* 1 = 0.0545524 loss)
I0403 09:45:26.303006  8106 sgd_solver.cpp:106] Iteration 5018, lr = 0.0005
I0403 09:45:35.783002  8106 solver.cpp:228] Iteration 5031, loss = 0.080862
I0403 09:45:35.783113  8106 solver.cpp:244]     Train net output #0: loss = 0.080862 (* 1 = 0.080862 loss)
I0403 09:45:35.983965  8106 sgd_solver.cpp:106] Iteration 5031, lr = 0.0005
I0403 09:45:45.177688  8106 solver.cpp:228] Iteration 5044, loss = 0.0675841
I0403 09:45:45.177784  8106 solver.cpp:244]     Train net output #0: loss = 0.0675841 (* 1 = 0.0675841 loss)
I0403 09:45:45.389595  8106 sgd_solver.cpp:106] Iteration 5044, lr = 0.0005
I0403 09:45:54.635188  8106 solver.cpp:228] Iteration 5057, loss = 0.0823934
I0403 09:45:54.635481  8106 solver.cpp:244]     Train net output #0: loss = 0.0823934 (* 1 = 0.0823934 loss)
I0403 09:45:54.838783  8106 sgd_solver.cpp:106] Iteration 5057, lr = 0.0005
I0403 09:46:04.127248  8106 solver.cpp:228] Iteration 5070, loss = 0.0287667
I0403 09:46:04.127336  8106 solver.cpp:244]     Train net output #0: loss = 0.0287668 (* 1 = 0.0287668 loss)
I0403 09:46:04.253801  8106 sgd_solver.cpp:106] Iteration 5070, lr = 0.0005
I0403 09:46:05.765293  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5073.caffemodel
I0403 09:46:08.572275  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5073.solverstate
I0403 09:46:10.471663  8106 solver.cpp:337] Iteration 5073, Testing net (#0)
I0403 09:47:12.517901  8106 solver.cpp:404]     Test net output #0: accuracy = 0.928399
I0403 09:47:12.518224  8106 solver.cpp:404]     Test net output #1: loss = 0.249672 (* 1 = 0.249672 loss)
I0403 09:47:20.412714  8106 solver.cpp:228] Iteration 5083, loss = 0.141027
I0403 09:47:20.412802  8106 solver.cpp:244]     Train net output #0: loss = 0.141027 (* 1 = 0.141027 loss)
I0403 09:47:20.589864  8106 sgd_solver.cpp:106] Iteration 5083, lr = 0.0005
I0403 09:47:29.896311  8106 solver.cpp:228] Iteration 5096, loss = 0.0417558
I0403 09:47:29.896396  8106 solver.cpp:244]     Train net output #0: loss = 0.0417558 (* 1 = 0.0417558 loss)
I0403 09:47:29.993598  8106 sgd_solver.cpp:106] Iteration 5096, lr = 0.0005
I0403 09:47:39.719151  8106 solver.cpp:228] Iteration 5109, loss = 0.0292167
I0403 09:47:39.719238  8106 solver.cpp:244]     Train net output #0: loss = 0.0292167 (* 1 = 0.0292167 loss)
I0403 09:47:39.899060  8106 sgd_solver.cpp:106] Iteration 5109, lr = 0.0005
I0403 09:47:49.109983  8106 solver.cpp:228] Iteration 5122, loss = 0.0998875
I0403 09:47:49.110292  8106 solver.cpp:244]     Train net output #0: loss = 0.0998876 (* 1 = 0.0998876 loss)
I0403 09:47:49.293481  8106 sgd_solver.cpp:106] Iteration 5122, lr = 0.0005
I0403 09:47:58.802868  8106 solver.cpp:228] Iteration 5135, loss = 0.079647
I0403 09:47:58.802956  8106 solver.cpp:244]     Train net output #0: loss = 0.079647 (* 1 = 0.079647 loss)
I0403 09:47:58.969266  8106 sgd_solver.cpp:106] Iteration 5135, lr = 0.0005
I0403 09:48:08.357560  8106 solver.cpp:228] Iteration 5148, loss = 0.0608166
I0403 09:48:08.357648  8106 solver.cpp:244]     Train net output #0: loss = 0.0608166 (* 1 = 0.0608166 loss)
I0403 09:48:08.529884  8106 sgd_solver.cpp:106] Iteration 5148, lr = 0.0005
I0403 09:48:17.785787  8106 solver.cpp:228] Iteration 5161, loss = 0.0696043
I0403 09:48:17.785886  8106 solver.cpp:244]     Train net output #0: loss = 0.0696043 (* 1 = 0.0696043 loss)
I0403 09:48:17.975388  8106 sgd_solver.cpp:106] Iteration 5161, lr = 0.0005
I0403 09:48:27.294461  8106 solver.cpp:228] Iteration 5174, loss = 0.0238047
I0403 09:48:27.294766  8106 solver.cpp:244]     Train net output #0: loss = 0.0238048 (* 1 = 0.0238048 loss)
I0403 09:48:27.484153  8106 sgd_solver.cpp:106] Iteration 5174, lr = 0.0005
I0403 09:48:36.864814  8106 solver.cpp:228] Iteration 5187, loss = 0.0475518
I0403 09:48:36.864900  8106 solver.cpp:244]     Train net output #0: loss = 0.0475518 (* 1 = 0.0475518 loss)
I0403 09:48:37.011309  8106 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 09:48:46.480823  8106 solver.cpp:228] Iteration 5200, loss = 0.0631126
I0403 09:48:46.480911  8106 solver.cpp:244]     Train net output #0: loss = 0.0631126 (* 1 = 0.0631126 loss)
I0403 09:48:46.647805  8106 sgd_solver.cpp:106] Iteration 5200, lr = 0.0005
I0403 09:48:55.995275  8106 solver.cpp:228] Iteration 5213, loss = 0.0169087
I0403 09:48:55.995371  8106 solver.cpp:244]     Train net output #0: loss = 0.0169088 (* 1 = 0.0169088 loss)
I0403 09:48:56.190822  8106 sgd_solver.cpp:106] Iteration 5213, lr = 0.0005
I0403 09:49:05.433250  8106 solver.cpp:228] Iteration 5226, loss = 0.03905
I0403 09:49:05.433569  8106 solver.cpp:244]     Train net output #0: loss = 0.0390501 (* 1 = 0.0390501 loss)
I0403 09:49:05.653008  8106 sgd_solver.cpp:106] Iteration 5226, lr = 0.0005
I0403 09:49:14.919159  8106 solver.cpp:228] Iteration 5239, loss = 0.0402265
I0403 09:49:14.919261  8106 solver.cpp:244]     Train net output #0: loss = 0.0402266 (* 1 = 0.0402266 loss)
I0403 09:49:15.167536  8106 sgd_solver.cpp:106] Iteration 5239, lr = 0.0005
I0403 09:49:24.394491  8106 solver.cpp:228] Iteration 5252, loss = 0.0737466
I0403 09:49:24.394598  8106 solver.cpp:244]     Train net output #0: loss = 0.0737466 (* 1 = 0.0737466 loss)
I0403 09:49:24.598899  8106 sgd_solver.cpp:106] Iteration 5252, lr = 0.0005
I0403 09:49:33.789783  8106 solver.cpp:228] Iteration 5265, loss = 0.0807551
I0403 09:49:33.789880  8106 solver.cpp:244]     Train net output #0: loss = 0.0807552 (* 1 = 0.0807552 loss)
I0403 09:49:33.979265  8106 sgd_solver.cpp:106] Iteration 5265, lr = 0.0005
I0403 09:49:43.266305  8106 solver.cpp:228] Iteration 5278, loss = 0.0211334
I0403 09:49:43.270475  8106 solver.cpp:244]     Train net output #0: loss = 0.0211335 (* 1 = 0.0211335 loss)
I0403 09:49:43.448614  8106 sgd_solver.cpp:106] Iteration 5278, lr = 0.0005
I0403 09:49:52.639122  8106 solver.cpp:228] Iteration 5291, loss = 0.0279105
I0403 09:49:52.639220  8106 solver.cpp:244]     Train net output #0: loss = 0.0279105 (* 1 = 0.0279105 loss)
I0403 09:49:52.840391  8106 sgd_solver.cpp:106] Iteration 5291, lr = 0.0005
I0403 09:50:02.138473  8106 solver.cpp:228] Iteration 5304, loss = 0.0686341
I0403 09:50:02.138567  8106 solver.cpp:244]     Train net output #0: loss = 0.0686341 (* 1 = 0.0686341 loss)
I0403 09:50:02.311622  8106 sgd_solver.cpp:106] Iteration 5304, lr = 0.0005
I0403 09:50:11.744544  8106 solver.cpp:228] Iteration 5317, loss = 0.0568437
I0403 09:50:11.744650  8106 solver.cpp:244]     Train net output #0: loss = 0.0568438 (* 1 = 0.0568438 loss)
I0403 09:50:11.937908  8106 sgd_solver.cpp:106] Iteration 5317, lr = 0.0005
I0403 09:50:21.187842  8106 solver.cpp:228] Iteration 5330, loss = 0.0230378
I0403 09:50:21.188143  8106 solver.cpp:244]     Train net output #0: loss = 0.0230378 (* 1 = 0.0230378 loss)
I0403 09:50:21.369488  8106 sgd_solver.cpp:106] Iteration 5330, lr = 0.0005
I0403 09:50:27.904160  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5340.caffemodel
I0403 09:50:30.674438  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5340.solverstate
I0403 09:50:32.568768  8106 solver.cpp:337] Iteration 5340, Testing net (#0)
I0403 09:51:34.615144  8106 solver.cpp:404]     Test net output #0: accuracy = 0.929491
I0403 09:51:34.615469  8106 solver.cpp:404]     Test net output #1: loss = 0.250475 (* 1 = 0.250475 loss)
I0403 09:51:37.353049  8106 solver.cpp:228] Iteration 5343, loss = 0.0382814
I0403 09:51:37.353140  8106 solver.cpp:244]     Train net output #0: loss = 0.0382814 (* 1 = 0.0382814 loss)
I0403 09:51:37.548307  8106 sgd_solver.cpp:106] Iteration 5343, lr = 0.0005
I0403 09:51:46.813570  8106 solver.cpp:228] Iteration 5356, loss = 0.0444832
I0403 09:51:46.813669  8106 solver.cpp:244]     Train net output #0: loss = 0.0444832 (* 1 = 0.0444832 loss)
I0403 09:51:47.009387  8106 sgd_solver.cpp:106] Iteration 5356, lr = 5e-05
I0403 09:51:56.159607  8106 solver.cpp:228] Iteration 5369, loss = 0.0306685
I0403 09:51:56.159694  8106 solver.cpp:244]     Train net output #0: loss = 0.0306686 (* 1 = 0.0306686 loss)
I0403 09:51:56.318796  8106 sgd_solver.cpp:106] Iteration 5369, lr = 5e-05
I0403 09:52:06.088608  8106 solver.cpp:228] Iteration 5382, loss = 0.0636053
I0403 09:52:06.088893  8106 solver.cpp:244]     Train net output #0: loss = 0.0636054 (* 1 = 0.0636054 loss)
I0403 09:52:06.266243  8106 sgd_solver.cpp:106] Iteration 5382, lr = 5e-05
I0403 09:52:15.532402  8106 solver.cpp:228] Iteration 5395, loss = 0.0209921
I0403 09:52:15.532501  8106 solver.cpp:244]     Train net output #0: loss = 0.0209921 (* 1 = 0.0209921 loss)
I0403 09:52:15.729113  8106 sgd_solver.cpp:106] Iteration 5395, lr = 5e-05
I0403 09:52:25.071564  8106 solver.cpp:228] Iteration 5408, loss = 0.0594798
I0403 09:52:25.071662  8106 solver.cpp:244]     Train net output #0: loss = 0.0594798 (* 1 = 0.0594798 loss)
I0403 09:52:25.260148  8106 sgd_solver.cpp:106] Iteration 5408, lr = 5e-05
I0403 09:52:34.433542  8106 solver.cpp:228] Iteration 5421, loss = 0.0902176
I0403 09:52:34.433639  8106 solver.cpp:244]     Train net output #0: loss = 0.0902177 (* 1 = 0.0902177 loss)
I0403 09:52:34.615244  8106 sgd_solver.cpp:106] Iteration 5421, lr = 5e-05
I0403 09:52:44.040582  8106 solver.cpp:228] Iteration 5434, loss = 0.0352307
I0403 09:52:44.040886  8106 solver.cpp:244]     Train net output #0: loss = 0.0352307 (* 1 = 0.0352307 loss)
I0403 09:52:44.216846  8106 sgd_solver.cpp:106] Iteration 5434, lr = 5e-05
I0403 09:52:53.464000  8106 solver.cpp:228] Iteration 5447, loss = 0.0759857
I0403 09:52:53.464097  8106 solver.cpp:244]     Train net output #0: loss = 0.0759858 (* 1 = 0.0759858 loss)
I0403 09:52:53.645468  8106 sgd_solver.cpp:106] Iteration 5447, lr = 5e-05
I0403 09:53:03.071396  8106 solver.cpp:228] Iteration 5460, loss = 0.190068
I0403 09:53:03.071483  8106 solver.cpp:244]     Train net output #0: loss = 0.190068 (* 1 = 0.190068 loss)
I0403 09:53:03.251588  8106 sgd_solver.cpp:106] Iteration 5460, lr = 5e-05
I0403 09:53:12.484947  8106 solver.cpp:228] Iteration 5473, loss = 0.0174171
I0403 09:53:12.485035  8106 solver.cpp:244]     Train net output #0: loss = 0.0174171 (* 1 = 0.0174171 loss)
I0403 09:53:12.662319  8106 sgd_solver.cpp:106] Iteration 5473, lr = 5e-05
I0403 09:53:21.932138  8106 solver.cpp:228] Iteration 5486, loss = 0.0547294
I0403 09:53:21.932445  8106 solver.cpp:244]     Train net output #0: loss = 0.0547295 (* 1 = 0.0547295 loss)
I0403 09:53:22.114157  8106 sgd_solver.cpp:106] Iteration 5486, lr = 5e-05
I0403 09:53:31.431008  8106 solver.cpp:228] Iteration 5499, loss = 0.0624078
I0403 09:53:31.431109  8106 solver.cpp:244]     Train net output #0: loss = 0.0624079 (* 1 = 0.0624079 loss)
I0403 09:53:31.641258  8106 sgd_solver.cpp:106] Iteration 5499, lr = 5e-05
I0403 09:53:41.028399  8106 solver.cpp:228] Iteration 5512, loss = 0.0472251
I0403 09:53:41.028496  8106 solver.cpp:244]     Train net output #0: loss = 0.0472251 (* 1 = 0.0472251 loss)
I0403 09:53:41.211318  8106 sgd_solver.cpp:106] Iteration 5512, lr = 5e-05
I0403 09:53:50.430558  8106 solver.cpp:228] Iteration 5525, loss = 0.0309464
I0403 09:53:50.430657  8106 solver.cpp:244]     Train net output #0: loss = 0.0309465 (* 1 = 0.0309465 loss)
I0403 09:53:50.621706  8106 sgd_solver.cpp:106] Iteration 5525, lr = 5e-05
I0403 09:53:59.880054  8106 solver.cpp:228] Iteration 5538, loss = 0.024701
I0403 09:53:59.880348  8106 solver.cpp:244]     Train net output #0: loss = 0.0247011 (* 1 = 0.0247011 loss)
I0403 09:54:00.009841  8106 sgd_solver.cpp:106] Iteration 5538, lr = 5e-05
I0403 09:54:09.449309  8106 solver.cpp:228] Iteration 5551, loss = 0.0478435
I0403 09:54:09.449398  8106 solver.cpp:244]     Train net output #0: loss = 0.0478435 (* 1 = 0.0478435 loss)
I0403 09:54:09.618602  8106 sgd_solver.cpp:106] Iteration 5551, lr = 5e-05
I0403 09:54:18.849390  8106 solver.cpp:228] Iteration 5564, loss = 0.0528087
I0403 09:54:18.849478  8106 solver.cpp:244]     Train net output #0: loss = 0.0528087 (* 1 = 0.0528087 loss)
I0403 09:54:19.028796  8106 sgd_solver.cpp:106] Iteration 5564, lr = 5e-05
I0403 09:54:28.241768  8106 solver.cpp:228] Iteration 5577, loss = 0.00900851
I0403 09:54:28.241866  8106 solver.cpp:244]     Train net output #0: loss = 0.00900855 (* 1 = 0.00900855 loss)
I0403 09:54:28.430203  8106 sgd_solver.cpp:106] Iteration 5577, lr = 5e-05
I0403 09:54:37.814330  8106 solver.cpp:228] Iteration 5590, loss = 0.0366327
I0403 09:54:37.814620  8106 solver.cpp:244]     Train net output #0: loss = 0.0366327 (* 1 = 0.0366327 loss)
I0403 09:54:37.972681  8106 sgd_solver.cpp:106] Iteration 5590, lr = 5e-05
I0403 09:54:47.296741  8106 solver.cpp:228] Iteration 5603, loss = 0.0656577
I0403 09:54:47.296855  8106 solver.cpp:244]     Train net output #0: loss = 0.0656578 (* 1 = 0.0656578 loss)
I0403 09:54:47.491520  8106 sgd_solver.cpp:106] Iteration 5603, lr = 5e-05
I0403 09:54:49.688940  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5607.caffemodel
I0403 09:54:52.385344  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5607.solverstate
I0403 09:54:54.210609  8106 solver.cpp:337] Iteration 5607, Testing net (#0)
I0403 09:55:56.297677  8106 solver.cpp:404]     Test net output #0: accuracy = 0.930727
I0403 09:55:56.298012  8106 solver.cpp:404]     Test net output #1: loss = 0.24775 (* 1 = 0.24775 loss)
I0403 09:56:03.472820  8106 solver.cpp:228] Iteration 5616, loss = 0.0253114
I0403 09:56:03.472908  8106 solver.cpp:244]     Train net output #0: loss = 0.0253114 (* 1 = 0.0253114 loss)
I0403 09:56:03.648280  8106 sgd_solver.cpp:106] Iteration 5616, lr = 5e-05
I0403 09:56:13.000551  8106 solver.cpp:228] Iteration 5629, loss = 0.032652
I0403 09:56:13.000648  8106 solver.cpp:244]     Train net output #0: loss = 0.032652 (* 1 = 0.032652 loss)
I0403 09:56:13.210062  8106 sgd_solver.cpp:106] Iteration 5629, lr = 5e-05
I0403 09:56:22.433130  8106 solver.cpp:228] Iteration 5642, loss = 0.0230244
I0403 09:56:22.433226  8106 solver.cpp:244]     Train net output #0: loss = 0.0230244 (* 1 = 0.0230244 loss)
I0403 09:56:22.638851  8106 sgd_solver.cpp:106] Iteration 5642, lr = 5e-05
I0403 09:56:31.899478  8106 solver.cpp:228] Iteration 5655, loss = 0.0198782
I0403 09:56:31.899783  8106 solver.cpp:244]     Train net output #0: loss = 0.0198782 (* 1 = 0.0198782 loss)
I0403 09:56:32.117596  8106 sgd_solver.cpp:106] Iteration 5655, lr = 5e-05
I0403 09:56:41.291100  8106 solver.cpp:228] Iteration 5668, loss = 0.0525649
I0403 09:56:41.291187  8106 solver.cpp:244]     Train net output #0: loss = 0.0525649 (* 1 = 0.0525649 loss)
I0403 09:56:41.453829  8106 sgd_solver.cpp:106] Iteration 5668, lr = 5e-05
I0403 09:56:50.681210  8106 solver.cpp:228] Iteration 5681, loss = 0.0351913
I0403 09:56:50.681301  8106 solver.cpp:244]     Train net output #0: loss = 0.0351913 (* 1 = 0.0351913 loss)
I0403 09:56:50.852692  8106 sgd_solver.cpp:106] Iteration 5681, lr = 5e-05
I0403 09:57:00.117015  8106 solver.cpp:228] Iteration 5694, loss = 0.0489064
I0403 09:57:00.117116  8106 solver.cpp:244]     Train net output #0: loss = 0.0489064 (* 1 = 0.0489064 loss)
I0403 09:57:00.349737  8106 sgd_solver.cpp:106] Iteration 5694, lr = 5e-05
I0403 09:57:09.632941  8106 solver.cpp:228] Iteration 5707, loss = 0.0544865
I0403 09:57:09.633232  8106 solver.cpp:244]     Train net output #0: loss = 0.0544865 (* 1 = 0.0544865 loss)
I0403 09:57:09.814642  8106 sgd_solver.cpp:106] Iteration 5707, lr = 5e-05
I0403 09:57:19.041393  8106 solver.cpp:228] Iteration 5720, loss = 0.105145
I0403 09:57:19.041484  8106 solver.cpp:244]     Train net output #0: loss = 0.105145 (* 1 = 0.105145 loss)
I0403 09:57:19.193969  8106 sgd_solver.cpp:106] Iteration 5720, lr = 5e-05
I0403 09:57:28.523447  8106 solver.cpp:228] Iteration 5733, loss = 0.0402937
I0403 09:57:28.523557  8106 solver.cpp:244]     Train net output #0: loss = 0.0402938 (* 1 = 0.0402938 loss)
I0403 09:57:28.732944  8106 sgd_solver.cpp:106] Iteration 5733, lr = 5e-05
I0403 09:57:37.895334  8106 solver.cpp:228] Iteration 5746, loss = 0.0161404
I0403 09:57:37.895421  8106 solver.cpp:244]     Train net output #0: loss = 0.0161404 (* 1 = 0.0161404 loss)
I0403 09:57:38.073803  8106 sgd_solver.cpp:106] Iteration 5746, lr = 5e-05
I0403 09:57:47.386759  8106 solver.cpp:228] Iteration 5759, loss = 0.0539026
I0403 09:57:47.387033  8106 solver.cpp:244]     Train net output #0: loss = 0.0539027 (* 1 = 0.0539027 loss)
I0403 09:57:47.570556  8106 sgd_solver.cpp:106] Iteration 5759, lr = 5e-05
I0403 09:57:56.901063  8106 solver.cpp:228] Iteration 5772, loss = 0.0371593
I0403 09:57:56.901155  8106 solver.cpp:244]     Train net output #0: loss = 0.0371593 (* 1 = 0.0371593 loss)
I0403 09:57:57.079165  8106 sgd_solver.cpp:106] Iteration 5772, lr = 5e-05
I0403 09:58:06.485985  8106 solver.cpp:228] Iteration 5785, loss = 0.0300529
I0403 09:58:06.486081  8106 solver.cpp:244]     Train net output #0: loss = 0.0300529 (* 1 = 0.0300529 loss)
I0403 09:58:06.669741  8106 sgd_solver.cpp:106] Iteration 5785, lr = 5e-05
I0403 09:58:15.940403  8106 solver.cpp:228] Iteration 5798, loss = 0.0825479
I0403 09:58:15.940492  8106 solver.cpp:244]     Train net output #0: loss = 0.0825479 (* 1 = 0.0825479 loss)
I0403 09:58:16.115954  8106 sgd_solver.cpp:106] Iteration 5798, lr = 5e-05
I0403 09:58:25.364349  8106 solver.cpp:228] Iteration 5811, loss = 0.0565623
I0403 09:58:25.364668  8106 solver.cpp:244]     Train net output #0: loss = 0.0565624 (* 1 = 0.0565624 loss)
I0403 09:58:25.538889  8106 sgd_solver.cpp:106] Iteration 5811, lr = 5e-05
I0403 09:58:34.774955  8106 solver.cpp:228] Iteration 5824, loss = 0.0995621
I0403 09:58:34.775053  8106 solver.cpp:244]     Train net output #0: loss = 0.0995622 (* 1 = 0.0995622 loss)
I0403 09:58:34.960324  8106 sgd_solver.cpp:106] Iteration 5824, lr = 5e-05
I0403 09:58:44.170754  8106 solver.cpp:228] Iteration 5837, loss = 0.0474642
I0403 09:58:44.170848  8106 solver.cpp:244]     Train net output #0: loss = 0.0474643 (* 1 = 0.0474643 loss)
I0403 09:58:44.355907  8106 sgd_solver.cpp:106] Iteration 5837, lr = 5e-05
I0403 09:58:53.630756  8106 solver.cpp:228] Iteration 5850, loss = 0.0239832
I0403 09:58:53.630858  8106 solver.cpp:244]     Train net output #0: loss = 0.0239832 (* 1 = 0.0239832 loss)
I0403 09:58:53.809021  8106 sgd_solver.cpp:106] Iteration 5850, lr = 5e-05
I0403 09:59:02.964846  8106 solver.cpp:228] Iteration 5863, loss = 0.0281128
I0403 09:59:02.965142  8106 solver.cpp:244]     Train net output #0: loss = 0.0281129 (* 1 = 0.0281129 loss)
I0403 09:59:03.149507  8106 sgd_solver.cpp:106] Iteration 5863, lr = 5e-05
I0403 09:59:10.468430  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5874.caffemodel
I0403 09:59:13.261291  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_5874.solverstate
I0403 09:59:15.155685  8106 solver.cpp:337] Iteration 5874, Testing net (#0)
I0403 10:00:17.214184  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931018
I0403 10:00:17.214524  8106 solver.cpp:404]     Test net output #1: loss = 0.246282 (* 1 = 0.246282 loss)
I0403 10:00:19.271911  8106 solver.cpp:228] Iteration 5876, loss = 0.104992
I0403 10:00:19.272007  8106 solver.cpp:244]     Train net output #0: loss = 0.104992 (* 1 = 0.104992 loss)
I0403 10:00:19.453440  8106 sgd_solver.cpp:106] Iteration 5876, lr = 5e-05
I0403 10:00:28.621768  8106 solver.cpp:228] Iteration 5889, loss = 0.0380837
I0403 10:00:28.621866  8106 solver.cpp:244]     Train net output #0: loss = 0.0380838 (* 1 = 0.0380838 loss)
I0403 10:00:28.846923  8106 sgd_solver.cpp:106] Iteration 5889, lr = 5e-05
I0403 10:00:38.076480  8106 solver.cpp:228] Iteration 5902, loss = 0.0251443
I0403 10:00:38.076572  8106 solver.cpp:244]     Train net output #0: loss = 0.0251443 (* 1 = 0.0251443 loss)
I0403 10:00:38.252463  8106 sgd_solver.cpp:106] Iteration 5902, lr = 5e-05
I0403 10:00:47.483701  8106 solver.cpp:228] Iteration 5915, loss = 0.0470458
I0403 10:00:47.483973  8106 solver.cpp:244]     Train net output #0: loss = 0.0470458 (* 1 = 0.0470458 loss)
I0403 10:00:47.650513  8106 sgd_solver.cpp:106] Iteration 5915, lr = 5e-05
I0403 10:00:56.887755  8106 solver.cpp:228] Iteration 5928, loss = 0.0742637
I0403 10:00:56.887869  8106 solver.cpp:244]     Train net output #0: loss = 0.0742637 (* 1 = 0.0742637 loss)
I0403 10:00:57.063390  8106 sgd_solver.cpp:106] Iteration 5928, lr = 5e-05
I0403 10:01:06.272186  8106 solver.cpp:228] Iteration 5941, loss = 0.0756578
I0403 10:01:06.272276  8106 solver.cpp:244]     Train net output #0: loss = 0.0756579 (* 1 = 0.0756579 loss)
I0403 10:01:06.438588  8106 sgd_solver.cpp:106] Iteration 5941, lr = 5e-05
I0403 10:01:15.685045  8106 solver.cpp:228] Iteration 5954, loss = 0.057179
I0403 10:01:15.685130  8106 solver.cpp:244]     Train net output #0: loss = 0.0571791 (* 1 = 0.0571791 loss)
I0403 10:01:15.866873  8106 sgd_solver.cpp:106] Iteration 5954, lr = 5e-05
I0403 10:01:25.115173  8106 solver.cpp:228] Iteration 5967, loss = 0.0713152
I0403 10:01:25.115501  8106 solver.cpp:244]     Train net output #0: loss = 0.0713152 (* 1 = 0.0713152 loss)
I0403 10:01:25.329989  8106 sgd_solver.cpp:106] Iteration 5967, lr = 5e-05
I0403 10:01:34.564764  8106 solver.cpp:228] Iteration 5980, loss = 0.0334433
I0403 10:01:34.564872  8106 solver.cpp:244]     Train net output #0: loss = 0.0334434 (* 1 = 0.0334434 loss)
I0403 10:01:34.746691  8106 sgd_solver.cpp:106] Iteration 5980, lr = 5e-05
I0403 10:01:44.015467  8106 solver.cpp:228] Iteration 5993, loss = 0.0445123
I0403 10:01:44.015568  8106 solver.cpp:244]     Train net output #0: loss = 0.0445124 (* 1 = 0.0445124 loss)
I0403 10:01:44.209233  8106 sgd_solver.cpp:106] Iteration 5993, lr = 5e-05
I0403 10:01:53.530032  8106 solver.cpp:228] Iteration 6006, loss = 0.0640722
I0403 10:01:53.530122  8106 solver.cpp:244]     Train net output #0: loss = 0.0640722 (* 1 = 0.0640722 loss)
I0403 10:01:53.703222  8106 sgd_solver.cpp:106] Iteration 6006, lr = 5e-05
I0403 10:02:02.895946  8106 solver.cpp:228] Iteration 6019, loss = 0.0912481
I0403 10:02:02.896237  8106 solver.cpp:244]     Train net output #0: loss = 0.0912481 (* 1 = 0.0912481 loss)
I0403 10:02:03.082417  8106 sgd_solver.cpp:106] Iteration 6019, lr = 5e-05
I0403 10:02:12.403481  8106 solver.cpp:228] Iteration 6032, loss = 0.0612179
I0403 10:02:12.403584  8106 solver.cpp:244]     Train net output #0: loss = 0.0612179 (* 1 = 0.0612179 loss)
I0403 10:02:12.625079  8106 sgd_solver.cpp:106] Iteration 6032, lr = 5e-05
I0403 10:02:21.808326  8106 solver.cpp:228] Iteration 6045, loss = 0.0292138
I0403 10:02:21.808423  8106 solver.cpp:244]     Train net output #0: loss = 0.0292138 (* 1 = 0.0292138 loss)
I0403 10:02:22.000161  8106 sgd_solver.cpp:106] Iteration 6045, lr = 5e-05
I0403 10:02:31.304529  8106 solver.cpp:228] Iteration 6058, loss = 0.0298455
I0403 10:02:31.304631  8106 solver.cpp:244]     Train net output #0: loss = 0.0298455 (* 1 = 0.0298455 loss)
I0403 10:02:31.486207  8106 sgd_solver.cpp:106] Iteration 6058, lr = 5e-05
I0403 10:02:40.734151  8106 solver.cpp:228] Iteration 6071, loss = 0.0720146
I0403 10:02:40.734434  8106 solver.cpp:244]     Train net output #0: loss = 0.0720146 (* 1 = 0.0720146 loss)
I0403 10:02:40.926022  8106 sgd_solver.cpp:106] Iteration 6071, lr = 5e-05
I0403 10:02:50.420997  8106 solver.cpp:228] Iteration 6084, loss = 0.0703567
I0403 10:02:50.421097  8106 solver.cpp:244]     Train net output #0: loss = 0.0703567 (* 1 = 0.0703567 loss)
I0403 10:02:50.603230  8106 sgd_solver.cpp:106] Iteration 6084, lr = 5e-05
I0403 10:02:59.812779  8106 solver.cpp:228] Iteration 6097, loss = 0.0324795
I0403 10:02:59.812875  8106 solver.cpp:244]     Train net output #0: loss = 0.0324795 (* 1 = 0.0324795 loss)
I0403 10:03:00.010355  8106 sgd_solver.cpp:106] Iteration 6097, lr = 5e-05
I0403 10:03:09.284867  8106 solver.cpp:228] Iteration 6110, loss = 0.0371413
I0403 10:03:09.284965  8106 solver.cpp:244]     Train net output #0: loss = 0.0371413 (* 1 = 0.0371413 loss)
I0403 10:03:09.484038  8106 sgd_solver.cpp:106] Iteration 6110, lr = 5e-05
I0403 10:03:18.754506  8106 solver.cpp:228] Iteration 6123, loss = 0.0243451
I0403 10:03:18.754801  8106 solver.cpp:244]     Train net output #0: loss = 0.0243451 (* 1 = 0.0243451 loss)
I0403 10:03:18.938613  8106 sgd_solver.cpp:106] Iteration 6123, lr = 5e-05
I0403 10:03:28.235961  8106 solver.cpp:228] Iteration 6136, loss = 0.0725705
I0403 10:03:28.236059  8106 solver.cpp:244]     Train net output #0: loss = 0.0725705 (* 1 = 0.0725705 loss)
I0403 10:03:28.455494  8106 sgd_solver.cpp:106] Iteration 6136, lr = 5e-05
I0403 10:03:31.379917  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6141.caffemodel
I0403 10:03:34.162128  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6141.solverstate
I0403 10:03:36.036365  8106 solver.cpp:337] Iteration 6141, Testing net (#0)
I0403 10:04:38.107617  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931054
I0403 10:04:38.107938  8106 solver.cpp:404]     Test net output #1: loss = 0.246852 (* 1 = 0.246852 loss)
I0403 10:04:44.443325  8106 solver.cpp:228] Iteration 6149, loss = 0.0524379
I0403 10:04:44.443413  8106 solver.cpp:244]     Train net output #0: loss = 0.052438 (* 1 = 0.052438 loss)
I0403 10:04:44.621645  8106 sgd_solver.cpp:106] Iteration 6149, lr = 5e-05
I0403 10:04:53.912519  8106 solver.cpp:228] Iteration 6162, loss = 0.11889
I0403 10:04:53.912611  8106 solver.cpp:244]     Train net output #0: loss = 0.11889 (* 1 = 0.11889 loss)
I0403 10:04:54.075726  8106 sgd_solver.cpp:106] Iteration 6162, lr = 5e-05
I0403 10:05:03.417904  8106 solver.cpp:228] Iteration 6175, loss = 0.00956611
I0403 10:05:03.418005  8106 solver.cpp:244]     Train net output #0: loss = 0.00956612 (* 1 = 0.00956612 loss)
I0403 10:05:03.624512  8106 sgd_solver.cpp:106] Iteration 6175, lr = 5e-05
I0403 10:05:12.796918  8106 solver.cpp:228] Iteration 6188, loss = 0.0778382
I0403 10:05:12.797207  8106 solver.cpp:244]     Train net output #0: loss = 0.0778382 (* 1 = 0.0778382 loss)
I0403 10:05:13.015943  8106 sgd_solver.cpp:106] Iteration 6188, lr = 5e-05
I0403 10:05:22.246770  8106 solver.cpp:228] Iteration 6201, loss = 0.0335662
I0403 10:05:22.246870  8106 solver.cpp:244]     Train net output #0: loss = 0.0335662 (* 1 = 0.0335662 loss)
I0403 10:05:22.445185  8106 sgd_solver.cpp:106] Iteration 6201, lr = 5e-05
I0403 10:05:31.660301  8106 solver.cpp:228] Iteration 6214, loss = 0.0113117
I0403 10:05:31.660390  8106 solver.cpp:244]     Train net output #0: loss = 0.0113117 (* 1 = 0.0113117 loss)
I0403 10:05:31.819614  8106 sgd_solver.cpp:106] Iteration 6214, lr = 5e-05
I0403 10:05:41.144918  8106 solver.cpp:228] Iteration 6227, loss = 0.0225541
I0403 10:05:41.145015  8106 solver.cpp:244]     Train net output #0: loss = 0.0225541 (* 1 = 0.0225541 loss)
I0403 10:05:41.326174  8106 sgd_solver.cpp:106] Iteration 6227, lr = 5e-05
I0403 10:05:50.490644  8106 solver.cpp:228] Iteration 6240, loss = 0.0366275
I0403 10:05:50.490941  8106 solver.cpp:244]     Train net output #0: loss = 0.0366275 (* 1 = 0.0366275 loss)
I0403 10:05:50.667659  8106 sgd_solver.cpp:106] Iteration 6240, lr = 5e-05
I0403 10:06:00.099800  8106 solver.cpp:228] Iteration 6253, loss = 0.0356392
I0403 10:06:00.099886  8106 solver.cpp:244]     Train net output #0: loss = 0.0356392 (* 1 = 0.0356392 loss)
I0403 10:06:00.244956  8106 sgd_solver.cpp:106] Iteration 6253, lr = 5e-05
I0403 10:06:09.681233  8106 solver.cpp:228] Iteration 6266, loss = 0.0361121
I0403 10:06:09.681331  8106 solver.cpp:244]     Train net output #0: loss = 0.0361121 (* 1 = 0.0361121 loss)
I0403 10:06:09.870533  8106 sgd_solver.cpp:106] Iteration 6266, lr = 5e-05
I0403 10:06:19.059098  8106 solver.cpp:228] Iteration 6279, loss = 0.00436939
I0403 10:06:19.059198  8106 solver.cpp:244]     Train net output #0: loss = 0.0043694 (* 1 = 0.0043694 loss)
I0403 10:06:19.258206  8106 sgd_solver.cpp:106] Iteration 6279, lr = 5e-05
I0403 10:06:28.409741  8106 solver.cpp:228] Iteration 6292, loss = 0.0450113
I0403 10:06:28.410037  8106 solver.cpp:244]     Train net output #0: loss = 0.0450113 (* 1 = 0.0450113 loss)
I0403 10:06:28.558960  8106 sgd_solver.cpp:106] Iteration 6292, lr = 5e-05
I0403 10:06:37.790364  8106 solver.cpp:228] Iteration 6305, loss = 0.0349979
I0403 10:06:37.790462  8106 solver.cpp:244]     Train net output #0: loss = 0.034998 (* 1 = 0.034998 loss)
I0403 10:06:37.983340  8106 sgd_solver.cpp:106] Iteration 6305, lr = 5e-05
I0403 10:06:47.244350  8106 solver.cpp:228] Iteration 6318, loss = 0.0646699
I0403 10:06:47.244451  8106 solver.cpp:244]     Train net output #0: loss = 0.0646699 (* 1 = 0.0646699 loss)
I0403 10:06:47.426966  8106 sgd_solver.cpp:106] Iteration 6318, lr = 5e-05
I0403 10:06:56.568055  8106 solver.cpp:228] Iteration 6331, loss = 0.0219235
I0403 10:06:56.568152  8106 solver.cpp:244]     Train net output #0: loss = 0.0219235 (* 1 = 0.0219235 loss)
I0403 10:06:56.762708  8106 sgd_solver.cpp:106] Iteration 6331, lr = 5e-05
I0403 10:07:06.018007  8106 solver.cpp:228] Iteration 6344, loss = 0.127369
I0403 10:07:06.022258  8106 solver.cpp:244]     Train net output #0: loss = 0.127369 (* 1 = 0.127369 loss)
I0403 10:07:06.183511  8106 sgd_solver.cpp:106] Iteration 6344, lr = 5e-05
I0403 10:07:15.466034  8106 solver.cpp:228] Iteration 6357, loss = 0.0862118
I0403 10:07:15.466145  8106 solver.cpp:244]     Train net output #0: loss = 0.0862119 (* 1 = 0.0862119 loss)
I0403 10:07:15.722417  8106 sgd_solver.cpp:106] Iteration 6357, lr = 5e-05
I0403 10:07:24.985689  8106 solver.cpp:228] Iteration 6370, loss = 0.0389342
I0403 10:07:24.985785  8106 solver.cpp:244]     Train net output #0: loss = 0.0389342 (* 1 = 0.0389342 loss)
I0403 10:07:25.174752  8106 sgd_solver.cpp:106] Iteration 6370, lr = 5e-05
I0403 10:07:34.595459  8106 solver.cpp:228] Iteration 6383, loss = 0.0245547
I0403 10:07:34.595553  8106 solver.cpp:244]     Train net output #0: loss = 0.0245547 (* 1 = 0.0245547 loss)
I0403 10:07:34.745061  8106 sgd_solver.cpp:106] Iteration 6383, lr = 5e-05
I0403 10:07:43.981155  8106 solver.cpp:228] Iteration 6396, loss = 0.113058
I0403 10:07:43.981446  8106 solver.cpp:244]     Train net output #0: loss = 0.113058 (* 1 = 0.113058 loss)
I0403 10:07:44.160125  8106 sgd_solver.cpp:106] Iteration 6396, lr = 5e-05
I0403 10:07:52.235280  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6408.caffemodel
I0403 10:07:55.003307  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6408.solverstate
I0403 10:07:56.880347  8106 solver.cpp:337] Iteration 6408, Testing net (#0)
I0403 10:08:58.938031  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931563
I0403 10:08:58.939052  8106 solver.cpp:404]     Test net output #1: loss = 0.246637 (* 1 = 0.246637 loss)
I0403 10:09:00.199954  8106 solver.cpp:228] Iteration 6409, loss = 0.112869
I0403 10:09:00.200042  8106 solver.cpp:244]     Train net output #0: loss = 0.112869 (* 1 = 0.112869 loss)
I0403 10:09:00.376961  8106 sgd_solver.cpp:106] Iteration 6409, lr = 5e-05
I0403 10:09:09.597173  8106 solver.cpp:228] Iteration 6422, loss = 0.0539932
I0403 10:09:09.597270  8106 solver.cpp:244]     Train net output #0: loss = 0.0539932 (* 1 = 0.0539932 loss)
I0403 10:09:09.794492  8106 sgd_solver.cpp:106] Iteration 6422, lr = 5e-05
I0403 10:09:18.980494  8106 solver.cpp:228] Iteration 6435, loss = 0.0528596
I0403 10:09:18.980599  8106 solver.cpp:244]     Train net output #0: loss = 0.0528597 (* 1 = 0.0528597 loss)
I0403 10:09:19.150941  8106 sgd_solver.cpp:106] Iteration 6435, lr = 5e-05
I0403 10:09:28.533778  8106 solver.cpp:228] Iteration 6448, loss = 0.0181369
I0403 10:09:28.533877  8106 solver.cpp:244]     Train net output #0: loss = 0.0181369 (* 1 = 0.0181369 loss)
I0403 10:09:28.718122  8106 sgd_solver.cpp:106] Iteration 6448, lr = 5e-05
I0403 10:09:37.899381  8106 solver.cpp:228] Iteration 6461, loss = 0.0941768
I0403 10:09:37.899680  8106 solver.cpp:244]     Train net output #0: loss = 0.0941768 (* 1 = 0.0941768 loss)
I0403 10:09:38.093726  8106 sgd_solver.cpp:106] Iteration 6461, lr = 5e-05
I0403 10:09:47.303189  8106 solver.cpp:228] Iteration 6474, loss = 0.0269229
I0403 10:09:47.303285  8106 solver.cpp:244]     Train net output #0: loss = 0.0269229 (* 1 = 0.0269229 loss)
I0403 10:09:47.542482  8106 sgd_solver.cpp:106] Iteration 6474, lr = 5e-05
I0403 10:09:57.013216  8106 solver.cpp:228] Iteration 6487, loss = 0.0625194
I0403 10:09:57.013317  8106 solver.cpp:244]     Train net output #0: loss = 0.0625194 (* 1 = 0.0625194 loss)
I0403 10:09:57.195137  8106 sgd_solver.cpp:106] Iteration 6487, lr = 5e-05
I0403 10:10:06.395311  8106 solver.cpp:228] Iteration 6500, loss = 0.0660388
I0403 10:10:06.395400  8106 solver.cpp:244]     Train net output #0: loss = 0.0660388 (* 1 = 0.0660388 loss)
I0403 10:10:06.572034  8106 sgd_solver.cpp:106] Iteration 6500, lr = 5e-05
I0403 10:10:15.900784  8106 solver.cpp:228] Iteration 6513, loss = 0.0253071
I0403 10:10:15.901113  8106 solver.cpp:244]     Train net output #0: loss = 0.0253071 (* 1 = 0.0253071 loss)
I0403 10:10:16.090221  8106 sgd_solver.cpp:106] Iteration 6513, lr = 5e-05
I0403 10:10:25.336316  8106 solver.cpp:228] Iteration 6526, loss = 0.0787279
I0403 10:10:25.336415  8106 solver.cpp:244]     Train net output #0: loss = 0.078728 (* 1 = 0.078728 loss)
I0403 10:10:25.533026  8106 sgd_solver.cpp:106] Iteration 6526, lr = 5e-05
I0403 10:10:34.954217  8106 solver.cpp:228] Iteration 6539, loss = 0.0790646
I0403 10:10:34.954318  8106 solver.cpp:244]     Train net output #0: loss = 0.0790647 (* 1 = 0.0790647 loss)
I0403 10:10:35.161222  8106 sgd_solver.cpp:106] Iteration 6539, lr = 5e-05
I0403 10:10:44.388787  8106 solver.cpp:228] Iteration 6552, loss = 0.030915
I0403 10:10:44.388887  8106 solver.cpp:244]     Train net output #0: loss = 0.030915 (* 1 = 0.030915 loss)
I0403 10:10:44.570575  8106 sgd_solver.cpp:106] Iteration 6552, lr = 5e-05
I0403 10:10:53.805649  8106 solver.cpp:228] Iteration 6565, loss = 0.025212
I0403 10:10:53.805932  8106 solver.cpp:244]     Train net output #0: loss = 0.025212 (* 1 = 0.025212 loss)
I0403 10:10:53.984604  8106 sgd_solver.cpp:106] Iteration 6565, lr = 5e-05
I0403 10:11:03.257254  8106 solver.cpp:228] Iteration 6578, loss = 0.0613053
I0403 10:11:03.257341  8106 solver.cpp:244]     Train net output #0: loss = 0.0613054 (* 1 = 0.0613054 loss)
I0403 10:11:03.402211  8106 sgd_solver.cpp:106] Iteration 6578, lr = 5e-05
I0403 10:11:12.743608  8106 solver.cpp:228] Iteration 6591, loss = 0.0205685
I0403 10:11:12.743706  8106 solver.cpp:244]     Train net output #0: loss = 0.0205686 (* 1 = 0.0205686 loss)
I0403 10:11:12.936141  8106 sgd_solver.cpp:106] Iteration 6591, lr = 5e-05
I0403 10:11:22.355062  8106 solver.cpp:228] Iteration 6604, loss = 0.0123171
I0403 10:11:22.355150  8106 solver.cpp:244]     Train net output #0: loss = 0.0123171 (* 1 = 0.0123171 loss)
I0403 10:11:22.532829  8106 sgd_solver.cpp:106] Iteration 6604, lr = 5e-05
I0403 10:11:31.824751  8106 solver.cpp:228] Iteration 6617, loss = 0.0792862
I0403 10:11:31.825006  8106 solver.cpp:244]     Train net output #0: loss = 0.0792862 (* 1 = 0.0792862 loss)
I0403 10:11:32.003320  8106 sgd_solver.cpp:106] Iteration 6617, lr = 5e-05
I0403 10:11:41.314100  8106 solver.cpp:228] Iteration 6630, loss = 0.0229035
I0403 10:11:41.314196  8106 solver.cpp:244]     Train net output #0: loss = 0.0229035 (* 1 = 0.0229035 loss)
I0403 10:11:41.501283  8106 sgd_solver.cpp:106] Iteration 6630, lr = 5e-05
I0403 10:11:50.649917  8106 solver.cpp:228] Iteration 6643, loss = 0.0307086
I0403 10:11:50.650019  8106 solver.cpp:244]     Train net output #0: loss = 0.0307086 (* 1 = 0.0307086 loss)
I0403 10:11:50.870048  8106 sgd_solver.cpp:106] Iteration 6643, lr = 5e-05
I0403 10:12:00.159696  8106 solver.cpp:228] Iteration 6656, loss = 0.0176805
I0403 10:12:00.159793  8106 solver.cpp:244]     Train net output #0: loss = 0.0176805 (* 1 = 0.0176805 loss)
I0403 10:12:00.355003  8106 sgd_solver.cpp:106] Iteration 6656, lr = 5e-05
I0403 10:12:09.485693  8106 solver.cpp:228] Iteration 6669, loss = 0.0195212
I0403 10:12:09.486008  8106 solver.cpp:244]     Train net output #0: loss = 0.0195212 (* 1 = 0.0195212 loss)
I0403 10:12:09.669817  8106 sgd_solver.cpp:106] Iteration 6669, lr = 5e-05
I0403 10:12:13.274536  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6675.caffemodel
I0403 10:12:16.052865  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6675.solverstate
I0403 10:12:17.918898  8106 solver.cpp:337] Iteration 6675, Testing net (#0)
I0403 10:13:19.981410  8106 solver.cpp:404]     Test net output #0: accuracy = 0.9312
I0403 10:13:19.981781  8106 solver.cpp:404]     Test net output #1: loss = 0.246925 (* 1 = 0.246925 loss)
I0403 10:13:25.605988  8106 solver.cpp:228] Iteration 6682, loss = 0.0413252
I0403 10:13:25.606071  8106 solver.cpp:244]     Train net output #0: loss = 0.0413252 (* 1 = 0.0413252 loss)
I0403 10:13:25.774981  8106 sgd_solver.cpp:106] Iteration 6682, lr = 5e-05
I0403 10:13:35.085589  8106 solver.cpp:228] Iteration 6695, loss = 0.0166477
I0403 10:13:35.085685  8106 solver.cpp:244]     Train net output #0: loss = 0.0166477 (* 1 = 0.0166477 loss)
I0403 10:13:35.279631  8106 sgd_solver.cpp:106] Iteration 6695, lr = 5e-05
I0403 10:13:44.570827  8106 solver.cpp:228] Iteration 6708, loss = 0.026713
I0403 10:13:44.570922  8106 solver.cpp:244]     Train net output #0: loss = 0.026713 (* 1 = 0.026713 loss)
I0403 10:13:44.752728  8106 sgd_solver.cpp:106] Iteration 6708, lr = 5e-05
I0403 10:13:53.922286  8106 solver.cpp:228] Iteration 6721, loss = 0.0666291
I0403 10:13:53.926386  8106 solver.cpp:244]     Train net output #0: loss = 0.0666291 (* 1 = 0.0666291 loss)
I0403 10:13:54.136275  8106 sgd_solver.cpp:106] Iteration 6721, lr = 5e-05
I0403 10:14:03.430534  8106 solver.cpp:228] Iteration 6734, loss = 0.027117
I0403 10:14:03.430634  8106 solver.cpp:244]     Train net output #0: loss = 0.027117 (* 1 = 0.027117 loss)
I0403 10:14:03.619937  8106 sgd_solver.cpp:106] Iteration 6734, lr = 5e-05
I0403 10:14:12.862272  8106 solver.cpp:228] Iteration 6747, loss = 0.0739523
I0403 10:14:12.862360  8106 solver.cpp:244]     Train net output #0: loss = 0.0739523 (* 1 = 0.0739523 loss)
I0403 10:14:13.023988  8106 sgd_solver.cpp:106] Iteration 6747, lr = 5e-05
I0403 10:14:22.348886  8106 solver.cpp:228] Iteration 6760, loss = 0.0156778
I0403 10:14:22.348984  8106 solver.cpp:244]     Train net output #0: loss = 0.0156778 (* 1 = 0.0156778 loss)
I0403 10:14:22.546139  8106 sgd_solver.cpp:106] Iteration 6760, lr = 5e-05
I0403 10:14:31.782148  8106 solver.cpp:228] Iteration 6773, loss = 0.0566655
I0403 10:14:31.782430  8106 solver.cpp:244]     Train net output #0: loss = 0.0566655 (* 1 = 0.0566655 loss)
I0403 10:14:31.970979  8106 sgd_solver.cpp:106] Iteration 6773, lr = 5e-05
I0403 10:14:41.260093  8106 solver.cpp:228] Iteration 6786, loss = 0.0386316
I0403 10:14:41.260191  8106 solver.cpp:244]     Train net output #0: loss = 0.0386316 (* 1 = 0.0386316 loss)
I0403 10:14:41.444917  8106 sgd_solver.cpp:106] Iteration 6786, lr = 5e-05
I0403 10:14:50.670120  8106 solver.cpp:228] Iteration 6799, loss = 0.028475
I0403 10:14:50.670217  8106 solver.cpp:244]     Train net output #0: loss = 0.028475 (* 1 = 0.028475 loss)
I0403 10:14:50.873494  8106 sgd_solver.cpp:106] Iteration 6799, lr = 5e-05
I0403 10:15:00.113330  8106 solver.cpp:228] Iteration 6812, loss = 0.0102185
I0403 10:15:00.113427  8106 solver.cpp:244]     Train net output #0: loss = 0.0102185 (* 1 = 0.0102185 loss)
I0403 10:15:00.322499  8106 sgd_solver.cpp:106] Iteration 6812, lr = 5e-05
I0403 10:15:09.572312  8106 solver.cpp:228] Iteration 6825, loss = 0.0548585
I0403 10:15:09.572612  8106 solver.cpp:244]     Train net output #0: loss = 0.0548585 (* 1 = 0.0548585 loss)
I0403 10:15:09.761608  8106 sgd_solver.cpp:106] Iteration 6825, lr = 5e-05
I0403 10:15:18.964664  8106 solver.cpp:228] Iteration 6838, loss = 0.0605254
I0403 10:15:18.964761  8106 solver.cpp:244]     Train net output #0: loss = 0.0605254 (* 1 = 0.0605254 loss)
I0403 10:15:19.163398  8106 sgd_solver.cpp:106] Iteration 6838, lr = 5e-05
I0403 10:15:28.420375  8106 solver.cpp:228] Iteration 6851, loss = 0.0300937
I0403 10:15:28.420465  8106 solver.cpp:244]     Train net output #0: loss = 0.0300937 (* 1 = 0.0300937 loss)
I0403 10:15:28.599567  8106 sgd_solver.cpp:106] Iteration 6851, lr = 5e-05
I0403 10:15:37.740772  8106 solver.cpp:228] Iteration 6864, loss = 0.0143813
I0403 10:15:37.740859  8106 solver.cpp:244]     Train net output #0: loss = 0.0143813 (* 1 = 0.0143813 loss)
I0403 10:15:37.897449  8106 sgd_solver.cpp:106] Iteration 6864, lr = 5e-05
I0403 10:15:47.483067  8106 solver.cpp:228] Iteration 6877, loss = 0.0356435
I0403 10:15:47.483391  8106 solver.cpp:244]     Train net output #0: loss = 0.0356435 (* 1 = 0.0356435 loss)
I0403 10:15:47.724617  8106 sgd_solver.cpp:106] Iteration 6877, lr = 5e-05
I0403 10:15:56.914610  8106 solver.cpp:228] Iteration 6890, loss = 0.0566411
I0403 10:15:56.914698  8106 solver.cpp:244]     Train net output #0: loss = 0.0566411 (* 1 = 0.0566411 loss)
I0403 10:15:57.092615  8106 sgd_solver.cpp:106] Iteration 6890, lr = 5e-05
I0403 10:16:06.263418  8106 solver.cpp:228] Iteration 6903, loss = 0.0196801
I0403 10:16:06.263520  8106 solver.cpp:244]     Train net output #0: loss = 0.0196801 (* 1 = 0.0196801 loss)
I0403 10:16:06.474030  8106 sgd_solver.cpp:106] Iteration 6903, lr = 5e-05
I0403 10:16:15.714972  8106 solver.cpp:228] Iteration 6916, loss = 0.0439216
I0403 10:16:15.715070  8106 solver.cpp:244]     Train net output #0: loss = 0.0439216 (* 1 = 0.0439216 loss)
I0403 10:16:15.946583  8106 sgd_solver.cpp:106] Iteration 6916, lr = 5e-05
I0403 10:16:25.371213  8106 solver.cpp:228] Iteration 6929, loss = 0.0670239
I0403 10:16:25.371520  8106 solver.cpp:244]     Train net output #0: loss = 0.067024 (* 1 = 0.067024 loss)
I0403 10:16:25.571758  8106 sgd_solver.cpp:106] Iteration 6929, lr = 5e-05
I0403 10:16:34.198861  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6942.caffemodel
I0403 10:16:36.963634  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_6942.solverstate
I0403 10:16:38.774791  8106 solver.cpp:337] Iteration 6942, Testing net (#0)
I0403 10:17:40.834808  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931636
I0403 10:17:40.835094  8106 solver.cpp:404]     Test net output #1: loss = 0.246067 (* 1 = 0.246067 loss)
I0403 10:17:41.349097  8106 solver.cpp:228] Iteration 6942, loss = 0.026684
I0403 10:17:41.349179  8106 solver.cpp:244]     Train net output #0: loss = 0.026684 (* 1 = 0.026684 loss)
I0403 10:17:41.519871  8106 sgd_solver.cpp:106] Iteration 6942, lr = 5e-05
I0403 10:17:50.752851  8106 solver.cpp:228] Iteration 6955, loss = 0.0448677
I0403 10:17:50.752951  8106 solver.cpp:244]     Train net output #0: loss = 0.0448677 (* 1 = 0.0448677 loss)
I0403 10:17:51.002828  8106 sgd_solver.cpp:106] Iteration 6955, lr = 5e-05
I0403 10:18:00.126368  8106 solver.cpp:228] Iteration 6968, loss = 0.0201163
I0403 10:18:00.126456  8106 solver.cpp:244]     Train net output #0: loss = 0.0201163 (* 1 = 0.0201163 loss)
I0403 10:18:00.295653  8106 sgd_solver.cpp:106] Iteration 6968, lr = 5e-05
I0403 10:18:09.503968  8106 solver.cpp:228] Iteration 6981, loss = 0.0211319
I0403 10:18:09.504060  8106 solver.cpp:244]     Train net output #0: loss = 0.0211319 (* 1 = 0.0211319 loss)
I0403 10:18:09.692903  8106 sgd_solver.cpp:106] Iteration 6981, lr = 5e-05
I0403 10:18:18.900156  8106 solver.cpp:228] Iteration 6994, loss = 0.0363193
I0403 10:18:18.900382  8106 solver.cpp:244]     Train net output #0: loss = 0.0363193 (* 1 = 0.0363193 loss)
I0403 10:18:19.099685  8106 sgd_solver.cpp:106] Iteration 6994, lr = 5e-05
I0403 10:18:28.364327  8106 solver.cpp:228] Iteration 7007, loss = 0.0181634
I0403 10:18:28.364416  8106 solver.cpp:244]     Train net output #0: loss = 0.0181634 (* 1 = 0.0181634 loss)
I0403 10:18:28.543112  8106 sgd_solver.cpp:106] Iteration 7007, lr = 5e-05
I0403 10:18:37.830731  8106 solver.cpp:228] Iteration 7020, loss = 0.0147381
I0403 10:18:37.830844  8106 solver.cpp:244]     Train net output #0: loss = 0.0147381 (* 1 = 0.0147381 loss)
I0403 10:18:38.035383  8106 sgd_solver.cpp:106] Iteration 7020, lr = 5e-05
I0403 10:18:47.364488  8106 solver.cpp:228] Iteration 7033, loss = 0.0126316
I0403 10:18:47.364603  8106 solver.cpp:244]     Train net output #0: loss = 0.0126316 (* 1 = 0.0126316 loss)
I0403 10:18:47.500200  8106 sgd_solver.cpp:106] Iteration 7033, lr = 5e-05
I0403 10:18:56.795920  8106 solver.cpp:228] Iteration 7046, loss = 0.0451376
I0403 10:18:56.796219  8106 solver.cpp:244]     Train net output #0: loss = 0.0451376 (* 1 = 0.0451376 loss)
I0403 10:18:56.993665  8106 sgd_solver.cpp:106] Iteration 7046, lr = 5e-05
I0403 10:19:06.189738  8106 solver.cpp:228] Iteration 7059, loss = 0.0148137
I0403 10:19:06.189837  8106 solver.cpp:244]     Train net output #0: loss = 0.0148137 (* 1 = 0.0148137 loss)
I0403 10:19:06.396550  8106 sgd_solver.cpp:106] Iteration 7059, lr = 5e-05
I0403 10:19:15.696213  8106 solver.cpp:228] Iteration 7072, loss = 0.0555415
I0403 10:19:15.696301  8106 solver.cpp:244]     Train net output #0: loss = 0.0555415 (* 1 = 0.0555415 loss)
I0403 10:19:15.848387  8106 sgd_solver.cpp:106] Iteration 7072, lr = 5e-05
I0403 10:19:25.293982  8106 solver.cpp:228] Iteration 7085, loss = 0.0170296
I0403 10:19:25.294071  8106 solver.cpp:244]     Train net output #0: loss = 0.0170296 (* 1 = 0.0170296 loss)
I0403 10:19:25.472090  8106 sgd_solver.cpp:106] Iteration 7085, lr = 5e-05
I0403 10:19:34.605526  8106 solver.cpp:228] Iteration 7098, loss = 0.047512
I0403 10:19:34.605829  8106 solver.cpp:244]     Train net output #0: loss = 0.047512 (* 1 = 0.047512 loss)
I0403 10:19:34.814954  8106 sgd_solver.cpp:106] Iteration 7098, lr = 5e-05
I0403 10:19:44.016430  8106 solver.cpp:228] Iteration 7111, loss = 0.0452235
I0403 10:19:44.016520  8106 solver.cpp:244]     Train net output #0: loss = 0.0452235 (* 1 = 0.0452235 loss)
I0403 10:19:44.179355  8106 sgd_solver.cpp:106] Iteration 7111, lr = 5e-05
I0403 10:19:53.439247  8106 solver.cpp:228] Iteration 7124, loss = 0.098354
I0403 10:19:53.439337  8106 solver.cpp:244]     Train net output #0: loss = 0.098354 (* 1 = 0.098354 loss)
I0403 10:19:53.609505  8106 sgd_solver.cpp:106] Iteration 7124, lr = 5e-05
I0403 10:20:02.789293  8106 solver.cpp:228] Iteration 7137, loss = 0.0501081
I0403 10:20:02.789391  8106 solver.cpp:244]     Train net output #0: loss = 0.0501081 (* 1 = 0.0501081 loss)
I0403 10:20:02.990649  8106 sgd_solver.cpp:106] Iteration 7137, lr = 5e-05
I0403 10:20:12.204044  8106 solver.cpp:228] Iteration 7150, loss = 0.0694322
I0403 10:20:12.204346  8106 solver.cpp:244]     Train net output #0: loss = 0.0694322 (* 1 = 0.0694322 loss)
I0403 10:20:12.401468  8106 sgd_solver.cpp:106] Iteration 7150, lr = 5e-05
I0403 10:20:21.587177  8106 solver.cpp:228] Iteration 7163, loss = 0.0463388
I0403 10:20:21.587276  8106 solver.cpp:244]     Train net output #0: loss = 0.0463388 (* 1 = 0.0463388 loss)
I0403 10:20:21.792325  8106 sgd_solver.cpp:106] Iteration 7163, lr = 5e-05
I0403 10:20:30.996259  8106 solver.cpp:228] Iteration 7176, loss = 0.0168663
I0403 10:20:30.996361  8106 solver.cpp:244]     Train net output #0: loss = 0.0168663 (* 1 = 0.0168663 loss)
I0403 10:20:31.266275  8106 sgd_solver.cpp:106] Iteration 7176, lr = 5e-05
I0403 10:20:40.432447  8106 solver.cpp:228] Iteration 7189, loss = 0.050216
I0403 10:20:40.432535  8106 solver.cpp:244]     Train net output #0: loss = 0.050216 (* 1 = 0.050216 loss)
I0403 10:20:40.609128  8106 sgd_solver.cpp:106] Iteration 7189, lr = 5e-05
I0403 10:20:49.849200  8106 solver.cpp:228] Iteration 7202, loss = 0.0148682
I0403 10:20:49.849478  8106 solver.cpp:244]     Train net output #0: loss = 0.0148681 (* 1 = 0.0148681 loss)
I0403 10:20:50.008260  8106 sgd_solver.cpp:106] Iteration 7202, lr = 5e-05
I0403 10:20:54.420960  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_7209.caffemodel
I0403 10:20:57.176491  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_7209.solverstate
I0403 10:20:59.044755  8106 solver.cpp:337] Iteration 7209, Testing net (#0)
I0403 10:22:01.078368  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931309
I0403 10:22:01.078635  8106 solver.cpp:404]     Test net output #1: loss = 0.245778 (* 1 = 0.245778 loss)
I0403 10:22:06.027771  8106 solver.cpp:228] Iteration 7215, loss = 0.0209792
I0403 10:22:06.027859  8106 solver.cpp:244]     Train net output #0: loss = 0.0209791 (* 1 = 0.0209791 loss)
I0403 10:22:06.170892  8106 sgd_solver.cpp:106] Iteration 7215, lr = 5e-05
I0403 10:22:15.500546  8106 solver.cpp:228] Iteration 7228, loss = 0.0518188
I0403 10:22:15.500644  8106 solver.cpp:244]     Train net output #0: loss = 0.0518188 (* 1 = 0.0518188 loss)
I0403 10:22:15.690557  8106 sgd_solver.cpp:106] Iteration 7228, lr = 5e-05
I0403 10:22:24.856581  8106 solver.cpp:228] Iteration 7241, loss = 0.0267397
I0403 10:22:24.856676  8106 solver.cpp:244]     Train net output #0: loss = 0.0267397 (* 1 = 0.0267397 loss)
I0403 10:22:25.076328  8106 sgd_solver.cpp:106] Iteration 7241, lr = 5e-05
I0403 10:22:34.285011  8106 solver.cpp:228] Iteration 7254, loss = 0.0449519
I0403 10:22:34.285331  8106 solver.cpp:244]     Train net output #0: loss = 0.0449518 (* 1 = 0.0449518 loss)
I0403 10:22:34.481050  8106 sgd_solver.cpp:106] Iteration 7254, lr = 5e-05
I0403 10:22:43.715824  8106 solver.cpp:228] Iteration 7267, loss = 0.0555953
I0403 10:22:43.715920  8106 solver.cpp:244]     Train net output #0: loss = 0.0555952 (* 1 = 0.0555952 loss)
I0403 10:22:43.900061  8106 sgd_solver.cpp:106] Iteration 7267, lr = 5e-05
I0403 10:22:53.203968  8106 solver.cpp:228] Iteration 7280, loss = 0.0257815
I0403 10:22:53.204067  8106 solver.cpp:244]     Train net output #0: loss = 0.0257815 (* 1 = 0.0257815 loss)
I0403 10:22:53.391290  8106 sgd_solver.cpp:106] Iteration 7280, lr = 5e-05
I0403 10:23:02.511152  8106 solver.cpp:228] Iteration 7293, loss = 0.0295122
I0403 10:23:02.511252  8106 solver.cpp:244]     Train net output #0: loss = 0.0295122 (* 1 = 0.0295122 loss)
I0403 10:23:02.714269  8106 sgd_solver.cpp:106] Iteration 7293, lr = 5e-05
I0403 10:23:11.937499  8106 solver.cpp:228] Iteration 7306, loss = 0.0597236
I0403 10:23:11.938421  8106 solver.cpp:244]     Train net output #0: loss = 0.0597236 (* 1 = 0.0597236 loss)
I0403 10:23:12.119160  8106 sgd_solver.cpp:106] Iteration 7306, lr = 5e-05
I0403 10:23:21.503888  8106 solver.cpp:228] Iteration 7319, loss = 0.0595727
I0403 10:23:21.503986  8106 solver.cpp:244]     Train net output #0: loss = 0.0595726 (* 1 = 0.0595726 loss)
I0403 10:23:21.732919  8106 sgd_solver.cpp:106] Iteration 7319, lr = 5e-05
I0403 10:23:30.945560  8106 solver.cpp:228] Iteration 7332, loss = 0.0614767
I0403 10:23:30.945662  8106 solver.cpp:244]     Train net output #0: loss = 0.0614766 (* 1 = 0.0614766 loss)
I0403 10:23:31.143748  8106 sgd_solver.cpp:106] Iteration 7332, lr = 5e-05
I0403 10:23:40.444210  8106 solver.cpp:228] Iteration 7345, loss = 0.032144
I0403 10:23:40.444296  8106 solver.cpp:244]     Train net output #0: loss = 0.032144 (* 1 = 0.032144 loss)
I0403 10:23:40.605638  8106 sgd_solver.cpp:106] Iteration 7345, lr = 5e-05
I0403 10:23:50.015151  8106 solver.cpp:228] Iteration 7358, loss = 0.0326817
I0403 10:23:50.015429  8106 solver.cpp:244]     Train net output #0: loss = 0.0326817 (* 1 = 0.0326817 loss)
I0403 10:23:50.191867  8106 sgd_solver.cpp:106] Iteration 7358, lr = 5e-05
I0403 10:23:59.406177  8106 solver.cpp:228] Iteration 7371, loss = 0.0749822
I0403 10:23:59.406275  8106 solver.cpp:244]     Train net output #0: loss = 0.0749821 (* 1 = 0.0749821 loss)
I0403 10:23:59.589421  8106 sgd_solver.cpp:106] Iteration 7371, lr = 5e-05
I0403 10:24:08.833395  8106 solver.cpp:228] Iteration 7384, loss = 0.0135615
I0403 10:24:08.833493  8106 solver.cpp:244]     Train net output #0: loss = 0.0135615 (* 1 = 0.0135615 loss)
I0403 10:24:09.030139  8106 sgd_solver.cpp:106] Iteration 7384, lr = 5e-05
I0403 10:24:18.220767  8106 solver.cpp:228] Iteration 7397, loss = 0.0221123
I0403 10:24:18.220854  8106 solver.cpp:244]     Train net output #0: loss = 0.0221123 (* 1 = 0.0221123 loss)
I0403 10:24:18.400166  8106 sgd_solver.cpp:106] Iteration 7397, lr = 5e-05
I0403 10:24:27.722280  8106 solver.cpp:228] Iteration 7410, loss = 0.0445108
I0403 10:24:27.722584  8106 solver.cpp:244]     Train net output #0: loss = 0.0445108 (* 1 = 0.0445108 loss)
I0403 10:24:27.904022  8106 sgd_solver.cpp:106] Iteration 7410, lr = 5e-05
I0403 10:24:37.102373  8106 solver.cpp:228] Iteration 7423, loss = 0.0386378
I0403 10:24:37.102463  8106 solver.cpp:244]     Train net output #0: loss = 0.0386378 (* 1 = 0.0386378 loss)
I0403 10:24:37.258458  8106 sgd_solver.cpp:106] Iteration 7423, lr = 5e-05
I0403 10:24:46.614104  8106 solver.cpp:228] Iteration 7436, loss = 0.0360516
I0403 10:24:46.614192  8106 solver.cpp:244]     Train net output #0: loss = 0.0360515 (* 1 = 0.0360515 loss)
I0403 10:24:46.782167  8106 sgd_solver.cpp:106] Iteration 7436, lr = 5e-05
I0403 10:24:56.186905  8106 solver.cpp:228] Iteration 7449, loss = 0.0159913
I0403 10:24:56.186995  8106 solver.cpp:244]     Train net output #0: loss = 0.0159913 (* 1 = 0.0159913 loss)
I0403 10:24:56.334897  8106 sgd_solver.cpp:106] Iteration 7449, lr = 5e-05
I0403 10:25:05.704659  8106 solver.cpp:228] Iteration 7462, loss = 0.076429
I0403 10:25:05.704979  8106 solver.cpp:244]     Train net output #0: loss = 0.076429 (* 1 = 0.076429 loss)
I0403 10:25:05.880504  8106 sgd_solver.cpp:106] Iteration 7462, lr = 5e-05
I0403 10:25:15.066117  8106 solver.cpp:228] Iteration 7475, loss = 0.039729
I0403 10:25:15.066213  8106 solver.cpp:244]     Train net output #0: loss = 0.0397289 (* 1 = 0.0397289 loss)
I0403 10:25:15.249408  8106 sgd_solver.cpp:106] Iteration 7475, lr = 5e-05
I0403 10:25:15.249661  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_7476.caffemodel
I0403 10:25:17.972470  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_7476.solverstate
I0403 10:25:19.859633  8106 solver.cpp:337] Iteration 7476, Testing net (#0)
I0403 10:26:21.920195  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931963
I0403 10:26:21.920493  8106 solver.cpp:404]     Test net output #1: loss = 0.247429 (* 1 = 0.247429 loss)
I0403 10:26:31.096925  8106 solver.cpp:228] Iteration 7488, loss = 0.0255794
I0403 10:26:31.097010  8106 solver.cpp:244]     Train net output #0: loss = 0.0255794 (* 1 = 0.0255794 loss)
I0403 10:26:31.273129  8106 sgd_solver.cpp:106] Iteration 7488, lr = 5e-05
I0403 10:26:40.729243  8106 solver.cpp:228] Iteration 7501, loss = 0.0178652
I0403 10:26:40.729331  8106 solver.cpp:244]     Train net output #0: loss = 0.0178651 (* 1 = 0.0178651 loss)
I0403 10:26:40.882256  8106 sgd_solver.cpp:106] Iteration 7501, lr = 5e-05
I0403 10:26:50.190475  8106 solver.cpp:228] Iteration 7514, loss = 0.0208453
I0403 10:26:50.190578  8106 solver.cpp:244]     Train net output #0: loss = 0.0208453 (* 1 = 0.0208453 loss)
I0403 10:26:50.394670  8106 sgd_solver.cpp:106] Iteration 7514, lr = 5e-05
I0403 10:26:59.593173  8106 solver.cpp:228] Iteration 7527, loss = 0.0344662
I0403 10:26:59.593478  8106 solver.cpp:244]     Train net output #0: loss = 0.0344662 (* 1 = 0.0344662 loss)
I0403 10:26:59.780118  8106 sgd_solver.cpp:106] Iteration 7527, lr = 5e-05
I0403 10:27:09.079488  8106 solver.cpp:228] Iteration 7540, loss = 0.0439819
I0403 10:27:09.079592  8106 solver.cpp:244]     Train net output #0: loss = 0.0439819 (* 1 = 0.0439819 loss)
I0403 10:27:09.268342  8106 sgd_solver.cpp:106] Iteration 7540, lr = 5e-05
I0403 10:27:18.440065  8106 solver.cpp:228] Iteration 7553, loss = 0.0253999
I0403 10:27:18.440166  8106 solver.cpp:244]     Train net output #0: loss = 0.0253999 (* 1 = 0.0253999 loss)
I0403 10:27:18.628235  8106 sgd_solver.cpp:106] Iteration 7553, lr = 5e-05
I0403 10:27:27.871841  8106 solver.cpp:228] Iteration 7566, loss = 0.0572807
I0403 10:27:27.871930  8106 solver.cpp:244]     Train net output #0: loss = 0.0572807 (* 1 = 0.0572807 loss)
I0403 10:27:28.043052  8106 sgd_solver.cpp:106] Iteration 7566, lr = 5e-05
I0403 10:27:37.360437  8106 solver.cpp:228] Iteration 7579, loss = 0.036112
I0403 10:27:37.360754  8106 solver.cpp:244]     Train net output #0: loss = 0.036112 (* 1 = 0.036112 loss)
I0403 10:27:37.540073  8106 sgd_solver.cpp:106] Iteration 7579, lr = 5e-05
I0403 10:27:46.940567  8106 solver.cpp:228] Iteration 7592, loss = 0.0284782
I0403 10:27:46.940677  8106 solver.cpp:244]     Train net output #0: loss = 0.0284782 (* 1 = 0.0284782 loss)
I0403 10:27:47.132436  8106 sgd_solver.cpp:106] Iteration 7592, lr = 5e-05
I0403 10:27:56.490476  8106 solver.cpp:228] Iteration 7605, loss = 0.0506755
I0403 10:27:56.490568  8106 solver.cpp:244]     Train net output #0: loss = 0.0506754 (* 1 = 0.0506754 loss)
I0403 10:27:56.601193  8106 sgd_solver.cpp:106] Iteration 7605, lr = 5e-05
I0403 10:28:06.099664  8106 solver.cpp:228] Iteration 7618, loss = 0.033624
I0403 10:28:06.099751  8106 solver.cpp:244]     Train net output #0: loss = 0.033624 (* 1 = 0.033624 loss)
I0403 10:28:06.271911  8106 sgd_solver.cpp:106] Iteration 7618, lr = 5e-05
I0403 10:28:15.464548  8106 solver.cpp:228] Iteration 7631, loss = 0.0168229
I0403 10:28:15.464864  8106 solver.cpp:244]     Train net output #0: loss = 0.0168229 (* 1 = 0.0168229 loss)
I0403 10:28:15.649529  8106 sgd_solver.cpp:106] Iteration 7631, lr = 5e-05
I0403 10:28:24.789494  8106 solver.cpp:228] Iteration 7644, loss = 0.0478248
I0403 10:28:24.789593  8106 solver.cpp:244]     Train net output #0: loss = 0.0478248 (* 1 = 0.0478248 loss)
I0403 10:28:24.989567  8106 sgd_solver.cpp:106] Iteration 7644, lr = 5e-05
I0403 10:28:34.187400  8106 solver.cpp:228] Iteration 7657, loss = 0.103765
I0403 10:28:34.187485  8106 solver.cpp:244]     Train net output #0: loss = 0.103765 (* 1 = 0.103765 loss)
I0403 10:28:34.358580  8106 sgd_solver.cpp:106] Iteration 7657, lr = 5e-05
I0403 10:28:43.552286  8106 solver.cpp:228] Iteration 7670, loss = 0.0425063
I0403 10:28:43.552374  8106 solver.cpp:244]     Train net output #0: loss = 0.0425063 (* 1 = 0.0425063 loss)
I0403 10:28:43.725427  8106 sgd_solver.cpp:106] Iteration 7670, lr = 5e-05
I0403 10:28:53.020267  8106 solver.cpp:228] Iteration 7683, loss = 0.0536757
I0403 10:28:53.020547  8106 solver.cpp:244]     Train net output #0: loss = 0.0536757 (* 1 = 0.0536757 loss)
I0403 10:28:53.191704  8106 sgd_solver.cpp:106] Iteration 7683, lr = 5e-05
I0403 10:29:02.336289  8106 solver.cpp:228] Iteration 7696, loss = 0.0621359
I0403 10:29:02.336390  8106 solver.cpp:244]     Train net output #0: loss = 0.0621359 (* 1 = 0.0621359 loss)
I0403 10:29:02.528102  8106 sgd_solver.cpp:106] Iteration 7696, lr = 5e-05
I0403 10:29:11.784464  8106 solver.cpp:228] Iteration 7709, loss = 0.0149769
I0403 10:29:11.784572  8106 solver.cpp:244]     Train net output #0: loss = 0.0149768 (* 1 = 0.0149768 loss)
I0403 10:29:12.055480  8106 sgd_solver.cpp:106] Iteration 7709, lr = 5e-05
I0403 10:29:21.263232  8106 solver.cpp:228] Iteration 7722, loss = 0.00776798
I0403 10:29:21.263330  8106 solver.cpp:244]     Train net output #0: loss = 0.00776793 (* 1 = 0.00776793 loss)
I0403 10:29:21.448155  8106 sgd_solver.cpp:106] Iteration 7722, lr = 5e-05
I0403 10:29:30.599200  8106 solver.cpp:228] Iteration 7735, loss = 0.059426
I0403 10:29:30.599511  8106 solver.cpp:244]     Train net output #0: loss = 0.059426 (* 1 = 0.059426 loss)
I0403 10:29:30.777753  8106 sgd_solver.cpp:106] Iteration 7735, lr = 5e-05
I0403 10:29:35.866730  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_7743.caffemodel
I0403 10:29:38.613271  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_7743.solverstate
I0403 10:29:40.400923  8106 solver.cpp:337] Iteration 7743, Testing net (#0)
I0403 10:30:42.450821  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931745
I0403 10:30:42.451127  8106 solver.cpp:404]     Test net output #1: loss = 0.247481 (* 1 = 0.247481 loss)
I0403 10:30:46.633476  8106 solver.cpp:228] Iteration 7748, loss = 0.0241487
I0403 10:30:46.633568  8106 solver.cpp:244]     Train net output #0: loss = 0.0241486 (* 1 = 0.0241486 loss)
I0403 10:30:46.811867  8106 sgd_solver.cpp:106] Iteration 7748, lr = 5e-05
I0403 10:30:55.949641  8106 solver.cpp:228] Iteration 7761, loss = 0.0601657
I0403 10:30:55.949741  8106 solver.cpp:244]     Train net output #0: loss = 0.0601657 (* 1 = 0.0601657 loss)
I0403 10:30:56.131364  8106 sgd_solver.cpp:106] Iteration 7761, lr = 5e-05
I0403 10:31:05.350658  8106 solver.cpp:228] Iteration 7774, loss = 0.0440237
I0403 10:31:05.350746  8106 solver.cpp:244]     Train net output #0: loss = 0.0440237 (* 1 = 0.0440237 loss)
I0403 10:31:05.521754  8106 sgd_solver.cpp:106] Iteration 7774, lr = 5e-05
I0403 10:31:14.864903  8106 solver.cpp:228] Iteration 7787, loss = 0.0366295
I0403 10:31:14.865206  8106 solver.cpp:244]     Train net output #0: loss = 0.0366295 (* 1 = 0.0366295 loss)
I0403 10:31:15.043448  8106 sgd_solver.cpp:106] Iteration 7787, lr = 5e-05
I0403 10:31:24.336700  8106 solver.cpp:228] Iteration 7800, loss = 0.0370155
I0403 10:31:24.336787  8106 solver.cpp:244]     Train net output #0: loss = 0.0370155 (* 1 = 0.0370155 loss)
I0403 10:31:24.510318  8106 sgd_solver.cpp:106] Iteration 7800, lr = 5e-05
I0403 10:31:33.763448  8106 solver.cpp:228] Iteration 7813, loss = 0.0735796
I0403 10:31:33.763551  8106 solver.cpp:244]     Train net output #0: loss = 0.0735796 (* 1 = 0.0735796 loss)
I0403 10:31:33.945842  8106 sgd_solver.cpp:106] Iteration 7813, lr = 5e-05
I0403 10:31:43.200268  8106 solver.cpp:228] Iteration 7826, loss = 0.0804424
I0403 10:31:43.200366  8106 solver.cpp:244]     Train net output #0: loss = 0.0804423 (* 1 = 0.0804423 loss)
I0403 10:31:43.414646  8106 sgd_solver.cpp:106] Iteration 7826, lr = 5e-05
I0403 10:31:52.604270  8106 solver.cpp:228] Iteration 7839, loss = 0.0640948
I0403 10:31:52.604555  8106 solver.cpp:244]     Train net output #0: loss = 0.0640947 (* 1 = 0.0640947 loss)
I0403 10:31:52.780792  8106 sgd_solver.cpp:106] Iteration 7839, lr = 5e-05
I0403 10:32:02.010982  8106 solver.cpp:228] Iteration 7852, loss = 0.00607698
I0403 10:32:02.011080  8106 solver.cpp:244]     Train net output #0: loss = 0.00607693 (* 1 = 0.00607693 loss)
I0403 10:32:02.192551  8106 sgd_solver.cpp:106] Iteration 7852, lr = 5e-05
I0403 10:32:11.425020  8106 solver.cpp:228] Iteration 7865, loss = 0.0308915
I0403 10:32:11.425117  8106 solver.cpp:244]     Train net output #0: loss = 0.0308915 (* 1 = 0.0308915 loss)
I0403 10:32:11.612387  8106 sgd_solver.cpp:106] Iteration 7865, lr = 5e-05
I0403 10:32:20.775740  8106 solver.cpp:228] Iteration 7878, loss = 0.0421434
I0403 10:32:20.775840  8106 solver.cpp:244]     Train net output #0: loss = 0.0421433 (* 1 = 0.0421433 loss)
I0403 10:32:20.958155  8106 sgd_solver.cpp:106] Iteration 7878, lr = 5e-05
I0403 10:32:30.193789  8106 solver.cpp:228] Iteration 7891, loss = 0.0486485
I0403 10:32:30.194079  8106 solver.cpp:244]     Train net output #0: loss = 0.0486484 (* 1 = 0.0486484 loss)
I0403 10:32:30.443814  8106 sgd_solver.cpp:106] Iteration 7891, lr = 5e-05
I0403 10:32:39.712568  8106 solver.cpp:228] Iteration 7904, loss = 0.0624753
I0403 10:32:39.712663  8106 solver.cpp:244]     Train net output #0: loss = 0.0624753 (* 1 = 0.0624753 loss)
I0403 10:32:39.910419  8106 sgd_solver.cpp:106] Iteration 7904, lr = 5e-05
I0403 10:32:49.210469  8106 solver.cpp:228] Iteration 7917, loss = 0.0406726
I0403 10:32:49.210566  8106 solver.cpp:244]     Train net output #0: loss = 0.0406725 (* 1 = 0.0406725 loss)
I0403 10:32:49.391175  8106 sgd_solver.cpp:106] Iteration 7917, lr = 5e-05
I0403 10:32:58.659020  8106 solver.cpp:228] Iteration 7930, loss = 0.0283978
I0403 10:32:58.659116  8106 solver.cpp:244]     Train net output #0: loss = 0.0283977 (* 1 = 0.0283977 loss)
I0403 10:32:58.840639  8106 sgd_solver.cpp:106] Iteration 7930, lr = 5e-05
I0403 10:33:08.254199  8106 solver.cpp:228] Iteration 7943, loss = 0.102123
I0403 10:33:08.254525  8106 solver.cpp:244]     Train net output #0: loss = 0.102123 (* 1 = 0.102123 loss)
I0403 10:33:08.436334  8106 sgd_solver.cpp:106] Iteration 7943, lr = 5e-05
I0403 10:33:17.743093  8106 solver.cpp:228] Iteration 7956, loss = 0.0638494
I0403 10:33:17.743209  8106 solver.cpp:244]     Train net output #0: loss = 0.0638494 (* 1 = 0.0638494 loss)
I0403 10:33:17.930857  8106 sgd_solver.cpp:106] Iteration 7956, lr = 5e-05
I0403 10:33:27.161206  8106 solver.cpp:228] Iteration 7969, loss = 0.118274
I0403 10:33:27.161303  8106 solver.cpp:244]     Train net output #0: loss = 0.118274 (* 1 = 0.118274 loss)
I0403 10:33:27.343122  8106 sgd_solver.cpp:106] Iteration 7969, lr = 5e-05
I0403 10:33:36.560292  8106 solver.cpp:228] Iteration 7982, loss = 0.0445959
I0403 10:33:36.560380  8106 solver.cpp:244]     Train net output #0: loss = 0.0445958 (* 1 = 0.0445958 loss)
I0403 10:33:36.739647  8106 sgd_solver.cpp:106] Iteration 7982, lr = 5e-05
I0403 10:33:46.129900  8106 solver.cpp:228] Iteration 7995, loss = 0.011194
I0403 10:33:46.130234  8106 solver.cpp:244]     Train net output #0: loss = 0.0111939 (* 1 = 0.0111939 loss)
I0403 10:33:46.328354  8106 sgd_solver.cpp:106] Iteration 7995, lr = 5e-05
I0403 10:33:55.614554  8106 solver.cpp:228] Iteration 8008, loss = 0.0257638
I0403 10:33:55.614653  8106 solver.cpp:244]     Train net output #0: loss = 0.0257637 (* 1 = 0.0257637 loss)
I0403 10:33:55.799001  8106 sgd_solver.cpp:106] Iteration 8008, lr = 5e-05
I0403 10:33:56.519821  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_8010.caffemodel
I0403 10:33:59.191237  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_8010.solverstate
I0403 10:34:01.036334  8106 solver.cpp:337] Iteration 8010, Testing net (#0)
I0403 10:35:03.097432  8106 solver.cpp:404]     Test net output #0: accuracy = 0.931927
I0403 10:35:03.097774  8106 solver.cpp:404]     Test net output #1: loss = 0.247624 (* 1 = 0.247624 loss)
I0403 10:35:11.583600  8106 solver.cpp:228] Iteration 8021, loss = 0.0211409
I0403 10:35:11.583701  8106 solver.cpp:244]     Train net output #0: loss = 0.0211409 (* 1 = 0.0211409 loss)
I0403 10:35:11.826046  8106 sgd_solver.cpp:106] Iteration 8021, lr = 5e-05
I0403 10:35:12.548444  8106 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_8023.caffemodel
I0403 10:35:15.268326  8106 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_grayscale-50-50_train_from_scratch/snapshots__iter_8023.solverstate
I0403 10:35:17.105186  8106 solver.cpp:322] Optimization Done.
I0403 10:35:17.190093  8106 caffe.cpp:222] Optimization Done.
