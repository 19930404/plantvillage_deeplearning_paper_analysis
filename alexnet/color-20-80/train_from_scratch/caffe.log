I0403 06:57:40.508292 10121 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 06:57:40.508764 10121 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 06:57:40.508792 10121 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 06:57:44.479022 10121 caffe.cpp:185] Using GPUs 0, 1
I0403 06:57:44.479475 10121 caffe.cpp:190] GPU 0: Tesla K40m
I0403 06:57:44.479862 10121 caffe.cpp:190] GPU 1: Tesla K40m
I0403 06:57:44.692378 10121 solver.cpp:48] Initializing solver from parameters: 
test_iter: 434
test_interval: 108
base_lr: 0.005
display: 5
max_iter: 3251
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1083
snapshot: 108
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 06:57:44.701323 10121 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 06:57:44.713770 10121 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 06:57:44.713901 10121 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 06:57:44.715622 10121 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-20-80/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 06:57:44.716591 10121 layer_factory.hpp:77] Creating layer data
I0403 06:57:44.718279 10121 net.cpp:91] Creating Layer data
I0403 06:57:44.718369 10121 net.cpp:399] data -> data
I0403 06:57:44.718492 10121 net.cpp:399] data -> label
I0403 06:57:44.718575 10121 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto
I0403 06:57:44.799485 10126 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-20-80/train_db
I0403 06:57:44.831882 10121 data_layer.cpp:41] output data size: 100,3,227,227
I0403 06:57:44.951155 10121 net.cpp:141] Setting up data
I0403 06:57:44.951243 10121 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 06:57:44.951267 10121 net.cpp:148] Top shape: 100 (100)
I0403 06:57:44.951283 10121 net.cpp:156] Memory required for data: 61835200
I0403 06:57:44.951313 10121 layer_factory.hpp:77] Creating layer conv1
I0403 06:57:44.951354 10121 net.cpp:91] Creating Layer conv1
I0403 06:57:44.951376 10121 net.cpp:425] conv1 <- data
I0403 06:57:44.951406 10121 net.cpp:399] conv1 -> conv1
I0403 06:57:44.954027 10121 net.cpp:141] Setting up conv1
I0403 06:57:44.954058 10121 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:57:44.954076 10121 net.cpp:156] Memory required for data: 177995200
I0403 06:57:44.954109 10121 layer_factory.hpp:77] Creating layer relu1
I0403 06:57:44.954136 10121 net.cpp:91] Creating Layer relu1
I0403 06:57:44.954156 10121 net.cpp:425] relu1 <- conv1
I0403 06:57:44.954174 10121 net.cpp:386] relu1 -> conv1 (in-place)
I0403 06:57:44.954197 10121 net.cpp:141] Setting up relu1
I0403 06:57:44.954216 10121 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:57:44.954231 10121 net.cpp:156] Memory required for data: 294155200
I0403 06:57:44.954253 10121 layer_factory.hpp:77] Creating layer norm1
I0403 06:57:44.954274 10121 net.cpp:91] Creating Layer norm1
I0403 06:57:44.954329 10121 net.cpp:425] norm1 <- conv1
I0403 06:57:44.954349 10121 net.cpp:399] norm1 -> norm1
I0403 06:57:44.959992 10121 net.cpp:141] Setting up norm1
I0403 06:57:44.960028 10121 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:57:44.960047 10121 net.cpp:156] Memory required for data: 410315200
I0403 06:57:44.960062 10121 layer_factory.hpp:77] Creating layer pool1
I0403 06:57:44.960084 10121 net.cpp:91] Creating Layer pool1
I0403 06:57:44.960100 10121 net.cpp:425] pool1 <- norm1
I0403 06:57:44.960119 10121 net.cpp:399] pool1 -> pool1
I0403 06:57:44.960180 10121 net.cpp:141] Setting up pool1
I0403 06:57:44.960206 10121 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 06:57:44.960222 10121 net.cpp:156] Memory required for data: 438308800
I0403 06:57:44.960249 10121 layer_factory.hpp:77] Creating layer conv2
I0403 06:57:44.960276 10121 net.cpp:91] Creating Layer conv2
I0403 06:57:44.960295 10121 net.cpp:425] conv2 <- pool1
I0403 06:57:44.960314 10121 net.cpp:399] conv2 -> conv2
I0403 06:57:44.961716 10127 blocking_queue.cpp:50] Waiting for data
I0403 06:57:44.972643 10121 net.cpp:141] Setting up conv2
I0403 06:57:44.972672 10121 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:57:44.972688 10121 net.cpp:156] Memory required for data: 512958400
I0403 06:57:44.972709 10121 layer_factory.hpp:77] Creating layer relu2
I0403 06:57:44.972729 10121 net.cpp:91] Creating Layer relu2
I0403 06:57:44.972745 10121 net.cpp:425] relu2 <- conv2
I0403 06:57:44.972764 10121 net.cpp:386] relu2 -> conv2 (in-place)
I0403 06:57:44.972784 10121 net.cpp:141] Setting up relu2
I0403 06:57:44.972800 10121 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:57:44.972815 10121 net.cpp:156] Memory required for data: 587608000
I0403 06:57:44.972829 10121 layer_factory.hpp:77] Creating layer norm2
I0403 06:57:44.972847 10121 net.cpp:91] Creating Layer norm2
I0403 06:57:44.972863 10121 net.cpp:425] norm2 <- conv2
I0403 06:57:44.972879 10121 net.cpp:399] norm2 -> norm2
I0403 06:57:44.972923 10121 net.cpp:141] Setting up norm2
I0403 06:57:44.972945 10121 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:57:44.972961 10121 net.cpp:156] Memory required for data: 662257600
I0403 06:57:44.972976 10121 layer_factory.hpp:77] Creating layer pool2
I0403 06:57:44.972995 10121 net.cpp:91] Creating Layer pool2
I0403 06:57:44.973011 10121 net.cpp:425] pool2 <- norm2
I0403 06:57:44.973027 10121 net.cpp:399] pool2 -> pool2
I0403 06:57:44.973070 10121 net.cpp:141] Setting up pool2
I0403 06:57:44.973093 10121 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:57:44.973107 10121 net.cpp:156] Memory required for data: 679563200
I0403 06:57:44.973120 10121 layer_factory.hpp:77] Creating layer conv3
I0403 06:57:44.973141 10121 net.cpp:91] Creating Layer conv3
I0403 06:57:44.973158 10121 net.cpp:425] conv3 <- pool2
I0403 06:57:44.973177 10121 net.cpp:399] conv3 -> conv3
I0403 06:57:45.005935 10121 net.cpp:141] Setting up conv3
I0403 06:57:45.005976 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:45.005991 10121 net.cpp:156] Memory required for data: 705521600
I0403 06:57:45.006011 10121 layer_factory.hpp:77] Creating layer relu3
I0403 06:57:45.006031 10121 net.cpp:91] Creating Layer relu3
I0403 06:57:45.006047 10121 net.cpp:425] relu3 <- conv3
I0403 06:57:45.006064 10121 net.cpp:386] relu3 -> conv3 (in-place)
I0403 06:57:45.006083 10121 net.cpp:141] Setting up relu3
I0403 06:57:45.006098 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:45.006111 10121 net.cpp:156] Memory required for data: 731480000
I0403 06:57:45.006125 10121 layer_factory.hpp:77] Creating layer conv4
I0403 06:57:45.006145 10121 net.cpp:91] Creating Layer conv4
I0403 06:57:45.006161 10121 net.cpp:425] conv4 <- conv3
I0403 06:57:45.006181 10121 net.cpp:399] conv4 -> conv4
I0403 06:57:45.030556 10121 net.cpp:141] Setting up conv4
I0403 06:57:45.030587 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:45.030603 10121 net.cpp:156] Memory required for data: 757438400
I0403 06:57:45.030638 10121 layer_factory.hpp:77] Creating layer relu4
I0403 06:57:45.030658 10121 net.cpp:91] Creating Layer relu4
I0403 06:57:45.030674 10121 net.cpp:425] relu4 <- conv4
I0403 06:57:45.030691 10121 net.cpp:386] relu4 -> conv4 (in-place)
I0403 06:57:45.030710 10121 net.cpp:141] Setting up relu4
I0403 06:57:45.030726 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:45.030740 10121 net.cpp:156] Memory required for data: 783396800
I0403 06:57:45.030753 10121 layer_factory.hpp:77] Creating layer conv5
I0403 06:57:45.030774 10121 net.cpp:91] Creating Layer conv5
I0403 06:57:45.030788 10121 net.cpp:425] conv5 <- conv4
I0403 06:57:45.030805 10121 net.cpp:399] conv5 -> conv5
I0403 06:57:45.047112 10121 net.cpp:141] Setting up conv5
I0403 06:57:45.047143 10121 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:57:45.047159 10121 net.cpp:156] Memory required for data: 800702400
I0403 06:57:45.047179 10121 layer_factory.hpp:77] Creating layer relu5
I0403 06:57:45.047199 10121 net.cpp:91] Creating Layer relu5
I0403 06:57:45.047214 10121 net.cpp:425] relu5 <- conv5
I0403 06:57:45.047233 10121 net.cpp:386] relu5 -> conv5 (in-place)
I0403 06:57:45.047258 10121 net.cpp:141] Setting up relu5
I0403 06:57:45.047276 10121 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:57:45.047291 10121 net.cpp:156] Memory required for data: 818008000
I0403 06:57:45.047304 10121 layer_factory.hpp:77] Creating layer pool5
I0403 06:57:45.047322 10121 net.cpp:91] Creating Layer pool5
I0403 06:57:45.047335 10121 net.cpp:425] pool5 <- conv5
I0403 06:57:45.047351 10121 net.cpp:399] pool5 -> pool5
I0403 06:57:45.047399 10121 net.cpp:141] Setting up pool5
I0403 06:57:45.047420 10121 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 06:57:45.047435 10121 net.cpp:156] Memory required for data: 821694400
I0403 06:57:45.047449 10121 layer_factory.hpp:77] Creating layer fc6
I0403 06:57:45.047473 10121 net.cpp:91] Creating Layer fc6
I0403 06:57:45.047490 10121 net.cpp:425] fc6 <- pool5
I0403 06:57:45.047508 10121 net.cpp:399] fc6 -> fc6
I0403 06:57:46.417713 10121 net.cpp:141] Setting up fc6
I0403 06:57:46.417794 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:46.417810 10121 net.cpp:156] Memory required for data: 823332800
I0403 06:57:46.417831 10121 layer_factory.hpp:77] Creating layer relu6
I0403 06:57:46.417856 10121 net.cpp:91] Creating Layer relu6
I0403 06:57:46.417873 10121 net.cpp:425] relu6 <- fc6
I0403 06:57:46.417894 10121 net.cpp:386] relu6 -> fc6 (in-place)
I0403 06:57:46.417917 10121 net.cpp:141] Setting up relu6
I0403 06:57:46.417934 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:46.417949 10121 net.cpp:156] Memory required for data: 824971200
I0403 06:57:46.417976 10121 layer_factory.hpp:77] Creating layer drop6
I0403 06:57:46.418001 10121 net.cpp:91] Creating Layer drop6
I0403 06:57:46.418018 10121 net.cpp:425] drop6 <- fc6
I0403 06:57:46.418035 10121 net.cpp:386] drop6 -> fc6 (in-place)
I0403 06:57:46.418083 10121 net.cpp:141] Setting up drop6
I0403 06:57:46.418107 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:46.418122 10121 net.cpp:156] Memory required for data: 826609600
I0403 06:57:46.418135 10121 layer_factory.hpp:77] Creating layer fc7
I0403 06:57:46.418156 10121 net.cpp:91] Creating Layer fc7
I0403 06:57:46.418172 10121 net.cpp:425] fc7 <- fc6
I0403 06:57:46.418191 10121 net.cpp:399] fc7 -> fc7
I0403 06:57:47.029121 10121 net.cpp:141] Setting up fc7
I0403 06:57:47.029201 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:47.029217 10121 net.cpp:156] Memory required for data: 828248000
I0403 06:57:47.029242 10121 layer_factory.hpp:77] Creating layer relu7
I0403 06:57:47.029273 10121 net.cpp:91] Creating Layer relu7
I0403 06:57:47.029289 10121 net.cpp:425] relu7 <- fc7
I0403 06:57:47.029311 10121 net.cpp:386] relu7 -> fc7 (in-place)
I0403 06:57:47.029333 10121 net.cpp:141] Setting up relu7
I0403 06:57:47.029350 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:47.029363 10121 net.cpp:156] Memory required for data: 829886400
I0403 06:57:47.029376 10121 layer_factory.hpp:77] Creating layer drop7
I0403 06:57:47.029434 10121 net.cpp:91] Creating Layer drop7
I0403 06:57:47.029451 10121 net.cpp:425] drop7 <- fc7
I0403 06:57:47.029471 10121 net.cpp:386] drop7 -> fc7 (in-place)
I0403 06:57:47.029510 10121 net.cpp:141] Setting up drop7
I0403 06:57:47.029531 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:47.029546 10121 net.cpp:156] Memory required for data: 831524800
I0403 06:57:47.029558 10121 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 06:57:47.029580 10121 net.cpp:91] Creating Layer fc8_plantvillage
I0403 06:57:47.029597 10121 net.cpp:425] fc8_plantvillage <- fc7
I0403 06:57:47.029618 10121 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 06:57:47.035661 10121 net.cpp:141] Setting up fc8_plantvillage
I0403 06:57:47.035689 10121 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:57:47.035704 10121 net.cpp:156] Memory required for data: 831540000
I0403 06:57:47.035722 10121 layer_factory.hpp:77] Creating layer loss
I0403 06:57:47.035744 10121 net.cpp:91] Creating Layer loss
I0403 06:57:47.035763 10121 net.cpp:425] loss <- fc8_plantvillage
I0403 06:57:47.035778 10121 net.cpp:425] loss <- label
I0403 06:57:47.035799 10121 net.cpp:399] loss -> loss
I0403 06:57:47.035826 10121 layer_factory.hpp:77] Creating layer loss
I0403 06:57:47.035924 10121 net.cpp:141] Setting up loss
I0403 06:57:47.035948 10121 net.cpp:148] Top shape: (1)
I0403 06:57:47.035962 10121 net.cpp:151]     with loss weight 1
I0403 06:57:47.036015 10121 net.cpp:156] Memory required for data: 831540004
I0403 06:57:47.036029 10121 net.cpp:217] loss needs backward computation.
I0403 06:57:47.036043 10121 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 06:57:47.036057 10121 net.cpp:217] drop7 needs backward computation.
I0403 06:57:47.036070 10121 net.cpp:217] relu7 needs backward computation.
I0403 06:57:47.036082 10121 net.cpp:217] fc7 needs backward computation.
I0403 06:57:47.036097 10121 net.cpp:217] drop6 needs backward computation.
I0403 06:57:47.036109 10121 net.cpp:217] relu6 needs backward computation.
I0403 06:57:47.036123 10121 net.cpp:217] fc6 needs backward computation.
I0403 06:57:47.036136 10121 net.cpp:217] pool5 needs backward computation.
I0403 06:57:47.036150 10121 net.cpp:217] relu5 needs backward computation.
I0403 06:57:47.036164 10121 net.cpp:217] conv5 needs backward computation.
I0403 06:57:47.036177 10121 net.cpp:217] relu4 needs backward computation.
I0403 06:57:47.036190 10121 net.cpp:217] conv4 needs backward computation.
I0403 06:57:47.036203 10121 net.cpp:217] relu3 needs backward computation.
I0403 06:57:47.036217 10121 net.cpp:217] conv3 needs backward computation.
I0403 06:57:47.036231 10121 net.cpp:217] pool2 needs backward computation.
I0403 06:57:47.036252 10121 net.cpp:217] norm2 needs backward computation.
I0403 06:57:47.036265 10121 net.cpp:217] relu2 needs backward computation.
I0403 06:57:47.036279 10121 net.cpp:217] conv2 needs backward computation.
I0403 06:57:47.036293 10121 net.cpp:217] pool1 needs backward computation.
I0403 06:57:47.036306 10121 net.cpp:217] norm1 needs backward computation.
I0403 06:57:47.036319 10121 net.cpp:217] relu1 needs backward computation.
I0403 06:57:47.036332 10121 net.cpp:217] conv1 needs backward computation.
I0403 06:57:47.036346 10121 net.cpp:219] data does not need backward computation.
I0403 06:57:47.036360 10121 net.cpp:261] This network produces output loss
I0403 06:57:47.036386 10121 net.cpp:274] Network initialization done.
I0403 06:57:47.037469 10121 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 06:57:47.037526 10121 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 06:57:47.038154 10121 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/color-20-80/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 06:57:47.038319 10121 layer_factory.hpp:77] Creating layer data
I0403 06:57:47.038488 10121 net.cpp:91] Creating Layer data
I0403 06:57:47.038516 10121 net.cpp:399] data -> data
I0403 06:57:47.038539 10121 net.cpp:399] data -> label
I0403 06:57:47.038566 10121 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/color-20-80/mean.binaryproto
I0403 06:57:47.090117 10128 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/color-20-80/test_db
I0403 06:57:47.141273 10121 data_layer.cpp:41] output data size: 100,3,227,227
I0403 06:57:47.293226 10121 net.cpp:141] Setting up data
I0403 06:57:47.293297 10121 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 06:57:47.293324 10121 net.cpp:148] Top shape: 100 (100)
I0403 06:57:47.293341 10121 net.cpp:156] Memory required for data: 61835200
I0403 06:57:47.293359 10121 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 06:57:47.293395 10121 net.cpp:91] Creating Layer label_data_1_split
I0403 06:57:47.293417 10121 net.cpp:425] label_data_1_split <- label
I0403 06:57:47.293447 10121 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 06:57:47.293479 10121 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 06:57:47.293540 10121 net.cpp:141] Setting up label_data_1_split
I0403 06:57:47.293568 10121 net.cpp:148] Top shape: 100 (100)
I0403 06:57:47.293587 10121 net.cpp:148] Top shape: 100 (100)
I0403 06:57:47.293606 10121 net.cpp:156] Memory required for data: 61836000
I0403 06:57:47.293627 10121 layer_factory.hpp:77] Creating layer conv1
I0403 06:57:47.293659 10121 net.cpp:91] Creating Layer conv1
I0403 06:57:47.293684 10121 net.cpp:425] conv1 <- data
I0403 06:57:47.293705 10121 net.cpp:399] conv1 -> conv1
I0403 06:57:47.295333 10121 net.cpp:141] Setting up conv1
I0403 06:57:47.295411 10121 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:57:47.295472 10121 net.cpp:156] Memory required for data: 177996000
I0403 06:57:47.295497 10121 layer_factory.hpp:77] Creating layer relu1
I0403 06:57:47.295519 10121 net.cpp:91] Creating Layer relu1
I0403 06:57:47.295536 10121 net.cpp:425] relu1 <- conv1
I0403 06:57:47.295554 10121 net.cpp:386] relu1 -> conv1 (in-place)
I0403 06:57:47.295574 10121 net.cpp:141] Setting up relu1
I0403 06:57:47.295593 10121 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:57:47.295619 10121 net.cpp:156] Memory required for data: 294156000
I0403 06:57:47.295634 10121 layer_factory.hpp:77] Creating layer norm1
I0403 06:57:47.295653 10121 net.cpp:91] Creating Layer norm1
I0403 06:57:47.295670 10121 net.cpp:425] norm1 <- conv1
I0403 06:57:47.295687 10121 net.cpp:399] norm1 -> norm1
I0403 06:57:47.295737 10121 net.cpp:141] Setting up norm1
I0403 06:57:47.295758 10121 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 06:57:47.295773 10121 net.cpp:156] Memory required for data: 410316000
I0403 06:57:47.295788 10121 layer_factory.hpp:77] Creating layer pool1
I0403 06:57:47.295806 10121 net.cpp:91] Creating Layer pool1
I0403 06:57:47.295822 10121 net.cpp:425] pool1 <- norm1
I0403 06:57:47.295840 10121 net.cpp:399] pool1 -> pool1
I0403 06:57:47.295887 10121 net.cpp:141] Setting up pool1
I0403 06:57:47.295910 10121 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 06:57:47.295924 10121 net.cpp:156] Memory required for data: 438309600
I0403 06:57:47.295966 10121 layer_factory.hpp:77] Creating layer conv2
I0403 06:57:47.295990 10121 net.cpp:91] Creating Layer conv2
I0403 06:57:47.296007 10121 net.cpp:425] conv2 <- pool1
I0403 06:57:47.296027 10121 net.cpp:399] conv2 -> conv2
I0403 06:57:47.308001 10121 net.cpp:141] Setting up conv2
I0403 06:57:47.308033 10121 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:57:47.308050 10121 net.cpp:156] Memory required for data: 512959200
I0403 06:57:47.308071 10121 layer_factory.hpp:77] Creating layer relu2
I0403 06:57:47.308091 10121 net.cpp:91] Creating Layer relu2
I0403 06:57:47.308107 10121 net.cpp:425] relu2 <- conv2
I0403 06:57:47.308125 10121 net.cpp:386] relu2 -> conv2 (in-place)
I0403 06:57:47.308143 10121 net.cpp:141] Setting up relu2
I0403 06:57:47.308161 10121 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:57:47.308176 10121 net.cpp:156] Memory required for data: 587608800
I0403 06:57:47.308188 10121 layer_factory.hpp:77] Creating layer norm2
I0403 06:57:47.308246 10121 net.cpp:91] Creating Layer norm2
I0403 06:57:47.308719 10121 net.cpp:425] norm2 <- conv2
I0403 06:57:47.329054 10121 net.cpp:399] norm2 -> norm2
I0403 06:57:47.329126 10121 net.cpp:141] Setting up norm2
I0403 06:57:47.329152 10121 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 06:57:47.329169 10121 net.cpp:156] Memory required for data: 662258400
I0403 06:57:47.329185 10121 layer_factory.hpp:77] Creating layer pool2
I0403 06:57:47.330072 10121 net.cpp:91] Creating Layer pool2
I0403 06:57:47.330097 10121 net.cpp:425] pool2 <- norm2
I0403 06:57:47.330116 10121 net.cpp:399] pool2 -> pool2
I0403 06:57:47.330168 10121 net.cpp:141] Setting up pool2
I0403 06:57:47.330191 10121 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:57:47.330210 10121 net.cpp:156] Memory required for data: 679564000
I0403 06:57:47.330227 10121 layer_factory.hpp:77] Creating layer conv3
I0403 06:57:47.330250 10121 net.cpp:91] Creating Layer conv3
I0403 06:57:47.330268 10121 net.cpp:425] conv3 <- pool2
I0403 06:57:47.330287 10121 net.cpp:399] conv3 -> conv3
I0403 06:57:47.367202 10121 net.cpp:141] Setting up conv3
I0403 06:57:47.367250 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:47.367269 10121 net.cpp:156] Memory required for data: 705522400
I0403 06:57:47.369125 10121 layer_factory.hpp:77] Creating layer relu3
I0403 06:57:47.370982 10121 net.cpp:91] Creating Layer relu3
I0403 06:57:47.371009 10121 net.cpp:425] relu3 <- conv3
I0403 06:57:47.371031 10121 net.cpp:386] relu3 -> conv3 (in-place)
I0403 06:57:47.371052 10121 net.cpp:141] Setting up relu3
I0403 06:57:47.371070 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:47.371084 10121 net.cpp:156] Memory required for data: 731480800
I0403 06:57:47.371099 10121 layer_factory.hpp:77] Creating layer conv4
I0403 06:57:47.371124 10121 net.cpp:91] Creating Layer conv4
I0403 06:57:47.371140 10121 net.cpp:425] conv4 <- conv3
I0403 06:57:47.371158 10121 net.cpp:399] conv4 -> conv4
I0403 06:57:47.396744 10121 net.cpp:141] Setting up conv4
I0403 06:57:47.396780 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:47.396796 10121 net.cpp:156] Memory required for data: 757439200
I0403 06:57:47.396814 10121 layer_factory.hpp:77] Creating layer relu4
I0403 06:57:47.396836 10121 net.cpp:91] Creating Layer relu4
I0403 06:57:47.396852 10121 net.cpp:425] relu4 <- conv4
I0403 06:57:47.396870 10121 net.cpp:386] relu4 -> conv4 (in-place)
I0403 06:57:47.396890 10121 net.cpp:141] Setting up relu4
I0403 06:57:47.396908 10121 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 06:57:47.396921 10121 net.cpp:156] Memory required for data: 783397600
I0403 06:57:47.396935 10121 layer_factory.hpp:77] Creating layer conv5
I0403 06:57:47.396958 10121 net.cpp:91] Creating Layer conv5
I0403 06:57:47.396975 10121 net.cpp:425] conv5 <- conv4
I0403 06:57:47.396994 10121 net.cpp:399] conv5 -> conv5
I0403 06:57:47.414618 10121 net.cpp:141] Setting up conv5
I0403 06:57:47.414652 10121 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:57:47.414669 10121 net.cpp:156] Memory required for data: 800703200
I0403 06:57:47.414732 10121 layer_factory.hpp:77] Creating layer relu5
I0403 06:57:47.414758 10121 net.cpp:91] Creating Layer relu5
I0403 06:57:47.414778 10121 net.cpp:425] relu5 <- conv5
I0403 06:57:47.414798 10121 net.cpp:386] relu5 -> conv5 (in-place)
I0403 06:57:47.414818 10121 net.cpp:141] Setting up relu5
I0403 06:57:47.414835 10121 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 06:57:47.414849 10121 net.cpp:156] Memory required for data: 818008800
I0403 06:57:47.414865 10121 layer_factory.hpp:77] Creating layer pool5
I0403 06:57:47.414887 10121 net.cpp:91] Creating Layer pool5
I0403 06:57:47.414904 10121 net.cpp:425] pool5 <- conv5
I0403 06:57:47.414922 10121 net.cpp:399] pool5 -> pool5
I0403 06:57:47.414976 10121 net.cpp:141] Setting up pool5
I0403 06:57:47.415001 10121 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 06:57:47.415016 10121 net.cpp:156] Memory required for data: 821695200
I0403 06:57:47.415032 10121 layer_factory.hpp:77] Creating layer fc6
I0403 06:57:47.415053 10121 net.cpp:91] Creating Layer fc6
I0403 06:57:47.415071 10121 net.cpp:425] fc6 <- pool5
I0403 06:57:47.415092 10121 net.cpp:399] fc6 -> fc6
I0403 06:57:48.800817 10121 net.cpp:141] Setting up fc6
I0403 06:57:48.800900 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:48.800917 10121 net.cpp:156] Memory required for data: 823333600
I0403 06:57:48.800940 10121 layer_factory.hpp:77] Creating layer relu6
I0403 06:57:48.800963 10121 net.cpp:91] Creating Layer relu6
I0403 06:57:48.800981 10121 net.cpp:425] relu6 <- fc6
I0403 06:57:48.801004 10121 net.cpp:386] relu6 -> fc6 (in-place)
I0403 06:57:48.801028 10121 net.cpp:141] Setting up relu6
I0403 06:57:48.801043 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:48.801057 10121 net.cpp:156] Memory required for data: 824972000
I0403 06:57:48.801070 10121 layer_factory.hpp:77] Creating layer drop6
I0403 06:57:48.801090 10121 net.cpp:91] Creating Layer drop6
I0403 06:57:48.801105 10121 net.cpp:425] drop6 <- fc6
I0403 06:57:48.801121 10121 net.cpp:386] drop6 -> fc6 (in-place)
I0403 06:57:48.801162 10121 net.cpp:141] Setting up drop6
I0403 06:57:48.801183 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:48.801198 10121 net.cpp:156] Memory required for data: 826610400
I0403 06:57:48.801218 10121 layer_factory.hpp:77] Creating layer fc7
I0403 06:57:48.801239 10121 net.cpp:91] Creating Layer fc7
I0403 06:57:48.801256 10121 net.cpp:425] fc7 <- fc6
I0403 06:57:48.801273 10121 net.cpp:399] fc7 -> fc7
I0403 06:57:49.401520 10121 net.cpp:141] Setting up fc7
I0403 06:57:49.401598 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:49.401614 10121 net.cpp:156] Memory required for data: 828248800
I0403 06:57:49.401635 10121 layer_factory.hpp:77] Creating layer relu7
I0403 06:57:49.401659 10121 net.cpp:91] Creating Layer relu7
I0403 06:57:49.401676 10121 net.cpp:425] relu7 <- fc7
I0403 06:57:49.401698 10121 net.cpp:386] relu7 -> fc7 (in-place)
I0403 06:57:49.401721 10121 net.cpp:141] Setting up relu7
I0403 06:57:49.401738 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:49.401752 10121 net.cpp:156] Memory required for data: 829887200
I0403 06:57:49.401767 10121 layer_factory.hpp:77] Creating layer drop7
I0403 06:57:49.401784 10121 net.cpp:91] Creating Layer drop7
I0403 06:57:49.401799 10121 net.cpp:425] drop7 <- fc7
I0403 06:57:49.401818 10121 net.cpp:386] drop7 -> fc7 (in-place)
I0403 06:57:49.401859 10121 net.cpp:141] Setting up drop7
I0403 06:57:49.401880 10121 net.cpp:148] Top shape: 100 4096 (409600)
I0403 06:57:49.401895 10121 net.cpp:156] Memory required for data: 831525600
I0403 06:57:49.401909 10121 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 06:57:49.401932 10121 net.cpp:91] Creating Layer fc8_plantvillage
I0403 06:57:49.401949 10121 net.cpp:425] fc8_plantvillage <- fc7
I0403 06:57:49.401969 10121 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 06:57:49.407984 10121 net.cpp:141] Setting up fc8_plantvillage
I0403 06:57:49.408012 10121 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:57:49.408067 10121 net.cpp:156] Memory required for data: 831540800
I0403 06:57:49.408087 10121 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 06:57:49.408105 10121 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 06:57:49.408121 10121 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 06:57:49.408140 10121 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 06:57:49.408162 10121 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 06:57:49.408220 10121 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 06:57:49.408246 10121 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:57:49.408262 10121 net.cpp:148] Top shape: 100 38 (3800)
I0403 06:57:49.408277 10121 net.cpp:156] Memory required for data: 831571200
I0403 06:57:49.408290 10121 layer_factory.hpp:77] Creating layer loss
I0403 06:57:49.408308 10121 net.cpp:91] Creating Layer loss
I0403 06:57:49.408324 10121 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 06:57:49.408340 10121 net.cpp:425] loss <- label_data_1_split_0
I0403 06:57:49.408357 10121 net.cpp:399] loss -> loss
I0403 06:57:49.408380 10121 layer_factory.hpp:77] Creating layer loss
I0403 06:57:49.408469 10121 net.cpp:141] Setting up loss
I0403 06:57:49.408493 10121 net.cpp:148] Top shape: (1)
I0403 06:57:49.408507 10121 net.cpp:151]     with loss weight 1
I0403 06:57:49.408529 10121 net.cpp:156] Memory required for data: 831571204
I0403 06:57:49.408545 10121 layer_factory.hpp:77] Creating layer accuracy
I0403 06:57:49.408561 10121 net.cpp:91] Creating Layer accuracy
I0403 06:57:49.408577 10121 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 06:57:49.408592 10121 net.cpp:425] accuracy <- label_data_1_split_1
I0403 06:57:49.408613 10121 net.cpp:399] accuracy -> accuracy
I0403 06:57:49.408643 10121 net.cpp:141] Setting up accuracy
I0403 06:57:49.408663 10121 net.cpp:148] Top shape: (1)
I0403 06:57:49.408676 10121 net.cpp:156] Memory required for data: 831571208
I0403 06:57:49.408690 10121 net.cpp:219] accuracy does not need backward computation.
I0403 06:57:49.408705 10121 net.cpp:217] loss needs backward computation.
I0403 06:57:49.408720 10121 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 06:57:49.408732 10121 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 06:57:49.408747 10121 net.cpp:217] drop7 needs backward computation.
I0403 06:57:49.408761 10121 net.cpp:217] relu7 needs backward computation.
I0403 06:57:49.408773 10121 net.cpp:217] fc7 needs backward computation.
I0403 06:57:49.408787 10121 net.cpp:217] drop6 needs backward computation.
I0403 06:57:49.408802 10121 net.cpp:217] relu6 needs backward computation.
I0403 06:57:49.408814 10121 net.cpp:217] fc6 needs backward computation.
I0403 06:57:49.408828 10121 net.cpp:217] pool5 needs backward computation.
I0403 06:57:49.408843 10121 net.cpp:217] relu5 needs backward computation.
I0403 06:57:49.408856 10121 net.cpp:217] conv5 needs backward computation.
I0403 06:57:49.408869 10121 net.cpp:217] relu4 needs backward computation.
I0403 06:57:49.408882 10121 net.cpp:217] conv4 needs backward computation.
I0403 06:57:49.408897 10121 net.cpp:217] relu3 needs backward computation.
I0403 06:57:49.408911 10121 net.cpp:217] conv3 needs backward computation.
I0403 06:57:49.408924 10121 net.cpp:217] pool2 needs backward computation.
I0403 06:57:49.408937 10121 net.cpp:217] norm2 needs backward computation.
I0403 06:57:49.408951 10121 net.cpp:217] relu2 needs backward computation.
I0403 06:57:49.408967 10121 net.cpp:217] conv2 needs backward computation.
I0403 06:57:49.408980 10121 net.cpp:217] pool1 needs backward computation.
I0403 06:57:49.408994 10121 net.cpp:217] norm1 needs backward computation.
I0403 06:57:49.409008 10121 net.cpp:217] relu1 needs backward computation.
I0403 06:57:49.409020 10121 net.cpp:217] conv1 needs backward computation.
I0403 06:57:49.409050 10121 net.cpp:219] label_data_1_split does not need backward computation.
I0403 06:57:49.409066 10121 net.cpp:219] data does not need backward computation.
I0403 06:57:49.409080 10121 net.cpp:261] This network produces output accuracy
I0403 06:57:49.409095 10121 net.cpp:261] This network produces output loss
I0403 06:57:49.409123 10121 net.cpp:274] Network initialization done.
I0403 06:57:49.409227 10121 solver.cpp:60] Solver scaffolding done.
I0403 06:57:49.432818 10121 parallel.cpp:392] GPUs pairs 0:1
I0403 06:57:49.639755 10121 data_layer.cpp:41] output data size: 100,3,227,227
I0403 06:57:52.076876 10121 parallel.cpp:425] Starting Optimization
I0403 06:57:52.077033 10121 solver.cpp:279] Solving 
I0403 06:57:52.077057 10121 solver.cpp:280] Learning Rate Policy: step
I0403 06:57:52.077250 10121 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 06:59:30.031764 10121 solver.cpp:404]     Test net output #0: accuracy = 0.0214747
I0403 06:59:30.033215 10121 solver.cpp:404]     Test net output #1: loss = 3.6532 (* 1 = 3.6532 loss)
I0403 06:59:30.612246 10121 solver.cpp:228] Iteration 0, loss = 3.66896
I0403 06:59:30.612308 10121 solver.cpp:244]     Train net output #0: loss = 3.66896 (* 1 = 3.66896 loss)
I0403 06:59:30.772546 10121 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 06:59:34.247062 10121 solver.cpp:228] Iteration 5, loss = 3.53243
I0403 06:59:34.247133 10121 solver.cpp:244]     Train net output #0: loss = 3.53243 (* 1 = 3.53243 loss)
I0403 06:59:34.448276 10121 sgd_solver.cpp:106] Iteration 5, lr = 0.005
I0403 06:59:37.873086 10121 solver.cpp:228] Iteration 10, loss = 3.35555
I0403 06:59:37.873158 10121 solver.cpp:244]     Train net output #0: loss = 3.35555 (* 1 = 3.35555 loss)
I0403 06:59:38.057512 10121 sgd_solver.cpp:106] Iteration 10, lr = 0.005
I0403 06:59:41.536011 10121 solver.cpp:228] Iteration 15, loss = 3.40652
I0403 06:59:41.536078 10121 solver.cpp:244]     Train net output #0: loss = 3.40652 (* 1 = 3.40652 loss)
I0403 06:59:41.688551 10121 sgd_solver.cpp:106] Iteration 15, lr = 0.005
I0403 06:59:45.229434 10121 solver.cpp:228] Iteration 20, loss = 3.29263
I0403 06:59:45.229564 10121 solver.cpp:244]     Train net output #0: loss = 3.29263 (* 1 = 3.29263 loss)
I0403 06:59:45.409363 10121 sgd_solver.cpp:106] Iteration 20, lr = 0.005
I0403 06:59:48.801970 10121 solver.cpp:228] Iteration 25, loss = 3.2768
I0403 06:59:48.802042 10121 solver.cpp:244]     Train net output #0: loss = 3.2768 (* 1 = 3.2768 loss)
I0403 06:59:48.986271 10121 sgd_solver.cpp:106] Iteration 25, lr = 0.005
I0403 06:59:52.419868 10121 solver.cpp:228] Iteration 30, loss = 3.22588
I0403 06:59:52.419934 10121 solver.cpp:244]     Train net output #0: loss = 3.22588 (* 1 = 3.22588 loss)
I0403 06:59:52.594671 10121 sgd_solver.cpp:106] Iteration 30, lr = 0.005
I0403 06:59:56.038625 10121 solver.cpp:228] Iteration 35, loss = 3.30439
I0403 06:59:56.038691 10121 solver.cpp:244]     Train net output #0: loss = 3.30439 (* 1 = 3.30439 loss)
I0403 06:59:56.220017 10121 sgd_solver.cpp:106] Iteration 35, lr = 0.005
I0403 06:59:59.612170 10121 solver.cpp:228] Iteration 40, loss = 3.0513
I0403 06:59:59.612251 10121 solver.cpp:244]     Train net output #0: loss = 3.0513 (* 1 = 3.0513 loss)
I0403 06:59:59.808676 10121 sgd_solver.cpp:106] Iteration 40, lr = 0.005
I0403 07:00:03.186900 10121 solver.cpp:228] Iteration 45, loss = 3.21705
I0403 07:00:03.187160 10121 solver.cpp:244]     Train net output #0: loss = 3.21705 (* 1 = 3.21705 loss)
I0403 07:00:03.368540 10121 sgd_solver.cpp:106] Iteration 45, lr = 0.005
I0403 07:00:06.793328 10121 solver.cpp:228] Iteration 50, loss = 2.93655
I0403 07:00:06.793413 10121 solver.cpp:244]     Train net output #0: loss = 2.93655 (* 1 = 2.93655 loss)
I0403 07:00:06.975214 10121 sgd_solver.cpp:106] Iteration 50, lr = 0.005
I0403 07:00:10.490329 10121 solver.cpp:228] Iteration 55, loss = 2.8325
I0403 07:00:10.490413 10121 solver.cpp:244]     Train net output #0: loss = 2.8325 (* 1 = 2.8325 loss)
I0403 07:00:10.643081 10121 sgd_solver.cpp:106] Iteration 55, lr = 0.005
I0403 07:00:14.132066 10121 solver.cpp:228] Iteration 60, loss = 2.81002
I0403 07:00:14.132158 10121 solver.cpp:244]     Train net output #0: loss = 2.81002 (* 1 = 2.81002 loss)
I0403 07:00:14.325666 10121 sgd_solver.cpp:106] Iteration 60, lr = 0.005
I0403 07:00:17.744776 10121 solver.cpp:228] Iteration 65, loss = 2.8928
I0403 07:00:17.744869 10121 solver.cpp:244]     Train net output #0: loss = 2.8928 (* 1 = 2.8928 loss)
I0403 07:00:17.928287 10121 sgd_solver.cpp:106] Iteration 65, lr = 0.005
I0403 07:00:21.394587 10121 solver.cpp:228] Iteration 70, loss = 2.72391
I0403 07:00:21.394680 10121 solver.cpp:244]     Train net output #0: loss = 2.72391 (* 1 = 2.72391 loss)
I0403 07:00:21.602552 10121 sgd_solver.cpp:106] Iteration 70, lr = 0.005
I0403 07:00:25.013828 10121 solver.cpp:228] Iteration 75, loss = 2.79288
I0403 07:00:25.013922 10121 solver.cpp:244]     Train net output #0: loss = 2.79288 (* 1 = 2.79288 loss)
I0403 07:00:25.207290 10121 sgd_solver.cpp:106] Iteration 75, lr = 0.005
I0403 07:00:28.697862 10121 solver.cpp:228] Iteration 80, loss = 2.51668
I0403 07:00:28.697947 10121 solver.cpp:244]     Train net output #0: loss = 2.51668 (* 1 = 2.51668 loss)
I0403 07:00:28.877053 10121 sgd_solver.cpp:106] Iteration 80, lr = 0.005
I0403 07:00:32.363911 10121 solver.cpp:228] Iteration 85, loss = 2.51647
I0403 07:00:32.364001 10121 solver.cpp:244]     Train net output #0: loss = 2.51647 (* 1 = 2.51647 loss)
I0403 07:00:32.593119 10121 sgd_solver.cpp:106] Iteration 85, lr = 0.005
I0403 07:00:36.015924 10121 solver.cpp:228] Iteration 90, loss = 2.88061
I0403 07:00:36.016240 10121 solver.cpp:244]     Train net output #0: loss = 2.88061 (* 1 = 2.88061 loss)
I0403 07:00:36.187065 10121 sgd_solver.cpp:106] Iteration 90, lr = 0.005
I0403 07:00:39.701416 10121 solver.cpp:228] Iteration 95, loss = 2.36099
I0403 07:00:39.701498 10121 solver.cpp:244]     Train net output #0: loss = 2.36099 (* 1 = 2.36099 loss)
I0403 07:00:39.860818 10121 sgd_solver.cpp:106] Iteration 95, lr = 0.005
I0403 07:00:43.358814 10121 solver.cpp:228] Iteration 100, loss = 2.62337
I0403 07:00:43.358906 10121 solver.cpp:244]     Train net output #0: loss = 2.62337 (* 1 = 2.62337 loss)
I0403 07:00:43.550508 10121 sgd_solver.cpp:106] Iteration 100, lr = 0.005
I0403 07:00:47.002218 10121 solver.cpp:228] Iteration 105, loss = 2.51345
I0403 07:00:47.002315 10121 solver.cpp:244]     Train net output #0: loss = 2.51345 (* 1 = 2.51345 loss)
I0403 07:00:47.209167 10121 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 07:00:48.647591 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_108.caffemodel
I0403 07:00:51.512416 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_108.solverstate
I0403 07:00:53.432142 10121 solver.cpp:337] Iteration 108, Testing net (#0)
I0403 07:02:31.316691 10121 solver.cpp:404]     Test net output #0: accuracy = 0.313894
I0403 07:02:31.317008 10121 solver.cpp:404]     Test net output #1: loss = 2.60805 (* 1 = 2.60805 loss)
I0403 07:02:33.285598 10121 solver.cpp:228] Iteration 110, loss = 2.69655
I0403 07:02:33.285691 10121 solver.cpp:244]     Train net output #0: loss = 2.69655 (* 1 = 2.69655 loss)
I0403 07:02:33.478188 10121 sgd_solver.cpp:106] Iteration 110, lr = 0.005
I0403 07:02:36.972718 10121 solver.cpp:228] Iteration 115, loss = 2.2775
I0403 07:02:36.972805 10121 solver.cpp:244]     Train net output #0: loss = 2.2775 (* 1 = 2.2775 loss)
I0403 07:02:37.146010 10121 sgd_solver.cpp:106] Iteration 115, lr = 0.005
I0403 07:02:40.707324 10121 solver.cpp:228] Iteration 120, loss = 2.21104
I0403 07:02:40.707422 10121 solver.cpp:244]     Train net output #0: loss = 2.21104 (* 1 = 2.21104 loss)
I0403 07:02:40.895494 10121 sgd_solver.cpp:106] Iteration 120, lr = 0.005
I0403 07:02:44.377346 10121 solver.cpp:228] Iteration 125, loss = 2.15221
I0403 07:02:44.378363 10121 solver.cpp:244]     Train net output #0: loss = 2.15221 (* 1 = 2.15221 loss)
I0403 07:02:44.594764 10121 sgd_solver.cpp:106] Iteration 125, lr = 0.005
I0403 07:02:48.028694 10121 solver.cpp:228] Iteration 130, loss = 2.15728
I0403 07:02:48.028784 10121 solver.cpp:244]     Train net output #0: loss = 2.15728 (* 1 = 2.15728 loss)
I0403 07:02:48.212674 10121 sgd_solver.cpp:106] Iteration 130, lr = 0.005
I0403 07:02:51.699885 10121 solver.cpp:228] Iteration 135, loss = 1.98263
I0403 07:02:51.699990 10121 solver.cpp:244]     Train net output #0: loss = 1.98263 (* 1 = 1.98263 loss)
I0403 07:02:51.906543 10121 sgd_solver.cpp:106] Iteration 135, lr = 0.005
I0403 07:02:55.370476 10121 solver.cpp:228] Iteration 140, loss = 2.18553
I0403 07:02:55.370566 10121 solver.cpp:244]     Train net output #0: loss = 2.18553 (* 1 = 2.18553 loss)
I0403 07:02:55.560591 10121 sgd_solver.cpp:106] Iteration 140, lr = 0.005
I0403 07:02:58.973645 10121 solver.cpp:228] Iteration 145, loss = 2.30824
I0403 07:02:58.973739 10121 solver.cpp:244]     Train net output #0: loss = 2.30824 (* 1 = 2.30824 loss)
I0403 07:02:59.179034 10121 sgd_solver.cpp:106] Iteration 145, lr = 0.005
I0403 07:03:02.607791 10121 solver.cpp:228] Iteration 150, loss = 2.01386
I0403 07:03:02.608137 10121 solver.cpp:244]     Train net output #0: loss = 2.01386 (* 1 = 2.01386 loss)
I0403 07:03:02.789495 10121 sgd_solver.cpp:106] Iteration 150, lr = 0.005
I0403 07:03:06.224279 10121 solver.cpp:228] Iteration 155, loss = 1.91907
I0403 07:03:06.224370 10121 solver.cpp:244]     Train net output #0: loss = 1.91907 (* 1 = 1.91907 loss)
I0403 07:03:06.395079 10121 sgd_solver.cpp:106] Iteration 155, lr = 0.005
I0403 07:03:10.010885 10121 solver.cpp:228] Iteration 160, loss = 1.98407
I0403 07:03:10.010970 10121 solver.cpp:244]     Train net output #0: loss = 1.98407 (* 1 = 1.98407 loss)
I0403 07:03:10.115236 10121 sgd_solver.cpp:106] Iteration 160, lr = 0.005
I0403 07:03:13.790618 10121 solver.cpp:228] Iteration 165, loss = 1.72937
I0403 07:03:13.790704 10121 solver.cpp:244]     Train net output #0: loss = 1.72937 (* 1 = 1.72937 loss)
I0403 07:03:13.894922 10121 sgd_solver.cpp:106] Iteration 165, lr = 0.005
I0403 07:03:17.446604 10121 solver.cpp:228] Iteration 170, loss = 1.50278
I0403 07:03:17.446697 10121 solver.cpp:244]     Train net output #0: loss = 1.50278 (* 1 = 1.50278 loss)
I0403 07:03:17.635890 10121 sgd_solver.cpp:106] Iteration 170, lr = 0.005
I0403 07:03:21.073801 10121 solver.cpp:228] Iteration 175, loss = 1.6366
I0403 07:03:21.073895 10121 solver.cpp:244]     Train net output #0: loss = 1.6366 (* 1 = 1.6366 loss)
I0403 07:03:21.262084 10121 sgd_solver.cpp:106] Iteration 175, lr = 0.005
I0403 07:03:24.746235 10121 solver.cpp:228] Iteration 180, loss = 1.70738
I0403 07:03:24.746345 10121 solver.cpp:244]     Train net output #0: loss = 1.70738 (* 1 = 1.70738 loss)
I0403 07:03:24.947175 10121 sgd_solver.cpp:106] Iteration 180, lr = 0.005
I0403 07:03:28.400774 10121 solver.cpp:228] Iteration 185, loss = 1.38187
I0403 07:03:28.400871 10121 solver.cpp:244]     Train net output #0: loss = 1.38187 (* 1 = 1.38187 loss)
I0403 07:03:28.624483 10121 sgd_solver.cpp:106] Iteration 185, lr = 0.005
I0403 07:03:32.139148 10121 solver.cpp:228] Iteration 190, loss = 1.46017
I0403 07:03:32.139251 10121 solver.cpp:244]     Train net output #0: loss = 1.46017 (* 1 = 1.46017 loss)
I0403 07:03:32.368131 10121 sgd_solver.cpp:106] Iteration 190, lr = 0.005
I0403 07:03:35.818032 10121 solver.cpp:228] Iteration 195, loss = 1.51133
I0403 07:03:35.818325 10121 solver.cpp:244]     Train net output #0: loss = 1.51133 (* 1 = 1.51133 loss)
I0403 07:03:36.007678 10121 sgd_solver.cpp:106] Iteration 195, lr = 0.005
I0403 07:03:39.398221 10121 solver.cpp:228] Iteration 200, loss = 1.23958
I0403 07:03:39.398313 10121 solver.cpp:244]     Train net output #0: loss = 1.23958 (* 1 = 1.23958 loss)
I0403 07:03:39.597340 10121 sgd_solver.cpp:106] Iteration 200, lr = 0.005
I0403 07:03:43.049737 10121 solver.cpp:228] Iteration 205, loss = 1.50156
I0403 07:03:43.051017 10121 solver.cpp:244]     Train net output #0: loss = 1.50156 (* 1 = 1.50156 loss)
I0403 07:03:43.275488 10121 sgd_solver.cpp:106] Iteration 205, lr = 0.005
I0403 07:03:46.784087 10121 solver.cpp:228] Iteration 210, loss = 1.57985
I0403 07:03:46.784173 10121 solver.cpp:244]     Train net output #0: loss = 1.57985 (* 1 = 1.57985 loss)
I0403 07:03:46.951761 10121 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 07:03:50.384413 10121 solver.cpp:228] Iteration 215, loss = 1.74334
I0403 07:03:50.384507 10121 solver.cpp:244]     Train net output #0: loss = 1.74334 (* 1 = 1.74334 loss)
I0403 07:03:50.586112 10121 sgd_solver.cpp:106] Iteration 215, lr = 0.005
I0403 07:03:50.586369 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_216.caffemodel
I0403 07:03:53.345578 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_216.solverstate
I0403 07:03:55.244684 10121 solver.cpp:337] Iteration 216, Testing net (#0)
I0403 07:05:33.127413 10121 solver.cpp:404]     Test net output #0: accuracy = 0.604839
I0403 07:05:33.131728 10121 solver.cpp:404]     Test net output #1: loss = 1.34999 (* 1 = 1.34999 loss)
I0403 07:05:36.514542 10121 solver.cpp:228] Iteration 220, loss = 1.30543
I0403 07:05:36.514636 10121 solver.cpp:244]     Train net output #0: loss = 1.30543 (* 1 = 1.30543 loss)
I0403 07:05:36.733865 10121 sgd_solver.cpp:106] Iteration 220, lr = 0.005
I0403 07:05:40.201175 10121 solver.cpp:228] Iteration 225, loss = 1.41568
I0403 07:05:40.201274 10121 solver.cpp:244]     Train net output #0: loss = 1.41568 (* 1 = 1.41568 loss)
I0403 07:05:40.425868 10121 sgd_solver.cpp:106] Iteration 225, lr = 0.005
I0403 07:05:43.840713 10121 solver.cpp:228] Iteration 230, loss = 1.52924
I0403 07:05:43.840800 10121 solver.cpp:244]     Train net output #0: loss = 1.52924 (* 1 = 1.52924 loss)
I0403 07:05:44.019408 10121 sgd_solver.cpp:106] Iteration 230, lr = 0.005
I0403 07:05:47.498661 10121 solver.cpp:228] Iteration 235, loss = 1.3474
I0403 07:05:47.498756 10121 solver.cpp:244]     Train net output #0: loss = 1.3474 (* 1 = 1.3474 loss)
I0403 07:05:47.719143 10121 sgd_solver.cpp:106] Iteration 235, lr = 0.005
I0403 07:05:51.147323 10121 solver.cpp:228] Iteration 240, loss = 1.14387
I0403 07:05:51.147413 10121 solver.cpp:244]     Train net output #0: loss = 1.14387 (* 1 = 1.14387 loss)
I0403 07:05:51.329818 10121 sgd_solver.cpp:106] Iteration 240, lr = 0.005
I0403 07:05:54.806365 10121 solver.cpp:228] Iteration 245, loss = 1.27823
I0403 07:05:54.806449 10121 solver.cpp:244]     Train net output #0: loss = 1.27823 (* 1 = 1.27823 loss)
I0403 07:05:54.978937 10121 sgd_solver.cpp:106] Iteration 245, lr = 0.005
I0403 07:05:58.468075 10121 solver.cpp:228] Iteration 250, loss = 1.03778
I0403 07:05:58.468158 10121 solver.cpp:244]     Train net output #0: loss = 1.03778 (* 1 = 1.03778 loss)
I0403 07:05:58.649931 10121 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0403 07:06:02.076916 10121 solver.cpp:228] Iteration 255, loss = 1.24053
I0403 07:06:02.077005 10121 solver.cpp:244]     Train net output #0: loss = 1.24053 (* 1 = 1.24053 loss)
I0403 07:06:02.257300 10121 sgd_solver.cpp:106] Iteration 255, lr = 0.005
I0403 07:06:05.749357 10121 solver.cpp:228] Iteration 260, loss = 1.04631
I0403 07:06:05.749671 10121 solver.cpp:244]     Train net output #0: loss = 1.04631 (* 1 = 1.04631 loss)
I0403 07:06:05.930769 10121 sgd_solver.cpp:106] Iteration 260, lr = 0.005
I0403 07:06:09.343385 10121 solver.cpp:228] Iteration 265, loss = 1.10833
I0403 07:06:09.343467 10121 solver.cpp:244]     Train net output #0: loss = 1.10833 (* 1 = 1.10833 loss)
I0403 07:06:09.524761 10121 sgd_solver.cpp:106] Iteration 265, lr = 0.005
I0403 07:06:12.948504 10121 solver.cpp:228] Iteration 270, loss = 1.12996
I0403 07:06:12.948597 10121 solver.cpp:244]     Train net output #0: loss = 1.12996 (* 1 = 1.12996 loss)
I0403 07:06:13.130669 10121 sgd_solver.cpp:106] Iteration 270, lr = 0.005
I0403 07:06:16.594030 10121 solver.cpp:228] Iteration 275, loss = 1.36687
I0403 07:06:16.594115 10121 solver.cpp:244]     Train net output #0: loss = 1.36687 (* 1 = 1.36687 loss)
I0403 07:06:16.773335 10121 sgd_solver.cpp:106] Iteration 275, lr = 0.005
I0403 07:06:20.234729 10121 solver.cpp:228] Iteration 280, loss = 0.948348
I0403 07:06:20.234823 10121 solver.cpp:244]     Train net output #0: loss = 0.948348 (* 1 = 0.948348 loss)
I0403 07:06:20.437866 10121 sgd_solver.cpp:106] Iteration 280, lr = 0.005
I0403 07:06:23.916066 10121 solver.cpp:228] Iteration 285, loss = 1.03149
I0403 07:06:23.916157 10121 solver.cpp:244]     Train net output #0: loss = 1.03149 (* 1 = 1.03149 loss)
I0403 07:06:24.098201 10121 sgd_solver.cpp:106] Iteration 285, lr = 0.005
I0403 07:06:27.494705 10121 solver.cpp:228] Iteration 290, loss = 0.93087
I0403 07:06:27.494801 10121 solver.cpp:244]     Train net output #0: loss = 0.93087 (* 1 = 0.93087 loss)
I0403 07:06:27.677350 10121 sgd_solver.cpp:106] Iteration 290, lr = 0.005
I0403 07:06:31.130167 10121 solver.cpp:228] Iteration 295, loss = 0.869476
I0403 07:06:31.130259 10121 solver.cpp:244]     Train net output #0: loss = 0.869476 (* 1 = 0.869476 loss)
I0403 07:06:31.262423 10121 sgd_solver.cpp:106] Iteration 295, lr = 0.005
I0403 07:06:34.747449 10121 solver.cpp:228] Iteration 300, loss = 0.816096
I0403 07:06:34.747545 10121 solver.cpp:244]     Train net output #0: loss = 0.816096 (* 1 = 0.816096 loss)
I0403 07:06:34.990634 10121 sgd_solver.cpp:106] Iteration 300, lr = 0.005
I0403 07:06:38.407675 10121 solver.cpp:228] Iteration 305, loss = 0.969328
I0403 07:06:38.408041 10121 solver.cpp:244]     Train net output #0: loss = 0.969328 (* 1 = 0.969328 loss)
I0403 07:06:38.613755 10121 sgd_solver.cpp:106] Iteration 305, lr = 0.005
I0403 07:06:42.145346 10121 solver.cpp:228] Iteration 310, loss = 1.10309
I0403 07:06:42.145440 10121 solver.cpp:244]     Train net output #0: loss = 1.10309 (* 1 = 1.10309 loss)
I0403 07:06:42.340265 10121 sgd_solver.cpp:106] Iteration 310, lr = 0.005
I0403 07:06:45.779021 10121 solver.cpp:228] Iteration 315, loss = 0.746446
I0403 07:06:45.779105 10121 solver.cpp:244]     Train net output #0: loss = 0.746446 (* 1 = 0.746446 loss)
I0403 07:06:45.955677 10121 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 07:06:49.395666 10121 solver.cpp:228] Iteration 320, loss = 0.941416
I0403 07:06:49.395761 10121 solver.cpp:244]     Train net output #0: loss = 0.941416 (* 1 = 0.941416 loss)
I0403 07:06:49.614105 10121 sgd_solver.cpp:106] Iteration 320, lr = 0.005
I0403 07:06:51.808169 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_324.caffemodel
I0403 07:06:54.576014 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_324.solverstate
I0403 07:06:56.839721 10121 solver.cpp:337] Iteration 324, Testing net (#0)
I0403 07:08:34.713171 10121 solver.cpp:404]     Test net output #0: accuracy = 0.745346
I0403 07:08:34.713474 10121 solver.cpp:404]     Test net output #1: loss = 0.848097 (* 1 = 0.848097 loss)
I0403 07:08:35.953997 10121 solver.cpp:228] Iteration 325, loss = 0.699085
I0403 07:08:35.954079 10121 solver.cpp:244]     Train net output #0: loss = 0.699085 (* 1 = 0.699085 loss)
I0403 07:08:36.122375 10121 sgd_solver.cpp:106] Iteration 325, lr = 0.005
I0403 07:08:39.668715 10121 solver.cpp:228] Iteration 330, loss = 0.918553
I0403 07:08:39.668808 10121 solver.cpp:244]     Train net output #0: loss = 0.918553 (* 1 = 0.918553 loss)
I0403 07:08:39.850896 10121 sgd_solver.cpp:106] Iteration 330, lr = 0.005
I0403 07:08:43.389894 10121 solver.cpp:228] Iteration 335, loss = 0.918778
I0403 07:08:43.389977 10121 solver.cpp:244]     Train net output #0: loss = 0.918778 (* 1 = 0.918778 loss)
I0403 07:08:43.542134 10121 sgd_solver.cpp:106] Iteration 335, lr = 0.005
I0403 07:08:47.186791 10121 solver.cpp:228] Iteration 340, loss = 0.68206
I0403 07:08:47.187788 10121 solver.cpp:244]     Train net output #0: loss = 0.68206 (* 1 = 0.68206 loss)
I0403 07:08:47.368357 10121 sgd_solver.cpp:106] Iteration 340, lr = 0.005
I0403 07:08:50.810025 10121 solver.cpp:228] Iteration 345, loss = 0.595475
I0403 07:08:50.810122 10121 solver.cpp:244]     Train net output #0: loss = 0.595475 (* 1 = 0.595475 loss)
I0403 07:08:51.012187 10121 sgd_solver.cpp:106] Iteration 345, lr = 0.005
I0403 07:08:54.399490 10121 solver.cpp:228] Iteration 350, loss = 0.678744
I0403 07:08:54.399583 10121 solver.cpp:244]     Train net output #0: loss = 0.678744 (* 1 = 0.678744 loss)
I0403 07:08:54.605401 10121 sgd_solver.cpp:106] Iteration 350, lr = 0.005
I0403 07:08:58.120793 10121 solver.cpp:228] Iteration 355, loss = 0.693084
I0403 07:08:58.120880 10121 solver.cpp:244]     Train net output #0: loss = 0.693084 (* 1 = 0.693084 loss)
I0403 07:08:58.297224 10121 sgd_solver.cpp:106] Iteration 355, lr = 0.005
I0403 07:09:01.858333 10121 solver.cpp:228] Iteration 360, loss = 0.708632
I0403 07:09:01.858424 10121 solver.cpp:244]     Train net output #0: loss = 0.708632 (* 1 = 0.708632 loss)
I0403 07:09:02.045719 10121 sgd_solver.cpp:106] Iteration 360, lr = 0.005
I0403 07:09:05.536844 10121 solver.cpp:228] Iteration 365, loss = 0.662299
I0403 07:09:05.537215 10121 solver.cpp:244]     Train net output #0: loss = 0.662299 (* 1 = 0.662299 loss)
I0403 07:09:05.719600 10121 sgd_solver.cpp:106] Iteration 365, lr = 0.005
I0403 07:09:09.147367 10121 solver.cpp:228] Iteration 370, loss = 0.733702
I0403 07:09:09.147461 10121 solver.cpp:244]     Train net output #0: loss = 0.733702 (* 1 = 0.733702 loss)
I0403 07:09:09.366932 10121 sgd_solver.cpp:106] Iteration 370, lr = 0.005
I0403 07:09:12.855511 10121 solver.cpp:228] Iteration 375, loss = 0.731319
I0403 07:09:12.855604 10121 solver.cpp:244]     Train net output #0: loss = 0.731319 (* 1 = 0.731319 loss)
I0403 07:09:13.040199 10121 sgd_solver.cpp:106] Iteration 375, lr = 0.005
I0403 07:09:16.536461 10121 solver.cpp:228] Iteration 380, loss = 0.807184
I0403 07:09:16.536555 10121 solver.cpp:244]     Train net output #0: loss = 0.807184 (* 1 = 0.807184 loss)
I0403 07:09:16.719780 10121 sgd_solver.cpp:106] Iteration 380, lr = 0.005
I0403 07:09:20.149595 10121 solver.cpp:228] Iteration 385, loss = 0.806616
I0403 07:09:20.149689 10121 solver.cpp:244]     Train net output #0: loss = 0.806616 (* 1 = 0.806616 loss)
I0403 07:09:20.356443 10121 sgd_solver.cpp:106] Iteration 385, lr = 0.005
I0403 07:09:23.755328 10121 solver.cpp:228] Iteration 390, loss = 0.808547
I0403 07:09:23.755424 10121 solver.cpp:244]     Train net output #0: loss = 0.808547 (* 1 = 0.808547 loss)
I0403 07:09:23.957914 10121 sgd_solver.cpp:106] Iteration 390, lr = 0.005
I0403 07:09:27.449465 10121 solver.cpp:228] Iteration 395, loss = 0.766236
I0403 07:09:27.449559 10121 solver.cpp:244]     Train net output #0: loss = 0.766236 (* 1 = 0.766236 loss)
I0403 07:09:27.653800 10121 sgd_solver.cpp:106] Iteration 395, lr = 0.005
I0403 07:09:31.086948 10121 solver.cpp:228] Iteration 400, loss = 0.502653
I0403 07:09:31.087033 10121 solver.cpp:244]     Train net output #0: loss = 0.502653 (* 1 = 0.502653 loss)
I0403 07:09:31.265672 10121 sgd_solver.cpp:106] Iteration 400, lr = 0.005
I0403 07:09:34.680086 10121 solver.cpp:228] Iteration 405, loss = 0.658607
I0403 07:09:34.680179 10121 solver.cpp:244]     Train net output #0: loss = 0.658607 (* 1 = 0.658607 loss)
I0403 07:09:34.871839 10121 sgd_solver.cpp:106] Iteration 405, lr = 0.005
I0403 07:09:38.429735 10121 solver.cpp:228] Iteration 410, loss = 0.643926
I0403 07:09:38.430050 10121 solver.cpp:244]     Train net output #0: loss = 0.643926 (* 1 = 0.643926 loss)
I0403 07:09:38.606704 10121 sgd_solver.cpp:106] Iteration 410, lr = 0.005
I0403 07:09:42.126564 10121 solver.cpp:228] Iteration 415, loss = 0.82521
I0403 07:09:42.126658 10121 solver.cpp:244]     Train net output #0: loss = 0.82521 (* 1 = 0.82521 loss)
I0403 07:09:42.320042 10121 sgd_solver.cpp:106] Iteration 415, lr = 0.005
I0403 07:09:45.740612 10121 solver.cpp:228] Iteration 420, loss = 0.594315
I0403 07:09:45.741853 10121 solver.cpp:244]     Train net output #0: loss = 0.594315 (* 1 = 0.594315 loss)
I0403 07:09:45.968535 10121 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 07:09:49.434903 10121 solver.cpp:228] Iteration 425, loss = 0.734163
I0403 07:09:49.434998 10121 solver.cpp:244]     Train net output #0: loss = 0.734163 (* 1 = 0.734163 loss)
I0403 07:09:49.637045 10121 sgd_solver.cpp:106] Iteration 425, lr = 0.005
I0403 07:09:53.189844 10121 solver.cpp:228] Iteration 430, loss = 0.674151
I0403 07:09:53.189939 10121 solver.cpp:244]     Train net output #0: loss = 0.674151 (* 1 = 0.674151 loss)
I0403 07:09:53.376675 10121 sgd_solver.cpp:106] Iteration 430, lr = 0.005
I0403 07:09:54.086714 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_432.caffemodel
I0403 07:09:56.838091 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_432.solverstate
I0403 07:09:58.750135 10121 solver.cpp:337] Iteration 432, Testing net (#0)
I0403 07:11:36.638957 10121 solver.cpp:404]     Test net output #0: accuracy = 0.773618
I0403 07:11:36.639312 10121 solver.cpp:404]     Test net output #1: loss = 0.728572 (* 1 = 0.728572 loss)
I0403 07:11:39.371989 10121 solver.cpp:228] Iteration 435, loss = 0.729365
I0403 07:11:39.372078 10121 solver.cpp:244]     Train net output #0: loss = 0.729365 (* 1 = 0.729365 loss)
I0403 07:11:39.565366 10121 sgd_solver.cpp:106] Iteration 435, lr = 0.005
I0403 07:11:42.954886 10121 solver.cpp:228] Iteration 440, loss = 0.517888
I0403 07:11:42.954982 10121 solver.cpp:244]     Train net output #0: loss = 0.517888 (* 1 = 0.517888 loss)
I0403 07:11:43.155726 10121 sgd_solver.cpp:106] Iteration 440, lr = 0.005
I0403 07:11:46.582715 10121 solver.cpp:228] Iteration 445, loss = 0.493856
I0403 07:11:46.582798 10121 solver.cpp:244]     Train net output #0: loss = 0.493856 (* 1 = 0.493856 loss)
I0403 07:11:46.760123 10121 sgd_solver.cpp:106] Iteration 445, lr = 0.005
I0403 07:11:50.214670 10121 solver.cpp:228] Iteration 450, loss = 0.450186
I0403 07:11:50.214764 10121 solver.cpp:244]     Train net output #0: loss = 0.450186 (* 1 = 0.450186 loss)
I0403 07:11:50.438663 10121 sgd_solver.cpp:106] Iteration 450, lr = 0.005
I0403 07:11:53.868213 10121 solver.cpp:228] Iteration 455, loss = 0.849845
I0403 07:11:53.868319 10121 solver.cpp:244]     Train net output #0: loss = 0.849845 (* 1 = 0.849845 loss)
I0403 07:11:54.065239 10121 sgd_solver.cpp:106] Iteration 455, lr = 0.005
I0403 07:11:57.537156 10121 solver.cpp:228] Iteration 460, loss = 0.489547
I0403 07:11:57.537257 10121 solver.cpp:244]     Train net output #0: loss = 0.489547 (* 1 = 0.489547 loss)
I0403 07:11:57.729696 10121 sgd_solver.cpp:106] Iteration 460, lr = 0.005
I0403 07:12:01.165879 10121 solver.cpp:228] Iteration 465, loss = 0.442785
I0403 07:12:01.165977 10121 solver.cpp:244]     Train net output #0: loss = 0.442785 (* 1 = 0.442785 loss)
I0403 07:12:01.348419 10121 sgd_solver.cpp:106] Iteration 465, lr = 0.005
I0403 07:12:04.766733 10121 solver.cpp:228] Iteration 470, loss = 0.621451
I0403 07:12:04.766813 10121 solver.cpp:244]     Train net output #0: loss = 0.621451 (* 1 = 0.621451 loss)
I0403 07:12:04.939080 10121 sgd_solver.cpp:106] Iteration 470, lr = 0.005
I0403 07:12:08.406260 10121 solver.cpp:228] Iteration 475, loss = 0.508662
I0403 07:12:08.406559 10121 solver.cpp:244]     Train net output #0: loss = 0.508662 (* 1 = 0.508662 loss)
I0403 07:12:08.607028 10121 sgd_solver.cpp:106] Iteration 475, lr = 0.005
I0403 07:12:12.115444 10121 solver.cpp:228] Iteration 480, loss = 0.624518
I0403 07:12:12.115550 10121 solver.cpp:244]     Train net output #0: loss = 0.624518 (* 1 = 0.624518 loss)
I0403 07:12:12.299376 10121 sgd_solver.cpp:106] Iteration 480, lr = 0.005
I0403 07:12:15.806911 10121 solver.cpp:228] Iteration 485, loss = 0.582668
I0403 07:12:15.807008 10121 solver.cpp:244]     Train net output #0: loss = 0.582668 (* 1 = 0.582668 loss)
I0403 07:12:16.046629 10121 sgd_solver.cpp:106] Iteration 485, lr = 0.005
I0403 07:12:19.497102 10121 solver.cpp:228] Iteration 490, loss = 0.54862
I0403 07:12:19.497190 10121 solver.cpp:244]     Train net output #0: loss = 0.54862 (* 1 = 0.54862 loss)
I0403 07:12:19.678627 10121 sgd_solver.cpp:106] Iteration 490, lr = 0.005
I0403 07:12:23.135419 10121 solver.cpp:228] Iteration 495, loss = 0.475928
I0403 07:12:23.135504 10121 solver.cpp:244]     Train net output #0: loss = 0.475928 (* 1 = 0.475928 loss)
I0403 07:12:23.289279 10121 sgd_solver.cpp:106] Iteration 495, lr = 0.005
I0403 07:12:26.887007 10121 solver.cpp:228] Iteration 500, loss = 0.475671
I0403 07:12:26.887094 10121 solver.cpp:244]     Train net output #0: loss = 0.475671 (* 1 = 0.475671 loss)
I0403 07:12:27.052276 10121 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0403 07:12:30.648257 10121 solver.cpp:228] Iteration 505, loss = 0.538958
I0403 07:12:30.648345 10121 solver.cpp:244]     Train net output #0: loss = 0.538958 (* 1 = 0.538958 loss)
I0403 07:12:30.824826 10121 sgd_solver.cpp:106] Iteration 505, lr = 0.005
I0403 07:12:34.258787 10121 solver.cpp:228] Iteration 510, loss = 0.735622
I0403 07:12:34.258883 10121 solver.cpp:244]     Train net output #0: loss = 0.735622 (* 1 = 0.735622 loss)
I0403 07:12:34.452608 10121 sgd_solver.cpp:106] Iteration 510, lr = 0.005
I0403 07:12:37.913838 10121 solver.cpp:228] Iteration 515, loss = 0.389074
I0403 07:12:37.913931 10121 solver.cpp:244]     Train net output #0: loss = 0.389074 (* 1 = 0.389074 loss)
I0403 07:12:38.121919 10121 sgd_solver.cpp:106] Iteration 515, lr = 0.005
I0403 07:12:41.583500 10121 solver.cpp:228] Iteration 520, loss = 0.602106
I0403 07:12:41.583849 10121 solver.cpp:244]     Train net output #0: loss = 0.602106 (* 1 = 0.602106 loss)
I0403 07:12:41.765967 10121 sgd_solver.cpp:106] Iteration 520, lr = 0.005
I0403 07:12:45.187161 10121 solver.cpp:228] Iteration 525, loss = 0.357624
I0403 07:12:45.187260 10121 solver.cpp:244]     Train net output #0: loss = 0.357624 (* 1 = 0.357624 loss)
I0403 07:12:45.388257 10121 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 07:12:48.781462 10121 solver.cpp:228] Iteration 530, loss = 0.698856
I0403 07:12:48.781556 10121 solver.cpp:244]     Train net output #0: loss = 0.698856 (* 1 = 0.698856 loss)
I0403 07:12:49.023535 10121 sgd_solver.cpp:106] Iteration 530, lr = 0.005
I0403 07:12:52.495507 10121 solver.cpp:228] Iteration 535, loss = 0.580622
I0403 07:12:52.495606 10121 solver.cpp:244]     Train net output #0: loss = 0.580622 (* 1 = 0.580622 loss)
I0403 07:12:52.698868 10121 sgd_solver.cpp:106] Iteration 535, lr = 0.005
I0403 07:12:55.693228 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_540.caffemodel
I0403 07:12:58.362819 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_540.solverstate
I0403 07:13:00.178782 10121 solver.cpp:337] Iteration 540, Testing net (#0)
I0403 07:14:38.050627 10121 solver.cpp:404]     Test net output #0: accuracy = 0.814608
I0403 07:14:38.050942 10121 solver.cpp:404]     Test net output #1: loss = 0.616476 (* 1 = 0.616476 loss)
I0403 07:14:38.570210 10121 solver.cpp:228] Iteration 540, loss = 0.563978
I0403 07:14:38.570296 10121 solver.cpp:244]     Train net output #0: loss = 0.563978 (* 1 = 0.563978 loss)
I0403 07:14:38.745689 10121 sgd_solver.cpp:106] Iteration 540, lr = 0.005
I0403 07:14:42.323372 10121 solver.cpp:228] Iteration 545, loss = 0.523515
I0403 07:14:42.323457 10121 solver.cpp:244]     Train net output #0: loss = 0.523515 (* 1 = 0.523515 loss)
I0403 07:14:42.480152 10121 sgd_solver.cpp:106] Iteration 545, lr = 0.005
I0403 07:14:45.978915 10121 solver.cpp:228] Iteration 550, loss = 0.407464
I0403 07:14:45.979012 10121 solver.cpp:244]     Train net output #0: loss = 0.407464 (* 1 = 0.407464 loss)
I0403 07:14:46.192773 10121 sgd_solver.cpp:106] Iteration 550, lr = 0.005
I0403 07:14:49.616472 10121 solver.cpp:228] Iteration 555, loss = 0.53041
I0403 07:14:49.616567 10121 solver.cpp:244]     Train net output #0: loss = 0.53041 (* 1 = 0.53041 loss)
I0403 07:14:49.818864 10121 sgd_solver.cpp:106] Iteration 555, lr = 0.005
I0403 07:14:53.246562 10121 solver.cpp:228] Iteration 560, loss = 0.511409
I0403 07:14:53.246647 10121 solver.cpp:244]     Train net output #0: loss = 0.511409 (* 1 = 0.511409 loss)
I0403 07:14:53.419780 10121 sgd_solver.cpp:106] Iteration 560, lr = 0.005
I0403 07:14:56.944761 10121 solver.cpp:228] Iteration 565, loss = 0.415888
I0403 07:14:56.944855 10121 solver.cpp:244]     Train net output #0: loss = 0.415888 (* 1 = 0.415888 loss)
I0403 07:14:57.127214 10121 sgd_solver.cpp:106] Iteration 565, lr = 0.005
I0403 07:15:00.603332 10121 solver.cpp:228] Iteration 570, loss = 0.557964
I0403 07:15:00.603435 10121 solver.cpp:244]     Train net output #0: loss = 0.557964 (* 1 = 0.557964 loss)
I0403 07:15:00.809032 10121 sgd_solver.cpp:106] Iteration 570, lr = 0.005
I0403 07:15:04.245949 10121 solver.cpp:228] Iteration 575, loss = 0.405266
I0403 07:15:04.246045 10121 solver.cpp:244]     Train net output #0: loss = 0.405266 (* 1 = 0.405266 loss)
I0403 07:15:04.439690 10121 sgd_solver.cpp:106] Iteration 575, lr = 0.005
I0403 07:15:07.889341 10121 solver.cpp:228] Iteration 580, loss = 0.489669
I0403 07:15:07.889433 10121 solver.cpp:244]     Train net output #0: loss = 0.489669 (* 1 = 0.489669 loss)
I0403 07:15:08.098141 10121 sgd_solver.cpp:106] Iteration 580, lr = 0.005
I0403 07:15:11.546319 10121 solver.cpp:228] Iteration 585, loss = 0.440925
I0403 07:15:11.546411 10121 solver.cpp:244]     Train net output #0: loss = 0.440925 (* 1 = 0.440925 loss)
I0403 07:15:11.741688 10121 sgd_solver.cpp:106] Iteration 585, lr = 0.005
I0403 07:15:15.231676 10121 solver.cpp:228] Iteration 590, loss = 0.518601
I0403 07:15:15.231763 10121 solver.cpp:244]     Train net output #0: loss = 0.518601 (* 1 = 0.518601 loss)
I0403 07:15:15.384436 10121 sgd_solver.cpp:106] Iteration 590, lr = 0.005
I0403 07:15:18.860954 10121 solver.cpp:228] Iteration 595, loss = 0.44245
I0403 07:15:18.861047 10121 solver.cpp:244]     Train net output #0: loss = 0.44245 (* 1 = 0.44245 loss)
I0403 07:15:19.048099 10121 sgd_solver.cpp:106] Iteration 595, lr = 0.005
I0403 07:15:22.469597 10121 solver.cpp:228] Iteration 600, loss = 0.641614
I0403 07:15:22.469686 10121 solver.cpp:244]     Train net output #0: loss = 0.641614 (* 1 = 0.641614 loss)
I0403 07:15:22.642302 10121 sgd_solver.cpp:106] Iteration 600, lr = 0.005
I0403 07:15:26.089440 10121 solver.cpp:228] Iteration 605, loss = 0.399353
I0403 07:15:26.089536 10121 solver.cpp:244]     Train net output #0: loss = 0.399353 (* 1 = 0.399353 loss)
I0403 07:15:26.299794 10121 sgd_solver.cpp:106] Iteration 605, lr = 0.005
I0403 07:15:29.754689 10121 solver.cpp:228] Iteration 610, loss = 0.548261
I0403 07:15:29.754776 10121 solver.cpp:244]     Train net output #0: loss = 0.548261 (* 1 = 0.548261 loss)
I0403 07:15:29.935948 10121 sgd_solver.cpp:106] Iteration 610, lr = 0.005
I0403 07:15:33.341433 10121 solver.cpp:228] Iteration 615, loss = 0.388499
I0403 07:15:33.341526 10121 solver.cpp:244]     Train net output #0: loss = 0.388499 (* 1 = 0.388499 loss)
I0403 07:15:33.527457 10121 sgd_solver.cpp:106] Iteration 615, lr = 0.005
I0403 07:15:36.961966 10121 solver.cpp:228] Iteration 620, loss = 0.323893
I0403 07:15:36.962061 10121 solver.cpp:244]     Train net output #0: loss = 0.323893 (* 1 = 0.323893 loss)
I0403 07:15:37.175743 10121 sgd_solver.cpp:106] Iteration 620, lr = 0.005
I0403 07:15:40.636462 10121 solver.cpp:228] Iteration 625, loss = 0.338031
I0403 07:15:40.636780 10121 solver.cpp:244]     Train net output #0: loss = 0.338031 (* 1 = 0.338031 loss)
I0403 07:15:40.829336 10121 sgd_solver.cpp:106] Iteration 625, lr = 0.005
I0403 07:15:44.313977 10121 solver.cpp:228] Iteration 630, loss = 0.552257
I0403 07:15:44.314070 10121 solver.cpp:244]     Train net output #0: loss = 0.552257 (* 1 = 0.552257 loss)
I0403 07:15:44.501597 10121 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 07:15:47.918644 10121 solver.cpp:228] Iteration 635, loss = 0.487593
I0403 07:15:47.918736 10121 solver.cpp:244]     Train net output #0: loss = 0.487593 (* 1 = 0.487593 loss)
I0403 07:15:48.110333 10121 sgd_solver.cpp:106] Iteration 635, lr = 0.005
I0403 07:15:51.483369 10121 solver.cpp:228] Iteration 640, loss = 0.310655
I0403 07:15:51.483458 10121 solver.cpp:244]     Train net output #0: loss = 0.310655 (* 1 = 0.310655 loss)
I0403 07:15:51.689604 10121 sgd_solver.cpp:106] Iteration 640, lr = 0.005
I0403 07:15:55.066032 10121 solver.cpp:228] Iteration 645, loss = 0.357583
I0403 07:15:55.066128 10121 solver.cpp:244]     Train net output #0: loss = 0.357583 (* 1 = 0.357583 loss)
I0403 07:15:55.315601 10121 sgd_solver.cpp:106] Iteration 645, lr = 0.005
I0403 07:15:56.801169 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_648.caffemodel
I0403 07:15:59.417196 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_648.solverstate
I0403 07:16:01.222338 10121 solver.cpp:337] Iteration 648, Testing net (#0)
I0403 07:17:39.094684 10121 solver.cpp:404]     Test net output #0: accuracy = 0.835507
I0403 07:17:39.095033 10121 solver.cpp:404]     Test net output #1: loss = 0.560223 (* 1 = 0.560223 loss)
I0403 07:17:41.063159 10121 solver.cpp:228] Iteration 650, loss = 0.181852
I0403 07:17:41.063257 10121 solver.cpp:244]     Train net output #0: loss = 0.181852 (* 1 = 0.181852 loss)
I0403 07:17:41.266432 10121 sgd_solver.cpp:106] Iteration 650, lr = 0.005
I0403 07:17:44.713857 10121 solver.cpp:228] Iteration 655, loss = 0.385207
I0403 07:17:44.713948 10121 solver.cpp:244]     Train net output #0: loss = 0.385207 (* 1 = 0.385207 loss)
I0403 07:17:44.905325 10121 sgd_solver.cpp:106] Iteration 655, lr = 0.005
I0403 07:17:48.404685 10121 solver.cpp:228] Iteration 660, loss = 0.424477
I0403 07:17:48.404773 10121 solver.cpp:244]     Train net output #0: loss = 0.424477 (* 1 = 0.424477 loss)
I0403 07:17:48.582818 10121 sgd_solver.cpp:106] Iteration 660, lr = 0.005
I0403 07:17:52.083057 10121 solver.cpp:228] Iteration 665, loss = 0.201378
I0403 07:17:52.083153 10121 solver.cpp:244]     Train net output #0: loss = 0.201378 (* 1 = 0.201378 loss)
I0403 07:17:52.265565 10121 sgd_solver.cpp:106] Iteration 665, lr = 0.005
I0403 07:17:55.722332 10121 solver.cpp:228] Iteration 670, loss = 0.310452
I0403 07:17:55.722430 10121 solver.cpp:244]     Train net output #0: loss = 0.310452 (* 1 = 0.310452 loss)
I0403 07:17:55.932093 10121 sgd_solver.cpp:106] Iteration 670, lr = 0.005
I0403 07:17:59.314329 10121 solver.cpp:228] Iteration 675, loss = 0.338465
I0403 07:17:59.314421 10121 solver.cpp:244]     Train net output #0: loss = 0.338465 (* 1 = 0.338465 loss)
I0403 07:17:59.507261 10121 sgd_solver.cpp:106] Iteration 675, lr = 0.005
I0403 07:18:02.943819 10121 solver.cpp:228] Iteration 680, loss = 0.413208
I0403 07:18:02.943913 10121 solver.cpp:244]     Train net output #0: loss = 0.413208 (* 1 = 0.413208 loss)
I0403 07:18:03.130708 10121 sgd_solver.cpp:106] Iteration 680, lr = 0.005
I0403 07:18:06.604164 10121 solver.cpp:228] Iteration 685, loss = 0.421965
I0403 07:18:06.604256 10121 solver.cpp:244]     Train net output #0: loss = 0.421965 (* 1 = 0.421965 loss)
I0403 07:18:06.781633 10121 sgd_solver.cpp:106] Iteration 685, lr = 0.005
I0403 07:18:10.242375 10121 solver.cpp:228] Iteration 690, loss = 0.233432
I0403 07:18:10.242676 10121 solver.cpp:244]     Train net output #0: loss = 0.233432 (* 1 = 0.233432 loss)
I0403 07:18:10.408787 10121 sgd_solver.cpp:106] Iteration 690, lr = 0.005
I0403 07:18:13.822666 10121 solver.cpp:228] Iteration 695, loss = 0.355107
I0403 07:18:13.822762 10121 solver.cpp:244]     Train net output #0: loss = 0.355107 (* 1 = 0.355107 loss)
I0403 07:18:14.052105 10121 sgd_solver.cpp:106] Iteration 695, lr = 0.005
I0403 07:18:17.477319 10121 solver.cpp:228] Iteration 700, loss = 0.353496
I0403 07:18:17.478472 10121 solver.cpp:244]     Train net output #0: loss = 0.353496 (* 1 = 0.353496 loss)
I0403 07:18:17.658429 10121 sgd_solver.cpp:106] Iteration 700, lr = 0.005
I0403 07:18:21.067292 10121 solver.cpp:228] Iteration 705, loss = 0.183611
I0403 07:18:21.067376 10121 solver.cpp:244]     Train net output #0: loss = 0.183611 (* 1 = 0.183611 loss)
I0403 07:18:21.246069 10121 sgd_solver.cpp:106] Iteration 705, lr = 0.005
I0403 07:18:24.675662 10121 solver.cpp:228] Iteration 710, loss = 0.462776
I0403 07:18:24.675756 10121 solver.cpp:244]     Train net output #0: loss = 0.462776 (* 1 = 0.462776 loss)
I0403 07:18:24.858109 10121 sgd_solver.cpp:106] Iteration 710, lr = 0.005
I0403 07:18:28.400192 10121 solver.cpp:228] Iteration 715, loss = 0.358291
I0403 07:18:28.400282 10121 solver.cpp:244]     Train net output #0: loss = 0.358291 (* 1 = 0.358291 loss)
I0403 07:18:28.550524 10121 sgd_solver.cpp:106] Iteration 715, lr = 0.005
I0403 07:18:32.029021 10121 solver.cpp:228] Iteration 720, loss = 0.505607
I0403 07:18:32.029112 10121 solver.cpp:244]     Train net output #0: loss = 0.505607 (* 1 = 0.505607 loss)
I0403 07:18:32.222363 10121 sgd_solver.cpp:106] Iteration 720, lr = 0.005
I0403 07:18:35.670045 10121 solver.cpp:228] Iteration 725, loss = 0.430729
I0403 07:18:35.670138 10121 solver.cpp:244]     Train net output #0: loss = 0.430729 (* 1 = 0.430729 loss)
I0403 07:18:35.856254 10121 sgd_solver.cpp:106] Iteration 725, lr = 0.005
I0403 07:18:39.275176 10121 solver.cpp:228] Iteration 730, loss = 0.276599
I0403 07:18:39.275274 10121 solver.cpp:244]     Train net output #0: loss = 0.276599 (* 1 = 0.276599 loss)
I0403 07:18:39.460824 10121 sgd_solver.cpp:106] Iteration 730, lr = 0.005
I0403 07:18:42.943743 10121 solver.cpp:228] Iteration 735, loss = 0.231082
I0403 07:18:42.944084 10121 solver.cpp:244]     Train net output #0: loss = 0.231082 (* 1 = 0.231082 loss)
I0403 07:18:43.119246 10121 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 07:18:46.583117 10121 solver.cpp:228] Iteration 740, loss = 0.428707
I0403 07:18:46.583211 10121 solver.cpp:244]     Train net output #0: loss = 0.428707 (* 1 = 0.428707 loss)
I0403 07:18:46.803987 10121 sgd_solver.cpp:106] Iteration 740, lr = 0.005
I0403 07:18:50.261699 10121 solver.cpp:228] Iteration 745, loss = 0.326369
I0403 07:18:50.261793 10121 solver.cpp:244]     Train net output #0: loss = 0.326369 (* 1 = 0.326369 loss)
I0403 07:18:50.449530 10121 sgd_solver.cpp:106] Iteration 745, lr = 0.005
I0403 07:18:53.839520 10121 solver.cpp:228] Iteration 750, loss = 0.44921
I0403 07:18:53.839613 10121 solver.cpp:244]     Train net output #0: loss = 0.44921 (* 1 = 0.44921 loss)
I0403 07:18:54.029135 10121 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0403 07:18:57.523361 10121 solver.cpp:228] Iteration 755, loss = 0.536263
I0403 07:18:57.523448 10121 solver.cpp:244]     Train net output #0: loss = 0.536263 (* 1 = 0.536263 loss)
I0403 07:18:57.703591 10121 sgd_solver.cpp:106] Iteration 755, lr = 0.005
I0403 07:18:57.703821 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_756.caffemodel
I0403 07:19:00.386513 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_756.solverstate
I0403 07:19:02.191365 10121 solver.cpp:337] Iteration 756, Testing net (#0)
I0403 07:20:40.062451 10121 solver.cpp:404]     Test net output #0: accuracy = 0.850023
I0403 07:20:40.062770 10121 solver.cpp:404]     Test net output #1: loss = 0.505209 (* 1 = 0.505209 loss)
I0403 07:20:43.555649 10121 solver.cpp:228] Iteration 760, loss = 0.600596
I0403 07:20:43.555734 10121 solver.cpp:244]     Train net output #0: loss = 0.600596 (* 1 = 0.600596 loss)
I0403 07:20:43.735203 10121 sgd_solver.cpp:106] Iteration 760, lr = 0.005
I0403 07:20:47.228260 10121 solver.cpp:228] Iteration 765, loss = 0.32934
I0403 07:20:47.228354 10121 solver.cpp:244]     Train net output #0: loss = 0.32934 (* 1 = 0.32934 loss)
I0403 07:20:47.443526 10121 sgd_solver.cpp:106] Iteration 765, lr = 0.005
I0403 07:20:50.881752 10121 solver.cpp:228] Iteration 770, loss = 0.357537
I0403 07:20:50.881839 10121 solver.cpp:244]     Train net output #0: loss = 0.357537 (* 1 = 0.357537 loss)
I0403 07:20:51.057611 10121 sgd_solver.cpp:106] Iteration 770, lr = 0.005
I0403 07:20:54.521760 10121 solver.cpp:228] Iteration 775, loss = 0.329222
I0403 07:20:54.521854 10121 solver.cpp:244]     Train net output #0: loss = 0.329222 (* 1 = 0.329222 loss)
I0403 07:20:54.717067 10121 sgd_solver.cpp:106] Iteration 775, lr = 0.005
I0403 07:20:58.144889 10121 solver.cpp:228] Iteration 780, loss = 0.407993
I0403 07:20:58.144991 10121 solver.cpp:244]     Train net output #0: loss = 0.407993 (* 1 = 0.407993 loss)
I0403 07:20:58.354441 10121 sgd_solver.cpp:106] Iteration 780, lr = 0.005
I0403 07:21:01.773515 10121 solver.cpp:228] Iteration 785, loss = 0.14331
I0403 07:21:01.773612 10121 solver.cpp:244]     Train net output #0: loss = 0.14331 (* 1 = 0.14331 loss)
I0403 07:21:01.965422 10121 sgd_solver.cpp:106] Iteration 785, lr = 0.005
I0403 07:21:05.398260 10121 solver.cpp:228] Iteration 790, loss = 0.269237
I0403 07:21:05.398345 10121 solver.cpp:244]     Train net output #0: loss = 0.269237 (* 1 = 0.269237 loss)
I0403 07:21:05.579967 10121 sgd_solver.cpp:106] Iteration 790, lr = 0.005
I0403 07:21:09.055582 10121 solver.cpp:228] Iteration 795, loss = 0.319939
I0403 07:21:09.055667 10121 solver.cpp:244]     Train net output #0: loss = 0.319939 (* 1 = 0.319939 loss)
I0403 07:21:09.213738 10121 sgd_solver.cpp:106] Iteration 795, lr = 0.005
I0403 07:21:12.696187 10121 solver.cpp:228] Iteration 800, loss = 0.304279
I0403 07:21:12.696527 10121 solver.cpp:244]     Train net output #0: loss = 0.304279 (* 1 = 0.304279 loss)
I0403 07:21:12.900480 10121 sgd_solver.cpp:106] Iteration 800, lr = 0.005
I0403 07:21:16.283053 10121 solver.cpp:228] Iteration 805, loss = 0.420121
I0403 07:21:16.283149 10121 solver.cpp:244]     Train net output #0: loss = 0.420121 (* 1 = 0.420121 loss)
I0403 07:21:16.544037 10121 sgd_solver.cpp:106] Iteration 805, lr = 0.005
I0403 07:21:19.997855 10121 solver.cpp:228] Iteration 810, loss = 0.263617
I0403 07:21:19.997949 10121 solver.cpp:244]     Train net output #0: loss = 0.263617 (* 1 = 0.263617 loss)
I0403 07:21:20.180517 10121 sgd_solver.cpp:106] Iteration 810, lr = 0.005
I0403 07:21:23.615226 10121 solver.cpp:228] Iteration 815, loss = 0.284826
I0403 07:21:23.615322 10121 solver.cpp:244]     Train net output #0: loss = 0.284826 (* 1 = 0.284826 loss)
I0403 07:21:23.797458 10121 sgd_solver.cpp:106] Iteration 815, lr = 0.005
I0403 07:21:27.194892 10121 solver.cpp:228] Iteration 820, loss = 0.506592
I0403 07:21:27.194991 10121 solver.cpp:244]     Train net output #0: loss = 0.506592 (* 1 = 0.506592 loss)
I0403 07:21:27.438031 10121 sgd_solver.cpp:106] Iteration 820, lr = 0.005
I0403 07:21:31.064307 10121 solver.cpp:228] Iteration 825, loss = 0.308423
I0403 07:21:31.064393 10121 solver.cpp:244]     Train net output #0: loss = 0.308423 (* 1 = 0.308423 loss)
I0403 07:21:31.240051 10121 sgd_solver.cpp:106] Iteration 825, lr = 0.005
I0403 07:21:34.755938 10121 solver.cpp:228] Iteration 830, loss = 0.311181
I0403 07:21:34.756032 10121 solver.cpp:244]     Train net output #0: loss = 0.311181 (* 1 = 0.311181 loss)
I0403 07:21:34.963724 10121 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0403 07:21:38.413992 10121 solver.cpp:228] Iteration 835, loss = 0.319185
I0403 07:21:38.414078 10121 solver.cpp:244]     Train net output #0: loss = 0.319185 (* 1 = 0.319185 loss)
I0403 07:21:38.582329 10121 sgd_solver.cpp:106] Iteration 835, lr = 0.005
I0403 07:21:42.046337 10121 solver.cpp:228] Iteration 840, loss = 0.320913
I0403 07:21:42.046432 10121 solver.cpp:244]     Train net output #0: loss = 0.320913 (* 1 = 0.320913 loss)
I0403 07:21:42.239683 10121 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 07:21:45.750529 10121 solver.cpp:228] Iteration 845, loss = 0.218014
I0403 07:21:45.750885 10121 solver.cpp:244]     Train net output #0: loss = 0.218014 (* 1 = 0.218014 loss)
I0403 07:21:45.957545 10121 sgd_solver.cpp:106] Iteration 845, lr = 0.005
I0403 07:21:49.498325 10121 solver.cpp:228] Iteration 850, loss = 0.224254
I0403 07:21:49.498422 10121 solver.cpp:244]     Train net output #0: loss = 0.224254 (* 1 = 0.224254 loss)
I0403 07:21:49.681273 10121 sgd_solver.cpp:106] Iteration 850, lr = 0.005
I0403 07:21:53.132479 10121 solver.cpp:228] Iteration 855, loss = 0.523603
I0403 07:21:53.132575 10121 solver.cpp:244]     Train net output #0: loss = 0.523603 (* 1 = 0.523603 loss)
I0403 07:21:53.316191 10121 sgd_solver.cpp:106] Iteration 855, lr = 0.005
I0403 07:21:56.728401 10121 solver.cpp:228] Iteration 860, loss = 0.215805
I0403 07:21:56.728494 10121 solver.cpp:244]     Train net output #0: loss = 0.215804 (* 1 = 0.215804 loss)
I0403 07:21:56.925792 10121 sgd_solver.cpp:106] Iteration 860, lr = 0.005
I0403 07:21:59.077149 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_864.caffemodel
I0403 07:22:01.738595 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_864.solverstate
I0403 07:22:03.547277 10121 solver.cpp:337] Iteration 864, Testing net (#0)
I0403 07:23:41.422245 10121 solver.cpp:404]     Test net output #0: accuracy = 0.867558
I0403 07:23:41.422567 10121 solver.cpp:404]     Test net output #1: loss = 0.44797 (* 1 = 0.44797 loss)
I0403 07:23:42.678362 10121 solver.cpp:228] Iteration 865, loss = 0.28062
I0403 07:23:42.678455 10121 solver.cpp:244]     Train net output #0: loss = 0.28062 (* 1 = 0.28062 loss)
I0403 07:23:42.876171 10121 sgd_solver.cpp:106] Iteration 865, lr = 0.005
I0403 07:23:46.339967 10121 solver.cpp:228] Iteration 870, loss = 0.247447
I0403 07:23:46.340054 10121 solver.cpp:244]     Train net output #0: loss = 0.247447 (* 1 = 0.247447 loss)
I0403 07:23:46.521384 10121 sgd_solver.cpp:106] Iteration 870, lr = 0.005
I0403 07:23:49.962975 10121 solver.cpp:228] Iteration 875, loss = 0.188879
I0403 07:23:49.963063 10121 solver.cpp:244]     Train net output #0: loss = 0.188879 (* 1 = 0.188879 loss)
I0403 07:23:50.140311 10121 sgd_solver.cpp:106] Iteration 875, lr = 0.005
I0403 07:23:53.625241 10121 solver.cpp:228] Iteration 880, loss = 0.336671
I0403 07:23:53.625334 10121 solver.cpp:244]     Train net output #0: loss = 0.336671 (* 1 = 0.336671 loss)
I0403 07:23:53.810271 10121 sgd_solver.cpp:106] Iteration 880, lr = 0.005
I0403 07:23:57.288275 10121 solver.cpp:228] Iteration 885, loss = 0.213867
I0403 07:23:57.288362 10121 solver.cpp:244]     Train net output #0: loss = 0.213867 (* 1 = 0.213867 loss)
I0403 07:23:57.467663 10121 sgd_solver.cpp:106] Iteration 885, lr = 0.005
I0403 07:24:00.914232 10121 solver.cpp:228] Iteration 890, loss = 0.234748
I0403 07:24:00.914326 10121 solver.cpp:244]     Train net output #0: loss = 0.234748 (* 1 = 0.234748 loss)
I0403 07:24:01.100312 10121 sgd_solver.cpp:106] Iteration 890, lr = 0.005
I0403 07:24:04.474891 10121 solver.cpp:228] Iteration 895, loss = 0.444837
I0403 07:24:04.474983 10121 solver.cpp:244]     Train net output #0: loss = 0.444837 (* 1 = 0.444837 loss)
I0403 07:24:04.660414 10121 sgd_solver.cpp:106] Iteration 895, lr = 0.005
I0403 07:24:08.103947 10121 solver.cpp:228] Iteration 900, loss = 0.232189
I0403 07:24:08.104041 10121 solver.cpp:244]     Train net output #0: loss = 0.232189 (* 1 = 0.232189 loss)
I0403 07:24:08.286823 10121 sgd_solver.cpp:106] Iteration 900, lr = 0.005
I0403 07:24:11.708653 10121 solver.cpp:228] Iteration 905, loss = 0.332809
I0403 07:24:11.708942 10121 solver.cpp:244]     Train net output #0: loss = 0.332809 (* 1 = 0.332809 loss)
I0403 07:24:11.890161 10121 sgd_solver.cpp:106] Iteration 905, lr = 0.005
I0403 07:24:15.455687 10121 solver.cpp:228] Iteration 910, loss = 0.172776
I0403 07:24:15.455777 10121 solver.cpp:244]     Train net output #0: loss = 0.172776 (* 1 = 0.172776 loss)
I0403 07:24:15.648324 10121 sgd_solver.cpp:106] Iteration 910, lr = 0.005
I0403 07:24:19.121008 10121 solver.cpp:228] Iteration 915, loss = 0.258113
I0403 07:24:19.121959 10121 solver.cpp:244]     Train net output #0: loss = 0.258113 (* 1 = 0.258113 loss)
I0403 07:24:19.316594 10121 sgd_solver.cpp:106] Iteration 915, lr = 0.005
I0403 07:24:22.823920 10121 solver.cpp:228] Iteration 920, loss = 0.196436
I0403 07:24:22.824020 10121 solver.cpp:244]     Train net output #0: loss = 0.196436 (* 1 = 0.196436 loss)
I0403 07:24:23.005942 10121 sgd_solver.cpp:106] Iteration 920, lr = 0.005
I0403 07:24:26.504637 10121 solver.cpp:228] Iteration 925, loss = 0.205047
I0403 07:24:26.504735 10121 solver.cpp:244]     Train net output #0: loss = 0.205047 (* 1 = 0.205047 loss)
I0403 07:24:26.699072 10121 sgd_solver.cpp:106] Iteration 925, lr = 0.005
I0403 07:24:30.229975 10121 solver.cpp:228] Iteration 930, loss = 0.173672
I0403 07:24:30.230072 10121 solver.cpp:244]     Train net output #0: loss = 0.173672 (* 1 = 0.173672 loss)
I0403 07:24:30.412500 10121 sgd_solver.cpp:106] Iteration 930, lr = 0.005
I0403 07:24:34.047487 10121 solver.cpp:228] Iteration 935, loss = 0.385667
I0403 07:24:34.047571 10121 solver.cpp:244]     Train net output #0: loss = 0.385667 (* 1 = 0.385667 loss)
I0403 07:24:34.217025 10121 sgd_solver.cpp:106] Iteration 935, lr = 0.005
I0403 07:24:37.696383 10121 solver.cpp:228] Iteration 940, loss = 0.154497
I0403 07:24:37.696476 10121 solver.cpp:244]     Train net output #0: loss = 0.154497 (* 1 = 0.154497 loss)
I0403 07:24:37.894379 10121 sgd_solver.cpp:106] Iteration 940, lr = 0.005
I0403 07:24:41.482754 10121 solver.cpp:228] Iteration 945, loss = 0.313485
I0403 07:24:41.482839 10121 solver.cpp:244]     Train net output #0: loss = 0.313485 (* 1 = 0.313485 loss)
I0403 07:24:41.637217 10121 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 07:24:45.202994 10121 solver.cpp:228] Iteration 950, loss = 0.117379
I0403 07:24:45.203336 10121 solver.cpp:244]     Train net output #0: loss = 0.117379 (* 1 = 0.117379 loss)
I0403 07:24:45.401734 10121 sgd_solver.cpp:106] Iteration 950, lr = 0.005
I0403 07:24:48.828339 10121 solver.cpp:228] Iteration 955, loss = 0.172358
I0403 07:24:48.828430 10121 solver.cpp:244]     Train net output #0: loss = 0.172358 (* 1 = 0.172358 loss)
I0403 07:24:49.010841 10121 sgd_solver.cpp:106] Iteration 955, lr = 0.005
I0403 07:24:52.424897 10121 solver.cpp:228] Iteration 960, loss = 0.178978
I0403 07:24:52.424994 10121 solver.cpp:244]     Train net output #0: loss = 0.178978 (* 1 = 0.178978 loss)
I0403 07:24:52.610198 10121 sgd_solver.cpp:106] Iteration 960, lr = 0.005
I0403 07:24:56.008787 10121 solver.cpp:228] Iteration 965, loss = 0.106701
I0403 07:24:56.008880 10121 solver.cpp:244]     Train net output #0: loss = 0.106701 (* 1 = 0.106701 loss)
I0403 07:24:56.201169 10121 sgd_solver.cpp:106] Iteration 965, lr = 0.005
I0403 07:24:59.598518 10121 solver.cpp:228] Iteration 970, loss = 0.189899
I0403 07:24:59.598611 10121 solver.cpp:244]     Train net output #0: loss = 0.189899 (* 1 = 0.189899 loss)
I0403 07:24:59.791009 10121 sgd_solver.cpp:106] Iteration 970, lr = 0.005
I0403 07:25:00.500144 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_972.caffemodel
I0403 07:25:03.145006 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_972.solverstate
I0403 07:25:04.928056 10121 solver.cpp:337] Iteration 972, Testing net (#0)
I0403 07:26:42.818635 10121 solver.cpp:404]     Test net output #0: accuracy = 0.87659
I0403 07:26:42.818945 10121 solver.cpp:404]     Test net output #1: loss = 0.425243 (* 1 = 0.425243 loss)
I0403 07:26:45.456095 10121 solver.cpp:228] Iteration 975, loss = 0.206246
I0403 07:26:45.456192 10121 solver.cpp:244]     Train net output #0: loss = 0.206246 (* 1 = 0.206246 loss)
I0403 07:26:45.662122 10121 sgd_solver.cpp:106] Iteration 975, lr = 0.005
I0403 07:26:49.088201 10121 solver.cpp:228] Iteration 980, loss = 0.159837
I0403 07:26:49.088294 10121 solver.cpp:244]     Train net output #0: loss = 0.159837 (* 1 = 0.159837 loss)
I0403 07:26:49.265319 10121 sgd_solver.cpp:106] Iteration 980, lr = 0.005
I0403 07:26:52.735095 10121 solver.cpp:228] Iteration 985, loss = 0.190161
I0403 07:26:52.735190 10121 solver.cpp:244]     Train net output #0: loss = 0.190161 (* 1 = 0.190161 loss)
I0403 07:26:52.921747 10121 sgd_solver.cpp:106] Iteration 985, lr = 0.005
I0403 07:26:56.353355 10121 solver.cpp:228] Iteration 990, loss = 0.19184
I0403 07:26:56.353451 10121 solver.cpp:244]     Train net output #0: loss = 0.191839 (* 1 = 0.191839 loss)
I0403 07:26:56.541117 10121 sgd_solver.cpp:106] Iteration 990, lr = 0.005
I0403 07:26:59.938210 10121 solver.cpp:228] Iteration 995, loss = 0.222403
I0403 07:26:59.938316 10121 solver.cpp:244]     Train net output #0: loss = 0.222403 (* 1 = 0.222403 loss)
I0403 07:27:00.127588 10121 sgd_solver.cpp:106] Iteration 995, lr = 0.005
I0403 07:27:03.565507 10121 solver.cpp:228] Iteration 1000, loss = 0.230082
I0403 07:27:03.565588 10121 solver.cpp:244]     Train net output #0: loss = 0.230082 (* 1 = 0.230082 loss)
I0403 07:27:03.729857 10121 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0403 07:27:07.213943 10121 solver.cpp:228] Iteration 1005, loss = 0.280065
I0403 07:27:07.214030 10121 solver.cpp:244]     Train net output #0: loss = 0.280065 (* 1 = 0.280065 loss)
I0403 07:27:07.389685 10121 sgd_solver.cpp:106] Iteration 1005, lr = 0.005
I0403 07:27:10.867033 10121 solver.cpp:228] Iteration 1010, loss = 0.205745
I0403 07:27:10.867118 10121 solver.cpp:244]     Train net output #0: loss = 0.205745 (* 1 = 0.205745 loss)
I0403 07:27:11.048755 10121 sgd_solver.cpp:106] Iteration 1010, lr = 0.005
I0403 07:27:14.479110 10121 solver.cpp:228] Iteration 1015, loss = 0.156633
I0403 07:27:14.479424 10121 solver.cpp:244]     Train net output #0: loss = 0.156633 (* 1 = 0.156633 loss)
I0403 07:27:14.660591 10121 sgd_solver.cpp:106] Iteration 1015, lr = 0.005
I0403 07:27:18.054090 10121 solver.cpp:228] Iteration 1020, loss = 0.207755
I0403 07:27:18.054183 10121 solver.cpp:244]     Train net output #0: loss = 0.207755 (* 1 = 0.207755 loss)
I0403 07:27:18.250286 10121 sgd_solver.cpp:106] Iteration 1020, lr = 0.005
I0403 07:27:21.804708 10121 solver.cpp:228] Iteration 1025, loss = 0.148521
I0403 07:27:21.804793 10121 solver.cpp:244]     Train net output #0: loss = 0.148521 (* 1 = 0.148521 loss)
I0403 07:27:21.981008 10121 sgd_solver.cpp:106] Iteration 1025, lr = 0.005
I0403 07:27:25.437577 10121 solver.cpp:228] Iteration 1030, loss = 0.0950632
I0403 07:27:25.437672 10121 solver.cpp:244]     Train net output #0: loss = 0.0950631 (* 1 = 0.0950631 loss)
I0403 07:27:25.627408 10121 sgd_solver.cpp:106] Iteration 1030, lr = 0.005
I0403 07:27:29.109771 10121 solver.cpp:228] Iteration 1035, loss = 0.194902
I0403 07:27:29.109868 10121 solver.cpp:244]     Train net output #0: loss = 0.194902 (* 1 = 0.194902 loss)
I0403 07:27:29.295007 10121 sgd_solver.cpp:106] Iteration 1035, lr = 0.005
I0403 07:27:32.716351 10121 solver.cpp:228] Iteration 1040, loss = 0.178068
I0403 07:27:32.716447 10121 solver.cpp:244]     Train net output #0: loss = 0.178068 (* 1 = 0.178068 loss)
I0403 07:27:32.907483 10121 sgd_solver.cpp:106] Iteration 1040, lr = 0.005
I0403 07:27:36.316640 10121 solver.cpp:228] Iteration 1045, loss = 0.224944
I0403 07:27:36.316731 10121 solver.cpp:244]     Train net output #0: loss = 0.224944 (* 1 = 0.224944 loss)
I0403 07:27:36.510375 10121 sgd_solver.cpp:106] Iteration 1045, lr = 0.005
I0403 07:27:39.957957 10121 solver.cpp:228] Iteration 1050, loss = 0.13853
I0403 07:27:39.958050 10121 solver.cpp:244]     Train net output #0: loss = 0.13853 (* 1 = 0.13853 loss)
I0403 07:27:40.157188 10121 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 07:27:43.575870 10121 solver.cpp:228] Iteration 1055, loss = 0.30571
I0403 07:27:43.575966 10121 solver.cpp:244]     Train net output #0: loss = 0.30571 (* 1 = 0.30571 loss)
I0403 07:27:43.767330 10121 sgd_solver.cpp:106] Iteration 1055, lr = 0.005
I0403 07:27:47.183778 10121 solver.cpp:228] Iteration 1060, loss = 0.116692
I0403 07:27:47.184128 10121 solver.cpp:244]     Train net output #0: loss = 0.116692 (* 1 = 0.116692 loss)
I0403 07:27:47.365699 10121 sgd_solver.cpp:106] Iteration 1060, lr = 0.005
I0403 07:27:50.820693 10121 solver.cpp:228] Iteration 1065, loss = 0.271335
I0403 07:27:50.820776 10121 solver.cpp:244]     Train net output #0: loss = 0.271335 (* 1 = 0.271335 loss)
I0403 07:27:50.989567 10121 sgd_solver.cpp:106] Iteration 1065, lr = 0.005
I0403 07:27:54.426789 10121 solver.cpp:228] Iteration 1070, loss = 0.111808
I0403 07:27:54.426887 10121 solver.cpp:244]     Train net output #0: loss = 0.111808 (* 1 = 0.111808 loss)
I0403 07:27:54.611021 10121 sgd_solver.cpp:106] Iteration 1070, lr = 0.005
I0403 07:27:58.023895 10121 solver.cpp:228] Iteration 1075, loss = 0.153756
I0403 07:27:58.023988 10121 solver.cpp:244]     Train net output #0: loss = 0.153756 (* 1 = 0.153756 loss)
I0403 07:27:58.219463 10121 sgd_solver.cpp:106] Iteration 1075, lr = 0.005
I0403 07:28:01.125530 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1080.caffemodel
I0403 07:28:03.879446 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1080.solverstate
I0403 07:28:05.779835 10121 solver.cpp:337] Iteration 1080, Testing net (#0)
I0403 07:29:43.657317 10121 solver.cpp:404]     Test net output #0: accuracy = 0.879494
I0403 07:29:43.657635 10121 solver.cpp:404]     Test net output #1: loss = 0.425407 (* 1 = 0.425407 loss)
I0403 07:29:44.199002 10121 solver.cpp:228] Iteration 1080, loss = 0.152174
I0403 07:29:44.199093 10121 solver.cpp:244]     Train net output #0: loss = 0.152174 (* 1 = 0.152174 loss)
I0403 07:29:44.357450 10121 sgd_solver.cpp:106] Iteration 1080, lr = 0.005
I0403 07:29:47.925022 10121 solver.cpp:228] Iteration 1085, loss = 0.25493
I0403 07:29:47.925112 10121 solver.cpp:244]     Train net output #0: loss = 0.25493 (* 1 = 0.25493 loss)
I0403 07:29:48.111446 10121 sgd_solver.cpp:106] Iteration 1085, lr = 0.0005
I0403 07:29:51.588218 10121 solver.cpp:228] Iteration 1090, loss = 0.394432
I0403 07:29:51.588315 10121 solver.cpp:244]     Train net output #0: loss = 0.394432 (* 1 = 0.394432 loss)
I0403 07:29:51.771019 10121 sgd_solver.cpp:106] Iteration 1090, lr = 0.0005
I0403 07:29:55.186570 10121 solver.cpp:228] Iteration 1095, loss = 0.299823
I0403 07:29:55.186669 10121 solver.cpp:244]     Train net output #0: loss = 0.299823 (* 1 = 0.299823 loss)
I0403 07:29:55.402206 10121 sgd_solver.cpp:106] Iteration 1095, lr = 0.0005
I0403 07:29:58.848405 10121 solver.cpp:228] Iteration 1100, loss = 0.253409
I0403 07:29:58.848498 10121 solver.cpp:244]     Train net output #0: loss = 0.253408 (* 1 = 0.253408 loss)
I0403 07:29:59.082336 10121 sgd_solver.cpp:106] Iteration 1100, lr = 0.0005
I0403 07:30:02.575796 10121 solver.cpp:228] Iteration 1105, loss = 0.242128
I0403 07:30:02.575891 10121 solver.cpp:244]     Train net output #0: loss = 0.242128 (* 1 = 0.242128 loss)
I0403 07:30:02.758040 10121 sgd_solver.cpp:106] Iteration 1105, lr = 0.0005
I0403 07:30:06.193837 10121 solver.cpp:228] Iteration 1110, loss = 0.121354
I0403 07:30:06.193936 10121 solver.cpp:244]     Train net output #0: loss = 0.121354 (* 1 = 0.121354 loss)
I0403 07:30:06.376425 10121 sgd_solver.cpp:106] Iteration 1110, lr = 0.0005
I0403 07:30:09.925307 10121 solver.cpp:228] Iteration 1115, loss = 0.112389
I0403 07:30:09.925400 10121 solver.cpp:244]     Train net output #0: loss = 0.112389 (* 1 = 0.112389 loss)
I0403 07:30:10.117635 10121 sgd_solver.cpp:106] Iteration 1115, lr = 0.0005
I0403 07:30:13.583618 10121 solver.cpp:228] Iteration 1120, loss = 0.165315
I0403 07:30:13.583711 10121 solver.cpp:244]     Train net output #0: loss = 0.165314 (* 1 = 0.165314 loss)
I0403 07:30:13.771353 10121 sgd_solver.cpp:106] Iteration 1120, lr = 0.0005
I0403 07:30:17.203265 10121 solver.cpp:228] Iteration 1125, loss = 0.118166
I0403 07:30:17.203351 10121 solver.cpp:244]     Train net output #0: loss = 0.118166 (* 1 = 0.118166 loss)
I0403 07:30:17.378057 10121 sgd_solver.cpp:106] Iteration 1125, lr = 0.0005
I0403 07:30:20.903754 10121 solver.cpp:228] Iteration 1130, loss = 0.149943
I0403 07:30:20.903849 10121 solver.cpp:244]     Train net output #0: loss = 0.149943 (* 1 = 0.149943 loss)
I0403 07:30:21.086565 10121 sgd_solver.cpp:106] Iteration 1130, lr = 0.0005
I0403 07:30:24.496476 10121 solver.cpp:228] Iteration 1135, loss = 0.0905516
I0403 07:30:24.496572 10121 solver.cpp:244]     Train net output #0: loss = 0.0905515 (* 1 = 0.0905515 loss)
I0403 07:30:24.695840 10121 sgd_solver.cpp:106] Iteration 1135, lr = 0.0005
I0403 07:30:28.192252 10121 solver.cpp:228] Iteration 1140, loss = 0.126711
I0403 07:30:28.192348 10121 solver.cpp:244]     Train net output #0: loss = 0.126711 (* 1 = 0.126711 loss)
I0403 07:30:28.375849 10121 sgd_solver.cpp:106] Iteration 1140, lr = 0.0005
I0403 07:30:31.809283 10121 solver.cpp:228] Iteration 1145, loss = 0.0953682
I0403 07:30:31.809375 10121 solver.cpp:244]     Train net output #0: loss = 0.0953681 (* 1 = 0.0953681 loss)
I0403 07:30:32.012051 10121 sgd_solver.cpp:106] Iteration 1145, lr = 0.0005
I0403 07:30:35.516342 10121 solver.cpp:228] Iteration 1150, loss = 0.0915373
I0403 07:30:35.516427 10121 solver.cpp:244]     Train net output #0: loss = 0.0915372 (* 1 = 0.0915372 loss)
I0403 07:30:35.678059 10121 sgd_solver.cpp:106] Iteration 1150, lr = 0.0005
I0403 07:30:39.188144 10121 solver.cpp:228] Iteration 1155, loss = 0.187166
I0403 07:30:39.188248 10121 solver.cpp:244]     Train net output #0: loss = 0.187166 (* 1 = 0.187166 loss)
I0403 07:30:39.394836 10121 sgd_solver.cpp:106] Iteration 1155, lr = 0.0005
I0403 07:30:42.824367 10121 solver.cpp:228] Iteration 1160, loss = 0.170255
I0403 07:30:42.824461 10121 solver.cpp:244]     Train net output #0: loss = 0.170255 (* 1 = 0.170255 loss)
I0403 07:30:43.008039 10121 sgd_solver.cpp:106] Iteration 1160, lr = 0.0005
I0403 07:30:46.485112 10121 solver.cpp:228] Iteration 1165, loss = 0.126464
I0403 07:30:46.485433 10121 solver.cpp:244]     Train net output #0: loss = 0.126463 (* 1 = 0.126463 loss)
I0403 07:30:46.666121 10121 sgd_solver.cpp:106] Iteration 1165, lr = 0.0005
I0403 07:30:50.229033 10121 solver.cpp:228] Iteration 1170, loss = 0.0701384
I0403 07:30:50.229128 10121 solver.cpp:244]     Train net output #0: loss = 0.0701382 (* 1 = 0.0701382 loss)
I0403 07:30:50.428153 10121 sgd_solver.cpp:106] Iteration 1170, lr = 0.0005
I0403 07:30:53.828753 10121 solver.cpp:228] Iteration 1175, loss = 0.105264
I0403 07:30:53.828850 10121 solver.cpp:244]     Train net output #0: loss = 0.105263 (* 1 = 0.105263 loss)
I0403 07:30:54.049850 10121 sgd_solver.cpp:106] Iteration 1175, lr = 0.0005
I0403 07:30:57.487155 10121 solver.cpp:228] Iteration 1180, loss = 0.132536
I0403 07:30:57.487251 10121 solver.cpp:244]     Train net output #0: loss = 0.132536 (* 1 = 0.132536 loss)
I0403 07:30:57.683477 10121 sgd_solver.cpp:106] Iteration 1180, lr = 0.0005
I0403 07:31:01.163903 10121 solver.cpp:228] Iteration 1185, loss = 0.121946
I0403 07:31:01.164000 10121 solver.cpp:244]     Train net output #0: loss = 0.121946 (* 1 = 0.121946 loss)
I0403 07:31:01.350386 10121 sgd_solver.cpp:106] Iteration 1185, lr = 0.0005
I0403 07:31:02.809779 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1188.caffemodel
I0403 07:31:05.545931 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1188.solverstate
I0403 07:31:07.481947 10121 solver.cpp:337] Iteration 1188, Testing net (#0)
I0403 07:32:45.347892 10121 solver.cpp:404]     Test net output #0: accuracy = 0.900876
I0403 07:32:45.348204 10121 solver.cpp:404]     Test net output #1: loss = 0.358909 (* 1 = 0.358909 loss)
I0403 07:32:47.300212 10121 solver.cpp:228] Iteration 1190, loss = 0.0630084
I0403 07:32:47.300299 10121 solver.cpp:244]     Train net output #0: loss = 0.0630083 (* 1 = 0.0630083 loss)
I0403 07:32:47.468720 10121 sgd_solver.cpp:106] Iteration 1190, lr = 0.0005
I0403 07:32:50.999131 10121 solver.cpp:228] Iteration 1195, loss = 0.162278
I0403 07:32:50.999228 10121 solver.cpp:244]     Train net output #0: loss = 0.162278 (* 1 = 0.162278 loss)
I0403 07:32:51.185537 10121 sgd_solver.cpp:106] Iteration 1195, lr = 0.0005
I0403 07:32:54.645530 10121 solver.cpp:228] Iteration 1200, loss = 0.06075
I0403 07:32:54.645629 10121 solver.cpp:244]     Train net output #0: loss = 0.0607499 (* 1 = 0.0607499 loss)
I0403 07:32:54.828757 10121 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0403 07:32:58.242666 10121 solver.cpp:228] Iteration 1205, loss = 0.112119
I0403 07:32:58.242761 10121 solver.cpp:244]     Train net output #0: loss = 0.112119 (* 1 = 0.112119 loss)
I0403 07:32:58.440135 10121 sgd_solver.cpp:106] Iteration 1205, lr = 0.0005
I0403 07:33:01.852877 10121 solver.cpp:228] Iteration 1210, loss = 0.0806351
I0403 07:33:01.852972 10121 solver.cpp:244]     Train net output #0: loss = 0.080635 (* 1 = 0.080635 loss)
I0403 07:33:02.059762 10121 sgd_solver.cpp:106] Iteration 1210, lr = 0.0005
I0403 07:33:05.614544 10121 solver.cpp:228] Iteration 1215, loss = 0.100404
I0403 07:33:05.614631 10121 solver.cpp:244]     Train net output #0: loss = 0.100404 (* 1 = 0.100404 loss)
I0403 07:33:05.787230 10121 sgd_solver.cpp:106] Iteration 1215, lr = 0.0005
I0403 07:33:09.309293 10121 solver.cpp:228] Iteration 1220, loss = 0.0391695
I0403 07:33:09.309389 10121 solver.cpp:244]     Train net output #0: loss = 0.0391694 (* 1 = 0.0391694 loss)
I0403 07:33:09.496192 10121 sgd_solver.cpp:106] Iteration 1220, lr = 0.0005
I0403 07:33:13.004840 10121 solver.cpp:228] Iteration 1225, loss = 0.037997
I0403 07:33:13.004936 10121 solver.cpp:244]     Train net output #0: loss = 0.0379969 (* 1 = 0.0379969 loss)
I0403 07:33:13.195053 10121 sgd_solver.cpp:106] Iteration 1225, lr = 0.0005
I0403 07:33:16.633085 10121 solver.cpp:228] Iteration 1230, loss = 0.097068
I0403 07:33:16.633417 10121 solver.cpp:244]     Train net output #0: loss = 0.0970679 (* 1 = 0.0970679 loss)
I0403 07:33:16.815433 10121 sgd_solver.cpp:106] Iteration 1230, lr = 0.0005
I0403 07:33:20.233937 10121 solver.cpp:228] Iteration 1235, loss = 0.0763588
I0403 07:33:20.234036 10121 solver.cpp:244]     Train net output #0: loss = 0.0763586 (* 1 = 0.0763586 loss)
I0403 07:33:20.424990 10121 sgd_solver.cpp:106] Iteration 1235, lr = 0.0005
I0403 07:33:23.889014 10121 solver.cpp:228] Iteration 1240, loss = 0.0525883
I0403 07:33:23.889103 10121 solver.cpp:244]     Train net output #0: loss = 0.0525881 (* 1 = 0.0525881 loss)
I0403 07:33:24.098325 10121 sgd_solver.cpp:106] Iteration 1240, lr = 0.0005
I0403 07:33:27.557102 10121 solver.cpp:228] Iteration 1245, loss = 0.0792343
I0403 07:33:27.557196 10121 solver.cpp:244]     Train net output #0: loss = 0.0792341 (* 1 = 0.0792341 loss)
I0403 07:33:27.769345 10121 sgd_solver.cpp:106] Iteration 1245, lr = 0.0005
I0403 07:33:31.244755 10121 solver.cpp:228] Iteration 1250, loss = 0.0741913
I0403 07:33:31.244851 10121 solver.cpp:244]     Train net output #0: loss = 0.0741912 (* 1 = 0.0741912 loss)
I0403 07:33:31.427732 10121 sgd_solver.cpp:106] Iteration 1250, lr = 0.0005
I0403 07:33:34.885165 10121 solver.cpp:228] Iteration 1255, loss = 0.0412262
I0403 07:33:34.885265 10121 solver.cpp:244]     Train net output #0: loss = 0.0412261 (* 1 = 0.0412261 loss)
I0403 07:33:35.067204 10121 sgd_solver.cpp:106] Iteration 1255, lr = 0.0005
I0403 07:33:38.623457 10121 solver.cpp:228] Iteration 1260, loss = 0.191422
I0403 07:33:38.623540 10121 solver.cpp:244]     Train net output #0: loss = 0.191422 (* 1 = 0.191422 loss)
I0403 07:33:38.766047 10121 sgd_solver.cpp:106] Iteration 1260, lr = 0.0005
I0403 07:33:42.293843 10121 solver.cpp:228] Iteration 1265, loss = 0.078024
I0403 07:33:42.293941 10121 solver.cpp:244]     Train net output #0: loss = 0.0780238 (* 1 = 0.0780238 loss)
I0403 07:33:42.481607 10121 sgd_solver.cpp:106] Iteration 1265, lr = 0.0005
I0403 07:33:45.928205 10121 solver.cpp:228] Iteration 1270, loss = 0.0530934
I0403 07:33:45.928308 10121 solver.cpp:244]     Train net output #0: loss = 0.0530933 (* 1 = 0.0530933 loss)
I0403 07:33:46.129998 10121 sgd_solver.cpp:106] Iteration 1270, lr = 0.0005
I0403 07:33:49.641034 10121 solver.cpp:228] Iteration 1275, loss = 0.0476627
I0403 07:33:49.641382 10121 solver.cpp:244]     Train net output #0: loss = 0.0476625 (* 1 = 0.0476625 loss)
I0403 07:33:49.816771 10121 sgd_solver.cpp:106] Iteration 1275, lr = 0.0005
I0403 07:33:53.373455 10121 solver.cpp:228] Iteration 1280, loss = 0.0373009
I0403 07:33:53.373539 10121 solver.cpp:244]     Train net output #0: loss = 0.0373008 (* 1 = 0.0373008 loss)
I0403 07:33:53.541326 10121 sgd_solver.cpp:106] Iteration 1280, lr = 0.0005
I0403 07:33:57.003763 10121 solver.cpp:228] Iteration 1285, loss = 0.095898
I0403 07:33:57.003859 10121 solver.cpp:244]     Train net output #0: loss = 0.0958978 (* 1 = 0.0958978 loss)
I0403 07:33:57.187326 10121 sgd_solver.cpp:106] Iteration 1285, lr = 0.0005
I0403 07:34:00.657727 10121 solver.cpp:228] Iteration 1290, loss = 0.0659597
I0403 07:34:00.657824 10121 solver.cpp:244]     Train net output #0: loss = 0.0659595 (* 1 = 0.0659595 loss)
I0403 07:34:00.845176 10121 sgd_solver.cpp:106] Iteration 1290, lr = 0.0005
I0403 07:34:04.334504 10121 solver.cpp:228] Iteration 1295, loss = 0.0927237
I0403 07:34:04.334600 10121 solver.cpp:244]     Train net output #0: loss = 0.0927236 (* 1 = 0.0927236 loss)
I0403 07:34:04.543340 10121 sgd_solver.cpp:106] Iteration 1295, lr = 0.0005
I0403 07:34:04.543570 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1296.caffemodel
I0403 07:34:07.296568 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1296.solverstate
I0403 07:34:09.207262 10121 solver.cpp:337] Iteration 1296, Testing net (#0)
I0403 07:35:47.073359 10121 solver.cpp:404]     Test net output #0: accuracy = 0.902972
I0403 07:35:47.073673 10121 solver.cpp:404]     Test net output #1: loss = 0.364287 (* 1 = 0.364287 loss)
I0403 07:35:50.473598 10121 solver.cpp:228] Iteration 1300, loss = 0.0622117
I0403 07:35:50.473692 10121 solver.cpp:244]     Train net output #0: loss = 0.0622115 (* 1 = 0.0622115 loss)
I0403 07:35:50.689115 10121 sgd_solver.cpp:106] Iteration 1300, lr = 0.0005
I0403 07:35:54.094316 10121 solver.cpp:228] Iteration 1305, loss = 0.0862641
I0403 07:35:54.094403 10121 solver.cpp:244]     Train net output #0: loss = 0.0862639 (* 1 = 0.0862639 loss)
I0403 07:35:54.247393 10121 sgd_solver.cpp:106] Iteration 1305, lr = 0.0005
I0403 07:35:57.755111 10121 solver.cpp:228] Iteration 1310, loss = 0.109659
I0403 07:35:57.755208 10121 solver.cpp:244]     Train net output #0: loss = 0.109659 (* 1 = 0.109659 loss)
I0403 07:35:57.996152 10121 sgd_solver.cpp:106] Iteration 1310, lr = 0.0005
I0403 07:36:01.395488 10121 solver.cpp:228] Iteration 1315, loss = 0.0553151
I0403 07:36:01.395582 10121 solver.cpp:244]     Train net output #0: loss = 0.055315 (* 1 = 0.055315 loss)
I0403 07:36:01.577958 10121 sgd_solver.cpp:106] Iteration 1315, lr = 0.0005
I0403 07:36:05.180956 10121 solver.cpp:228] Iteration 1320, loss = 0.067902
I0403 07:36:05.181044 10121 solver.cpp:244]     Train net output #0: loss = 0.0679019 (* 1 = 0.0679019 loss)
I0403 07:36:05.311381 10121 sgd_solver.cpp:106] Iteration 1320, lr = 0.0005
I0403 07:36:08.891232 10121 solver.cpp:228] Iteration 1325, loss = 0.116884
I0403 07:36:08.891332 10121 solver.cpp:244]     Train net output #0: loss = 0.116884 (* 1 = 0.116884 loss)
I0403 07:36:09.092854 10121 sgd_solver.cpp:106] Iteration 1325, lr = 0.0005
I0403 07:36:12.673781 10121 solver.cpp:228] Iteration 1330, loss = 0.0930183
I0403 07:36:12.673868 10121 solver.cpp:244]     Train net output #0: loss = 0.0930182 (* 1 = 0.0930182 loss)
I0403 07:36:12.852179 10121 sgd_solver.cpp:106] Iteration 1330, lr = 0.0005
I0403 07:36:16.364063 10121 solver.cpp:228] Iteration 1335, loss = 0.111811
I0403 07:36:16.364150 10121 solver.cpp:244]     Train net output #0: loss = 0.111811 (* 1 = 0.111811 loss)
I0403 07:36:16.539777 10121 sgd_solver.cpp:106] Iteration 1335, lr = 0.0005
I0403 07:36:20.014641 10121 solver.cpp:228] Iteration 1340, loss = 0.0468116
I0403 07:36:20.014993 10121 solver.cpp:244]     Train net output #0: loss = 0.0468114 (* 1 = 0.0468114 loss)
I0403 07:36:20.216200 10121 sgd_solver.cpp:106] Iteration 1340, lr = 0.0005
I0403 07:36:23.628515 10121 solver.cpp:228] Iteration 1345, loss = 0.0483036
I0403 07:36:23.628612 10121 solver.cpp:244]     Train net output #0: loss = 0.0483035 (* 1 = 0.0483035 loss)
I0403 07:36:23.816498 10121 sgd_solver.cpp:106] Iteration 1345, lr = 0.0005
I0403 07:36:27.239557 10121 solver.cpp:228] Iteration 1350, loss = 0.0876074
I0403 07:36:27.239651 10121 solver.cpp:244]     Train net output #0: loss = 0.0876072 (* 1 = 0.0876072 loss)
I0403 07:36:27.452033 10121 sgd_solver.cpp:106] Iteration 1350, lr = 0.0005
I0403 07:36:30.867939 10121 solver.cpp:228] Iteration 1355, loss = 0.0556979
I0403 07:36:30.868036 10121 solver.cpp:244]     Train net output #0: loss = 0.0556977 (* 1 = 0.0556977 loss)
I0403 07:36:31.060554 10121 sgd_solver.cpp:106] Iteration 1355, lr = 0.0005
I0403 07:36:34.533571 10121 solver.cpp:228] Iteration 1360, loss = 0.0823445
I0403 07:36:34.533658 10121 solver.cpp:244]     Train net output #0: loss = 0.0823444 (* 1 = 0.0823444 loss)
I0403 07:36:34.702759 10121 sgd_solver.cpp:106] Iteration 1360, lr = 0.0005
I0403 07:36:38.215204 10121 solver.cpp:228] Iteration 1365, loss = 0.124083
I0403 07:36:38.215304 10121 solver.cpp:244]     Train net output #0: loss = 0.124083 (* 1 = 0.124083 loss)
I0403 07:36:38.432365 10121 sgd_solver.cpp:106] Iteration 1365, lr = 0.0005
I0403 07:36:41.876026 10121 solver.cpp:228] Iteration 1370, loss = 0.0805942
I0403 07:36:41.876114 10121 solver.cpp:244]     Train net output #0: loss = 0.080594 (* 1 = 0.080594 loss)
I0403 07:36:42.103458 10121 sgd_solver.cpp:106] Iteration 1370, lr = 0.0005
I0403 07:36:45.529475 10121 solver.cpp:228] Iteration 1375, loss = 0.0375256
I0403 07:36:45.529568 10121 solver.cpp:244]     Train net output #0: loss = 0.0375254 (* 1 = 0.0375254 loss)
I0403 07:36:45.717263 10121 sgd_solver.cpp:106] Iteration 1375, lr = 0.0005
I0403 07:36:49.174885 10121 solver.cpp:228] Iteration 1380, loss = 0.0618993
I0403 07:36:49.174969 10121 solver.cpp:244]     Train net output #0: loss = 0.0618992 (* 1 = 0.0618992 loss)
I0403 07:36:49.355864 10121 sgd_solver.cpp:106] Iteration 1380, lr = 0.0005
I0403 07:36:52.773886 10121 solver.cpp:228] Iteration 1385, loss = 0.0529561
I0403 07:36:52.774216 10121 solver.cpp:244]     Train net output #0: loss = 0.0529559 (* 1 = 0.0529559 loss)
I0403 07:36:52.950790 10121 sgd_solver.cpp:106] Iteration 1385, lr = 0.0005
I0403 07:36:56.395464 10121 solver.cpp:228] Iteration 1390, loss = 0.151549
I0403 07:36:56.395565 10121 solver.cpp:244]     Train net output #0: loss = 0.151549 (* 1 = 0.151549 loss)
I0403 07:36:56.594812 10121 sgd_solver.cpp:106] Iteration 1390, lr = 0.0005
I0403 07:37:00.009765 10121 solver.cpp:228] Iteration 1395, loss = 0.0419166
I0403 07:37:00.009855 10121 solver.cpp:244]     Train net output #0: loss = 0.0419165 (* 1 = 0.0419165 loss)
I0403 07:37:00.209771 10121 sgd_solver.cpp:106] Iteration 1395, lr = 0.0005
I0403 07:37:03.685667 10121 solver.cpp:228] Iteration 1400, loss = 0.0884142
I0403 07:37:03.685751 10121 solver.cpp:244]     Train net output #0: loss = 0.088414 (* 1 = 0.088414 loss)
I0403 07:37:03.866365 10121 sgd_solver.cpp:106] Iteration 1400, lr = 0.0005
I0403 07:37:06.048283 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1404.caffemodel
I0403 07:37:08.874789 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1404.solverstate
I0403 07:37:10.766537 10121 solver.cpp:337] Iteration 1404, Testing net (#0)
I0403 07:38:48.649277 10121 solver.cpp:404]     Test net output #0: accuracy = 0.903457
I0403 07:38:48.650990 10121 solver.cpp:404]     Test net output #1: loss = 0.370434 (* 1 = 0.370434 loss)
I0403 07:38:49.923225 10121 solver.cpp:228] Iteration 1405, loss = 0.127141
I0403 07:38:49.923313 10121 solver.cpp:244]     Train net output #0: loss = 0.127141 (* 1 = 0.127141 loss)
I0403 07:38:50.099913 10121 sgd_solver.cpp:106] Iteration 1405, lr = 0.0005
I0403 07:38:53.534780 10121 solver.cpp:228] Iteration 1410, loss = 0.0494215
I0403 07:38:53.534873 10121 solver.cpp:244]     Train net output #0: loss = 0.0494214 (* 1 = 0.0494214 loss)
I0403 07:38:53.729535 10121 sgd_solver.cpp:106] Iteration 1410, lr = 0.0005
I0403 07:38:57.188737 10121 solver.cpp:228] Iteration 1415, loss = 0.0725852
I0403 07:38:57.188832 10121 solver.cpp:244]     Train net output #0: loss = 0.072585 (* 1 = 0.072585 loss)
I0403 07:38:57.371018 10121 sgd_solver.cpp:106] Iteration 1415, lr = 0.0005
I0403 07:39:00.817615 10121 solver.cpp:228] Iteration 1420, loss = 0.043785
I0403 07:39:00.817709 10121 solver.cpp:244]     Train net output #0: loss = 0.0437848 (* 1 = 0.0437848 loss)
I0403 07:39:01.027673 10121 sgd_solver.cpp:106] Iteration 1420, lr = 0.0005
I0403 07:39:04.455008 10121 solver.cpp:228] Iteration 1425, loss = 0.0849037
I0403 07:39:04.455101 10121 solver.cpp:244]     Train net output #0: loss = 0.0849035 (* 1 = 0.0849035 loss)
I0403 07:39:04.667783 10121 sgd_solver.cpp:106] Iteration 1425, lr = 0.0005
I0403 07:39:08.124590 10121 solver.cpp:228] Iteration 1430, loss = 0.0684624
I0403 07:39:08.124677 10121 solver.cpp:244]     Train net output #0: loss = 0.0684622 (* 1 = 0.0684622 loss)
I0403 07:39:08.298156 10121 sgd_solver.cpp:106] Iteration 1430, lr = 0.0005
I0403 07:39:11.745899 10121 solver.cpp:228] Iteration 1435, loss = 0.0520895
I0403 07:39:11.745992 10121 solver.cpp:244]     Train net output #0: loss = 0.0520894 (* 1 = 0.0520894 loss)
I0403 07:39:12.012588 10121 sgd_solver.cpp:106] Iteration 1435, lr = 0.0005
I0403 07:39:15.469977 10121 solver.cpp:228] Iteration 1440, loss = 0.0167146
I0403 07:39:15.470073 10121 solver.cpp:244]     Train net output #0: loss = 0.0167144 (* 1 = 0.0167144 loss)
I0403 07:39:15.752893 10121 sgd_solver.cpp:106] Iteration 1440, lr = 0.0005
I0403 07:39:19.171746 10121 solver.cpp:228] Iteration 1445, loss = 0.0769233
I0403 07:39:19.172071 10121 solver.cpp:244]     Train net output #0: loss = 0.0769231 (* 1 = 0.0769231 loss)
I0403 07:39:19.385561 10121 sgd_solver.cpp:106] Iteration 1445, lr = 0.0005
I0403 07:39:22.817744 10121 solver.cpp:228] Iteration 1450, loss = 0.0506157
I0403 07:39:22.817838 10121 solver.cpp:244]     Train net output #0: loss = 0.0506155 (* 1 = 0.0506155 loss)
I0403 07:39:23.016022 10121 sgd_solver.cpp:106] Iteration 1450, lr = 0.0005
I0403 07:39:26.473902 10121 solver.cpp:228] Iteration 1455, loss = 0.0857157
I0403 07:39:26.473999 10121 solver.cpp:244]     Train net output #0: loss = 0.0857155 (* 1 = 0.0857155 loss)
I0403 07:39:26.713263 10121 sgd_solver.cpp:106] Iteration 1455, lr = 0.0005
I0403 07:39:30.167532 10121 solver.cpp:228] Iteration 1460, loss = 0.031632
I0403 07:39:30.167629 10121 solver.cpp:244]     Train net output #0: loss = 0.0316318 (* 1 = 0.0316318 loss)
I0403 07:39:30.367209 10121 sgd_solver.cpp:106] Iteration 1460, lr = 0.0005
I0403 07:39:33.826856 10121 solver.cpp:228] Iteration 1465, loss = 0.112437
I0403 07:39:33.826949 10121 solver.cpp:244]     Train net output #0: loss = 0.112437 (* 1 = 0.112437 loss)
I0403 07:39:34.022462 10121 sgd_solver.cpp:106] Iteration 1465, lr = 0.0005
I0403 07:39:37.513775 10121 solver.cpp:228] Iteration 1470, loss = 0.081933
I0403 07:39:37.513870 10121 solver.cpp:244]     Train net output #0: loss = 0.0819329 (* 1 = 0.0819329 loss)
I0403 07:39:37.714102 10121 sgd_solver.cpp:106] Iteration 1470, lr = 0.0005
I0403 07:39:41.175603 10121 solver.cpp:228] Iteration 1475, loss = 0.0239104
I0403 07:39:41.175698 10121 solver.cpp:244]     Train net output #0: loss = 0.0239102 (* 1 = 0.0239102 loss)
I0403 07:39:41.369521 10121 sgd_solver.cpp:106] Iteration 1475, lr = 0.0005
I0403 07:39:44.820554 10121 solver.cpp:228] Iteration 1480, loss = 0.125122
I0403 07:39:44.821797 10121 solver.cpp:244]     Train net output #0: loss = 0.125121 (* 1 = 0.125121 loss)
I0403 07:39:44.948107 10121 sgd_solver.cpp:106] Iteration 1480, lr = 0.0005
I0403 07:39:48.473971 10121 solver.cpp:228] Iteration 1485, loss = 0.112666
I0403 07:39:48.474066 10121 solver.cpp:244]     Train net output #0: loss = 0.112666 (* 1 = 0.112666 loss)
I0403 07:39:48.670176 10121 sgd_solver.cpp:106] Iteration 1485, lr = 0.0005
I0403 07:39:52.085288 10121 solver.cpp:228] Iteration 1490, loss = 0.0367252
I0403 07:39:52.085613 10121 solver.cpp:244]     Train net output #0: loss = 0.036725 (* 1 = 0.036725 loss)
I0403 07:39:52.291493 10121 sgd_solver.cpp:106] Iteration 1490, lr = 0.0005
I0403 07:39:55.774374 10121 solver.cpp:228] Iteration 1495, loss = 0.0854075
I0403 07:39:55.774458 10121 solver.cpp:244]     Train net output #0: loss = 0.0854073 (* 1 = 0.0854073 loss)
I0403 07:39:55.935923 10121 sgd_solver.cpp:106] Iteration 1495, lr = 0.0005
I0403 07:39:59.643892 10121 solver.cpp:228] Iteration 1500, loss = 0.0616828
I0403 07:39:59.643976 10121 solver.cpp:244]     Train net output #0: loss = 0.0616826 (* 1 = 0.0616826 loss)
I0403 07:39:59.810947 10121 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0403 07:40:03.307488 10121 solver.cpp:228] Iteration 1505, loss = 0.115969
I0403 07:40:03.307585 10121 solver.cpp:244]     Train net output #0: loss = 0.115969 (* 1 = 0.115969 loss)
I0403 07:40:03.491622 10121 sgd_solver.cpp:106] Iteration 1505, lr = 0.0005
I0403 07:40:07.079812 10121 solver.cpp:228] Iteration 1510, loss = 0.069313
I0403 07:40:07.079897 10121 solver.cpp:244]     Train net output #0: loss = 0.0693129 (* 1 = 0.0693129 loss)
I0403 07:40:07.225646 10121 sgd_solver.cpp:106] Iteration 1510, lr = 0.0005
I0403 07:40:08.017861 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1512.caffemodel
I0403 07:40:10.812655 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1512.solverstate
I0403 07:40:12.722739 10121 solver.cpp:337] Iteration 1512, Testing net (#0)
I0403 07:41:50.594487 10121 solver.cpp:404]     Test net output #0: accuracy = 0.90613
I0403 07:41:50.594830 10121 solver.cpp:404]     Test net output #1: loss = 0.362028 (* 1 = 0.362028 loss)
I0403 07:41:53.363838 10121 solver.cpp:228] Iteration 1515, loss = 0.050032
I0403 07:41:53.363925 10121 solver.cpp:244]     Train net output #0: loss = 0.0500318 (* 1 = 0.0500318 loss)
I0403 07:41:53.537365 10121 sgd_solver.cpp:106] Iteration 1515, lr = 0.0005
I0403 07:41:56.982921 10121 solver.cpp:228] Iteration 1520, loss = 0.0907958
I0403 07:41:56.983008 10121 solver.cpp:244]     Train net output #0: loss = 0.0907957 (* 1 = 0.0907957 loss)
I0403 07:41:57.161834 10121 sgd_solver.cpp:106] Iteration 1520, lr = 0.0005
I0403 07:42:00.578766 10121 solver.cpp:228] Iteration 1525, loss = 0.0511197
I0403 07:42:00.578860 10121 solver.cpp:244]     Train net output #0: loss = 0.0511195 (* 1 = 0.0511195 loss)
I0403 07:42:00.783529 10121 sgd_solver.cpp:106] Iteration 1525, lr = 0.0005
I0403 07:42:04.202164 10121 solver.cpp:228] Iteration 1530, loss = 0.0736542
I0403 07:42:04.202266 10121 solver.cpp:244]     Train net output #0: loss = 0.0736541 (* 1 = 0.0736541 loss)
I0403 07:42:04.398792 10121 sgd_solver.cpp:106] Iteration 1530, lr = 0.0005
I0403 07:42:07.902328 10121 solver.cpp:228] Iteration 1535, loss = 0.0557368
I0403 07:42:07.902421 10121 solver.cpp:244]     Train net output #0: loss = 0.0557366 (* 1 = 0.0557366 loss)
I0403 07:42:08.117044 10121 sgd_solver.cpp:106] Iteration 1535, lr = 0.0005
I0403 07:42:11.566241 10121 solver.cpp:228] Iteration 1540, loss = 0.0188413
I0403 07:42:11.566346 10121 solver.cpp:244]     Train net output #0: loss = 0.0188412 (* 1 = 0.0188412 loss)
I0403 07:42:11.752324 10121 sgd_solver.cpp:106] Iteration 1540, lr = 0.0005
I0403 07:42:15.182772 10121 solver.cpp:228] Iteration 1545, loss = 0.0542697
I0403 07:42:15.183851 10121 solver.cpp:244]     Train net output #0: loss = 0.0542695 (* 1 = 0.0542695 loss)
I0403 07:42:15.368283 10121 sgd_solver.cpp:106] Iteration 1545, lr = 0.0005
I0403 07:42:18.817803 10121 solver.cpp:228] Iteration 1550, loss = 0.0268246
I0403 07:42:18.817893 10121 solver.cpp:244]     Train net output #0: loss = 0.0268245 (* 1 = 0.0268245 loss)
I0403 07:42:19.007946 10121 sgd_solver.cpp:106] Iteration 1550, lr = 0.0005
I0403 07:42:22.512573 10121 solver.cpp:228] Iteration 1555, loss = 0.0943982
I0403 07:42:22.512938 10121 solver.cpp:244]     Train net output #0: loss = 0.094398 (* 1 = 0.094398 loss)
I0403 07:42:22.722095 10121 sgd_solver.cpp:106] Iteration 1555, lr = 0.0005
I0403 07:42:26.352612 10121 solver.cpp:228] Iteration 1560, loss = 0.0469632
I0403 07:42:26.352699 10121 solver.cpp:244]     Train net output #0: loss = 0.046963 (* 1 = 0.046963 loss)
I0403 07:42:26.503849 10121 sgd_solver.cpp:106] Iteration 1560, lr = 0.0005
I0403 07:42:29.993680 10121 solver.cpp:228] Iteration 1565, loss = 0.0305165
I0403 07:42:29.993772 10121 solver.cpp:244]     Train net output #0: loss = 0.0305164 (* 1 = 0.0305164 loss)
I0403 07:42:30.183814 10121 sgd_solver.cpp:106] Iteration 1565, lr = 0.0005
I0403 07:42:33.667544 10121 solver.cpp:228] Iteration 1570, loss = 0.03754
I0403 07:42:33.667639 10121 solver.cpp:244]     Train net output #0: loss = 0.0375399 (* 1 = 0.0375399 loss)
I0403 07:42:33.866034 10121 sgd_solver.cpp:106] Iteration 1570, lr = 0.0005
I0403 07:42:37.333830 10121 solver.cpp:228] Iteration 1575, loss = 0.0334713
I0403 07:42:37.333920 10121 solver.cpp:244]     Train net output #0: loss = 0.0334711 (* 1 = 0.0334711 loss)
I0403 07:42:37.488327 10121 sgd_solver.cpp:106] Iteration 1575, lr = 0.0005
I0403 07:42:40.986379 10121 solver.cpp:228] Iteration 1580, loss = 0.0186433
I0403 07:42:40.986474 10121 solver.cpp:244]     Train net output #0: loss = 0.0186431 (* 1 = 0.0186431 loss)
I0403 07:42:41.171026 10121 sgd_solver.cpp:106] Iteration 1580, lr = 0.0005
I0403 07:42:44.606827 10121 solver.cpp:228] Iteration 1585, loss = 0.0700874
I0403 07:42:44.606920 10121 solver.cpp:244]     Train net output #0: loss = 0.0700873 (* 1 = 0.0700873 loss)
I0403 07:42:44.805397 10121 sgd_solver.cpp:106] Iteration 1585, lr = 0.0005
I0403 07:42:48.254432 10121 solver.cpp:228] Iteration 1590, loss = 0.0428142
I0403 07:42:48.254518 10121 solver.cpp:244]     Train net output #0: loss = 0.042814 (* 1 = 0.042814 loss)
I0403 07:42:48.435704 10121 sgd_solver.cpp:106] Iteration 1590, lr = 0.0005
I0403 07:42:51.851219 10121 solver.cpp:228] Iteration 1595, loss = 0.0532329
I0403 07:42:51.851315 10121 solver.cpp:244]     Train net output #0: loss = 0.0532327 (* 1 = 0.0532327 loss)
I0403 07:42:52.044914 10121 sgd_solver.cpp:106] Iteration 1595, lr = 0.0005
I0403 07:42:55.489938 10121 solver.cpp:228] Iteration 1600, loss = 0.0550374
I0403 07:42:55.490269 10121 solver.cpp:244]     Train net output #0: loss = 0.0550372 (* 1 = 0.0550372 loss)
I0403 07:42:55.688721 10121 sgd_solver.cpp:106] Iteration 1600, lr = 0.0005
I0403 07:42:59.107439 10121 solver.cpp:228] Iteration 1605, loss = 0.0409208
I0403 07:42:59.107542 10121 solver.cpp:244]     Train net output #0: loss = 0.0409206 (* 1 = 0.0409206 loss)
I0403 07:42:59.299393 10121 sgd_solver.cpp:106] Iteration 1605, lr = 0.0005
I0403 07:43:02.910532 10121 solver.cpp:228] Iteration 1610, loss = 0.0745876
I0403 07:43:02.910619 10121 solver.cpp:244]     Train net output #0: loss = 0.0745874 (* 1 = 0.0745874 loss)
I0403 07:43:03.038386 10121 sgd_solver.cpp:106] Iteration 1610, lr = 0.0005
I0403 07:43:06.666363 10121 solver.cpp:228] Iteration 1615, loss = 0.0468236
I0403 07:43:06.666457 10121 solver.cpp:244]     Train net output #0: loss = 0.0468234 (* 1 = 0.0468234 loss)
I0403 07:43:06.870592 10121 sgd_solver.cpp:106] Iteration 1615, lr = 0.0005
I0403 07:43:09.736549 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1620.caffemodel
I0403 07:43:12.453325 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1620.solverstate
I0403 07:43:14.249029 10121 solver.cpp:337] Iteration 1620, Testing net (#0)
I0403 07:44:52.130614 10121 solver.cpp:404]     Test net output #0: accuracy = 0.909563
I0403 07:44:52.130954 10121 solver.cpp:404]     Test net output #1: loss = 0.360321 (* 1 = 0.360321 loss)
I0403 07:44:52.644764 10121 solver.cpp:228] Iteration 1620, loss = 0.076456
I0403 07:44:52.644850 10121 solver.cpp:244]     Train net output #0: loss = 0.0764558 (* 1 = 0.0764558 loss)
I0403 07:44:52.816792 10121 sgd_solver.cpp:106] Iteration 1620, lr = 0.0005
I0403 07:44:56.291645 10121 solver.cpp:228] Iteration 1625, loss = 0.019698
I0403 07:44:56.291738 10121 solver.cpp:244]     Train net output #0: loss = 0.0196978 (* 1 = 0.0196978 loss)
I0403 07:44:56.476034 10121 sgd_solver.cpp:106] Iteration 1625, lr = 0.0005
I0403 07:45:00.020352 10121 solver.cpp:228] Iteration 1630, loss = 0.148484
I0403 07:45:00.020437 10121 solver.cpp:244]     Train net output #0: loss = 0.148484 (* 1 = 0.148484 loss)
I0403 07:45:00.118501 10121 sgd_solver.cpp:106] Iteration 1630, lr = 0.0005
I0403 07:45:03.689494 10121 solver.cpp:228] Iteration 1635, loss = 0.0939701
I0403 07:45:03.689581 10121 solver.cpp:244]     Train net output #0: loss = 0.0939699 (* 1 = 0.0939699 loss)
I0403 07:45:03.871387 10121 sgd_solver.cpp:106] Iteration 1635, lr = 0.0005
I0403 07:45:07.333295 10121 solver.cpp:228] Iteration 1640, loss = 0.0424169
I0403 07:45:07.333396 10121 solver.cpp:244]     Train net output #0: loss = 0.0424167 (* 1 = 0.0424167 loss)
I0403 07:45:07.592735 10121 sgd_solver.cpp:106] Iteration 1640, lr = 0.0005
I0403 07:45:11.006950 10121 solver.cpp:228] Iteration 1645, loss = 0.0410655
I0403 07:45:11.007046 10121 solver.cpp:244]     Train net output #0: loss = 0.0410653 (* 1 = 0.0410653 loss)
I0403 07:45:11.205492 10121 sgd_solver.cpp:106] Iteration 1645, lr = 0.0005
I0403 07:45:14.664470 10121 solver.cpp:228] Iteration 1650, loss = 0.0840827
I0403 07:45:14.664556 10121 solver.cpp:244]     Train net output #0: loss = 0.0840825 (* 1 = 0.0840825 loss)
I0403 07:45:14.829879 10121 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I0403 07:45:18.269877 10121 solver.cpp:228] Iteration 1655, loss = 0.0364819
I0403 07:45:18.269974 10121 solver.cpp:244]     Train net output #0: loss = 0.0364817 (* 1 = 0.0364817 loss)
I0403 07:45:18.488034 10121 sgd_solver.cpp:106] Iteration 1655, lr = 0.0005
I0403 07:45:21.917585 10121 solver.cpp:228] Iteration 1660, loss = 0.0497304
I0403 07:45:21.917680 10121 solver.cpp:244]     Train net output #0: loss = 0.0497302 (* 1 = 0.0497302 loss)
I0403 07:45:22.117063 10121 sgd_solver.cpp:106] Iteration 1660, lr = 0.0005
I0403 07:45:25.600514 10121 solver.cpp:228] Iteration 1665, loss = 0.0170948
I0403 07:45:25.600816 10121 solver.cpp:244]     Train net output #0: loss = 0.0170946 (* 1 = 0.0170946 loss)
I0403 07:45:25.787856 10121 sgd_solver.cpp:106] Iteration 1665, lr = 0.0005
I0403 07:45:29.290089 10121 solver.cpp:228] Iteration 1670, loss = 0.0652089
I0403 07:45:29.290175 10121 solver.cpp:244]     Train net output #0: loss = 0.0652087 (* 1 = 0.0652087 loss)
I0403 07:45:29.465275 10121 sgd_solver.cpp:106] Iteration 1670, lr = 0.0005
I0403 07:45:32.894376 10121 solver.cpp:228] Iteration 1675, loss = 0.0360566
I0403 07:45:32.894464 10121 solver.cpp:244]     Train net output #0: loss = 0.0360564 (* 1 = 0.0360564 loss)
I0403 07:45:33.068255 10121 sgd_solver.cpp:106] Iteration 1675, lr = 0.0005
I0403 07:45:36.541860 10121 solver.cpp:228] Iteration 1680, loss = 0.0695159
I0403 07:45:36.541955 10121 solver.cpp:244]     Train net output #0: loss = 0.0695157 (* 1 = 0.0695157 loss)
I0403 07:45:36.704588 10121 sgd_solver.cpp:106] Iteration 1680, lr = 0.0005
I0403 07:45:40.192188 10121 solver.cpp:228] Iteration 1685, loss = 0.0260736
I0403 07:45:40.192283 10121 solver.cpp:244]     Train net output #0: loss = 0.0260734 (* 1 = 0.0260734 loss)
I0403 07:45:40.385097 10121 sgd_solver.cpp:106] Iteration 1685, lr = 0.0005
I0403 07:45:43.826297 10121 solver.cpp:228] Iteration 1690, loss = 0.064164
I0403 07:45:43.827566 10121 solver.cpp:244]     Train net output #0: loss = 0.0641638 (* 1 = 0.0641638 loss)
I0403 07:45:44.066277 10121 sgd_solver.cpp:106] Iteration 1690, lr = 0.0005
I0403 07:45:47.493839 10121 solver.cpp:228] Iteration 1695, loss = 0.103907
I0403 07:45:47.493934 10121 solver.cpp:244]     Train net output #0: loss = 0.103907 (* 1 = 0.103907 loss)
I0403 07:45:47.743283 10121 sgd_solver.cpp:106] Iteration 1695, lr = 0.0005
I0403 07:45:51.202338 10121 solver.cpp:228] Iteration 1700, loss = 0.0335515
I0403 07:45:51.202435 10121 solver.cpp:244]     Train net output #0: loss = 0.0335513 (* 1 = 0.0335513 loss)
I0403 07:45:51.384614 10121 sgd_solver.cpp:106] Iteration 1700, lr = 0.0005
I0403 07:45:54.820447 10121 solver.cpp:228] Iteration 1705, loss = 0.0454439
I0403 07:45:54.820541 10121 solver.cpp:244]     Train net output #0: loss = 0.0454437 (* 1 = 0.0454437 loss)
I0403 07:45:55.048892 10121 sgd_solver.cpp:106] Iteration 1705, lr = 0.0005
I0403 07:45:58.527181 10121 solver.cpp:228] Iteration 1710, loss = 0.0851186
I0403 07:45:58.527537 10121 solver.cpp:244]     Train net output #0: loss = 0.0851184 (* 1 = 0.0851184 loss)
I0403 07:45:58.710670 10121 sgd_solver.cpp:106] Iteration 1710, lr = 0.0005
I0403 07:46:02.216895 10121 solver.cpp:228] Iteration 1715, loss = 0.0502061
I0403 07:46:02.216991 10121 solver.cpp:244]     Train net output #0: loss = 0.0502059 (* 1 = 0.0502059 loss)
I0403 07:46:02.405323 10121 sgd_solver.cpp:106] Iteration 1715, lr = 0.0005
I0403 07:46:05.822690 10121 solver.cpp:228] Iteration 1720, loss = 0.0183233
I0403 07:46:05.822782 10121 solver.cpp:244]     Train net output #0: loss = 0.0183231 (* 1 = 0.0183231 loss)
I0403 07:46:06.006465 10121 sgd_solver.cpp:106] Iteration 1720, lr = 0.0005
I0403 07:46:09.493240 10121 solver.cpp:228] Iteration 1725, loss = 0.0868267
I0403 07:46:09.493331 10121 solver.cpp:244]     Train net output #0: loss = 0.0868265 (* 1 = 0.0868265 loss)
I0403 07:46:09.677237 10121 sgd_solver.cpp:106] Iteration 1725, lr = 0.0005
I0403 07:46:11.122531 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1728.caffemodel
I0403 07:46:13.804576 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1728.solverstate
I0403 07:46:15.585000 10121 solver.cpp:337] Iteration 1728, Testing net (#0)
I0403 07:47:53.454478 10121 solver.cpp:404]     Test net output #0: accuracy = 0.908986
I0403 07:47:53.454797 10121 solver.cpp:404]     Test net output #1: loss = 0.366333 (* 1 = 0.366333 loss)
I0403 07:47:55.436517 10121 solver.cpp:228] Iteration 1730, loss = 0.051115
I0403 07:47:55.436604 10121 solver.cpp:244]     Train net output #0: loss = 0.0511149 (* 1 = 0.0511149 loss)
I0403 07:47:55.607544 10121 sgd_solver.cpp:106] Iteration 1730, lr = 0.0005
I0403 07:47:59.062794 10121 solver.cpp:228] Iteration 1735, loss = 0.0366348
I0403 07:47:59.062891 10121 solver.cpp:244]     Train net output #0: loss = 0.0366347 (* 1 = 0.0366347 loss)
I0403 07:47:59.292858 10121 sgd_solver.cpp:106] Iteration 1735, lr = 0.0005
I0403 07:48:02.870667 10121 solver.cpp:228] Iteration 1740, loss = 0.040667
I0403 07:48:02.870754 10121 solver.cpp:244]     Train net output #0: loss = 0.0406668 (* 1 = 0.0406668 loss)
I0403 07:48:02.991614 10121 sgd_solver.cpp:106] Iteration 1740, lr = 0.0005
I0403 07:48:06.561079 10121 solver.cpp:228] Iteration 1745, loss = 0.118444
I0403 07:48:06.561170 10121 solver.cpp:244]     Train net output #0: loss = 0.118444 (* 1 = 0.118444 loss)
I0403 07:48:06.779407 10121 sgd_solver.cpp:106] Iteration 1745, lr = 0.0005
I0403 07:48:10.274220 10121 solver.cpp:228] Iteration 1750, loss = 0.0316703
I0403 07:48:10.274310 10121 solver.cpp:244]     Train net output #0: loss = 0.0316701 (* 1 = 0.0316701 loss)
I0403 07:48:10.449935 10121 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I0403 07:48:13.937677 10121 solver.cpp:228] Iteration 1755, loss = 0.0161731
I0403 07:48:13.938659 10121 solver.cpp:244]     Train net output #0: loss = 0.0161729 (* 1 = 0.0161729 loss)
I0403 07:48:14.153350 10121 sgd_solver.cpp:106] Iteration 1755, lr = 0.0005
I0403 07:48:17.581626 10121 solver.cpp:228] Iteration 1760, loss = 0.0191625
I0403 07:48:17.581708 10121 solver.cpp:244]     Train net output #0: loss = 0.0191623 (* 1 = 0.0191623 loss)
I0403 07:48:17.742374 10121 sgd_solver.cpp:106] Iteration 1760, lr = 0.0005
I0403 07:48:21.247058 10121 solver.cpp:228] Iteration 1765, loss = 0.0360479
I0403 07:48:21.247144 10121 solver.cpp:244]     Train net output #0: loss = 0.0360477 (* 1 = 0.0360477 loss)
I0403 07:48:21.428746 10121 sgd_solver.cpp:106] Iteration 1765, lr = 0.0005
I0403 07:48:24.910768 10121 solver.cpp:228] Iteration 1770, loss = 0.0354459
I0403 07:48:24.911123 10121 solver.cpp:244]     Train net output #0: loss = 0.0354457 (* 1 = 0.0354457 loss)
I0403 07:48:25.101353 10121 sgd_solver.cpp:106] Iteration 1770, lr = 0.0005
I0403 07:48:28.547981 10121 solver.cpp:228] Iteration 1775, loss = 0.0264446
I0403 07:48:28.548077 10121 solver.cpp:244]     Train net output #0: loss = 0.0264445 (* 1 = 0.0264445 loss)
I0403 07:48:28.739622 10121 sgd_solver.cpp:106] Iteration 1775, lr = 0.0005
I0403 07:48:32.177753 10121 solver.cpp:228] Iteration 1780, loss = 0.0937855
I0403 07:48:32.177846 10121 solver.cpp:244]     Train net output #0: loss = 0.0937853 (* 1 = 0.0937853 loss)
I0403 07:48:32.377894 10121 sgd_solver.cpp:106] Iteration 1780, lr = 0.0005
I0403 07:48:35.806854 10121 solver.cpp:228] Iteration 1785, loss = 0.0464511
I0403 07:48:35.806952 10121 solver.cpp:244]     Train net output #0: loss = 0.046451 (* 1 = 0.046451 loss)
I0403 07:48:36.032078 10121 sgd_solver.cpp:106] Iteration 1785, lr = 0.0005
I0403 07:48:39.546165 10121 solver.cpp:228] Iteration 1790, loss = 0.0717006
I0403 07:48:39.546254 10121 solver.cpp:244]     Train net output #0: loss = 0.0717004 (* 1 = 0.0717004 loss)
I0403 07:48:39.737015 10121 sgd_solver.cpp:106] Iteration 1790, lr = 0.0005
I0403 07:48:43.207686 10121 solver.cpp:228] Iteration 1795, loss = 0.0186918
I0403 07:48:43.207780 10121 solver.cpp:244]     Train net output #0: loss = 0.0186916 (* 1 = 0.0186916 loss)
I0403 07:48:43.396862 10121 sgd_solver.cpp:106] Iteration 1795, lr = 0.0005
I0403 07:48:46.795825 10121 solver.cpp:228] Iteration 1800, loss = 0.0669297
I0403 07:48:46.795922 10121 solver.cpp:244]     Train net output #0: loss = 0.0669295 (* 1 = 0.0669295 loss)
I0403 07:48:47.039124 10121 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0403 07:48:50.496477 10121 solver.cpp:228] Iteration 1805, loss = 0.0690398
I0403 07:48:50.496574 10121 solver.cpp:244]     Train net output #0: loss = 0.0690396 (* 1 = 0.0690396 loss)
I0403 07:48:50.678953 10121 sgd_solver.cpp:106] Iteration 1805, lr = 0.0005
I0403 07:48:54.128145 10121 solver.cpp:228] Iteration 1810, loss = 0.0326937
I0403 07:48:54.128252 10121 solver.cpp:244]     Train net output #0: loss = 0.0326936 (* 1 = 0.0326936 loss)
I0403 07:48:54.326264 10121 sgd_solver.cpp:106] Iteration 1810, lr = 0.0005
I0403 07:48:57.798305 10121 solver.cpp:228] Iteration 1815, loss = 0.0791215
I0403 07:48:57.798629 10121 solver.cpp:244]     Train net output #0: loss = 0.0791214 (* 1 = 0.0791214 loss)
I0403 07:48:58.002302 10121 sgd_solver.cpp:106] Iteration 1815, lr = 0.0005
I0403 07:49:01.436640 10121 solver.cpp:228] Iteration 1820, loss = 0.036972
I0403 07:49:01.436736 10121 solver.cpp:244]     Train net output #0: loss = 0.0369718 (* 1 = 0.0369718 loss)
I0403 07:49:01.619565 10121 sgd_solver.cpp:106] Iteration 1820, lr = 0.0005
I0403 07:49:05.071934 10121 solver.cpp:228] Iteration 1825, loss = 0.0535907
I0403 07:49:05.072028 10121 solver.cpp:244]     Train net output #0: loss = 0.0535905 (* 1 = 0.0535905 loss)
I0403 07:49:05.256665 10121 sgd_solver.cpp:106] Iteration 1825, lr = 0.0005
I0403 07:49:08.678000 10121 solver.cpp:228] Iteration 1830, loss = 0.104369
I0403 07:49:08.678098 10121 solver.cpp:244]     Train net output #0: loss = 0.104368 (* 1 = 0.104368 loss)
I0403 07:49:08.866300 10121 sgd_solver.cpp:106] Iteration 1830, lr = 0.0005
I0403 07:49:12.304944 10121 solver.cpp:228] Iteration 1835, loss = 0.103554
I0403 07:49:12.305038 10121 solver.cpp:244]     Train net output #0: loss = 0.103553 (* 1 = 0.103553 loss)
I0403 07:49:12.488962 10121 sgd_solver.cpp:106] Iteration 1835, lr = 0.0005
I0403 07:49:12.489198 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1836.caffemodel
I0403 07:49:15.170270 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1836.solverstate
I0403 07:49:16.971752 10121 solver.cpp:337] Iteration 1836, Testing net (#0)
I0403 07:50:54.841675 10121 solver.cpp:404]     Test net output #0: accuracy = 0.910761
I0403 07:50:54.842011 10121 solver.cpp:404]     Test net output #1: loss = 0.366592 (* 1 = 0.366592 loss)
I0403 07:50:58.238394 10121 solver.cpp:228] Iteration 1840, loss = 0.0187731
I0403 07:50:58.238489 10121 solver.cpp:244]     Train net output #0: loss = 0.0187729 (* 1 = 0.0187729 loss)
I0403 07:50:58.427662 10121 sgd_solver.cpp:106] Iteration 1840, lr = 0.0005
I0403 07:51:01.916224 10121 solver.cpp:228] Iteration 1845, loss = 0.11472
I0403 07:51:01.916322 10121 solver.cpp:244]     Train net output #0: loss = 0.11472 (* 1 = 0.11472 loss)
I0403 07:51:02.112113 10121 sgd_solver.cpp:106] Iteration 1845, lr = 0.0005
I0403 07:51:05.559192 10121 solver.cpp:228] Iteration 1850, loss = 0.0459248
I0403 07:51:05.559281 10121 solver.cpp:244]     Train net output #0: loss = 0.0459246 (* 1 = 0.0459246 loss)
I0403 07:51:05.740466 10121 sgd_solver.cpp:106] Iteration 1850, lr = 0.0005
I0403 07:51:09.176141 10121 solver.cpp:228] Iteration 1855, loss = 0.0196567
I0403 07:51:09.176241 10121 solver.cpp:244]     Train net output #0: loss = 0.0196566 (* 1 = 0.0196566 loss)
I0403 07:51:09.376956 10121 sgd_solver.cpp:106] Iteration 1855, lr = 0.0005
I0403 07:51:12.807535 10121 solver.cpp:228] Iteration 1860, loss = 0.0426529
I0403 07:51:12.807629 10121 solver.cpp:244]     Train net output #0: loss = 0.0426527 (* 1 = 0.0426527 loss)
I0403 07:51:12.991247 10121 sgd_solver.cpp:106] Iteration 1860, lr = 0.0005
I0403 07:51:16.408434 10121 solver.cpp:228] Iteration 1865, loss = 0.0267704
I0403 07:51:16.408529 10121 solver.cpp:244]     Train net output #0: loss = 0.0267702 (* 1 = 0.0267702 loss)
I0403 07:51:16.674033 10121 sgd_solver.cpp:106] Iteration 1865, lr = 0.0005
I0403 07:51:20.127998 10121 solver.cpp:228] Iteration 1870, loss = 0.0373328
I0403 07:51:20.128085 10121 solver.cpp:244]     Train net output #0: loss = 0.0373327 (* 1 = 0.0373327 loss)
I0403 07:51:20.299892 10121 sgd_solver.cpp:106] Iteration 1870, lr = 0.0005
I0403 07:51:23.755234 10121 solver.cpp:228] Iteration 1875, loss = 0.046298
I0403 07:51:23.755332 10121 solver.cpp:244]     Train net output #0: loss = 0.0462978 (* 1 = 0.0462978 loss)
I0403 07:51:23.938100 10121 sgd_solver.cpp:106] Iteration 1875, lr = 0.0005
I0403 07:51:27.457911 10121 solver.cpp:228] Iteration 1880, loss = 0.0275235
I0403 07:51:27.458259 10121 solver.cpp:244]     Train net output #0: loss = 0.0275233 (* 1 = 0.0275233 loss)
I0403 07:51:27.648846 10121 sgd_solver.cpp:106] Iteration 1880, lr = 0.0005
I0403 07:51:31.087033 10121 solver.cpp:228] Iteration 1885, loss = 0.0301646
I0403 07:51:31.087126 10121 solver.cpp:244]     Train net output #0: loss = 0.0301644 (* 1 = 0.0301644 loss)
I0403 07:51:31.276170 10121 sgd_solver.cpp:106] Iteration 1885, lr = 0.0005
I0403 07:51:34.728299 10121 solver.cpp:228] Iteration 1890, loss = 0.014098
I0403 07:51:34.728385 10121 solver.cpp:244]     Train net output #0: loss = 0.0140978 (* 1 = 0.0140978 loss)
I0403 07:51:34.907178 10121 sgd_solver.cpp:106] Iteration 1890, lr = 0.0005
I0403 07:51:38.377765 10121 solver.cpp:228] Iteration 1895, loss = 0.0320527
I0403 07:51:38.377861 10121 solver.cpp:244]     Train net output #0: loss = 0.0320525 (* 1 = 0.0320525 loss)
I0403 07:51:38.568428 10121 sgd_solver.cpp:106] Iteration 1895, lr = 0.0005
I0403 07:51:42.033174 10121 solver.cpp:228] Iteration 1900, loss = 0.0471106
I0403 07:51:42.033265 10121 solver.cpp:244]     Train net output #0: loss = 0.0471105 (* 1 = 0.0471105 loss)
I0403 07:51:42.182247 10121 sgd_solver.cpp:106] Iteration 1900, lr = 0.0005
I0403 07:51:45.710844 10121 solver.cpp:228] Iteration 1905, loss = 0.02414
I0403 07:51:45.710932 10121 solver.cpp:244]     Train net output #0: loss = 0.0241398 (* 1 = 0.0241398 loss)
I0403 07:51:45.861400 10121 sgd_solver.cpp:106] Iteration 1905, lr = 0.0005
I0403 07:51:49.337570 10121 solver.cpp:228] Iteration 1910, loss = 0.0285812
I0403 07:51:49.337666 10121 solver.cpp:244]     Train net output #0: loss = 0.028581 (* 1 = 0.028581 loss)
I0403 07:51:49.578047 10121 sgd_solver.cpp:106] Iteration 1910, lr = 0.0005
I0403 07:51:53.085657 10121 solver.cpp:228] Iteration 1915, loss = 0.0310666
I0403 07:51:53.085752 10121 solver.cpp:244]     Train net output #0: loss = 0.0310664 (* 1 = 0.0310664 loss)
I0403 07:51:53.268491 10121 sgd_solver.cpp:106] Iteration 1915, lr = 0.0005
I0403 07:51:56.762759 10121 solver.cpp:228] Iteration 1920, loss = 0.0197713
I0403 07:51:56.762856 10121 solver.cpp:244]     Train net output #0: loss = 0.0197711 (* 1 = 0.0197711 loss)
I0403 07:51:56.979063 10121 sgd_solver.cpp:106] Iteration 1920, lr = 0.0005
I0403 07:52:00.491843 10121 solver.cpp:228] Iteration 1925, loss = 0.0125241
I0403 07:52:00.492131 10121 solver.cpp:244]     Train net output #0: loss = 0.0125239 (* 1 = 0.0125239 loss)
I0403 07:52:00.609825 10121 sgd_solver.cpp:106] Iteration 1925, lr = 0.0005
I0403 07:52:04.154111 10121 solver.cpp:228] Iteration 1930, loss = 0.0969482
I0403 07:52:04.154193 10121 solver.cpp:244]     Train net output #0: loss = 0.096948 (* 1 = 0.096948 loss)
I0403 07:52:04.324398 10121 sgd_solver.cpp:106] Iteration 1930, lr = 0.0005
I0403 07:52:07.777354 10121 solver.cpp:228] Iteration 1935, loss = 0.0655662
I0403 07:52:07.777451 10121 solver.cpp:244]     Train net output #0: loss = 0.0655661 (* 1 = 0.0655661 loss)
I0403 07:52:07.970127 10121 sgd_solver.cpp:106] Iteration 1935, lr = 0.0005
I0403 07:52:11.453305 10121 solver.cpp:228] Iteration 1940, loss = 0.0179279
I0403 07:52:11.453400 10121 solver.cpp:244]     Train net output #0: loss = 0.0179277 (* 1 = 0.0179277 loss)
I0403 07:52:11.637920 10121 sgd_solver.cpp:106] Iteration 1940, lr = 0.0005
I0403 07:52:13.797467 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1944.caffemodel
I0403 07:52:16.566702 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_1944.solverstate
I0403 07:52:18.484259 10121 solver.cpp:337] Iteration 1944, Testing net (#0)
I0403 07:53:56.349133 10121 solver.cpp:404]     Test net output #0: accuracy = 0.908733
I0403 07:53:56.349455 10121 solver.cpp:404]     Test net output #1: loss = 0.381051 (* 1 = 0.381051 loss)
I0403 07:53:57.598521 10121 solver.cpp:228] Iteration 1945, loss = 0.0538378
I0403 07:53:57.598624 10121 solver.cpp:244]     Train net output #0: loss = 0.0538377 (* 1 = 0.0538377 loss)
I0403 07:53:57.791373 10121 sgd_solver.cpp:106] Iteration 1945, lr = 0.0005
I0403 07:54:01.225869 10121 solver.cpp:228] Iteration 1950, loss = 0.0169681
I0403 07:54:01.225966 10121 solver.cpp:244]     Train net output #0: loss = 0.016968 (* 1 = 0.016968 loss)
I0403 07:54:01.452767 10121 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I0403 07:54:04.893537 10121 solver.cpp:228] Iteration 1955, loss = 0.0591418
I0403 07:54:04.893632 10121 solver.cpp:244]     Train net output #0: loss = 0.0591416 (* 1 = 0.0591416 loss)
I0403 07:54:05.090104 10121 sgd_solver.cpp:106] Iteration 1955, lr = 0.0005
I0403 07:54:08.512094 10121 solver.cpp:228] Iteration 1960, loss = 0.0585
I0403 07:54:08.512198 10121 solver.cpp:244]     Train net output #0: loss = 0.0584998 (* 1 = 0.0584998 loss)
I0403 07:54:08.714505 10121 sgd_solver.cpp:106] Iteration 1960, lr = 0.0005
I0403 07:54:12.153676 10121 solver.cpp:228] Iteration 1965, loss = 0.0661603
I0403 07:54:12.153772 10121 solver.cpp:244]     Train net output #0: loss = 0.0661601 (* 1 = 0.0661601 loss)
I0403 07:54:12.347637 10121 sgd_solver.cpp:106] Iteration 1965, lr = 0.0005
I0403 07:54:15.788542 10121 solver.cpp:228] Iteration 1970, loss = 0.022486
I0403 07:54:15.788637 10121 solver.cpp:244]     Train net output #0: loss = 0.0224858 (* 1 = 0.0224858 loss)
I0403 07:54:15.979792 10121 sgd_solver.cpp:106] Iteration 1970, lr = 0.0005
I0403 07:54:19.497434 10121 solver.cpp:228] Iteration 1975, loss = 0.0221707
I0403 07:54:19.497540 10121 solver.cpp:244]     Train net output #0: loss = 0.0221705 (* 1 = 0.0221705 loss)
I0403 07:54:19.687914 10121 sgd_solver.cpp:106] Iteration 1975, lr = 0.0005
I0403 07:54:23.086669 10121 solver.cpp:228] Iteration 1980, loss = 0.0102133
I0403 07:54:23.086756 10121 solver.cpp:244]     Train net output #0: loss = 0.0102132 (* 1 = 0.0102132 loss)
I0403 07:54:23.263578 10121 sgd_solver.cpp:106] Iteration 1980, lr = 0.0005
I0403 07:54:26.825896 10121 solver.cpp:228] Iteration 1985, loss = 0.0557305
I0403 07:54:26.826220 10121 solver.cpp:244]     Train net output #0: loss = 0.0557303 (* 1 = 0.0557303 loss)
I0403 07:54:27.007953 10121 sgd_solver.cpp:106] Iteration 1985, lr = 0.0005
I0403 07:54:30.456121 10121 solver.cpp:228] Iteration 1990, loss = 0.0322402
I0403 07:54:30.456221 10121 solver.cpp:244]     Train net output #0: loss = 0.03224 (* 1 = 0.03224 loss)
I0403 07:54:30.640934 10121 sgd_solver.cpp:106] Iteration 1990, lr = 0.0005
I0403 07:54:34.120102 10121 solver.cpp:228] Iteration 1995, loss = 0.0358644
I0403 07:54:34.120198 10121 solver.cpp:244]     Train net output #0: loss = 0.0358642 (* 1 = 0.0358642 loss)
I0403 07:54:34.305372 10121 sgd_solver.cpp:106] Iteration 1995, lr = 0.0005
I0403 07:54:37.703914 10121 solver.cpp:228] Iteration 2000, loss = 0.0324887
I0403 07:54:37.704011 10121 solver.cpp:244]     Train net output #0: loss = 0.0324886 (* 1 = 0.0324886 loss)
I0403 07:54:37.888283 10121 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I0403 07:54:41.320786 10121 solver.cpp:228] Iteration 2005, loss = 0.0313864
I0403 07:54:41.320873 10121 solver.cpp:244]     Train net output #0: loss = 0.0313862 (* 1 = 0.0313862 loss)
I0403 07:54:41.480003 10121 sgd_solver.cpp:106] Iteration 2005, lr = 0.0005
I0403 07:54:45.124426 10121 solver.cpp:228] Iteration 2010, loss = 0.0420291
I0403 07:54:45.124524 10121 solver.cpp:244]     Train net output #0: loss = 0.0420289 (* 1 = 0.0420289 loss)
I0403 07:54:45.335036 10121 sgd_solver.cpp:106] Iteration 2010, lr = 0.0005
I0403 07:54:48.748121 10121 solver.cpp:228] Iteration 2015, loss = 0.0292627
I0403 07:54:48.748220 10121 solver.cpp:244]     Train net output #0: loss = 0.0292625 (* 1 = 0.0292625 loss)
I0403 07:54:48.931957 10121 sgd_solver.cpp:106] Iteration 2015, lr = 0.0005
I0403 07:54:52.423794 10121 solver.cpp:228] Iteration 2020, loss = 0.0680652
I0403 07:54:52.423892 10121 solver.cpp:244]     Train net output #0: loss = 0.0680651 (* 1 = 0.0680651 loss)
I0403 07:54:52.610324 10121 sgd_solver.cpp:106] Iteration 2020, lr = 0.0005
I0403 07:54:56.028036 10121 solver.cpp:228] Iteration 2025, loss = 0.0224039
I0403 07:54:56.028134 10121 solver.cpp:244]     Train net output #0: loss = 0.0224037 (* 1 = 0.0224037 loss)
I0403 07:54:56.214512 10121 sgd_solver.cpp:106] Iteration 2025, lr = 0.0005
I0403 07:54:59.672200 10121 solver.cpp:228] Iteration 2030, loss = 0.0384044
I0403 07:54:59.672534 10121 solver.cpp:244]     Train net output #0: loss = 0.0384043 (* 1 = 0.0384043 loss)
I0403 07:54:59.889145 10121 sgd_solver.cpp:106] Iteration 2030, lr = 0.0005
I0403 07:55:03.367532 10121 solver.cpp:228] Iteration 2035, loss = 0.041749
I0403 07:55:03.367626 10121 solver.cpp:244]     Train net output #0: loss = 0.0417488 (* 1 = 0.0417488 loss)
I0403 07:55:03.561080 10121 sgd_solver.cpp:106] Iteration 2035, lr = 0.0005
I0403 07:55:07.129043 10121 solver.cpp:228] Iteration 2040, loss = 0.050546
I0403 07:55:07.129132 10121 solver.cpp:244]     Train net output #0: loss = 0.0505458 (* 1 = 0.0505458 loss)
I0403 07:55:07.212021 10121 sgd_solver.cpp:106] Iteration 2040, lr = 0.0005
I0403 07:55:10.819032 10121 solver.cpp:228] Iteration 2045, loss = 0.00794305
I0403 07:55:10.819130 10121 solver.cpp:244]     Train net output #0: loss = 0.00794287 (* 1 = 0.00794287 loss)
I0403 07:55:11.009692 10121 sgd_solver.cpp:106] Iteration 2045, lr = 0.0005
I0403 07:55:14.408252 10121 solver.cpp:228] Iteration 2050, loss = 0.0235231
I0403 07:55:14.408359 10121 solver.cpp:244]     Train net output #0: loss = 0.0235229 (* 1 = 0.0235229 loss)
I0403 07:55:14.617419 10121 sgd_solver.cpp:106] Iteration 2050, lr = 0.0005
I0403 07:55:15.320086 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2052.caffemodel
I0403 07:55:17.999976 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2052.solverstate
I0403 07:55:19.809034 10121 solver.cpp:337] Iteration 2052, Testing net (#0)
I0403 07:56:57.690335 10121 solver.cpp:404]     Test net output #0: accuracy = 0.912466
I0403 07:56:57.690685 10121 solver.cpp:404]     Test net output #1: loss = 0.365783 (* 1 = 0.365783 loss)
I0403 07:57:00.424442 10121 solver.cpp:228] Iteration 2055, loss = 0.0516131
I0403 07:57:00.424537 10121 solver.cpp:244]     Train net output #0: loss = 0.0516129 (* 1 = 0.0516129 loss)
I0403 07:57:00.610867 10121 sgd_solver.cpp:106] Iteration 2055, lr = 0.0005
I0403 07:57:04.006641 10121 solver.cpp:228] Iteration 2060, loss = 0.0237704
I0403 07:57:04.006737 10121 solver.cpp:244]     Train net output #0: loss = 0.0237702 (* 1 = 0.0237702 loss)
I0403 07:57:04.197947 10121 sgd_solver.cpp:106] Iteration 2060, lr = 0.0005
I0403 07:57:07.645756 10121 solver.cpp:228] Iteration 2065, loss = 0.0588514
I0403 07:57:07.645854 10121 solver.cpp:244]     Train net output #0: loss = 0.0588513 (* 1 = 0.0588513 loss)
I0403 07:57:07.852848 10121 sgd_solver.cpp:106] Iteration 2065, lr = 0.0005
I0403 07:57:11.303755 10121 solver.cpp:228] Iteration 2070, loss = 0.0525584
I0403 07:57:11.303843 10121 solver.cpp:244]     Train net output #0: loss = 0.0525582 (* 1 = 0.0525582 loss)
I0403 07:57:11.485175 10121 sgd_solver.cpp:106] Iteration 2070, lr = 0.0005
I0403 07:57:14.970152 10121 solver.cpp:228] Iteration 2075, loss = 0.0352229
I0403 07:57:14.970252 10121 solver.cpp:244]     Train net output #0: loss = 0.0352227 (* 1 = 0.0352227 loss)
I0403 07:57:15.158478 10121 sgd_solver.cpp:106] Iteration 2075, lr = 0.0005
I0403 07:57:18.675403 10121 solver.cpp:228] Iteration 2080, loss = 0.0431728
I0403 07:57:18.675498 10121 solver.cpp:244]     Train net output #0: loss = 0.0431727 (* 1 = 0.0431727 loss)
I0403 07:57:18.892717 10121 sgd_solver.cpp:106] Iteration 2080, lr = 0.0005
I0403 07:57:22.343534 10121 solver.cpp:228] Iteration 2085, loss = 0.0884251
I0403 07:57:22.343628 10121 solver.cpp:244]     Train net output #0: loss = 0.0884249 (* 1 = 0.0884249 loss)
I0403 07:57:22.549319 10121 sgd_solver.cpp:106] Iteration 2085, lr = 0.0005
I0403 07:57:26.006297 10121 solver.cpp:228] Iteration 2090, loss = 0.0339854
I0403 07:57:26.006387 10121 solver.cpp:244]     Train net output #0: loss = 0.0339852 (* 1 = 0.0339852 loss)
I0403 07:57:26.196187 10121 sgd_solver.cpp:106] Iteration 2090, lr = 0.0005
I0403 07:57:29.653475 10121 solver.cpp:228] Iteration 2095, loss = 0.0513038
I0403 07:57:29.653808 10121 solver.cpp:244]     Train net output #0: loss = 0.0513037 (* 1 = 0.0513037 loss)
I0403 07:57:29.810241 10121 sgd_solver.cpp:106] Iteration 2095, lr = 0.0005
I0403 07:57:33.477221 10121 solver.cpp:228] Iteration 2100, loss = 0.0115784
I0403 07:57:33.477322 10121 solver.cpp:244]     Train net output #0: loss = 0.0115782 (* 1 = 0.0115782 loss)
I0403 07:57:33.672206 10121 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0403 07:57:37.112226 10121 solver.cpp:228] Iteration 2105, loss = 0.0416837
I0403 07:57:37.112323 10121 solver.cpp:244]     Train net output #0: loss = 0.0416835 (* 1 = 0.0416835 loss)
I0403 07:57:37.296041 10121 sgd_solver.cpp:106] Iteration 2105, lr = 0.0005
I0403 07:57:40.752419 10121 solver.cpp:228] Iteration 2110, loss = 0.0277348
I0403 07:57:40.752523 10121 solver.cpp:244]     Train net output #0: loss = 0.0277346 (* 1 = 0.0277346 loss)
I0403 07:57:40.939685 10121 sgd_solver.cpp:106] Iteration 2110, lr = 0.0005
I0403 07:57:44.321804 10121 solver.cpp:228] Iteration 2115, loss = 0.0385751
I0403 07:57:44.321900 10121 solver.cpp:244]     Train net output #0: loss = 0.0385749 (* 1 = 0.0385749 loss)
I0403 07:57:44.562423 10121 sgd_solver.cpp:106] Iteration 2115, lr = 0.0005
I0403 07:57:47.991838 10121 solver.cpp:228] Iteration 2120, loss = 0.0215797
I0403 07:57:47.991935 10121 solver.cpp:244]     Train net output #0: loss = 0.0215795 (* 1 = 0.0215795 loss)
I0403 07:57:48.199404 10121 sgd_solver.cpp:106] Iteration 2120, lr = 0.0005
I0403 07:57:51.680554 10121 solver.cpp:228] Iteration 2125, loss = 0.0161617
I0403 07:57:51.680640 10121 solver.cpp:244]     Train net output #0: loss = 0.0161615 (* 1 = 0.0161615 loss)
I0403 07:57:51.849643 10121 sgd_solver.cpp:106] Iteration 2125, lr = 0.0005
I0403 07:57:55.337728 10121 solver.cpp:228] Iteration 2130, loss = 0.0391074
I0403 07:57:55.337813 10121 solver.cpp:244]     Train net output #0: loss = 0.0391072 (* 1 = 0.0391072 loss)
I0403 07:57:55.501220 10121 sgd_solver.cpp:106] Iteration 2130, lr = 0.0005
I0403 07:57:59.003989 10121 solver.cpp:228] Iteration 2135, loss = 0.0205405
I0403 07:57:59.004076 10121 solver.cpp:244]     Train net output #0: loss = 0.0205403 (* 1 = 0.0205403 loss)
I0403 07:57:59.152432 10121 sgd_solver.cpp:106] Iteration 2135, lr = 0.0005
I0403 07:58:02.683899 10121 solver.cpp:228] Iteration 2140, loss = 0.039635
I0403 07:58:02.684262 10121 solver.cpp:244]     Train net output #0: loss = 0.0396348 (* 1 = 0.0396348 loss)
I0403 07:58:02.878064 10121 sgd_solver.cpp:106] Iteration 2140, lr = 0.0005
I0403 07:58:06.406807 10121 solver.cpp:228] Iteration 2145, loss = 0.0104901
I0403 07:58:06.406903 10121 solver.cpp:244]     Train net output #0: loss = 0.01049 (* 1 = 0.01049 loss)
I0403 07:58:06.597820 10121 sgd_solver.cpp:106] Iteration 2145, lr = 0.0005
I0403 07:58:10.059559 10121 solver.cpp:228] Iteration 2150, loss = 0.0246608
I0403 07:58:10.059658 10121 solver.cpp:244]     Train net output #0: loss = 0.0246606 (* 1 = 0.0246606 loss)
I0403 07:58:10.242800 10121 sgd_solver.cpp:106] Iteration 2150, lr = 0.0005
I0403 07:58:13.663614 10121 solver.cpp:228] Iteration 2155, loss = 0.116366
I0403 07:58:13.663707 10121 solver.cpp:244]     Train net output #0: loss = 0.116366 (* 1 = 0.116366 loss)
I0403 07:58:13.861481 10121 sgd_solver.cpp:106] Iteration 2155, lr = 0.0005
I0403 07:58:16.766871 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2160.caffemodel
I0403 07:58:19.446074 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2160.solverstate
I0403 07:58:21.256633 10121 solver.cpp:337] Iteration 2160, Testing net (#0)
I0403 07:59:59.116931 10121 solver.cpp:404]     Test net output #0: accuracy = 0.911798
I0403 07:59:59.117279 10121 solver.cpp:404]     Test net output #1: loss = 0.376329 (* 1 = 0.376329 loss)
I0403 07:59:59.628216 10121 solver.cpp:228] Iteration 2160, loss = 0.0289583
I0403 07:59:59.628305 10121 solver.cpp:244]     Train net output #0: loss = 0.0289581 (* 1 = 0.0289581 loss)
I0403 07:59:59.800350 10121 sgd_solver.cpp:106] Iteration 2160, lr = 0.0005
I0403 08:00:03.245002 10121 solver.cpp:228] Iteration 2165, loss = 0.0241164
I0403 08:00:03.245090 10121 solver.cpp:244]     Train net output #0: loss = 0.0241162 (* 1 = 0.0241162 loss)
I0403 08:00:03.406929 10121 sgd_solver.cpp:106] Iteration 2165, lr = 0.0005
I0403 08:00:06.892680 10121 solver.cpp:228] Iteration 2170, loss = 0.0950048
I0403 08:00:06.892768 10121 solver.cpp:244]     Train net output #0: loss = 0.0950046 (* 1 = 0.0950046 loss)
I0403 08:00:07.045022 10121 sgd_solver.cpp:106] Iteration 2170, lr = 5e-05
I0403 08:00:10.568574 10121 solver.cpp:228] Iteration 2175, loss = 0.0580972
I0403 08:00:10.568666 10121 solver.cpp:244]     Train net output #0: loss = 0.058097 (* 1 = 0.058097 loss)
I0403 08:00:10.751579 10121 sgd_solver.cpp:106] Iteration 2175, lr = 5e-05
I0403 08:00:14.385174 10121 solver.cpp:228] Iteration 2180, loss = 0.0139752
I0403 08:00:14.385263 10121 solver.cpp:244]     Train net output #0: loss = 0.013975 (* 1 = 0.013975 loss)
I0403 08:00:14.545718 10121 sgd_solver.cpp:106] Iteration 2180, lr = 5e-05
I0403 08:00:18.037943 10121 solver.cpp:228] Iteration 2185, loss = 0.0252885
I0403 08:00:18.038043 10121 solver.cpp:244]     Train net output #0: loss = 0.0252883 (* 1 = 0.0252883 loss)
I0403 08:00:18.269520 10121 sgd_solver.cpp:106] Iteration 2185, lr = 5e-05
I0403 08:00:21.713685 10121 solver.cpp:228] Iteration 2190, loss = 0.0255985
I0403 08:00:21.713773 10121 solver.cpp:244]     Train net output #0: loss = 0.0255983 (* 1 = 0.0255983 loss)
I0403 08:00:21.888103 10121 sgd_solver.cpp:106] Iteration 2190, lr = 5e-05
I0403 08:00:25.402431 10121 solver.cpp:228] Iteration 2195, loss = 0.0184844
I0403 08:00:25.402529 10121 solver.cpp:244]     Train net output #0: loss = 0.0184842 (* 1 = 0.0184842 loss)
I0403 08:00:25.623237 10121 sgd_solver.cpp:106] Iteration 2195, lr = 5e-05
I0403 08:00:29.057940 10121 solver.cpp:228] Iteration 2200, loss = 0.0555325
I0403 08:00:29.058023 10121 solver.cpp:244]     Train net output #0: loss = 0.0555323 (* 1 = 0.0555323 loss)
I0403 08:00:29.225757 10121 sgd_solver.cpp:106] Iteration 2200, lr = 5e-05
I0403 08:00:32.689131 10121 solver.cpp:228] Iteration 2205, loss = 0.0707804
I0403 08:00:32.689231 10121 solver.cpp:244]     Train net output #0: loss = 0.0707802 (* 1 = 0.0707802 loss)
I0403 08:00:32.871196 10121 sgd_solver.cpp:106] Iteration 2205, lr = 5e-05
I0403 08:00:36.322237 10121 solver.cpp:228] Iteration 2210, loss = 0.0494639
I0403 08:00:36.322334 10121 solver.cpp:244]     Train net output #0: loss = 0.0494637 (* 1 = 0.0494637 loss)
I0403 08:00:36.559782 10121 sgd_solver.cpp:106] Iteration 2210, lr = 5e-05
I0403 08:00:39.967072 10121 solver.cpp:228] Iteration 2215, loss = 0.0224456
I0403 08:00:39.967169 10121 solver.cpp:244]     Train net output #0: loss = 0.0224454 (* 1 = 0.0224454 loss)
I0403 08:00:40.197160 10121 sgd_solver.cpp:106] Iteration 2215, lr = 5e-05
I0403 08:00:43.574080 10121 solver.cpp:228] Iteration 2220, loss = 0.0171299
I0403 08:00:43.574177 10121 solver.cpp:244]     Train net output #0: loss = 0.0171297 (* 1 = 0.0171297 loss)
I0403 08:00:43.756407 10121 sgd_solver.cpp:106] Iteration 2220, lr = 5e-05
I0403 08:00:47.217828 10121 solver.cpp:228] Iteration 2225, loss = 0.0200313
I0403 08:00:47.217921 10121 solver.cpp:244]     Train net output #0: loss = 0.0200311 (* 1 = 0.0200311 loss)
I0403 08:00:47.401528 10121 sgd_solver.cpp:106] Iteration 2225, lr = 5e-05
I0403 08:00:50.830986 10121 solver.cpp:228] Iteration 2230, loss = 0.0269572
I0403 08:00:50.831081 10121 solver.cpp:244]     Train net output #0: loss = 0.026957 (* 1 = 0.026957 loss)
I0403 08:00:51.029225 10121 sgd_solver.cpp:106] Iteration 2230, lr = 5e-05
I0403 08:00:54.524190 10121 solver.cpp:228] Iteration 2235, loss = 0.0282507
I0403 08:00:54.524298 10121 solver.cpp:244]     Train net output #0: loss = 0.0282505 (* 1 = 0.0282505 loss)
I0403 08:00:54.708012 10121 sgd_solver.cpp:106] Iteration 2235, lr = 5e-05
I0403 08:00:58.086410 10121 solver.cpp:228] Iteration 2240, loss = 0.0375473
I0403 08:00:58.086508 10121 solver.cpp:244]     Train net output #0: loss = 0.0375471 (* 1 = 0.0375471 loss)
I0403 08:00:58.275874 10121 sgd_solver.cpp:106] Iteration 2240, lr = 5e-05
I0403 08:01:01.693125 10121 solver.cpp:228] Iteration 2245, loss = 0.0100857
I0403 08:01:01.693418 10121 solver.cpp:244]     Train net output #0: loss = 0.0100855 (* 1 = 0.0100855 loss)
I0403 08:01:01.870338 10121 sgd_solver.cpp:106] Iteration 2245, lr = 5e-05
I0403 08:01:05.362138 10121 solver.cpp:228] Iteration 2250, loss = 0.0032082
I0403 08:01:05.362241 10121 solver.cpp:244]     Train net output #0: loss = 0.00320801 (* 1 = 0.00320801 loss)
I0403 08:01:05.582592 10121 sgd_solver.cpp:106] Iteration 2250, lr = 5e-05
I0403 08:01:09.081513 10121 solver.cpp:228] Iteration 2255, loss = 0.0309447
I0403 08:01:09.081598 10121 solver.cpp:244]     Train net output #0: loss = 0.0309445 (* 1 = 0.0309445 loss)
I0403 08:01:09.234429 10121 sgd_solver.cpp:106] Iteration 2255, lr = 5e-05
I0403 08:01:12.729233 10121 solver.cpp:228] Iteration 2260, loss = 0.0529115
I0403 08:01:12.729331 10121 solver.cpp:244]     Train net output #0: loss = 0.0529113 (* 1 = 0.0529113 loss)
I0403 08:01:12.927011 10121 sgd_solver.cpp:106] Iteration 2260, lr = 5e-05
I0403 08:01:16.365053 10121 solver.cpp:228] Iteration 2265, loss = 0.00988948
I0403 08:01:16.365150 10121 solver.cpp:244]     Train net output #0: loss = 0.00988929 (* 1 = 0.00988929 loss)
I0403 08:01:16.605247 10121 sgd_solver.cpp:106] Iteration 2265, lr = 5e-05
I0403 08:01:18.101698 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2268.caffemodel
I0403 08:01:20.772006 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2268.solverstate
I0403 08:01:22.580904 10121 solver.cpp:337] Iteration 2268, Testing net (#0)
I0403 08:03:00.446692 10121 solver.cpp:404]     Test net output #0: accuracy = 0.912282
I0403 08:03:00.447037 10121 solver.cpp:404]     Test net output #1: loss = 0.371243 (* 1 = 0.371243 loss)
I0403 08:03:02.424266 10121 solver.cpp:228] Iteration 2270, loss = 0.0557959
I0403 08:03:02.424352 10121 solver.cpp:244]     Train net output #0: loss = 0.0557957 (* 1 = 0.0557957 loss)
I0403 08:03:02.603803 10121 sgd_solver.cpp:106] Iteration 2270, lr = 5e-05
I0403 08:03:06.039863 10121 solver.cpp:228] Iteration 2275, loss = 0.0309472
I0403 08:03:06.039958 10121 solver.cpp:244]     Train net output #0: loss = 0.0309471 (* 1 = 0.0309471 loss)
I0403 08:03:06.246124 10121 sgd_solver.cpp:106] Iteration 2275, lr = 5e-05
I0403 08:03:09.703518 10121 solver.cpp:228] Iteration 2280, loss = 0.0437537
I0403 08:03:09.703606 10121 solver.cpp:244]     Train net output #0: loss = 0.0437535 (* 1 = 0.0437535 loss)
I0403 08:03:09.888722 10121 sgd_solver.cpp:106] Iteration 2280, lr = 5e-05
I0403 08:03:13.293170 10121 solver.cpp:228] Iteration 2285, loss = 0.0701332
I0403 08:03:13.293272 10121 solver.cpp:244]     Train net output #0: loss = 0.0701331 (* 1 = 0.0701331 loss)
I0403 08:03:13.514909 10121 sgd_solver.cpp:106] Iteration 2285, lr = 5e-05
I0403 08:03:16.957574 10121 solver.cpp:228] Iteration 2290, loss = 0.0483813
I0403 08:03:16.957672 10121 solver.cpp:244]     Train net output #0: loss = 0.0483811 (* 1 = 0.0483811 loss)
I0403 08:03:17.223157 10121 sgd_solver.cpp:106] Iteration 2290, lr = 5e-05
I0403 08:03:20.701889 10121 solver.cpp:228] Iteration 2295, loss = 0.00707996
I0403 08:03:20.701983 10121 solver.cpp:244]     Train net output #0: loss = 0.00707978 (* 1 = 0.00707978 loss)
I0403 08:03:20.910698 10121 sgd_solver.cpp:106] Iteration 2295, lr = 5e-05
I0403 08:03:24.338253 10121 solver.cpp:228] Iteration 2300, loss = 0.0444353
I0403 08:03:24.338346 10121 solver.cpp:244]     Train net output #0: loss = 0.0444352 (* 1 = 0.0444352 loss)
I0403 08:03:24.540696 10121 sgd_solver.cpp:106] Iteration 2300, lr = 5e-05
I0403 08:03:28.016685 10121 solver.cpp:228] Iteration 2305, loss = 0.0218939
I0403 08:03:28.016773 10121 solver.cpp:244]     Train net output #0: loss = 0.0218937 (* 1 = 0.0218937 loss)
I0403 08:03:28.168699 10121 sgd_solver.cpp:106] Iteration 2305, lr = 5e-05
I0403 08:03:31.767148 10121 solver.cpp:228] Iteration 2310, loss = 0.0500695
I0403 08:03:31.767467 10121 solver.cpp:244]     Train net output #0: loss = 0.0500693 (* 1 = 0.0500693 loss)
I0403 08:03:31.945502 10121 sgd_solver.cpp:106] Iteration 2310, lr = 5e-05
I0403 08:03:35.348342 10121 solver.cpp:228] Iteration 2315, loss = 0.0225769
I0403 08:03:35.348426 10121 solver.cpp:244]     Train net output #0: loss = 0.0225767 (* 1 = 0.0225767 loss)
I0403 08:03:35.525044 10121 sgd_solver.cpp:106] Iteration 2315, lr = 5e-05
I0403 08:03:39.021378 10121 solver.cpp:228] Iteration 2320, loss = 0.0192747
I0403 08:03:39.021476 10121 solver.cpp:244]     Train net output #0: loss = 0.0192745 (* 1 = 0.0192745 loss)
I0403 08:03:39.216567 10121 sgd_solver.cpp:106] Iteration 2320, lr = 5e-05
I0403 08:03:42.636059 10121 solver.cpp:228] Iteration 2325, loss = 0.0398865
I0403 08:03:42.636155 10121 solver.cpp:244]     Train net output #0: loss = 0.0398863 (* 1 = 0.0398863 loss)
I0403 08:03:42.832305 10121 sgd_solver.cpp:106] Iteration 2325, lr = 5e-05
I0403 08:03:46.248785 10121 solver.cpp:228] Iteration 2330, loss = 0.0459048
I0403 08:03:46.248883 10121 solver.cpp:244]     Train net output #0: loss = 0.0459047 (* 1 = 0.0459047 loss)
I0403 08:03:46.445729 10121 sgd_solver.cpp:106] Iteration 2330, lr = 5e-05
I0403 08:03:49.904743 10121 solver.cpp:228] Iteration 2335, loss = 0.0523372
I0403 08:03:49.904839 10121 solver.cpp:244]     Train net output #0: loss = 0.052337 (* 1 = 0.052337 loss)
I0403 08:03:50.109844 10121 sgd_solver.cpp:106] Iteration 2335, lr = 5e-05
I0403 08:03:53.557731 10121 solver.cpp:228] Iteration 2340, loss = 0.0572189
I0403 08:03:53.557826 10121 solver.cpp:244]     Train net output #0: loss = 0.0572187 (* 1 = 0.0572187 loss)
I0403 08:03:53.786286 10121 sgd_solver.cpp:106] Iteration 2340, lr = 5e-05
I0403 08:03:57.193004 10121 solver.cpp:228] Iteration 2345, loss = 0.0523547
I0403 08:03:57.193089 10121 solver.cpp:244]     Train net output #0: loss = 0.0523545 (* 1 = 0.0523545 loss)
I0403 08:03:57.368746 10121 sgd_solver.cpp:106] Iteration 2345, lr = 5e-05
I0403 08:04:00.804738 10121 solver.cpp:228] Iteration 2350, loss = 0.0274347
I0403 08:04:00.804836 10121 solver.cpp:244]     Train net output #0: loss = 0.0274346 (* 1 = 0.0274346 loss)
I0403 08:04:00.997705 10121 sgd_solver.cpp:106] Iteration 2350, lr = 5e-05
I0403 08:04:04.418675 10121 solver.cpp:228] Iteration 2355, loss = 0.0620293
I0403 08:04:04.422696 10121 solver.cpp:244]     Train net output #0: loss = 0.0620291 (* 1 = 0.0620291 loss)
I0403 08:04:04.616194 10121 sgd_solver.cpp:106] Iteration 2355, lr = 5e-05
I0403 08:04:08.119593 10121 solver.cpp:228] Iteration 2360, loss = 0.0099446
I0403 08:04:08.119689 10121 solver.cpp:244]     Train net output #0: loss = 0.0099444 (* 1 = 0.0099444 loss)
I0403 08:04:08.305657 10121 sgd_solver.cpp:106] Iteration 2360, lr = 5e-05
I0403 08:04:11.765439 10121 solver.cpp:228] Iteration 2365, loss = 0.0388629
I0403 08:04:11.765533 10121 solver.cpp:244]     Train net output #0: loss = 0.0388627 (* 1 = 0.0388627 loss)
I0403 08:04:11.954526 10121 sgd_solver.cpp:106] Iteration 2365, lr = 5e-05
I0403 08:04:15.424424 10121 solver.cpp:228] Iteration 2370, loss = 0.00404837
I0403 08:04:15.424510 10121 solver.cpp:244]     Train net output #0: loss = 0.00404817 (* 1 = 0.00404817 loss)
I0403 08:04:15.599335 10121 sgd_solver.cpp:106] Iteration 2370, lr = 5e-05
I0403 08:04:19.067126 10121 solver.cpp:228] Iteration 2375, loss = 0.0944714
I0403 08:04:19.067221 10121 solver.cpp:244]     Train net output #0: loss = 0.0944712 (* 1 = 0.0944712 loss)
I0403 08:04:19.291028 10121 sgd_solver.cpp:106] Iteration 2375, lr = 5e-05
I0403 08:04:19.291285 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2376.caffemodel
I0403 08:04:22.034593 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2376.solverstate
I0403 08:04:23.923666 10121 solver.cpp:337] Iteration 2376, Testing net (#0)
I0403 08:06:01.791276 10121 solver.cpp:404]     Test net output #0: accuracy = 0.912282
I0403 08:06:01.791594 10121 solver.cpp:404]     Test net output #1: loss = 0.37266 (* 1 = 0.37266 loss)
I0403 08:06:05.204164 10121 solver.cpp:228] Iteration 2380, loss = 0.0371047
I0403 08:06:05.204253 10121 solver.cpp:244]     Train net output #0: loss = 0.0371045 (* 1 = 0.0371045 loss)
I0403 08:06:05.377948 10121 sgd_solver.cpp:106] Iteration 2380, lr = 5e-05
I0403 08:06:08.832109 10121 solver.cpp:228] Iteration 2385, loss = 0.0687923
I0403 08:06:08.832201 10121 solver.cpp:244]     Train net output #0: loss = 0.0687921 (* 1 = 0.0687921 loss)
I0403 08:06:09.024031 10121 sgd_solver.cpp:106] Iteration 2385, lr = 5e-05
I0403 08:06:12.575497 10121 solver.cpp:228] Iteration 2390, loss = 0.0173214
I0403 08:06:12.575592 10121 solver.cpp:244]     Train net output #0: loss = 0.0173212 (* 1 = 0.0173212 loss)
I0403 08:06:12.764235 10121 sgd_solver.cpp:106] Iteration 2390, lr = 5e-05
I0403 08:06:16.303992 10121 solver.cpp:228] Iteration 2395, loss = 0.0176835
I0403 08:06:16.304081 10121 solver.cpp:244]     Train net output #0: loss = 0.0176833 (* 1 = 0.0176833 loss)
I0403 08:06:16.469902 10121 sgd_solver.cpp:106] Iteration 2395, lr = 5e-05
I0403 08:06:19.986968 10121 solver.cpp:228] Iteration 2400, loss = 0.0235746
I0403 08:06:19.987064 10121 solver.cpp:244]     Train net output #0: loss = 0.0235744 (* 1 = 0.0235744 loss)
I0403 08:06:20.191679 10121 sgd_solver.cpp:106] Iteration 2400, lr = 5e-05
I0403 08:06:23.668371 10121 solver.cpp:228] Iteration 2405, loss = 0.0271861
I0403 08:06:23.668467 10121 solver.cpp:244]     Train net output #0: loss = 0.0271859 (* 1 = 0.0271859 loss)
I0403 08:06:23.881816 10121 sgd_solver.cpp:106] Iteration 2405, lr = 5e-05
I0403 08:06:27.345006 10121 solver.cpp:228] Iteration 2410, loss = 0.0171372
I0403 08:06:27.345101 10121 solver.cpp:244]     Train net output #0: loss = 0.017137 (* 1 = 0.017137 loss)
I0403 08:06:27.527393 10121 sgd_solver.cpp:106] Iteration 2410, lr = 5e-05
I0403 08:06:30.956383 10121 solver.cpp:228] Iteration 2415, loss = 0.0126736
I0403 08:06:30.956480 10121 solver.cpp:244]     Train net output #0: loss = 0.0126734 (* 1 = 0.0126734 loss)
I0403 08:06:31.213052 10121 sgd_solver.cpp:106] Iteration 2415, lr = 5e-05
I0403 08:06:34.637737 10121 solver.cpp:228] Iteration 2420, loss = 0.0256147
I0403 08:06:34.638072 10121 solver.cpp:244]     Train net output #0: loss = 0.0256145 (* 1 = 0.0256145 loss)
I0403 08:06:34.820142 10121 sgd_solver.cpp:106] Iteration 2420, lr = 5e-05
I0403 08:06:38.273792 10121 solver.cpp:228] Iteration 2425, loss = 0.0197259
I0403 08:06:38.273880 10121 solver.cpp:244]     Train net output #0: loss = 0.0197257 (* 1 = 0.0197257 loss)
I0403 08:06:38.441269 10121 sgd_solver.cpp:106] Iteration 2425, lr = 5e-05
I0403 08:06:41.887228 10121 solver.cpp:228] Iteration 2430, loss = 0.0702772
I0403 08:06:41.887325 10121 solver.cpp:244]     Train net output #0: loss = 0.070277 (* 1 = 0.070277 loss)
I0403 08:06:42.096482 10121 sgd_solver.cpp:106] Iteration 2430, lr = 5e-05
I0403 08:06:45.559931 10121 solver.cpp:228] Iteration 2435, loss = 0.0239097
I0403 08:06:45.560015 10121 solver.cpp:244]     Train net output #0: loss = 0.0239095 (* 1 = 0.0239095 loss)
I0403 08:06:45.735780 10121 sgd_solver.cpp:106] Iteration 2435, lr = 5e-05
I0403 08:06:49.196393 10121 solver.cpp:228] Iteration 2440, loss = 0.00801285
I0403 08:06:49.196491 10121 solver.cpp:244]     Train net output #0: loss = 0.00801264 (* 1 = 0.00801264 loss)
I0403 08:06:49.385462 10121 sgd_solver.cpp:106] Iteration 2440, lr = 5e-05
I0403 08:06:52.827217 10121 solver.cpp:228] Iteration 2445, loss = 0.0309462
I0403 08:06:52.827312 10121 solver.cpp:244]     Train net output #0: loss = 0.030946 (* 1 = 0.030946 loss)
I0403 08:06:53.022765 10121 sgd_solver.cpp:106] Iteration 2445, lr = 5e-05
I0403 08:06:56.461244 10121 solver.cpp:228] Iteration 2450, loss = 0.0271095
I0403 08:06:56.461338 10121 solver.cpp:244]     Train net output #0: loss = 0.0271093 (* 1 = 0.0271093 loss)
I0403 08:06:56.651116 10121 sgd_solver.cpp:106] Iteration 2450, lr = 5e-05
I0403 08:07:00.139194 10121 solver.cpp:228] Iteration 2455, loss = 0.030982
I0403 08:07:00.139284 10121 solver.cpp:244]     Train net output #0: loss = 0.0309818 (* 1 = 0.0309818 loss)
I0403 08:07:00.310642 10121 sgd_solver.cpp:106] Iteration 2455, lr = 5e-05
I0403 08:07:03.748553 10121 solver.cpp:228] Iteration 2460, loss = 0.0804622
I0403 08:07:03.749608 10121 solver.cpp:244]     Train net output #0: loss = 0.080462 (* 1 = 0.080462 loss)
I0403 08:07:03.922318 10121 sgd_solver.cpp:106] Iteration 2460, lr = 5e-05
I0403 08:07:07.347043 10121 solver.cpp:228] Iteration 2465, loss = 0.0327224
I0403 08:07:07.347407 10121 solver.cpp:244]     Train net output #0: loss = 0.0327222 (* 1 = 0.0327222 loss)
I0403 08:07:07.530745 10121 sgd_solver.cpp:106] Iteration 2465, lr = 5e-05
I0403 08:07:10.919915 10121 solver.cpp:228] Iteration 2470, loss = 0.0163822
I0403 08:07:10.920011 10121 solver.cpp:244]     Train net output #0: loss = 0.016382 (* 1 = 0.016382 loss)
I0403 08:07:11.107512 10121 sgd_solver.cpp:106] Iteration 2470, lr = 5e-05
I0403 08:07:14.486652 10121 solver.cpp:228] Iteration 2475, loss = 0.0142169
I0403 08:07:14.486748 10121 solver.cpp:244]     Train net output #0: loss = 0.0142167 (* 1 = 0.0142167 loss)
I0403 08:07:14.671769 10121 sgd_solver.cpp:106] Iteration 2475, lr = 5e-05
I0403 08:07:18.083097 10121 solver.cpp:228] Iteration 2480, loss = 0.119108
I0403 08:07:18.083194 10121 solver.cpp:244]     Train net output #0: loss = 0.119108 (* 1 = 0.119108 loss)
I0403 08:07:18.295657 10121 sgd_solver.cpp:106] Iteration 2480, lr = 5e-05
I0403 08:07:20.505798 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2484.caffemodel
I0403 08:07:23.304780 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2484.solverstate
I0403 08:07:25.223821 10121 solver.cpp:337] Iteration 2484, Testing net (#0)
I0403 08:09:03.093830 10121 solver.cpp:404]     Test net output #0: accuracy = 0.912996
I0403 08:09:03.094149 10121 solver.cpp:404]     Test net output #1: loss = 0.371003 (* 1 = 0.371003 loss)
I0403 08:09:04.321938 10121 solver.cpp:228] Iteration 2485, loss = 0.017705
I0403 08:09:04.322026 10121 solver.cpp:244]     Train net output #0: loss = 0.0177048 (* 1 = 0.0177048 loss)
I0403 08:09:04.508290 10121 sgd_solver.cpp:106] Iteration 2485, lr = 5e-05
I0403 08:09:07.964639 10121 solver.cpp:228] Iteration 2490, loss = 0.0335328
I0403 08:09:07.964741 10121 solver.cpp:244]     Train net output #0: loss = 0.0335325 (* 1 = 0.0335325 loss)
I0403 08:09:08.174617 10121 sgd_solver.cpp:106] Iteration 2490, lr = 5e-05
I0403 08:09:11.657402 10121 solver.cpp:228] Iteration 2495, loss = 0.0542349
I0403 08:09:11.657495 10121 solver.cpp:244]     Train net output #0: loss = 0.0542347 (* 1 = 0.0542347 loss)
I0403 08:09:11.856941 10121 sgd_solver.cpp:106] Iteration 2495, lr = 5e-05
I0403 08:09:15.431177 10121 solver.cpp:228] Iteration 2500, loss = 0.0533933
I0403 08:09:15.431267 10121 solver.cpp:244]     Train net output #0: loss = 0.0533931 (* 1 = 0.0533931 loss)
I0403 08:09:15.576401 10121 sgd_solver.cpp:106] Iteration 2500, lr = 5e-05
I0403 08:09:19.283234 10121 solver.cpp:228] Iteration 2505, loss = 0.0266404
I0403 08:09:19.283334 10121 solver.cpp:244]     Train net output #0: loss = 0.0266402 (* 1 = 0.0266402 loss)
I0403 08:09:19.514319 10121 sgd_solver.cpp:106] Iteration 2505, lr = 5e-05
I0403 08:09:22.925480 10121 solver.cpp:228] Iteration 2510, loss = 0.024266
I0403 08:09:22.925588 10121 solver.cpp:244]     Train net output #0: loss = 0.0242658 (* 1 = 0.0242658 loss)
I0403 08:09:23.133431 10121 sgd_solver.cpp:106] Iteration 2510, lr = 5e-05
I0403 08:09:26.568280 10121 solver.cpp:228] Iteration 2515, loss = 0.0236521
I0403 08:09:26.568367 10121 solver.cpp:244]     Train net output #0: loss = 0.0236518 (* 1 = 0.0236518 loss)
I0403 08:09:26.749243 10121 sgd_solver.cpp:106] Iteration 2515, lr = 5e-05
I0403 08:09:30.174558 10121 solver.cpp:228] Iteration 2520, loss = 0.0172819
I0403 08:09:30.174661 10121 solver.cpp:244]     Train net output #0: loss = 0.0172817 (* 1 = 0.0172817 loss)
I0403 08:09:30.359906 10121 sgd_solver.cpp:106] Iteration 2520, lr = 5e-05
I0403 08:09:33.843782 10121 solver.cpp:228] Iteration 2525, loss = 0.0321767
I0403 08:09:33.844120 10121 solver.cpp:244]     Train net output #0: loss = 0.0321765 (* 1 = 0.0321765 loss)
I0403 08:09:34.024742 10121 sgd_solver.cpp:106] Iteration 2525, lr = 5e-05
I0403 08:09:37.442057 10121 solver.cpp:228] Iteration 2530, loss = 0.0189479
I0403 08:09:37.442142 10121 solver.cpp:244]     Train net output #0: loss = 0.0189477 (* 1 = 0.0189477 loss)
I0403 08:09:37.614573 10121 sgd_solver.cpp:106] Iteration 2530, lr = 5e-05
I0403 08:09:41.104164 10121 solver.cpp:228] Iteration 2535, loss = 0.0270925
I0403 08:09:41.104256 10121 solver.cpp:244]     Train net output #0: loss = 0.0270923 (* 1 = 0.0270923 loss)
I0403 08:09:41.268168 10121 sgd_solver.cpp:106] Iteration 2535, lr = 5e-05
I0403 08:09:44.817703 10121 solver.cpp:228] Iteration 2540, loss = 0.00574365
I0403 08:09:44.817796 10121 solver.cpp:244]     Train net output #0: loss = 0.00574342 (* 1 = 0.00574342 loss)
I0403 08:09:45.015806 10121 sgd_solver.cpp:106] Iteration 2540, lr = 5e-05
I0403 08:09:48.579347 10121 solver.cpp:228] Iteration 2545, loss = 0.0404386
I0403 08:09:48.579442 10121 solver.cpp:244]     Train net output #0: loss = 0.0404383 (* 1 = 0.0404383 loss)
I0403 08:09:48.762181 10121 sgd_solver.cpp:106] Iteration 2545, lr = 5e-05
I0403 08:09:52.162091 10121 solver.cpp:228] Iteration 2550, loss = 0.0131708
I0403 08:09:52.162175 10121 solver.cpp:244]     Train net output #0: loss = 0.0131706 (* 1 = 0.0131706 loss)
I0403 08:09:52.340258 10121 sgd_solver.cpp:106] Iteration 2550, lr = 5e-05
I0403 08:09:55.782232 10121 solver.cpp:228] Iteration 2555, loss = 0.0134321
I0403 08:09:55.782328 10121 solver.cpp:244]     Train net output #0: loss = 0.0134319 (* 1 = 0.0134319 loss)
I0403 08:09:55.981761 10121 sgd_solver.cpp:106] Iteration 2555, lr = 5e-05
I0403 08:09:59.431854 10121 solver.cpp:228] Iteration 2560, loss = 0.0499396
I0403 08:09:59.431949 10121 solver.cpp:244]     Train net output #0: loss = 0.0499394 (* 1 = 0.0499394 loss)
I0403 08:09:59.615375 10121 sgd_solver.cpp:106] Iteration 2560, lr = 5e-05
I0403 08:10:03.040534 10121 solver.cpp:228] Iteration 2565, loss = 0.0354701
I0403 08:10:03.040621 10121 solver.cpp:244]     Train net output #0: loss = 0.0354699 (* 1 = 0.0354699 loss)
I0403 08:10:03.222024 10121 sgd_solver.cpp:106] Iteration 2565, lr = 5e-05
I0403 08:10:06.604732 10121 solver.cpp:228] Iteration 2570, loss = 0.0220586
I0403 08:10:06.605063 10121 solver.cpp:244]     Train net output #0: loss = 0.0220584 (* 1 = 0.0220584 loss)
I0403 08:10:06.788545 10121 sgd_solver.cpp:106] Iteration 2570, lr = 5e-05
I0403 08:10:10.234410 10121 solver.cpp:228] Iteration 2575, loss = 0.0150763
I0403 08:10:10.234506 10121 solver.cpp:244]     Train net output #0: loss = 0.0150761 (* 1 = 0.0150761 loss)
I0403 08:10:10.438406 10121 sgd_solver.cpp:106] Iteration 2575, lr = 5e-05
I0403 08:10:13.843451 10121 solver.cpp:228] Iteration 2580, loss = 0.0379608
I0403 08:10:13.843546 10121 solver.cpp:244]     Train net output #0: loss = 0.0379606 (* 1 = 0.0379606 loss)
I0403 08:10:14.051326 10121 sgd_solver.cpp:106] Iteration 2580, lr = 5e-05
I0403 08:10:17.461329 10121 solver.cpp:228] Iteration 2585, loss = 0.016022
I0403 08:10:17.461423 10121 solver.cpp:244]     Train net output #0: loss = 0.0160218 (* 1 = 0.0160218 loss)
I0403 08:10:17.667083 10121 sgd_solver.cpp:106] Iteration 2585, lr = 5e-05
I0403 08:10:21.140956 10121 solver.cpp:228] Iteration 2590, loss = 0.026395
I0403 08:10:21.141046 10121 solver.cpp:244]     Train net output #0: loss = 0.0263947 (* 1 = 0.0263947 loss)
I0403 08:10:21.318292 10121 sgd_solver.cpp:106] Iteration 2590, lr = 5e-05
I0403 08:10:22.054599 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2592.caffemodel
I0403 08:10:24.722311 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2592.solverstate
I0403 08:10:26.530387 10121 solver.cpp:337] Iteration 2592, Testing net (#0)
I0403 08:12:04.420944 10121 solver.cpp:404]     Test net output #0: accuracy = 0.91295
I0403 08:12:04.422574 10121 solver.cpp:404]     Test net output #1: loss = 0.370986 (* 1 = 0.370986 loss)
I0403 08:12:07.106703 10121 solver.cpp:228] Iteration 2595, loss = 0.021752
I0403 08:12:07.106791 10121 solver.cpp:244]     Train net output #0: loss = 0.0217517 (* 1 = 0.0217517 loss)
I0403 08:12:07.288245 10121 sgd_solver.cpp:106] Iteration 2595, lr = 5e-05
I0403 08:12:10.716770 10121 solver.cpp:228] Iteration 2600, loss = 0.00496571
I0403 08:12:10.716866 10121 solver.cpp:244]     Train net output #0: loss = 0.00496549 (* 1 = 0.00496549 loss)
I0403 08:12:10.942581 10121 sgd_solver.cpp:106] Iteration 2600, lr = 5e-05
I0403 08:12:14.348078 10121 solver.cpp:228] Iteration 2605, loss = 0.0356355
I0403 08:12:14.348173 10121 solver.cpp:244]     Train net output #0: loss = 0.0356353 (* 1 = 0.0356353 loss)
I0403 08:12:14.537941 10121 sgd_solver.cpp:106] Iteration 2605, lr = 5e-05
I0403 08:12:18.008822 10121 solver.cpp:228] Iteration 2610, loss = 0.0260155
I0403 08:12:18.008914 10121 solver.cpp:244]     Train net output #0: loss = 0.0260153 (* 1 = 0.0260153 loss)
I0403 08:12:18.192677 10121 sgd_solver.cpp:106] Iteration 2610, lr = 5e-05
I0403 08:12:21.678038 10121 solver.cpp:228] Iteration 2615, loss = 0.0566668
I0403 08:12:21.678125 10121 solver.cpp:244]     Train net output #0: loss = 0.0566666 (* 1 = 0.0566666 loss)
I0403 08:12:21.847998 10121 sgd_solver.cpp:106] Iteration 2615, lr = 5e-05
I0403 08:12:25.383857 10121 solver.cpp:228] Iteration 2620, loss = 0.0143546
I0403 08:12:25.383954 10121 solver.cpp:244]     Train net output #0: loss = 0.0143544 (* 1 = 0.0143544 loss)
I0403 08:12:25.568608 10121 sgd_solver.cpp:106] Iteration 2620, lr = 5e-05
I0403 08:12:29.048276 10121 solver.cpp:228] Iteration 2625, loss = 0.0944805
I0403 08:12:29.048372 10121 solver.cpp:244]     Train net output #0: loss = 0.0944803 (* 1 = 0.0944803 loss)
I0403 08:12:29.249539 10121 sgd_solver.cpp:106] Iteration 2625, lr = 5e-05
I0403 08:12:32.658061 10121 solver.cpp:228] Iteration 2630, loss = 0.00810726
I0403 08:12:32.658149 10121 solver.cpp:244]     Train net output #0: loss = 0.00810704 (* 1 = 0.00810704 loss)
I0403 08:12:32.849761 10121 sgd_solver.cpp:106] Iteration 2630, lr = 5e-05
I0403 08:12:36.284041 10121 solver.cpp:228] Iteration 2635, loss = 0.0408503
I0403 08:12:36.284346 10121 solver.cpp:244]     Train net output #0: loss = 0.0408501 (* 1 = 0.0408501 loss)
I0403 08:12:36.456609 10121 sgd_solver.cpp:106] Iteration 2635, lr = 5e-05
I0403 08:12:40.026657 10121 solver.cpp:228] Iteration 2640, loss = 0.0157171
I0403 08:12:40.026742 10121 solver.cpp:244]     Train net output #0: loss = 0.0157169 (* 1 = 0.0157169 loss)
I0403 08:12:40.206943 10121 sgd_solver.cpp:106] Iteration 2640, lr = 5e-05
I0403 08:12:43.674996 10121 solver.cpp:228] Iteration 2645, loss = 0.0351567
I0403 08:12:43.675092 10121 solver.cpp:244]     Train net output #0: loss = 0.0351565 (* 1 = 0.0351565 loss)
I0403 08:12:43.858309 10121 sgd_solver.cpp:106] Iteration 2645, lr = 5e-05
I0403 08:12:47.378427 10121 solver.cpp:228] Iteration 2650, loss = 0.0190797
I0403 08:12:47.378511 10121 solver.cpp:244]     Train net output #0: loss = 0.0190795 (* 1 = 0.0190795 loss)
I0403 08:12:47.558773 10121 sgd_solver.cpp:106] Iteration 2650, lr = 5e-05
I0403 08:12:50.962263 10121 solver.cpp:228] Iteration 2655, loss = 0.0403745
I0403 08:12:50.962358 10121 solver.cpp:244]     Train net output #0: loss = 0.0403742 (* 1 = 0.0403742 loss)
I0403 08:12:51.167832 10121 sgd_solver.cpp:106] Iteration 2655, lr = 5e-05
I0403 08:12:54.632355 10121 solver.cpp:228] Iteration 2660, loss = 0.0367966
I0403 08:12:54.632452 10121 solver.cpp:244]     Train net output #0: loss = 0.0367964 (* 1 = 0.0367964 loss)
I0403 08:12:54.864373 10121 sgd_solver.cpp:106] Iteration 2660, lr = 5e-05
I0403 08:12:58.307596 10121 solver.cpp:228] Iteration 2665, loss = 0.0265392
I0403 08:12:58.307692 10121 solver.cpp:244]     Train net output #0: loss = 0.0265389 (* 1 = 0.0265389 loss)
I0403 08:12:58.492823 10121 sgd_solver.cpp:106] Iteration 2665, lr = 5e-05
I0403 08:13:01.939721 10121 solver.cpp:228] Iteration 2670, loss = 0.0632925
I0403 08:13:01.940855 10121 solver.cpp:244]     Train net output #0: loss = 0.0632923 (* 1 = 0.0632923 loss)
I0403 08:13:02.088879 10121 sgd_solver.cpp:106] Iteration 2670, lr = 5e-05
I0403 08:13:05.656627 10121 solver.cpp:228] Iteration 2675, loss = 0.0220601
I0403 08:13:05.656723 10121 solver.cpp:244]     Train net output #0: loss = 0.0220599 (* 1 = 0.0220599 loss)
I0403 08:13:05.845592 10121 sgd_solver.cpp:106] Iteration 2675, lr = 5e-05
I0403 08:13:09.241677 10121 solver.cpp:228] Iteration 2680, loss = 0.0379883
I0403 08:13:09.242010 10121 solver.cpp:244]     Train net output #0: loss = 0.0379881 (* 1 = 0.0379881 loss)
I0403 08:13:09.435639 10121 sgd_solver.cpp:106] Iteration 2680, lr = 5e-05
I0403 08:13:12.897253 10121 solver.cpp:228] Iteration 2685, loss = 0.0175113
I0403 08:13:12.897351 10121 solver.cpp:244]     Train net output #0: loss = 0.0175111 (* 1 = 0.0175111 loss)
I0403 08:13:13.087870 10121 sgd_solver.cpp:106] Iteration 2685, lr = 5e-05
I0403 08:13:16.546813 10121 solver.cpp:228] Iteration 2690, loss = 0.0623489
I0403 08:13:16.546900 10121 solver.cpp:244]     Train net output #0: loss = 0.0623487 (* 1 = 0.0623487 loss)
I0403 08:13:16.719362 10121 sgd_solver.cpp:106] Iteration 2690, lr = 5e-05
I0403 08:13:20.154157 10121 solver.cpp:228] Iteration 2695, loss = 0.0700054
I0403 08:13:20.154258 10121 solver.cpp:244]     Train net output #0: loss = 0.0700052 (* 1 = 0.0700052 loss)
I0403 08:13:20.384026 10121 sgd_solver.cpp:106] Iteration 2695, lr = 5e-05
I0403 08:13:23.268221 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2700.caffemodel
I0403 08:13:25.926450 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2700.solverstate
I0403 08:13:27.724499 10121 solver.cpp:337] Iteration 2700, Testing net (#0)
I0403 08:15:05.578428 10121 solver.cpp:404]     Test net output #0: accuracy = 0.913065
I0403 08:15:05.578744 10121 solver.cpp:404]     Test net output #1: loss = 0.369317 (* 1 = 0.369317 loss)
I0403 08:15:06.105777 10121 solver.cpp:228] Iteration 2700, loss = 0.0726624
I0403 08:15:06.105860 10121 solver.cpp:244]     Train net output #0: loss = 0.0726622 (* 1 = 0.0726622 loss)
I0403 08:15:06.259132 10121 sgd_solver.cpp:106] Iteration 2700, lr = 5e-05
I0403 08:15:09.836951 10121 solver.cpp:228] Iteration 2705, loss = 0.0212231
I0403 08:15:09.837045 10121 solver.cpp:244]     Train net output #0: loss = 0.0212229 (* 1 = 0.0212229 loss)
I0403 08:15:10.028945 10121 sgd_solver.cpp:106] Iteration 2705, lr = 5e-05
I0403 08:15:13.478052 10121 solver.cpp:228] Iteration 2710, loss = 0.0572815
I0403 08:15:13.478147 10121 solver.cpp:244]     Train net output #0: loss = 0.0572813 (* 1 = 0.0572813 loss)
I0403 08:15:13.660392 10121 sgd_solver.cpp:106] Iteration 2710, lr = 5e-05
I0403 08:15:17.134806 10121 solver.cpp:228] Iteration 2715, loss = 0.0356611
I0403 08:15:17.134902 10121 solver.cpp:244]     Train net output #0: loss = 0.0356609 (* 1 = 0.0356609 loss)
I0403 08:15:17.323061 10121 sgd_solver.cpp:106] Iteration 2715, lr = 5e-05
I0403 08:15:20.791319 10121 solver.cpp:228] Iteration 2720, loss = 0.074794
I0403 08:15:20.791414 10121 solver.cpp:244]     Train net output #0: loss = 0.0747938 (* 1 = 0.0747938 loss)
I0403 08:15:21.006981 10121 sgd_solver.cpp:106] Iteration 2720, lr = 5e-05
I0403 08:15:24.453105 10121 solver.cpp:228] Iteration 2725, loss = 0.0190991
I0403 08:15:24.453203 10121 solver.cpp:244]     Train net output #0: loss = 0.0190989 (* 1 = 0.0190989 loss)
I0403 08:15:24.655274 10121 sgd_solver.cpp:106] Iteration 2725, lr = 5e-05
I0403 08:15:28.064512 10121 solver.cpp:228] Iteration 2730, loss = 0.0263485
I0403 08:15:28.064610 10121 solver.cpp:244]     Train net output #0: loss = 0.0263483 (* 1 = 0.0263483 loss)
I0403 08:15:28.266096 10121 sgd_solver.cpp:106] Iteration 2730, lr = 5e-05
I0403 08:15:31.648133 10121 solver.cpp:228] Iteration 2735, loss = 0.0300348
I0403 08:15:31.649304 10121 solver.cpp:244]     Train net output #0: loss = 0.0300346 (* 1 = 0.0300346 loss)
I0403 08:15:31.912847 10121 sgd_solver.cpp:106] Iteration 2735, lr = 5e-05
I0403 08:15:35.419315 10121 solver.cpp:228] Iteration 2740, loss = 0.0203235
I0403 08:15:35.419410 10121 solver.cpp:244]     Train net output #0: loss = 0.0203233 (* 1 = 0.0203233 loss)
I0403 08:15:35.612818 10121 sgd_solver.cpp:106] Iteration 2740, lr = 5e-05
I0403 08:15:39.057076 10121 solver.cpp:228] Iteration 2745, loss = 0.0403619
I0403 08:15:39.057169 10121 solver.cpp:244]     Train net output #0: loss = 0.0403617 (* 1 = 0.0403617 loss)
I0403 08:15:39.241701 10121 sgd_solver.cpp:106] Iteration 2745, lr = 5e-05
I0403 08:15:42.665426 10121 solver.cpp:228] Iteration 2750, loss = 0.00983326
I0403 08:15:42.665511 10121 solver.cpp:244]     Train net output #0: loss = 0.00983306 (* 1 = 0.00983306 loss)
I0403 08:15:42.847026 10121 sgd_solver.cpp:106] Iteration 2750, lr = 5e-05
I0403 08:15:46.423058 10121 solver.cpp:228] Iteration 2755, loss = 0.0538235
I0403 08:15:46.423146 10121 solver.cpp:244]     Train net output #0: loss = 0.0538233 (* 1 = 0.0538233 loss)
I0403 08:15:46.599604 10121 sgd_solver.cpp:106] Iteration 2755, lr = 5e-05
I0403 08:15:50.046430 10121 solver.cpp:228] Iteration 2760, loss = 0.0651519
I0403 08:15:50.046528 10121 solver.cpp:244]     Train net output #0: loss = 0.0651517 (* 1 = 0.0651517 loss)
I0403 08:15:50.236280 10121 sgd_solver.cpp:106] Iteration 2760, lr = 5e-05
I0403 08:15:53.727260 10121 solver.cpp:228] Iteration 2765, loss = 0.0475188
I0403 08:15:53.727355 10121 solver.cpp:244]     Train net output #0: loss = 0.0475186 (* 1 = 0.0475186 loss)
I0403 08:15:53.921664 10121 sgd_solver.cpp:106] Iteration 2765, lr = 5e-05
I0403 08:15:57.405764 10121 solver.cpp:228] Iteration 2770, loss = 0.0197854
I0403 08:15:57.405860 10121 solver.cpp:244]     Train net output #0: loss = 0.0197852 (* 1 = 0.0197852 loss)
I0403 08:15:57.605049 10121 sgd_solver.cpp:106] Iteration 2770, lr = 5e-05
I0403 08:16:01.129345 10121 solver.cpp:228] Iteration 2775, loss = 0.0271316
I0403 08:16:01.129441 10121 solver.cpp:244]     Train net output #0: loss = 0.0271314 (* 1 = 0.0271314 loss)
I0403 08:16:01.326225 10121 sgd_solver.cpp:106] Iteration 2775, lr = 5e-05
I0403 08:16:04.741744 10121 solver.cpp:228] Iteration 2780, loss = 0.0453671
I0403 08:16:04.741828 10121 solver.cpp:244]     Train net output #0: loss = 0.0453669 (* 1 = 0.0453669 loss)
I0403 08:16:04.920115 10121 sgd_solver.cpp:106] Iteration 2780, lr = 5e-05
I0403 08:16:08.444574 10121 solver.cpp:228] Iteration 2785, loss = 0.0377008
I0403 08:16:08.444893 10121 solver.cpp:244]     Train net output #0: loss = 0.0377006 (* 1 = 0.0377006 loss)
I0403 08:16:08.621948 10121 sgd_solver.cpp:106] Iteration 2785, lr = 5e-05
I0403 08:16:12.184000 10121 solver.cpp:228] Iteration 2790, loss = 0.0647663
I0403 08:16:12.184100 10121 solver.cpp:244]     Train net output #0: loss = 0.0647661 (* 1 = 0.0647661 loss)
I0403 08:16:12.422827 10121 sgd_solver.cpp:106] Iteration 2790, lr = 5e-05
I0403 08:16:15.894022 10121 solver.cpp:228] Iteration 2795, loss = 0.0314128
I0403 08:16:15.894109 10121 solver.cpp:244]     Train net output #0: loss = 0.0314126 (* 1 = 0.0314126 loss)
I0403 08:16:16.072047 10121 sgd_solver.cpp:106] Iteration 2795, lr = 5e-05
I0403 08:16:19.503351 10121 solver.cpp:228] Iteration 2800, loss = 0.0234145
I0403 08:16:19.503448 10121 solver.cpp:244]     Train net output #0: loss = 0.0234143 (* 1 = 0.0234143 loss)
I0403 08:16:19.695739 10121 sgd_solver.cpp:106] Iteration 2800, lr = 5e-05
I0403 08:16:23.137118 10121 solver.cpp:228] Iteration 2805, loss = 0.0667314
I0403 08:16:23.137228 10121 solver.cpp:244]     Train net output #0: loss = 0.0667312 (* 1 = 0.0667312 loss)
I0403 08:16:23.335103 10121 sgd_solver.cpp:106] Iteration 2805, lr = 5e-05
I0403 08:16:24.766829 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2808.caffemodel
I0403 08:16:27.428481 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2808.solverstate
I0403 08:16:29.212309 10121 solver.cpp:337] Iteration 2808, Testing net (#0)
I0403 08:18:07.072149 10121 solver.cpp:404]     Test net output #0: accuracy = 0.913134
I0403 08:18:07.072502 10121 solver.cpp:404]     Test net output #1: loss = 0.369499 (* 1 = 0.369499 loss)
I0403 08:18:09.041683 10121 solver.cpp:228] Iteration 2810, loss = 0.0221762
I0403 08:18:09.041777 10121 solver.cpp:244]     Train net output #0: loss = 0.022176 (* 1 = 0.022176 loss)
I0403 08:18:09.246328 10121 sgd_solver.cpp:106] Iteration 2810, lr = 5e-05
I0403 08:18:12.724974 10121 solver.cpp:228] Iteration 2815, loss = 0.0365334
I0403 08:18:12.725074 10121 solver.cpp:244]     Train net output #0: loss = 0.0365332 (* 1 = 0.0365332 loss)
I0403 08:18:12.935853 10121 sgd_solver.cpp:106] Iteration 2815, lr = 5e-05
I0403 08:18:16.411620 10121 solver.cpp:228] Iteration 2820, loss = 0.0361308
I0403 08:18:16.411717 10121 solver.cpp:244]     Train net output #0: loss = 0.0361306 (* 1 = 0.0361306 loss)
I0403 08:18:16.595564 10121 sgd_solver.cpp:106] Iteration 2820, lr = 5e-05
I0403 08:18:20.038854 10121 solver.cpp:228] Iteration 2825, loss = 0.0201252
I0403 08:18:20.038952 10121 solver.cpp:244]     Train net output #0: loss = 0.020125 (* 1 = 0.020125 loss)
I0403 08:18:20.299438 10121 sgd_solver.cpp:106] Iteration 2825, lr = 5e-05
I0403 08:18:23.731693 10121 solver.cpp:228] Iteration 2830, loss = 0.0198438
I0403 08:18:23.731788 10121 solver.cpp:244]     Train net output #0: loss = 0.0198436 (* 1 = 0.0198436 loss)
I0403 08:18:23.934326 10121 sgd_solver.cpp:106] Iteration 2830, lr = 5e-05
I0403 08:18:27.384682 10121 solver.cpp:228] Iteration 2835, loss = 0.0276403
I0403 08:18:27.384778 10121 solver.cpp:244]     Train net output #0: loss = 0.0276401 (* 1 = 0.0276401 loss)
I0403 08:18:27.584022 10121 sgd_solver.cpp:106] Iteration 2835, lr = 5e-05
I0403 08:18:30.994565 10121 solver.cpp:228] Iteration 2840, loss = 0.0305754
I0403 08:18:30.994662 10121 solver.cpp:244]     Train net output #0: loss = 0.0305752 (* 1 = 0.0305752 loss)
I0403 08:18:31.196082 10121 sgd_solver.cpp:106] Iteration 2840, lr = 5e-05
I0403 08:18:34.648044 10121 solver.cpp:228] Iteration 2845, loss = 0.00806744
I0403 08:18:34.648133 10121 solver.cpp:244]     Train net output #0: loss = 0.00806724 (* 1 = 0.00806724 loss)
I0403 08:18:34.809276 10121 sgd_solver.cpp:106] Iteration 2845, lr = 5e-05
I0403 08:18:38.298002 10121 solver.cpp:228] Iteration 2850, loss = 0.0140412
I0403 08:18:38.298331 10121 solver.cpp:244]     Train net output #0: loss = 0.014041 (* 1 = 0.014041 loss)
I0403 08:18:38.493281 10121 sgd_solver.cpp:106] Iteration 2850, lr = 5e-05
I0403 08:18:41.960081 10121 solver.cpp:228] Iteration 2855, loss = 0.0382644
I0403 08:18:41.960173 10121 solver.cpp:244]     Train net output #0: loss = 0.0382643 (* 1 = 0.0382643 loss)
I0403 08:18:42.165961 10121 sgd_solver.cpp:106] Iteration 2855, lr = 5e-05
I0403 08:18:45.602819 10121 solver.cpp:228] Iteration 2860, loss = 0.0238959
I0403 08:18:45.602910 10121 solver.cpp:244]     Train net output #0: loss = 0.0238957 (* 1 = 0.0238957 loss)
I0403 08:18:45.787123 10121 sgd_solver.cpp:106] Iteration 2860, lr = 5e-05
I0403 08:18:49.215260 10121 solver.cpp:228] Iteration 2865, loss = 0.0139408
I0403 08:18:49.215348 10121 solver.cpp:244]     Train net output #0: loss = 0.0139406 (* 1 = 0.0139406 loss)
I0403 08:18:49.370296 10121 sgd_solver.cpp:106] Iteration 2865, lr = 5e-05
I0403 08:18:53.107583 10121 solver.cpp:228] Iteration 2870, loss = 0.0248629
I0403 08:18:53.107671 10121 solver.cpp:244]     Train net output #0: loss = 0.0248627 (* 1 = 0.0248627 loss)
I0403 08:18:53.277866 10121 sgd_solver.cpp:106] Iteration 2870, lr = 5e-05
I0403 08:18:56.765872 10121 solver.cpp:228] Iteration 2875, loss = 0.00372853
I0403 08:18:56.765966 10121 solver.cpp:244]     Train net output #0: loss = 0.00372833 (* 1 = 0.00372833 loss)
I0403 08:18:56.948616 10121 sgd_solver.cpp:106] Iteration 2875, lr = 5e-05
I0403 08:19:00.347141 10121 solver.cpp:228] Iteration 2880, loss = 0.00693048
I0403 08:19:00.347244 10121 solver.cpp:244]     Train net output #0: loss = 0.00693028 (* 1 = 0.00693028 loss)
I0403 08:19:00.545686 10121 sgd_solver.cpp:106] Iteration 2880, lr = 5e-05
I0403 08:19:04.044512 10121 solver.cpp:228] Iteration 2885, loss = 0.0135962
I0403 08:19:04.044600 10121 solver.cpp:244]     Train net output #0: loss = 0.013596 (* 1 = 0.013596 loss)
I0403 08:19:04.217221 10121 sgd_solver.cpp:106] Iteration 2885, lr = 5e-05
I0403 08:19:07.653866 10121 solver.cpp:228] Iteration 2890, loss = 0.0298938
I0403 08:19:07.653954 10121 solver.cpp:244]     Train net output #0: loss = 0.0298936 (* 1 = 0.0298936 loss)
I0403 08:19:07.817232 10121 sgd_solver.cpp:106] Iteration 2890, lr = 5e-05
I0403 08:19:11.325325 10121 solver.cpp:228] Iteration 2895, loss = 0.0116022
I0403 08:19:11.325675 10121 solver.cpp:244]     Train net output #0: loss = 0.011602 (* 1 = 0.011602 loss)
I0403 08:19:11.506755 10121 sgd_solver.cpp:106] Iteration 2895, lr = 5e-05
I0403 08:19:14.881768 10121 solver.cpp:228] Iteration 2900, loss = 0.0424255
I0403 08:19:14.881852 10121 solver.cpp:244]     Train net output #0: loss = 0.0424253 (* 1 = 0.0424253 loss)
I0403 08:19:15.060776 10121 sgd_solver.cpp:106] Iteration 2900, lr = 5e-05
I0403 08:19:18.467789 10121 solver.cpp:228] Iteration 2905, loss = 0.0257876
I0403 08:19:18.467886 10121 solver.cpp:244]     Train net output #0: loss = 0.0257874 (* 1 = 0.0257874 loss)
I0403 08:19:18.650431 10121 sgd_solver.cpp:106] Iteration 2905, lr = 5e-05
I0403 08:19:22.108486 10121 solver.cpp:228] Iteration 2910, loss = 0.0516992
I0403 08:19:22.108588 10121 solver.cpp:244]     Train net output #0: loss = 0.051699 (* 1 = 0.051699 loss)
I0403 08:19:22.296330 10121 sgd_solver.cpp:106] Iteration 2910, lr = 5e-05
I0403 08:19:25.743597 10121 solver.cpp:228] Iteration 2915, loss = 0.0747878
I0403 08:19:25.743691 10121 solver.cpp:244]     Train net output #0: loss = 0.0747876 (* 1 = 0.0747876 loss)
I0403 08:19:25.926805 10121 sgd_solver.cpp:106] Iteration 2915, lr = 5e-05
I0403 08:19:25.927036 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2916.caffemodel
I0403 08:19:28.683195 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_2916.solverstate
I0403 08:19:30.590729 10121 solver.cpp:337] Iteration 2916, Testing net (#0)
I0403 08:21:08.444470 10121 solver.cpp:404]     Test net output #0: accuracy = 0.913019
I0403 08:21:08.444792 10121 solver.cpp:404]     Test net output #1: loss = 0.370333 (* 1 = 0.370333 loss)
I0403 08:21:11.965848 10121 solver.cpp:228] Iteration 2920, loss = 0.00770343
I0403 08:21:11.965931 10121 solver.cpp:244]     Train net output #0: loss = 0.00770323 (* 1 = 0.00770323 loss)
I0403 08:21:12.136073 10121 sgd_solver.cpp:106] Iteration 2920, lr = 5e-05
I0403 08:21:15.601678 10121 solver.cpp:228] Iteration 2925, loss = 0.0247713
I0403 08:21:15.601773 10121 solver.cpp:244]     Train net output #0: loss = 0.0247711 (* 1 = 0.0247711 loss)
I0403 08:21:15.788259 10121 sgd_solver.cpp:106] Iteration 2925, lr = 5e-05
I0403 08:21:19.314431 10121 solver.cpp:228] Iteration 2930, loss = 0.0512808
I0403 08:21:19.314519 10121 solver.cpp:244]     Train net output #0: loss = 0.0512806 (* 1 = 0.0512806 loss)
I0403 08:21:19.477588 10121 sgd_solver.cpp:106] Iteration 2930, lr = 5e-05
I0403 08:21:22.928536 10121 solver.cpp:228] Iteration 2935, loss = 0.0157529
I0403 08:21:22.928632 10121 solver.cpp:244]     Train net output #0: loss = 0.0157527 (* 1 = 0.0157527 loss)
I0403 08:21:23.115473 10121 sgd_solver.cpp:106] Iteration 2935, lr = 5e-05
I0403 08:21:26.534378 10121 solver.cpp:228] Iteration 2940, loss = 0.0351802
I0403 08:21:26.534474 10121 solver.cpp:244]     Train net output #0: loss = 0.03518 (* 1 = 0.03518 loss)
I0403 08:21:26.728076 10121 sgd_solver.cpp:106] Iteration 2940, lr = 5e-05
I0403 08:21:30.355674 10121 solver.cpp:228] Iteration 2945, loss = 0.020633
I0403 08:21:30.356709 10121 solver.cpp:244]     Train net output #0: loss = 0.0206329 (* 1 = 0.0206329 loss)
I0403 08:21:30.534725 10121 sgd_solver.cpp:106] Iteration 2945, lr = 5e-05
I0403 08:21:33.984484 10121 solver.cpp:228] Iteration 2950, loss = 0.0203617
I0403 08:21:33.984576 10121 solver.cpp:244]     Train net output #0: loss = 0.0203615 (* 1 = 0.0203615 loss)
I0403 08:21:34.191427 10121 sgd_solver.cpp:106] Iteration 2950, lr = 5e-05
I0403 08:21:37.633030 10121 solver.cpp:228] Iteration 2955, loss = 0.00923472
I0403 08:21:37.633124 10121 solver.cpp:244]     Train net output #0: loss = 0.00923453 (* 1 = 0.00923453 loss)
I0403 08:21:37.827559 10121 sgd_solver.cpp:106] Iteration 2955, lr = 5e-05
I0403 08:21:41.285008 10121 solver.cpp:228] Iteration 2960, loss = 0.0472151
I0403 08:21:41.285358 10121 solver.cpp:244]     Train net output #0: loss = 0.0472149 (* 1 = 0.0472149 loss)
I0403 08:21:41.459769 10121 sgd_solver.cpp:106] Iteration 2960, lr = 5e-05
I0403 08:21:44.950412 10121 solver.cpp:228] Iteration 2965, loss = 0.0225746
I0403 08:21:44.950503 10121 solver.cpp:244]     Train net output #0: loss = 0.0225744 (* 1 = 0.0225744 loss)
I0403 08:21:45.099287 10121 sgd_solver.cpp:106] Iteration 2965, lr = 5e-05
I0403 08:21:48.704747 10121 solver.cpp:228] Iteration 2970, loss = 0.04754
I0403 08:21:48.704840 10121 solver.cpp:244]     Train net output #0: loss = 0.0475398 (* 1 = 0.0475398 loss)
I0403 08:21:48.889710 10121 sgd_solver.cpp:106] Iteration 2970, lr = 5e-05
I0403 08:21:52.323668 10121 solver.cpp:228] Iteration 2975, loss = 0.0541743
I0403 08:21:52.323765 10121 solver.cpp:244]     Train net output #0: loss = 0.0541741 (* 1 = 0.0541741 loss)
I0403 08:21:52.518668 10121 sgd_solver.cpp:106] Iteration 2975, lr = 5e-05
I0403 08:21:55.950366 10121 solver.cpp:228] Iteration 2980, loss = 0.101302
I0403 08:21:55.950465 10121 solver.cpp:244]     Train net output #0: loss = 0.101302 (* 1 = 0.101302 loss)
I0403 08:21:56.170296 10121 sgd_solver.cpp:106] Iteration 2980, lr = 5e-05
I0403 08:21:59.575377 10121 solver.cpp:228] Iteration 2985, loss = 0.0615185
I0403 08:21:59.575472 10121 solver.cpp:244]     Train net output #0: loss = 0.0615184 (* 1 = 0.0615184 loss)
I0403 08:21:59.767310 10121 sgd_solver.cpp:106] Iteration 2985, lr = 5e-05
I0403 08:22:03.146723 10121 solver.cpp:228] Iteration 2990, loss = 0.0427763
I0403 08:22:03.146817 10121 solver.cpp:244]     Train net output #0: loss = 0.0427761 (* 1 = 0.0427761 loss)
I0403 08:22:03.357041 10121 sgd_solver.cpp:106] Iteration 2990, lr = 5e-05
I0403 08:22:06.855656 10121 solver.cpp:228] Iteration 2995, loss = 0.0512763
I0403 08:22:06.855753 10121 solver.cpp:244]     Train net output #0: loss = 0.0512761 (* 1 = 0.0512761 loss)
I0403 08:22:07.046177 10121 sgd_solver.cpp:106] Iteration 2995, lr = 5e-05
I0403 08:22:10.446419 10121 solver.cpp:228] Iteration 3000, loss = 0.0103669
I0403 08:22:10.446516 10121 solver.cpp:244]     Train net output #0: loss = 0.0103667 (* 1 = 0.0103667 loss)
I0403 08:22:10.635829 10121 sgd_solver.cpp:106] Iteration 3000, lr = 5e-05
I0403 08:22:14.093508 10121 solver.cpp:228] Iteration 3005, loss = 0.0580758
I0403 08:22:14.093837 10121 solver.cpp:244]     Train net output #0: loss = 0.0580756 (* 1 = 0.0580756 loss)
I0403 08:22:14.277951 10121 sgd_solver.cpp:106] Iteration 3005, lr = 5e-05
I0403 08:22:17.743201 10121 solver.cpp:228] Iteration 3010, loss = 0.0173126
I0403 08:22:17.743297 10121 solver.cpp:244]     Train net output #0: loss = 0.0173124 (* 1 = 0.0173124 loss)
I0403 08:22:17.940029 10121 sgd_solver.cpp:106] Iteration 3010, lr = 5e-05
I0403 08:22:21.354578 10121 solver.cpp:228] Iteration 3015, loss = 0.0368751
I0403 08:22:21.354676 10121 solver.cpp:244]     Train net output #0: loss = 0.036875 (* 1 = 0.036875 loss)
I0403 08:22:21.550433 10121 sgd_solver.cpp:106] Iteration 3015, lr = 5e-05
I0403 08:22:25.043372 10121 solver.cpp:228] Iteration 3020, loss = 0.031683
I0403 08:22:25.043460 10121 solver.cpp:244]     Train net output #0: loss = 0.0316828 (* 1 = 0.0316828 loss)
I0403 08:22:25.214769 10121 sgd_solver.cpp:106] Iteration 3020, lr = 5e-05
I0403 08:22:27.429050 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3024.caffemodel
I0403 08:22:30.169076 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3024.solverstate
I0403 08:22:31.965047 10121 solver.cpp:337] Iteration 3024, Testing net (#0)
I0403 08:24:09.816273 10121 solver.cpp:404]     Test net output #0: accuracy = 0.913134
I0403 08:24:09.816612 10121 solver.cpp:404]     Test net output #1: loss = 0.371198 (* 1 = 0.371198 loss)
I0403 08:24:11.097214 10121 solver.cpp:228] Iteration 3025, loss = 0.0772316
I0403 08:24:11.097302 10121 solver.cpp:244]     Train net output #0: loss = 0.0772314 (* 1 = 0.0772314 loss)
I0403 08:24:11.278348 10121 sgd_solver.cpp:106] Iteration 3025, lr = 5e-05
I0403 08:24:14.745195 10121 solver.cpp:228] Iteration 3030, loss = 0.0088618
I0403 08:24:14.745292 10121 solver.cpp:244]     Train net output #0: loss = 0.00886162 (* 1 = 0.00886162 loss)
I0403 08:24:14.929508 10121 sgd_solver.cpp:106] Iteration 3030, lr = 5e-05
I0403 08:24:18.417203 10121 solver.cpp:228] Iteration 3035, loss = 0.0445146
I0403 08:24:18.417300 10121 solver.cpp:244]     Train net output #0: loss = 0.0445144 (* 1 = 0.0445144 loss)
I0403 08:24:18.602893 10121 sgd_solver.cpp:106] Iteration 3035, lr = 5e-05
I0403 08:24:22.083938 10121 solver.cpp:228] Iteration 3040, loss = 0.0202944
I0403 08:24:22.084025 10121 solver.cpp:244]     Train net output #0: loss = 0.0202942 (* 1 = 0.0202942 loss)
I0403 08:24:22.255307 10121 sgd_solver.cpp:106] Iteration 3040, lr = 5e-05
I0403 08:24:25.702353 10121 solver.cpp:228] Iteration 3045, loss = 0.043088
I0403 08:24:25.702446 10121 solver.cpp:244]     Train net output #0: loss = 0.0430879 (* 1 = 0.0430879 loss)
I0403 08:24:25.884328 10121 sgd_solver.cpp:106] Iteration 3045, lr = 5e-05
I0403 08:24:29.304853 10121 solver.cpp:228] Iteration 3050, loss = 0.0401024
I0403 08:24:29.304951 10121 solver.cpp:244]     Train net output #0: loss = 0.0401023 (* 1 = 0.0401023 loss)
I0403 08:24:29.496482 10121 sgd_solver.cpp:106] Iteration 3050, lr = 5e-05
I0403 08:24:32.927450 10121 solver.cpp:228] Iteration 3055, loss = 0.0108751
I0403 08:24:32.927546 10121 solver.cpp:244]     Train net output #0: loss = 0.0108749 (* 1 = 0.0108749 loss)
I0403 08:24:33.117162 10121 sgd_solver.cpp:106] Iteration 3055, lr = 5e-05
I0403 08:24:36.526412 10121 solver.cpp:228] Iteration 3060, loss = 0.0197498
I0403 08:24:36.526509 10121 solver.cpp:244]     Train net output #0: loss = 0.0197496 (* 1 = 0.0197496 loss)
I0403 08:24:36.729631 10121 sgd_solver.cpp:106] Iteration 3060, lr = 5e-05
I0403 08:24:40.132849 10121 solver.cpp:228] Iteration 3065, loss = 0.0275751
I0403 08:24:40.133114 10121 solver.cpp:244]     Train net output #0: loss = 0.0275749 (* 1 = 0.0275749 loss)
I0403 08:24:40.329895 10121 sgd_solver.cpp:106] Iteration 3065, lr = 5e-05
I0403 08:24:43.758949 10121 solver.cpp:228] Iteration 3070, loss = 0.00984531
I0403 08:24:43.759044 10121 solver.cpp:244]     Train net output #0: loss = 0.00984512 (* 1 = 0.00984512 loss)
I0403 08:24:43.941928 10121 sgd_solver.cpp:106] Iteration 3070, lr = 5e-05
I0403 08:24:47.408377 10121 solver.cpp:228] Iteration 3075, loss = 0.00268144
I0403 08:24:47.408464 10121 solver.cpp:244]     Train net output #0: loss = 0.00268126 (* 1 = 0.00268126 loss)
I0403 08:24:47.560993 10121 sgd_solver.cpp:106] Iteration 3075, lr = 5e-05
I0403 08:24:51.101933 10121 solver.cpp:228] Iteration 3080, loss = 0.0221962
I0403 08:24:51.102030 10121 solver.cpp:244]     Train net output #0: loss = 0.0221961 (* 1 = 0.0221961 loss)
I0403 08:24:51.286078 10121 sgd_solver.cpp:106] Iteration 3080, lr = 5e-05
I0403 08:24:54.724398 10121 solver.cpp:228] Iteration 3085, loss = 0.0211793
I0403 08:24:54.724486 10121 solver.cpp:244]     Train net output #0: loss = 0.0211792 (* 1 = 0.0211792 loss)
I0403 08:24:54.895794 10121 sgd_solver.cpp:106] Iteration 3085, lr = 5e-05
I0403 08:24:58.366359 10121 solver.cpp:228] Iteration 3090, loss = 0.0359438
I0403 08:24:58.366456 10121 solver.cpp:244]     Train net output #0: loss = 0.0359436 (* 1 = 0.0359436 loss)
I0403 08:24:58.561097 10121 sgd_solver.cpp:106] Iteration 3090, lr = 5e-05
I0403 08:25:02.023493 10121 solver.cpp:228] Iteration 3095, loss = 0.0138488
I0403 08:25:02.023591 10121 solver.cpp:244]     Train net output #0: loss = 0.0138487 (* 1 = 0.0138487 loss)
I0403 08:25:02.209887 10121 sgd_solver.cpp:106] Iteration 3095, lr = 5e-05
I0403 08:25:05.608855 10121 solver.cpp:228] Iteration 3100, loss = 0.0237385
I0403 08:25:05.608952 10121 solver.cpp:244]     Train net output #0: loss = 0.0237383 (* 1 = 0.0237383 loss)
I0403 08:25:05.808533 10121 sgd_solver.cpp:106] Iteration 3100, lr = 5e-05
I0403 08:25:09.261564 10121 solver.cpp:228] Iteration 3105, loss = 0.0351493
I0403 08:25:09.261661 10121 solver.cpp:244]     Train net output #0: loss = 0.0351491 (* 1 = 0.0351491 loss)
I0403 08:25:09.483157 10121 sgd_solver.cpp:106] Iteration 3105, lr = 5e-05
I0403 08:25:12.954000 10121 solver.cpp:228] Iteration 3110, loss = 0.027776
I0403 08:25:12.954357 10121 solver.cpp:244]     Train net output #0: loss = 0.0277758 (* 1 = 0.0277758 loss)
I0403 08:25:13.172247 10121 sgd_solver.cpp:106] Iteration 3110, lr = 5e-05
I0403 08:25:16.599134 10121 solver.cpp:228] Iteration 3115, loss = 0.0601467
I0403 08:25:16.599222 10121 solver.cpp:244]     Train net output #0: loss = 0.0601466 (* 1 = 0.0601466 loss)
I0403 08:25:16.780920 10121 sgd_solver.cpp:106] Iteration 3115, lr = 5e-05
I0403 08:25:20.261677 10121 solver.cpp:228] Iteration 3120, loss = 0.00554348
I0403 08:25:20.261775 10121 solver.cpp:244]     Train net output #0: loss = 0.0055433 (* 1 = 0.0055433 loss)
I0403 08:25:20.483263 10121 sgd_solver.cpp:106] Iteration 3120, lr = 5e-05
I0403 08:25:23.992591 10121 solver.cpp:228] Iteration 3125, loss = 0.0498013
I0403 08:25:23.992674 10121 solver.cpp:244]     Train net output #0: loss = 0.0498011 (* 1 = 0.0498011 loss)
I0403 08:25:24.161804 10121 sgd_solver.cpp:106] Iteration 3125, lr = 5e-05
I0403 08:25:27.603790 10121 solver.cpp:228] Iteration 3130, loss = 0.119881
I0403 08:25:27.603888 10121 solver.cpp:244]     Train net output #0: loss = 0.119881 (* 1 = 0.119881 loss)
I0403 08:25:27.813123 10121 sgd_solver.cpp:106] Iteration 3130, lr = 5e-05
I0403 08:25:28.526365 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3132.caffemodel
I0403 08:25:31.217047 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3132.solverstate
I0403 08:25:33.045485 10121 solver.cpp:337] Iteration 3132, Testing net (#0)
I0403 08:27:10.905555 10121 solver.cpp:404]     Test net output #0: accuracy = 0.913572
I0403 08:27:10.905867 10121 solver.cpp:404]     Test net output #1: loss = 0.370604 (* 1 = 0.370604 loss)
I0403 08:27:13.616860 10121 solver.cpp:228] Iteration 3135, loss = 0.0229202
I0403 08:27:13.616953 10121 solver.cpp:244]     Train net output #0: loss = 0.0229201 (* 1 = 0.0229201 loss)
I0403 08:27:13.814285 10121 sgd_solver.cpp:106] Iteration 3135, lr = 5e-05
I0403 08:27:17.255815 10121 solver.cpp:228] Iteration 3140, loss = 0.012437
I0403 08:27:17.255899 10121 solver.cpp:244]     Train net output #0: loss = 0.0124369 (* 1 = 0.0124369 loss)
I0403 08:27:17.428745 10121 sgd_solver.cpp:106] Iteration 3140, lr = 5e-05
I0403 08:27:20.854233 10121 solver.cpp:228] Iteration 3145, loss = 0.0227647
I0403 08:27:20.854328 10121 solver.cpp:244]     Train net output #0: loss = 0.0227645 (* 1 = 0.0227645 loss)
I0403 08:27:21.082088 10121 sgd_solver.cpp:106] Iteration 3145, lr = 5e-05
I0403 08:27:24.549327 10121 solver.cpp:228] Iteration 3150, loss = 0.0210075
I0403 08:27:24.549415 10121 solver.cpp:244]     Train net output #0: loss = 0.0210074 (* 1 = 0.0210074 loss)
I0403 08:27:24.727555 10121 sgd_solver.cpp:106] Iteration 3150, lr = 5e-05
I0403 08:27:28.179075 10121 solver.cpp:228] Iteration 3155, loss = 0.0518869
I0403 08:27:28.179162 10121 solver.cpp:244]     Train net output #0: loss = 0.0518867 (* 1 = 0.0518867 loss)
I0403 08:27:28.357492 10121 sgd_solver.cpp:106] Iteration 3155, lr = 5e-05
I0403 08:27:31.779036 10121 solver.cpp:228] Iteration 3160, loss = 0.0444982
I0403 08:27:31.779129 10121 solver.cpp:244]     Train net output #0: loss = 0.044498 (* 1 = 0.044498 loss)
I0403 08:27:31.961688 10121 sgd_solver.cpp:106] Iteration 3160, lr = 5e-05
I0403 08:27:35.430658 10121 solver.cpp:228] Iteration 3165, loss = 0.0280914
I0403 08:27:35.430747 10121 solver.cpp:244]     Train net output #0: loss = 0.0280912 (* 1 = 0.0280912 loss)
I0403 08:27:35.610256 10121 sgd_solver.cpp:106] Iteration 3165, lr = 5e-05
I0403 08:27:39.024368 10121 solver.cpp:228] Iteration 3170, loss = 0.00858509
I0403 08:27:39.024462 10121 solver.cpp:244]     Train net output #0: loss = 0.00858491 (* 1 = 0.00858491 loss)
I0403 08:27:39.211500 10121 sgd_solver.cpp:106] Iteration 3170, lr = 5e-05
I0403 08:27:42.708005 10121 solver.cpp:228] Iteration 3175, loss = 0.0238763
I0403 08:27:42.708359 10121 solver.cpp:244]     Train net output #0: loss = 0.0238761 (* 1 = 0.0238761 loss)
I0403 08:27:42.890600 10121 sgd_solver.cpp:106] Iteration 3175, lr = 5e-05
I0403 08:27:46.339568 10121 solver.cpp:228] Iteration 3180, loss = 0.0734966
I0403 08:27:46.339663 10121 solver.cpp:244]     Train net output #0: loss = 0.0734964 (* 1 = 0.0734964 loss)
I0403 08:27:46.582273 10121 sgd_solver.cpp:106] Iteration 3180, lr = 5e-05
I0403 08:27:50.103515 10121 solver.cpp:228] Iteration 3185, loss = 0.0391376
I0403 08:27:50.103616 10121 solver.cpp:244]     Train net output #0: loss = 0.0391374 (* 1 = 0.0391374 loss)
I0403 08:27:50.291453 10121 sgd_solver.cpp:106] Iteration 3185, lr = 5e-05
I0403 08:27:53.757294 10121 solver.cpp:228] Iteration 3190, loss = 0.0128651
I0403 08:27:53.757390 10121 solver.cpp:244]     Train net output #0: loss = 0.012865 (* 1 = 0.012865 loss)
I0403 08:27:53.979637 10121 sgd_solver.cpp:106] Iteration 3190, lr = 5e-05
I0403 08:27:57.483584 10121 solver.cpp:228] Iteration 3195, loss = 0.0849822
I0403 08:27:57.483683 10121 solver.cpp:244]     Train net output #0: loss = 0.084982 (* 1 = 0.084982 loss)
I0403 08:27:57.667958 10121 sgd_solver.cpp:106] Iteration 3195, lr = 5e-05
I0403 08:28:01.060405 10121 solver.cpp:228] Iteration 3200, loss = 0.00579713
I0403 08:28:01.060503 10121 solver.cpp:244]     Train net output #0: loss = 0.00579694 (* 1 = 0.00579694 loss)
I0403 08:28:01.273977 10121 sgd_solver.cpp:106] Iteration 3200, lr = 5e-05
I0403 08:28:04.816092 10121 solver.cpp:228] Iteration 3205, loss = 0.0538448
I0403 08:28:04.816184 10121 solver.cpp:244]     Train net output #0: loss = 0.0538446 (* 1 = 0.0538446 loss)
I0403 08:28:05.007663 10121 sgd_solver.cpp:106] Iteration 3205, lr = 5e-05
I0403 08:28:08.444501 10121 solver.cpp:228] Iteration 3210, loss = 0.0191813
I0403 08:28:08.444602 10121 solver.cpp:244]     Train net output #0: loss = 0.0191811 (* 1 = 0.0191811 loss)
I0403 08:28:08.676340 10121 sgd_solver.cpp:106] Iteration 3210, lr = 5e-05
I0403 08:28:12.116758 10121 solver.cpp:228] Iteration 3215, loss = 0.0090592
I0403 08:28:12.116854 10121 solver.cpp:244]     Train net output #0: loss = 0.00905901 (* 1 = 0.00905901 loss)
I0403 08:28:12.312654 10121 sgd_solver.cpp:106] Iteration 3215, lr = 5e-05
I0403 08:28:15.761836 10121 solver.cpp:228] Iteration 3220, loss = 0.0507163
I0403 08:28:15.762143 10121 solver.cpp:244]     Train net output #0: loss = 0.0507161 (* 1 = 0.0507161 loss)
I0403 08:28:16.021961 10121 sgd_solver.cpp:106] Iteration 3220, lr = 5e-05
I0403 08:28:19.446913 10121 solver.cpp:228] Iteration 3225, loss = 0.0351331
I0403 08:28:19.447011 10121 solver.cpp:244]     Train net output #0: loss = 0.0351329 (* 1 = 0.0351329 loss)
I0403 08:28:19.645920 10121 sgd_solver.cpp:106] Iteration 3225, lr = 5e-05
I0403 08:28:23.044666 10121 solver.cpp:228] Iteration 3230, loss = 0.00824203
I0403 08:28:23.044760 10121 solver.cpp:244]     Train net output #0: loss = 0.00824184 (* 1 = 0.00824184 loss)
I0403 08:28:23.235425 10121 sgd_solver.cpp:106] Iteration 3230, lr = 5e-05
I0403 08:28:26.802572 10121 solver.cpp:228] Iteration 3235, loss = 0.036453
I0403 08:28:26.802659 10121 solver.cpp:244]     Train net output #0: loss = 0.0364528 (* 1 = 0.0364528 loss)
I0403 08:28:26.935690 10121 sgd_solver.cpp:106] Iteration 3235, lr = 5e-05
I0403 08:28:29.909001 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3240.caffemodel
I0403 08:28:32.652232 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3240.solverstate
I0403 08:28:34.559501 10121 solver.cpp:337] Iteration 3240, Testing net (#0)
I0403 08:30:12.427891 10121 solver.cpp:404]     Test net output #0: accuracy = 0.912996
I0403 08:30:12.428282 10121 solver.cpp:404]     Test net output #1: loss = 0.37402 (* 1 = 0.37402 loss)
I0403 08:30:12.945605 10121 solver.cpp:228] Iteration 3240, loss = 0.029454
I0403 08:30:12.945686 10121 solver.cpp:244]     Train net output #0: loss = 0.0294538 (* 1 = 0.0294538 loss)
I0403 08:30:13.120403 10121 sgd_solver.cpp:106] Iteration 3240, lr = 5e-05
I0403 08:30:16.686084 10121 solver.cpp:228] Iteration 3245, loss = 0.0677917
I0403 08:30:16.686178 10121 solver.cpp:244]     Train net output #0: loss = 0.0677915 (* 1 = 0.0677915 loss)
I0403 08:30:16.883481 10121 sgd_solver.cpp:106] Iteration 3245, lr = 5e-05
I0403 08:30:20.420336 10121 solver.cpp:228] Iteration 3250, loss = 0.0126963
I0403 08:30:20.420433 10121 solver.cpp:244]     Train net output #0: loss = 0.0126961 (* 1 = 0.0126961 loss)
I0403 08:30:20.643606 10121 sgd_solver.cpp:106] Iteration 3250, lr = 5e-06
I0403 08:30:20.643842 10121 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3251.caffemodel
I0403 08:30:23.389700 10121 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_color-20-80_train_from_scratch/snapshots__iter_3251.solverstate
I0403 08:30:25.300436 10121 solver.cpp:322] Optimization Done.
I0403 08:30:25.377815 10121 caffe.cpp:222] Optimization Done.
