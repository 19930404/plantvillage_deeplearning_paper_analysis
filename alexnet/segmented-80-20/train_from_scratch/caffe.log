I0403 08:45:36.483788  3803 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 08:45:36.484418  3803 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 08:45:36.484447  3803 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 08:45:40.444731  3803 caffe.cpp:185] Using GPUs 0, 1
I0403 08:45:40.445191  3803 caffe.cpp:190] GPU 0: Tesla K40m
I0403 08:45:40.445564  3803 caffe.cpp:190] GPU 1: Tesla K40m
I0403 08:45:40.664659  3803 solver.cpp:48] Initializing solver from parameters: 
test_iter: 107
test_interval: 435
base_lr: 0.005
display: 21
max_iter: 13057
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 4352
snapshot: 435
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 08:45:40.694888  3803 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 08:45:40.705147  3803 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 08:45:40.705435  3803 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 08:45:40.707095  3803 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 08:45:40.708118  3803 layer_factory.hpp:77] Creating layer data
I0403 08:45:40.709843  3803 net.cpp:91] Creating Layer data
I0403 08:45:40.709941  3803 net.cpp:399] data -> data
I0403 08:45:40.710059  3803 net.cpp:399] data -> label
I0403 08:45:40.710142  3803 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto
I0403 08:45:40.794767  3806 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-80-20/train_db
I0403 08:45:40.814342  3803 data_layer.cpp:41] output data size: 100,3,227,227
I0403 08:45:40.933178  3803 net.cpp:141] Setting up data
I0403 08:45:40.933284  3803 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 08:45:40.933307  3803 net.cpp:148] Top shape: 100 (100)
I0403 08:45:40.933325  3803 net.cpp:156] Memory required for data: 61835200
I0403 08:45:40.933354  3803 layer_factory.hpp:77] Creating layer conv1
I0403 08:45:40.933395  3803 net.cpp:91] Creating Layer conv1
I0403 08:45:40.933416  3803 net.cpp:425] conv1 <- data
I0403 08:45:40.933446  3803 net.cpp:399] conv1 -> conv1
I0403 08:45:40.935984  3803 net.cpp:141] Setting up conv1
I0403 08:45:40.936015  3803 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:45:40.936033  3803 net.cpp:156] Memory required for data: 177995200
I0403 08:45:40.936067  3803 layer_factory.hpp:77] Creating layer relu1
I0403 08:45:40.936094  3803 net.cpp:91] Creating Layer relu1
I0403 08:45:40.936112  3803 net.cpp:425] relu1 <- conv1
I0403 08:45:40.936131  3803 net.cpp:386] relu1 -> conv1 (in-place)
I0403 08:45:40.936152  3803 net.cpp:141] Setting up relu1
I0403 08:45:40.936170  3803 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:45:40.936184  3803 net.cpp:156] Memory required for data: 294155200
I0403 08:45:40.936198  3803 layer_factory.hpp:77] Creating layer norm1
I0403 08:45:40.936249  3803 net.cpp:91] Creating Layer norm1
I0403 08:45:40.936272  3803 net.cpp:425] norm1 <- conv1
I0403 08:45:40.936292  3803 net.cpp:399] norm1 -> norm1
I0403 08:45:40.941947  3803 net.cpp:141] Setting up norm1
I0403 08:45:40.941982  3803 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:45:40.941999  3803 net.cpp:156] Memory required for data: 410315200
I0403 08:45:40.942014  3803 layer_factory.hpp:77] Creating layer pool1
I0403 08:45:40.942035  3803 net.cpp:91] Creating Layer pool1
I0403 08:45:40.942052  3803 net.cpp:425] pool1 <- norm1
I0403 08:45:40.942072  3803 net.cpp:399] pool1 -> pool1
I0403 08:45:40.942131  3803 net.cpp:141] Setting up pool1
I0403 08:45:40.942157  3803 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 08:45:40.942172  3803 net.cpp:156] Memory required for data: 438308800
I0403 08:45:40.942186  3803 layer_factory.hpp:77] Creating layer conv2
I0403 08:45:40.942209  3803 net.cpp:91] Creating Layer conv2
I0403 08:45:40.942225  3803 net.cpp:425] conv2 <- pool1
I0403 08:45:40.942245  3803 net.cpp:399] conv2 -> conv2
I0403 08:45:40.943434  3807 blocking_queue.cpp:50] Waiting for data
I0403 08:45:40.958210  3803 net.cpp:141] Setting up conv2
I0403 08:45:40.958240  3803 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:45:40.958261  3803 net.cpp:156] Memory required for data: 512958400
I0403 08:45:40.958281  3803 layer_factory.hpp:77] Creating layer relu2
I0403 08:45:40.958302  3803 net.cpp:91] Creating Layer relu2
I0403 08:45:40.958319  3803 net.cpp:425] relu2 <- conv2
I0403 08:45:40.958338  3803 net.cpp:386] relu2 -> conv2 (in-place)
I0403 08:45:40.958355  3803 net.cpp:141] Setting up relu2
I0403 08:45:40.958372  3803 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:45:40.958386  3803 net.cpp:156] Memory required for data: 587608000
I0403 08:45:40.958401  3803 layer_factory.hpp:77] Creating layer norm2
I0403 08:45:40.958418  3803 net.cpp:91] Creating Layer norm2
I0403 08:45:40.958434  3803 net.cpp:425] norm2 <- conv2
I0403 08:45:40.958451  3803 net.cpp:399] norm2 -> norm2
I0403 08:45:40.958497  3803 net.cpp:141] Setting up norm2
I0403 08:45:40.958518  3803 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:45:40.958533  3803 net.cpp:156] Memory required for data: 662257600
I0403 08:45:40.958549  3803 layer_factory.hpp:77] Creating layer pool2
I0403 08:45:40.958567  3803 net.cpp:91] Creating Layer pool2
I0403 08:45:40.958583  3803 net.cpp:425] pool2 <- norm2
I0403 08:45:40.958600  3803 net.cpp:399] pool2 -> pool2
I0403 08:45:40.958642  3803 net.cpp:141] Setting up pool2
I0403 08:45:40.958663  3803 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:45:40.958678  3803 net.cpp:156] Memory required for data: 679563200
I0403 08:45:40.958693  3803 layer_factory.hpp:77] Creating layer conv3
I0403 08:45:40.958714  3803 net.cpp:91] Creating Layer conv3
I0403 08:45:40.958729  3803 net.cpp:425] conv3 <- pool2
I0403 08:45:40.958746  3803 net.cpp:399] conv3 -> conv3
I0403 08:45:40.990754  3803 net.cpp:141] Setting up conv3
I0403 08:45:40.990785  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:40.990800  3803 net.cpp:156] Memory required for data: 705521600
I0403 08:45:40.990821  3803 layer_factory.hpp:77] Creating layer relu3
I0403 08:45:40.990840  3803 net.cpp:91] Creating Layer relu3
I0403 08:45:40.990855  3803 net.cpp:425] relu3 <- conv3
I0403 08:45:40.990874  3803 net.cpp:386] relu3 -> conv3 (in-place)
I0403 08:45:40.990891  3803 net.cpp:141] Setting up relu3
I0403 08:45:40.990909  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:40.990923  3803 net.cpp:156] Memory required for data: 731480000
I0403 08:45:40.990937  3803 layer_factory.hpp:77] Creating layer conv4
I0403 08:45:40.990957  3803 net.cpp:91] Creating Layer conv4
I0403 08:45:40.990973  3803 net.cpp:425] conv4 <- conv3
I0403 08:45:40.990993  3803 net.cpp:399] conv4 -> conv4
I0403 08:45:41.015161  3803 net.cpp:141] Setting up conv4
I0403 08:45:41.015192  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:41.015207  3803 net.cpp:156] Memory required for data: 757438400
I0403 08:45:41.015241  3803 layer_factory.hpp:77] Creating layer relu4
I0403 08:45:41.015269  3803 net.cpp:91] Creating Layer relu4
I0403 08:45:41.015288  3803 net.cpp:425] relu4 <- conv4
I0403 08:45:41.015306  3803 net.cpp:386] relu4 -> conv4 (in-place)
I0403 08:45:41.015326  3803 net.cpp:141] Setting up relu4
I0403 08:45:41.015343  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:41.015357  3803 net.cpp:156] Memory required for data: 783396800
I0403 08:45:41.015370  3803 layer_factory.hpp:77] Creating layer conv5
I0403 08:45:41.015391  3803 net.cpp:91] Creating Layer conv5
I0403 08:45:41.015408  3803 net.cpp:425] conv5 <- conv4
I0403 08:45:41.015426  3803 net.cpp:399] conv5 -> conv5
I0403 08:45:41.031685  3803 net.cpp:141] Setting up conv5
I0403 08:45:41.031714  3803 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:45:41.031731  3803 net.cpp:156] Memory required for data: 800702400
I0403 08:45:41.031810  3803 layer_factory.hpp:77] Creating layer relu5
I0403 08:45:41.031836  3803 net.cpp:91] Creating Layer relu5
I0403 08:45:41.031853  3803 net.cpp:425] relu5 <- conv5
I0403 08:45:41.031872  3803 net.cpp:386] relu5 -> conv5 (in-place)
I0403 08:45:41.031889  3803 net.cpp:141] Setting up relu5
I0403 08:45:41.031906  3803 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:45:41.031920  3803 net.cpp:156] Memory required for data: 818008000
I0403 08:45:41.031935  3803 layer_factory.hpp:77] Creating layer pool5
I0403 08:45:41.031952  3803 net.cpp:91] Creating Layer pool5
I0403 08:45:41.031967  3803 net.cpp:425] pool5 <- conv5
I0403 08:45:41.031987  3803 net.cpp:399] pool5 -> pool5
I0403 08:45:41.032032  3803 net.cpp:141] Setting up pool5
I0403 08:45:41.032054  3803 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 08:45:41.032069  3803 net.cpp:156] Memory required for data: 821694400
I0403 08:45:41.032084  3803 layer_factory.hpp:77] Creating layer fc6
I0403 08:45:41.032112  3803 net.cpp:91] Creating Layer fc6
I0403 08:45:41.032131  3803 net.cpp:425] fc6 <- pool5
I0403 08:45:41.032150  3803 net.cpp:399] fc6 -> fc6
I0403 08:45:42.407240  3803 net.cpp:141] Setting up fc6
I0403 08:45:42.407338  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:42.407356  3803 net.cpp:156] Memory required for data: 823332800
I0403 08:45:42.407378  3803 layer_factory.hpp:77] Creating layer relu6
I0403 08:45:42.407407  3803 net.cpp:91] Creating Layer relu6
I0403 08:45:42.407425  3803 net.cpp:425] relu6 <- fc6
I0403 08:45:42.407444  3803 net.cpp:386] relu6 -> fc6 (in-place)
I0403 08:45:42.407466  3803 net.cpp:141] Setting up relu6
I0403 08:45:42.407483  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:42.407497  3803 net.cpp:156] Memory required for data: 824971200
I0403 08:45:42.407511  3803 layer_factory.hpp:77] Creating layer drop6
I0403 08:45:42.407539  3803 net.cpp:91] Creating Layer drop6
I0403 08:45:42.407557  3803 net.cpp:425] drop6 <- fc6
I0403 08:45:42.407572  3803 net.cpp:386] drop6 -> fc6 (in-place)
I0403 08:45:42.407618  3803 net.cpp:141] Setting up drop6
I0403 08:45:42.407639  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:42.407655  3803 net.cpp:156] Memory required for data: 826609600
I0403 08:45:42.407668  3803 layer_factory.hpp:77] Creating layer fc7
I0403 08:45:42.407693  3803 net.cpp:91] Creating Layer fc7
I0403 08:45:42.407709  3803 net.cpp:425] fc7 <- fc6
I0403 08:45:42.407727  3803 net.cpp:399] fc7 -> fc7
I0403 08:45:43.013514  3803 net.cpp:141] Setting up fc7
I0403 08:45:43.013608  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:43.013627  3803 net.cpp:156] Memory required for data: 828248000
I0403 08:45:43.013648  3803 layer_factory.hpp:77] Creating layer relu7
I0403 08:45:43.013672  3803 net.cpp:91] Creating Layer relu7
I0403 08:45:43.013689  3803 net.cpp:425] relu7 <- fc7
I0403 08:45:43.013710  3803 net.cpp:386] relu7 -> fc7 (in-place)
I0403 08:45:43.013731  3803 net.cpp:141] Setting up relu7
I0403 08:45:43.013747  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:43.013761  3803 net.cpp:156] Memory required for data: 829886400
I0403 08:45:43.013809  3803 layer_factory.hpp:77] Creating layer drop7
I0403 08:45:43.013833  3803 net.cpp:91] Creating Layer drop7
I0403 08:45:43.013849  3803 net.cpp:425] drop7 <- fc7
I0403 08:45:43.013866  3803 net.cpp:386] drop7 -> fc7 (in-place)
I0403 08:45:43.013906  3803 net.cpp:141] Setting up drop7
I0403 08:45:43.013928  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:43.013942  3803 net.cpp:156] Memory required for data: 831524800
I0403 08:45:43.013958  3803 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 08:45:43.013979  3803 net.cpp:91] Creating Layer fc8_plantvillage
I0403 08:45:43.013994  3803 net.cpp:425] fc8_plantvillage <- fc7
I0403 08:45:43.014014  3803 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 08:45:43.020077  3803 net.cpp:141] Setting up fc8_plantvillage
I0403 08:45:43.020105  3803 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:45:43.020123  3803 net.cpp:156] Memory required for data: 831540000
I0403 08:45:43.020141  3803 layer_factory.hpp:77] Creating layer loss
I0403 08:45:43.020169  3803 net.cpp:91] Creating Layer loss
I0403 08:45:43.020186  3803 net.cpp:425] loss <- fc8_plantvillage
I0403 08:45:43.020202  3803 net.cpp:425] loss <- label
I0403 08:45:43.020222  3803 net.cpp:399] loss -> loss
I0403 08:45:43.020248  3803 layer_factory.hpp:77] Creating layer loss
I0403 08:45:43.020354  3803 net.cpp:141] Setting up loss
I0403 08:45:43.020377  3803 net.cpp:148] Top shape: (1)
I0403 08:45:43.020392  3803 net.cpp:151]     with loss weight 1
I0403 08:45:43.020445  3803 net.cpp:156] Memory required for data: 831540004
I0403 08:45:43.020462  3803 net.cpp:217] loss needs backward computation.
I0403 08:45:43.020475  3803 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 08:45:43.020489  3803 net.cpp:217] drop7 needs backward computation.
I0403 08:45:43.020503  3803 net.cpp:217] relu7 needs backward computation.
I0403 08:45:43.020517  3803 net.cpp:217] fc7 needs backward computation.
I0403 08:45:43.020532  3803 net.cpp:217] drop6 needs backward computation.
I0403 08:45:43.020546  3803 net.cpp:217] relu6 needs backward computation.
I0403 08:45:43.020560  3803 net.cpp:217] fc6 needs backward computation.
I0403 08:45:43.020573  3803 net.cpp:217] pool5 needs backward computation.
I0403 08:45:43.020587  3803 net.cpp:217] relu5 needs backward computation.
I0403 08:45:43.020602  3803 net.cpp:217] conv5 needs backward computation.
I0403 08:45:43.020615  3803 net.cpp:217] relu4 needs backward computation.
I0403 08:45:43.020629  3803 net.cpp:217] conv4 needs backward computation.
I0403 08:45:43.020643  3803 net.cpp:217] relu3 needs backward computation.
I0403 08:45:43.020658  3803 net.cpp:217] conv3 needs backward computation.
I0403 08:45:43.020673  3803 net.cpp:217] pool2 needs backward computation.
I0403 08:45:43.020686  3803 net.cpp:217] norm2 needs backward computation.
I0403 08:45:43.020700  3803 net.cpp:217] relu2 needs backward computation.
I0403 08:45:43.020714  3803 net.cpp:217] conv2 needs backward computation.
I0403 08:45:43.020728  3803 net.cpp:217] pool1 needs backward computation.
I0403 08:45:43.020741  3803 net.cpp:217] norm1 needs backward computation.
I0403 08:45:43.020756  3803 net.cpp:217] relu1 needs backward computation.
I0403 08:45:43.020769  3803 net.cpp:217] conv1 needs backward computation.
I0403 08:45:43.020784  3803 net.cpp:219] data does not need backward computation.
I0403 08:45:43.020798  3803 net.cpp:261] This network produces output loss
I0403 08:45:43.020824  3803 net.cpp:274] Network initialization done.
I0403 08:45:43.021836  3803 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 08:45:43.021894  3803 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 08:45:43.022501  3803 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 08:45:43.022655  3803 layer_factory.hpp:77] Creating layer data
I0403 08:45:43.022819  3803 net.cpp:91] Creating Layer data
I0403 08:45:43.022850  3803 net.cpp:399] data -> data
I0403 08:45:43.022874  3803 net.cpp:399] data -> label
I0403 08:45:43.022897  3803 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto
I0403 08:45:43.093300  3808 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-80-20/test_db
I0403 08:45:43.113997  3803 data_layer.cpp:41] output data size: 100,3,227,227
I0403 08:45:43.252005  3803 net.cpp:141] Setting up data
I0403 08:45:43.252104  3803 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 08:45:43.252125  3803 net.cpp:148] Top shape: 100 (100)
I0403 08:45:43.252140  3803 net.cpp:156] Memory required for data: 61835200
I0403 08:45:43.252159  3803 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 08:45:43.252188  3803 net.cpp:91] Creating Layer label_data_1_split
I0403 08:45:43.252207  3803 net.cpp:425] label_data_1_split <- label
I0403 08:45:43.252228  3803 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 08:45:43.252251  3803 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 08:45:43.252315  3803 net.cpp:141] Setting up label_data_1_split
I0403 08:45:43.252339  3803 net.cpp:148] Top shape: 100 (100)
I0403 08:45:43.252357  3803 net.cpp:148] Top shape: 100 (100)
I0403 08:45:43.252373  3803 net.cpp:156] Memory required for data: 61836000
I0403 08:45:43.252389  3803 layer_factory.hpp:77] Creating layer conv1
I0403 08:45:43.252435  3803 net.cpp:91] Creating Layer conv1
I0403 08:45:43.252455  3803 net.cpp:425] conv1 <- data
I0403 08:45:43.252475  3803 net.cpp:399] conv1 -> conv1
I0403 08:45:43.254019  3803 net.cpp:141] Setting up conv1
I0403 08:45:43.254048  3803 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:45:43.254065  3803 net.cpp:156] Memory required for data: 177996000
I0403 08:45:43.254091  3803 layer_factory.hpp:77] Creating layer relu1
I0403 08:45:43.254112  3803 net.cpp:91] Creating Layer relu1
I0403 08:45:43.254129  3803 net.cpp:425] relu1 <- conv1
I0403 08:45:43.254148  3803 net.cpp:386] relu1 -> conv1 (in-place)
I0403 08:45:43.254168  3803 net.cpp:141] Setting up relu1
I0403 08:45:43.254186  3803 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:45:43.254202  3803 net.cpp:156] Memory required for data: 294156000
I0403 08:45:43.254217  3803 layer_factory.hpp:77] Creating layer norm1
I0403 08:45:43.254240  3803 net.cpp:91] Creating Layer norm1
I0403 08:45:43.254256  3803 net.cpp:425] norm1 <- conv1
I0403 08:45:43.254276  3803 net.cpp:399] norm1 -> norm1
I0403 08:45:43.260004  3803 net.cpp:141] Setting up norm1
I0403 08:45:43.260040  3803 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 08:45:43.260059  3803 net.cpp:156] Memory required for data: 410316000
I0403 08:45:43.260076  3803 layer_factory.hpp:77] Creating layer pool1
I0403 08:45:43.260097  3803 net.cpp:91] Creating Layer pool1
I0403 08:45:43.260113  3803 net.cpp:425] pool1 <- norm1
I0403 08:45:43.260133  3803 net.cpp:399] pool1 -> pool1
I0403 08:45:43.260185  3803 net.cpp:141] Setting up pool1
I0403 08:45:43.260210  3803 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 08:45:43.260226  3803 net.cpp:156] Memory required for data: 438309600
I0403 08:45:43.260273  3803 layer_factory.hpp:77] Creating layer conv2
I0403 08:45:43.260304  3803 net.cpp:91] Creating Layer conv2
I0403 08:45:43.260325  3803 net.cpp:425] conv2 <- pool1
I0403 08:45:43.260345  3803 net.cpp:399] conv2 -> conv2
I0403 08:45:43.272632  3803 net.cpp:141] Setting up conv2
I0403 08:45:43.272665  3803 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:45:43.272682  3803 net.cpp:156] Memory required for data: 512959200
I0403 08:45:43.272704  3803 layer_factory.hpp:77] Creating layer relu2
I0403 08:45:43.272725  3803 net.cpp:91] Creating Layer relu2
I0403 08:45:43.272743  3803 net.cpp:425] relu2 <- conv2
I0403 08:45:43.272761  3803 net.cpp:386] relu2 -> conv2 (in-place)
I0403 08:45:43.272781  3803 net.cpp:141] Setting up relu2
I0403 08:45:43.272799  3803 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:45:43.272814  3803 net.cpp:156] Memory required for data: 587608800
I0403 08:45:43.272830  3803 layer_factory.hpp:77] Creating layer norm2
I0403 08:45:43.272850  3803 net.cpp:91] Creating Layer norm2
I0403 08:45:43.272866  3803 net.cpp:425] norm2 <- conv2
I0403 08:45:43.272886  3803 net.cpp:399] norm2 -> norm2
I0403 08:45:43.272933  3803 net.cpp:141] Setting up norm2
I0403 08:45:43.272958  3803 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 08:45:43.272974  3803 net.cpp:156] Memory required for data: 662258400
I0403 08:45:43.272990  3803 layer_factory.hpp:77] Creating layer pool2
I0403 08:45:43.273010  3803 net.cpp:91] Creating Layer pool2
I0403 08:45:43.273026  3803 net.cpp:425] pool2 <- norm2
I0403 08:45:43.273044  3803 net.cpp:399] pool2 -> pool2
I0403 08:45:43.273090  3803 net.cpp:141] Setting up pool2
I0403 08:45:43.273114  3803 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:45:43.273130  3803 net.cpp:156] Memory required for data: 679564000
I0403 08:45:43.273145  3803 layer_factory.hpp:77] Creating layer conv3
I0403 08:45:43.273167  3803 net.cpp:91] Creating Layer conv3
I0403 08:45:43.273183  3803 net.cpp:425] conv3 <- pool2
I0403 08:45:43.273203  3803 net.cpp:399] conv3 -> conv3
I0403 08:45:43.307335  3803 net.cpp:141] Setting up conv3
I0403 08:45:43.307396  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:43.307415  3803 net.cpp:156] Memory required for data: 705522400
I0403 08:45:43.307440  3803 layer_factory.hpp:77] Creating layer relu3
I0403 08:45:43.307464  3803 net.cpp:91] Creating Layer relu3
I0403 08:45:43.307482  3803 net.cpp:425] relu3 <- conv3
I0403 08:45:43.307502  3803 net.cpp:386] relu3 -> conv3 (in-place)
I0403 08:45:43.307523  3803 net.cpp:141] Setting up relu3
I0403 08:45:43.307540  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:43.307555  3803 net.cpp:156] Memory required for data: 731480800
I0403 08:45:43.307570  3803 layer_factory.hpp:77] Creating layer conv4
I0403 08:45:43.307595  3803 net.cpp:91] Creating Layer conv4
I0403 08:45:43.307612  3803 net.cpp:425] conv4 <- conv3
I0403 08:45:43.307631  3803 net.cpp:399] conv4 -> conv4
I0403 08:45:43.333720  3803 net.cpp:141] Setting up conv4
I0403 08:45:43.333760  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:43.333778  3803 net.cpp:156] Memory required for data: 757439200
I0403 08:45:43.333798  3803 layer_factory.hpp:77] Creating layer relu4
I0403 08:45:43.333819  3803 net.cpp:91] Creating Layer relu4
I0403 08:45:43.333837  3803 net.cpp:425] relu4 <- conv4
I0403 08:45:43.333855  3803 net.cpp:386] relu4 -> conv4 (in-place)
I0403 08:45:43.333875  3803 net.cpp:141] Setting up relu4
I0403 08:45:43.333894  3803 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 08:45:43.333909  3803 net.cpp:156] Memory required for data: 783397600
I0403 08:45:43.333925  3803 layer_factory.hpp:77] Creating layer conv5
I0403 08:45:43.333946  3803 net.cpp:91] Creating Layer conv5
I0403 08:45:43.333964  3803 net.cpp:425] conv5 <- conv4
I0403 08:45:43.333984  3803 net.cpp:399] conv5 -> conv5
I0403 08:45:43.351320  3803 net.cpp:141] Setting up conv5
I0403 08:45:43.351356  3803 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:45:43.351403  3803 net.cpp:156] Memory required for data: 800703200
I0403 08:45:43.351433  3803 layer_factory.hpp:77] Creating layer relu5
I0403 08:45:43.351456  3803 net.cpp:91] Creating Layer relu5
I0403 08:45:43.351475  3803 net.cpp:425] relu5 <- conv5
I0403 08:45:43.351493  3803 net.cpp:386] relu5 -> conv5 (in-place)
I0403 08:45:43.351513  3803 net.cpp:141] Setting up relu5
I0403 08:45:43.351532  3803 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 08:45:43.351547  3803 net.cpp:156] Memory required for data: 818008800
I0403 08:45:43.351565  3803 layer_factory.hpp:77] Creating layer pool5
I0403 08:45:43.351593  3803 net.cpp:91] Creating Layer pool5
I0403 08:45:43.351613  3803 net.cpp:425] pool5 <- conv5
I0403 08:45:43.351632  3803 net.cpp:399] pool5 -> pool5
I0403 08:45:43.351691  3803 net.cpp:141] Setting up pool5
I0403 08:45:43.351716  3803 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 08:45:43.351732  3803 net.cpp:156] Memory required for data: 821695200
I0403 08:45:43.351748  3803 layer_factory.hpp:77] Creating layer fc6
I0403 08:45:43.351773  3803 net.cpp:91] Creating Layer fc6
I0403 08:45:43.351788  3803 net.cpp:425] fc6 <- pool5
I0403 08:45:43.351810  3803 net.cpp:399] fc6 -> fc6
I0403 08:45:44.764459  3803 net.cpp:141] Setting up fc6
I0403 08:45:44.764551  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:44.764570  3803 net.cpp:156] Memory required for data: 823333600
I0403 08:45:44.764595  3803 layer_factory.hpp:77] Creating layer relu6
I0403 08:45:44.764624  3803 net.cpp:91] Creating Layer relu6
I0403 08:45:44.764644  3803 net.cpp:425] relu6 <- fc6
I0403 08:45:44.764670  3803 net.cpp:386] relu6 -> fc6 (in-place)
I0403 08:45:44.764693  3803 net.cpp:141] Setting up relu6
I0403 08:45:44.764713  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:44.764729  3803 net.cpp:156] Memory required for data: 824972000
I0403 08:45:44.764744  3803 layer_factory.hpp:77] Creating layer drop6
I0403 08:45:44.764765  3803 net.cpp:91] Creating Layer drop6
I0403 08:45:44.764781  3803 net.cpp:425] drop6 <- fc6
I0403 08:45:44.764803  3803 net.cpp:386] drop6 -> fc6 (in-place)
I0403 08:45:44.764847  3803 net.cpp:141] Setting up drop6
I0403 08:45:44.764870  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:44.764886  3803 net.cpp:156] Memory required for data: 826610400
I0403 08:45:44.764902  3803 layer_factory.hpp:77] Creating layer fc7
I0403 08:45:44.764928  3803 net.cpp:91] Creating Layer fc7
I0403 08:45:44.764960  3803 net.cpp:425] fc7 <- fc6
I0403 08:45:44.764978  3803 net.cpp:399] fc7 -> fc7
I0403 08:45:45.393657  3803 net.cpp:141] Setting up fc7
I0403 08:45:45.393754  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:45.393770  3803 net.cpp:156] Memory required for data: 828248800
I0403 08:45:45.393793  3803 layer_factory.hpp:77] Creating layer relu7
I0403 08:45:45.393818  3803 net.cpp:91] Creating Layer relu7
I0403 08:45:45.393836  3803 net.cpp:425] relu7 <- fc7
I0403 08:45:45.393856  3803 net.cpp:386] relu7 -> fc7 (in-place)
I0403 08:45:45.393877  3803 net.cpp:141] Setting up relu7
I0403 08:45:45.393894  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:45.393909  3803 net.cpp:156] Memory required for data: 829887200
I0403 08:45:45.393924  3803 layer_factory.hpp:77] Creating layer drop7
I0403 08:45:45.393946  3803 net.cpp:91] Creating Layer drop7
I0403 08:45:45.393964  3803 net.cpp:425] drop7 <- fc7
I0403 08:45:45.393980  3803 net.cpp:386] drop7 -> fc7 (in-place)
I0403 08:45:45.394018  3803 net.cpp:141] Setting up drop7
I0403 08:45:45.394044  3803 net.cpp:148] Top shape: 100 4096 (409600)
I0403 08:45:45.394062  3803 net.cpp:156] Memory required for data: 831525600
I0403 08:45:45.394076  3803 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 08:45:45.394098  3803 net.cpp:91] Creating Layer fc8_plantvillage
I0403 08:45:45.394112  3803 net.cpp:425] fc8_plantvillage <- fc7
I0403 08:45:45.394132  3803 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 08:45:45.400266  3803 net.cpp:141] Setting up fc8_plantvillage
I0403 08:45:45.400305  3803 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:45:45.400352  3803 net.cpp:156] Memory required for data: 831540800
I0403 08:45:45.400372  3803 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 08:45:45.400391  3803 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 08:45:45.400408  3803 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 08:45:45.400425  3803 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 08:45:45.400445  3803 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 08:45:45.400497  3803 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 08:45:45.400521  3803 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:45:45.400537  3803 net.cpp:148] Top shape: 100 38 (3800)
I0403 08:45:45.400549  3803 net.cpp:156] Memory required for data: 831571200
I0403 08:45:45.400564  3803 layer_factory.hpp:77] Creating layer loss
I0403 08:45:45.400583  3803 net.cpp:91] Creating Layer loss
I0403 08:45:45.400599  3803 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 08:45:45.400615  3803 net.cpp:425] loss <- label_data_1_split_0
I0403 08:45:45.400635  3803 net.cpp:399] loss -> loss
I0403 08:45:45.400656  3803 layer_factory.hpp:77] Creating layer loss
I0403 08:45:45.400749  3803 net.cpp:141] Setting up loss
I0403 08:45:45.400774  3803 net.cpp:148] Top shape: (1)
I0403 08:45:45.400789  3803 net.cpp:151]     with loss weight 1
I0403 08:45:45.400815  3803 net.cpp:156] Memory required for data: 831571204
I0403 08:45:45.400830  3803 layer_factory.hpp:77] Creating layer accuracy
I0403 08:45:45.400851  3803 net.cpp:91] Creating Layer accuracy
I0403 08:45:45.400867  3803 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 08:45:45.400883  3803 net.cpp:425] accuracy <- label_data_1_split_1
I0403 08:45:45.400902  3803 net.cpp:399] accuracy -> accuracy
I0403 08:45:45.400933  3803 net.cpp:141] Setting up accuracy
I0403 08:45:45.400952  3803 net.cpp:148] Top shape: (1)
I0403 08:45:45.400967  3803 net.cpp:156] Memory required for data: 831571208
I0403 08:45:45.400982  3803 net.cpp:219] accuracy does not need backward computation.
I0403 08:45:45.400998  3803 net.cpp:217] loss needs backward computation.
I0403 08:45:45.401013  3803 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 08:45:45.401028  3803 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 08:45:45.401043  3803 net.cpp:217] drop7 needs backward computation.
I0403 08:45:45.401057  3803 net.cpp:217] relu7 needs backward computation.
I0403 08:45:45.401069  3803 net.cpp:217] fc7 needs backward computation.
I0403 08:45:45.401083  3803 net.cpp:217] drop6 needs backward computation.
I0403 08:45:45.401098  3803 net.cpp:217] relu6 needs backward computation.
I0403 08:45:45.401111  3803 net.cpp:217] fc6 needs backward computation.
I0403 08:45:45.401126  3803 net.cpp:217] pool5 needs backward computation.
I0403 08:45:45.401140  3803 net.cpp:217] relu5 needs backward computation.
I0403 08:45:45.401154  3803 net.cpp:217] conv5 needs backward computation.
I0403 08:45:45.401167  3803 net.cpp:217] relu4 needs backward computation.
I0403 08:45:45.401181  3803 net.cpp:217] conv4 needs backward computation.
I0403 08:45:45.401196  3803 net.cpp:217] relu3 needs backward computation.
I0403 08:45:45.401211  3803 net.cpp:217] conv3 needs backward computation.
I0403 08:45:45.401226  3803 net.cpp:217] pool2 needs backward computation.
I0403 08:45:45.401240  3803 net.cpp:217] norm2 needs backward computation.
I0403 08:45:45.401254  3803 net.cpp:217] relu2 needs backward computation.
I0403 08:45:45.401268  3803 net.cpp:217] conv2 needs backward computation.
I0403 08:45:45.401283  3803 net.cpp:217] pool1 needs backward computation.
I0403 08:45:45.401304  3803 net.cpp:217] norm1 needs backward computation.
I0403 08:45:45.401321  3803 net.cpp:217] relu1 needs backward computation.
I0403 08:45:45.401336  3803 net.cpp:217] conv1 needs backward computation.
I0403 08:45:45.401365  3803 net.cpp:219] label_data_1_split does not need backward computation.
I0403 08:45:45.401388  3803 net.cpp:219] data does not need backward computation.
I0403 08:45:45.401403  3803 net.cpp:261] This network produces output accuracy
I0403 08:45:45.401419  3803 net.cpp:261] This network produces output loss
I0403 08:45:45.401450  3803 net.cpp:274] Network initialization done.
I0403 08:45:45.401551  3803 solver.cpp:60] Solver scaffolding done.
I0403 08:45:45.425189  3803 parallel.cpp:392] GPUs pairs 0:1
I0403 08:45:45.659132  3803 data_layer.cpp:41] output data size: 100,3,227,227
I0403 08:45:48.085919  3803 parallel.cpp:425] Starting Optimization
I0403 08:45:48.086074  3803 solver.cpp:279] Solving 
I0403 08:45:48.086099  3803 solver.cpp:280] Learning Rate Policy: step
I0403 08:45:48.086410  3803 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 08:46:12.549865  3803 solver.cpp:404]     Test net output #0: accuracy = 0.0273832
I0403 08:46:12.550071  3803 solver.cpp:404]     Test net output #1: loss = 3.64224 (* 1 = 3.64224 loss)
I0403 08:46:13.126463  3803 solver.cpp:228] Iteration 0, loss = 3.65348
I0403 08:46:13.126546  3803 solver.cpp:244]     Train net output #0: loss = 3.65348 (* 1 = 3.65348 loss)
I0403 08:46:13.312301  3803 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 08:46:28.460953  3803 solver.cpp:228] Iteration 21, loss = 3.34522
I0403 08:46:28.461042  3803 solver.cpp:244]     Train net output #0: loss = 3.34522 (* 1 = 3.34522 loss)
I0403 08:46:28.666923  3803 sgd_solver.cpp:106] Iteration 21, lr = 0.005
I0403 08:46:43.962643  3803 solver.cpp:228] Iteration 42, loss = 3.51064
I0403 08:46:43.962925  3803 solver.cpp:244]     Train net output #0: loss = 3.51064 (* 1 = 3.51064 loss)
I0403 08:46:44.109324  3803 sgd_solver.cpp:106] Iteration 42, lr = 0.005
I0403 08:46:59.237460  3803 solver.cpp:228] Iteration 63, loss = 2.87828
I0403 08:46:59.237552  3803 solver.cpp:244]     Train net output #0: loss = 2.87828 (* 1 = 2.87828 loss)
I0403 08:46:59.446411  3803 sgd_solver.cpp:106] Iteration 63, lr = 0.005
I0403 08:47:14.570801  3803 solver.cpp:228] Iteration 84, loss = 2.67048
I0403 08:47:14.571107  3803 solver.cpp:244]     Train net output #0: loss = 2.67048 (* 1 = 2.67048 loss)
I0403 08:47:14.784056  3803 sgd_solver.cpp:106] Iteration 84, lr = 0.005
I0403 08:47:29.957661  3803 solver.cpp:228] Iteration 105, loss = 2.41841
I0403 08:47:29.957738  3803 solver.cpp:244]     Train net output #0: loss = 2.41841 (* 1 = 2.41841 loss)
I0403 08:47:30.130867  3803 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 08:47:45.164480  3803 solver.cpp:228] Iteration 126, loss = 2.0755
I0403 08:47:45.164724  3803 solver.cpp:244]     Train net output #0: loss = 2.0755 (* 1 = 2.0755 loss)
I0403 08:47:45.360015  3803 sgd_solver.cpp:106] Iteration 126, lr = 0.005
I0403 08:48:00.413108  3803 solver.cpp:228] Iteration 147, loss = 1.99792
I0403 08:48:00.413197  3803 solver.cpp:244]     Train net output #0: loss = 1.99792 (* 1 = 1.99792 loss)
I0403 08:48:00.617386  3803 sgd_solver.cpp:106] Iteration 147, lr = 0.005
I0403 08:48:15.823873  3803 solver.cpp:228] Iteration 168, loss = 1.45829
I0403 08:48:15.824136  3803 solver.cpp:244]     Train net output #0: loss = 1.45829 (* 1 = 1.45829 loss)
I0403 08:48:16.021178  3803 sgd_solver.cpp:106] Iteration 168, lr = 0.005
I0403 08:48:31.069057  3803 solver.cpp:228] Iteration 189, loss = 1.45586
I0403 08:48:31.075569  3803 solver.cpp:244]     Train net output #0: loss = 1.45586 (* 1 = 1.45586 loss)
I0403 08:48:31.267177  3803 sgd_solver.cpp:106] Iteration 189, lr = 0.005
I0403 08:48:46.323968  3803 solver.cpp:228] Iteration 210, loss = 1.75068
I0403 08:48:46.324242  3803 solver.cpp:244]     Train net output #0: loss = 1.75068 (* 1 = 1.75068 loss)
I0403 08:48:46.495860  3803 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 08:49:01.887135  3803 solver.cpp:228] Iteration 231, loss = 1.49326
I0403 08:49:01.887246  3803 solver.cpp:244]     Train net output #0: loss = 1.49326 (* 1 = 1.49326 loss)
I0403 08:49:02.078635  3803 sgd_solver.cpp:106] Iteration 231, lr = 0.005
I0403 08:49:17.420399  3803 solver.cpp:228] Iteration 252, loss = 1.37314
I0403 08:49:17.420740  3803 solver.cpp:244]     Train net output #0: loss = 1.37314 (* 1 = 1.37314 loss)
I0403 08:49:17.618448  3803 sgd_solver.cpp:106] Iteration 252, lr = 0.005
I0403 08:49:32.920338  3803 solver.cpp:228] Iteration 273, loss = 1.15953
I0403 08:49:32.920449  3803 solver.cpp:244]     Train net output #0: loss = 1.15953 (* 1 = 1.15953 loss)
I0403 08:49:33.145937  3803 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 08:49:48.562878  3803 solver.cpp:228] Iteration 294, loss = 1.08924
I0403 08:49:48.563160  3803 solver.cpp:244]     Train net output #0: loss = 1.08924 (* 1 = 1.08924 loss)
I0403 08:49:48.741080  3803 sgd_solver.cpp:106] Iteration 294, lr = 0.005
I0403 08:50:03.900172  3803 solver.cpp:228] Iteration 315, loss = 1.14973
I0403 08:50:03.900275  3803 solver.cpp:244]     Train net output #0: loss = 1.14973 (* 1 = 1.14973 loss)
I0403 08:50:04.040940  3803 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 08:50:19.469454  3803 solver.cpp:228] Iteration 336, loss = 1.15435
I0403 08:50:19.469717  3803 solver.cpp:244]     Train net output #0: loss = 1.15435 (* 1 = 1.15435 loss)
I0403 08:50:19.678333  3803 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 08:50:34.909193  3803 solver.cpp:228] Iteration 357, loss = 0.971591
I0403 08:50:34.909312  3803 solver.cpp:244]     Train net output #0: loss = 0.971591 (* 1 = 0.971591 loss)
I0403 08:50:35.108747  3803 sgd_solver.cpp:106] Iteration 357, lr = 0.005
I0403 08:50:50.439939  3803 solver.cpp:228] Iteration 378, loss = 1.1542
I0403 08:50:50.440261  3803 solver.cpp:244]     Train net output #0: loss = 1.1542 (* 1 = 1.1542 loss)
I0403 08:50:50.649024  3803 sgd_solver.cpp:106] Iteration 378, lr = 0.005
I0403 08:51:05.814776  3803 solver.cpp:228] Iteration 399, loss = 1.05337
I0403 08:51:05.814888  3803 solver.cpp:244]     Train net output #0: loss = 1.05337 (* 1 = 1.05337 loss)
I0403 08:51:06.000646  3803 sgd_solver.cpp:106] Iteration 399, lr = 0.005
I0403 08:51:21.478370  3803 solver.cpp:228] Iteration 420, loss = 0.792942
I0403 08:51:21.495723  3803 solver.cpp:244]     Train net output #0: loss = 0.792942 (* 1 = 0.792942 loss)
I0403 08:51:21.657150  3803 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 08:51:32.197852  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_435.caffemodel
I0403 08:51:35.087251  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_435.solverstate
I0403 08:51:36.884034  3803 solver.cpp:337] Iteration 435, Testing net (#0)
I0403 08:52:01.311532  3803 solver.cpp:404]     Test net output #0: accuracy = 0.736542
I0403 08:52:01.311892  3803 solver.cpp:404]     Test net output #1: loss = 0.828784 (* 1 = 0.828784 loss)
I0403 08:52:06.416348  3803 solver.cpp:228] Iteration 441, loss = 0.708556
I0403 08:52:06.416448  3803 solver.cpp:244]     Train net output #0: loss = 0.708556 (* 1 = 0.708556 loss)
I0403 08:52:06.594874  3803 sgd_solver.cpp:106] Iteration 441, lr = 0.005
I0403 08:52:22.329721  3803 solver.cpp:228] Iteration 462, loss = 0.793159
I0403 08:52:22.329823  3803 solver.cpp:244]     Train net output #0: loss = 0.793159 (* 1 = 0.793159 loss)
I0403 08:52:22.441334  3803 sgd_solver.cpp:106] Iteration 462, lr = 0.005
I0403 08:52:37.919932  3803 solver.cpp:228] Iteration 483, loss = 0.763377
I0403 08:52:37.920248  3803 solver.cpp:244]     Train net output #0: loss = 0.763377 (* 1 = 0.763377 loss)
I0403 08:52:38.187536  3803 sgd_solver.cpp:106] Iteration 483, lr = 0.005
I0403 08:52:53.572064  3803 solver.cpp:228] Iteration 504, loss = 0.922372
I0403 08:52:53.572177  3803 solver.cpp:244]     Train net output #0: loss = 0.922372 (* 1 = 0.922372 loss)
I0403 08:52:53.782212  3803 sgd_solver.cpp:106] Iteration 504, lr = 0.005
I0403 08:53:09.076167  3803 solver.cpp:228] Iteration 525, loss = 0.682773
I0403 08:53:09.076491  3803 solver.cpp:244]     Train net output #0: loss = 0.682773 (* 1 = 0.682773 loss)
I0403 08:53:09.263787  3803 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 08:53:24.329967  3803 solver.cpp:228] Iteration 546, loss = 0.748011
I0403 08:53:24.330085  3803 solver.cpp:244]     Train net output #0: loss = 0.748011 (* 1 = 0.748011 loss)
I0403 08:53:24.589226  3803 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 08:53:39.904552  3803 solver.cpp:228] Iteration 567, loss = 0.520998
I0403 08:53:39.904871  3803 solver.cpp:244]     Train net output #0: loss = 0.520998 (* 1 = 0.520998 loss)
I0403 08:53:40.128813  3803 sgd_solver.cpp:106] Iteration 567, lr = 0.005
I0403 08:53:55.633652  3803 solver.cpp:228] Iteration 588, loss = 0.550104
I0403 08:53:55.633764  3803 solver.cpp:244]     Train net output #0: loss = 0.550104 (* 1 = 0.550104 loss)
I0403 08:53:55.832510  3803 sgd_solver.cpp:106] Iteration 588, lr = 0.005
I0403 08:54:11.013365  3803 solver.cpp:228] Iteration 609, loss = 0.643775
I0403 08:54:11.013679  3803 solver.cpp:244]     Train net output #0: loss = 0.643775 (* 1 = 0.643775 loss)
I0403 08:54:11.196604  3803 sgd_solver.cpp:106] Iteration 609, lr = 0.005
I0403 08:54:26.406674  3803 solver.cpp:228] Iteration 630, loss = 0.587385
I0403 08:54:26.406786  3803 solver.cpp:244]     Train net output #0: loss = 0.587385 (* 1 = 0.587385 loss)
I0403 08:54:26.591681  3803 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 08:54:42.092378  3803 solver.cpp:228] Iteration 651, loss = 0.598019
I0403 08:54:42.092689  3803 solver.cpp:244]     Train net output #0: loss = 0.598019 (* 1 = 0.598019 loss)
I0403 08:54:42.284725  3803 sgd_solver.cpp:106] Iteration 651, lr = 0.005
I0403 08:54:57.457867  3803 solver.cpp:228] Iteration 672, loss = 0.710842
I0403 08:54:57.457967  3803 solver.cpp:244]     Train net output #0: loss = 0.710842 (* 1 = 0.710842 loss)
I0403 08:54:57.633996  3803 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 08:55:13.187374  3803 solver.cpp:228] Iteration 693, loss = 0.548986
I0403 08:55:13.187682  3803 solver.cpp:244]     Train net output #0: loss = 0.548986 (* 1 = 0.548986 loss)
I0403 08:55:13.361836  3803 sgd_solver.cpp:106] Iteration 693, lr = 0.005
I0403 08:55:28.513118  3803 solver.cpp:228] Iteration 714, loss = 0.445384
I0403 08:55:28.513221  3803 solver.cpp:244]     Train net output #0: loss = 0.445384 (* 1 = 0.445384 loss)
I0403 08:55:28.689414  3803 sgd_solver.cpp:106] Iteration 714, lr = 0.005
I0403 08:55:43.966740  3803 solver.cpp:228] Iteration 735, loss = 0.613438
I0403 08:55:43.967049  3803 solver.cpp:244]     Train net output #0: loss = 0.613438 (* 1 = 0.613438 loss)
I0403 08:55:44.177937  3803 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 08:55:59.513298  3803 solver.cpp:228] Iteration 756, loss = 0.529489
I0403 08:55:59.513397  3803 solver.cpp:244]     Train net output #0: loss = 0.529489 (* 1 = 0.529489 loss)
I0403 08:55:59.691757  3803 sgd_solver.cpp:106] Iteration 756, lr = 0.005
I0403 08:56:14.985016  3803 solver.cpp:228] Iteration 777, loss = 0.447685
I0403 08:56:14.985324  3803 solver.cpp:244]     Train net output #0: loss = 0.447685 (* 1 = 0.447685 loss)
I0403 08:56:15.208530  3803 sgd_solver.cpp:106] Iteration 777, lr = 0.005
I0403 08:56:30.374359  3803 solver.cpp:228] Iteration 798, loss = 0.453601
I0403 08:56:30.374459  3803 solver.cpp:244]     Train net output #0: loss = 0.453601 (* 1 = 0.453601 loss)
I0403 08:56:30.545070  3803 sgd_solver.cpp:106] Iteration 798, lr = 0.005
I0403 08:56:45.746908  3803 solver.cpp:228] Iteration 819, loss = 0.398841
I0403 08:56:45.748003  3803 solver.cpp:244]     Train net output #0: loss = 0.398841 (* 1 = 0.398841 loss)
I0403 08:56:45.961308  3803 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 08:57:01.100621  3803 solver.cpp:228] Iteration 840, loss = 0.563965
I0403 08:57:01.100734  3803 solver.cpp:244]     Train net output #0: loss = 0.563965 (* 1 = 0.563965 loss)
I0403 08:57:01.285074  3803 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 08:57:16.487679  3803 solver.cpp:228] Iteration 861, loss = 0.365438
I0403 08:57:16.487998  3803 solver.cpp:244]     Train net output #0: loss = 0.365438 (* 1 = 0.365438 loss)
I0403 08:57:16.666080  3803 sgd_solver.cpp:106] Iteration 861, lr = 0.005
I0403 08:57:22.445864  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_870.caffemodel
I0403 08:57:25.192842  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_870.solverstate
I0403 08:57:27.097110  3803 solver.cpp:337] Iteration 870, Testing net (#0)
I0403 08:57:51.504603  3803 solver.cpp:404]     Test net output #0: accuracy = 0.885234
I0403 08:57:51.504895  3803 solver.cpp:404]     Test net output #1: loss = 0.36141 (* 1 = 0.36141 loss)
I0403 08:58:00.864557  3803 solver.cpp:228] Iteration 882, loss = 0.489056
I0403 08:58:00.864658  3803 solver.cpp:244]     Train net output #0: loss = 0.489056 (* 1 = 0.489056 loss)
I0403 08:58:01.041646  3803 sgd_solver.cpp:106] Iteration 882, lr = 0.005
I0403 08:58:16.222836  3803 solver.cpp:228] Iteration 903, loss = 0.403995
I0403 08:58:16.222937  3803 solver.cpp:244]     Train net output #0: loss = 0.403995 (* 1 = 0.403995 loss)
I0403 08:58:16.395470  3803 sgd_solver.cpp:106] Iteration 903, lr = 0.005
I0403 08:58:31.523772  3803 solver.cpp:228] Iteration 924, loss = 0.466477
I0403 08:58:31.524092  3803 solver.cpp:244]     Train net output #0: loss = 0.466477 (* 1 = 0.466477 loss)
I0403 08:58:31.724587  3803 sgd_solver.cpp:106] Iteration 924, lr = 0.005
I0403 08:58:47.195719  3803 solver.cpp:228] Iteration 945, loss = 0.317857
I0403 08:58:47.195832  3803 solver.cpp:244]     Train net output #0: loss = 0.317857 (* 1 = 0.317857 loss)
I0403 08:58:47.468667  3803 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 08:59:02.849459  3803 solver.cpp:228] Iteration 966, loss = 0.425983
I0403 08:59:02.849747  3803 solver.cpp:244]     Train net output #0: loss = 0.425983 (* 1 = 0.425983 loss)
I0403 08:59:03.032822  3803 sgd_solver.cpp:106] Iteration 966, lr = 0.005
I0403 08:59:18.389739  3803 solver.cpp:228] Iteration 987, loss = 0.531815
I0403 08:59:18.389838  3803 solver.cpp:244]     Train net output #0: loss = 0.531815 (* 1 = 0.531815 loss)
I0403 08:59:18.478816  3803 sgd_solver.cpp:106] Iteration 987, lr = 0.005
I0403 08:59:33.891161  3803 solver.cpp:228] Iteration 1008, loss = 0.474289
I0403 08:59:33.891438  3803 solver.cpp:244]     Train net output #0: loss = 0.474289 (* 1 = 0.474289 loss)
I0403 08:59:34.069061  3803 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 08:59:49.256657  3803 solver.cpp:228] Iteration 1029, loss = 0.512749
I0403 08:59:49.256755  3803 solver.cpp:244]     Train net output #0: loss = 0.512749 (* 1 = 0.512749 loss)
I0403 08:59:49.430466  3803 sgd_solver.cpp:106] Iteration 1029, lr = 0.005
I0403 09:00:04.515456  3803 solver.cpp:228] Iteration 1050, loss = 0.270489
I0403 09:00:04.515707  3803 solver.cpp:244]     Train net output #0: loss = 0.270489 (* 1 = 0.270489 loss)
I0403 09:00:04.695364  3803 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 09:00:19.907356  3803 solver.cpp:228] Iteration 1071, loss = 0.259972
I0403 09:00:19.907459  3803 solver.cpp:244]     Train net output #0: loss = 0.259972 (* 1 = 0.259972 loss)
I0403 09:00:20.075029  3803 sgd_solver.cpp:106] Iteration 1071, lr = 0.005
I0403 09:00:35.360859  3803 solver.cpp:228] Iteration 1092, loss = 0.366042
I0403 09:00:35.361156  3803 solver.cpp:244]     Train net output #0: loss = 0.366042 (* 1 = 0.366042 loss)
I0403 09:00:35.540853  3803 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 09:00:50.736659  3803 solver.cpp:228] Iteration 1113, loss = 0.581078
I0403 09:00:50.736768  3803 solver.cpp:244]     Train net output #0: loss = 0.581078 (* 1 = 0.581078 loss)
I0403 09:00:50.950551  3803 sgd_solver.cpp:106] Iteration 1113, lr = 0.005
I0403 09:01:06.112185  3803 solver.cpp:228] Iteration 1134, loss = 0.399026
I0403 09:01:06.112499  3803 solver.cpp:244]     Train net output #0: loss = 0.399026 (* 1 = 0.399026 loss)
I0403 09:01:06.291474  3803 sgd_solver.cpp:106] Iteration 1134, lr = 0.005
I0403 09:01:21.745708  3803 solver.cpp:228] Iteration 1155, loss = 0.394181
I0403 09:01:21.745823  3803 solver.cpp:244]     Train net output #0: loss = 0.394181 (* 1 = 0.394181 loss)
I0403 09:01:21.937197  3803 sgd_solver.cpp:106] Iteration 1155, lr = 0.005
I0403 09:01:37.480675  3803 solver.cpp:228] Iteration 1176, loss = 0.290986
I0403 09:01:37.480975  3803 solver.cpp:244]     Train net output #0: loss = 0.290986 (* 1 = 0.290986 loss)
I0403 09:01:37.641618  3803 sgd_solver.cpp:106] Iteration 1176, lr = 0.005
I0403 09:01:52.878232  3803 solver.cpp:228] Iteration 1197, loss = 0.348434
I0403 09:01:52.878350  3803 solver.cpp:244]     Train net output #0: loss = 0.348434 (* 1 = 0.348434 loss)
I0403 09:01:53.076135  3803 sgd_solver.cpp:106] Iteration 1197, lr = 0.005
I0403 09:02:08.526207  3803 solver.cpp:228] Iteration 1218, loss = 0.281128
I0403 09:02:08.526515  3803 solver.cpp:244]     Train net output #0: loss = 0.281128 (* 1 = 0.281128 loss)
I0403 09:02:08.670261  3803 sgd_solver.cpp:106] Iteration 1218, lr = 0.005
I0403 09:02:24.194738  3803 solver.cpp:228] Iteration 1239, loss = 0.236812
I0403 09:02:24.194854  3803 solver.cpp:244]     Train net output #0: loss = 0.236812 (* 1 = 0.236812 loss)
I0403 09:02:24.428078  3803 sgd_solver.cpp:106] Iteration 1239, lr = 0.005
I0403 09:02:39.565975  3803 solver.cpp:228] Iteration 1260, loss = 0.262584
I0403 09:02:39.566277  3803 solver.cpp:244]     Train net output #0: loss = 0.262584 (* 1 = 0.262584 loss)
I0403 09:02:39.741240  3803 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 09:02:55.144176  3803 solver.cpp:228] Iteration 1281, loss = 0.297629
I0403 09:02:55.144284  3803 solver.cpp:244]     Train net output #0: loss = 0.297629 (* 1 = 0.297629 loss)
I0403 09:02:55.334059  3803 sgd_solver.cpp:106] Iteration 1281, lr = 0.005
I0403 09:03:10.685804  3803 solver.cpp:228] Iteration 1302, loss = 0.282909
I0403 09:03:10.686092  3803 solver.cpp:244]     Train net output #0: loss = 0.282909 (* 1 = 0.282909 loss)
I0403 09:03:10.871889  3803 sgd_solver.cpp:106] Iteration 1302, lr = 0.005
I0403 09:03:12.383237  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_1305.caffemodel
I0403 09:03:15.225214  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_1305.solverstate
I0403 09:03:17.090951  3803 solver.cpp:337] Iteration 1305, Testing net (#0)
I0403 09:03:41.506847  3803 solver.cpp:404]     Test net output #0: accuracy = 0.902243
I0403 09:03:41.507156  3803 solver.cpp:404]     Test net output #1: loss = 0.303617 (* 1 = 0.303617 loss)
I0403 09:03:55.123280  3803 solver.cpp:228] Iteration 1323, loss = 0.438218
I0403 09:03:55.123380  3803 solver.cpp:244]     Train net output #0: loss = 0.438218 (* 1 = 0.438218 loss)
I0403 09:03:55.288378  3803 sgd_solver.cpp:106] Iteration 1323, lr = 0.005
I0403 09:04:10.387560  3803 solver.cpp:228] Iteration 1344, loss = 0.287118
I0403 09:04:10.387672  3803 solver.cpp:244]     Train net output #0: loss = 0.287118 (* 1 = 0.287118 loss)
I0403 09:04:10.590734  3803 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 09:04:25.815323  3803 solver.cpp:228] Iteration 1365, loss = 0.185471
I0403 09:04:25.815625  3803 solver.cpp:244]     Train net output #0: loss = 0.185471 (* 1 = 0.185471 loss)
I0403 09:04:25.998683  3803 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 09:04:41.196801  3803 solver.cpp:228] Iteration 1386, loss = 0.21866
I0403 09:04:41.196910  3803 solver.cpp:244]     Train net output #0: loss = 0.21866 (* 1 = 0.21866 loss)
I0403 09:04:41.382424  3803 sgd_solver.cpp:106] Iteration 1386, lr = 0.005
I0403 09:04:56.575263  3803 solver.cpp:228] Iteration 1407, loss = 0.31018
I0403 09:04:56.575595  3803 solver.cpp:244]     Train net output #0: loss = 0.31018 (* 1 = 0.31018 loss)
I0403 09:04:56.772058  3803 sgd_solver.cpp:106] Iteration 1407, lr = 0.005
I0403 09:05:12.082319  3803 solver.cpp:228] Iteration 1428, loss = 0.276593
I0403 09:05:12.082428  3803 solver.cpp:244]     Train net output #0: loss = 0.276593 (* 1 = 0.276593 loss)
I0403 09:05:12.272351  3803 sgd_solver.cpp:106] Iteration 1428, lr = 0.005
I0403 09:05:27.607544  3803 solver.cpp:228] Iteration 1449, loss = 0.270495
I0403 09:05:27.607856  3803 solver.cpp:244]     Train net output #0: loss = 0.270495 (* 1 = 0.270495 loss)
I0403 09:05:27.769074  3803 sgd_solver.cpp:106] Iteration 1449, lr = 0.005
I0403 09:05:43.329780  3803 solver.cpp:228] Iteration 1470, loss = 0.203535
I0403 09:05:43.329895  3803 solver.cpp:244]     Train net output #0: loss = 0.203535 (* 1 = 0.203535 loss)
I0403 09:05:43.577911  3803 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 09:05:58.652181  3803 solver.cpp:228] Iteration 1491, loss = 0.359216
I0403 09:05:58.652501  3803 solver.cpp:244]     Train net output #0: loss = 0.359216 (* 1 = 0.359216 loss)
I0403 09:05:58.856689  3803 sgd_solver.cpp:106] Iteration 1491, lr = 0.005
I0403 09:06:14.042367  3803 solver.cpp:228] Iteration 1512, loss = 0.280984
I0403 09:06:14.042469  3803 solver.cpp:244]     Train net output #0: loss = 0.280984 (* 1 = 0.280984 loss)
I0403 09:06:14.220594  3803 sgd_solver.cpp:106] Iteration 1512, lr = 0.005
I0403 09:06:29.436067  3803 solver.cpp:228] Iteration 1533, loss = 0.227367
I0403 09:06:29.436372  3803 solver.cpp:244]     Train net output #0: loss = 0.227367 (* 1 = 0.227367 loss)
I0403 09:06:29.599078  3803 sgd_solver.cpp:106] Iteration 1533, lr = 0.005
I0403 09:06:44.982245  3803 solver.cpp:228] Iteration 1554, loss = 0.263999
I0403 09:06:44.982364  3803 solver.cpp:244]     Train net output #0: loss = 0.263999 (* 1 = 0.263999 loss)
I0403 09:06:45.168256  3803 sgd_solver.cpp:106] Iteration 1554, lr = 0.005
I0403 09:07:00.454803  3803 solver.cpp:228] Iteration 1575, loss = 0.32405
I0403 09:07:02.939038  3803 solver.cpp:244]     Train net output #0: loss = 0.32405 (* 1 = 0.32405 loss)
I0403 09:07:02.939237  3803 sgd_solver.cpp:106] Iteration 1575, lr = 0.005
I0403 09:07:18.139502  3803 solver.cpp:228] Iteration 1596, loss = 0.122862
I0403 09:07:18.139618  3803 solver.cpp:244]     Train net output #0: loss = 0.122862 (* 1 = 0.122862 loss)
I0403 09:07:18.351454  3803 sgd_solver.cpp:106] Iteration 1596, lr = 0.005
I0403 09:07:33.533754  3803 solver.cpp:228] Iteration 1617, loss = 0.289016
I0403 09:07:33.534060  3803 solver.cpp:244]     Train net output #0: loss = 0.289016 (* 1 = 0.289016 loss)
I0403 09:07:33.716832  3803 sgd_solver.cpp:106] Iteration 1617, lr = 0.005
I0403 09:07:49.096379  3803 solver.cpp:228] Iteration 1638, loss = 0.233575
I0403 09:07:49.096472  3803 solver.cpp:244]     Train net output #0: loss = 0.233575 (* 1 = 0.233575 loss)
I0403 09:07:49.270299  3803 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 09:08:04.744233  3803 solver.cpp:228] Iteration 1659, loss = 0.16062
I0403 09:08:04.744541  3803 solver.cpp:244]     Train net output #0: loss = 0.16062 (* 1 = 0.16062 loss)
I0403 09:08:04.942047  3803 sgd_solver.cpp:106] Iteration 1659, lr = 0.005
I0403 09:08:20.195436  3803 solver.cpp:228] Iteration 1680, loss = 0.24307
I0403 09:08:20.195526  3803 solver.cpp:244]     Train net output #0: loss = 0.24307 (* 1 = 0.24307 loss)
I0403 09:08:20.372086  3803 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 09:08:35.439015  3803 solver.cpp:228] Iteration 1701, loss = 0.11038
I0403 09:08:35.439332  3803 solver.cpp:244]     Train net output #0: loss = 0.11038 (* 1 = 0.11038 loss)
I0403 09:08:35.633708  3803 sgd_solver.cpp:106] Iteration 1701, lr = 0.005
I0403 09:08:51.122402  3803 solver.cpp:228] Iteration 1722, loss = 0.321819
I0403 09:08:51.122494  3803 solver.cpp:244]     Train net output #0: loss = 0.321819 (* 1 = 0.321819 loss)
I0403 09:08:51.303165  3803 sgd_solver.cpp:106] Iteration 1722, lr = 0.005
I0403 09:09:03.864004  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_1740.caffemodel
I0403 09:09:06.978554  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_1740.solverstate
I0403 09:09:09.111243  3803 solver.cpp:337] Iteration 1740, Testing net (#0)
I0403 09:09:33.536667  3803 solver.cpp:404]     Test net output #0: accuracy = 0.917196
I0403 09:09:33.536766  3803 solver.cpp:404]     Test net output #1: loss = 0.249904 (* 1 = 0.249904 loss)
I0403 09:09:36.221642  3803 solver.cpp:228] Iteration 1743, loss = 0.340867
I0403 09:09:36.221731  3803 solver.cpp:244]     Train net output #0: loss = 0.340867 (* 1 = 0.340867 loss)
I0403 09:09:36.403070  3803 sgd_solver.cpp:106] Iteration 1743, lr = 0.005
I0403 09:09:51.802176  3803 solver.cpp:228] Iteration 1764, loss = 0.371988
I0403 09:09:51.802472  3803 solver.cpp:244]     Train net output #0: loss = 0.371988 (* 1 = 0.371988 loss)
I0403 09:09:51.999218  3803 sgd_solver.cpp:106] Iteration 1764, lr = 0.005
I0403 09:10:07.249330  3803 solver.cpp:228] Iteration 1785, loss = 0.255729
I0403 09:10:07.249424  3803 solver.cpp:244]     Train net output #0: loss = 0.255729 (* 1 = 0.255729 loss)
I0403 09:10:07.432759  3803 sgd_solver.cpp:106] Iteration 1785, lr = 0.005
I0403 09:10:23.224822  3803 solver.cpp:228] Iteration 1806, loss = 0.322352
I0403 09:10:23.225169  3803 solver.cpp:244]     Train net output #0: loss = 0.322352 (* 1 = 0.322352 loss)
I0403 09:10:23.411471  3803 sgd_solver.cpp:106] Iteration 1806, lr = 0.005
I0403 09:10:38.657501  3803 solver.cpp:228] Iteration 1827, loss = 0.252232
I0403 09:10:38.657604  3803 solver.cpp:244]     Train net output #0: loss = 0.252232 (* 1 = 0.252232 loss)
I0403 09:10:38.804111  3803 sgd_solver.cpp:106] Iteration 1827, lr = 0.005
I0403 09:10:54.279775  3803 solver.cpp:228] Iteration 1848, loss = 0.173612
I0403 09:10:54.280094  3803 solver.cpp:244]     Train net output #0: loss = 0.173612 (* 1 = 0.173612 loss)
I0403 09:10:54.489707  3803 sgd_solver.cpp:106] Iteration 1848, lr = 0.005
I0403 09:11:09.756018  3803 solver.cpp:228] Iteration 1869, loss = 0.259731
I0403 09:11:09.756108  3803 solver.cpp:244]     Train net output #0: loss = 0.259731 (* 1 = 0.259731 loss)
I0403 09:11:09.946331  3803 sgd_solver.cpp:106] Iteration 1869, lr = 0.005
I0403 09:11:25.042764  3803 solver.cpp:228] Iteration 1890, loss = 0.153718
I0403 09:11:25.043027  3803 solver.cpp:244]     Train net output #0: loss = 0.153718 (* 1 = 0.153718 loss)
I0403 09:11:25.236614  3803 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 09:11:40.397827  3803 solver.cpp:228] Iteration 1911, loss = 0.231318
I0403 09:11:40.397925  3803 solver.cpp:244]     Train net output #0: loss = 0.231318 (* 1 = 0.231318 loss)
I0403 09:11:40.567282  3803 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 09:11:55.777525  3803 solver.cpp:228] Iteration 1932, loss = 0.149743
I0403 09:11:55.777806  3803 solver.cpp:244]     Train net output #0: loss = 0.149743 (* 1 = 0.149743 loss)
I0403 09:11:55.966032  3803 sgd_solver.cpp:106] Iteration 1932, lr = 0.005
I0403 09:12:11.143036  3803 solver.cpp:228] Iteration 1953, loss = 0.186099
I0403 09:12:11.143118  3803 solver.cpp:244]     Train net output #0: loss = 0.186099 (* 1 = 0.186099 loss)
I0403 09:12:11.322178  3803 sgd_solver.cpp:106] Iteration 1953, lr = 0.005
I0403 09:12:26.612344  3803 solver.cpp:228] Iteration 1974, loss = 0.202225
I0403 09:12:26.612634  3803 solver.cpp:244]     Train net output #0: loss = 0.202225 (* 1 = 0.202225 loss)
I0403 09:12:26.792778  3803 sgd_solver.cpp:106] Iteration 1974, lr = 0.005
I0403 09:12:42.053766  3803 solver.cpp:228] Iteration 1995, loss = 0.183149
I0403 09:12:42.053849  3803 solver.cpp:244]     Train net output #0: loss = 0.183149 (* 1 = 0.183149 loss)
I0403 09:12:42.231657  3803 sgd_solver.cpp:106] Iteration 1995, lr = 0.005
I0403 09:12:57.348347  3803 solver.cpp:228] Iteration 2016, loss = 0.247548
I0403 09:12:57.366310  3803 solver.cpp:244]     Train net output #0: loss = 0.247548 (* 1 = 0.247548 loss)
I0403 09:12:57.536602  3803 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 09:13:12.771766  3803 solver.cpp:228] Iteration 2037, loss = 0.162832
I0403 09:13:12.771867  3803 solver.cpp:244]     Train net output #0: loss = 0.162832 (* 1 = 0.162832 loss)
I0403 09:13:12.891309  3803 sgd_solver.cpp:106] Iteration 2037, lr = 0.005
I0403 09:13:28.247648  3803 solver.cpp:228] Iteration 2058, loss = 0.172152
I0403 09:13:28.247967  3803 solver.cpp:244]     Train net output #0: loss = 0.172152 (* 1 = 0.172152 loss)
I0403 09:13:28.426933  3803 sgd_solver.cpp:106] Iteration 2058, lr = 0.005
I0403 09:13:43.710355  3803 solver.cpp:228] Iteration 2079, loss = 0.204123
I0403 09:13:43.710467  3803 solver.cpp:244]     Train net output #0: loss = 0.204123 (* 1 = 0.204123 loss)
I0403 09:13:43.919085  3803 sgd_solver.cpp:106] Iteration 2079, lr = 0.005
I0403 09:13:59.069630  3803 solver.cpp:228] Iteration 2100, loss = 0.143567
I0403 09:13:59.069957  3803 solver.cpp:244]     Train net output #0: loss = 0.143567 (* 1 = 0.143567 loss)
I0403 09:13:59.320906  3803 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 09:14:14.471612  3803 solver.cpp:228] Iteration 2121, loss = 0.238347
I0403 09:14:14.471725  3803 solver.cpp:244]     Train net output #0: loss = 0.238347 (* 1 = 0.238347 loss)
I0403 09:14:14.686401  3803 sgd_solver.cpp:106] Iteration 2121, lr = 0.005
I0403 09:14:29.873972  3803 solver.cpp:228] Iteration 2142, loss = 0.279598
I0403 09:14:29.874291  3803 solver.cpp:244]     Train net output #0: loss = 0.279598 (* 1 = 0.279598 loss)
I0403 09:14:30.088093  3803 sgd_solver.cpp:106] Iteration 2142, lr = 0.005
I0403 09:14:45.297060  3803 solver.cpp:228] Iteration 2163, loss = 0.170029
I0403 09:14:45.297163  3803 solver.cpp:244]     Train net output #0: loss = 0.170029 (* 1 = 0.170029 loss)
I0403 09:14:45.474622  3803 sgd_solver.cpp:106] Iteration 2163, lr = 0.005
I0403 09:14:53.622205  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_2175.caffemodel
I0403 09:14:56.408152  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_2175.solverstate
I0403 09:14:58.250633  3803 solver.cpp:337] Iteration 2175, Testing net (#0)
I0403 09:15:22.660320  3803 solver.cpp:404]     Test net output #0: accuracy = 0.924206
I0403 09:15:22.660670  3803 solver.cpp:404]     Test net output #1: loss = 0.24261 (* 1 = 0.24261 loss)
I0403 09:15:29.794020  3803 solver.cpp:228] Iteration 2184, loss = 0.09714
I0403 09:15:29.794133  3803 solver.cpp:244]     Train net output #0: loss = 0.0971399 (* 1 = 0.0971399 loss)
I0403 09:15:29.977823  3803 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 09:15:45.247382  3803 solver.cpp:228] Iteration 2205, loss = 0.158094
I0403 09:15:45.247484  3803 solver.cpp:244]     Train net output #0: loss = 0.158094 (* 1 = 0.158094 loss)
I0403 09:15:45.417531  3803 sgd_solver.cpp:106] Iteration 2205, lr = 0.005
I0403 09:16:00.817232  3803 solver.cpp:228] Iteration 2226, loss = 0.123689
I0403 09:16:00.817554  3803 solver.cpp:244]     Train net output #0: loss = 0.123689 (* 1 = 0.123689 loss)
I0403 09:16:01.019191  3803 sgd_solver.cpp:106] Iteration 2226, lr = 0.005
I0403 09:16:16.495503  3803 solver.cpp:228] Iteration 2247, loss = 0.209278
I0403 09:16:16.495617  3803 solver.cpp:244]     Train net output #0: loss = 0.209278 (* 1 = 0.209278 loss)
I0403 09:16:16.698632  3803 sgd_solver.cpp:106] Iteration 2247, lr = 0.005
I0403 09:16:31.926733  3803 solver.cpp:228] Iteration 2268, loss = 0.0910259
I0403 09:16:31.927037  3803 solver.cpp:244]     Train net output #0: loss = 0.0910258 (* 1 = 0.0910258 loss)
I0403 09:16:32.104908  3803 sgd_solver.cpp:106] Iteration 2268, lr = 0.005
I0403 09:16:47.673620  3803 solver.cpp:228] Iteration 2289, loss = 0.123913
I0403 09:16:47.673722  3803 solver.cpp:244]     Train net output #0: loss = 0.123913 (* 1 = 0.123913 loss)
I0403 09:16:47.831795  3803 sgd_solver.cpp:106] Iteration 2289, lr = 0.005
I0403 09:17:03.051298  3803 solver.cpp:228] Iteration 2310, loss = 0.18625
I0403 09:17:03.051635  3803 solver.cpp:244]     Train net output #0: loss = 0.18625 (* 1 = 0.18625 loss)
I0403 09:17:03.188784  3803 sgd_solver.cpp:106] Iteration 2310, lr = 0.005
I0403 09:17:18.525187  3803 solver.cpp:228] Iteration 2331, loss = 0.145497
I0403 09:17:18.525305  3803 solver.cpp:244]     Train net output #0: loss = 0.145497 (* 1 = 0.145497 loss)
I0403 09:17:18.718585  3803 sgd_solver.cpp:106] Iteration 2331, lr = 0.005
I0403 09:17:33.868427  3803 solver.cpp:228] Iteration 2352, loss = 0.0372503
I0403 09:17:33.868739  3803 solver.cpp:244]     Train net output #0: loss = 0.0372502 (* 1 = 0.0372502 loss)
I0403 09:17:34.055342  3803 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 09:17:49.294335  3803 solver.cpp:228] Iteration 2373, loss = 0.144955
I0403 09:17:49.294438  3803 solver.cpp:244]     Train net output #0: loss = 0.144955 (* 1 = 0.144955 loss)
I0403 09:17:49.444825  3803 sgd_solver.cpp:106] Iteration 2373, lr = 0.005
I0403 09:18:04.941747  3803 solver.cpp:228] Iteration 2394, loss = 0.186228
I0403 09:18:04.942049  3803 solver.cpp:244]     Train net output #0: loss = 0.186228 (* 1 = 0.186228 loss)
I0403 09:18:05.138396  3803 sgd_solver.cpp:106] Iteration 2394, lr = 0.005
I0403 09:18:20.205461  3803 solver.cpp:228] Iteration 2415, loss = 0.120098
I0403 09:18:20.205574  3803 solver.cpp:244]     Train net output #0: loss = 0.120098 (* 1 = 0.120098 loss)
I0403 09:18:20.403635  3803 sgd_solver.cpp:106] Iteration 2415, lr = 0.005
I0403 09:18:35.747112  3803 solver.cpp:228] Iteration 2436, loss = 0.168841
I0403 09:18:35.747712  3803 solver.cpp:244]     Train net output #0: loss = 0.168841 (* 1 = 0.168841 loss)
I0403 09:18:35.939380  3803 sgd_solver.cpp:106] Iteration 2436, lr = 0.005
I0403 09:18:51.233161  3803 solver.cpp:228] Iteration 2457, loss = 0.116285
I0403 09:18:51.233278  3803 solver.cpp:244]     Train net output #0: loss = 0.116285 (* 1 = 0.116285 loss)
I0403 09:18:51.432709  3803 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 09:19:06.690565  3803 solver.cpp:228] Iteration 2478, loss = 0.154008
I0403 09:19:06.690862  3803 solver.cpp:244]     Train net output #0: loss = 0.154008 (* 1 = 0.154008 loss)
I0403 09:19:06.857192  3803 sgd_solver.cpp:106] Iteration 2478, lr = 0.005
I0403 09:19:22.032985  3803 solver.cpp:228] Iteration 2499, loss = 0.142621
I0403 09:19:22.033102  3803 solver.cpp:244]     Train net output #0: loss = 0.142621 (* 1 = 0.142621 loss)
I0403 09:19:22.268364  3803 sgd_solver.cpp:106] Iteration 2499, lr = 0.005
I0403 09:19:37.599041  3803 solver.cpp:228] Iteration 2520, loss = 0.067689
I0403 09:19:37.599345  3803 solver.cpp:244]     Train net output #0: loss = 0.0676889 (* 1 = 0.0676889 loss)
I0403 09:19:37.770304  3803 sgd_solver.cpp:106] Iteration 2520, lr = 0.005
I0403 09:19:53.083369  3803 solver.cpp:228] Iteration 2541, loss = 0.0503002
I0403 09:19:53.083484  3803 solver.cpp:244]     Train net output #0: loss = 0.0503 (* 1 = 0.0503 loss)
I0403 09:19:53.309864  3803 sgd_solver.cpp:106] Iteration 2541, lr = 0.005
I0403 09:20:08.426703  3803 solver.cpp:228] Iteration 2562, loss = 0.17282
I0403 09:20:08.427031  3803 solver.cpp:244]     Train net output #0: loss = 0.17282 (* 1 = 0.17282 loss)
I0403 09:20:08.610661  3803 sgd_solver.cpp:106] Iteration 2562, lr = 0.005
I0403 09:20:23.952114  3803 solver.cpp:228] Iteration 2583, loss = 0.0645521
I0403 09:20:23.952215  3803 solver.cpp:244]     Train net output #0: loss = 0.064552 (* 1 = 0.064552 loss)
I0403 09:20:24.124825  3803 sgd_solver.cpp:106] Iteration 2583, lr = 0.005
I0403 09:20:39.367498  3803 solver.cpp:228] Iteration 2604, loss = 0.187557
I0403 09:20:39.370518  3803 solver.cpp:244]     Train net output #0: loss = 0.187556 (* 1 = 0.187556 loss)
I0403 09:20:39.545958  3803 sgd_solver.cpp:106] Iteration 2604, lr = 0.005
I0403 09:20:43.182751  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_2610.caffemodel
I0403 09:20:45.915225  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_2610.solverstate
I0403 09:20:47.779883  3803 solver.cpp:337] Iteration 2610, Testing net (#0)
I0403 09:21:12.205114  3803 solver.cpp:404]     Test net output #0: accuracy = 0.940935
I0403 09:21:12.205502  3803 solver.cpp:404]     Test net output #1: loss = 0.185304 (* 1 = 0.185304 loss)
I0403 09:21:23.654021  3803 solver.cpp:228] Iteration 2625, loss = 0.110539
I0403 09:21:23.654134  3803 solver.cpp:244]     Train net output #0: loss = 0.110539 (* 1 = 0.110539 loss)
I0403 09:21:23.837637  3803 sgd_solver.cpp:106] Iteration 2625, lr = 0.005
I0403 09:21:39.301841  3803 solver.cpp:228] Iteration 2646, loss = 0.170399
I0403 09:21:39.301941  3803 solver.cpp:244]     Train net output #0: loss = 0.170398 (* 1 = 0.170398 loss)
I0403 09:21:39.478685  3803 sgd_solver.cpp:106] Iteration 2646, lr = 0.005
I0403 09:21:54.675356  3803 solver.cpp:228] Iteration 2667, loss = 0.118201
I0403 09:21:54.675680  3803 solver.cpp:244]     Train net output #0: loss = 0.118201 (* 1 = 0.118201 loss)
I0403 09:21:54.895357  3803 sgd_solver.cpp:106] Iteration 2667, lr = 0.005
I0403 09:22:10.284240  3803 solver.cpp:228] Iteration 2688, loss = 0.110547
I0403 09:22:10.284361  3803 solver.cpp:244]     Train net output #0: loss = 0.110547 (* 1 = 0.110547 loss)
I0403 09:22:10.467779  3803 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 09:22:25.970098  3803 solver.cpp:228] Iteration 2709, loss = 0.135061
I0403 09:22:25.970407  3803 solver.cpp:244]     Train net output #0: loss = 0.135061 (* 1 = 0.135061 loss)
I0403 09:22:26.143837  3803 sgd_solver.cpp:106] Iteration 2709, lr = 0.005
I0403 09:22:41.449348  3803 solver.cpp:228] Iteration 2730, loss = 0.147263
I0403 09:22:41.449448  3803 solver.cpp:244]     Train net output #0: loss = 0.147263 (* 1 = 0.147263 loss)
I0403 09:22:41.627661  3803 sgd_solver.cpp:106] Iteration 2730, lr = 0.005
I0403 09:22:56.931834  3803 solver.cpp:228] Iteration 2751, loss = 0.073353
I0403 09:22:56.932129  3803 solver.cpp:244]     Train net output #0: loss = 0.0733528 (* 1 = 0.0733528 loss)
I0403 09:22:57.093612  3803 sgd_solver.cpp:106] Iteration 2751, lr = 0.005
I0403 09:23:12.392323  3803 solver.cpp:228] Iteration 2772, loss = 0.110312
I0403 09:23:12.392436  3803 solver.cpp:244]     Train net output #0: loss = 0.110312 (* 1 = 0.110312 loss)
I0403 09:23:12.585507  3803 sgd_solver.cpp:106] Iteration 2772, lr = 0.005
I0403 09:23:28.226393  3803 solver.cpp:228] Iteration 2793, loss = 0.117531
I0403 09:23:28.226706  3803 solver.cpp:244]     Train net output #0: loss = 0.117531 (* 1 = 0.117531 loss)
I0403 09:23:28.435545  3803 sgd_solver.cpp:106] Iteration 2793, lr = 0.005
I0403 09:23:43.886344  3803 solver.cpp:228] Iteration 2814, loss = 0.0596378
I0403 09:23:43.886443  3803 solver.cpp:244]     Train net output #0: loss = 0.0596376 (* 1 = 0.0596376 loss)
I0403 09:23:44.045399  3803 sgd_solver.cpp:106] Iteration 2814, lr = 0.005
I0403 09:23:59.252737  3803 solver.cpp:228] Iteration 2835, loss = 0.122861
I0403 09:23:59.253052  3803 solver.cpp:244]     Train net output #0: loss = 0.122861 (* 1 = 0.122861 loss)
I0403 09:23:59.440628  3803 sgd_solver.cpp:106] Iteration 2835, lr = 0.005
I0403 09:24:14.680524  3803 solver.cpp:228] Iteration 2856, loss = 0.247508
I0403 09:24:14.680630  3803 solver.cpp:244]     Train net output #0: loss = 0.247507 (* 1 = 0.247507 loss)
I0403 09:24:14.850282  3803 sgd_solver.cpp:106] Iteration 2856, lr = 0.005
I0403 09:24:30.292081  3803 solver.cpp:228] Iteration 2877, loss = 0.235548
I0403 09:24:30.293598  3803 solver.cpp:244]     Train net output #0: loss = 0.235548 (* 1 = 0.235548 loss)
I0403 09:24:30.468422  3803 sgd_solver.cpp:106] Iteration 2877, lr = 0.005
I0403 09:24:45.826387  3803 solver.cpp:228] Iteration 2898, loss = 0.212066
I0403 09:24:45.826498  3803 solver.cpp:244]     Train net output #0: loss = 0.212066 (* 1 = 0.212066 loss)
I0403 09:24:46.024660  3803 sgd_solver.cpp:106] Iteration 2898, lr = 0.005
I0403 09:25:01.242470  3803 solver.cpp:228] Iteration 2919, loss = 0.106096
I0403 09:25:01.242812  3803 solver.cpp:244]     Train net output #0: loss = 0.106096 (* 1 = 0.106096 loss)
I0403 09:25:01.469149  3803 sgd_solver.cpp:106] Iteration 2919, lr = 0.005
I0403 09:25:16.751183  3803 solver.cpp:228] Iteration 2940, loss = 0.113622
I0403 09:25:16.751302  3803 solver.cpp:244]     Train net output #0: loss = 0.113622 (* 1 = 0.113622 loss)
I0403 09:25:16.948005  3803 sgd_solver.cpp:106] Iteration 2940, lr = 0.005
I0403 09:25:32.060025  3803 solver.cpp:228] Iteration 2961, loss = 0.171214
I0403 09:25:32.060355  3803 solver.cpp:244]     Train net output #0: loss = 0.171214 (* 1 = 0.171214 loss)
I0403 09:25:32.278573  3803 sgd_solver.cpp:106] Iteration 2961, lr = 0.005
I0403 09:25:47.621831  3803 solver.cpp:228] Iteration 2982, loss = 0.0994065
I0403 09:25:47.621944  3803 solver.cpp:244]     Train net output #0: loss = 0.0994064 (* 1 = 0.0994064 loss)
I0403 09:25:47.818655  3803 sgd_solver.cpp:106] Iteration 2982, lr = 0.005
I0403 09:26:03.280390  3803 solver.cpp:228] Iteration 3003, loss = 0.0712305
I0403 09:26:03.280684  3803 solver.cpp:244]     Train net output #0: loss = 0.0712304 (* 1 = 0.0712304 loss)
I0403 09:26:03.375527  3803 sgd_solver.cpp:106] Iteration 3003, lr = 0.005
I0403 09:26:18.816326  3803 solver.cpp:228] Iteration 3024, loss = 0.0678638
I0403 09:26:18.816439  3803 solver.cpp:244]     Train net output #0: loss = 0.0678637 (* 1 = 0.0678637 loss)
I0403 09:26:19.004664  3803 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 09:26:33.722010  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_3045.caffemodel
I0403 09:26:36.572588  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_3045.solverstate
I0403 09:26:38.436260  3803 solver.cpp:337] Iteration 3045, Testing net (#0)
I0403 09:27:02.853348  3803 solver.cpp:404]     Test net output #0: accuracy = 0.941495
I0403 09:27:02.853456  3803 solver.cpp:404]     Test net output #1: loss = 0.195033 (* 1 = 0.195033 loss)
I0403 09:27:03.414523  3803 solver.cpp:228] Iteration 3045, loss = 0.117011
I0403 09:27:03.414618  3803 solver.cpp:244]     Train net output #0: loss = 0.117011 (* 1 = 0.117011 loss)
I0403 09:27:03.543366  3803 sgd_solver.cpp:106] Iteration 3045, lr = 0.005
I0403 09:27:19.094151  3803 solver.cpp:228] Iteration 3066, loss = 0.0393517
I0403 09:27:19.094409  3803 solver.cpp:244]     Train net output #0: loss = 0.0393516 (* 1 = 0.0393516 loss)
I0403 09:27:19.277034  3803 sgd_solver.cpp:106] Iteration 3066, lr = 0.005
I0403 09:27:34.452972  3803 solver.cpp:228] Iteration 3087, loss = 0.0479458
I0403 09:27:34.453085  3803 solver.cpp:244]     Train net output #0: loss = 0.0479457 (* 1 = 0.0479457 loss)
I0403 09:27:34.654696  3803 sgd_solver.cpp:106] Iteration 3087, lr = 0.005
I0403 09:27:50.134150  3803 solver.cpp:228] Iteration 3108, loss = 0.0870245
I0403 09:27:50.139633  3803 solver.cpp:244]     Train net output #0: loss = 0.0870244 (* 1 = 0.0870244 loss)
I0403 09:27:50.352377  3803 sgd_solver.cpp:106] Iteration 3108, lr = 0.005
I0403 09:28:05.547036  3803 solver.cpp:228] Iteration 3129, loss = 0.161814
I0403 09:28:05.547137  3803 solver.cpp:244]     Train net output #0: loss = 0.161814 (* 1 = 0.161814 loss)
I0403 09:28:05.705358  3803 sgd_solver.cpp:106] Iteration 3129, lr = 0.005
I0403 09:28:20.866842  3803 solver.cpp:228] Iteration 3150, loss = 0.0991191
I0403 09:28:20.869665  3803 solver.cpp:244]     Train net output #0: loss = 0.099119 (* 1 = 0.099119 loss)
I0403 09:28:21.042644  3803 sgd_solver.cpp:106] Iteration 3150, lr = 0.005
I0403 09:28:36.326282  3803 solver.cpp:228] Iteration 3171, loss = 0.0835399
I0403 09:28:36.326391  3803 solver.cpp:244]     Train net output #0: loss = 0.0835398 (* 1 = 0.0835398 loss)
I0403 09:28:36.509595  3803 sgd_solver.cpp:106] Iteration 3171, lr = 0.005
I0403 09:28:51.665503  3803 solver.cpp:228] Iteration 3192, loss = 0.106419
I0403 09:28:51.665848  3803 solver.cpp:244]     Train net output #0: loss = 0.106419 (* 1 = 0.106419 loss)
I0403 09:28:51.863595  3803 sgd_solver.cpp:106] Iteration 3192, lr = 0.005
I0403 09:29:07.166200  3803 solver.cpp:228] Iteration 3213, loss = 0.0803458
I0403 09:29:07.166309  3803 solver.cpp:244]     Train net output #0: loss = 0.0803457 (* 1 = 0.0803457 loss)
I0403 09:29:07.324317  3803 sgd_solver.cpp:106] Iteration 3213, lr = 0.005
I0403 09:29:22.611358  3803 solver.cpp:228] Iteration 3234, loss = 0.0499842
I0403 09:29:22.611687  3803 solver.cpp:244]     Train net output #0: loss = 0.0499841 (* 1 = 0.0499841 loss)
I0403 09:29:22.809788  3803 sgd_solver.cpp:106] Iteration 3234, lr = 0.005
I0403 09:29:37.994339  3803 solver.cpp:228] Iteration 3255, loss = 0.115463
I0403 09:29:37.994457  3803 solver.cpp:244]     Train net output #0: loss = 0.115463 (* 1 = 0.115463 loss)
I0403 09:29:38.171433  3803 sgd_solver.cpp:106] Iteration 3255, lr = 0.005
I0403 09:29:53.411718  3803 solver.cpp:228] Iteration 3276, loss = 0.12026
I0403 09:29:53.412034  3803 solver.cpp:244]     Train net output #0: loss = 0.12026 (* 1 = 0.12026 loss)
I0403 09:29:53.622491  3803 sgd_solver.cpp:106] Iteration 3276, lr = 0.005
I0403 09:30:08.936866  3803 solver.cpp:228] Iteration 3297, loss = 0.0666639
I0403 09:30:08.936966  3803 solver.cpp:244]     Train net output #0: loss = 0.0666638 (* 1 = 0.0666638 loss)
I0403 09:30:09.116053  3803 sgd_solver.cpp:106] Iteration 3297, lr = 0.005
I0403 09:30:24.302130  3803 solver.cpp:228] Iteration 3318, loss = 0.142975
I0403 09:30:24.302430  3803 solver.cpp:244]     Train net output #0: loss = 0.142975 (* 1 = 0.142975 loss)
I0403 09:30:24.453327  3803 sgd_solver.cpp:106] Iteration 3318, lr = 0.005
I0403 09:30:39.660238  3803 solver.cpp:228] Iteration 3339, loss = 0.114567
I0403 09:30:39.660357  3803 solver.cpp:244]     Train net output #0: loss = 0.114566 (* 1 = 0.114566 loss)
I0403 09:30:39.852187  3803 sgd_solver.cpp:106] Iteration 3339, lr = 0.005
I0403 09:30:54.975679  3803 solver.cpp:228] Iteration 3360, loss = 0.0897556
I0403 09:30:54.976008  3803 solver.cpp:244]     Train net output #0: loss = 0.0897555 (* 1 = 0.0897555 loss)
I0403 09:30:55.163574  3803 sgd_solver.cpp:106] Iteration 3360, lr = 0.005
I0403 09:31:10.463019  3803 solver.cpp:228] Iteration 3381, loss = 0.0998741
I0403 09:31:10.463131  3803 solver.cpp:244]     Train net output #0: loss = 0.099874 (* 1 = 0.099874 loss)
I0403 09:31:10.651366  3803 sgd_solver.cpp:106] Iteration 3381, lr = 0.005
I0403 09:31:26.065009  3803 solver.cpp:228] Iteration 3402, loss = 0.0929647
I0403 09:31:26.065309  3803 solver.cpp:244]     Train net output #0: loss = 0.0929646 (* 1 = 0.0929646 loss)
I0403 09:31:26.287361  3803 sgd_solver.cpp:106] Iteration 3402, lr = 0.005
I0403 09:31:41.703021  3803 solver.cpp:228] Iteration 3423, loss = 0.127823
I0403 09:31:41.703121  3803 solver.cpp:244]     Train net output #0: loss = 0.127823 (* 1 = 0.127823 loss)
I0403 09:31:41.871129  3803 sgd_solver.cpp:106] Iteration 3423, lr = 0.005
I0403 09:31:57.228754  3803 solver.cpp:228] Iteration 3444, loss = 0.0584239
I0403 09:31:57.229037  3803 solver.cpp:244]     Train net output #0: loss = 0.0584238 (* 1 = 0.0584238 loss)
I0403 09:31:57.405290  3803 sgd_solver.cpp:106] Iteration 3444, lr = 0.005
I0403 09:32:12.637326  3803 solver.cpp:228] Iteration 3465, loss = 0.0404736
I0403 09:32:12.637428  3803 solver.cpp:244]     Train net output #0: loss = 0.0404735 (* 1 = 0.0404735 loss)
I0403 09:32:12.817994  3803 sgd_solver.cpp:106] Iteration 3465, lr = 0.005
I0403 09:32:22.998108  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_3480.caffemodel
I0403 09:32:25.694514  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_3480.solverstate
I0403 09:32:27.535862  3803 solver.cpp:337] Iteration 3480, Testing net (#0)
I0403 09:32:51.953080  3803 solver.cpp:404]     Test net output #0: accuracy = 0.946916
I0403 09:32:51.953191  3803 solver.cpp:404]     Test net output #1: loss = 0.182306 (* 1 = 0.182306 loss)
I0403 09:32:56.955507  3803 solver.cpp:228] Iteration 3486, loss = 0.11902
I0403 09:32:56.955617  3803 solver.cpp:244]     Train net output #0: loss = 0.11902 (* 1 = 0.11902 loss)
I0403 09:32:57.122419  3803 sgd_solver.cpp:106] Iteration 3486, lr = 0.005
I0403 09:33:12.575170  3803 solver.cpp:228] Iteration 3507, loss = 0.0967752
I0403 09:33:12.575426  3803 solver.cpp:244]     Train net output #0: loss = 0.0967752 (* 1 = 0.0967752 loss)
I0403 09:33:12.735272  3803 sgd_solver.cpp:106] Iteration 3507, lr = 0.005
I0403 09:33:28.103075  3803 solver.cpp:228] Iteration 3528, loss = 0.0945375
I0403 09:33:28.103190  3803 solver.cpp:244]     Train net output #0: loss = 0.0945374 (* 1 = 0.0945374 loss)
I0403 09:33:28.303194  3803 sgd_solver.cpp:106] Iteration 3528, lr = 0.005
I0403 09:33:43.592645  3803 solver.cpp:228] Iteration 3549, loss = 0.0932797
I0403 09:33:43.592941  3803 solver.cpp:244]     Train net output #0: loss = 0.0932797 (* 1 = 0.0932797 loss)
I0403 09:33:43.754564  3803 sgd_solver.cpp:106] Iteration 3549, lr = 0.005
I0403 09:33:59.093401  3803 solver.cpp:228] Iteration 3570, loss = 0.0997574
I0403 09:33:59.093502  3803 solver.cpp:244]     Train net output #0: loss = 0.0997573 (* 1 = 0.0997573 loss)
I0403 09:33:59.273118  3803 sgd_solver.cpp:106] Iteration 3570, lr = 0.005
I0403 09:34:14.624960  3803 solver.cpp:228] Iteration 3591, loss = 0.148373
I0403 09:34:14.625267  3803 solver.cpp:244]     Train net output #0: loss = 0.148373 (* 1 = 0.148373 loss)
I0403 09:34:14.786455  3803 sgd_solver.cpp:106] Iteration 3591, lr = 0.005
I0403 09:34:30.124804  3803 solver.cpp:228] Iteration 3612, loss = 0.0453014
I0403 09:34:30.124907  3803 solver.cpp:244]     Train net output #0: loss = 0.0453014 (* 1 = 0.0453014 loss)
I0403 09:34:30.292531  3803 sgd_solver.cpp:106] Iteration 3612, lr = 0.005
I0403 09:34:45.692688  3803 solver.cpp:228] Iteration 3633, loss = 0.0441501
I0403 09:34:45.692986  3803 solver.cpp:244]     Train net output #0: loss = 0.04415 (* 1 = 0.04415 loss)
I0403 09:34:45.868798  3803 sgd_solver.cpp:106] Iteration 3633, lr = 0.005
I0403 09:35:01.066944  3803 solver.cpp:228] Iteration 3654, loss = 0.0406773
I0403 09:35:01.067055  3803 solver.cpp:244]     Train net output #0: loss = 0.0406772 (* 1 = 0.0406772 loss)
I0403 09:35:01.250948  3803 sgd_solver.cpp:106] Iteration 3654, lr = 0.005
I0403 09:35:16.513154  3803 solver.cpp:228] Iteration 3675, loss = 0.0481579
I0403 09:35:16.513478  3803 solver.cpp:244]     Train net output #0: loss = 0.0481579 (* 1 = 0.0481579 loss)
I0403 09:35:16.767768  3803 sgd_solver.cpp:106] Iteration 3675, lr = 0.005
I0403 09:35:32.031635  3803 solver.cpp:228] Iteration 3696, loss = 0.11527
I0403 09:35:32.031754  3803 solver.cpp:244]     Train net output #0: loss = 0.11527 (* 1 = 0.11527 loss)
I0403 09:35:32.258579  3803 sgd_solver.cpp:106] Iteration 3696, lr = 0.005
I0403 09:35:47.495932  3803 solver.cpp:228] Iteration 3717, loss = 0.114639
I0403 09:35:47.496254  3803 solver.cpp:244]     Train net output #0: loss = 0.114639 (* 1 = 0.114639 loss)
I0403 09:35:47.719130  3803 sgd_solver.cpp:106] Iteration 3717, lr = 0.005
I0403 09:36:02.935828  3803 solver.cpp:228] Iteration 3738, loss = 0.20311
I0403 09:36:02.935942  3803 solver.cpp:244]     Train net output #0: loss = 0.20311 (* 1 = 0.20311 loss)
I0403 09:36:03.128559  3803 sgd_solver.cpp:106] Iteration 3738, lr = 0.005
I0403 09:36:18.317279  3803 solver.cpp:228] Iteration 3759, loss = 0.142611
I0403 09:36:18.317603  3803 solver.cpp:244]     Train net output #0: loss = 0.142611 (* 1 = 0.142611 loss)
I0403 09:36:18.545178  3803 sgd_solver.cpp:106] Iteration 3759, lr = 0.005
I0403 09:36:33.956239  3803 solver.cpp:228] Iteration 3780, loss = 0.0269864
I0403 09:36:33.956358  3803 solver.cpp:244]     Train net output #0: loss = 0.0269864 (* 1 = 0.0269864 loss)
I0403 09:36:34.198096  3803 sgd_solver.cpp:106] Iteration 3780, lr = 0.005
I0403 09:36:49.677129  3803 solver.cpp:228] Iteration 3801, loss = 0.0281398
I0403 09:36:49.677472  3803 solver.cpp:244]     Train net output #0: loss = 0.0281397 (* 1 = 0.0281397 loss)
I0403 09:36:49.828223  3803 sgd_solver.cpp:106] Iteration 3801, lr = 0.005
I0403 09:37:05.208642  3803 solver.cpp:228] Iteration 3822, loss = 0.0935551
I0403 09:37:05.208762  3803 solver.cpp:244]     Train net output #0: loss = 0.093555 (* 1 = 0.093555 loss)
I0403 09:37:05.437095  3803 sgd_solver.cpp:106] Iteration 3822, lr = 0.005
I0403 09:37:20.667275  3803 solver.cpp:228] Iteration 3843, loss = 0.113136
I0403 09:37:20.667583  3803 solver.cpp:244]     Train net output #0: loss = 0.113136 (* 1 = 0.113136 loss)
I0403 09:37:20.846678  3803 sgd_solver.cpp:106] Iteration 3843, lr = 0.005
I0403 09:37:36.335818  3803 solver.cpp:228] Iteration 3864, loss = 0.0489854
I0403 09:37:36.335927  3803 solver.cpp:244]     Train net output #0: loss = 0.0489854 (* 1 = 0.0489854 loss)
I0403 09:37:36.534821  3803 sgd_solver.cpp:106] Iteration 3864, lr = 0.005
I0403 09:37:51.726547  3803 solver.cpp:228] Iteration 3885, loss = 0.0968362
I0403 09:37:51.726833  3803 solver.cpp:244]     Train net output #0: loss = 0.0968362 (* 1 = 0.0968362 loss)
I0403 09:37:51.910176  3803 sgd_solver.cpp:106] Iteration 3885, lr = 0.005
I0403 09:38:07.069170  3803 solver.cpp:228] Iteration 3906, loss = 0.0621715
I0403 09:38:07.069284  3803 solver.cpp:244]     Train net output #0: loss = 0.0621714 (* 1 = 0.0621714 loss)
I0403 09:38:07.257643  3803 sgd_solver.cpp:106] Iteration 3906, lr = 0.005
I0403 09:38:13.145696  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_3915.caffemodel
I0403 09:38:15.874018  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_3915.solverstate
I0403 09:38:17.739742  3803 solver.cpp:337] Iteration 3915, Testing net (#0)
I0403 09:38:42.157191  3803 solver.cpp:404]     Test net output #0: accuracy = 0.954018
I0403 09:38:42.157505  3803 solver.cpp:404]     Test net output #1: loss = 0.159751 (* 1 = 0.159751 loss)
I0403 09:38:51.577457  3803 solver.cpp:228] Iteration 3927, loss = 0.051285
I0403 09:38:51.577558  3803 solver.cpp:244]     Train net output #0: loss = 0.051285 (* 1 = 0.051285 loss)
I0403 09:38:51.756124  3803 sgd_solver.cpp:106] Iteration 3927, lr = 0.005
I0403 09:39:06.967806  3803 solver.cpp:228] Iteration 3948, loss = 0.046635
I0403 09:39:06.967918  3803 solver.cpp:244]     Train net output #0: loss = 0.046635 (* 1 = 0.046635 loss)
I0403 09:39:07.208794  3803 sgd_solver.cpp:106] Iteration 3948, lr = 0.005
I0403 09:39:22.795438  3803 solver.cpp:228] Iteration 3969, loss = 0.109741
I0403 09:39:22.795744  3803 solver.cpp:244]     Train net output #0: loss = 0.109741 (* 1 = 0.109741 loss)
I0403 09:39:22.993584  3803 sgd_solver.cpp:106] Iteration 3969, lr = 0.005
I0403 09:39:38.126538  3803 solver.cpp:228] Iteration 3990, loss = 0.0765645
I0403 09:39:38.126637  3803 solver.cpp:244]     Train net output #0: loss = 0.0765645 (* 1 = 0.0765645 loss)
I0403 09:39:38.305184  3803 sgd_solver.cpp:106] Iteration 3990, lr = 0.005
I0403 09:39:53.401748  3803 solver.cpp:228] Iteration 4011, loss = 0.0956219
I0403 09:39:53.402050  3803 solver.cpp:244]     Train net output #0: loss = 0.0956219 (* 1 = 0.0956219 loss)
I0403 09:39:53.581037  3803 sgd_solver.cpp:106] Iteration 4011, lr = 0.005
I0403 09:40:08.902598  3803 solver.cpp:228] Iteration 4032, loss = 0.0466943
I0403 09:40:08.902695  3803 solver.cpp:244]     Train net output #0: loss = 0.0466943 (* 1 = 0.0466943 loss)
I0403 09:40:09.077570  3803 sgd_solver.cpp:106] Iteration 4032, lr = 0.005
I0403 09:40:24.369384  3803 solver.cpp:228] Iteration 4053, loss = 0.0809118
I0403 09:40:24.369724  3803 solver.cpp:244]     Train net output #0: loss = 0.0809118 (* 1 = 0.0809118 loss)
I0403 09:40:24.547722  3803 sgd_solver.cpp:106] Iteration 4053, lr = 0.005
I0403 09:40:40.220690  3803 solver.cpp:228] Iteration 4074, loss = 0.0615377
I0403 09:40:40.220782  3803 solver.cpp:244]     Train net output #0: loss = 0.0615377 (* 1 = 0.0615377 loss)
I0403 09:40:40.351171  3803 sgd_solver.cpp:106] Iteration 4074, lr = 0.005
I0403 09:40:55.722159  3803 solver.cpp:228] Iteration 4095, loss = 0.11426
I0403 09:40:55.722489  3803 solver.cpp:244]     Train net output #0: loss = 0.11426 (* 1 = 0.11426 loss)
I0403 09:40:55.920840  3803 sgd_solver.cpp:106] Iteration 4095, lr = 0.005
I0403 09:41:11.290428  3803 solver.cpp:228] Iteration 4116, loss = 0.0810666
I0403 09:41:11.290544  3803 solver.cpp:244]     Train net output #0: loss = 0.0810666 (* 1 = 0.0810666 loss)
I0403 09:41:11.493834  3803 sgd_solver.cpp:106] Iteration 4116, lr = 0.005
I0403 09:41:26.698391  3803 solver.cpp:228] Iteration 4137, loss = 0.0197624
I0403 09:41:26.698700  3803 solver.cpp:244]     Train net output #0: loss = 0.0197624 (* 1 = 0.0197624 loss)
I0403 09:41:26.891067  3803 sgd_solver.cpp:106] Iteration 4137, lr = 0.005
I0403 09:41:42.182804  3803 solver.cpp:228] Iteration 4158, loss = 0.096507
I0403 09:41:42.182904  3803 solver.cpp:244]     Train net output #0: loss = 0.096507 (* 1 = 0.096507 loss)
I0403 09:41:42.307607  3803 sgd_solver.cpp:106] Iteration 4158, lr = 0.005
I0403 09:41:57.550544  3803 solver.cpp:228] Iteration 4179, loss = 0.117632
I0403 09:41:57.560334  3803 solver.cpp:244]     Train net output #0: loss = 0.117632 (* 1 = 0.117632 loss)
I0403 09:41:57.732980  3803 sgd_solver.cpp:106] Iteration 4179, lr = 0.005
I0403 09:42:13.252010  3803 solver.cpp:228] Iteration 4200, loss = 0.0288671
I0403 09:42:13.252113  3803 solver.cpp:244]     Train net output #0: loss = 0.0288671 (* 1 = 0.0288671 loss)
I0403 09:42:13.413609  3803 sgd_solver.cpp:106] Iteration 4200, lr = 0.005
I0403 09:42:29.121639  3803 solver.cpp:228] Iteration 4221, loss = 0.0281542
I0403 09:42:29.121938  3803 solver.cpp:244]     Train net output #0: loss = 0.0281542 (* 1 = 0.0281542 loss)
I0403 09:42:29.299149  3803 sgd_solver.cpp:106] Iteration 4221, lr = 0.005
I0403 09:42:45.019373  3803 solver.cpp:228] Iteration 4242, loss = 0.0979624
I0403 09:42:45.019476  3803 solver.cpp:244]     Train net output #0: loss = 0.0979624 (* 1 = 0.0979624 loss)
I0403 09:42:45.146563  3803 sgd_solver.cpp:106] Iteration 4242, lr = 0.005
I0403 09:43:00.559317  3803 solver.cpp:228] Iteration 4263, loss = 0.0838313
I0403 09:43:00.559638  3803 solver.cpp:244]     Train net output #0: loss = 0.0838313 (* 1 = 0.0838313 loss)
I0403 09:43:00.742521  3803 sgd_solver.cpp:106] Iteration 4263, lr = 0.005
I0403 09:43:16.058989  3803 solver.cpp:228] Iteration 4284, loss = 0.0361552
I0403 09:43:16.059092  3803 solver.cpp:244]     Train net output #0: loss = 0.0361552 (* 1 = 0.0361552 loss)
I0403 09:43:16.182237  3803 sgd_solver.cpp:106] Iteration 4284, lr = 0.005
I0403 09:43:31.582692  3803 solver.cpp:228] Iteration 4305, loss = 0.0479768
I0403 09:43:31.582996  3803 solver.cpp:244]     Train net output #0: loss = 0.0479768 (* 1 = 0.0479768 loss)
I0403 09:43:31.756710  3803 sgd_solver.cpp:106] Iteration 4305, lr = 0.005
I0403 09:43:47.248728  3803 solver.cpp:228] Iteration 4326, loss = 0.0438534
I0403 09:43:47.248859  3803 solver.cpp:244]     Train net output #0: loss = 0.0438534 (* 1 = 0.0438534 loss)
I0403 09:43:47.458487  3803 sgd_solver.cpp:106] Iteration 4326, lr = 0.005
I0403 09:44:02.669555  3803 solver.cpp:228] Iteration 4347, loss = 0.0444633
I0403 09:44:02.669875  3803 solver.cpp:244]     Train net output #0: loss = 0.0444633 (* 1 = 0.0444633 loss)
I0403 09:44:02.863569  3803 sgd_solver.cpp:106] Iteration 4347, lr = 0.005
I0403 09:44:04.325764  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_4350.caffemodel
I0403 09:44:07.013883  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_4350.solverstate
I0403 09:44:08.855605  3803 solver.cpp:337] Iteration 4350, Testing net (#0)
I0403 09:44:33.268203  3803 solver.cpp:404]     Test net output #0: accuracy = 0.950841
I0403 09:44:33.268555  3803 solver.cpp:404]     Test net output #1: loss = 0.168943 (* 1 = 0.168943 loss)
I0403 09:44:46.874167  3803 solver.cpp:228] Iteration 4368, loss = 0.105776
I0403 09:44:46.874280  3803 solver.cpp:244]     Train net output #0: loss = 0.105776 (* 1 = 0.105776 loss)
I0403 09:44:47.057643  3803 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 09:45:02.462152  3803 solver.cpp:228] Iteration 4389, loss = 0.0529959
I0403 09:45:02.462265  3803 solver.cpp:244]     Train net output #0: loss = 0.0529959 (* 1 = 0.0529959 loss)
I0403 09:45:02.684988  3803 sgd_solver.cpp:106] Iteration 4389, lr = 0.0005
I0403 09:45:18.009347  3803 solver.cpp:228] Iteration 4410, loss = 0.0715621
I0403 09:45:18.009661  3803 solver.cpp:244]     Train net output #0: loss = 0.0715621 (* 1 = 0.0715621 loss)
I0403 09:45:18.185221  3803 sgd_solver.cpp:106] Iteration 4410, lr = 0.0005
I0403 09:45:33.715966  3803 solver.cpp:228] Iteration 4431, loss = 0.0252489
I0403 09:45:33.716068  3803 solver.cpp:244]     Train net output #0: loss = 0.0252489 (* 1 = 0.0252489 loss)
I0403 09:45:33.885265  3803 sgd_solver.cpp:106] Iteration 4431, lr = 0.0005
I0403 09:45:49.164850  3803 solver.cpp:228] Iteration 4452, loss = 0.0123718
I0403 09:45:49.168103  3803 solver.cpp:244]     Train net output #0: loss = 0.0123718 (* 1 = 0.0123718 loss)
I0403 09:45:49.321300  3803 sgd_solver.cpp:106] Iteration 4452, lr = 0.0005
I0403 09:46:04.780544  3803 solver.cpp:228] Iteration 4473, loss = 0.0239787
I0403 09:46:04.780658  3803 solver.cpp:244]     Train net output #0: loss = 0.0239787 (* 1 = 0.0239787 loss)
I0403 09:46:04.972033  3803 sgd_solver.cpp:106] Iteration 4473, lr = 0.0005
I0403 09:46:20.328379  3803 solver.cpp:228] Iteration 4494, loss = 0.0576984
I0403 09:46:20.328657  3803 solver.cpp:244]     Train net output #0: loss = 0.0576983 (* 1 = 0.0576983 loss)
I0403 09:46:20.507308  3803 sgd_solver.cpp:106] Iteration 4494, lr = 0.0005
I0403 09:46:35.706970  3803 solver.cpp:228] Iteration 4515, loss = 0.0371693
I0403 09:46:35.707072  3803 solver.cpp:244]     Train net output #0: loss = 0.0371693 (* 1 = 0.0371693 loss)
I0403 09:46:35.877173  3803 sgd_solver.cpp:106] Iteration 4515, lr = 0.0005
I0403 09:46:51.068019  3803 solver.cpp:228] Iteration 4536, loss = 0.0284614
I0403 09:46:51.068338  3803 solver.cpp:244]     Train net output #0: loss = 0.0284614 (* 1 = 0.0284614 loss)
I0403 09:46:51.253796  3803 sgd_solver.cpp:106] Iteration 4536, lr = 0.0005
I0403 09:47:06.773603  3803 solver.cpp:228] Iteration 4557, loss = 0.0311526
I0403 09:47:06.773702  3803 solver.cpp:244]     Train net output #0: loss = 0.0311525 (* 1 = 0.0311525 loss)
I0403 09:47:06.951086  3803 sgd_solver.cpp:106] Iteration 4557, lr = 0.0005
I0403 09:47:22.388366  3803 solver.cpp:228] Iteration 4578, loss = 0.0211917
I0403 09:47:22.388674  3803 solver.cpp:244]     Train net output #0: loss = 0.0211916 (* 1 = 0.0211916 loss)
I0403 09:47:22.507675  3803 sgd_solver.cpp:106] Iteration 4578, lr = 0.0005
I0403 09:47:37.928949  3803 solver.cpp:228] Iteration 4599, loss = 0.00777656
I0403 09:47:37.929049  3803 solver.cpp:244]     Train net output #0: loss = 0.00777655 (* 1 = 0.00777655 loss)
I0403 09:47:38.108501  3803 sgd_solver.cpp:106] Iteration 4599, lr = 0.0005
I0403 09:47:53.211647  3803 solver.cpp:228] Iteration 4620, loss = 0.0437012
I0403 09:47:53.211947  3803 solver.cpp:244]     Train net output #0: loss = 0.0437012 (* 1 = 0.0437012 loss)
I0403 09:47:53.357955  3803 sgd_solver.cpp:106] Iteration 4620, lr = 0.0005
I0403 09:48:08.575615  3803 solver.cpp:228] Iteration 4641, loss = 0.0999107
I0403 09:48:08.575726  3803 solver.cpp:244]     Train net output #0: loss = 0.0999106 (* 1 = 0.0999106 loss)
I0403 09:48:08.772673  3803 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 09:48:24.336846  3803 solver.cpp:228] Iteration 4662, loss = 0.007666
I0403 09:48:24.337180  3803 solver.cpp:244]     Train net output #0: loss = 0.00766598 (* 1 = 0.00766598 loss)
I0403 09:48:24.520043  3803 sgd_solver.cpp:106] Iteration 4662, lr = 0.0005
I0403 09:48:40.054859  3803 solver.cpp:228] Iteration 4683, loss = 0.0368439
I0403 09:48:40.054975  3803 solver.cpp:244]     Train net output #0: loss = 0.0368438 (* 1 = 0.0368438 loss)
I0403 09:48:40.258064  3803 sgd_solver.cpp:106] Iteration 4683, lr = 0.0005
I0403 09:48:55.717571  3803 solver.cpp:228] Iteration 4704, loss = 0.0197819
I0403 09:48:55.717874  3803 solver.cpp:244]     Train net output #0: loss = 0.0197819 (* 1 = 0.0197819 loss)
I0403 09:48:55.897037  3803 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 09:49:11.035280  3803 solver.cpp:228] Iteration 4725, loss = 0.00411217
I0403 09:49:11.035382  3803 solver.cpp:244]     Train net output #0: loss = 0.00411215 (* 1 = 0.00411215 loss)
I0403 09:49:11.205982  3803 sgd_solver.cpp:106] Iteration 4725, lr = 0.0005
I0403 09:49:26.362162  3803 solver.cpp:228] Iteration 4746, loss = 0.0194729
I0403 09:49:26.362457  3803 solver.cpp:244]     Train net output #0: loss = 0.0194729 (* 1 = 0.0194729 loss)
I0403 09:49:26.545513  3803 sgd_solver.cpp:106] Iteration 4746, lr = 0.0005
I0403 09:49:41.748858  3803 solver.cpp:228] Iteration 4767, loss = 0.0166714
I0403 09:49:41.748975  3803 solver.cpp:244]     Train net output #0: loss = 0.0166714 (* 1 = 0.0166714 loss)
I0403 09:49:41.967728  3803 sgd_solver.cpp:106] Iteration 4767, lr = 0.0005
I0403 09:49:54.402364  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_4785.caffemodel
I0403 09:49:57.063623  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_4785.solverstate
I0403 09:49:58.898411  3803 solver.cpp:337] Iteration 4785, Testing net (#0)
I0403 09:50:23.314754  3803 solver.cpp:404]     Test net output #0: accuracy = 0.968692
I0403 09:50:23.314879  3803 solver.cpp:404]     Test net output #1: loss = 0.1098 (* 1 = 0.1098 loss)
I0403 09:50:26.010105  3803 solver.cpp:228] Iteration 4788, loss = 0.0367956
I0403 09:50:26.010221  3803 solver.cpp:244]     Train net output #0: loss = 0.0367956 (* 1 = 0.0367956 loss)
I0403 09:50:26.205586  3803 sgd_solver.cpp:106] Iteration 4788, lr = 0.0005
I0403 09:50:41.849031  3803 solver.cpp:228] Iteration 4809, loss = 0.00966478
I0403 09:50:41.849344  3803 solver.cpp:244]     Train net output #0: loss = 0.00966476 (* 1 = 0.00966476 loss)
I0403 09:50:41.980228  3803 sgd_solver.cpp:106] Iteration 4809, lr = 0.0005
I0403 09:50:57.406131  3803 solver.cpp:228] Iteration 4830, loss = 0.0184294
I0403 09:50:57.406235  3803 solver.cpp:244]     Train net output #0: loss = 0.0184294 (* 1 = 0.0184294 loss)
I0403 09:50:57.546653  3803 sgd_solver.cpp:106] Iteration 4830, lr = 0.0005
I0403 09:51:12.912469  3803 solver.cpp:228] Iteration 4851, loss = 0.0313895
I0403 09:51:12.912771  3803 solver.cpp:244]     Train net output #0: loss = 0.0313895 (* 1 = 0.0313895 loss)
I0403 09:51:13.062685  3803 sgd_solver.cpp:106] Iteration 4851, lr = 0.0005
I0403 09:51:28.468950  3803 solver.cpp:228] Iteration 4872, loss = 0.0187468
I0403 09:51:28.469077  3803 solver.cpp:244]     Train net output #0: loss = 0.0187468 (* 1 = 0.0187468 loss)
I0403 09:51:28.659651  3803 sgd_solver.cpp:106] Iteration 4872, lr = 0.0005
I0403 09:51:44.222245  3803 solver.cpp:228] Iteration 4893, loss = 0.0247687
I0403 09:51:44.222568  3803 solver.cpp:244]     Train net output #0: loss = 0.0247687 (* 1 = 0.0247687 loss)
I0403 09:51:44.412631  3803 sgd_solver.cpp:106] Iteration 4893, lr = 0.0005
I0403 09:52:00.014361  3803 solver.cpp:228] Iteration 4914, loss = 0.00520179
I0403 09:52:00.014473  3803 solver.cpp:244]     Train net output #0: loss = 0.00520176 (* 1 = 0.00520176 loss)
I0403 09:52:00.197681  3803 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 09:52:15.435025  3803 solver.cpp:228] Iteration 4935, loss = 0.0648736
I0403 09:52:15.435369  3803 solver.cpp:244]     Train net output #0: loss = 0.0648736 (* 1 = 0.0648736 loss)
I0403 09:52:15.640288  3803 sgd_solver.cpp:106] Iteration 4935, lr = 0.0005
I0403 09:52:30.876266  3803 solver.cpp:228] Iteration 4956, loss = 0.0145102
I0403 09:52:30.876365  3803 solver.cpp:244]     Train net output #0: loss = 0.0145102 (* 1 = 0.0145102 loss)
I0403 09:52:31.045531  3803 sgd_solver.cpp:106] Iteration 4956, lr = 0.0005
I0403 09:52:46.529343  3803 solver.cpp:228] Iteration 4977, loss = 0.0196686
I0403 09:52:46.529662  3803 solver.cpp:244]     Train net output #0: loss = 0.0196686 (* 1 = 0.0196686 loss)
I0403 09:52:46.642122  3803 sgd_solver.cpp:106] Iteration 4977, lr = 0.0005
I0403 09:53:02.051723  3803 solver.cpp:228] Iteration 4998, loss = 0.0963776
I0403 09:53:02.051827  3803 solver.cpp:244]     Train net output #0: loss = 0.0963775 (* 1 = 0.0963775 loss)
I0403 09:53:02.203094  3803 sgd_solver.cpp:106] Iteration 4998, lr = 0.0005
I0403 09:53:17.759171  3803 solver.cpp:228] Iteration 5019, loss = 0.0207595
I0403 09:53:17.759485  3803 solver.cpp:244]     Train net output #0: loss = 0.0207595 (* 1 = 0.0207595 loss)
I0403 09:53:17.962618  3803 sgd_solver.cpp:106] Iteration 5019, lr = 0.0005
I0403 09:53:33.166141  3803 solver.cpp:228] Iteration 5040, loss = 0.0578289
I0403 09:53:33.171600  3803 solver.cpp:244]     Train net output #0: loss = 0.0578288 (* 1 = 0.0578288 loss)
I0403 09:53:33.342602  3803 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 09:53:48.883101  3803 solver.cpp:228] Iteration 5061, loss = 0.0100842
I0403 09:53:48.883429  3803 solver.cpp:244]     Train net output #0: loss = 0.0100842 (* 1 = 0.0100842 loss)
I0403 09:53:49.109127  3803 sgd_solver.cpp:106] Iteration 5061, lr = 0.0005
I0403 09:54:04.302897  3803 solver.cpp:228] Iteration 5082, loss = 0.00896455
I0403 09:54:04.302999  3803 solver.cpp:244]     Train net output #0: loss = 0.00896452 (* 1 = 0.00896452 loss)
I0403 09:54:04.475450  3803 sgd_solver.cpp:106] Iteration 5082, lr = 0.0005
I0403 09:54:19.707846  3803 solver.cpp:228] Iteration 5103, loss = 0.0466455
I0403 09:54:19.708156  3803 solver.cpp:244]     Train net output #0: loss = 0.0466455 (* 1 = 0.0466455 loss)
I0403 09:54:19.907763  3803 sgd_solver.cpp:106] Iteration 5103, lr = 0.0005
I0403 09:54:35.308497  3803 solver.cpp:228] Iteration 5124, loss = 0.00670294
I0403 09:54:35.308611  3803 solver.cpp:244]     Train net output #0: loss = 0.00670292 (* 1 = 0.00670292 loss)
I0403 09:54:35.495018  3803 sgd_solver.cpp:106] Iteration 5124, lr = 0.0005
I0403 09:54:50.857141  3803 solver.cpp:228] Iteration 5145, loss = 0.0527984
I0403 09:54:50.857445  3803 solver.cpp:244]     Train net output #0: loss = 0.0527984 (* 1 = 0.0527984 loss)
I0403 09:54:51.042217  3803 sgd_solver.cpp:106] Iteration 5145, lr = 0.0005
I0403 09:55:06.435632  3803 solver.cpp:228] Iteration 5166, loss = 0.00898911
I0403 09:55:06.435741  3803 solver.cpp:244]     Train net output #0: loss = 0.0089891 (* 1 = 0.0089891 loss)
I0403 09:55:06.634189  3803 sgd_solver.cpp:106] Iteration 5166, lr = 0.0005
I0403 09:55:22.050494  3803 solver.cpp:228] Iteration 5187, loss = 0.00812954
I0403 09:55:22.050818  3803 solver.cpp:244]     Train net output #0: loss = 0.00812953 (* 1 = 0.00812953 loss)
I0403 09:55:22.298694  3803 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 09:55:37.579860  3803 solver.cpp:228] Iteration 5208, loss = 0.00285859
I0403 09:55:37.579960  3803 solver.cpp:244]     Train net output #0: loss = 0.00285857 (* 1 = 0.00285857 loss)
I0403 09:55:37.732041  3803 sgd_solver.cpp:106] Iteration 5208, lr = 0.0005
I0403 09:55:45.913130  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_5220.caffemodel
I0403 09:55:48.664929  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_5220.solverstate
I0403 09:55:50.577229  3803 solver.cpp:337] Iteration 5220, Testing net (#0)
I0403 09:56:14.980911  3803 solver.cpp:404]     Test net output #0: accuracy = 0.968598
I0403 09:56:14.981246  3803 solver.cpp:404]     Test net output #1: loss = 0.109911 (* 1 = 0.109911 loss)
I0403 09:56:22.173964  3803 solver.cpp:228] Iteration 5229, loss = 0.0265137
I0403 09:56:22.174080  3803 solver.cpp:244]     Train net output #0: loss = 0.0265136 (* 1 = 0.0265136 loss)
I0403 09:56:22.402914  3803 sgd_solver.cpp:106] Iteration 5229, lr = 0.0005
I0403 09:56:37.595724  3803 solver.cpp:228] Iteration 5250, loss = 0.0369319
I0403 09:56:37.595839  3803 solver.cpp:244]     Train net output #0: loss = 0.0369319 (* 1 = 0.0369319 loss)
I0403 09:56:37.779682  3803 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0403 09:56:53.083304  3803 solver.cpp:228] Iteration 5271, loss = 0.0953689
I0403 09:56:53.083629  3803 solver.cpp:244]     Train net output #0: loss = 0.0953689 (* 1 = 0.0953689 loss)
I0403 09:56:53.272357  3803 sgd_solver.cpp:106] Iteration 5271, lr = 0.0005
I0403 09:57:08.523910  3803 solver.cpp:228] Iteration 5292, loss = 0.0167775
I0403 09:57:08.524008  3803 solver.cpp:244]     Train net output #0: loss = 0.0167775 (* 1 = 0.0167775 loss)
I0403 09:57:08.690693  3803 sgd_solver.cpp:106] Iteration 5292, lr = 0.0005
I0403 09:57:23.907624  3803 solver.cpp:228] Iteration 5313, loss = 0.0363956
I0403 09:57:23.907935  3803 solver.cpp:244]     Train net output #0: loss = 0.0363956 (* 1 = 0.0363956 loss)
I0403 09:57:24.090878  3803 sgd_solver.cpp:106] Iteration 5313, lr = 0.0005
I0403 09:57:39.317222  3803 solver.cpp:228] Iteration 5334, loss = 0.00494374
I0403 09:57:39.317329  3803 solver.cpp:244]     Train net output #0: loss = 0.00494374 (* 1 = 0.00494374 loss)
I0403 09:57:39.495187  3803 sgd_solver.cpp:106] Iteration 5334, lr = 0.0005
I0403 09:57:55.195802  3803 solver.cpp:228] Iteration 5355, loss = 0.00854864
I0403 09:57:55.201688  3803 solver.cpp:244]     Train net output #0: loss = 0.00854864 (* 1 = 0.00854864 loss)
I0403 09:57:55.353554  3803 sgd_solver.cpp:106] Iteration 5355, lr = 0.0005
I0403 09:58:10.557214  3803 solver.cpp:228] Iteration 5376, loss = 0.0211156
I0403 09:58:10.557330  3803 solver.cpp:244]     Train net output #0: loss = 0.0211156 (* 1 = 0.0211156 loss)
I0403 09:58:10.781637  3803 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 09:58:25.920722  3803 solver.cpp:228] Iteration 5397, loss = 0.0237177
I0403 09:58:25.921051  3803 solver.cpp:244]     Train net output #0: loss = 0.0237177 (* 1 = 0.0237177 loss)
I0403 09:58:26.093003  3803 sgd_solver.cpp:106] Iteration 5397, lr = 0.0005
I0403 09:58:41.620967  3803 solver.cpp:228] Iteration 5418, loss = 0.0416787
I0403 09:58:41.621068  3803 solver.cpp:244]     Train net output #0: loss = 0.0416787 (* 1 = 0.0416787 loss)
I0403 09:58:41.777359  3803 sgd_solver.cpp:106] Iteration 5418, lr = 0.0005
I0403 09:58:57.154099  3803 solver.cpp:228] Iteration 5439, loss = 0.0161181
I0403 09:58:57.154412  3803 solver.cpp:244]     Train net output #0: loss = 0.0161181 (* 1 = 0.0161181 loss)
I0403 09:58:57.398814  3803 sgd_solver.cpp:106] Iteration 5439, lr = 0.0005
I0403 09:59:12.774431  3803 solver.cpp:228] Iteration 5460, loss = 0.0310174
I0403 09:59:12.774564  3803 solver.cpp:244]     Train net output #0: loss = 0.0310174 (* 1 = 0.0310174 loss)
I0403 09:59:12.992430  3803 sgd_solver.cpp:106] Iteration 5460, lr = 0.0005
I0403 09:59:28.150235  3803 solver.cpp:228] Iteration 5481, loss = 0.0148331
I0403 09:59:28.150550  3803 solver.cpp:244]     Train net output #0: loss = 0.0148331 (* 1 = 0.0148331 loss)
I0403 09:59:28.347319  3803 sgd_solver.cpp:106] Iteration 5481, lr = 0.0005
I0403 09:59:43.779216  3803 solver.cpp:228] Iteration 5502, loss = 0.0247956
I0403 09:59:43.779321  3803 solver.cpp:244]     Train net output #0: loss = 0.0247956 (* 1 = 0.0247956 loss)
I0403 09:59:43.892590  3803 sgd_solver.cpp:106] Iteration 5502, lr = 0.0005
I0403 09:59:59.359309  3803 solver.cpp:228] Iteration 5523, loss = 0.0107222
I0403 09:59:59.359616  3803 solver.cpp:244]     Train net output #0: loss = 0.0107222 (* 1 = 0.0107222 loss)
I0403 09:59:59.463721  3803 sgd_solver.cpp:106] Iteration 5523, lr = 0.0005
I0403 10:00:15.456382  3803 solver.cpp:228] Iteration 5544, loss = 0.0296435
I0403 10:00:15.456480  3803 solver.cpp:244]     Train net output #0: loss = 0.0296435 (* 1 = 0.0296435 loss)
I0403 10:00:15.556381  3803 sgd_solver.cpp:106] Iteration 5544, lr = 0.0005
I0403 10:00:30.991914  3803 solver.cpp:228] Iteration 5565, loss = 0.0106378
I0403 10:00:30.992266  3803 solver.cpp:244]     Train net output #0: loss = 0.0106378 (* 1 = 0.0106378 loss)
I0403 10:00:31.197660  3803 sgd_solver.cpp:106] Iteration 5565, lr = 0.0005
I0403 10:00:46.486609  3803 solver.cpp:228] Iteration 5586, loss = 0.0242641
I0403 10:00:46.486716  3803 solver.cpp:244]     Train net output #0: loss = 0.0242641 (* 1 = 0.0242641 loss)
I0403 10:00:46.674407  3803 sgd_solver.cpp:106] Iteration 5586, lr = 0.0005
I0403 10:01:02.102900  3803 solver.cpp:228] Iteration 5607, loss = 0.0378505
I0403 10:01:02.103229  3803 solver.cpp:244]     Train net output #0: loss = 0.0378505 (* 1 = 0.0378505 loss)
I0403 10:01:02.339164  3803 sgd_solver.cpp:106] Iteration 5607, lr = 0.0005
I0403 10:01:17.680671  3803 solver.cpp:228] Iteration 5628, loss = 0.010766
I0403 10:01:17.680785  3803 solver.cpp:244]     Train net output #0: loss = 0.0107661 (* 1 = 0.0107661 loss)
I0403 10:01:17.864186  3803 sgd_solver.cpp:106] Iteration 5628, lr = 0.0005
I0403 10:01:33.168954  3803 solver.cpp:228] Iteration 5649, loss = 0.0164342
I0403 10:01:33.169260  3803 solver.cpp:244]     Train net output #0: loss = 0.0164342 (* 1 = 0.0164342 loss)
I0403 10:01:33.320591  3803 sgd_solver.cpp:106] Iteration 5649, lr = 0.0005
I0403 10:01:37.135810  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_5655.caffemodel
I0403 10:01:39.902071  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_5655.solverstate
I0403 10:01:41.797785  3803 solver.cpp:337] Iteration 5655, Testing net (#0)
I0403 10:02:06.209818  3803 solver.cpp:404]     Test net output #0: accuracy = 0.969065
I0403 10:02:06.210770  3803 solver.cpp:404]     Test net output #1: loss = 0.110361 (* 1 = 0.110361 loss)
I0403 10:02:17.714108  3803 solver.cpp:228] Iteration 5670, loss = 0.00999864
I0403 10:02:17.714208  3803 solver.cpp:244]     Train net output #0: loss = 0.00999864 (* 1 = 0.00999864 loss)
I0403 10:02:17.873544  3803 sgd_solver.cpp:106] Iteration 5670, lr = 0.0005
I0403 10:02:33.460075  3803 solver.cpp:228] Iteration 5691, loss = 0.00994085
I0403 10:02:33.460178  3803 solver.cpp:244]     Train net output #0: loss = 0.00994084 (* 1 = 0.00994084 loss)
I0403 10:02:33.636059  3803 sgd_solver.cpp:106] Iteration 5691, lr = 0.0005
I0403 10:02:48.938683  3803 solver.cpp:228] Iteration 5712, loss = 0.0267222
I0403 10:02:48.939002  3803 solver.cpp:244]     Train net output #0: loss = 0.0267222 (* 1 = 0.0267222 loss)
I0403 10:02:49.131852  3803 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 10:03:04.252595  3803 solver.cpp:228] Iteration 5733, loss = 0.00570875
I0403 10:03:04.252697  3803 solver.cpp:244]     Train net output #0: loss = 0.00570875 (* 1 = 0.00570875 loss)
I0403 10:03:04.426769  3803 sgd_solver.cpp:106] Iteration 5733, lr = 0.0005
I0403 10:03:19.561252  3803 solver.cpp:228] Iteration 5754, loss = 0.00619438
I0403 10:03:19.561569  3803 solver.cpp:244]     Train net output #0: loss = 0.00619437 (* 1 = 0.00619437 loss)
I0403 10:03:19.737968  3803 sgd_solver.cpp:106] Iteration 5754, lr = 0.0005
I0403 10:03:35.112812  3803 solver.cpp:228] Iteration 5775, loss = 0.0325779
I0403 10:03:35.112911  3803 solver.cpp:244]     Train net output #0: loss = 0.0325779 (* 1 = 0.0325779 loss)
I0403 10:03:35.293386  3803 sgd_solver.cpp:106] Iteration 5775, lr = 0.0005
I0403 10:03:50.687374  3803 solver.cpp:228] Iteration 5796, loss = 0.0137938
I0403 10:03:50.687700  3803 solver.cpp:244]     Train net output #0: loss = 0.0137938 (* 1 = 0.0137938 loss)
I0403 10:03:50.884363  3803 sgd_solver.cpp:106] Iteration 5796, lr = 0.0005
I0403 10:04:06.087584  3803 solver.cpp:228] Iteration 5817, loss = 0.0637233
I0403 10:04:06.087699  3803 solver.cpp:244]     Train net output #0: loss = 0.0637233 (* 1 = 0.0637233 loss)
I0403 10:04:06.296752  3803 sgd_solver.cpp:106] Iteration 5817, lr = 0.0005
I0403 10:04:21.424758  3803 solver.cpp:228] Iteration 5838, loss = 0.00222732
I0403 10:04:21.425060  3803 solver.cpp:244]     Train net output #0: loss = 0.00222732 (* 1 = 0.00222732 loss)
I0403 10:04:21.603832  3803 sgd_solver.cpp:106] Iteration 5838, lr = 0.0005
I0403 10:04:37.122275  3803 solver.cpp:228] Iteration 5859, loss = 0.0125833
I0403 10:04:37.122393  3803 solver.cpp:244]     Train net output #0: loss = 0.0125833 (* 1 = 0.0125833 loss)
I0403 10:04:37.355480  3803 sgd_solver.cpp:106] Iteration 5859, lr = 0.0005
I0403 10:04:52.646301  3803 solver.cpp:228] Iteration 5880, loss = 0.0140852
I0403 10:04:52.646618  3803 solver.cpp:244]     Train net output #0: loss = 0.0140852 (* 1 = 0.0140852 loss)
I0403 10:04:52.838441  3803 sgd_solver.cpp:106] Iteration 5880, lr = 0.0005
I0403 10:05:08.211691  3803 solver.cpp:228] Iteration 5901, loss = 0.00968078
I0403 10:05:08.211803  3803 solver.cpp:244]     Train net output #0: loss = 0.00968078 (* 1 = 0.00968078 loss)
I0403 10:05:08.411326  3803 sgd_solver.cpp:106] Iteration 5901, lr = 0.0005
I0403 10:05:23.710182  3803 solver.cpp:228] Iteration 5922, loss = 0.040265
I0403 10:05:23.710501  3803 solver.cpp:244]     Train net output #0: loss = 0.040265 (* 1 = 0.040265 loss)
I0403 10:05:23.906461  3803 sgd_solver.cpp:106] Iteration 5922, lr = 0.0005
I0403 10:05:38.892114  3803 solver.cpp:228] Iteration 5943, loss = 0.00609719
I0403 10:05:38.892222  3803 solver.cpp:244]     Train net output #0: loss = 0.00609718 (* 1 = 0.00609718 loss)
I0403 10:05:39.083230  3803 sgd_solver.cpp:106] Iteration 5943, lr = 0.0005
I0403 10:05:54.383715  3803 solver.cpp:228] Iteration 5964, loss = 0.0441638
I0403 10:05:54.383992  3803 solver.cpp:244]     Train net output #0: loss = 0.0441638 (* 1 = 0.0441638 loss)
I0403 10:05:54.539705  3803 sgd_solver.cpp:106] Iteration 5964, lr = 0.0005
I0403 10:06:10.013974  3803 solver.cpp:228] Iteration 5985, loss = 0.0129547
I0403 10:06:10.014056  3803 solver.cpp:244]     Train net output #0: loss = 0.0129547 (* 1 = 0.0129547 loss)
I0403 10:06:10.185015  3803 sgd_solver.cpp:106] Iteration 5985, lr = 0.0005
I0403 10:06:25.465522  3803 solver.cpp:228] Iteration 6006, loss = 0.00510477
I0403 10:06:25.465844  3803 solver.cpp:244]     Train net output #0: loss = 0.00510477 (* 1 = 0.00510477 loss)
I0403 10:06:25.658304  3803 sgd_solver.cpp:106] Iteration 6006, lr = 0.0005
I0403 10:06:40.895788  3803 solver.cpp:228] Iteration 6027, loss = 0.0167141
I0403 10:06:40.895889  3803 solver.cpp:244]     Train net output #0: loss = 0.0167141 (* 1 = 0.0167141 loss)
I0403 10:06:41.072747  3803 sgd_solver.cpp:106] Iteration 6027, lr = 0.0005
I0403 10:06:56.358139  3803 solver.cpp:228] Iteration 6048, loss = 0.00147661
I0403 10:06:56.358453  3803 solver.cpp:244]     Train net output #0: loss = 0.00147661 (* 1 = 0.00147661 loss)
I0403 10:06:56.548388  3803 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 10:07:11.707378  3803 solver.cpp:228] Iteration 6069, loss = 0.00809223
I0403 10:07:11.707491  3803 solver.cpp:244]     Train net output #0: loss = 0.00809222 (* 1 = 0.00809222 loss)
I0403 10:07:11.901717  3803 sgd_solver.cpp:106] Iteration 6069, lr = 0.0005
I0403 10:07:26.520450  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_6090.caffemodel
I0403 10:07:29.209813  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_6090.solverstate
I0403 10:07:31.032496  3803 solver.cpp:337] Iteration 6090, Testing net (#0)
I0403 10:07:55.438526  3803 solver.cpp:404]     Test net output #0: accuracy = 0.969252
I0403 10:07:55.438647  3803 solver.cpp:404]     Test net output #1: loss = 0.10597 (* 1 = 0.10597 loss)
I0403 10:07:55.961485  3803 solver.cpp:228] Iteration 6090, loss = 0.054047
I0403 10:07:55.961582  3803 solver.cpp:244]     Train net output #0: loss = 0.054047 (* 1 = 0.054047 loss)
I0403 10:07:56.137425  3803 sgd_solver.cpp:106] Iteration 6090, lr = 0.0005
I0403 10:08:11.403033  3803 solver.cpp:228] Iteration 6111, loss = 0.00310715
I0403 10:08:11.403352  3803 solver.cpp:244]     Train net output #0: loss = 0.00310714 (* 1 = 0.00310714 loss)
I0403 10:08:11.580420  3803 sgd_solver.cpp:106] Iteration 6111, lr = 0.0005
I0403 10:08:26.849843  3803 solver.cpp:228] Iteration 6132, loss = 0.00802488
I0403 10:08:26.849942  3803 solver.cpp:244]     Train net output #0: loss = 0.00802488 (* 1 = 0.00802488 loss)
I0403 10:08:27.001454  3803 sgd_solver.cpp:106] Iteration 6132, lr = 0.0005
I0403 10:08:42.404265  3803 solver.cpp:228] Iteration 6153, loss = 0.000272676
I0403 10:08:42.404597  3803 solver.cpp:244]     Train net output #0: loss = 0.00027268 (* 1 = 0.00027268 loss)
I0403 10:08:42.592316  3803 sgd_solver.cpp:106] Iteration 6153, lr = 0.0005
I0403 10:08:57.808886  3803 solver.cpp:228] Iteration 6174, loss = 0.00724691
I0403 10:08:57.809000  3803 solver.cpp:244]     Train net output #0: loss = 0.00724691 (* 1 = 0.00724691 loss)
I0403 10:08:58.007565  3803 sgd_solver.cpp:106] Iteration 6174, lr = 0.0005
I0403 10:09:13.377118  3803 solver.cpp:228] Iteration 6195, loss = 0.0188142
I0403 10:09:13.377442  3803 solver.cpp:244]     Train net output #0: loss = 0.0188142 (* 1 = 0.0188142 loss)
I0403 10:09:13.592950  3803 sgd_solver.cpp:106] Iteration 6195, lr = 0.0005
I0403 10:09:28.967795  3803 solver.cpp:228] Iteration 6216, loss = 0.00364549
I0403 10:09:28.967895  3803 solver.cpp:244]     Train net output #0: loss = 0.0036455 (* 1 = 0.0036455 loss)
I0403 10:09:29.146064  3803 sgd_solver.cpp:106] Iteration 6216, lr = 0.0005
I0403 10:09:44.348415  3803 solver.cpp:228] Iteration 6237, loss = 0.0161786
I0403 10:09:44.348711  3803 solver.cpp:244]     Train net output #0: loss = 0.0161786 (* 1 = 0.0161786 loss)
I0403 10:09:44.527905  3803 sgd_solver.cpp:106] Iteration 6237, lr = 0.0005
I0403 10:09:59.801054  3803 solver.cpp:228] Iteration 6258, loss = 0.00764926
I0403 10:09:59.801164  3803 solver.cpp:244]     Train net output #0: loss = 0.00764926 (* 1 = 0.00764926 loss)
I0403 10:09:59.976922  3803 sgd_solver.cpp:106] Iteration 6258, lr = 0.0005
I0403 10:10:15.255537  3803 solver.cpp:228] Iteration 6279, loss = 0.0431356
I0403 10:10:15.255834  3803 solver.cpp:244]     Train net output #0: loss = 0.0431356 (* 1 = 0.0431356 loss)
I0403 10:10:15.428748  3803 sgd_solver.cpp:106] Iteration 6279, lr = 0.0005
I0403 10:10:30.799345  3803 solver.cpp:228] Iteration 6300, loss = 0.0194726
I0403 10:10:30.799448  3803 solver.cpp:244]     Train net output #0: loss = 0.0194726 (* 1 = 0.0194726 loss)
I0403 10:10:30.936378  3803 sgd_solver.cpp:106] Iteration 6300, lr = 0.0005
I0403 10:10:46.124905  3803 solver.cpp:228] Iteration 6321, loss = 0.0260993
I0403 10:10:46.125206  3803 solver.cpp:244]     Train net output #0: loss = 0.0260993 (* 1 = 0.0260993 loss)
I0403 10:10:46.290525  3803 sgd_solver.cpp:106] Iteration 6321, lr = 0.0005
I0403 10:11:01.615569  3803 solver.cpp:228] Iteration 6342, loss = 0.0223403
I0403 10:11:01.634217  3803 solver.cpp:244]     Train net output #0: loss = 0.0223403 (* 1 = 0.0223403 loss)
I0403 10:11:01.809016  3803 sgd_solver.cpp:106] Iteration 6342, lr = 0.0005
I0403 10:11:17.243165  3803 solver.cpp:228] Iteration 6363, loss = 0.0372738
I0403 10:11:17.243412  3803 solver.cpp:244]     Train net output #0: loss = 0.0372738 (* 1 = 0.0372738 loss)
I0403 10:11:17.378674  3803 sgd_solver.cpp:106] Iteration 6363, lr = 0.0005
I0403 10:11:32.845943  3803 solver.cpp:228] Iteration 6384, loss = 0.00324077
I0403 10:11:32.846060  3803 solver.cpp:244]     Train net output #0: loss = 0.00324078 (* 1 = 0.00324078 loss)
I0403 10:11:33.070282  3803 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 10:11:48.549087  3803 solver.cpp:228] Iteration 6405, loss = 0.0296656
I0403 10:11:48.549424  3803 solver.cpp:244]     Train net output #0: loss = 0.0296657 (* 1 = 0.0296657 loss)
I0403 10:11:48.700922  3803 sgd_solver.cpp:106] Iteration 6405, lr = 0.0005
I0403 10:12:04.149230  3803 solver.cpp:228] Iteration 6426, loss = 0.0218773
I0403 10:12:04.149348  3803 solver.cpp:244]     Train net output #0: loss = 0.0218773 (* 1 = 0.0218773 loss)
I0403 10:12:04.325968  3803 sgd_solver.cpp:106] Iteration 6426, lr = 0.0005
I0403 10:12:19.541910  3803 solver.cpp:228] Iteration 6447, loss = 0.0078234
I0403 10:12:19.542224  3803 solver.cpp:244]     Train net output #0: loss = 0.0078234 (* 1 = 0.0078234 loss)
I0403 10:12:19.695716  3803 sgd_solver.cpp:106] Iteration 6447, lr = 0.0005
I0403 10:12:34.725641  3803 solver.cpp:228] Iteration 6468, loss = 0.00358757
I0403 10:12:34.725741  3803 solver.cpp:244]     Train net output #0: loss = 0.00358758 (* 1 = 0.00358758 loss)
I0403 10:12:34.900995  3803 sgd_solver.cpp:106] Iteration 6468, lr = 0.0005
I0403 10:12:50.080947  3803 solver.cpp:228] Iteration 6489, loss = 0.00286317
I0403 10:12:50.081269  3803 solver.cpp:244]     Train net output #0: loss = 0.00286319 (* 1 = 0.00286319 loss)
I0403 10:12:50.282757  3803 sgd_solver.cpp:106] Iteration 6489, lr = 0.0005
I0403 10:13:05.521148  3803 solver.cpp:228] Iteration 6510, loss = 0.0688327
I0403 10:13:05.521246  3803 solver.cpp:244]     Train net output #0: loss = 0.0688327 (* 1 = 0.0688327 loss)
I0403 10:13:05.682626  3803 sgd_solver.cpp:106] Iteration 6510, lr = 0.0005
I0403 10:13:16.087565  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_6525.caffemodel
I0403 10:13:18.845125  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_6525.solverstate
I0403 10:13:20.720923  3803 solver.cpp:337] Iteration 6525, Testing net (#0)
I0403 10:13:45.142376  3803 solver.cpp:404]     Test net output #0: accuracy = 0.969907
I0403 10:13:45.142487  3803 solver.cpp:404]     Test net output #1: loss = 0.109743 (* 1 = 0.109743 loss)
I0403 10:13:50.184794  3803 solver.cpp:228] Iteration 6531, loss = 0.0255002
I0403 10:13:50.184906  3803 solver.cpp:244]     Train net output #0: loss = 0.0255002 (* 1 = 0.0255002 loss)
I0403 10:13:50.368559  3803 sgd_solver.cpp:106] Iteration 6531, lr = 0.0005
I0403 10:14:05.706679  3803 solver.cpp:228] Iteration 6552, loss = 0.00465521
I0403 10:14:05.706979  3803 solver.cpp:244]     Train net output #0: loss = 0.00465523 (* 1 = 0.00465523 loss)
I0403 10:14:05.858490  3803 sgd_solver.cpp:106] Iteration 6552, lr = 0.0005
I0403 10:14:21.586068  3803 solver.cpp:228] Iteration 6573, loss = 0.0173618
I0403 10:14:21.586174  3803 solver.cpp:244]     Train net output #0: loss = 0.0173618 (* 1 = 0.0173618 loss)
I0403 10:14:21.756204  3803 sgd_solver.cpp:106] Iteration 6573, lr = 0.0005
I0403 10:14:37.059602  3803 solver.cpp:228] Iteration 6594, loss = 0.0160785
I0403 10:14:37.059841  3803 solver.cpp:244]     Train net output #0: loss = 0.0160785 (* 1 = 0.0160785 loss)
I0403 10:14:37.236768  3803 sgd_solver.cpp:106] Iteration 6594, lr = 0.0005
I0403 10:14:52.456485  3803 solver.cpp:228] Iteration 6615, loss = 0.011525
I0403 10:14:52.456591  3803 solver.cpp:244]     Train net output #0: loss = 0.0115251 (* 1 = 0.0115251 loss)
I0403 10:14:52.611708  3803 sgd_solver.cpp:106] Iteration 6615, lr = 0.0005
I0403 10:15:07.695207  3803 solver.cpp:228] Iteration 6636, loss = 0.0164082
I0403 10:15:07.695528  3803 solver.cpp:244]     Train net output #0: loss = 0.0164082 (* 1 = 0.0164082 loss)
I0403 10:15:07.873751  3803 sgd_solver.cpp:106] Iteration 6636, lr = 0.0005
I0403 10:15:23.181808  3803 solver.cpp:228] Iteration 6657, loss = 0.0074504
I0403 10:15:23.181924  3803 solver.cpp:244]     Train net output #0: loss = 0.00745041 (* 1 = 0.00745041 loss)
I0403 10:15:23.377363  3803 sgd_solver.cpp:106] Iteration 6657, lr = 0.0005
I0403 10:15:38.626207  3803 solver.cpp:228] Iteration 6678, loss = 0.0061961
I0403 10:15:38.626544  3803 solver.cpp:244]     Train net output #0: loss = 0.00619611 (* 1 = 0.00619611 loss)
I0403 10:15:38.805987  3803 sgd_solver.cpp:106] Iteration 6678, lr = 0.0005
I0403 10:15:53.865576  3803 solver.cpp:228] Iteration 6699, loss = 0.00726316
I0403 10:15:53.865689  3803 solver.cpp:244]     Train net output #0: loss = 0.00726317 (* 1 = 0.00726317 loss)
I0403 10:15:54.065613  3803 sgd_solver.cpp:106] Iteration 6699, lr = 0.0005
I0403 10:16:08.942966  3803 solver.cpp:228] Iteration 6720, loss = 0.00208974
I0403 10:16:08.943289  3803 solver.cpp:244]     Train net output #0: loss = 0.00208974 (* 1 = 0.00208974 loss)
I0403 10:16:09.136356  3803 sgd_solver.cpp:106] Iteration 6720, lr = 0.0005
I0403 10:16:24.418521  3803 solver.cpp:228] Iteration 6741, loss = 0.0400991
I0403 10:16:24.418634  3803 solver.cpp:244]     Train net output #0: loss = 0.0400991 (* 1 = 0.0400991 loss)
I0403 10:16:24.602124  3803 sgd_solver.cpp:106] Iteration 6741, lr = 0.0005
I0403 10:16:40.026062  3803 solver.cpp:228] Iteration 6762, loss = 0.00931984
I0403 10:16:40.026365  3803 solver.cpp:244]     Train net output #0: loss = 0.00931983 (* 1 = 0.00931983 loss)
I0403 10:16:40.204205  3803 sgd_solver.cpp:106] Iteration 6762, lr = 0.0005
I0403 10:16:55.246446  3803 solver.cpp:228] Iteration 6783, loss = 0.00264965
I0403 10:16:55.246562  3803 solver.cpp:244]     Train net output #0: loss = 0.00264964 (* 1 = 0.00264964 loss)
I0403 10:16:55.452265  3803 sgd_solver.cpp:106] Iteration 6783, lr = 0.0005
I0403 10:17:10.819641  3803 solver.cpp:228] Iteration 6804, loss = 0.0383985
I0403 10:17:10.819916  3803 solver.cpp:244]     Train net output #0: loss = 0.0383985 (* 1 = 0.0383985 loss)
I0403 10:17:11.048400  3803 sgd_solver.cpp:106] Iteration 6804, lr = 0.0005
I0403 10:17:26.480615  3803 solver.cpp:228] Iteration 6825, loss = 0.0254965
I0403 10:17:26.480717  3803 solver.cpp:244]     Train net output #0: loss = 0.0254965 (* 1 = 0.0254965 loss)
I0403 10:17:26.627300  3803 sgd_solver.cpp:106] Iteration 6825, lr = 0.0005
I0403 10:17:41.857800  3803 solver.cpp:228] Iteration 6846, loss = 0.00579173
I0403 10:17:41.858101  3803 solver.cpp:244]     Train net output #0: loss = 0.00579173 (* 1 = 0.00579173 loss)
I0403 10:17:42.030731  3803 sgd_solver.cpp:106] Iteration 6846, lr = 0.0005
I0403 10:17:57.627087  3803 solver.cpp:228] Iteration 6867, loss = 0.00168652
I0403 10:17:57.627197  3803 solver.cpp:244]     Train net output #0: loss = 0.00168651 (* 1 = 0.00168651 loss)
I0403 10:17:57.826333  3803 sgd_solver.cpp:106] Iteration 6867, lr = 0.0005
I0403 10:18:13.168711  3803 solver.cpp:228] Iteration 6888, loss = 0.0421315
I0403 10:18:13.169013  3803 solver.cpp:244]     Train net output #0: loss = 0.0421315 (* 1 = 0.0421315 loss)
I0403 10:18:13.346516  3803 sgd_solver.cpp:106] Iteration 6888, lr = 0.0005
I0403 10:18:28.570523  3803 solver.cpp:228] Iteration 6909, loss = 0.00944841
I0403 10:18:28.570642  3803 solver.cpp:244]     Train net output #0: loss = 0.0094484 (* 1 = 0.0094484 loss)
I0403 10:18:28.753902  3803 sgd_solver.cpp:106] Iteration 6909, lr = 0.0005
I0403 10:18:44.176872  3803 solver.cpp:228] Iteration 6930, loss = 0.0331842
I0403 10:18:44.177175  3803 solver.cpp:244]     Train net output #0: loss = 0.0331842 (* 1 = 0.0331842 loss)
I0403 10:18:44.340456  3803 sgd_solver.cpp:106] Iteration 6930, lr = 0.0005
I0403 10:18:59.655689  3803 solver.cpp:228] Iteration 6951, loss = 0.0124598
I0403 10:18:59.655791  3803 solver.cpp:244]     Train net output #0: loss = 0.0124598 (* 1 = 0.0124598 loss)
I0403 10:18:59.835469  3803 sgd_solver.cpp:106] Iteration 6951, lr = 0.0005
I0403 10:19:05.676753  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_6960.caffemodel
I0403 10:19:08.377883  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_6960.solverstate
I0403 10:19:10.278439  3803 solver.cpp:337] Iteration 6960, Testing net (#0)
I0403 10:19:34.692821  3803 solver.cpp:404]     Test net output #0: accuracy = 0.97
I0403 10:19:34.693162  3803 solver.cpp:404]     Test net output #1: loss = 0.10893 (* 1 = 0.10893 loss)
I0403 10:19:44.051851  3803 solver.cpp:228] Iteration 6972, loss = 0.0134567
I0403 10:19:44.051951  3803 solver.cpp:244]     Train net output #0: loss = 0.0134567 (* 1 = 0.0134567 loss)
I0403 10:19:44.214617  3803 sgd_solver.cpp:106] Iteration 6972, lr = 0.0005
I0403 10:19:59.575733  3803 solver.cpp:228] Iteration 6993, loss = 0.0089189
I0403 10:19:59.575847  3803 solver.cpp:244]     Train net output #0: loss = 0.00891889 (* 1 = 0.00891889 loss)
I0403 10:19:59.818778  3803 sgd_solver.cpp:106] Iteration 6993, lr = 0.0005
I0403 10:20:14.973675  3803 solver.cpp:228] Iteration 7014, loss = 0.00860597
I0403 10:20:14.973959  3803 solver.cpp:244]     Train net output #0: loss = 0.00860596 (* 1 = 0.00860596 loss)
I0403 10:20:15.143133  3803 sgd_solver.cpp:106] Iteration 7014, lr = 0.0005
I0403 10:20:30.425190  3803 solver.cpp:228] Iteration 7035, loss = 0.0385624
I0403 10:20:30.425307  3803 solver.cpp:244]     Train net output #0: loss = 0.0385623 (* 1 = 0.0385623 loss)
I0403 10:20:30.631537  3803 sgd_solver.cpp:106] Iteration 7035, lr = 0.0005
I0403 10:20:45.713840  3803 solver.cpp:228] Iteration 7056, loss = 0.00990128
I0403 10:20:45.714154  3803 solver.cpp:244]     Train net output #0: loss = 0.00990127 (* 1 = 0.00990127 loss)
I0403 10:20:45.907954  3803 sgd_solver.cpp:106] Iteration 7056, lr = 0.0005
I0403 10:21:01.075153  3803 solver.cpp:228] Iteration 7077, loss = 0.00874358
I0403 10:21:01.075270  3803 solver.cpp:244]     Train net output #0: loss = 0.00874358 (* 1 = 0.00874358 loss)
I0403 10:21:01.328706  3803 sgd_solver.cpp:106] Iteration 7077, lr = 0.0005
I0403 10:21:16.638319  3803 solver.cpp:228] Iteration 7098, loss = 0.00352435
I0403 10:21:16.638617  3803 solver.cpp:244]     Train net output #0: loss = 0.00352434 (* 1 = 0.00352434 loss)
I0403 10:21:16.858871  3803 sgd_solver.cpp:106] Iteration 7098, lr = 0.0005
I0403 10:21:31.917448  3803 solver.cpp:228] Iteration 7119, loss = 0.00819964
I0403 10:21:31.917562  3803 solver.cpp:244]     Train net output #0: loss = 0.00819963 (* 1 = 0.00819963 loss)
I0403 10:21:32.103327  3803 sgd_solver.cpp:106] Iteration 7119, lr = 0.0005
I0403 10:21:47.179358  3803 solver.cpp:228] Iteration 7140, loss = 0.00336388
I0403 10:21:47.179672  3803 solver.cpp:244]     Train net output #0: loss = 0.00336387 (* 1 = 0.00336387 loss)
I0403 10:21:47.350879  3803 sgd_solver.cpp:106] Iteration 7140, lr = 0.0005
I0403 10:22:02.493263  3803 solver.cpp:228] Iteration 7161, loss = 0.0178959
I0403 10:22:02.493381  3803 solver.cpp:244]     Train net output #0: loss = 0.0178959 (* 1 = 0.0178959 loss)
I0403 10:22:02.688217  3803 sgd_solver.cpp:106] Iteration 7161, lr = 0.0005
I0403 10:22:17.921834  3803 solver.cpp:228] Iteration 7182, loss = 0.0283222
I0403 10:22:17.922137  3803 solver.cpp:244]     Train net output #0: loss = 0.0283222 (* 1 = 0.0283222 loss)
I0403 10:22:18.094630  3803 sgd_solver.cpp:106] Iteration 7182, lr = 0.0005
I0403 10:22:33.193696  3803 solver.cpp:228] Iteration 7203, loss = 0.00450183
I0403 10:22:33.193800  3803 solver.cpp:244]     Train net output #0: loss = 0.00450183 (* 1 = 0.00450183 loss)
I0403 10:22:33.365567  3803 sgd_solver.cpp:106] Iteration 7203, lr = 0.0005
I0403 10:22:48.502833  3803 solver.cpp:228] Iteration 7224, loss = 0.00654164
I0403 10:22:48.503152  3803 solver.cpp:244]     Train net output #0: loss = 0.00654164 (* 1 = 0.00654164 loss)
I0403 10:22:48.691944  3803 sgd_solver.cpp:106] Iteration 7224, lr = 0.0005
I0403 10:23:03.872663  3803 solver.cpp:228] Iteration 7245, loss = 0.00285959
I0403 10:23:03.872763  3803 solver.cpp:244]     Train net output #0: loss = 0.00285959 (* 1 = 0.00285959 loss)
I0403 10:23:04.045521  3803 sgd_solver.cpp:106] Iteration 7245, lr = 0.0005
I0403 10:23:18.953519  3803 solver.cpp:228] Iteration 7266, loss = 0.015088
I0403 10:23:18.953857  3803 solver.cpp:244]     Train net output #0: loss = 0.015088 (* 1 = 0.015088 loss)
I0403 10:23:19.151056  3803 sgd_solver.cpp:106] Iteration 7266, lr = 0.0005
I0403 10:23:34.406108  3803 solver.cpp:228] Iteration 7287, loss = 0.0189352
I0403 10:23:34.406224  3803 solver.cpp:244]     Train net output #0: loss = 0.0189352 (* 1 = 0.0189352 loss)
I0403 10:23:34.605690  3803 sgd_solver.cpp:106] Iteration 7287, lr = 0.0005
I0403 10:23:50.161258  3803 solver.cpp:228] Iteration 7308, loss = 0.0246893
I0403 10:23:50.161602  3803 solver.cpp:244]     Train net output #0: loss = 0.0246893 (* 1 = 0.0246893 loss)
I0403 10:23:50.324385  3803 sgd_solver.cpp:106] Iteration 7308, lr = 0.0005
I0403 10:24:05.764438  3803 solver.cpp:228] Iteration 7329, loss = 0.00308475
I0403 10:24:05.764536  3803 solver.cpp:244]     Train net output #0: loss = 0.00308475 (* 1 = 0.00308475 loss)
I0403 10:24:05.915899  3803 sgd_solver.cpp:106] Iteration 7329, lr = 0.0005
I0403 10:24:21.290984  3803 solver.cpp:228] Iteration 7350, loss = 0.00653996
I0403 10:24:21.291317  3803 solver.cpp:244]     Train net output #0: loss = 0.00653995 (* 1 = 0.00653995 loss)
I0403 10:24:21.508380  3803 sgd_solver.cpp:106] Iteration 7350, lr = 0.0005
I0403 10:24:36.702558  3803 solver.cpp:228] Iteration 7371, loss = 0.00120299
I0403 10:24:36.702673  3803 solver.cpp:244]     Train net output #0: loss = 0.00120297 (* 1 = 0.00120297 loss)
I0403 10:24:36.864603  3803 sgd_solver.cpp:106] Iteration 7371, lr = 0.0005
I0403 10:24:52.614909  3803 solver.cpp:228] Iteration 7392, loss = 0.0468405
I0403 10:24:52.615203  3803 solver.cpp:244]     Train net output #0: loss = 0.0468405 (* 1 = 0.0468405 loss)
I0403 10:24:52.794019  3803 sgd_solver.cpp:106] Iteration 7392, lr = 0.0005
I0403 10:24:54.328344  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_7395.caffemodel
I0403 10:24:57.010221  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_7395.solverstate
I0403 10:24:58.836702  3803 solver.cpp:337] Iteration 7395, Testing net (#0)
I0403 10:25:23.251935  3803 solver.cpp:404]     Test net output #0: accuracy = 0.970561
I0403 10:25:23.252295  3803 solver.cpp:404]     Test net output #1: loss = 0.110154 (* 1 = 0.110154 loss)
I0403 10:25:37.092424  3803 solver.cpp:228] Iteration 7413, loss = 0.017015
I0403 10:25:37.092536  3803 solver.cpp:244]     Train net output #0: loss = 0.017015 (* 1 = 0.017015 loss)
I0403 10:25:37.285291  3803 sgd_solver.cpp:106] Iteration 7413, lr = 0.0005
I0403 10:25:52.546852  3803 solver.cpp:228] Iteration 7434, loss = 0.00868186
I0403 10:25:52.546969  3803 solver.cpp:244]     Train net output #0: loss = 0.00868184 (* 1 = 0.00868184 loss)
I0403 10:25:52.754827  3803 sgd_solver.cpp:106] Iteration 7434, lr = 0.0005
I0403 10:26:08.121266  3803 solver.cpp:228] Iteration 7455, loss = 0.0385095
I0403 10:26:08.121569  3803 solver.cpp:244]     Train net output #0: loss = 0.0385095 (* 1 = 0.0385095 loss)
I0403 10:26:08.299870  3803 sgd_solver.cpp:106] Iteration 7455, lr = 0.0005
I0403 10:26:23.582617  3803 solver.cpp:228] Iteration 7476, loss = 0.00383831
I0403 10:26:23.582718  3803 solver.cpp:244]     Train net output #0: loss = 0.0038383 (* 1 = 0.0038383 loss)
I0403 10:26:23.764484  3803 sgd_solver.cpp:106] Iteration 7476, lr = 0.0005
I0403 10:26:39.060535  3803 solver.cpp:228] Iteration 7497, loss = 0.0212813
I0403 10:26:39.060832  3803 solver.cpp:244]     Train net output #0: loss = 0.0212813 (* 1 = 0.0212813 loss)
I0403 10:26:39.169664  3803 sgd_solver.cpp:106] Iteration 7497, lr = 0.0005
I0403 10:26:54.636159  3803 solver.cpp:228] Iteration 7518, loss = 0.00299043
I0403 10:26:54.636265  3803 solver.cpp:244]     Train net output #0: loss = 0.00299043 (* 1 = 0.00299043 loss)
I0403 10:26:54.805361  3803 sgd_solver.cpp:106] Iteration 7518, lr = 0.0005
I0403 10:27:10.237692  3803 solver.cpp:228] Iteration 7539, loss = 0.0379433
I0403 10:27:10.237999  3803 solver.cpp:244]     Train net output #0: loss = 0.0379433 (* 1 = 0.0379433 loss)
I0403 10:27:10.431712  3803 sgd_solver.cpp:106] Iteration 7539, lr = 0.0005
I0403 10:27:25.792954  3803 solver.cpp:228] Iteration 7560, loss = 0.00124897
I0403 10:27:25.793056  3803 solver.cpp:244]     Train net output #0: loss = 0.00124897 (* 1 = 0.00124897 loss)
I0403 10:27:25.969734  3803 sgd_solver.cpp:106] Iteration 7560, lr = 0.0005
I0403 10:27:41.271684  3803 solver.cpp:228] Iteration 7581, loss = 0.00288423
I0403 10:27:41.272027  3803 solver.cpp:244]     Train net output #0: loss = 0.00288423 (* 1 = 0.00288423 loss)
I0403 10:27:41.408255  3803 sgd_solver.cpp:106] Iteration 7581, lr = 0.0005
I0403 10:27:57.018251  3803 solver.cpp:228] Iteration 7602, loss = 0.0126741
I0403 10:27:57.018371  3803 solver.cpp:244]     Train net output #0: loss = 0.0126741 (* 1 = 0.0126741 loss)
I0403 10:27:57.191475  3803 sgd_solver.cpp:106] Iteration 7602, lr = 0.0005
I0403 10:28:12.387032  3803 solver.cpp:228] Iteration 7623, loss = 0.00456379
I0403 10:28:12.387346  3803 solver.cpp:244]     Train net output #0: loss = 0.00456379 (* 1 = 0.00456379 loss)
I0403 10:28:12.558059  3803 sgd_solver.cpp:106] Iteration 7623, lr = 0.0005
I0403 10:28:27.838394  3803 solver.cpp:228] Iteration 7644, loss = 0.142157
I0403 10:28:27.838496  3803 solver.cpp:244]     Train net output #0: loss = 0.142157 (* 1 = 0.142157 loss)
I0403 10:28:28.002992  3803 sgd_solver.cpp:106] Iteration 7644, lr = 0.0005
I0403 10:28:43.243778  3803 solver.cpp:228] Iteration 7665, loss = 0.00302593
I0403 10:28:43.244103  3803 solver.cpp:244]     Train net output #0: loss = 0.00302593 (* 1 = 0.00302593 loss)
I0403 10:28:43.415283  3803 sgd_solver.cpp:106] Iteration 7665, lr = 0.0005
I0403 10:28:58.725335  3803 solver.cpp:228] Iteration 7686, loss = 0.00677281
I0403 10:28:58.725450  3803 solver.cpp:244]     Train net output #0: loss = 0.0067728 (* 1 = 0.0067728 loss)
I0403 10:28:58.914096  3803 sgd_solver.cpp:106] Iteration 7686, lr = 0.0005
I0403 10:29:14.428469  3803 solver.cpp:228] Iteration 7707, loss = 0.0344476
I0403 10:29:14.428800  3803 solver.cpp:244]     Train net output #0: loss = 0.0344476 (* 1 = 0.0344476 loss)
I0403 10:29:14.623782  3803 sgd_solver.cpp:106] Iteration 7707, lr = 0.0005
I0403 10:29:30.059568  3803 solver.cpp:228] Iteration 7728, loss = 0.0133884
I0403 10:29:30.059669  3803 solver.cpp:244]     Train net output #0: loss = 0.0133884 (* 1 = 0.0133884 loss)
I0403 10:29:30.238896  3803 sgd_solver.cpp:106] Iteration 7728, lr = 0.0005
I0403 10:29:45.448595  3803 solver.cpp:228] Iteration 7749, loss = 0.00614913
I0403 10:29:45.448914  3803 solver.cpp:244]     Train net output #0: loss = 0.00614912 (* 1 = 0.00614912 loss)
I0403 10:29:45.675621  3803 sgd_solver.cpp:106] Iteration 7749, lr = 0.0005
I0403 10:30:01.049144  3803 solver.cpp:228] Iteration 7770, loss = 0.0135766
I0403 10:30:01.049257  3803 solver.cpp:244]     Train net output #0: loss = 0.0135765 (* 1 = 0.0135765 loss)
I0403 10:30:01.304555  3803 sgd_solver.cpp:106] Iteration 7770, lr = 0.0005
I0403 10:30:16.644863  3803 solver.cpp:228] Iteration 7791, loss = 0.0338285
I0403 10:30:16.645151  3803 solver.cpp:244]     Train net output #0: loss = 0.0338285 (* 1 = 0.0338285 loss)
I0403 10:30:16.813726  3803 sgd_solver.cpp:106] Iteration 7791, lr = 0.0005
I0403 10:30:32.442826  3803 solver.cpp:228] Iteration 7812, loss = 0.0300549
I0403 10:30:32.442942  3803 solver.cpp:244]     Train net output #0: loss = 0.0300549 (* 1 = 0.0300549 loss)
I0403 10:30:32.635113  3803 sgd_solver.cpp:106] Iteration 7812, lr = 0.0005
I0403 10:30:45.007187  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_7830.caffemodel
I0403 10:30:47.701570  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_7830.solverstate
I0403 10:30:49.558337  3803 solver.cpp:337] Iteration 7830, Testing net (#0)
I0403 10:31:13.969344  3803 solver.cpp:404]     Test net output #0: accuracy = 0.970935
I0403 10:31:13.969452  3803 solver.cpp:404]     Test net output #1: loss = 0.109834 (* 1 = 0.109834 loss)
I0403 10:31:16.651348  3803 solver.cpp:228] Iteration 7833, loss = 0.012791
I0403 10:31:16.651448  3803 solver.cpp:244]     Train net output #0: loss = 0.012791 (* 1 = 0.012791 loss)
I0403 10:31:16.823341  3803 sgd_solver.cpp:106] Iteration 7833, lr = 0.0005
I0403 10:31:31.982100  3803 solver.cpp:228] Iteration 7854, loss = 0.0178397
I0403 10:31:31.982439  3803 solver.cpp:244]     Train net output #0: loss = 0.0178397 (* 1 = 0.0178397 loss)
I0403 10:31:32.151831  3803 sgd_solver.cpp:106] Iteration 7854, lr = 0.0005
I0403 10:31:47.264560  3803 solver.cpp:228] Iteration 7875, loss = 0.0792201
I0403 10:31:47.264660  3803 solver.cpp:244]     Train net output #0: loss = 0.0792201 (* 1 = 0.0792201 loss)
I0403 10:31:47.442077  3803 sgd_solver.cpp:106] Iteration 7875, lr = 0.0005
I0403 10:32:02.618415  3803 solver.cpp:228] Iteration 7896, loss = 0.0377383
I0403 10:32:02.618675  3803 solver.cpp:244]     Train net output #0: loss = 0.0377383 (* 1 = 0.0377383 loss)
I0403 10:32:02.783825  3803 sgd_solver.cpp:106] Iteration 7896, lr = 0.0005
I0403 10:32:17.876503  3803 solver.cpp:228] Iteration 7917, loss = 0.0309444
I0403 10:32:17.876603  3803 solver.cpp:244]     Train net output #0: loss = 0.0309444 (* 1 = 0.0309444 loss)
I0403 10:32:18.050392  3803 sgd_solver.cpp:106] Iteration 7917, lr = 0.0005
I0403 10:32:33.241461  3803 solver.cpp:228] Iteration 7938, loss = 0.0299378
I0403 10:32:33.241791  3803 solver.cpp:244]     Train net output #0: loss = 0.0299378 (* 1 = 0.0299378 loss)
I0403 10:32:33.454535  3803 sgd_solver.cpp:106] Iteration 7938, lr = 0.0005
I0403 10:32:48.742161  3803 solver.cpp:228] Iteration 7959, loss = 0.00141048
I0403 10:32:48.742265  3803 solver.cpp:244]     Train net output #0: loss = 0.00141047 (* 1 = 0.00141047 loss)
I0403 10:32:48.919562  3803 sgd_solver.cpp:106] Iteration 7959, lr = 0.0005
I0403 10:33:04.194679  3803 solver.cpp:228] Iteration 7980, loss = 0.0110683
I0403 10:33:04.199635  3803 solver.cpp:244]     Train net output #0: loss = 0.0110683 (* 1 = 0.0110683 loss)
I0403 10:33:04.448004  3803 sgd_solver.cpp:106] Iteration 7980, lr = 0.0005
I0403 10:33:19.726573  3803 solver.cpp:228] Iteration 8001, loss = 0.00943179
I0403 10:33:19.726675  3803 solver.cpp:244]     Train net output #0: loss = 0.00943177 (* 1 = 0.00943177 loss)
I0403 10:33:19.904404  3803 sgd_solver.cpp:106] Iteration 8001, lr = 0.0005
I0403 10:33:35.182003  3803 solver.cpp:228] Iteration 8022, loss = 0.00319197
I0403 10:33:35.182308  3803 solver.cpp:244]     Train net output #0: loss = 0.00319194 (* 1 = 0.00319194 loss)
I0403 10:33:35.359545  3803 sgd_solver.cpp:106] Iteration 8022, lr = 0.0005
I0403 10:33:50.580905  3803 solver.cpp:228] Iteration 8043, loss = 0.000513083
I0403 10:33:50.581007  3803 solver.cpp:244]     Train net output #0: loss = 0.000513057 (* 1 = 0.000513057 loss)
I0403 10:33:50.740728  3803 sgd_solver.cpp:106] Iteration 8043, lr = 0.0005
I0403 10:34:06.379160  3803 solver.cpp:228] Iteration 8064, loss = 0.0689448
I0403 10:34:06.379467  3803 solver.cpp:244]     Train net output #0: loss = 0.0689448 (* 1 = 0.0689448 loss)
I0403 10:34:06.478222  3803 sgd_solver.cpp:106] Iteration 8064, lr = 0.0005
I0403 10:34:22.085810  3803 solver.cpp:228] Iteration 8085, loss = 0.00736357
I0403 10:34:22.085925  3803 solver.cpp:244]     Train net output #0: loss = 0.00736354 (* 1 = 0.00736354 loss)
I0403 10:34:22.299496  3803 sgd_solver.cpp:106] Iteration 8085, lr = 0.0005
I0403 10:34:37.499388  3803 solver.cpp:228] Iteration 8106, loss = 0.00776071
I0403 10:34:37.499703  3803 solver.cpp:244]     Train net output #0: loss = 0.00776068 (* 1 = 0.00776068 loss)
I0403 10:34:37.682771  3803 sgd_solver.cpp:106] Iteration 8106, lr = 0.0005
I0403 10:34:52.974316  3803 solver.cpp:228] Iteration 8127, loss = 0.0107382
I0403 10:34:52.974431  3803 solver.cpp:244]     Train net output #0: loss = 0.0107382 (* 1 = 0.0107382 loss)
I0403 10:34:53.168687  3803 sgd_solver.cpp:106] Iteration 8127, lr = 0.0005
I0403 10:35:08.663983  3803 solver.cpp:228] Iteration 8148, loss = 0.00288499
I0403 10:35:08.664342  3803 solver.cpp:244]     Train net output #0: loss = 0.00288496 (* 1 = 0.00288496 loss)
I0403 10:35:08.867913  3803 sgd_solver.cpp:106] Iteration 8148, lr = 0.0005
I0403 10:35:24.018764  3803 solver.cpp:228] Iteration 8169, loss = 0.00999506
I0403 10:35:24.018880  3803 solver.cpp:244]     Train net output #0: loss = 0.00999504 (* 1 = 0.00999504 loss)
I0403 10:35:24.198590  3803 sgd_solver.cpp:106] Iteration 8169, lr = 0.0005
I0403 10:35:39.649330  3803 solver.cpp:228] Iteration 8190, loss = 0.0023084
I0403 10:35:39.649637  3803 solver.cpp:244]     Train net output #0: loss = 0.00230837 (* 1 = 0.00230837 loss)
I0403 10:35:39.743373  3803 sgd_solver.cpp:106] Iteration 8190, lr = 0.0005
I0403 10:35:55.459748  3803 solver.cpp:228] Iteration 8211, loss = 0.0140452
I0403 10:35:55.459859  3803 solver.cpp:244]     Train net output #0: loss = 0.0140452 (* 1 = 0.0140452 loss)
I0403 10:35:55.658138  3803 sgd_solver.cpp:106] Iteration 8211, lr = 0.0005
I0403 10:36:10.849486  3803 solver.cpp:228] Iteration 8232, loss = 0.00196727
I0403 10:36:10.849786  3803 solver.cpp:244]     Train net output #0: loss = 0.00196723 (* 1 = 0.00196723 loss)
I0403 10:36:11.002297  3803 sgd_solver.cpp:106] Iteration 8232, lr = 0.0005
I0403 10:36:26.271365  3803 solver.cpp:228] Iteration 8253, loss = 0.00645808
I0403 10:36:26.271481  3803 solver.cpp:244]     Train net output #0: loss = 0.00645803 (* 1 = 0.00645803 loss)
I0403 10:36:26.455461  3803 sgd_solver.cpp:106] Iteration 8253, lr = 0.0005
I0403 10:36:34.499485  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_8265.caffemodel
I0403 10:36:37.289270  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_8265.solverstate
I0403 10:36:39.174664  3803 solver.cpp:337] Iteration 8265, Testing net (#0)
I0403 10:37:03.590169  3803 solver.cpp:404]     Test net output #0: accuracy = 0.970468
I0403 10:37:03.590554  3803 solver.cpp:404]     Test net output #1: loss = 0.11066 (* 1 = 0.11066 loss)
I0403 10:37:10.712182  3803 solver.cpp:228] Iteration 8274, loss = 0.00323338
I0403 10:37:10.712299  3803 solver.cpp:244]     Train net output #0: loss = 0.00323334 (* 1 = 0.00323334 loss)
I0403 10:37:10.944326  3803 sgd_solver.cpp:106] Iteration 8274, lr = 0.0005
I0403 10:37:26.300890  3803 solver.cpp:228] Iteration 8295, loss = 0.00442912
I0403 10:37:26.300992  3803 solver.cpp:244]     Train net output #0: loss = 0.00442908 (* 1 = 0.00442908 loss)
I0403 10:37:26.475353  3803 sgd_solver.cpp:106] Iteration 8295, lr = 0.0005
I0403 10:37:42.372395  3803 solver.cpp:228] Iteration 8316, loss = 0.0501159
I0403 10:37:42.372704  3803 solver.cpp:244]     Train net output #0: loss = 0.0501159 (* 1 = 0.0501159 loss)
I0403 10:37:42.542606  3803 sgd_solver.cpp:106] Iteration 8316, lr = 0.0005
I0403 10:37:57.744748  3803 solver.cpp:228] Iteration 8337, loss = 0.00623663
I0403 10:37:57.744858  3803 solver.cpp:244]     Train net output #0: loss = 0.00623658 (* 1 = 0.00623658 loss)
I0403 10:37:57.948328  3803 sgd_solver.cpp:106] Iteration 8337, lr = 0.0005
I0403 10:38:13.118633  3803 solver.cpp:228] Iteration 8358, loss = 0.00814275
I0403 10:38:13.119017  3803 solver.cpp:244]     Train net output #0: loss = 0.00814271 (* 1 = 0.00814271 loss)
I0403 10:38:13.329234  3803 sgd_solver.cpp:106] Iteration 8358, lr = 0.0005
I0403 10:38:28.547776  3803 solver.cpp:228] Iteration 8379, loss = 0.0144633
I0403 10:38:28.547879  3803 solver.cpp:244]     Train net output #0: loss = 0.0144633 (* 1 = 0.0144633 loss)
I0403 10:38:28.714664  3803 sgd_solver.cpp:106] Iteration 8379, lr = 0.0005
I0403 10:38:43.974169  3803 solver.cpp:228] Iteration 8400, loss = 0.0036361
I0403 10:38:43.974449  3803 solver.cpp:244]     Train net output #0: loss = 0.00363606 (* 1 = 0.00363606 loss)
I0403 10:38:44.145372  3803 sgd_solver.cpp:106] Iteration 8400, lr = 0.0005
I0403 10:38:59.535459  3803 solver.cpp:228] Iteration 8421, loss = 0.0050045
I0403 10:38:59.535573  3803 solver.cpp:244]     Train net output #0: loss = 0.00500445 (* 1 = 0.00500445 loss)
I0403 10:38:59.731590  3803 sgd_solver.cpp:106] Iteration 8421, lr = 0.0005
I0403 10:39:15.250836  3803 solver.cpp:228] Iteration 8442, loss = 0.00462453
I0403 10:39:15.251165  3803 solver.cpp:244]     Train net output #0: loss = 0.00462448 (* 1 = 0.00462448 loss)
I0403 10:39:15.403133  3803 sgd_solver.cpp:106] Iteration 8442, lr = 0.0005
I0403 10:39:31.002035  3803 solver.cpp:228] Iteration 8463, loss = 0.0286499
I0403 10:39:31.002142  3803 solver.cpp:244]     Train net output #0: loss = 0.0286498 (* 1 = 0.0286498 loss)
I0403 10:39:31.176182  3803 sgd_solver.cpp:106] Iteration 8463, lr = 0.0005
I0403 10:39:46.569912  3803 solver.cpp:228] Iteration 8484, loss = 0.0137454
I0403 10:39:46.570163  3803 solver.cpp:244]     Train net output #0: loss = 0.0137453 (* 1 = 0.0137453 loss)
I0403 10:39:46.714813  3803 sgd_solver.cpp:106] Iteration 8484, lr = 0.0005
I0403 10:40:02.253563  3803 solver.cpp:228] Iteration 8505, loss = 0.02204
I0403 10:40:02.253667  3803 solver.cpp:244]     Train net output #0: loss = 0.0220399 (* 1 = 0.0220399 loss)
I0403 10:40:02.421155  3803 sgd_solver.cpp:106] Iteration 8505, lr = 0.0005
I0403 10:40:17.690114  3803 solver.cpp:228] Iteration 8526, loss = 0.0317406
I0403 10:40:17.690431  3803 solver.cpp:244]     Train net output #0: loss = 0.0317406 (* 1 = 0.0317406 loss)
I0403 10:40:17.873704  3803 sgd_solver.cpp:106] Iteration 8526, lr = 0.0005
I0403 10:40:33.071156  3803 solver.cpp:228] Iteration 8547, loss = 0.00708624
I0403 10:40:33.071270  3803 solver.cpp:244]     Train net output #0: loss = 0.00708619 (* 1 = 0.00708619 loss)
I0403 10:40:33.296140  3803 sgd_solver.cpp:106] Iteration 8547, lr = 0.0005
I0403 10:40:48.512068  3803 solver.cpp:228] Iteration 8568, loss = 0.00602505
I0403 10:40:48.512382  3803 solver.cpp:244]     Train net output #0: loss = 0.006025 (* 1 = 0.006025 loss)
I0403 10:40:48.736639  3803 sgd_solver.cpp:106] Iteration 8568, lr = 0.0005
I0403 10:41:04.227960  3803 solver.cpp:228] Iteration 8589, loss = 0.00276754
I0403 10:41:04.228061  3803 solver.cpp:244]     Train net output #0: loss = 0.00276749 (* 1 = 0.00276749 loss)
I0403 10:41:04.406056  3803 sgd_solver.cpp:106] Iteration 8589, lr = 0.0005
I0403 10:41:19.934684  3803 solver.cpp:228] Iteration 8610, loss = 0.00687064
I0403 10:41:19.935528  3803 solver.cpp:244]     Train net output #0: loss = 0.00687059 (* 1 = 0.00687059 loss)
I0403 10:41:20.128479  3803 sgd_solver.cpp:106] Iteration 8610, lr = 0.0005
I0403 10:41:35.410380  3803 solver.cpp:228] Iteration 8631, loss = 0.00348483
I0403 10:41:35.410480  3803 solver.cpp:244]     Train net output #0: loss = 0.00348477 (* 1 = 0.00348477 loss)
I0403 10:41:35.590149  3803 sgd_solver.cpp:106] Iteration 8631, lr = 0.0005
I0403 10:41:50.832747  3803 solver.cpp:228] Iteration 8652, loss = 0.00596122
I0403 10:41:50.833004  3803 solver.cpp:244]     Train net output #0: loss = 0.00596117 (* 1 = 0.00596117 loss)
I0403 10:41:51.003507  3803 sgd_solver.cpp:106] Iteration 8652, lr = 0.0005
I0403 10:42:06.342494  3803 solver.cpp:228] Iteration 8673, loss = 0.00454116
I0403 10:42:06.342594  3803 solver.cpp:244]     Train net output #0: loss = 0.00454111 (* 1 = 0.00454111 loss)
I0403 10:42:06.519481  3803 sgd_solver.cpp:106] Iteration 8673, lr = 0.0005
I0403 10:42:21.937043  3803 solver.cpp:228] Iteration 8694, loss = 0.00307406
I0403 10:42:21.937366  3803 solver.cpp:244]     Train net output #0: loss = 0.003074 (* 1 = 0.003074 loss)
I0403 10:42:22.145335  3803 sgd_solver.cpp:106] Iteration 8694, lr = 0.0005
I0403 10:42:25.758208  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_8700.caffemodel
I0403 10:42:28.541251  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_8700.solverstate
I0403 10:42:30.416297  3803 solver.cpp:337] Iteration 8700, Testing net (#0)
I0403 10:42:54.819546  3803 solver.cpp:404]     Test net output #0: accuracy = 0.971682
I0403 10:42:54.819926  3803 solver.cpp:404]     Test net output #1: loss = 0.111148 (* 1 = 0.111148 loss)
I0403 10:43:06.342876  3803 solver.cpp:228] Iteration 8715, loss = 0.00725294
I0403 10:43:06.342973  3803 solver.cpp:244]     Train net output #0: loss = 0.00725288 (* 1 = 0.00725288 loss)
I0403 10:43:06.493849  3803 sgd_solver.cpp:106] Iteration 8715, lr = 5e-05
I0403 10:43:21.825325  3803 solver.cpp:228] Iteration 8736, loss = 0.00734371
I0403 10:43:21.825439  3803 solver.cpp:244]     Train net output #0: loss = 0.00734364 (* 1 = 0.00734364 loss)
I0403 10:43:22.013651  3803 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 10:43:37.422641  3803 solver.cpp:228] Iteration 8757, loss = 0.00281841
I0403 10:43:37.422946  3803 solver.cpp:244]     Train net output #0: loss = 0.00281835 (* 1 = 0.00281835 loss)
I0403 10:43:37.650977  3803 sgd_solver.cpp:106] Iteration 8757, lr = 5e-05
I0403 10:43:52.999999  3803 solver.cpp:228] Iteration 8778, loss = 0.00357933
I0403 10:43:53.000103  3803 solver.cpp:244]     Train net output #0: loss = 0.00357926 (* 1 = 0.00357926 loss)
I0403 10:43:53.119801  3803 sgd_solver.cpp:106] Iteration 8778, lr = 5e-05
I0403 10:44:08.514087  3803 solver.cpp:228] Iteration 8799, loss = 0.02069
I0403 10:44:08.514401  3803 solver.cpp:244]     Train net output #0: loss = 0.0206899 (* 1 = 0.0206899 loss)
I0403 10:44:08.712731  3803 sgd_solver.cpp:106] Iteration 8799, lr = 5e-05
I0403 10:44:23.991644  3803 solver.cpp:228] Iteration 8820, loss = 0.00497842
I0403 10:44:23.991756  3803 solver.cpp:244]     Train net output #0: loss = 0.00497835 (* 1 = 0.00497835 loss)
I0403 10:44:24.189057  3803 sgd_solver.cpp:106] Iteration 8820, lr = 5e-05
I0403 10:44:39.768491  3803 solver.cpp:228] Iteration 8841, loss = 0.0344899
I0403 10:44:39.768801  3803 solver.cpp:244]     Train net output #0: loss = 0.0344899 (* 1 = 0.0344899 loss)
I0403 10:44:39.953522  3803 sgd_solver.cpp:106] Iteration 8841, lr = 5e-05
I0403 10:44:55.216091  3803 solver.cpp:228] Iteration 8862, loss = 0.0170761
I0403 10:44:55.216194  3803 solver.cpp:244]     Train net output #0: loss = 0.017076 (* 1 = 0.017076 loss)
I0403 10:44:55.359344  3803 sgd_solver.cpp:106] Iteration 8862, lr = 5e-05
I0403 10:45:10.648413  3803 solver.cpp:228] Iteration 8883, loss = 0.00863328
I0403 10:45:10.648695  3803 solver.cpp:244]     Train net output #0: loss = 0.00863321 (* 1 = 0.00863321 loss)
I0403 10:45:10.827834  3803 sgd_solver.cpp:106] Iteration 8883, lr = 5e-05
I0403 10:45:26.146361  3803 solver.cpp:228] Iteration 8904, loss = 0.00159245
I0403 10:45:26.146455  3803 solver.cpp:244]     Train net output #0: loss = 0.00159238 (* 1 = 0.00159238 loss)
I0403 10:45:26.329741  3803 sgd_solver.cpp:106] Iteration 8904, lr = 5e-05
I0403 10:45:41.595650  3803 solver.cpp:228] Iteration 8925, loss = 0.00791037
I0403 10:45:41.595990  3803 solver.cpp:244]     Train net output #0: loss = 0.00791031 (* 1 = 0.00791031 loss)
I0403 10:45:41.788117  3803 sgd_solver.cpp:106] Iteration 8925, lr = 5e-05
I0403 10:45:57.462538  3803 solver.cpp:228] Iteration 8946, loss = 0.00553154
I0403 10:45:57.462632  3803 solver.cpp:244]     Train net output #0: loss = 0.00553147 (* 1 = 0.00553147 loss)
I0403 10:45:57.610543  3803 sgd_solver.cpp:106] Iteration 8946, lr = 5e-05
I0403 10:46:13.030443  3803 solver.cpp:228] Iteration 8967, loss = 0.00450838
I0403 10:46:13.030745  3803 solver.cpp:244]     Train net output #0: loss = 0.00450832 (* 1 = 0.00450832 loss)
I0403 10:46:13.238862  3803 sgd_solver.cpp:106] Iteration 8967, lr = 5e-05
I0403 10:46:28.793222  3803 solver.cpp:228] Iteration 8988, loss = 0.00655069
I0403 10:46:28.793342  3803 solver.cpp:244]     Train net output #0: loss = 0.00655063 (* 1 = 0.00655063 loss)
I0403 10:46:29.016131  3803 sgd_solver.cpp:106] Iteration 8988, lr = 5e-05
I0403 10:46:44.202880  3803 solver.cpp:228] Iteration 9009, loss = 0.0216855
I0403 10:46:44.203225  3803 solver.cpp:244]     Train net output #0: loss = 0.0216854 (* 1 = 0.0216854 loss)
I0403 10:46:44.416075  3803 sgd_solver.cpp:106] Iteration 9009, lr = 5e-05
I0403 10:46:59.902076  3803 solver.cpp:228] Iteration 9030, loss = 0.0124992
I0403 10:46:59.902178  3803 solver.cpp:244]     Train net output #0: loss = 0.0124991 (* 1 = 0.0124991 loss)
I0403 10:47:00.080271  3803 sgd_solver.cpp:106] Iteration 9030, lr = 5e-05
I0403 10:47:15.260385  3803 solver.cpp:228] Iteration 9051, loss = 0.0233855
I0403 10:47:15.260650  3803 solver.cpp:244]     Train net output #0: loss = 0.0233855 (* 1 = 0.0233855 loss)
I0403 10:47:15.465137  3803 sgd_solver.cpp:106] Iteration 9051, lr = 5e-05
I0403 10:47:30.609045  3803 solver.cpp:228] Iteration 9072, loss = 0.00568868
I0403 10:47:30.609159  3803 solver.cpp:244]     Train net output #0: loss = 0.00568861 (* 1 = 0.00568861 loss)
I0403 10:47:30.803488  3803 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 10:47:45.968721  3803 solver.cpp:228] Iteration 9093, loss = 0.010398
I0403 10:47:45.969041  3803 solver.cpp:244]     Train net output #0: loss = 0.0103979 (* 1 = 0.0103979 loss)
I0403 10:47:46.187438  3803 sgd_solver.cpp:106] Iteration 9093, lr = 5e-05
I0403 10:48:01.373102  3803 solver.cpp:228] Iteration 9114, loss = 0.0117688
I0403 10:48:01.373205  3803 solver.cpp:244]     Train net output #0: loss = 0.0117688 (* 1 = 0.0117688 loss)
I0403 10:48:01.540887  3803 sgd_solver.cpp:106] Iteration 9114, lr = 5e-05
I0403 10:48:16.290951  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_9135.caffemodel
I0403 10:48:18.934154  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_9135.solverstate
I0403 10:48:20.743150  3803 solver.cpp:337] Iteration 9135, Testing net (#0)
I0403 10:48:45.167315  3803 solver.cpp:404]     Test net output #0: accuracy = 0.971215
I0403 10:48:45.167424  3803 solver.cpp:404]     Test net output #1: loss = 0.108569 (* 1 = 0.108569 loss)
I0403 10:48:45.685067  3803 solver.cpp:228] Iteration 9135, loss = 0.0043301
I0403 10:48:45.685163  3803 solver.cpp:244]     Train net output #0: loss = 0.00433003 (* 1 = 0.00433003 loss)
I0403 10:48:45.862735  3803 sgd_solver.cpp:106] Iteration 9135, lr = 5e-05
I0403 10:49:01.233927  3803 solver.cpp:228] Iteration 9156, loss = 0.00320303
I0403 10:49:01.234237  3803 solver.cpp:244]     Train net output #0: loss = 0.00320295 (* 1 = 0.00320295 loss)
I0403 10:49:01.400885  3803 sgd_solver.cpp:106] Iteration 9156, lr = 5e-05
I0403 10:49:16.562326  3803 solver.cpp:228] Iteration 9177, loss = 0.0109186
I0403 10:49:16.562456  3803 solver.cpp:244]     Train net output #0: loss = 0.0109185 (* 1 = 0.0109185 loss)
I0403 10:49:16.751811  3803 sgd_solver.cpp:106] Iteration 9177, lr = 5e-05
I0403 10:49:31.837327  3803 solver.cpp:228] Iteration 9198, loss = 0.00769581
I0403 10:49:31.837623  3803 solver.cpp:244]     Train net output #0: loss = 0.00769574 (* 1 = 0.00769574 loss)
I0403 10:49:32.016880  3803 sgd_solver.cpp:106] Iteration 9198, lr = 5e-05
I0403 10:49:47.061503  3803 solver.cpp:228] Iteration 9219, loss = 0.00559916
I0403 10:49:47.061625  3803 solver.cpp:244]     Train net output #0: loss = 0.00559908 (* 1 = 0.00559908 loss)
I0403 10:49:47.262105  3803 sgd_solver.cpp:106] Iteration 9219, lr = 5e-05
I0403 10:50:02.453727  3803 solver.cpp:228] Iteration 9240, loss = 0.0015803
I0403 10:50:02.454033  3803 solver.cpp:244]     Train net output #0: loss = 0.00158022 (* 1 = 0.00158022 loss)
I0403 10:50:02.626848  3803 sgd_solver.cpp:106] Iteration 9240, lr = 5e-05
I0403 10:50:18.056895  3803 solver.cpp:228] Iteration 9261, loss = 0.0171279
I0403 10:50:18.056995  3803 solver.cpp:244]     Train net output #0: loss = 0.0171279 (* 1 = 0.0171279 loss)
I0403 10:50:18.236006  3803 sgd_solver.cpp:106] Iteration 9261, lr = 5e-05
I0403 10:50:33.509107  3803 solver.cpp:228] Iteration 9282, loss = 0.0034013
I0403 10:50:33.516661  3803 solver.cpp:244]     Train net output #0: loss = 0.00340122 (* 1 = 0.00340122 loss)
I0403 10:50:33.724525  3803 sgd_solver.cpp:106] Iteration 9282, lr = 5e-05
I0403 10:50:48.886989  3803 solver.cpp:228] Iteration 9303, loss = 0.00199446
I0403 10:50:48.887099  3803 solver.cpp:244]     Train net output #0: loss = 0.00199437 (* 1 = 0.00199437 loss)
I0403 10:50:49.083691  3803 sgd_solver.cpp:106] Iteration 9303, lr = 5e-05
I0403 10:51:04.555986  3803 solver.cpp:228] Iteration 9324, loss = 0.00932215
I0403 10:51:04.556254  3803 solver.cpp:244]     Train net output #0: loss = 0.00932206 (* 1 = 0.00932206 loss)
I0403 10:51:04.744606  3803 sgd_solver.cpp:106] Iteration 9324, lr = 5e-05
I0403 10:51:20.074198  3803 solver.cpp:228] Iteration 9345, loss = 0.00888631
I0403 10:51:20.074324  3803 solver.cpp:244]     Train net output #0: loss = 0.00888622 (* 1 = 0.00888622 loss)
I0403 10:51:20.264924  3803 sgd_solver.cpp:106] Iteration 9345, lr = 5e-05
I0403 10:51:35.643352  3803 solver.cpp:228] Iteration 9366, loss = 0.0528067
I0403 10:51:35.643646  3803 solver.cpp:244]     Train net output #0: loss = 0.0528066 (* 1 = 0.0528066 loss)
I0403 10:51:35.819121  3803 sgd_solver.cpp:106] Iteration 9366, lr = 5e-05
I0403 10:51:51.018496  3803 solver.cpp:228] Iteration 9387, loss = 0.0239546
I0403 10:51:51.018615  3803 solver.cpp:244]     Train net output #0: loss = 0.0239545 (* 1 = 0.0239545 loss)
I0403 10:51:51.220933  3803 sgd_solver.cpp:106] Iteration 9387, lr = 5e-05
I0403 10:52:06.397507  3803 solver.cpp:228] Iteration 9408, loss = 0.00409784
I0403 10:52:06.397826  3803 solver.cpp:244]     Train net output #0: loss = 0.00409775 (* 1 = 0.00409775 loss)
I0403 10:52:06.611724  3803 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 10:52:22.051581  3803 solver.cpp:228] Iteration 9429, loss = 0.0180939
I0403 10:52:22.051698  3803 solver.cpp:244]     Train net output #0: loss = 0.0180938 (* 1 = 0.0180938 loss)
I0403 10:52:22.234661  3803 sgd_solver.cpp:106] Iteration 9429, lr = 5e-05
I0403 10:52:37.489855  3803 solver.cpp:228] Iteration 9450, loss = 0.0146747
I0403 10:52:37.490175  3803 solver.cpp:244]     Train net output #0: loss = 0.0146746 (* 1 = 0.0146746 loss)
I0403 10:52:37.682258  3803 sgd_solver.cpp:106] Iteration 9450, lr = 5e-05
I0403 10:52:52.925786  3803 solver.cpp:228] Iteration 9471, loss = 0.0366371
I0403 10:52:52.925890  3803 solver.cpp:244]     Train net output #0: loss = 0.036637 (* 1 = 0.036637 loss)
I0403 10:52:53.090332  3803 sgd_solver.cpp:106] Iteration 9471, lr = 5e-05
I0403 10:53:08.434072  3803 solver.cpp:228] Iteration 9492, loss = 0.0552185
I0403 10:53:08.434375  3803 solver.cpp:244]     Train net output #0: loss = 0.0552184 (* 1 = 0.0552184 loss)
I0403 10:53:08.654459  3803 sgd_solver.cpp:106] Iteration 9492, lr = 5e-05
I0403 10:53:23.888048  3803 solver.cpp:228] Iteration 9513, loss = 0.00181677
I0403 10:53:23.888164  3803 solver.cpp:244]     Train net output #0: loss = 0.00181667 (* 1 = 0.00181667 loss)
I0403 10:53:24.147554  3803 sgd_solver.cpp:106] Iteration 9513, lr = 5e-05
I0403 10:53:39.438345  3803 solver.cpp:228] Iteration 9534, loss = 0.0026091
I0403 10:53:39.438652  3803 solver.cpp:244]     Train net output #0: loss = 0.002609 (* 1 = 0.002609 loss)
I0403 10:53:39.687955  3803 sgd_solver.cpp:106] Iteration 9534, lr = 5e-05
I0403 10:53:55.011325  3803 solver.cpp:228] Iteration 9555, loss = 0.00182443
I0403 10:53:55.011440  3803 solver.cpp:244]     Train net output #0: loss = 0.00182433 (* 1 = 0.00182433 loss)
I0403 10:53:55.209482  3803 sgd_solver.cpp:106] Iteration 9555, lr = 5e-05
I0403 10:54:05.490684  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_9570.caffemodel
I0403 10:54:08.229218  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_9570.solverstate
I0403 10:54:13.557342  3803 solver.cpp:337] Iteration 9570, Testing net (#0)
I0403 10:54:37.983160  3803 solver.cpp:404]     Test net output #0: accuracy = 0.97215
I0403 10:54:37.983269  3803 solver.cpp:404]     Test net output #1: loss = 0.107344 (* 1 = 0.107344 loss)
I0403 10:54:43.057404  3803 solver.cpp:228] Iteration 9576, loss = 0.00193533
I0403 10:54:43.057515  3803 solver.cpp:244]     Train net output #0: loss = 0.00193524 (* 1 = 0.00193524 loss)
I0403 10:54:43.245389  3803 sgd_solver.cpp:106] Iteration 9576, lr = 5e-05
I0403 10:54:58.872674  3803 solver.cpp:228] Iteration 9597, loss = 0.00200849
I0403 10:54:58.872995  3803 solver.cpp:244]     Train net output #0: loss = 0.0020084 (* 1 = 0.0020084 loss)
I0403 10:54:59.068555  3803 sgd_solver.cpp:106] Iteration 9597, lr = 5e-05
I0403 10:55:14.454321  3803 solver.cpp:228] Iteration 9618, loss = 0.0102939
I0403 10:55:14.454437  3803 solver.cpp:244]     Train net output #0: loss = 0.0102938 (* 1 = 0.0102938 loss)
I0403 10:55:14.639073  3803 sgd_solver.cpp:106] Iteration 9618, lr = 5e-05
I0403 10:55:29.809829  3803 solver.cpp:228] Iteration 9639, loss = 0.00144888
I0403 10:55:29.810142  3803 solver.cpp:244]     Train net output #0: loss = 0.00144879 (* 1 = 0.00144879 loss)
I0403 10:55:30.047868  3803 sgd_solver.cpp:106] Iteration 9639, lr = 5e-05
I0403 10:55:45.399035  3803 solver.cpp:228] Iteration 9660, loss = 0.0137738
I0403 10:55:45.399149  3803 solver.cpp:244]     Train net output #0: loss = 0.0137737 (* 1 = 0.0137737 loss)
I0403 10:55:45.625798  3803 sgd_solver.cpp:106] Iteration 9660, lr = 5e-05
I0403 10:56:00.908083  3803 solver.cpp:228] Iteration 9681, loss = 0.0194452
I0403 10:56:00.908375  3803 solver.cpp:244]     Train net output #0: loss = 0.0194451 (* 1 = 0.0194451 loss)
I0403 10:56:01.091394  3803 sgd_solver.cpp:106] Iteration 9681, lr = 5e-05
I0403 10:56:16.183771  3803 solver.cpp:228] Iteration 9702, loss = 0.0031534
I0403 10:56:16.183884  3803 solver.cpp:244]     Train net output #0: loss = 0.00315331 (* 1 = 0.00315331 loss)
I0403 10:56:16.373206  3803 sgd_solver.cpp:106] Iteration 9702, lr = 5e-05
I0403 10:56:31.467144  3803 solver.cpp:228] Iteration 9723, loss = 0.0181837
I0403 10:56:31.467458  3803 solver.cpp:244]     Train net output #0: loss = 0.0181836 (* 1 = 0.0181836 loss)
I0403 10:56:31.635774  3803 sgd_solver.cpp:106] Iteration 9723, lr = 5e-05
I0403 10:56:46.825500  3803 solver.cpp:228] Iteration 9744, loss = 0.0147666
I0403 10:56:46.825601  3803 solver.cpp:244]     Train net output #0: loss = 0.0147665 (* 1 = 0.0147665 loss)
I0403 10:56:46.998939  3803 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 10:57:02.352238  3803 solver.cpp:228] Iteration 9765, loss = 0.00196562
I0403 10:57:02.352526  3803 solver.cpp:244]     Train net output #0: loss = 0.00196553 (* 1 = 0.00196553 loss)
I0403 10:57:02.532143  3803 sgd_solver.cpp:106] Iteration 9765, lr = 5e-05
I0403 10:57:17.691226  3803 solver.cpp:228] Iteration 9786, loss = 0.0116504
I0403 10:57:17.691330  3803 solver.cpp:244]     Train net output #0: loss = 0.0116504 (* 1 = 0.0116504 loss)
I0403 10:57:17.865180  3803 sgd_solver.cpp:106] Iteration 9786, lr = 5e-05
I0403 10:57:33.208392  3803 solver.cpp:228] Iteration 9807, loss = 0.023978
I0403 10:57:33.208709  3803 solver.cpp:244]     Train net output #0: loss = 0.0239779 (* 1 = 0.0239779 loss)
I0403 10:57:33.400557  3803 sgd_solver.cpp:106] Iteration 9807, lr = 5e-05
I0403 10:57:48.503410  3803 solver.cpp:228] Iteration 9828, loss = 0.00439201
I0403 10:57:48.503511  3803 solver.cpp:244]     Train net output #0: loss = 0.00439192 (* 1 = 0.00439192 loss)
I0403 10:57:48.683082  3803 sgd_solver.cpp:106] Iteration 9828, lr = 5e-05
I0403 10:58:03.733608  3803 solver.cpp:228] Iteration 9849, loss = 0.00288952
I0403 10:58:03.733927  3803 solver.cpp:244]     Train net output #0: loss = 0.00288943 (* 1 = 0.00288943 loss)
I0403 10:58:03.938873  3803 sgd_solver.cpp:106] Iteration 9849, lr = 5e-05
I0403 10:58:19.181036  3803 solver.cpp:228] Iteration 9870, loss = 0.0122235
I0403 10:58:19.181149  3803 solver.cpp:244]     Train net output #0: loss = 0.0122234 (* 1 = 0.0122234 loss)
I0403 10:58:19.372084  3803 sgd_solver.cpp:106] Iteration 9870, lr = 5e-05
I0403 10:58:34.598491  3803 solver.cpp:228] Iteration 9891, loss = 0.00102842
I0403 10:58:34.598846  3803 solver.cpp:244]     Train net output #0: loss = 0.00102833 (* 1 = 0.00102833 loss)
I0403 10:58:34.787945  3803 sgd_solver.cpp:106] Iteration 9891, lr = 5e-05
I0403 10:58:49.977193  3803 solver.cpp:228] Iteration 9912, loss = 0.0077324
I0403 10:58:49.977313  3803 solver.cpp:244]     Train net output #0: loss = 0.00773231 (* 1 = 0.00773231 loss)
I0403 10:58:50.162786  3803 sgd_solver.cpp:106] Iteration 9912, lr = 5e-05
I0403 10:59:05.522022  3803 solver.cpp:228] Iteration 9933, loss = 0.00462765
I0403 10:59:05.522337  3803 solver.cpp:244]     Train net output #0: loss = 0.00462757 (* 1 = 0.00462757 loss)
I0403 10:59:05.673243  3803 sgd_solver.cpp:106] Iteration 9933, lr = 5e-05
I0403 10:59:21.071584  3803 solver.cpp:228] Iteration 9954, loss = 0.00039907
I0403 10:59:21.071701  3803 solver.cpp:244]     Train net output #0: loss = 0.000398989 (* 1 = 0.000398989 loss)
I0403 10:59:21.269634  3803 sgd_solver.cpp:106] Iteration 9954, lr = 5e-05
I0403 10:59:36.357465  3803 solver.cpp:228] Iteration 9975, loss = 0.00151066
I0403 10:59:36.357789  3803 solver.cpp:244]     Train net output #0: loss = 0.00151058 (* 1 = 0.00151058 loss)
I0403 10:59:36.565877  3803 sgd_solver.cpp:106] Iteration 9975, lr = 5e-05
I0403 10:59:51.883595  3803 solver.cpp:228] Iteration 9996, loss = 0.00459714
I0403 10:59:51.883698  3803 solver.cpp:244]     Train net output #0: loss = 0.00459705 (* 1 = 0.00459705 loss)
I0403 10:59:52.055447  3803 sgd_solver.cpp:106] Iteration 9996, lr = 5e-05
I0403 10:59:57.942201  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_10005.caffemodel
I0403 11:00:00.693009  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_10005.solverstate
I0403 11:00:02.575737  3803 solver.cpp:337] Iteration 10005, Testing net (#0)
I0403 11:00:26.998327  3803 solver.cpp:404]     Test net output #0: accuracy = 0.972617
I0403 11:00:26.998616  3803 solver.cpp:404]     Test net output #1: loss = 0.107733 (* 1 = 0.107733 loss)
I0403 11:00:36.308723  3803 solver.cpp:228] Iteration 10017, loss = 0.0022109
I0403 11:00:36.308822  3803 solver.cpp:244]     Train net output #0: loss = 0.00221081 (* 1 = 0.00221081 loss)
I0403 11:00:36.486366  3803 sgd_solver.cpp:106] Iteration 10017, lr = 5e-05
I0403 11:00:51.834381  3803 solver.cpp:228] Iteration 10038, loss = 0.00808076
I0403 11:00:51.834494  3803 solver.cpp:244]     Train net output #0: loss = 0.00808067 (* 1 = 0.00808067 loss)
I0403 11:00:52.030709  3803 sgd_solver.cpp:106] Iteration 10038, lr = 5e-05
I0403 11:01:07.280805  3803 solver.cpp:228] Iteration 10059, loss = 0.00838513
I0403 11:01:07.281121  3803 solver.cpp:244]     Train net output #0: loss = 0.00838505 (* 1 = 0.00838505 loss)
I0403 11:01:07.502918  3803 sgd_solver.cpp:106] Iteration 10059, lr = 5e-05
I0403 11:01:23.018632  3803 solver.cpp:228] Iteration 10080, loss = 0.00313504
I0403 11:01:23.018740  3803 solver.cpp:244]     Train net output #0: loss = 0.00313495 (* 1 = 0.00313495 loss)
I0403 11:01:23.156281  3803 sgd_solver.cpp:106] Iteration 10080, lr = 5e-05
I0403 11:01:38.468960  3803 solver.cpp:228] Iteration 10101, loss = 0.0237993
I0403 11:01:38.469256  3803 solver.cpp:244]     Train net output #0: loss = 0.0237992 (* 1 = 0.0237992 loss)
I0403 11:01:38.659313  3803 sgd_solver.cpp:106] Iteration 10101, lr = 5e-05
I0403 11:01:53.923991  3803 solver.cpp:228] Iteration 10122, loss = 0.00364439
I0403 11:01:53.924103  3803 solver.cpp:244]     Train net output #0: loss = 0.00364431 (* 1 = 0.00364431 loss)
I0403 11:01:54.123100  3803 sgd_solver.cpp:106] Iteration 10122, lr = 5e-05
I0403 11:02:09.344631  3803 solver.cpp:228] Iteration 10143, loss = 0.00480978
I0403 11:02:09.344931  3803 solver.cpp:244]     Train net output #0: loss = 0.0048097 (* 1 = 0.0048097 loss)
I0403 11:02:09.525388  3803 sgd_solver.cpp:106] Iteration 10143, lr = 5e-05
I0403 11:02:24.777357  3803 solver.cpp:228] Iteration 10164, loss = 0.00441297
I0403 11:02:24.777469  3803 solver.cpp:244]     Train net output #0: loss = 0.00441289 (* 1 = 0.00441289 loss)
I0403 11:02:24.972477  3803 sgd_solver.cpp:106] Iteration 10164, lr = 5e-05
I0403 11:02:40.238014  3803 solver.cpp:228] Iteration 10185, loss = 0.00585695
I0403 11:02:40.238332  3803 solver.cpp:244]     Train net output #0: loss = 0.00585687 (* 1 = 0.00585687 loss)
I0403 11:02:40.423271  3803 sgd_solver.cpp:106] Iteration 10185, lr = 5e-05
I0403 11:02:55.748806  3803 solver.cpp:228] Iteration 10206, loss = 0.0213207
I0403 11:02:55.748921  3803 solver.cpp:244]     Train net output #0: loss = 0.0213206 (* 1 = 0.0213206 loss)
I0403 11:02:55.957876  3803 sgd_solver.cpp:106] Iteration 10206, lr = 5e-05
I0403 11:03:11.184541  3803 solver.cpp:228] Iteration 10227, loss = 0.0165296
I0403 11:03:11.184857  3803 solver.cpp:244]     Train net output #0: loss = 0.0165295 (* 1 = 0.0165295 loss)
I0403 11:03:11.370322  3803 sgd_solver.cpp:106] Iteration 10227, lr = 5e-05
I0403 11:03:26.839565  3803 solver.cpp:228] Iteration 10248, loss = 0.00790442
I0403 11:03:26.839660  3803 solver.cpp:244]     Train net output #0: loss = 0.00790433 (* 1 = 0.00790433 loss)
I0403 11:03:26.947798  3803 sgd_solver.cpp:106] Iteration 10248, lr = 5e-05
I0403 11:03:42.654860  3803 solver.cpp:228] Iteration 10269, loss = 0.0363415
I0403 11:03:42.655155  3803 solver.cpp:244]     Train net output #0: loss = 0.0363414 (* 1 = 0.0363414 loss)
I0403 11:03:42.841706  3803 sgd_solver.cpp:106] Iteration 10269, lr = 5e-05
I0403 11:03:58.025993  3803 solver.cpp:228] Iteration 10290, loss = 0.00862741
I0403 11:03:58.026110  3803 solver.cpp:244]     Train net output #0: loss = 0.00862732 (* 1 = 0.00862732 loss)
I0403 11:03:58.284924  3803 sgd_solver.cpp:106] Iteration 10290, lr = 5e-05
I0403 11:04:13.437106  3803 solver.cpp:228] Iteration 10311, loss = 0.00230008
I0403 11:04:13.437389  3803 solver.cpp:244]     Train net output #0: loss = 0.00229999 (* 1 = 0.00229999 loss)
I0403 11:04:13.617130  3803 sgd_solver.cpp:106] Iteration 10311, lr = 5e-05
I0403 11:04:28.891335  3803 solver.cpp:228] Iteration 10332, loss = 0.0106592
I0403 11:04:28.891417  3803 solver.cpp:244]     Train net output #0: loss = 0.0106591 (* 1 = 0.0106591 loss)
I0403 11:04:29.067818  3803 sgd_solver.cpp:106] Iteration 10332, lr = 5e-05
I0403 11:04:44.231377  3803 solver.cpp:228] Iteration 10353, loss = 0.0161799
I0403 11:04:44.231663  3803 solver.cpp:244]     Train net output #0: loss = 0.0161798 (* 1 = 0.0161798 loss)
I0403 11:04:44.450558  3803 sgd_solver.cpp:106] Iteration 10353, lr = 5e-05
I0403 11:05:00.019909  3803 solver.cpp:228] Iteration 10374, loss = 0.00239629
I0403 11:05:00.020021  3803 solver.cpp:244]     Train net output #0: loss = 0.00239618 (* 1 = 0.00239618 loss)
I0403 11:05:00.221315  3803 sgd_solver.cpp:106] Iteration 10374, lr = 5e-05
I0403 11:05:15.366828  3803 solver.cpp:228] Iteration 10395, loss = 0.0178713
I0403 11:05:15.367082  3803 solver.cpp:244]     Train net output #0: loss = 0.0178712 (* 1 = 0.0178712 loss)
I0403 11:05:15.579897  3803 sgd_solver.cpp:106] Iteration 10395, lr = 5e-05
I0403 11:05:30.709862  3803 solver.cpp:228] Iteration 10416, loss = 0.0179757
I0403 11:05:30.709977  3803 solver.cpp:244]     Train net output #0: loss = 0.0179756 (* 1 = 0.0179756 loss)
I0403 11:05:30.905031  3803 sgd_solver.cpp:106] Iteration 10416, lr = 5e-05
I0403 11:05:45.953632  3803 solver.cpp:228] Iteration 10437, loss = 0.00221229
I0403 11:05:45.953936  3803 solver.cpp:244]     Train net output #0: loss = 0.00221218 (* 1 = 0.00221218 loss)
I0403 11:05:46.132196  3803 sgd_solver.cpp:106] Iteration 10437, lr = 5e-05
I0403 11:05:47.619707  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_10440.caffemodel
I0403 11:05:50.347204  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_10440.solverstate
I0403 11:05:52.230087  3803 solver.cpp:337] Iteration 10440, Testing net (#0)
I0403 11:06:16.643350  3803 solver.cpp:404]     Test net output #0: accuracy = 0.972056
I0403 11:06:16.643693  3803 solver.cpp:404]     Test net output #1: loss = 0.107349 (* 1 = 0.107349 loss)
I0403 11:06:30.528172  3803 solver.cpp:228] Iteration 10458, loss = 0.0523648
I0403 11:06:30.528285  3803 solver.cpp:244]     Train net output #0: loss = 0.0523647 (* 1 = 0.0523647 loss)
I0403 11:06:30.725615  3803 sgd_solver.cpp:106] Iteration 10458, lr = 5e-05
I0403 11:06:46.137994  3803 solver.cpp:228] Iteration 10479, loss = 0.00247812
I0403 11:06:46.138097  3803 solver.cpp:244]     Train net output #0: loss = 0.00247801 (* 1 = 0.00247801 loss)
I0403 11:06:46.316308  3803 sgd_solver.cpp:106] Iteration 10479, lr = 5e-05
I0403 11:07:01.531554  3803 solver.cpp:228] Iteration 10500, loss = 0.00967347
I0403 11:07:01.531846  3803 solver.cpp:244]     Train net output #0: loss = 0.00967335 (* 1 = 0.00967335 loss)
I0403 11:07:01.710963  3803 sgd_solver.cpp:106] Iteration 10500, lr = 5e-05
I0403 11:07:17.051358  3803 solver.cpp:228] Iteration 10521, loss = 0.00334345
I0403 11:07:17.051473  3803 solver.cpp:244]     Train net output #0: loss = 0.00334333 (* 1 = 0.00334333 loss)
I0403 11:07:17.278154  3803 sgd_solver.cpp:106] Iteration 10521, lr = 5e-05
I0403 11:07:32.471228  3803 solver.cpp:228] Iteration 10542, loss = 0.0148905
I0403 11:07:32.471556  3803 solver.cpp:244]     Train net output #0: loss = 0.0148904 (* 1 = 0.0148904 loss)
I0403 11:07:32.654568  3803 sgd_solver.cpp:106] Iteration 10542, lr = 5e-05
I0403 11:07:47.786967  3803 solver.cpp:228] Iteration 10563, loss = 0.0210412
I0403 11:07:47.787070  3803 solver.cpp:244]     Train net output #0: loss = 0.021041 (* 1 = 0.021041 loss)
I0403 11:07:47.938884  3803 sgd_solver.cpp:106] Iteration 10563, lr = 5e-05
I0403 11:08:03.698854  3803 solver.cpp:228] Iteration 10584, loss = 0.0146067
I0403 11:08:03.699152  3803 solver.cpp:244]     Train net output #0: loss = 0.0146066 (* 1 = 0.0146066 loss)
I0403 11:08:03.856796  3803 sgd_solver.cpp:106] Iteration 10584, lr = 5e-05
I0403 11:08:19.346479  3803 solver.cpp:228] Iteration 10605, loss = 0.0428599
I0403 11:08:19.346596  3803 solver.cpp:244]     Train net output #0: loss = 0.0428598 (* 1 = 0.0428598 loss)
I0403 11:08:19.530869  3803 sgd_solver.cpp:106] Iteration 10605, lr = 5e-05
I0403 11:08:35.060895  3803 solver.cpp:228] Iteration 10626, loss = 0.00404742
I0403 11:08:35.061187  3803 solver.cpp:244]     Train net output #0: loss = 0.00404729 (* 1 = 0.00404729 loss)
I0403 11:08:35.225219  3803 sgd_solver.cpp:106] Iteration 10626, lr = 5e-05
I0403 11:08:50.594235  3803 solver.cpp:228] Iteration 10647, loss = 0.00540426
I0403 11:08:50.594346  3803 solver.cpp:244]     Train net output #0: loss = 0.00540413 (* 1 = 0.00540413 loss)
I0403 11:08:50.774421  3803 sgd_solver.cpp:106] Iteration 10647, lr = 5e-05
I0403 11:09:06.080874  3803 solver.cpp:228] Iteration 10668, loss = 0.00100848
I0403 11:09:06.081159  3803 solver.cpp:244]     Train net output #0: loss = 0.00100835 (* 1 = 0.00100835 loss)
I0403 11:09:06.320199  3803 sgd_solver.cpp:106] Iteration 10668, lr = 5e-05
I0403 11:09:21.568372  3803 solver.cpp:228] Iteration 10689, loss = 0.0110355
I0403 11:09:21.568487  3803 solver.cpp:244]     Train net output #0: loss = 0.0110354 (* 1 = 0.0110354 loss)
I0403 11:09:21.838861  3803 sgd_solver.cpp:106] Iteration 10689, lr = 5e-05
I0403 11:09:37.041198  3803 solver.cpp:228] Iteration 10710, loss = 0.0024782
I0403 11:09:37.041522  3803 solver.cpp:244]     Train net output #0: loss = 0.00247807 (* 1 = 0.00247807 loss)
I0403 11:09:37.234938  3803 sgd_solver.cpp:106] Iteration 10710, lr = 5e-05
I0403 11:09:52.610229  3803 solver.cpp:228] Iteration 10731, loss = 0.00757828
I0403 11:09:52.610337  3803 solver.cpp:244]     Train net output #0: loss = 0.00757815 (* 1 = 0.00757815 loss)
I0403 11:09:52.788494  3803 sgd_solver.cpp:106] Iteration 10731, lr = 5e-05
I0403 11:10:08.185521  3803 solver.cpp:228] Iteration 10752, loss = 0.00358469
I0403 11:10:08.185854  3803 solver.cpp:244]     Train net output #0: loss = 0.00358455 (* 1 = 0.00358455 loss)
I0403 11:10:08.358885  3803 sgd_solver.cpp:106] Iteration 10752, lr = 5e-05
I0403 11:10:23.652171  3803 solver.cpp:228] Iteration 10773, loss = 0.00314802
I0403 11:10:23.652281  3803 solver.cpp:244]     Train net output #0: loss = 0.00314789 (* 1 = 0.00314789 loss)
I0403 11:10:23.813069  3803 sgd_solver.cpp:106] Iteration 10773, lr = 5e-05
I0403 11:10:39.110875  3803 solver.cpp:228] Iteration 10794, loss = 0.0106317
I0403 11:10:39.111181  3803 solver.cpp:244]     Train net output #0: loss = 0.0106316 (* 1 = 0.0106316 loss)
I0403 11:10:39.288558  3803 sgd_solver.cpp:106] Iteration 10794, lr = 5e-05
I0403 11:10:54.796455  3803 solver.cpp:228] Iteration 10815, loss = 0.00153518
I0403 11:10:54.796560  3803 solver.cpp:244]     Train net output #0: loss = 0.00153505 (* 1 = 0.00153505 loss)
I0403 11:10:54.943733  3803 sgd_solver.cpp:106] Iteration 10815, lr = 5e-05
I0403 11:11:10.084019  3803 solver.cpp:228] Iteration 10836, loss = 0.00149301
I0403 11:11:10.084347  3803 solver.cpp:244]     Train net output #0: loss = 0.00149287 (* 1 = 0.00149287 loss)
I0403 11:11:10.338300  3803 sgd_solver.cpp:106] Iteration 10836, lr = 5e-05
I0403 11:11:25.492321  3803 solver.cpp:228] Iteration 10857, loss = 0.00546006
I0403 11:11:25.492431  3803 solver.cpp:244]     Train net output #0: loss = 0.00545993 (* 1 = 0.00545993 loss)
I0403 11:11:25.692512  3803 sgd_solver.cpp:106] Iteration 10857, lr = 5e-05
I0403 11:11:38.295123  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_10875.caffemodel
I0403 11:11:41.022260  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_10875.solverstate
I0403 11:11:42.971149  3803 solver.cpp:337] Iteration 10875, Testing net (#0)
I0403 11:12:07.384680  3803 solver.cpp:404]     Test net output #0: accuracy = 0.97243
I0403 11:12:07.384788  3803 solver.cpp:404]     Test net output #1: loss = 0.106921 (* 1 = 0.106921 loss)
I0403 11:12:10.119143  3803 solver.cpp:228] Iteration 10878, loss = 0.0166419
I0403 11:12:10.119243  3803 solver.cpp:244]     Train net output #0: loss = 0.0166417 (* 1 = 0.0166417 loss)
I0403 11:12:10.267729  3803 sgd_solver.cpp:106] Iteration 10878, lr = 5e-05
I0403 11:12:25.794549  3803 solver.cpp:228] Iteration 10899, loss = 0.00585629
I0403 11:12:25.794822  3803 solver.cpp:244]     Train net output #0: loss = 0.00585615 (* 1 = 0.00585615 loss)
I0403 11:12:25.964357  3803 sgd_solver.cpp:106] Iteration 10899, lr = 5e-05
I0403 11:12:41.114485  3803 solver.cpp:228] Iteration 10920, loss = 0.00696185
I0403 11:12:41.114596  3803 solver.cpp:244]     Train net output #0: loss = 0.00696172 (* 1 = 0.00696172 loss)
I0403 11:12:41.309875  3803 sgd_solver.cpp:106] Iteration 10920, lr = 5e-05
I0403 11:12:56.462996  3803 solver.cpp:228] Iteration 10941, loss = 0.00977735
I0403 11:12:56.463296  3803 solver.cpp:244]     Train net output #0: loss = 0.00977721 (* 1 = 0.00977721 loss)
I0403 11:12:56.640686  3803 sgd_solver.cpp:106] Iteration 10941, lr = 5e-05
I0403 11:13:11.748810  3803 solver.cpp:228] Iteration 10962, loss = 0.0138189
I0403 11:13:11.748934  3803 solver.cpp:244]     Train net output #0: loss = 0.0138187 (* 1 = 0.0138187 loss)
I0403 11:13:11.932224  3803 sgd_solver.cpp:106] Iteration 10962, lr = 5e-05
I0403 11:13:27.141099  3803 solver.cpp:228] Iteration 10983, loss = 0.00586709
I0403 11:13:27.141414  3803 solver.cpp:244]     Train net output #0: loss = 0.00586695 (* 1 = 0.00586695 loss)
I0403 11:13:27.350262  3803 sgd_solver.cpp:106] Iteration 10983, lr = 5e-05
I0403 11:13:42.395805  3803 solver.cpp:228] Iteration 11004, loss = 0.00154397
I0403 11:13:42.395906  3803 solver.cpp:244]     Train net output #0: loss = 0.00154383 (* 1 = 0.00154383 loss)
I0403 11:13:42.577010  3803 sgd_solver.cpp:106] Iteration 11004, lr = 5e-05
I0403 11:13:57.841678  3803 solver.cpp:228] Iteration 11025, loss = 0.00356806
I0403 11:13:57.842006  3803 solver.cpp:244]     Train net output #0: loss = 0.00356792 (* 1 = 0.00356792 loss)
I0403 11:13:57.995864  3803 sgd_solver.cpp:106] Iteration 11025, lr = 5e-05
I0403 11:14:13.230592  3803 solver.cpp:228] Iteration 11046, loss = 0.0068995
I0403 11:14:13.230705  3803 solver.cpp:244]     Train net output #0: loss = 0.00689936 (* 1 = 0.00689936 loss)
I0403 11:14:13.423156  3803 sgd_solver.cpp:106] Iteration 11046, lr = 5e-05
I0403 11:14:28.970615  3803 solver.cpp:228] Iteration 11067, loss = 0.00187858
I0403 11:14:28.970873  3803 solver.cpp:244]     Train net output #0: loss = 0.00187844 (* 1 = 0.00187844 loss)
I0403 11:14:29.218618  3803 sgd_solver.cpp:106] Iteration 11067, lr = 5e-05
I0403 11:14:44.440188  3803 solver.cpp:228] Iteration 11088, loss = 0.00584668
I0403 11:14:44.440307  3803 solver.cpp:244]     Train net output #0: loss = 0.00584654 (* 1 = 0.00584654 loss)
I0403 11:14:44.588467  3803 sgd_solver.cpp:106] Iteration 11088, lr = 5e-05
I0403 11:14:59.928606  3803 solver.cpp:228] Iteration 11109, loss = 0.00824935
I0403 11:14:59.928915  3803 solver.cpp:244]     Train net output #0: loss = 0.00824921 (* 1 = 0.00824921 loss)
I0403 11:15:00.120393  3803 sgd_solver.cpp:106] Iteration 11109, lr = 5e-05
I0403 11:15:15.258687  3803 solver.cpp:228] Iteration 11130, loss = 0.0128934
I0403 11:15:15.258802  3803 solver.cpp:244]     Train net output #0: loss = 0.0128933 (* 1 = 0.0128933 loss)
I0403 11:15:15.453629  3803 sgd_solver.cpp:106] Iteration 11130, lr = 5e-05
I0403 11:15:30.825851  3803 solver.cpp:228] Iteration 11151, loss = 0.0554005
I0403 11:15:30.826164  3803 solver.cpp:244]     Train net output #0: loss = 0.0554004 (* 1 = 0.0554004 loss)
I0403 11:15:31.087512  3803 sgd_solver.cpp:106] Iteration 11151, lr = 5e-05
I0403 11:15:46.311049  3803 solver.cpp:228] Iteration 11172, loss = 0.00675103
I0403 11:15:46.311168  3803 solver.cpp:244]     Train net output #0: loss = 0.00675089 (* 1 = 0.00675089 loss)
I0403 11:15:46.500514  3803 sgd_solver.cpp:106] Iteration 11172, lr = 5e-05
I0403 11:16:01.801739  3803 solver.cpp:228] Iteration 11193, loss = 0.00515629
I0403 11:16:01.807662  3803 solver.cpp:244]     Train net output #0: loss = 0.00515615 (* 1 = 0.00515615 loss)
I0403 11:16:01.981478  3803 sgd_solver.cpp:106] Iteration 11193, lr = 5e-05
I0403 11:16:17.342180  3803 solver.cpp:228] Iteration 11214, loss = 0.0046473
I0403 11:16:17.342283  3803 solver.cpp:244]     Train net output #0: loss = 0.00464716 (* 1 = 0.00464716 loss)
I0403 11:16:17.495522  3803 sgd_solver.cpp:106] Iteration 11214, lr = 5e-05
I0403 11:16:32.912044  3803 solver.cpp:228] Iteration 11235, loss = 0.0104084
I0403 11:16:32.912371  3803 solver.cpp:244]     Train net output #0: loss = 0.0104082 (* 1 = 0.0104082 loss)
I0403 11:16:33.114720  3803 sgd_solver.cpp:106] Iteration 11235, lr = 5e-05
I0403 11:16:48.298960  3803 solver.cpp:228] Iteration 11256, loss = 0.0259866
I0403 11:16:48.299062  3803 solver.cpp:244]     Train net output #0: loss = 0.0259865 (* 1 = 0.0259865 loss)
I0403 11:16:48.455595  3803 sgd_solver.cpp:106] Iteration 11256, lr = 5e-05
I0403 11:17:03.853314  3803 solver.cpp:228] Iteration 11277, loss = 0.00205182
I0403 11:17:03.853610  3803 solver.cpp:244]     Train net output #0: loss = 0.00205168 (* 1 = 0.00205168 loss)
I0403 11:17:04.030681  3803 sgd_solver.cpp:106] Iteration 11277, lr = 5e-05
I0403 11:17:19.377508  3803 solver.cpp:228] Iteration 11298, loss = 0.0199406
I0403 11:17:19.377624  3803 solver.cpp:244]     Train net output #0: loss = 0.0199404 (* 1 = 0.0199404 loss)
I0403 11:17:19.557585  3803 sgd_solver.cpp:106] Iteration 11298, lr = 5e-05
I0403 11:17:27.546576  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_11310.caffemodel
I0403 11:17:30.337385  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_11310.solverstate
I0403 11:17:32.226999  3803 solver.cpp:337] Iteration 11310, Testing net (#0)
I0403 11:17:56.643908  3803 solver.cpp:404]     Test net output #0: accuracy = 0.972243
I0403 11:17:56.644248  3803 solver.cpp:404]     Test net output #1: loss = 0.106632 (* 1 = 0.106632 loss)
I0403 11:18:03.821527  3803 solver.cpp:228] Iteration 11319, loss = 0.00550945
I0403 11:18:03.821642  3803 solver.cpp:244]     Train net output #0: loss = 0.00550931 (* 1 = 0.00550931 loss)
I0403 11:18:04.047986  3803 sgd_solver.cpp:106] Iteration 11319, lr = 5e-05
I0403 11:18:19.412835  3803 solver.cpp:228] Iteration 11340, loss = 0.0151161
I0403 11:18:19.412950  3803 solver.cpp:244]     Train net output #0: loss = 0.0151159 (* 1 = 0.0151159 loss)
I0403 11:18:19.632848  3803 sgd_solver.cpp:106] Iteration 11340, lr = 5e-05
I0403 11:18:35.062770  3803 solver.cpp:228] Iteration 11361, loss = 0.00265189
I0403 11:18:35.063082  3803 solver.cpp:244]     Train net output #0: loss = 0.00265175 (* 1 = 0.00265175 loss)
I0403 11:18:35.240326  3803 sgd_solver.cpp:106] Iteration 11361, lr = 5e-05
I0403 11:18:50.573917  3803 solver.cpp:228] Iteration 11382, loss = 0.028981
I0403 11:18:50.574031  3803 solver.cpp:244]     Train net output #0: loss = 0.0289809 (* 1 = 0.0289809 loss)
I0403 11:18:50.793673  3803 sgd_solver.cpp:106] Iteration 11382, lr = 5e-05
I0403 11:19:06.009407  3803 solver.cpp:228] Iteration 11403, loss = 0.00737488
I0403 11:19:06.009701  3803 solver.cpp:244]     Train net output #0: loss = 0.00737473 (* 1 = 0.00737473 loss)
I0403 11:19:06.173818  3803 sgd_solver.cpp:106] Iteration 11403, lr = 5e-05
I0403 11:19:21.673820  3803 solver.cpp:228] Iteration 11424, loss = 0.00323963
I0403 11:19:21.673936  3803 solver.cpp:244]     Train net output #0: loss = 0.00323949 (* 1 = 0.00323949 loss)
I0403 11:19:21.909070  3803 sgd_solver.cpp:106] Iteration 11424, lr = 5e-05
I0403 11:19:37.134083  3803 solver.cpp:228] Iteration 11445, loss = 0.00328981
I0403 11:19:37.134392  3803 solver.cpp:244]     Train net output #0: loss = 0.00328967 (* 1 = 0.00328967 loss)
I0403 11:19:37.285329  3803 sgd_solver.cpp:106] Iteration 11445, lr = 5e-05
I0403 11:19:52.560220  3803 solver.cpp:228] Iteration 11466, loss = 0.0106959
I0403 11:19:52.560327  3803 solver.cpp:244]     Train net output #0: loss = 0.0106957 (* 1 = 0.0106957 loss)
I0403 11:19:52.742192  3803 sgd_solver.cpp:106] Iteration 11466, lr = 5e-05
I0403 11:20:08.212350  3803 solver.cpp:228] Iteration 11487, loss = 0.0194253
I0403 11:20:08.212654  3803 solver.cpp:244]     Train net output #0: loss = 0.0194251 (* 1 = 0.0194251 loss)
I0403 11:20:08.375538  3803 sgd_solver.cpp:106] Iteration 11487, lr = 5e-05
I0403 11:20:23.820844  3803 solver.cpp:228] Iteration 11508, loss = 0.00126582
I0403 11:20:23.820948  3803 solver.cpp:244]     Train net output #0: loss = 0.00126568 (* 1 = 0.00126568 loss)
I0403 11:20:24.003329  3803 sgd_solver.cpp:106] Iteration 11508, lr = 5e-05
I0403 11:20:39.467123  3803 solver.cpp:228] Iteration 11529, loss = 0.00867851
I0403 11:20:39.467452  3803 solver.cpp:244]     Train net output #0: loss = 0.00867836 (* 1 = 0.00867836 loss)
I0403 11:20:39.710386  3803 sgd_solver.cpp:106] Iteration 11529, lr = 5e-05
I0403 11:20:55.092625  3803 solver.cpp:228] Iteration 11550, loss = 0.00310508
I0403 11:20:55.092728  3803 solver.cpp:244]     Train net output #0: loss = 0.00310494 (* 1 = 0.00310494 loss)
I0403 11:20:55.261276  3803 sgd_solver.cpp:106] Iteration 11550, lr = 5e-05
I0403 11:21:10.393318  3803 solver.cpp:228] Iteration 11571, loss = 0.00168542
I0403 11:21:10.393611  3803 solver.cpp:244]     Train net output #0: loss = 0.00168528 (* 1 = 0.00168528 loss)
I0403 11:21:10.579053  3803 sgd_solver.cpp:106] Iteration 11571, lr = 5e-05
I0403 11:21:25.788647  3803 solver.cpp:228] Iteration 11592, loss = 0.0155959
I0403 11:21:25.788766  3803 solver.cpp:244]     Train net output #0: loss = 0.0155958 (* 1 = 0.0155958 loss)
I0403 11:21:26.024914  3803 sgd_solver.cpp:106] Iteration 11592, lr = 5e-05
I0403 11:21:41.306314  3803 solver.cpp:228] Iteration 11613, loss = 0.0140131
I0403 11:21:41.309638  3803 solver.cpp:244]     Train net output #0: loss = 0.014013 (* 1 = 0.014013 loss)
I0403 11:21:41.489717  3803 sgd_solver.cpp:106] Iteration 11613, lr = 5e-05
I0403 11:21:56.779191  3803 solver.cpp:228] Iteration 11634, loss = 0.02825
I0403 11:21:56.779299  3803 solver.cpp:244]     Train net output #0: loss = 0.0282499 (* 1 = 0.0282499 loss)
I0403 11:21:56.911185  3803 sgd_solver.cpp:106] Iteration 11634, lr = 5e-05
I0403 11:22:12.444383  3803 solver.cpp:228] Iteration 11655, loss = 0.0195592
I0403 11:22:12.444686  3803 solver.cpp:244]     Train net output #0: loss = 0.019559 (* 1 = 0.019559 loss)
I0403 11:22:12.622056  3803 sgd_solver.cpp:106] Iteration 11655, lr = 5e-05
I0403 11:22:28.096850  3803 solver.cpp:228] Iteration 11676, loss = 0.0077167
I0403 11:22:28.096961  3803 solver.cpp:244]     Train net output #0: loss = 0.00771657 (* 1 = 0.00771657 loss)
I0403 11:22:28.292841  3803 sgd_solver.cpp:106] Iteration 11676, lr = 5e-05
I0403 11:22:43.715852  3803 solver.cpp:228] Iteration 11697, loss = 0.00297711
I0403 11:22:43.716156  3803 solver.cpp:244]     Train net output #0: loss = 0.00297697 (* 1 = 0.00297697 loss)
I0403 11:22:43.893055  3803 sgd_solver.cpp:106] Iteration 11697, lr = 5e-05
I0403 11:22:59.251950  3803 solver.cpp:228] Iteration 11718, loss = 0.00561375
I0403 11:22:59.252053  3803 solver.cpp:244]     Train net output #0: loss = 0.00561361 (* 1 = 0.00561361 loss)
I0403 11:22:59.423964  3803 sgd_solver.cpp:106] Iteration 11718, lr = 5e-05
I0403 11:23:14.848300  3803 solver.cpp:228] Iteration 11739, loss = 0.000821209
I0403 11:23:14.848580  3803 solver.cpp:244]     Train net output #0: loss = 0.000821069 (* 1 = 0.000821069 loss)
I0403 11:23:15.027053  3803 sgd_solver.cpp:106] Iteration 11739, lr = 5e-05
I0403 11:23:18.667606  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_11745.caffemodel
I0403 11:23:21.433903  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_11745.solverstate
I0403 11:23:23.329069  3803 solver.cpp:337] Iteration 11745, Testing net (#0)
I0403 11:23:47.746601  3803 solver.cpp:404]     Test net output #0: accuracy = 0.97215
I0403 11:23:47.746922  3803 solver.cpp:404]     Test net output #1: loss = 0.107503 (* 1 = 0.107503 loss)
I0403 11:23:59.315850  3803 solver.cpp:228] Iteration 11760, loss = 0.00245499
I0403 11:23:59.315961  3803 solver.cpp:244]     Train net output #0: loss = 0.00245485 (* 1 = 0.00245485 loss)
I0403 11:23:59.522055  3803 sgd_solver.cpp:106] Iteration 11760, lr = 5e-05
I0403 11:24:14.685752  3803 solver.cpp:228] Iteration 11781, loss = 0.00780386
I0403 11:24:14.685855  3803 solver.cpp:244]     Train net output #0: loss = 0.00780371 (* 1 = 0.00780371 loss)
I0403 11:24:14.853832  3803 sgd_solver.cpp:106] Iteration 11781, lr = 5e-05
I0403 11:24:30.187813  3803 solver.cpp:228] Iteration 11802, loss = 0.0127325
I0403 11:24:30.188119  3803 solver.cpp:244]     Train net output #0: loss = 0.0127324 (* 1 = 0.0127324 loss)
I0403 11:24:30.355538  3803 sgd_solver.cpp:106] Iteration 11802, lr = 5e-05
I0403 11:24:45.725914  3803 solver.cpp:228] Iteration 11823, loss = 0.0108865
I0403 11:24:45.726013  3803 solver.cpp:244]     Train net output #0: loss = 0.0108864 (* 1 = 0.0108864 loss)
I0403 11:24:45.887573  3803 sgd_solver.cpp:106] Iteration 11823, lr = 5e-05
I0403 11:25:01.240161  3803 solver.cpp:228] Iteration 11844, loss = 0.0046028
I0403 11:25:01.240478  3803 solver.cpp:244]     Train net output #0: loss = 0.00460266 (* 1 = 0.00460266 loss)
I0403 11:25:01.451985  3803 sgd_solver.cpp:106] Iteration 11844, lr = 5e-05
I0403 11:25:16.718269  3803 solver.cpp:228] Iteration 11865, loss = 0.040373
I0403 11:25:16.718387  3803 solver.cpp:244]     Train net output #0: loss = 0.0403729 (* 1 = 0.0403729 loss)
I0403 11:25:16.918301  3803 sgd_solver.cpp:106] Iteration 11865, lr = 5e-05
I0403 11:25:32.468430  3803 solver.cpp:228] Iteration 11886, loss = 0.0222663
I0403 11:25:32.468744  3803 solver.cpp:244]     Train net output #0: loss = 0.0222662 (* 1 = 0.0222662 loss)
I0403 11:25:32.631809  3803 sgd_solver.cpp:106] Iteration 11886, lr = 5e-05
I0403 11:25:47.853500  3803 solver.cpp:228] Iteration 11907, loss = 0.00333849
I0403 11:25:47.853615  3803 solver.cpp:244]     Train net output #0: loss = 0.00333835 (* 1 = 0.00333835 loss)
I0403 11:25:48.070938  3803 sgd_solver.cpp:106] Iteration 11907, lr = 5e-05
I0403 11:26:03.232962  3803 solver.cpp:228] Iteration 11928, loss = 0.0075205
I0403 11:26:03.233274  3803 solver.cpp:244]     Train net output #0: loss = 0.00752035 (* 1 = 0.00752035 loss)
I0403 11:26:03.399503  3803 sgd_solver.cpp:106] Iteration 11928, lr = 5e-05
I0403 11:26:18.428345  3803 solver.cpp:228] Iteration 11949, loss = 0.00444047
I0403 11:26:18.428462  3803 solver.cpp:244]     Train net output #0: loss = 0.00444032 (* 1 = 0.00444032 loss)
I0403 11:26:18.627849  3803 sgd_solver.cpp:106] Iteration 11949, lr = 5e-05
I0403 11:26:34.051795  3803 solver.cpp:228] Iteration 11970, loss = 0.0171427
I0403 11:26:34.052043  3803 solver.cpp:244]     Train net output #0: loss = 0.0171426 (* 1 = 0.0171426 loss)
I0403 11:26:34.236680  3803 sgd_solver.cpp:106] Iteration 11970, lr = 5e-05
I0403 11:26:49.452559  3803 solver.cpp:228] Iteration 11991, loss = 0.00153963
I0403 11:26:49.452663  3803 solver.cpp:244]     Train net output #0: loss = 0.00153949 (* 1 = 0.00153949 loss)
I0403 11:26:49.622810  3803 sgd_solver.cpp:106] Iteration 11991, lr = 5e-05
I0403 11:27:04.821744  3803 solver.cpp:228] Iteration 12012, loss = 0.00376125
I0403 11:27:04.822057  3803 solver.cpp:244]     Train net output #0: loss = 0.00376111 (* 1 = 0.00376111 loss)
I0403 11:27:05.000979  3803 sgd_solver.cpp:106] Iteration 12012, lr = 5e-05
I0403 11:27:20.336470  3803 solver.cpp:228] Iteration 12033, loss = 0.0187874
I0403 11:27:20.336572  3803 solver.cpp:244]     Train net output #0: loss = 0.0187872 (* 1 = 0.0187872 loss)
I0403 11:27:20.502727  3803 sgd_solver.cpp:106] Iteration 12033, lr = 5e-05
I0403 11:27:35.912176  3803 solver.cpp:228] Iteration 12054, loss = 0.0244977
I0403 11:27:35.912498  3803 solver.cpp:244]     Train net output #0: loss = 0.0244975 (* 1 = 0.0244975 loss)
I0403 11:27:36.118751  3803 sgd_solver.cpp:106] Iteration 12054, lr = 5e-05
I0403 11:27:51.610251  3803 solver.cpp:228] Iteration 12075, loss = 0.00755526
I0403 11:27:51.610357  3803 solver.cpp:244]     Train net output #0: loss = 0.00755511 (* 1 = 0.00755511 loss)
I0403 11:27:51.789773  3803 sgd_solver.cpp:106] Iteration 12075, lr = 5e-05
I0403 11:28:07.210769  3803 solver.cpp:228] Iteration 12096, loss = 0.00463877
I0403 11:28:07.211056  3803 solver.cpp:244]     Train net output #0: loss = 0.00463862 (* 1 = 0.00463862 loss)
I0403 11:28:07.358403  3803 sgd_solver.cpp:106] Iteration 12096, lr = 5e-05
I0403 11:28:22.923143  3803 solver.cpp:228] Iteration 12117, loss = 0.00155668
I0403 11:28:22.923259  3803 solver.cpp:244]     Train net output #0: loss = 0.00155654 (* 1 = 0.00155654 loss)
I0403 11:28:23.129451  3803 sgd_solver.cpp:106] Iteration 12117, lr = 5e-05
I0403 11:28:38.456869  3803 solver.cpp:228] Iteration 12138, loss = 0.00642486
I0403 11:28:38.457123  3803 solver.cpp:244]     Train net output #0: loss = 0.00642471 (* 1 = 0.00642471 loss)
I0403 11:28:38.645354  3803 sgd_solver.cpp:106] Iteration 12138, lr = 5e-05
I0403 11:28:54.239853  3803 solver.cpp:228] Iteration 12159, loss = 0.00255739
I0403 11:28:54.239967  3803 solver.cpp:244]     Train net output #0: loss = 0.00255725 (* 1 = 0.00255725 loss)
I0403 11:28:54.429977  3803 sgd_solver.cpp:106] Iteration 12159, lr = 5e-05
I0403 11:29:09.183014  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_12180.caffemodel
I0403 11:29:11.941644  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_12180.solverstate
I0403 11:29:13.815821  3803 solver.cpp:337] Iteration 12180, Testing net (#0)
I0403 11:29:38.234537  3803 solver.cpp:404]     Test net output #0: accuracy = 0.972056
I0403 11:29:38.234644  3803 solver.cpp:404]     Test net output #1: loss = 0.108209 (* 1 = 0.108209 loss)
I0403 11:29:38.755491  3803 solver.cpp:228] Iteration 12180, loss = 0.00423641
I0403 11:29:38.755589  3803 solver.cpp:244]     Train net output #0: loss = 0.00423626 (* 1 = 0.00423626 loss)
I0403 11:29:38.926945  3803 sgd_solver.cpp:106] Iteration 12180, lr = 5e-05
I0403 11:29:54.217317  3803 solver.cpp:228] Iteration 12201, loss = 0.0276083
I0403 11:29:54.217669  3803 solver.cpp:244]     Train net output #0: loss = 0.0276081 (* 1 = 0.0276081 loss)
I0403 11:29:54.402115  3803 sgd_solver.cpp:106] Iteration 12201, lr = 5e-05
I0403 11:30:09.669704  3803 solver.cpp:228] Iteration 12222, loss = 0.0118693
I0403 11:30:09.669806  3803 solver.cpp:244]     Train net output #0: loss = 0.0118692 (* 1 = 0.0118692 loss)
I0403 11:30:09.848695  3803 sgd_solver.cpp:106] Iteration 12222, lr = 5e-05
I0403 11:30:25.083798  3803 solver.cpp:228] Iteration 12243, loss = 0.00202382
I0403 11:30:25.084122  3803 solver.cpp:244]     Train net output #0: loss = 0.00202367 (* 1 = 0.00202367 loss)
I0403 11:30:25.277822  3803 sgd_solver.cpp:106] Iteration 12243, lr = 5e-05
I0403 11:30:40.415124  3803 solver.cpp:228] Iteration 12264, loss = 0.00460231
I0403 11:30:40.415238  3803 solver.cpp:244]     Train net output #0: loss = 0.00460217 (* 1 = 0.00460217 loss)
I0403 11:30:40.637539  3803 sgd_solver.cpp:106] Iteration 12264, lr = 5e-05
I0403 11:30:55.821148  3803 solver.cpp:228] Iteration 12285, loss = 0.014608
I0403 11:30:55.821472  3803 solver.cpp:244]     Train net output #0: loss = 0.0146078 (* 1 = 0.0146078 loss)
I0403 11:30:56.034694  3803 sgd_solver.cpp:106] Iteration 12285, lr = 5e-05
I0403 11:31:11.265502  3803 solver.cpp:228] Iteration 12306, loss = 0.0103859
I0403 11:31:11.265619  3803 solver.cpp:244]     Train net output #0: loss = 0.0103858 (* 1 = 0.0103858 loss)
I0403 11:31:11.535501  3803 sgd_solver.cpp:106] Iteration 12306, lr = 5e-05
I0403 11:31:26.936789  3803 solver.cpp:228] Iteration 12327, loss = 0.00276687
I0403 11:31:26.937090  3803 solver.cpp:244]     Train net output #0: loss = 0.00276671 (* 1 = 0.00276671 loss)
I0403 11:31:27.101994  3803 sgd_solver.cpp:106] Iteration 12327, lr = 5e-05
I0403 11:31:42.485676  3803 solver.cpp:228] Iteration 12348, loss = 0.00513879
I0403 11:31:42.485780  3803 solver.cpp:244]     Train net output #0: loss = 0.00513864 (* 1 = 0.00513864 loss)
I0403 11:31:42.637728  3803 sgd_solver.cpp:106] Iteration 12348, lr = 5e-05
I0403 11:31:57.995901  3803 solver.cpp:228] Iteration 12369, loss = 0.00724022
I0403 11:31:58.006218  3803 solver.cpp:244]     Train net output #0: loss = 0.00724007 (* 1 = 0.00724007 loss)
I0403 11:31:58.179452  3803 sgd_solver.cpp:106] Iteration 12369, lr = 5e-05
I0403 11:32:13.414540  3803 solver.cpp:228] Iteration 12390, loss = 0.00165225
I0403 11:32:13.414639  3803 solver.cpp:244]     Train net output #0: loss = 0.0016521 (* 1 = 0.0016521 loss)
I0403 11:32:13.589301  3803 sgd_solver.cpp:106] Iteration 12390, lr = 5e-05
I0403 11:32:28.984946  3803 solver.cpp:228] Iteration 12411, loss = 0.00250779
I0403 11:32:28.985265  3803 solver.cpp:244]     Train net output #0: loss = 0.00250764 (* 1 = 0.00250764 loss)
I0403 11:32:29.188405  3803 sgd_solver.cpp:106] Iteration 12411, lr = 5e-05
I0403 11:32:44.511883  3803 solver.cpp:228] Iteration 12432, loss = 0.023696
I0403 11:32:44.511986  3803 solver.cpp:244]     Train net output #0: loss = 0.0236958 (* 1 = 0.0236958 loss)
I0403 11:32:44.637594  3803 sgd_solver.cpp:106] Iteration 12432, lr = 5e-05
I0403 11:32:59.912374  3803 solver.cpp:228] Iteration 12453, loss = 0.00151647
I0403 11:32:59.912658  3803 solver.cpp:244]     Train net output #0: loss = 0.00151632 (* 1 = 0.00151632 loss)
I0403 11:33:00.098266  3803 sgd_solver.cpp:106] Iteration 12453, lr = 5e-05
I0403 11:33:15.325145  3803 solver.cpp:228] Iteration 12474, loss = 0.00343726
I0403 11:33:15.325263  3803 solver.cpp:244]     Train net output #0: loss = 0.0034371 (* 1 = 0.0034371 loss)
I0403 11:33:15.567463  3803 sgd_solver.cpp:106] Iteration 12474, lr = 5e-05
I0403 11:33:30.866652  3803 solver.cpp:228] Iteration 12495, loss = 0.0177106
I0403 11:33:30.866992  3803 solver.cpp:244]     Train net output #0: loss = 0.0177105 (* 1 = 0.0177105 loss)
I0403 11:33:31.054555  3803 sgd_solver.cpp:106] Iteration 12495, lr = 5e-05
I0403 11:33:46.252097  3803 solver.cpp:228] Iteration 12516, loss = 0.0102193
I0403 11:33:46.252199  3803 solver.cpp:244]     Train net output #0: loss = 0.0102192 (* 1 = 0.0102192 loss)
I0403 11:33:46.426972  3803 sgd_solver.cpp:106] Iteration 12516, lr = 5e-05
I0403 11:34:01.577594  3803 solver.cpp:228] Iteration 12537, loss = 0.0146956
I0403 11:34:01.577898  3803 solver.cpp:244]     Train net output #0: loss = 0.0146954 (* 1 = 0.0146954 loss)
I0403 11:34:01.751823  3803 sgd_solver.cpp:106] Iteration 12537, lr = 5e-05
I0403 11:34:16.997161  3803 solver.cpp:228] Iteration 12558, loss = 0.0044122
I0403 11:34:16.997277  3803 solver.cpp:244]     Train net output #0: loss = 0.00441204 (* 1 = 0.00441204 loss)
I0403 11:34:17.210700  3803 sgd_solver.cpp:106] Iteration 12558, lr = 5e-05
I0403 11:34:32.592541  3803 solver.cpp:228] Iteration 12579, loss = 0.00520714
I0403 11:34:32.592861  3803 solver.cpp:244]     Train net output #0: loss = 0.00520698 (* 1 = 0.00520698 loss)
I0403 11:34:32.791033  3803 sgd_solver.cpp:106] Iteration 12579, lr = 5e-05
I0403 11:34:48.205569  3803 solver.cpp:228] Iteration 12600, loss = 0.0220818
I0403 11:34:48.205669  3803 solver.cpp:244]     Train net output #0: loss = 0.0220817 (* 1 = 0.0220817 loss)
I0403 11:34:48.347892  3803 sgd_solver.cpp:106] Iteration 12600, lr = 5e-05
I0403 11:34:58.626567  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_12615.caffemodel
I0403 11:35:01.349625  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_12615.solverstate
I0403 11:35:03.260860  3803 solver.cpp:337] Iteration 12615, Testing net (#0)
I0403 11:35:27.676507  3803 solver.cpp:404]     Test net output #0: accuracy = 0.972337
I0403 11:35:27.676617  3803 solver.cpp:404]     Test net output #1: loss = 0.10681 (* 1 = 0.10681 loss)
I0403 11:35:32.775403  3803 solver.cpp:228] Iteration 12621, loss = 0.00777519
I0403 11:35:32.775495  3803 solver.cpp:244]     Train net output #0: loss = 0.00777503 (* 1 = 0.00777503 loss)
I0403 11:35:32.925405  3803 sgd_solver.cpp:106] Iteration 12621, lr = 5e-05
I0403 11:35:48.588553  3803 solver.cpp:228] Iteration 12642, loss = 0.000657802
I0403 11:35:48.588845  3803 solver.cpp:244]     Train net output #0: loss = 0.000657644 (* 1 = 0.000657644 loss)
I0403 11:35:48.754977  3803 sgd_solver.cpp:106] Iteration 12642, lr = 5e-05
I0403 11:36:04.456960  3803 solver.cpp:228] Iteration 12663, loss = 0.00249943
I0403 11:36:04.457067  3803 solver.cpp:244]     Train net output #0: loss = 0.00249927 (* 1 = 0.00249927 loss)
I0403 11:36:04.630939  3803 sgd_solver.cpp:106] Iteration 12663, lr = 5e-05
I0403 11:36:19.848909  3803 solver.cpp:228] Iteration 12684, loss = 0.00399344
I0403 11:36:19.849228  3803 solver.cpp:244]     Train net output #0: loss = 0.00399327 (* 1 = 0.00399327 loss)
I0403 11:36:20.063041  3803 sgd_solver.cpp:106] Iteration 12684, lr = 5e-05
I0403 11:36:35.279878  3803 solver.cpp:228] Iteration 12705, loss = 0.00985479
I0403 11:36:35.279985  3803 solver.cpp:244]     Train net output #0: loss = 0.00985463 (* 1 = 0.00985463 loss)
I0403 11:36:35.480661  3803 sgd_solver.cpp:106] Iteration 12705, lr = 5e-05
I0403 11:36:50.966285  3803 solver.cpp:228] Iteration 12726, loss = 0.00453747
I0403 11:36:50.966601  3803 solver.cpp:244]     Train net output #0: loss = 0.00453731 (* 1 = 0.00453731 loss)
I0403 11:36:51.163245  3803 sgd_solver.cpp:106] Iteration 12726, lr = 5e-05
I0403 11:37:06.518262  3803 solver.cpp:228] Iteration 12747, loss = 0.0358639
I0403 11:37:06.518374  3803 solver.cpp:244]     Train net output #0: loss = 0.0358638 (* 1 = 0.0358638 loss)
I0403 11:37:06.703868  3803 sgd_solver.cpp:106] Iteration 12747, lr = 5e-05
I0403 11:37:22.358364  3803 solver.cpp:228] Iteration 12768, loss = 0.00485229
I0403 11:37:22.358700  3803 solver.cpp:244]     Train net output #0: loss = 0.00485212 (* 1 = 0.00485212 loss)
I0403 11:37:22.527484  3803 sgd_solver.cpp:106] Iteration 12768, lr = 5e-05
I0403 11:37:37.854483  3803 solver.cpp:228] Iteration 12789, loss = 0.00304968
I0403 11:37:37.854598  3803 solver.cpp:244]     Train net output #0: loss = 0.00304951 (* 1 = 0.00304951 loss)
I0403 11:37:38.053421  3803 sgd_solver.cpp:106] Iteration 12789, lr = 5e-05
I0403 11:37:53.441457  3803 solver.cpp:228] Iteration 12810, loss = 0.00490092
I0403 11:37:53.441711  3803 solver.cpp:244]     Train net output #0: loss = 0.00490076 (* 1 = 0.00490076 loss)
I0403 11:37:53.613546  3803 sgd_solver.cpp:106] Iteration 12810, lr = 5e-05
I0403 11:38:09.141710  3803 solver.cpp:228] Iteration 12831, loss = 0.00232518
I0403 11:38:09.141816  3803 solver.cpp:244]     Train net output #0: loss = 0.00232502 (* 1 = 0.00232502 loss)
I0403 11:38:09.314162  3803 sgd_solver.cpp:106] Iteration 12831, lr = 5e-05
I0403 11:38:24.795624  3803 solver.cpp:228] Iteration 12852, loss = 0.0144361
I0403 11:38:24.795941  3803 solver.cpp:244]     Train net output #0: loss = 0.014436 (* 1 = 0.014436 loss)
I0403 11:38:25.035511  3803 sgd_solver.cpp:106] Iteration 12852, lr = 5e-05
I0403 11:38:40.183434  3803 solver.cpp:228] Iteration 12873, loss = 0.002453
I0403 11:38:40.183537  3803 solver.cpp:244]     Train net output #0: loss = 0.00245283 (* 1 = 0.00245283 loss)
I0403 11:38:40.362732  3803 sgd_solver.cpp:106] Iteration 12873, lr = 5e-05
I0403 11:38:55.595526  3803 solver.cpp:228] Iteration 12894, loss = 0.0134771
I0403 11:38:55.595851  3803 solver.cpp:244]     Train net output #0: loss = 0.0134769 (* 1 = 0.0134769 loss)
I0403 11:38:55.801345  3803 sgd_solver.cpp:106] Iteration 12894, lr = 5e-05
I0403 11:39:11.201406  3803 solver.cpp:228] Iteration 12915, loss = 0.0017558
I0403 11:39:11.201508  3803 solver.cpp:244]     Train net output #0: loss = 0.00175563 (* 1 = 0.00175563 loss)
I0403 11:39:11.372800  3803 sgd_solver.cpp:106] Iteration 12915, lr = 5e-05
I0403 11:39:26.558621  3803 solver.cpp:228] Iteration 12936, loss = 0.0118737
I0403 11:39:26.558953  3803 solver.cpp:244]     Train net output #0: loss = 0.0118735 (* 1 = 0.0118735 loss)
I0403 11:39:26.709429  3803 sgd_solver.cpp:106] Iteration 12936, lr = 5e-05
I0403 11:39:42.435403  3803 solver.cpp:228] Iteration 12957, loss = 0.0116307
I0403 11:39:42.435505  3803 solver.cpp:244]     Train net output #0: loss = 0.0116306 (* 1 = 0.0116306 loss)
I0403 11:39:42.614310  3803 sgd_solver.cpp:106] Iteration 12957, lr = 5e-05
I0403 11:39:58.148604  3803 solver.cpp:228] Iteration 12978, loss = 0.00495397
I0403 11:39:58.148926  3803 solver.cpp:244]     Train net output #0: loss = 0.0049538 (* 1 = 0.0049538 loss)
I0403 11:39:58.297760  3803 sgd_solver.cpp:106] Iteration 12978, lr = 5e-05
I0403 11:40:13.802093  3803 solver.cpp:228] Iteration 12999, loss = 0.0135305
I0403 11:40:13.802207  3803 solver.cpp:244]     Train net output #0: loss = 0.0135304 (* 1 = 0.0135304 loss)
I0403 11:40:13.997577  3803 sgd_solver.cpp:106] Iteration 12999, lr = 5e-05
I0403 11:40:29.502310  3803 solver.cpp:228] Iteration 13020, loss = 0.0130207
I0403 11:40:29.502622  3803 solver.cpp:244]     Train net output #0: loss = 0.0130206 (* 1 = 0.0130206 loss)
I0403 11:40:29.675631  3803 sgd_solver.cpp:106] Iteration 13020, lr = 5e-05
I0403 11:40:44.782538  3803 solver.cpp:228] Iteration 13041, loss = 0.00393178
I0403 11:40:44.782639  3803 solver.cpp:244]     Train net output #0: loss = 0.0039316 (* 1 = 0.0039316 loss)
I0403 11:40:44.961796  3803 sgd_solver.cpp:106] Iteration 13041, lr = 5e-05
I0403 11:40:50.881386  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_13050.caffemodel
I0403 11:40:53.684739  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_13050.solverstate
I0403 11:40:55.576323  3803 solver.cpp:337] Iteration 13050, Testing net (#0)
I0403 11:41:19.989291  3803 solver.cpp:404]     Test net output #0: accuracy = 0.972336
I0403 11:41:19.989681  3803 solver.cpp:404]     Test net output #1: loss = 0.107716 (* 1 = 0.107716 loss)
I0403 11:41:25.085974  3803 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_13057.caffemodel
I0403 11:41:27.866766  3803 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_train_from_scratch/snapshots__iter_13057.solverstate
I0403 11:41:29.760128  3803 solver.cpp:322] Optimization Done.
I0403 11:41:29.844808  3803 caffe.cpp:222] Optimization Done.
