I0403 02:30:27.993376  4269 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0403 02:30:27.994027  4269 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0403 02:30:27.994076  4269 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0403 02:30:35.896348  4269 caffe.cpp:185] Using GPUs 0, 1
I0403 02:30:35.897927  4269 caffe.cpp:190] GPU 0: Tesla K40m
I0403 02:30:35.899379  4269 caffe.cpp:190] GPU 1: Tesla K40m
I0403 02:30:37.007812  4269 solver.cpp:48] Initializing solver from parameters: 
test_iter: 107
test_interval: 435
base_lr: 0.005
display: 21
max_iter: 13057
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 4352
snapshot: 435
snapshot_prefix: "/scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots_"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
type: "SGD"
I0403 02:30:37.048496  4269 solver.cpp:91] Creating training net from net file: train_val.prototxt
I0403 02:30:37.058603  4269 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0403 02:30:37.058681  4269 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0403 02:30:37.059546  4269 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/train_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
I0403 02:30:37.061421  4269 layer_factory.hpp:77] Creating layer data
I0403 02:30:37.062430  4269 net.cpp:91] Creating Layer data
I0403 02:30:37.062546  4269 net.cpp:399] data -> data
I0403 02:30:37.062675  4269 net.cpp:399] data -> label
I0403 02:30:37.062748  4269 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto
I0403 02:30:37.094990  4275 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-80-20/train_db
I0403 02:30:37.109391  4269 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:37.246944  4269 net.cpp:141] Setting up data
I0403 02:30:37.247059  4269 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:37.247087  4269 net.cpp:148] Top shape: 100 (100)
I0403 02:30:37.247107  4269 net.cpp:156] Memory required for data: 61835200
I0403 02:30:37.247143  4269 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:37.247196  4269 net.cpp:91] Creating Layer conv1
I0403 02:30:37.247225  4269 net.cpp:425] conv1 <- data
I0403 02:30:37.247268  4269 net.cpp:399] conv1 -> conv1
I0403 02:30:37.256680  4269 net.cpp:141] Setting up conv1
I0403 02:30:37.256718  4269 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.256739  4269 net.cpp:156] Memory required for data: 177995200
I0403 02:30:37.256798  4269 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:37.256849  4269 net.cpp:91] Creating Layer relu1
I0403 02:30:37.256872  4269 net.cpp:425] relu1 <- conv1
I0403 02:30:37.256896  4269 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:37.256940  4269 net.cpp:141] Setting up relu1
I0403 02:30:37.256966  4269 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.256985  4269 net.cpp:156] Memory required for data: 294155200
I0403 02:30:37.257005  4269 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:37.257030  4269 net.cpp:91] Creating Layer norm1
I0403 02:30:37.257097  4269 net.cpp:425] norm1 <- conv1
I0403 02:30:37.257119  4269 net.cpp:399] norm1 -> norm1
I0403 02:30:37.257257  4269 net.cpp:141] Setting up norm1
I0403 02:30:37.257287  4269 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:37.257305  4269 net.cpp:156] Memory required for data: 410315200
I0403 02:30:37.257324  4269 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:37.257349  4269 net.cpp:91] Creating Layer pool1
I0403 02:30:37.257369  4269 net.cpp:425] pool1 <- norm1
I0403 02:30:37.257390  4269 net.cpp:399] pool1 -> pool1
I0403 02:30:37.257479  4269 net.cpp:141] Setting up pool1
I0403 02:30:37.257510  4269 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:37.257529  4269 net.cpp:156] Memory required for data: 438308800
I0403 02:30:37.257546  4269 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:37.257572  4269 net.cpp:91] Creating Layer conv2
I0403 02:30:37.257593  4269 net.cpp:425] conv2 <- pool1
I0403 02:30:37.257617  4269 net.cpp:399] conv2 -> conv2
I0403 02:30:37.257894  4277 blocking_queue.cpp:50] Waiting for data
I0403 02:30:37.277535  4269 net.cpp:141] Setting up conv2
I0403 02:30:37.277573  4269 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.277595  4269 net.cpp:156] Memory required for data: 512958400
I0403 02:30:37.277619  4269 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:37.277643  4269 net.cpp:91] Creating Layer relu2
I0403 02:30:37.277664  4269 net.cpp:425] relu2 <- conv2
I0403 02:30:37.277688  4269 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:37.277710  4269 net.cpp:141] Setting up relu2
I0403 02:30:37.277732  4269 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.277750  4269 net.cpp:156] Memory required for data: 587608000
I0403 02:30:37.277768  4269 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:37.277791  4269 net.cpp:91] Creating Layer norm2
I0403 02:30:37.277809  4269 net.cpp:425] norm2 <- conv2
I0403 02:30:37.277832  4269 net.cpp:399] norm2 -> norm2
I0403 02:30:37.277890  4269 net.cpp:141] Setting up norm2
I0403 02:30:37.277920  4269 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:37.277938  4269 net.cpp:156] Memory required for data: 662257600
I0403 02:30:37.277956  4269 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:37.277981  4269 net.cpp:91] Creating Layer pool2
I0403 02:30:37.278002  4269 net.cpp:425] pool2 <- norm2
I0403 02:30:37.278025  4269 net.cpp:399] pool2 -> pool2
I0403 02:30:37.278079  4269 net.cpp:141] Setting up pool2
I0403 02:30:37.278105  4269 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.278123  4269 net.cpp:156] Memory required for data: 679563200
I0403 02:30:37.278141  4269 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:37.278168  4269 net.cpp:91] Creating Layer conv3
I0403 02:30:37.278189  4269 net.cpp:425] conv3 <- pool2
I0403 02:30:37.278214  4269 net.cpp:399] conv3 -> conv3
I0403 02:30:37.319789  4269 net.cpp:141] Setting up conv3
I0403 02:30:37.319830  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.319851  4269 net.cpp:156] Memory required for data: 705521600
I0403 02:30:37.319876  4269 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:37.319901  4269 net.cpp:91] Creating Layer relu3
I0403 02:30:37.319921  4269 net.cpp:425] relu3 <- conv3
I0403 02:30:37.319944  4269 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:37.319969  4269 net.cpp:141] Setting up relu3
I0403 02:30:37.319993  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.320009  4269 net.cpp:156] Memory required for data: 731480000
I0403 02:30:37.320026  4269 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:37.320053  4269 net.cpp:91] Creating Layer conv4
I0403 02:30:37.320075  4269 net.cpp:425] conv4 <- conv3
I0403 02:30:37.320098  4269 net.cpp:399] conv4 -> conv4
I0403 02:30:37.351475  4269 net.cpp:141] Setting up conv4
I0403 02:30:37.351512  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.351533  4269 net.cpp:156] Memory required for data: 757438400
I0403 02:30:37.351578  4269 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:37.351604  4269 net.cpp:91] Creating Layer relu4
I0403 02:30:37.351625  4269 net.cpp:425] relu4 <- conv4
I0403 02:30:37.351649  4269 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:37.351672  4269 net.cpp:141] Setting up relu4
I0403 02:30:37.351693  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:37.351711  4269 net.cpp:156] Memory required for data: 783396800
I0403 02:30:37.351729  4269 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:37.351758  4269 net.cpp:91] Creating Layer conv5
I0403 02:30:37.351776  4269 net.cpp:425] conv5 <- conv4
I0403 02:30:37.351800  4269 net.cpp:399] conv5 -> conv5
I0403 02:30:37.372849  4269 net.cpp:141] Setting up conv5
I0403 02:30:37.372908  4269 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.372952  4269 net.cpp:156] Memory required for data: 800702400
I0403 02:30:37.373009  4269 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:37.373059  4269 net.cpp:91] Creating Layer relu5
I0403 02:30:37.373105  4269 net.cpp:425] relu5 <- conv5
I0403 02:30:37.373126  4269 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:37.373152  4269 net.cpp:141] Setting up relu5
I0403 02:30:37.373173  4269 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:37.373191  4269 net.cpp:156] Memory required for data: 818008000
I0403 02:30:37.373208  4269 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:37.373231  4269 net.cpp:91] Creating Layer pool5
I0403 02:30:37.373256  4269 net.cpp:425] pool5 <- conv5
I0403 02:30:37.373284  4269 net.cpp:399] pool5 -> pool5
I0403 02:30:37.373345  4269 net.cpp:141] Setting up pool5
I0403 02:30:37.373373  4269 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:37.373391  4269 net.cpp:156] Memory required for data: 821694400
I0403 02:30:37.373409  4269 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:37.373461  4269 net.cpp:91] Creating Layer fc6
I0403 02:30:37.373486  4269 net.cpp:425] fc6 <- pool5
I0403 02:30:37.373512  4269 net.cpp:399] fc6 -> fc6
I0403 02:30:38.855218  4269 net.cpp:141] Setting up fc6
I0403 02:30:38.855300  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.855317  4269 net.cpp:156] Memory required for data: 823332800
I0403 02:30:38.855340  4269 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:38.855366  4269 net.cpp:91] Creating Layer relu6
I0403 02:30:38.855383  4269 net.cpp:425] relu6 <- fc6
I0403 02:30:38.855402  4269 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:38.855423  4269 net.cpp:141] Setting up relu6
I0403 02:30:38.855440  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.855453  4269 net.cpp:156] Memory required for data: 824971200
I0403 02:30:38.855468  4269 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:38.855521  4269 net.cpp:91] Creating Layer drop6
I0403 02:30:38.855540  4269 net.cpp:425] drop6 <- fc6
I0403 02:30:38.855557  4269 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:38.855613  4269 net.cpp:141] Setting up drop6
I0403 02:30:38.855638  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:38.855655  4269 net.cpp:156] Memory required for data: 826609600
I0403 02:30:38.855669  4269 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:38.855689  4269 net.cpp:91] Creating Layer fc7
I0403 02:30:38.855703  4269 net.cpp:425] fc7 <- fc6
I0403 02:30:38.855721  4269 net.cpp:399] fc7 -> fc7
I0403 02:30:39.458298  4269 net.cpp:141] Setting up fc7
I0403 02:30:39.458379  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.458395  4269 net.cpp:156] Memory required for data: 828248000
I0403 02:30:39.458417  4269 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:39.458441  4269 net.cpp:91] Creating Layer relu7
I0403 02:30:39.458459  4269 net.cpp:425] relu7 <- fc7
I0403 02:30:39.458478  4269 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:39.458500  4269 net.cpp:141] Setting up relu7
I0403 02:30:39.458518  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.458533  4269 net.cpp:156] Memory required for data: 829886400
I0403 02:30:39.458546  4269 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:39.458609  4269 net.cpp:91] Creating Layer drop7
I0403 02:30:39.458627  4269 net.cpp:425] drop7 <- fc7
I0403 02:30:39.458645  4269 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:39.458685  4269 net.cpp:141] Setting up drop7
I0403 02:30:39.458706  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:39.458721  4269 net.cpp:156] Memory required for data: 831524800
I0403 02:30:39.458735  4269 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:39.458755  4269 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:39.458770  4269 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:39.458791  4269 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:39.464916  4269 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:39.464944  4269 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:39.464962  4269 net.cpp:156] Memory required for data: 831540000
I0403 02:30:39.464979  4269 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.465030  4269 net.cpp:91] Creating Layer loss
I0403 02:30:39.465051  4269 net.cpp:425] loss <- fc8_plantvillage
I0403 02:30:39.465067  4269 net.cpp:425] loss <- label
I0403 02:30:39.465088  4269 net.cpp:399] loss -> loss
I0403 02:30:39.465128  4269 layer_factory.hpp:77] Creating layer loss
I0403 02:30:39.465268  4269 net.cpp:141] Setting up loss
I0403 02:30:39.465292  4269 net.cpp:148] Top shape: (1)
I0403 02:30:39.465307  4269 net.cpp:151]     with loss weight 1
I0403 02:30:39.465387  4269 net.cpp:156] Memory required for data: 831540004
I0403 02:30:39.465404  4269 net.cpp:217] loss needs backward computation.
I0403 02:30:39.465418  4269 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:39.465432  4269 net.cpp:217] drop7 needs backward computation.
I0403 02:30:39.465446  4269 net.cpp:217] relu7 needs backward computation.
I0403 02:30:39.465459  4269 net.cpp:217] fc7 needs backward computation.
I0403 02:30:39.465473  4269 net.cpp:217] drop6 needs backward computation.
I0403 02:30:39.465487  4269 net.cpp:217] relu6 needs backward computation.
I0403 02:30:39.465500  4269 net.cpp:217] fc6 needs backward computation.
I0403 02:30:39.465514  4269 net.cpp:217] pool5 needs backward computation.
I0403 02:30:39.465529  4269 net.cpp:217] relu5 needs backward computation.
I0403 02:30:39.465549  4269 net.cpp:217] conv5 needs backward computation.
I0403 02:30:39.465564  4269 net.cpp:217] relu4 needs backward computation.
I0403 02:30:39.465577  4269 net.cpp:217] conv4 needs backward computation.
I0403 02:30:39.465591  4269 net.cpp:217] relu3 needs backward computation.
I0403 02:30:39.465605  4269 net.cpp:217] conv3 needs backward computation.
I0403 02:30:39.465618  4269 net.cpp:217] pool2 needs backward computation.
I0403 02:30:39.465632  4269 net.cpp:217] norm2 needs backward computation.
I0403 02:30:39.465646  4269 net.cpp:217] relu2 needs backward computation.
I0403 02:30:39.465661  4269 net.cpp:217] conv2 needs backward computation.
I0403 02:30:39.465674  4269 net.cpp:217] pool1 needs backward computation.
I0403 02:30:39.465688  4269 net.cpp:217] norm1 needs backward computation.
I0403 02:30:39.465703  4269 net.cpp:217] relu1 needs backward computation.
I0403 02:30:39.465715  4269 net.cpp:217] conv1 needs backward computation.
I0403 02:30:39.465730  4269 net.cpp:219] data does not need backward computation.
I0403 02:30:39.465745  4269 net.cpp:261] This network produces output loss
I0403 02:30:39.465771  4269 net.cpp:274] Network initialization done.
I0403 02:30:39.466902  4269 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I0403 02:30:39.466959  4269 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0403 02:30:39.467615  4269 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_file: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto"
  }
  data_param {
    source: "/home/mohanty/data/final_dataset/lmdb/segmented-80-20/test_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_plantvillage"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_plantvillage"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 38
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_plantvillage"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0403 02:30:39.467788  4269 layer_factory.hpp:77] Creating layer data
I0403 02:30:39.467931  4269 net.cpp:91] Creating Layer data
I0403 02:30:39.467960  4269 net.cpp:399] data -> data
I0403 02:30:39.467985  4269 net.cpp:399] data -> label
I0403 02:30:39.468008  4269 data_transformer.cpp:25] Loading mean file from: /home/mohanty/data/final_dataset/lmdb/segmented-80-20/mean.binaryproto
I0403 02:30:39.483150  4279 db_lmdb.cpp:38] Opened lmdb /home/mohanty/data/final_dataset/lmdb/segmented-80-20/test_db
I0403 02:30:39.488418  4269 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:39.628876  4269 net.cpp:141] Setting up data
I0403 02:30:39.628957  4269 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0403 02:30:39.628979  4269 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.628994  4269 net.cpp:156] Memory required for data: 61835200
I0403 02:30:39.629012  4269 layer_factory.hpp:77] Creating layer label_data_1_split
I0403 02:30:39.629041  4269 net.cpp:91] Creating Layer label_data_1_split
I0403 02:30:39.629060  4269 net.cpp:425] label_data_1_split <- label
I0403 02:30:39.629081  4269 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0403 02:30:39.629106  4269 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0403 02:30:39.629163  4269 net.cpp:141] Setting up label_data_1_split
I0403 02:30:39.629185  4269 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.629202  4269 net.cpp:148] Top shape: 100 (100)
I0403 02:30:39.629223  4269 net.cpp:156] Memory required for data: 61836000
I0403 02:30:39.629240  4269 layer_factory.hpp:77] Creating layer conv1
I0403 02:30:39.629267  4269 net.cpp:91] Creating Layer conv1
I0403 02:30:39.629286  4269 net.cpp:425] conv1 <- data
I0403 02:30:39.629307  4269 net.cpp:399] conv1 -> conv1
I0403 02:30:39.630812  4269 net.cpp:141] Setting up conv1
I0403 02:30:39.630841  4269 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.630856  4269 net.cpp:156] Memory required for data: 177996000
I0403 02:30:39.630880  4269 layer_factory.hpp:77] Creating layer relu1
I0403 02:30:39.630899  4269 net.cpp:91] Creating Layer relu1
I0403 02:30:39.630916  4269 net.cpp:425] relu1 <- conv1
I0403 02:30:39.630934  4269 net.cpp:386] relu1 -> conv1 (in-place)
I0403 02:30:39.630954  4269 net.cpp:141] Setting up relu1
I0403 02:30:39.630971  4269 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.630986  4269 net.cpp:156] Memory required for data: 294156000
I0403 02:30:39.631001  4269 layer_factory.hpp:77] Creating layer norm1
I0403 02:30:39.631022  4269 net.cpp:91] Creating Layer norm1
I0403 02:30:39.631039  4269 net.cpp:425] norm1 <- conv1
I0403 02:30:39.631058  4269 net.cpp:399] norm1 -> norm1
I0403 02:30:39.636939  4269 net.cpp:141] Setting up norm1
I0403 02:30:39.636976  4269 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0403 02:30:39.636993  4269 net.cpp:156] Memory required for data: 410316000
I0403 02:30:39.637009  4269 layer_factory.hpp:77] Creating layer pool1
I0403 02:30:39.637030  4269 net.cpp:91] Creating Layer pool1
I0403 02:30:39.637048  4269 net.cpp:425] pool1 <- norm1
I0403 02:30:39.637068  4269 net.cpp:399] pool1 -> pool1
I0403 02:30:39.637118  4269 net.cpp:141] Setting up pool1
I0403 02:30:39.637142  4269 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0403 02:30:39.637157  4269 net.cpp:156] Memory required for data: 438309600
I0403 02:30:39.637202  4269 layer_factory.hpp:77] Creating layer conv2
I0403 02:30:39.637233  4269 net.cpp:91] Creating Layer conv2
I0403 02:30:39.637251  4269 net.cpp:425] conv2 <- pool1
I0403 02:30:39.637272  4269 net.cpp:399] conv2 -> conv2
I0403 02:30:39.649220  4269 net.cpp:141] Setting up conv2
I0403 02:30:39.649251  4269 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.649268  4269 net.cpp:156] Memory required for data: 512959200
I0403 02:30:39.649291  4269 layer_factory.hpp:77] Creating layer relu2
I0403 02:30:39.649312  4269 net.cpp:91] Creating Layer relu2
I0403 02:30:39.649330  4269 net.cpp:425] relu2 <- conv2
I0403 02:30:39.649348  4269 net.cpp:386] relu2 -> conv2 (in-place)
I0403 02:30:39.649369  4269 net.cpp:141] Setting up relu2
I0403 02:30:39.649387  4269 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.649402  4269 net.cpp:156] Memory required for data: 587608800
I0403 02:30:39.649417  4269 layer_factory.hpp:77] Creating layer norm2
I0403 02:30:39.649436  4269 net.cpp:91] Creating Layer norm2
I0403 02:30:39.649454  4269 net.cpp:425] norm2 <- conv2
I0403 02:30:39.649472  4269 net.cpp:399] norm2 -> norm2
I0403 02:30:39.649521  4269 net.cpp:141] Setting up norm2
I0403 02:30:39.649545  4269 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0403 02:30:39.649561  4269 net.cpp:156] Memory required for data: 662258400
I0403 02:30:39.649576  4269 layer_factory.hpp:77] Creating layer pool2
I0403 02:30:39.649595  4269 net.cpp:91] Creating Layer pool2
I0403 02:30:39.649611  4269 net.cpp:425] pool2 <- norm2
I0403 02:30:39.649631  4269 net.cpp:399] pool2 -> pool2
I0403 02:30:39.649675  4269 net.cpp:141] Setting up pool2
I0403 02:30:39.649698  4269 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.649713  4269 net.cpp:156] Memory required for data: 679564000
I0403 02:30:39.649729  4269 layer_factory.hpp:77] Creating layer conv3
I0403 02:30:39.649750  4269 net.cpp:91] Creating Layer conv3
I0403 02:30:39.649767  4269 net.cpp:425] conv3 <- pool2
I0403 02:30:39.649786  4269 net.cpp:399] conv3 -> conv3
I0403 02:30:39.684756  4269 net.cpp:141] Setting up conv3
I0403 02:30:39.684836  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.684936  4269 net.cpp:156] Memory required for data: 705522400
I0403 02:30:39.685029  4269 layer_factory.hpp:77] Creating layer relu3
I0403 02:30:39.685075  4269 net.cpp:91] Creating Layer relu3
I0403 02:30:39.685093  4269 net.cpp:425] relu3 <- conv3
I0403 02:30:39.685112  4269 net.cpp:386] relu3 -> conv3 (in-place)
I0403 02:30:39.685226  4269 net.cpp:141] Setting up relu3
I0403 02:30:39.685258  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.685315  4269 net.cpp:156] Memory required for data: 731480800
I0403 02:30:39.685359  4269 layer_factory.hpp:77] Creating layer conv4
I0403 02:30:39.685413  4269 net.cpp:91] Creating Layer conv4
I0403 02:30:39.685433  4269 net.cpp:425] conv4 <- conv3
I0403 02:30:39.685480  4269 net.cpp:399] conv4 -> conv4
I0403 02:30:39.711416  4269 net.cpp:141] Setting up conv4
I0403 02:30:39.711457  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.711498  4269 net.cpp:156] Memory required for data: 757439200
I0403 02:30:39.711541  4269 layer_factory.hpp:77] Creating layer relu4
I0403 02:30:39.711576  4269 net.cpp:91] Creating Layer relu4
I0403 02:30:39.711635  4269 net.cpp:425] relu4 <- conv4
I0403 02:30:39.711706  4269 net.cpp:386] relu4 -> conv4 (in-place)
I0403 02:30:39.711736  4269 net.cpp:141] Setting up relu4
I0403 02:30:39.711757  4269 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0403 02:30:39.711772  4269 net.cpp:156] Memory required for data: 783397600
I0403 02:30:39.711788  4269 layer_factory.hpp:77] Creating layer conv5
I0403 02:30:39.711833  4269 net.cpp:91] Creating Layer conv5
I0403 02:30:39.711858  4269 net.cpp:425] conv5 <- conv4
I0403 02:30:39.711879  4269 net.cpp:399] conv5 -> conv5
I0403 02:30:39.729563  4269 net.cpp:141] Setting up conv5
I0403 02:30:39.729601  4269 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.729647  4269 net.cpp:156] Memory required for data: 800703200
I0403 02:30:39.729673  4269 layer_factory.hpp:77] Creating layer relu5
I0403 02:30:39.729693  4269 net.cpp:91] Creating Layer relu5
I0403 02:30:39.729710  4269 net.cpp:425] relu5 <- conv5
I0403 02:30:39.729728  4269 net.cpp:386] relu5 -> conv5 (in-place)
I0403 02:30:39.729749  4269 net.cpp:141] Setting up relu5
I0403 02:30:39.729768  4269 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0403 02:30:39.729782  4269 net.cpp:156] Memory required for data: 818008800
I0403 02:30:39.729799  4269 layer_factory.hpp:77] Creating layer pool5
I0403 02:30:39.729822  4269 net.cpp:91] Creating Layer pool5
I0403 02:30:39.729851  4269 net.cpp:425] pool5 <- conv5
I0403 02:30:39.729876  4269 net.cpp:399] pool5 -> pool5
I0403 02:30:39.729933  4269 net.cpp:141] Setting up pool5
I0403 02:30:39.729957  4269 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0403 02:30:39.729974  4269 net.cpp:156] Memory required for data: 821695200
I0403 02:30:39.729989  4269 layer_factory.hpp:77] Creating layer fc6
I0403 02:30:39.730010  4269 net.cpp:91] Creating Layer fc6
I0403 02:30:39.730029  4269 net.cpp:425] fc6 <- pool5
I0403 02:30:39.730048  4269 net.cpp:399] fc6 -> fc6
I0403 02:30:41.129081  4269 net.cpp:141] Setting up fc6
I0403 02:30:41.129159  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.129176  4269 net.cpp:156] Memory required for data: 823333600
I0403 02:30:41.129199  4269 layer_factory.hpp:77] Creating layer relu6
I0403 02:30:41.129230  4269 net.cpp:91] Creating Layer relu6
I0403 02:30:41.129250  4269 net.cpp:425] relu6 <- fc6
I0403 02:30:41.129269  4269 net.cpp:386] relu6 -> fc6 (in-place)
I0403 02:30:41.129292  4269 net.cpp:141] Setting up relu6
I0403 02:30:41.129308  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.129333  4269 net.cpp:156] Memory required for data: 824972000
I0403 02:30:41.129346  4269 layer_factory.hpp:77] Creating layer drop6
I0403 02:30:41.129365  4269 net.cpp:91] Creating Layer drop6
I0403 02:30:41.129384  4269 net.cpp:425] drop6 <- fc6
I0403 02:30:41.129402  4269 net.cpp:386] drop6 -> fc6 (in-place)
I0403 02:30:41.129441  4269 net.cpp:141] Setting up drop6
I0403 02:30:41.129462  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.129477  4269 net.cpp:156] Memory required for data: 826610400
I0403 02:30:41.129492  4269 layer_factory.hpp:77] Creating layer fc7
I0403 02:30:41.129514  4269 net.cpp:91] Creating Layer fc7
I0403 02:30:41.129530  4269 net.cpp:425] fc7 <- fc6
I0403 02:30:41.129549  4269 net.cpp:399] fc7 -> fc7
I0403 02:30:41.736834  4269 net.cpp:141] Setting up fc7
I0403 02:30:41.736913  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.736929  4269 net.cpp:156] Memory required for data: 828248800
I0403 02:30:41.736951  4269 layer_factory.hpp:77] Creating layer relu7
I0403 02:30:41.736975  4269 net.cpp:91] Creating Layer relu7
I0403 02:30:41.737002  4269 net.cpp:425] relu7 <- fc7
I0403 02:30:41.737023  4269 net.cpp:386] relu7 -> fc7 (in-place)
I0403 02:30:41.737046  4269 net.cpp:141] Setting up relu7
I0403 02:30:41.737061  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.737074  4269 net.cpp:156] Memory required for data: 829887200
I0403 02:30:41.737088  4269 layer_factory.hpp:77] Creating layer drop7
I0403 02:30:41.737110  4269 net.cpp:91] Creating Layer drop7
I0403 02:30:41.737126  4269 net.cpp:425] drop7 <- fc7
I0403 02:30:41.737143  4269 net.cpp:386] drop7 -> fc7 (in-place)
I0403 02:30:41.737184  4269 net.cpp:141] Setting up drop7
I0403 02:30:41.737208  4269 net.cpp:148] Top shape: 100 4096 (409600)
I0403 02:30:41.737224  4269 net.cpp:156] Memory required for data: 831525600
I0403 02:30:41.737238  4269 layer_factory.hpp:77] Creating layer fc8_plantvillage
I0403 02:30:41.737258  4269 net.cpp:91] Creating Layer fc8_plantvillage
I0403 02:30:41.737273  4269 net.cpp:425] fc8_plantvillage <- fc7
I0403 02:30:41.737303  4269 net.cpp:399] fc8_plantvillage -> fc8_plantvillage
I0403 02:30:41.743269  4269 net.cpp:141] Setting up fc8_plantvillage
I0403 02:30:41.743300  4269 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.743366  4269 net.cpp:156] Memory required for data: 831540800
I0403 02:30:41.743386  4269 layer_factory.hpp:77] Creating layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.743404  4269 net.cpp:91] Creating Layer fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.743422  4269 net.cpp:425] fc8_plantvillage_fc8_plantvillage_0_split <- fc8_plantvillage
I0403 02:30:41.743438  4269 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.743458  4269 net.cpp:399] fc8_plantvillage_fc8_plantvillage_0_split -> fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.743507  4269 net.cpp:141] Setting up fc8_plantvillage_fc8_plantvillage_0_split
I0403 02:30:41.743530  4269 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.743546  4269 net.cpp:148] Top shape: 100 38 (3800)
I0403 02:30:41.743559  4269 net.cpp:156] Memory required for data: 831571200
I0403 02:30:41.743573  4269 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.743590  4269 net.cpp:91] Creating Layer loss
I0403 02:30:41.743605  4269 net.cpp:425] loss <- fc8_plantvillage_fc8_plantvillage_0_split_0
I0403 02:30:41.743621  4269 net.cpp:425] loss <- label_data_1_split_0
I0403 02:30:41.743641  4269 net.cpp:399] loss -> loss
I0403 02:30:41.743664  4269 layer_factory.hpp:77] Creating layer loss
I0403 02:30:41.743759  4269 net.cpp:141] Setting up loss
I0403 02:30:41.743782  4269 net.cpp:148] Top shape: (1)
I0403 02:30:41.743798  4269 net.cpp:151]     with loss weight 1
I0403 02:30:41.743820  4269 net.cpp:156] Memory required for data: 831571204
I0403 02:30:41.743834  4269 layer_factory.hpp:77] Creating layer accuracy
I0403 02:30:41.743854  4269 net.cpp:91] Creating Layer accuracy
I0403 02:30:41.743870  4269 net.cpp:425] accuracy <- fc8_plantvillage_fc8_plantvillage_0_split_1
I0403 02:30:41.743886  4269 net.cpp:425] accuracy <- label_data_1_split_1
I0403 02:30:41.743904  4269 net.cpp:399] accuracy -> accuracy
I0403 02:30:41.743957  4269 net.cpp:141] Setting up accuracy
I0403 02:30:41.743978  4269 net.cpp:148] Top shape: (1)
I0403 02:30:41.743993  4269 net.cpp:156] Memory required for data: 831571208
I0403 02:30:41.744006  4269 net.cpp:219] accuracy does not need backward computation.
I0403 02:30:41.744020  4269 net.cpp:217] loss needs backward computation.
I0403 02:30:41.744035  4269 net.cpp:217] fc8_plantvillage_fc8_plantvillage_0_split needs backward computation.
I0403 02:30:41.744050  4269 net.cpp:217] fc8_plantvillage needs backward computation.
I0403 02:30:41.744062  4269 net.cpp:217] drop7 needs backward computation.
I0403 02:30:41.744076  4269 net.cpp:217] relu7 needs backward computation.
I0403 02:30:41.744088  4269 net.cpp:217] fc7 needs backward computation.
I0403 02:30:41.744102  4269 net.cpp:217] drop6 needs backward computation.
I0403 02:30:41.744115  4269 net.cpp:217] relu6 needs backward computation.
I0403 02:30:41.744128  4269 net.cpp:217] fc6 needs backward computation.
I0403 02:30:41.744143  4269 net.cpp:217] pool5 needs backward computation.
I0403 02:30:41.744156  4269 net.cpp:217] relu5 needs backward computation.
I0403 02:30:41.744168  4269 net.cpp:217] conv5 needs backward computation.
I0403 02:30:41.744181  4269 net.cpp:217] relu4 needs backward computation.
I0403 02:30:41.744194  4269 net.cpp:217] conv4 needs backward computation.
I0403 02:30:41.744215  4269 net.cpp:217] relu3 needs backward computation.
I0403 02:30:41.744231  4269 net.cpp:217] conv3 needs backward computation.
I0403 02:30:41.744246  4269 net.cpp:217] pool2 needs backward computation.
I0403 02:30:41.744261  4269 net.cpp:217] norm2 needs backward computation.
I0403 02:30:41.744273  4269 net.cpp:217] relu2 needs backward computation.
I0403 02:30:41.744287  4269 net.cpp:217] conv2 needs backward computation.
I0403 02:30:41.744302  4269 net.cpp:217] pool1 needs backward computation.
I0403 02:30:41.744314  4269 net.cpp:217] norm1 needs backward computation.
I0403 02:30:41.744328  4269 net.cpp:217] relu1 needs backward computation.
I0403 02:30:41.744345  4269 net.cpp:217] conv1 needs backward computation.
I0403 02:30:41.747421  4269 net.cpp:219] label_data_1_split does not need backward computation.
I0403 02:30:41.747442  4269 net.cpp:219] data does not need backward computation.
I0403 02:30:41.747457  4269 net.cpp:261] This network produces output accuracy
I0403 02:30:41.747470  4269 net.cpp:261] This network produces output loss
I0403 02:30:41.747503  4269 net.cpp:274] Network initialization done.
I0403 02:30:41.747617  4269 solver.cpp:60] Solver scaffolding done.
I0403 02:30:41.748073  4269 caffe.cpp:129] Finetuning from /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.184870  4269 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.184943  4269 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:43.184975  4269 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:43.185029  4269 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:43.557579  4269 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:43.593041  4269 net.cpp:753] Ignoring source layer fc8
I0403 02:30:44.696101  4269 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:44.696177  4269 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W0403 02:30:44.696216  4269 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0403 02:30:44.696265  4269 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/mohanty/caffe_experiments/AWS_FRESH_RUN/models/bvlc_alexnet.caffemodel
I0403 02:30:45.071640  4269 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I0403 02:30:45.105900  4269 net.cpp:753] Ignoring source layer fc8
I0403 02:30:45.131925  4269 parallel.cpp:392] GPUs pairs 0:1
I0403 02:30:45.378279  4269 data_layer.cpp:41] output data size: 100,3,227,227
I0403 02:30:47.875128  4269 parallel.cpp:425] Starting Optimization
I0403 02:30:47.875305  4269 solver.cpp:279] Solving 
I0403 02:30:47.875330  4269 solver.cpp:280] Learning Rate Policy: step
I0403 02:30:47.875519  4269 solver.cpp:337] Iteration 0, Testing net (#0)
I0403 02:31:11.991940  4269 solver.cpp:404]     Test net output #0: accuracy = 0.0166355
I0403 02:31:11.992810  4269 solver.cpp:404]     Test net output #1: loss = 4.02843 (* 1 = 4.02843 loss)
I0403 02:31:12.616037  4269 solver.cpp:228] Iteration 0, loss = 4.56623
I0403 02:31:12.616103  4269 solver.cpp:244]     Train net output #0: loss = 4.56623 (* 1 = 4.56623 loss)
I0403 02:31:12.717528  4269 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0403 02:31:27.834013  4269 solver.cpp:228] Iteration 21, loss = 1.02051
I0403 02:31:27.842067  4269 solver.cpp:244]     Train net output #0: loss = 1.02051 (* 1 = 1.02051 loss)
I0403 02:31:27.998301  4269 sgd_solver.cpp:106] Iteration 21, lr = 0.005
I0403 02:31:43.035308  4269 solver.cpp:228] Iteration 42, loss = 0.637245
I0403 02:31:43.042799  4269 solver.cpp:244]     Train net output #0: loss = 0.637245 (* 1 = 0.637245 loss)
I0403 02:31:43.272518  4269 sgd_solver.cpp:106] Iteration 42, lr = 0.005
I0403 02:31:58.243953  4269 solver.cpp:228] Iteration 63, loss = 0.302547
I0403 02:31:58.248656  4269 solver.cpp:244]     Train net output #0: loss = 0.302547 (* 1 = 0.302547 loss)
I0403 02:31:58.474032  4269 sgd_solver.cpp:106] Iteration 63, lr = 0.005
I0403 02:32:13.566181  4269 solver.cpp:228] Iteration 84, loss = 0.501014
I0403 02:32:13.572491  4269 solver.cpp:244]     Train net output #0: loss = 0.501014 (* 1 = 0.501014 loss)
I0403 02:32:13.709888  4269 sgd_solver.cpp:106] Iteration 84, lr = 0.005
I0403 02:32:28.736768  4269 solver.cpp:228] Iteration 105, loss = 0.433959
I0403 02:32:28.742776  4269 solver.cpp:244]     Train net output #0: loss = 0.433959 (* 1 = 0.433959 loss)
I0403 02:32:28.942013  4269 sgd_solver.cpp:106] Iteration 105, lr = 0.005
I0403 02:32:43.869868  4269 solver.cpp:228] Iteration 126, loss = 0.2636
I0403 02:32:43.874718  4269 solver.cpp:244]     Train net output #0: loss = 0.2636 (* 1 = 0.2636 loss)
I0403 02:32:44.083304  4269 sgd_solver.cpp:106] Iteration 126, lr = 0.005
I0403 02:32:59.050287  4269 solver.cpp:228] Iteration 147, loss = 0.318506
I0403 02:32:59.055431  4269 solver.cpp:244]     Train net output #0: loss = 0.318506 (* 1 = 0.318506 loss)
I0403 02:32:59.236801  4269 sgd_solver.cpp:106] Iteration 147, lr = 0.005
I0403 02:33:14.221511  4269 solver.cpp:228] Iteration 168, loss = 0.275653
I0403 02:33:14.229086  4269 solver.cpp:244]     Train net output #0: loss = 0.275653 (* 1 = 0.275653 loss)
I0403 02:33:14.405256  4269 sgd_solver.cpp:106] Iteration 168, lr = 0.005
I0403 02:33:29.349441  4269 solver.cpp:228] Iteration 189, loss = 0.179456
I0403 02:33:29.355311  4269 solver.cpp:244]     Train net output #0: loss = 0.179456 (* 1 = 0.179456 loss)
I0403 02:33:29.581518  4269 sgd_solver.cpp:106] Iteration 189, lr = 0.005
I0403 02:33:44.494942  4269 solver.cpp:228] Iteration 210, loss = 0.206578
I0403 02:33:44.500087  4269 solver.cpp:244]     Train net output #0: loss = 0.206578 (* 1 = 0.206578 loss)
I0403 02:33:44.679545  4269 sgd_solver.cpp:106] Iteration 210, lr = 0.005
I0403 02:33:59.973054  4269 solver.cpp:228] Iteration 231, loss = 0.215553
I0403 02:33:59.986282  4269 solver.cpp:244]     Train net output #0: loss = 0.215553 (* 1 = 0.215553 loss)
I0403 02:34:00.171887  4269 sgd_solver.cpp:106] Iteration 231, lr = 0.005
I0403 02:34:15.165398  4269 solver.cpp:228] Iteration 252, loss = 0.117678
I0403 02:34:15.171921  4269 solver.cpp:244]     Train net output #0: loss = 0.117678 (* 1 = 0.117678 loss)
I0403 02:34:15.370636  4269 sgd_solver.cpp:106] Iteration 252, lr = 0.005
I0403 02:34:30.387948  4269 solver.cpp:228] Iteration 273, loss = 0.0610208
I0403 02:34:30.392755  4269 solver.cpp:244]     Train net output #0: loss = 0.0610208 (* 1 = 0.0610208 loss)
I0403 02:34:30.532101  4269 sgd_solver.cpp:106] Iteration 273, lr = 0.005
I0403 02:34:45.934974  4269 solver.cpp:228] Iteration 294, loss = 0.051658
I0403 02:34:45.941731  4269 solver.cpp:244]     Train net output #0: loss = 0.051658 (* 1 = 0.051658 loss)
I0403 02:34:46.099604  4269 sgd_solver.cpp:106] Iteration 294, lr = 0.005
I0403 02:35:01.797665  4269 solver.cpp:228] Iteration 315, loss = 0.101262
I0403 02:35:01.804510  4269 solver.cpp:244]     Train net output #0: loss = 0.101262 (* 1 = 0.101262 loss)
I0403 02:35:01.930611  4269 sgd_solver.cpp:106] Iteration 315, lr = 0.005
I0403 02:35:17.082082  4269 solver.cpp:228] Iteration 336, loss = 0.335991
I0403 02:35:17.098134  4269 solver.cpp:244]     Train net output #0: loss = 0.335991 (* 1 = 0.335991 loss)
I0403 02:35:17.274579  4269 sgd_solver.cpp:106] Iteration 336, lr = 0.005
I0403 02:35:32.601058  4269 solver.cpp:228] Iteration 357, loss = 0.206833
I0403 02:35:32.605829  4269 solver.cpp:244]     Train net output #0: loss = 0.206833 (* 1 = 0.206833 loss)
I0403 02:35:32.812469  4269 sgd_solver.cpp:106] Iteration 357, lr = 0.005
I0403 02:35:48.108487  4269 solver.cpp:228] Iteration 378, loss = 0.044737
I0403 02:35:48.114285  4269 solver.cpp:244]     Train net output #0: loss = 0.044737 (* 1 = 0.044737 loss)
I0403 02:35:48.305176  4269 sgd_solver.cpp:106] Iteration 378, lr = 0.005
I0403 02:36:03.407430  4269 solver.cpp:228] Iteration 399, loss = 0.0926267
I0403 02:36:03.413657  4269 solver.cpp:244]     Train net output #0: loss = 0.0926267 (* 1 = 0.0926267 loss)
I0403 02:36:03.605687  4269 sgd_solver.cpp:106] Iteration 399, lr = 0.005
I0403 02:36:18.926635  4269 solver.cpp:228] Iteration 420, loss = 0.207224
I0403 02:36:18.932545  4269 solver.cpp:244]     Train net output #0: loss = 0.207224 (* 1 = 0.207224 loss)
I0403 02:36:19.162446  4269 sgd_solver.cpp:106] Iteration 420, lr = 0.005
I0403 02:36:29.609943  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_435.caffemodel
I0403 02:36:32.335052  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_435.solverstate
I0403 02:36:34.172138  4269 solver.cpp:337] Iteration 435, Testing net (#0)
I0403 02:36:58.238848  4269 solver.cpp:404]     Test net output #0: accuracy = 0.965327
I0403 02:36:58.245733  4269 solver.cpp:404]     Test net output #1: loss = 0.1092 (* 1 = 0.1092 loss)
I0403 02:37:03.233563  4269 solver.cpp:228] Iteration 441, loss = 0.171772
I0403 02:37:03.240819  4269 solver.cpp:244]     Train net output #0: loss = 0.171772 (* 1 = 0.171772 loss)
I0403 02:37:03.375428  4269 sgd_solver.cpp:106] Iteration 441, lr = 0.005
I0403 02:37:18.622689  4269 solver.cpp:228] Iteration 462, loss = 0.233861
I0403 02:37:18.629546  4269 solver.cpp:244]     Train net output #0: loss = 0.233861 (* 1 = 0.233861 loss)
I0403 02:37:18.819697  4269 sgd_solver.cpp:106] Iteration 462, lr = 0.005
I0403 02:37:34.011909  4269 solver.cpp:228] Iteration 483, loss = 0.152136
I0403 02:37:34.018229  4269 solver.cpp:244]     Train net output #0: loss = 0.152136 (* 1 = 0.152136 loss)
I0403 02:37:34.196938  4269 sgd_solver.cpp:106] Iteration 483, lr = 0.005
I0403 02:37:49.185746  4269 solver.cpp:228] Iteration 504, loss = 0.133848
I0403 02:37:49.192322  4269 solver.cpp:244]     Train net output #0: loss = 0.133848 (* 1 = 0.133848 loss)
I0403 02:37:49.395045  4269 sgd_solver.cpp:106] Iteration 504, lr = 0.005
I0403 02:38:04.523447  4269 solver.cpp:228] Iteration 525, loss = 0.128476
I0403 02:38:04.523712  4269 solver.cpp:244]     Train net output #0: loss = 0.128476 (* 1 = 0.128476 loss)
I0403 02:38:04.687707  4269 sgd_solver.cpp:106] Iteration 525, lr = 0.005
I0403 02:38:19.948043  4269 solver.cpp:228] Iteration 546, loss = 0.128687
I0403 02:38:19.954372  4269 solver.cpp:244]     Train net output #0: loss = 0.128687 (* 1 = 0.128687 loss)
I0403 02:38:20.139739  4269 sgd_solver.cpp:106] Iteration 546, lr = 0.005
I0403 02:38:35.209640  4269 solver.cpp:228] Iteration 567, loss = 0.060154
I0403 02:38:35.219456  4269 solver.cpp:244]     Train net output #0: loss = 0.060154 (* 1 = 0.060154 loss)
I0403 02:38:35.419912  4269 sgd_solver.cpp:106] Iteration 567, lr = 0.005
I0403 02:38:50.477711  4269 solver.cpp:228] Iteration 588, loss = 0.0334552
I0403 02:38:50.477805  4269 solver.cpp:244]     Train net output #0: loss = 0.0334552 (* 1 = 0.0334552 loss)
I0403 02:38:50.666481  4269 sgd_solver.cpp:106] Iteration 588, lr = 0.005
I0403 02:39:05.641554  4269 solver.cpp:228] Iteration 609, loss = 0.017758
I0403 02:39:05.641844  4269 solver.cpp:244]     Train net output #0: loss = 0.017758 (* 1 = 0.017758 loss)
I0403 02:39:05.903059  4269 sgd_solver.cpp:106] Iteration 609, lr = 0.005
I0403 02:39:21.045964  4269 solver.cpp:228] Iteration 630, loss = 0.297316
I0403 02:39:21.046056  4269 solver.cpp:244]     Train net output #0: loss = 0.297316 (* 1 = 0.297316 loss)
I0403 02:39:21.225550  4269 sgd_solver.cpp:106] Iteration 630, lr = 0.005
I0403 02:39:36.328663  4269 solver.cpp:228] Iteration 651, loss = 0.060899
I0403 02:39:36.328989  4269 solver.cpp:244]     Train net output #0: loss = 0.060899 (* 1 = 0.060899 loss)
I0403 02:39:36.523635  4269 sgd_solver.cpp:106] Iteration 651, lr = 0.005
I0403 02:39:51.732715  4269 solver.cpp:228] Iteration 672, loss = 0.0969567
I0403 02:39:51.744256  4269 solver.cpp:244]     Train net output #0: loss = 0.0969567 (* 1 = 0.0969567 loss)
I0403 02:39:51.923164  4269 sgd_solver.cpp:106] Iteration 672, lr = 0.005
I0403 02:40:07.077953  4269 solver.cpp:228] Iteration 693, loss = 0.0380215
I0403 02:40:07.078331  4269 solver.cpp:244]     Train net output #0: loss = 0.0380215 (* 1 = 0.0380215 loss)
I0403 02:40:07.248983  4269 sgd_solver.cpp:106] Iteration 693, lr = 0.005
I0403 02:40:22.459439  4269 solver.cpp:228] Iteration 714, loss = 0.0167558
I0403 02:40:22.459524  4269 solver.cpp:244]     Train net output #0: loss = 0.0167558 (* 1 = 0.0167558 loss)
I0403 02:40:22.640388  4269 sgd_solver.cpp:106] Iteration 714, lr = 0.005
I0403 02:40:37.958614  4269 solver.cpp:228] Iteration 735, loss = 0.19705
I0403 02:40:37.964906  4269 solver.cpp:244]     Train net output #0: loss = 0.19705 (* 1 = 0.19705 loss)
I0403 02:40:38.145463  4269 sgd_solver.cpp:106] Iteration 735, lr = 0.005
I0403 02:40:53.211570  4269 solver.cpp:228] Iteration 756, loss = 0.0500551
I0403 02:40:53.218683  4269 solver.cpp:244]     Train net output #0: loss = 0.0500551 (* 1 = 0.0500551 loss)
I0403 02:40:53.398118  4269 sgd_solver.cpp:106] Iteration 756, lr = 0.005
I0403 02:41:08.602280  4269 solver.cpp:228] Iteration 777, loss = 0.0134822
I0403 02:41:08.608167  4269 solver.cpp:244]     Train net output #0: loss = 0.0134822 (* 1 = 0.0134822 loss)
I0403 02:41:08.822268  4269 sgd_solver.cpp:106] Iteration 777, lr = 0.005
I0403 02:41:24.027032  4269 solver.cpp:228] Iteration 798, loss = 0.0620701
I0403 02:41:24.033429  4269 solver.cpp:244]     Train net output #0: loss = 0.0620701 (* 1 = 0.0620701 loss)
I0403 02:41:24.248962  4269 sgd_solver.cpp:106] Iteration 798, lr = 0.005
I0403 02:41:39.615623  4269 solver.cpp:228] Iteration 819, loss = 0.0533491
I0403 02:41:39.622445  4269 solver.cpp:244]     Train net output #0: loss = 0.0533491 (* 1 = 0.0533491 loss)
I0403 02:41:39.825456  4269 sgd_solver.cpp:106] Iteration 819, lr = 0.005
I0403 02:41:54.878995  4269 solver.cpp:228] Iteration 840, loss = 0.0404791
I0403 02:41:54.885349  4269 solver.cpp:244]     Train net output #0: loss = 0.0404791 (* 1 = 0.0404791 loss)
I0403 02:41:55.059911  4269 sgd_solver.cpp:106] Iteration 840, lr = 0.005
I0403 02:42:10.314097  4269 solver.cpp:228] Iteration 861, loss = 0.0430867
I0403 02:42:10.319699  4269 solver.cpp:244]     Train net output #0: loss = 0.0430867 (* 1 = 0.0430867 loss)
I0403 02:42:10.485415  4269 sgd_solver.cpp:106] Iteration 861, lr = 0.005
I0403 02:42:16.388278  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_870.caffemodel
I0403 02:42:19.049129  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_870.solverstate
I0403 02:42:20.832044  4269 solver.cpp:337] Iteration 870, Testing net (#0)
I0403 02:42:44.892758  4269 solver.cpp:404]     Test net output #0: accuracy = 0.968411
I0403 02:42:44.899556  4269 solver.cpp:404]     Test net output #1: loss = 0.102393 (* 1 = 0.102393 loss)
I0403 02:42:54.106070  4269 solver.cpp:228] Iteration 882, loss = 0.0375448
I0403 02:42:54.111847  4269 solver.cpp:244]     Train net output #0: loss = 0.0375448 (* 1 = 0.0375448 loss)
I0403 02:42:54.304771  4269 sgd_solver.cpp:106] Iteration 882, lr = 0.005
I0403 02:43:09.424561  4269 solver.cpp:228] Iteration 903, loss = 0.00925156
I0403 02:43:09.430277  4269 solver.cpp:244]     Train net output #0: loss = 0.00925157 (* 1 = 0.00925157 loss)
I0403 02:43:09.597864  4269 sgd_solver.cpp:106] Iteration 903, lr = 0.005
I0403 02:43:24.707516  4269 solver.cpp:228] Iteration 924, loss = 0.0899407
I0403 02:43:24.713876  4269 solver.cpp:244]     Train net output #0: loss = 0.0899407 (* 1 = 0.0899407 loss)
I0403 02:43:24.925945  4269 sgd_solver.cpp:106] Iteration 924, lr = 0.005
I0403 02:43:40.237004  4269 solver.cpp:228] Iteration 945, loss = 0.0138524
I0403 02:43:40.243232  4269 solver.cpp:244]     Train net output #0: loss = 0.0138524 (* 1 = 0.0138524 loss)
I0403 02:43:40.425662  4269 sgd_solver.cpp:106] Iteration 945, lr = 0.005
I0403 02:43:55.642189  4269 solver.cpp:228] Iteration 966, loss = 0.0824341
I0403 02:43:55.652952  4269 solver.cpp:244]     Train net output #0: loss = 0.0824341 (* 1 = 0.0824341 loss)
I0403 02:43:55.834673  4269 sgd_solver.cpp:106] Iteration 966, lr = 0.005
I0403 02:44:11.151669  4269 solver.cpp:228] Iteration 987, loss = 0.0971311
I0403 02:44:11.157961  4269 solver.cpp:244]     Train net output #0: loss = 0.0971311 (* 1 = 0.0971311 loss)
I0403 02:44:11.292372  4269 sgd_solver.cpp:106] Iteration 987, lr = 0.005
I0403 02:44:26.534363  4269 solver.cpp:228] Iteration 1008, loss = 0.0313601
I0403 02:44:26.540153  4269 solver.cpp:244]     Train net output #0: loss = 0.0313601 (* 1 = 0.0313601 loss)
I0403 02:44:26.740028  4269 sgd_solver.cpp:106] Iteration 1008, lr = 0.005
I0403 02:44:42.017695  4269 solver.cpp:228] Iteration 1029, loss = 0.117417
I0403 02:44:42.024380  4269 solver.cpp:244]     Train net output #0: loss = 0.117418 (* 1 = 0.117418 loss)
I0403 02:44:42.256279  4269 sgd_solver.cpp:106] Iteration 1029, lr = 0.005
I0403 02:44:57.507705  4269 solver.cpp:228] Iteration 1050, loss = 0.0533053
I0403 02:44:57.513766  4269 solver.cpp:244]     Train net output #0: loss = 0.0533053 (* 1 = 0.0533053 loss)
I0403 02:44:57.697737  4269 sgd_solver.cpp:106] Iteration 1050, lr = 0.005
I0403 02:45:12.776178  4269 solver.cpp:228] Iteration 1071, loss = 0.0490201
I0403 02:45:12.782989  4269 solver.cpp:244]     Train net output #0: loss = 0.0490201 (* 1 = 0.0490201 loss)
I0403 02:45:12.958614  4269 sgd_solver.cpp:106] Iteration 1071, lr = 0.005
I0403 02:45:28.256109  4269 solver.cpp:228] Iteration 1092, loss = 0.103075
I0403 02:45:28.263244  4269 solver.cpp:244]     Train net output #0: loss = 0.103075 (* 1 = 0.103075 loss)
I0403 02:45:28.430127  4269 sgd_solver.cpp:106] Iteration 1092, lr = 0.005
I0403 02:45:43.595407  4269 solver.cpp:228] Iteration 1113, loss = 0.165856
I0403 02:45:43.601972  4269 solver.cpp:244]     Train net output #0: loss = 0.165856 (* 1 = 0.165856 loss)
I0403 02:45:43.789734  4269 sgd_solver.cpp:106] Iteration 1113, lr = 0.005
I0403 02:45:58.954097  4269 solver.cpp:228] Iteration 1134, loss = 0.0390399
I0403 02:45:58.959631  4269 solver.cpp:244]     Train net output #0: loss = 0.0390399 (* 1 = 0.0390399 loss)
I0403 02:45:59.117342  4269 sgd_solver.cpp:106] Iteration 1134, lr = 0.005
I0403 02:46:14.340137  4269 solver.cpp:228] Iteration 1155, loss = 0.0532031
I0403 02:46:14.346443  4269 solver.cpp:244]     Train net output #0: loss = 0.0532032 (* 1 = 0.0532032 loss)
I0403 02:46:14.542841  4269 sgd_solver.cpp:106] Iteration 1155, lr = 0.005
I0403 02:46:29.749307  4269 solver.cpp:228] Iteration 1176, loss = 0.0296037
I0403 02:46:29.756096  4269 solver.cpp:244]     Train net output #0: loss = 0.0296038 (* 1 = 0.0296038 loss)
I0403 02:46:29.935883  4269 sgd_solver.cpp:106] Iteration 1176, lr = 0.005
I0403 02:46:45.060643  4269 solver.cpp:228] Iteration 1197, loss = 0.0331912
I0403 02:46:45.067195  4269 solver.cpp:244]     Train net output #0: loss = 0.0331912 (* 1 = 0.0331912 loss)
I0403 02:46:45.249186  4269 sgd_solver.cpp:106] Iteration 1197, lr = 0.005
I0403 02:47:00.498319  4269 solver.cpp:228] Iteration 1218, loss = 0.0823744
I0403 02:47:00.504942  4269 solver.cpp:244]     Train net output #0: loss = 0.0823744 (* 1 = 0.0823744 loss)
I0403 02:47:00.684008  4269 sgd_solver.cpp:106] Iteration 1218, lr = 0.005
I0403 02:47:15.791162  4269 solver.cpp:228] Iteration 1239, loss = 0.0262315
I0403 02:47:15.797123  4269 solver.cpp:244]     Train net output #0: loss = 0.0262316 (* 1 = 0.0262316 loss)
I0403 02:47:15.963887  4269 sgd_solver.cpp:106] Iteration 1239, lr = 0.005
I0403 02:47:31.178447  4269 solver.cpp:228] Iteration 1260, loss = 0.0438533
I0403 02:47:31.184695  4269 solver.cpp:244]     Train net output #0: loss = 0.0438533 (* 1 = 0.0438533 loss)
I0403 02:47:31.360783  4269 sgd_solver.cpp:106] Iteration 1260, lr = 0.005
I0403 02:47:46.463842  4269 solver.cpp:228] Iteration 1281, loss = 0.130127
I0403 02:47:46.470568  4269 solver.cpp:244]     Train net output #0: loss = 0.130127 (* 1 = 0.130127 loss)
I0403 02:47:46.639660  4269 sgd_solver.cpp:106] Iteration 1281, lr = 0.005
I0403 02:48:01.519052  4269 solver.cpp:228] Iteration 1302, loss = 0.142924
I0403 02:48:01.529407  4269 solver.cpp:244]     Train net output #0: loss = 0.142924 (* 1 = 0.142924 loss)
I0403 02:48:01.708552  4269 sgd_solver.cpp:106] Iteration 1302, lr = 0.005
I0403 02:48:03.149917  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_1305.caffemodel
I0403 02:48:05.963724  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_1305.solverstate
I0403 02:48:07.891000  4269 solver.cpp:337] Iteration 1305, Testing net (#0)
I0403 02:48:31.951445  4269 solver.cpp:404]     Test net output #0: accuracy = 0.97458
I0403 02:48:31.958093  4269 solver.cpp:404]     Test net output #1: loss = 0.0863236 (* 1 = 0.0863236 loss)
I0403 02:48:45.415992  4269 solver.cpp:228] Iteration 1323, loss = 0.0509284
I0403 02:48:45.422149  4269 solver.cpp:244]     Train net output #0: loss = 0.0509284 (* 1 = 0.0509284 loss)
I0403 02:48:45.598821  4269 sgd_solver.cpp:106] Iteration 1323, lr = 0.005
I0403 02:49:00.586755  4269 solver.cpp:228] Iteration 1344, loss = 0.0844088
I0403 02:49:00.591951  4269 solver.cpp:244]     Train net output #0: loss = 0.0844088 (* 1 = 0.0844088 loss)
I0403 02:49:00.777827  4269 sgd_solver.cpp:106] Iteration 1344, lr = 0.005
I0403 02:49:15.825037  4269 solver.cpp:228] Iteration 1365, loss = 0.0242896
I0403 02:49:15.831349  4269 solver.cpp:244]     Train net output #0: loss = 0.0242897 (* 1 = 0.0242897 loss)
I0403 02:49:15.963711  4269 sgd_solver.cpp:106] Iteration 1365, lr = 0.005
I0403 02:49:31.602594  4269 solver.cpp:228] Iteration 1386, loss = 0.0519103
I0403 02:49:31.608991  4269 solver.cpp:244]     Train net output #0: loss = 0.0519103 (* 1 = 0.0519103 loss)
I0403 02:49:31.745378  4269 sgd_solver.cpp:106] Iteration 1386, lr = 0.005
I0403 02:49:46.985106  4269 solver.cpp:228] Iteration 1407, loss = 0.129249
I0403 02:49:46.990965  4269 solver.cpp:244]     Train net output #0: loss = 0.129249 (* 1 = 0.129249 loss)
I0403 02:49:47.176496  4269 sgd_solver.cpp:106] Iteration 1407, lr = 0.005
I0403 02:50:02.338996  4269 solver.cpp:228] Iteration 1428, loss = 0.0327922
I0403 02:50:02.345897  4269 solver.cpp:244]     Train net output #0: loss = 0.0327923 (* 1 = 0.0327923 loss)
I0403 02:50:02.522876  4269 sgd_solver.cpp:106] Iteration 1428, lr = 0.005
I0403 02:50:17.773627  4269 solver.cpp:228] Iteration 1449, loss = 0.0463765
I0403 02:50:17.779994  4269 solver.cpp:244]     Train net output #0: loss = 0.0463766 (* 1 = 0.0463766 loss)
I0403 02:50:17.952541  4269 sgd_solver.cpp:106] Iteration 1449, lr = 0.005
I0403 02:50:33.196115  4269 solver.cpp:228] Iteration 1470, loss = 0.0112309
I0403 02:50:33.201871  4269 solver.cpp:244]     Train net output #0: loss = 0.011231 (* 1 = 0.011231 loss)
I0403 02:50:33.449141  4269 sgd_solver.cpp:106] Iteration 1470, lr = 0.005
I0403 02:50:48.676182  4269 solver.cpp:228] Iteration 1491, loss = 0.0254483
I0403 02:50:48.682876  4269 solver.cpp:244]     Train net output #0: loss = 0.0254484 (* 1 = 0.0254484 loss)
I0403 02:50:48.902812  4269 sgd_solver.cpp:106] Iteration 1491, lr = 0.005
I0403 02:51:04.078830  4269 solver.cpp:228] Iteration 1512, loss = 0.0499835
I0403 02:51:04.084081  4269 solver.cpp:244]     Train net output #0: loss = 0.0499836 (* 1 = 0.0499836 loss)
I0403 02:51:04.273473  4269 sgd_solver.cpp:106] Iteration 1512, lr = 0.005
I0403 02:51:19.521394  4269 solver.cpp:228] Iteration 1533, loss = 0.0381064
I0403 02:51:19.527698  4269 solver.cpp:244]     Train net output #0: loss = 0.0381065 (* 1 = 0.0381065 loss)
I0403 02:51:19.699213  4269 sgd_solver.cpp:106] Iteration 1533, lr = 0.005
I0403 02:51:34.985158  4269 solver.cpp:228] Iteration 1554, loss = 0.0791813
I0403 02:51:34.990943  4269 solver.cpp:244]     Train net output #0: loss = 0.0791814 (* 1 = 0.0791814 loss)
I0403 02:51:35.165586  4269 sgd_solver.cpp:106] Iteration 1554, lr = 0.005
I0403 02:51:50.478612  4269 solver.cpp:228] Iteration 1575, loss = 0.108984
I0403 02:51:50.485725  4269 solver.cpp:244]     Train net output #0: loss = 0.108984 (* 1 = 0.108984 loss)
I0403 02:51:50.630548  4269 sgd_solver.cpp:106] Iteration 1575, lr = 0.005
I0403 02:52:06.073001  4269 solver.cpp:228] Iteration 1596, loss = 0.0212301
I0403 02:52:06.080152  4269 solver.cpp:244]     Train net output #0: loss = 0.0212302 (* 1 = 0.0212302 loss)
I0403 02:52:06.303489  4269 sgd_solver.cpp:106] Iteration 1596, lr = 0.005
I0403 02:52:21.618361  4269 solver.cpp:228] Iteration 1617, loss = 0.0861761
I0403 02:52:21.624522  4269 solver.cpp:244]     Train net output #0: loss = 0.0861762 (* 1 = 0.0861762 loss)
I0403 02:52:21.789599  4269 sgd_solver.cpp:106] Iteration 1617, lr = 0.005
I0403 02:52:37.001265  4269 solver.cpp:228] Iteration 1638, loss = 0.0150555
I0403 02:52:37.006770  4269 solver.cpp:244]     Train net output #0: loss = 0.0150556 (* 1 = 0.0150556 loss)
I0403 02:52:37.178607  4269 sgd_solver.cpp:106] Iteration 1638, lr = 0.005
I0403 02:52:52.563666  4269 solver.cpp:228] Iteration 1659, loss = 0.0146869
I0403 02:52:52.571102  4269 solver.cpp:244]     Train net output #0: loss = 0.014687 (* 1 = 0.014687 loss)
I0403 02:52:52.729630  4269 sgd_solver.cpp:106] Iteration 1659, lr = 0.005
I0403 02:53:07.939663  4269 solver.cpp:228] Iteration 1680, loss = 0.00971495
I0403 02:53:07.945670  4269 solver.cpp:244]     Train net output #0: loss = 0.00971503 (* 1 = 0.00971503 loss)
I0403 02:53:08.117557  4269 sgd_solver.cpp:106] Iteration 1680, lr = 0.005
I0403 02:53:23.293576  4269 solver.cpp:228] Iteration 1701, loss = 0.00861099
I0403 02:53:23.300130  4269 solver.cpp:244]     Train net output #0: loss = 0.00861107 (* 1 = 0.00861107 loss)
I0403 02:53:23.482606  4269 sgd_solver.cpp:106] Iteration 1701, lr = 0.005
I0403 02:53:38.798133  4269 solver.cpp:228] Iteration 1722, loss = 0.0287226
I0403 02:53:38.804772  4269 solver.cpp:244]     Train net output #0: loss = 0.0287226 (* 1 = 0.0287226 loss)
I0403 02:53:38.995590  4269 sgd_solver.cpp:106] Iteration 1722, lr = 0.005
I0403 02:53:51.638397  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_1740.caffemodel
I0403 02:53:54.461449  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_1740.solverstate
I0403 02:53:56.395848  4269 solver.cpp:337] Iteration 1740, Testing net (#0)
I0403 02:54:20.464701  4269 solver.cpp:404]     Test net output #0: accuracy = 0.975421
I0403 02:54:20.471997  4269 solver.cpp:404]     Test net output #1: loss = 0.085855 (* 1 = 0.085855 loss)
I0403 02:54:23.173059  4269 solver.cpp:228] Iteration 1743, loss = 0.00855158
I0403 02:54:23.179651  4269 solver.cpp:244]     Train net output #0: loss = 0.00855165 (* 1 = 0.00855165 loss)
I0403 02:54:23.372297  4269 sgd_solver.cpp:106] Iteration 1743, lr = 0.005
I0403 02:54:38.409093  4269 solver.cpp:228] Iteration 1764, loss = 0.0931035
I0403 02:54:38.415179  4269 solver.cpp:244]     Train net output #0: loss = 0.0931036 (* 1 = 0.0931036 loss)
I0403 02:54:38.605200  4269 sgd_solver.cpp:106] Iteration 1764, lr = 0.005
I0403 02:54:53.737525  4269 solver.cpp:228] Iteration 1785, loss = 0.0111254
I0403 02:54:53.743301  4269 solver.cpp:244]     Train net output #0: loss = 0.0111254 (* 1 = 0.0111254 loss)
I0403 02:54:53.919827  4269 sgd_solver.cpp:106] Iteration 1785, lr = 0.005
I0403 02:55:09.229395  4269 solver.cpp:228] Iteration 1806, loss = 0.0126099
I0403 02:55:09.235904  4269 solver.cpp:244]     Train net output #0: loss = 0.01261 (* 1 = 0.01261 loss)
I0403 02:55:09.452692  4269 sgd_solver.cpp:106] Iteration 1806, lr = 0.005
I0403 02:55:24.559664  4269 solver.cpp:228] Iteration 1827, loss = 0.0151673
I0403 02:55:24.565752  4269 solver.cpp:244]     Train net output #0: loss = 0.0151673 (* 1 = 0.0151673 loss)
I0403 02:55:24.759377  4269 sgd_solver.cpp:106] Iteration 1827, lr = 0.005
I0403 02:55:39.758664  4269 solver.cpp:228] Iteration 1848, loss = 0.0558694
I0403 02:55:39.766252  4269 solver.cpp:244]     Train net output #0: loss = 0.0558695 (* 1 = 0.0558695 loss)
I0403 02:55:39.952306  4269 sgd_solver.cpp:106] Iteration 1848, lr = 0.005
I0403 02:55:55.043110  4269 solver.cpp:228] Iteration 1869, loss = 0.0288243
I0403 02:55:55.049113  4269 solver.cpp:244]     Train net output #0: loss = 0.0288244 (* 1 = 0.0288244 loss)
I0403 02:55:55.230857  4269 sgd_solver.cpp:106] Iteration 1869, lr = 0.005
I0403 02:56:10.126418  4269 solver.cpp:228] Iteration 1890, loss = 0.00540111
I0403 02:56:10.133508  4269 solver.cpp:244]     Train net output #0: loss = 0.00540117 (* 1 = 0.00540117 loss)
I0403 02:56:10.309598  4269 sgd_solver.cpp:106] Iteration 1890, lr = 0.005
I0403 02:56:25.304029  4269 solver.cpp:228] Iteration 1911, loss = 0.0546996
I0403 02:56:25.310256  4269 solver.cpp:244]     Train net output #0: loss = 0.0546997 (* 1 = 0.0546997 loss)
I0403 02:56:25.480126  4269 sgd_solver.cpp:106] Iteration 1911, lr = 0.005
I0403 02:56:40.386710  4269 solver.cpp:228] Iteration 1932, loss = 0.0222433
I0403 02:56:40.392706  4269 solver.cpp:244]     Train net output #0: loss = 0.0222434 (* 1 = 0.0222434 loss)
I0403 02:56:40.573477  4269 sgd_solver.cpp:106] Iteration 1932, lr = 0.005
I0403 02:56:55.483664  4269 solver.cpp:228] Iteration 1953, loss = 0.0242231
I0403 02:56:55.490309  4269 solver.cpp:244]     Train net output #0: loss = 0.0242232 (* 1 = 0.0242232 loss)
I0403 02:56:55.669817  4269 sgd_solver.cpp:106] Iteration 1953, lr = 0.005
I0403 02:57:10.720432  4269 solver.cpp:228] Iteration 1974, loss = 0.0235253
I0403 02:57:10.725399  4269 solver.cpp:244]     Train net output #0: loss = 0.0235254 (* 1 = 0.0235254 loss)
I0403 02:57:10.905484  4269 sgd_solver.cpp:106] Iteration 1974, lr = 0.005
I0403 02:57:25.990299  4269 solver.cpp:228] Iteration 1995, loss = 0.0372302
I0403 02:57:25.996567  4269 solver.cpp:244]     Train net output #0: loss = 0.0372303 (* 1 = 0.0372303 loss)
I0403 02:57:26.199317  4269 sgd_solver.cpp:106] Iteration 1995, lr = 0.005
I0403 02:57:41.457940  4269 solver.cpp:228] Iteration 2016, loss = 0.01185
I0403 02:57:41.464927  4269 solver.cpp:244]     Train net output #0: loss = 0.0118501 (* 1 = 0.0118501 loss)
I0403 02:57:41.639474  4269 sgd_solver.cpp:106] Iteration 2016, lr = 0.005
I0403 02:57:56.920837  4269 solver.cpp:228] Iteration 2037, loss = 0.019477
I0403 02:57:56.936298  4269 solver.cpp:244]     Train net output #0: loss = 0.019477 (* 1 = 0.019477 loss)
I0403 02:57:57.125103  4269 sgd_solver.cpp:106] Iteration 2037, lr = 0.005
I0403 02:58:12.307643  4269 solver.cpp:228] Iteration 2058, loss = 0.0227801
I0403 02:58:12.312978  4269 solver.cpp:244]     Train net output #0: loss = 0.0227802 (* 1 = 0.0227802 loss)
I0403 02:58:12.562424  4269 sgd_solver.cpp:106] Iteration 2058, lr = 0.005
I0403 02:58:28.025478  4269 solver.cpp:228] Iteration 2079, loss = 0.0033581
I0403 02:58:28.031632  4269 solver.cpp:244]     Train net output #0: loss = 0.00335817 (* 1 = 0.00335817 loss)
I0403 02:58:28.191823  4269 sgd_solver.cpp:106] Iteration 2079, lr = 0.005
I0403 02:58:43.362133  4269 solver.cpp:228] Iteration 2100, loss = 0.0246064
I0403 02:58:43.368965  4269 solver.cpp:244]     Train net output #0: loss = 0.0246064 (* 1 = 0.0246064 loss)
I0403 02:58:43.527565  4269 sgd_solver.cpp:106] Iteration 2100, lr = 0.005
I0403 02:58:59.221678  4269 solver.cpp:228] Iteration 2121, loss = 0.0296385
I0403 02:58:59.228322  4269 solver.cpp:244]     Train net output #0: loss = 0.0296385 (* 1 = 0.0296385 loss)
I0403 02:58:59.426534  4269 sgd_solver.cpp:106] Iteration 2121, lr = 0.005
I0403 02:59:14.907030  4269 solver.cpp:228] Iteration 2142, loss = 0.0126939
I0403 02:59:14.913450  4269 solver.cpp:244]     Train net output #0: loss = 0.012694 (* 1 = 0.012694 loss)
I0403 02:59:15.091219  4269 sgd_solver.cpp:106] Iteration 2142, lr = 0.005
I0403 02:59:30.335710  4269 solver.cpp:228] Iteration 2163, loss = 0.00368142
I0403 02:59:30.342341  4269 solver.cpp:244]     Train net output #0: loss = 0.00368149 (* 1 = 0.00368149 loss)
I0403 02:59:30.535856  4269 sgd_solver.cpp:106] Iteration 2163, lr = 0.005
I0403 02:59:38.539173  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_2175.caffemodel
I0403 02:59:41.337013  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_2175.solverstate
I0403 02:59:43.265352  4269 solver.cpp:337] Iteration 2175, Testing net (#0)
I0403 03:00:07.322942  4269 solver.cpp:404]     Test net output #0: accuracy = 0.979066
I0403 03:00:07.329056  4269 solver.cpp:404]     Test net output #1: loss = 0.0757403 (* 1 = 0.0757403 loss)
I0403 03:00:14.384341  4269 solver.cpp:228] Iteration 2184, loss = 0.00112369
I0403 03:00:14.391108  4269 solver.cpp:244]     Train net output #0: loss = 0.00112376 (* 1 = 0.00112376 loss)
I0403 03:00:14.599469  4269 sgd_solver.cpp:106] Iteration 2184, lr = 0.005
I0403 03:00:29.770772  4269 solver.cpp:228] Iteration 2205, loss = 0.00910692
I0403 03:00:29.777137  4269 solver.cpp:244]     Train net output #0: loss = 0.00910699 (* 1 = 0.00910699 loss)
I0403 03:00:30.005383  4269 sgd_solver.cpp:106] Iteration 2205, lr = 0.005
I0403 03:00:45.151826  4269 solver.cpp:228] Iteration 2226, loss = 0.0158237
I0403 03:00:45.158473  4269 solver.cpp:244]     Train net output #0: loss = 0.0158238 (* 1 = 0.0158238 loss)
I0403 03:00:45.386509  4269 sgd_solver.cpp:106] Iteration 2226, lr = 0.005
I0403 03:01:00.495496  4269 solver.cpp:228] Iteration 2247, loss = 0.0616846
I0403 03:01:00.501868  4269 solver.cpp:244]     Train net output #0: loss = 0.0616847 (* 1 = 0.0616847 loss)
I0403 03:01:00.672351  4269 sgd_solver.cpp:106] Iteration 2247, lr = 0.005
I0403 03:01:15.796943  4269 solver.cpp:228] Iteration 2268, loss = 0.0457735
I0403 03:01:15.803277  4269 solver.cpp:244]     Train net output #0: loss = 0.0457736 (* 1 = 0.0457736 loss)
I0403 03:01:15.983657  4269 sgd_solver.cpp:106] Iteration 2268, lr = 0.005
I0403 03:01:31.260939  4269 solver.cpp:228] Iteration 2289, loss = 0.0282126
I0403 03:01:31.266418  4269 solver.cpp:244]     Train net output #0: loss = 0.0282127 (* 1 = 0.0282127 loss)
I0403 03:01:31.371932  4269 sgd_solver.cpp:106] Iteration 2289, lr = 0.005
I0403 03:01:46.831027  4269 solver.cpp:228] Iteration 2310, loss = 0.0335385
I0403 03:01:46.839092  4269 solver.cpp:244]     Train net output #0: loss = 0.0335386 (* 1 = 0.0335386 loss)
I0403 03:01:46.941874  4269 sgd_solver.cpp:106] Iteration 2310, lr = 0.005
I0403 03:02:02.440850  4269 solver.cpp:228] Iteration 2331, loss = 0.0385334
I0403 03:02:02.447021  4269 solver.cpp:244]     Train net output #0: loss = 0.0385335 (* 1 = 0.0385335 loss)
I0403 03:02:02.637298  4269 sgd_solver.cpp:106] Iteration 2331, lr = 0.005
I0403 03:02:17.845218  4269 solver.cpp:228] Iteration 2352, loss = 0.0223734
I0403 03:02:17.856098  4269 solver.cpp:244]     Train net output #0: loss = 0.0223735 (* 1 = 0.0223735 loss)
I0403 03:02:18.027277  4269 sgd_solver.cpp:106] Iteration 2352, lr = 0.005
I0403 03:02:33.390094  4269 solver.cpp:228] Iteration 2373, loss = 0.0126004
I0403 03:02:33.396571  4269 solver.cpp:244]     Train net output #0: loss = 0.0126005 (* 1 = 0.0126005 loss)
I0403 03:02:33.580546  4269 sgd_solver.cpp:106] Iteration 2373, lr = 0.005
I0403 03:02:49.145794  4269 solver.cpp:228] Iteration 2394, loss = 0.0292712
I0403 03:02:49.152078  4269 solver.cpp:244]     Train net output #0: loss = 0.0292713 (* 1 = 0.0292713 loss)
I0403 03:02:49.326485  4269 sgd_solver.cpp:106] Iteration 2394, lr = 0.005
I0403 03:03:04.651285  4269 solver.cpp:228] Iteration 2415, loss = 0.0436607
I0403 03:03:04.658033  4269 solver.cpp:244]     Train net output #0: loss = 0.0436608 (* 1 = 0.0436608 loss)
I0403 03:03:04.793669  4269 sgd_solver.cpp:106] Iteration 2415, lr = 0.005
I0403 03:03:20.120895  4269 solver.cpp:228] Iteration 2436, loss = 0.00798079
I0403 03:03:20.126613  4269 solver.cpp:244]     Train net output #0: loss = 0.00798086 (* 1 = 0.00798086 loss)
I0403 03:03:20.283926  4269 sgd_solver.cpp:106] Iteration 2436, lr = 0.005
I0403 03:03:35.507309  4269 solver.cpp:228] Iteration 2457, loss = 0.0422019
I0403 03:03:35.514277  4269 solver.cpp:244]     Train net output #0: loss = 0.042202 (* 1 = 0.042202 loss)
I0403 03:03:35.724972  4269 sgd_solver.cpp:106] Iteration 2457, lr = 0.005
I0403 03:03:50.939343  4269 solver.cpp:228] Iteration 2478, loss = 0.00400667
I0403 03:03:50.947372  4269 solver.cpp:244]     Train net output #0: loss = 0.00400674 (* 1 = 0.00400674 loss)
I0403 03:03:51.134685  4269 sgd_solver.cpp:106] Iteration 2478, lr = 0.005
I0403 03:04:06.258348  4269 solver.cpp:228] Iteration 2499, loss = 0.00945052
I0403 03:04:06.263403  4269 solver.cpp:244]     Train net output #0: loss = 0.00945059 (* 1 = 0.00945059 loss)
I0403 03:04:06.446426  4269 sgd_solver.cpp:106] Iteration 2499, lr = 0.005
I0403 03:04:21.557422  4269 solver.cpp:228] Iteration 2520, loss = 0.0157275
I0403 03:04:21.564484  4269 solver.cpp:244]     Train net output #0: loss = 0.0157276 (* 1 = 0.0157276 loss)
I0403 03:04:21.749770  4269 sgd_solver.cpp:106] Iteration 2520, lr = 0.005
I0403 03:04:36.899618  4269 solver.cpp:228] Iteration 2541, loss = 0.0129925
I0403 03:04:36.905877  4269 solver.cpp:244]     Train net output #0: loss = 0.0129926 (* 1 = 0.0129926 loss)
I0403 03:04:37.096890  4269 sgd_solver.cpp:106] Iteration 2541, lr = 0.005
I0403 03:04:52.475009  4269 solver.cpp:228] Iteration 2562, loss = 0.0777605
I0403 03:04:52.481750  4269 solver.cpp:244]     Train net output #0: loss = 0.0777606 (* 1 = 0.0777606 loss)
I0403 03:04:52.658970  4269 sgd_solver.cpp:106] Iteration 2562, lr = 0.005
I0403 03:05:07.726147  4269 solver.cpp:228] Iteration 2583, loss = 0.00287356
I0403 03:05:07.733131  4269 solver.cpp:244]     Train net output #0: loss = 0.00287366 (* 1 = 0.00287366 loss)
I0403 03:05:07.909759  4269 sgd_solver.cpp:106] Iteration 2583, lr = 0.005
I0403 03:05:23.205703  4269 solver.cpp:228] Iteration 2604, loss = 0.0453509
I0403 03:05:23.213165  4269 solver.cpp:244]     Train net output #0: loss = 0.045351 (* 1 = 0.045351 loss)
I0403 03:05:23.412206  4269 sgd_solver.cpp:106] Iteration 2604, lr = 0.005
I0403 03:05:27.002172  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_2610.caffemodel
I0403 03:05:29.839015  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_2610.solverstate
I0403 03:05:31.778596  4269 solver.cpp:337] Iteration 2610, Testing net (#0)
I0403 03:05:55.837301  4269 solver.cpp:404]     Test net output #0: accuracy = 0.976823
I0403 03:05:55.844023  4269 solver.cpp:404]     Test net output #1: loss = 0.0778229 (* 1 = 0.0778229 loss)
I0403 03:06:07.325846  4269 solver.cpp:228] Iteration 2625, loss = 0.058563
I0403 03:06:07.332219  4269 solver.cpp:244]     Train net output #0: loss = 0.0585631 (* 1 = 0.0585631 loss)
I0403 03:06:07.499445  4269 sgd_solver.cpp:106] Iteration 2625, lr = 0.005
I0403 03:06:22.604372  4269 solver.cpp:228] Iteration 2646, loss = 0.0267441
I0403 03:06:22.609871  4269 solver.cpp:244]     Train net output #0: loss = 0.0267442 (* 1 = 0.0267442 loss)
I0403 03:06:22.796881  4269 sgd_solver.cpp:106] Iteration 2646, lr = 0.005
I0403 03:06:37.875720  4269 solver.cpp:228] Iteration 2667, loss = 0.00891442
I0403 03:06:37.881062  4269 solver.cpp:244]     Train net output #0: loss = 0.00891451 (* 1 = 0.00891451 loss)
I0403 03:06:38.060159  4269 sgd_solver.cpp:106] Iteration 2667, lr = 0.005
I0403 03:06:53.198971  4269 solver.cpp:228] Iteration 2688, loss = 0.00976085
I0403 03:06:53.204804  4269 solver.cpp:244]     Train net output #0: loss = 0.00976095 (* 1 = 0.00976095 loss)
I0403 03:06:53.408458  4269 sgd_solver.cpp:106] Iteration 2688, lr = 0.005
I0403 03:07:08.717020  4269 solver.cpp:228] Iteration 2709, loss = 0.0242886
I0403 03:07:08.724465  4269 solver.cpp:244]     Train net output #0: loss = 0.0242887 (* 1 = 0.0242887 loss)
I0403 03:07:08.898422  4269 sgd_solver.cpp:106] Iteration 2709, lr = 0.005
I0403 03:07:23.817065  4269 solver.cpp:228] Iteration 2730, loss = 0.0306276
I0403 03:07:23.824219  4269 solver.cpp:244]     Train net output #0: loss = 0.0306277 (* 1 = 0.0306277 loss)
I0403 03:07:24.007710  4269 sgd_solver.cpp:106] Iteration 2730, lr = 0.005
I0403 03:07:39.230243  4269 solver.cpp:228] Iteration 2751, loss = 0.0268058
I0403 03:07:39.236495  4269 solver.cpp:244]     Train net output #0: loss = 0.0268059 (* 1 = 0.0268059 loss)
I0403 03:07:39.414458  4269 sgd_solver.cpp:106] Iteration 2751, lr = 0.005
I0403 03:07:54.523143  4269 solver.cpp:228] Iteration 2772, loss = 0.0139093
I0403 03:07:54.528982  4269 solver.cpp:244]     Train net output #0: loss = 0.0139094 (* 1 = 0.0139094 loss)
I0403 03:07:54.764888  4269 sgd_solver.cpp:106] Iteration 2772, lr = 0.005
I0403 03:08:09.931737  4269 solver.cpp:228] Iteration 2793, loss = 0.00398141
I0403 03:08:09.938112  4269 solver.cpp:244]     Train net output #0: loss = 0.00398153 (* 1 = 0.00398153 loss)
I0403 03:08:10.175133  4269 sgd_solver.cpp:106] Iteration 2793, lr = 0.005
I0403 03:08:25.376863  4269 solver.cpp:228] Iteration 2814, loss = 0.000829227
I0403 03:08:25.383105  4269 solver.cpp:244]     Train net output #0: loss = 0.000829346 (* 1 = 0.000829346 loss)
I0403 03:08:25.555853  4269 sgd_solver.cpp:106] Iteration 2814, lr = 0.005
I0403 03:08:40.618505  4269 solver.cpp:228] Iteration 2835, loss = 0.0380811
I0403 03:08:40.623816  4269 solver.cpp:244]     Train net output #0: loss = 0.0380812 (* 1 = 0.0380812 loss)
I0403 03:08:40.789098  4269 sgd_solver.cpp:106] Iteration 2835, lr = 0.005
I0403 03:08:55.867199  4269 solver.cpp:228] Iteration 2856, loss = 0.0261889
I0403 03:08:55.872947  4269 solver.cpp:244]     Train net output #0: loss = 0.026189 (* 1 = 0.026189 loss)
I0403 03:08:56.051400  4269 sgd_solver.cpp:106] Iteration 2856, lr = 0.005
I0403 03:09:11.228148  4269 solver.cpp:228] Iteration 2877, loss = 0.0240878
I0403 03:09:11.234175  4269 solver.cpp:244]     Train net output #0: loss = 0.0240879 (* 1 = 0.0240879 loss)
I0403 03:09:11.391002  4269 sgd_solver.cpp:106] Iteration 2877, lr = 0.005
I0403 03:09:26.505807  4269 solver.cpp:228] Iteration 2898, loss = 0.00540814
I0403 03:09:26.512945  4269 solver.cpp:244]     Train net output #0: loss = 0.00540824 (* 1 = 0.00540824 loss)
I0403 03:09:26.675501  4269 sgd_solver.cpp:106] Iteration 2898, lr = 0.005
I0403 03:09:41.688311  4269 solver.cpp:228] Iteration 2919, loss = 0.00562023
I0403 03:09:41.694568  4269 solver.cpp:244]     Train net output #0: loss = 0.00562033 (* 1 = 0.00562033 loss)
I0403 03:09:41.868638  4269 sgd_solver.cpp:106] Iteration 2919, lr = 0.005
I0403 03:09:56.906227  4269 solver.cpp:228] Iteration 2940, loss = 0.041139
I0403 03:09:56.912498  4269 solver.cpp:244]     Train net output #0: loss = 0.041139 (* 1 = 0.041139 loss)
I0403 03:09:57.060266  4269 sgd_solver.cpp:106] Iteration 2940, lr = 0.005
I0403 03:10:12.156638  4269 solver.cpp:228] Iteration 2961, loss = 0.0376672
I0403 03:10:12.163405  4269 solver.cpp:244]     Train net output #0: loss = 0.0376673 (* 1 = 0.0376673 loss)
I0403 03:10:12.339768  4269 sgd_solver.cpp:106] Iteration 2961, lr = 0.005
I0403 03:10:27.258086  4269 solver.cpp:228] Iteration 2982, loss = 0.00977952
I0403 03:10:27.264946  4269 solver.cpp:244]     Train net output #0: loss = 0.00977961 (* 1 = 0.00977961 loss)
I0403 03:10:27.439304  4269 sgd_solver.cpp:106] Iteration 2982, lr = 0.005
I0403 03:10:42.444145  4269 solver.cpp:228] Iteration 3003, loss = 0.00756721
I0403 03:10:42.451076  4269 solver.cpp:244]     Train net output #0: loss = 0.0075673 (* 1 = 0.0075673 loss)
I0403 03:10:42.620841  4269 sgd_solver.cpp:106] Iteration 3003, lr = 0.005
I0403 03:10:57.718685  4269 solver.cpp:228] Iteration 3024, loss = 0.0154789
I0403 03:10:57.724946  4269 solver.cpp:244]     Train net output #0: loss = 0.015479 (* 1 = 0.015479 loss)
I0403 03:10:57.922662  4269 sgd_solver.cpp:106] Iteration 3024, lr = 0.005
I0403 03:11:12.371111  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_3045.caffemodel
I0403 03:11:15.132184  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_3045.solverstate
I0403 03:11:17.076433  4269 solver.cpp:337] Iteration 3045, Testing net (#0)
I0403 03:11:41.135045  4269 solver.cpp:404]     Test net output #0: accuracy = 0.982337
I0403 03:11:41.140620  4269 solver.cpp:404]     Test net output #1: loss = 0.0626703 (* 1 = 0.0626703 loss)
I0403 03:11:41.648378  4269 solver.cpp:228] Iteration 3045, loss = 0.0153556
I0403 03:11:41.653177  4269 solver.cpp:244]     Train net output #0: loss = 0.0153557 (* 1 = 0.0153557 loss)
I0403 03:11:41.830631  4269 sgd_solver.cpp:106] Iteration 3045, lr = 0.005
I0403 03:11:57.304783  4269 solver.cpp:228] Iteration 3066, loss = 0.00718319
I0403 03:11:57.310137  4269 solver.cpp:244]     Train net output #0: loss = 0.00718329 (* 1 = 0.00718329 loss)
I0403 03:11:57.492280  4269 sgd_solver.cpp:106] Iteration 3066, lr = 0.005
I0403 03:12:12.581059  4269 solver.cpp:228] Iteration 3087, loss = 0.0297939
I0403 03:12:12.588325  4269 solver.cpp:244]     Train net output #0: loss = 0.029794 (* 1 = 0.029794 loss)
I0403 03:12:12.744721  4269 sgd_solver.cpp:106] Iteration 3087, lr = 0.005
I0403 03:12:28.008481  4269 solver.cpp:228] Iteration 3108, loss = 0.0125258
I0403 03:12:28.014750  4269 solver.cpp:244]     Train net output #0: loss = 0.0125259 (* 1 = 0.0125259 loss)
I0403 03:12:28.212698  4269 sgd_solver.cpp:106] Iteration 3108, lr = 0.005
I0403 03:12:43.243131  4269 solver.cpp:228] Iteration 3129, loss = 0.00462031
I0403 03:12:43.248270  4269 solver.cpp:244]     Train net output #0: loss = 0.00462041 (* 1 = 0.00462041 loss)
I0403 03:12:43.445613  4269 sgd_solver.cpp:106] Iteration 3129, lr = 0.005
I0403 03:12:58.489238  4269 solver.cpp:228] Iteration 3150, loss = 0.0176839
I0403 03:12:58.500756  4269 solver.cpp:244]     Train net output #0: loss = 0.017684 (* 1 = 0.017684 loss)
I0403 03:12:58.672664  4269 sgd_solver.cpp:106] Iteration 3150, lr = 0.005
I0403 03:13:13.686923  4269 solver.cpp:228] Iteration 3171, loss = 0.001975
I0403 03:13:13.692615  4269 solver.cpp:244]     Train net output #0: loss = 0.0019751 (* 1 = 0.0019751 loss)
I0403 03:13:13.877523  4269 sgd_solver.cpp:106] Iteration 3171, lr = 0.005
I0403 03:13:28.914602  4269 solver.cpp:228] Iteration 3192, loss = 0.0127421
I0403 03:13:28.920711  4269 solver.cpp:244]     Train net output #0: loss = 0.0127422 (* 1 = 0.0127422 loss)
I0403 03:13:29.089390  4269 sgd_solver.cpp:106] Iteration 3192, lr = 0.005
I0403 03:13:44.430968  4269 solver.cpp:228] Iteration 3213, loss = 0.00405943
I0403 03:13:44.436316  4269 solver.cpp:244]     Train net output #0: loss = 0.00405953 (* 1 = 0.00405953 loss)
I0403 03:13:44.609388  4269 sgd_solver.cpp:106] Iteration 3213, lr = 0.005
I0403 03:13:59.538017  4269 solver.cpp:228] Iteration 3234, loss = 0.00693954
I0403 03:13:59.544520  4269 solver.cpp:244]     Train net output #0: loss = 0.00693963 (* 1 = 0.00693963 loss)
I0403 03:13:59.747402  4269 sgd_solver.cpp:106] Iteration 3234, lr = 0.005
I0403 03:14:14.683261  4269 solver.cpp:228] Iteration 3255, loss = 0.00262939
I0403 03:14:14.688380  4269 solver.cpp:244]     Train net output #0: loss = 0.00262949 (* 1 = 0.00262949 loss)
I0403 03:14:14.902813  4269 sgd_solver.cpp:106] Iteration 3255, lr = 0.005
I0403 03:14:30.096688  4269 solver.cpp:228] Iteration 3276, loss = 0.00395029
I0403 03:14:30.103010  4269 solver.cpp:244]     Train net output #0: loss = 0.00395039 (* 1 = 0.00395039 loss)
I0403 03:14:30.285673  4269 sgd_solver.cpp:106] Iteration 3276, lr = 0.005
I0403 03:14:45.396472  4269 solver.cpp:228] Iteration 3297, loss = 0.00410757
I0403 03:14:45.403128  4269 solver.cpp:244]     Train net output #0: loss = 0.00410767 (* 1 = 0.00410767 loss)
I0403 03:14:45.577808  4269 sgd_solver.cpp:106] Iteration 3297, lr = 0.005
I0403 03:15:00.695318  4269 solver.cpp:228] Iteration 3318, loss = 0.00192324
I0403 03:15:00.700711  4269 solver.cpp:244]     Train net output #0: loss = 0.00192335 (* 1 = 0.00192335 loss)
I0403 03:15:00.874706  4269 sgd_solver.cpp:106] Iteration 3318, lr = 0.005
I0403 03:15:16.188817  4269 solver.cpp:228] Iteration 3339, loss = 0.00313728
I0403 03:15:16.195148  4269 solver.cpp:244]     Train net output #0: loss = 0.00313738 (* 1 = 0.00313738 loss)
I0403 03:15:16.392344  4269 sgd_solver.cpp:106] Iteration 3339, lr = 0.005
I0403 03:15:31.512969  4269 solver.cpp:228] Iteration 3360, loss = 0.0053726
I0403 03:15:31.519577  4269 solver.cpp:244]     Train net output #0: loss = 0.00537271 (* 1 = 0.00537271 loss)
I0403 03:15:31.695710  4269 sgd_solver.cpp:106] Iteration 3360, lr = 0.005
I0403 03:15:46.714727  4269 solver.cpp:228] Iteration 3381, loss = 0.0152013
I0403 03:15:46.721288  4269 solver.cpp:244]     Train net output #0: loss = 0.0152015 (* 1 = 0.0152015 loss)
I0403 03:15:46.902065  4269 sgd_solver.cpp:106] Iteration 3381, lr = 0.005
I0403 03:16:02.033025  4269 solver.cpp:228] Iteration 3402, loss = 0.00934063
I0403 03:16:02.039577  4269 solver.cpp:244]     Train net output #0: loss = 0.00934074 (* 1 = 0.00934074 loss)
I0403 03:16:02.214736  4269 sgd_solver.cpp:106] Iteration 3402, lr = 0.005
I0403 03:16:17.217387  4269 solver.cpp:228] Iteration 3423, loss = 0.0261597
I0403 03:16:17.222983  4269 solver.cpp:244]     Train net output #0: loss = 0.0261598 (* 1 = 0.0261598 loss)
I0403 03:16:17.408133  4269 sgd_solver.cpp:106] Iteration 3423, lr = 0.005
I0403 03:16:32.360867  4269 solver.cpp:228] Iteration 3444, loss = 0.0372496
I0403 03:16:32.367014  4269 solver.cpp:244]     Train net output #0: loss = 0.0372497 (* 1 = 0.0372497 loss)
I0403 03:16:32.555197  4269 sgd_solver.cpp:106] Iteration 3444, lr = 0.005
I0403 03:16:47.752656  4269 solver.cpp:228] Iteration 3465, loss = 0.032579
I0403 03:16:47.758535  4269 solver.cpp:244]     Train net output #0: loss = 0.0325791 (* 1 = 0.0325791 loss)
I0403 03:16:47.953944  4269 sgd_solver.cpp:106] Iteration 3465, lr = 0.005
I0403 03:16:58.233192  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_3480.caffemodel
I0403 03:17:01.047780  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_3480.solverstate
I0403 03:17:02.993114  4269 solver.cpp:337] Iteration 3480, Testing net (#0)
I0403 03:17:27.046109  4269 solver.cpp:404]     Test net output #0: accuracy = 0.979439
I0403 03:17:27.052588  4269 solver.cpp:404]     Test net output #1: loss = 0.0759416 (* 1 = 0.0759416 loss)
I0403 03:17:32.102083  4269 solver.cpp:228] Iteration 3486, loss = 0.00533079
I0403 03:17:32.107890  4269 solver.cpp:244]     Train net output #0: loss = 0.0053309 (* 1 = 0.0053309 loss)
I0403 03:17:32.283960  4269 sgd_solver.cpp:106] Iteration 3486, lr = 0.005
I0403 03:17:47.419134  4269 solver.cpp:228] Iteration 3507, loss = 0.00419659
I0403 03:17:47.426702  4269 solver.cpp:244]     Train net output #0: loss = 0.0041967 (* 1 = 0.0041967 loss)
I0403 03:17:47.591764  4269 sgd_solver.cpp:106] Iteration 3507, lr = 0.005
I0403 03:18:02.876938  4269 solver.cpp:228] Iteration 3528, loss = 0.022341
I0403 03:18:02.883618  4269 solver.cpp:244]     Train net output #0: loss = 0.0223412 (* 1 = 0.0223412 loss)
I0403 03:18:03.066830  4269 sgd_solver.cpp:106] Iteration 3528, lr = 0.005
I0403 03:18:18.146813  4269 solver.cpp:228] Iteration 3549, loss = 0.0116046
I0403 03:18:18.153257  4269 solver.cpp:244]     Train net output #0: loss = 0.0116047 (* 1 = 0.0116047 loss)
I0403 03:18:18.339736  4269 sgd_solver.cpp:106] Iteration 3549, lr = 0.005
I0403 03:18:33.577607  4269 solver.cpp:228] Iteration 3570, loss = 0.00471166
I0403 03:18:33.583987  4269 solver.cpp:244]     Train net output #0: loss = 0.00471176 (* 1 = 0.00471176 loss)
I0403 03:18:33.787395  4269 sgd_solver.cpp:106] Iteration 3570, lr = 0.005
I0403 03:18:49.014578  4269 solver.cpp:228] Iteration 3591, loss = 0.00275651
I0403 03:18:49.021304  4269 solver.cpp:244]     Train net output #0: loss = 0.00275661 (* 1 = 0.00275661 loss)
I0403 03:18:49.222250  4269 sgd_solver.cpp:106] Iteration 3591, lr = 0.005
I0403 03:19:04.406730  4269 solver.cpp:228] Iteration 3612, loss = 0.0667517
I0403 03:19:04.412262  4269 solver.cpp:244]     Train net output #0: loss = 0.0667518 (* 1 = 0.0667518 loss)
I0403 03:19:04.635911  4269 sgd_solver.cpp:106] Iteration 3612, lr = 0.005
I0403 03:19:19.793989  4269 solver.cpp:228] Iteration 3633, loss = 0.00474512
I0403 03:19:19.799504  4269 solver.cpp:244]     Train net output #0: loss = 0.00474523 (* 1 = 0.00474523 loss)
I0403 03:19:19.978461  4269 sgd_solver.cpp:106] Iteration 3633, lr = 0.005
I0403 03:19:35.080742  4269 solver.cpp:228] Iteration 3654, loss = 0.00173463
I0403 03:19:35.089267  4269 solver.cpp:244]     Train net output #0: loss = 0.00173473 (* 1 = 0.00173473 loss)
I0403 03:19:35.285218  4269 sgd_solver.cpp:106] Iteration 3654, lr = 0.005
I0403 03:19:50.453600  4269 solver.cpp:228] Iteration 3675, loss = 0.000443416
I0403 03:19:50.460983  4269 solver.cpp:244]     Train net output #0: loss = 0.000443519 (* 1 = 0.000443519 loss)
I0403 03:19:50.644744  4269 sgd_solver.cpp:106] Iteration 3675, lr = 0.005
I0403 03:20:05.870267  4269 solver.cpp:228] Iteration 3696, loss = 0.0546334
I0403 03:20:05.878026  4269 solver.cpp:244]     Train net output #0: loss = 0.0546335 (* 1 = 0.0546335 loss)
I0403 03:20:06.049960  4269 sgd_solver.cpp:106] Iteration 3696, lr = 0.005
I0403 03:20:21.107947  4269 solver.cpp:228] Iteration 3717, loss = 0.00307765
I0403 03:20:21.114023  4269 solver.cpp:244]     Train net output #0: loss = 0.00307775 (* 1 = 0.00307775 loss)
I0403 03:20:21.321579  4269 sgd_solver.cpp:106] Iteration 3717, lr = 0.005
I0403 03:20:36.314270  4269 solver.cpp:228] Iteration 3738, loss = 0.00223982
I0403 03:20:36.318825  4269 solver.cpp:244]     Train net output #0: loss = 0.00223992 (* 1 = 0.00223992 loss)
I0403 03:20:36.533071  4269 sgd_solver.cpp:106] Iteration 3738, lr = 0.005
I0403 03:20:51.994282  4269 solver.cpp:228] Iteration 3759, loss = 0.0283928
I0403 03:20:52.000705  4269 solver.cpp:244]     Train net output #0: loss = 0.0283929 (* 1 = 0.0283929 loss)
I0403 03:20:52.159497  4269 sgd_solver.cpp:106] Iteration 3759, lr = 0.005
I0403 03:21:07.560683  4269 solver.cpp:228] Iteration 3780, loss = 0.000874452
I0403 03:21:07.578299  4269 solver.cpp:244]     Train net output #0: loss = 0.000874555 (* 1 = 0.000874555 loss)
I0403 03:21:07.770527  4269 sgd_solver.cpp:106] Iteration 3780, lr = 0.005
I0403 03:21:22.778635  4269 solver.cpp:228] Iteration 3801, loss = 0.00408701
I0403 03:21:22.785032  4269 solver.cpp:244]     Train net output #0: loss = 0.00408711 (* 1 = 0.00408711 loss)
I0403 03:21:22.978101  4269 sgd_solver.cpp:106] Iteration 3801, lr = 0.005
I0403 03:21:37.829131  4269 solver.cpp:228] Iteration 3822, loss = 0.00962118
I0403 03:21:37.835582  4269 solver.cpp:244]     Train net output #0: loss = 0.00962128 (* 1 = 0.00962128 loss)
I0403 03:21:37.991281  4269 sgd_solver.cpp:106] Iteration 3822, lr = 0.005
I0403 03:21:53.034047  4269 solver.cpp:228] Iteration 3843, loss = 0.0159338
I0403 03:21:53.039974  4269 solver.cpp:244]     Train net output #0: loss = 0.0159339 (* 1 = 0.0159339 loss)
I0403 03:21:53.210131  4269 sgd_solver.cpp:106] Iteration 3843, lr = 0.005
I0403 03:22:08.328006  4269 solver.cpp:228] Iteration 3864, loss = 0.00363023
I0403 03:22:08.334980  4269 solver.cpp:244]     Train net output #0: loss = 0.00363033 (* 1 = 0.00363033 loss)
I0403 03:22:08.543229  4269 sgd_solver.cpp:106] Iteration 3864, lr = 0.005
I0403 03:22:23.499233  4269 solver.cpp:228] Iteration 3885, loss = 0.105809
I0403 03:22:23.506477  4269 solver.cpp:244]     Train net output #0: loss = 0.105809 (* 1 = 0.105809 loss)
I0403 03:22:23.698225  4269 sgd_solver.cpp:106] Iteration 3885, lr = 0.005
I0403 03:22:38.937640  4269 solver.cpp:228] Iteration 3906, loss = 0.0040553
I0403 03:22:38.944422  4269 solver.cpp:244]     Train net output #0: loss = 0.0040554 (* 1 = 0.0040554 loss)
I0403 03:22:39.123854  4269 sgd_solver.cpp:106] Iteration 3906, lr = 0.005
I0403 03:22:44.815587  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_3915.caffemodel
I0403 03:22:47.436769  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_3915.solverstate
I0403 03:22:49.203725  4269 solver.cpp:337] Iteration 3915, Testing net (#0)
I0403 03:23:13.258744  4269 solver.cpp:404]     Test net output #0: accuracy = 0.983739
I0403 03:23:13.264400  4269 solver.cpp:404]     Test net output #1: loss = 0.060919 (* 1 = 0.060919 loss)
I0403 03:23:22.430277  4269 solver.cpp:228] Iteration 3927, loss = 0.0378999
I0403 03:23:22.436511  4269 solver.cpp:244]     Train net output #0: loss = 0.0379 (* 1 = 0.0379 loss)
I0403 03:23:22.612722  4269 sgd_solver.cpp:106] Iteration 3927, lr = 0.005
I0403 03:23:37.613991  4269 solver.cpp:228] Iteration 3948, loss = 0.0120941
I0403 03:23:37.620066  4269 solver.cpp:244]     Train net output #0: loss = 0.0120942 (* 1 = 0.0120942 loss)
I0403 03:23:37.786919  4269 sgd_solver.cpp:106] Iteration 3948, lr = 0.005
I0403 03:23:52.824563  4269 solver.cpp:228] Iteration 3969, loss = 0.0457142
I0403 03:23:52.831102  4269 solver.cpp:244]     Train net output #0: loss = 0.0457143 (* 1 = 0.0457143 loss)
I0403 03:23:53.017436  4269 sgd_solver.cpp:106] Iteration 3969, lr = 0.005
I0403 03:24:08.003376  4269 solver.cpp:228] Iteration 3990, loss = 0.0114342
I0403 03:24:08.009584  4269 solver.cpp:244]     Train net output #0: loss = 0.0114343 (* 1 = 0.0114343 loss)
I0403 03:24:08.181051  4269 sgd_solver.cpp:106] Iteration 3990, lr = 0.005
I0403 03:24:23.350420  4269 solver.cpp:228] Iteration 4011, loss = 0.0236249
I0403 03:24:23.357492  4269 solver.cpp:244]     Train net output #0: loss = 0.023625 (* 1 = 0.023625 loss)
I0403 03:24:23.545274  4269 sgd_solver.cpp:106] Iteration 4011, lr = 0.005
I0403 03:24:38.569576  4269 solver.cpp:228] Iteration 4032, loss = 0.00236075
I0403 03:24:38.576297  4269 solver.cpp:244]     Train net output #0: loss = 0.00236083 (* 1 = 0.00236083 loss)
I0403 03:24:38.749893  4269 sgd_solver.cpp:106] Iteration 4032, lr = 0.005
I0403 03:24:54.024554  4269 solver.cpp:228] Iteration 4053, loss = 0.0103492
I0403 03:24:54.030975  4269 solver.cpp:244]     Train net output #0: loss = 0.0103493 (* 1 = 0.0103493 loss)
I0403 03:24:54.227416  4269 sgd_solver.cpp:106] Iteration 4053, lr = 0.005
I0403 03:25:09.571552  4269 solver.cpp:228] Iteration 4074, loss = 0.00231948
I0403 03:25:09.597167  4269 solver.cpp:244]     Train net output #0: loss = 0.00231957 (* 1 = 0.00231957 loss)
I0403 03:25:09.736554  4269 sgd_solver.cpp:106] Iteration 4074, lr = 0.005
I0403 03:25:24.987843  4269 solver.cpp:228] Iteration 4095, loss = 0.000463885
I0403 03:25:24.996531  4269 solver.cpp:244]     Train net output #0: loss = 0.000463974 (* 1 = 0.000463974 loss)
I0403 03:25:25.171424  4269 sgd_solver.cpp:106] Iteration 4095, lr = 0.005
I0403 03:25:40.571627  4269 solver.cpp:228] Iteration 4116, loss = 0.0341674
I0403 03:25:40.577996  4269 solver.cpp:244]     Train net output #0: loss = 0.0341675 (* 1 = 0.0341675 loss)
I0403 03:25:40.793836  4269 sgd_solver.cpp:106] Iteration 4116, lr = 0.005
I0403 03:25:56.056994  4269 solver.cpp:228] Iteration 4137, loss = 0.00229296
I0403 03:25:56.063313  4269 solver.cpp:244]     Train net output #0: loss = 0.00229305 (* 1 = 0.00229305 loss)
I0403 03:25:56.279245  4269 sgd_solver.cpp:106] Iteration 4137, lr = 0.005
I0403 03:26:11.447881  4269 solver.cpp:228] Iteration 4158, loss = 0.00348282
I0403 03:26:11.454298  4269 solver.cpp:244]     Train net output #0: loss = 0.00348291 (* 1 = 0.00348291 loss)
I0403 03:26:11.636685  4269 sgd_solver.cpp:106] Iteration 4158, lr = 0.005
I0403 03:26:26.618893  4269 solver.cpp:228] Iteration 4179, loss = 0.0793069
I0403 03:26:26.624912  4269 solver.cpp:244]     Train net output #0: loss = 0.0793069 (* 1 = 0.0793069 loss)
I0403 03:26:26.811868  4269 sgd_solver.cpp:106] Iteration 4179, lr = 0.005
I0403 03:26:41.993880  4269 solver.cpp:228] Iteration 4200, loss = 0.0128241
I0403 03:26:41.999289  4269 solver.cpp:244]     Train net output #0: loss = 0.0128242 (* 1 = 0.0128242 loss)
I0403 03:26:42.212201  4269 sgd_solver.cpp:106] Iteration 4200, lr = 0.005
I0403 03:26:57.504051  4269 solver.cpp:228] Iteration 4221, loss = 0.00423215
I0403 03:26:57.510180  4269 solver.cpp:244]     Train net output #0: loss = 0.00423223 (* 1 = 0.00423223 loss)
I0403 03:26:57.702671  4269 sgd_solver.cpp:106] Iteration 4221, lr = 0.005
I0403 03:27:13.097177  4269 solver.cpp:228] Iteration 4242, loss = 0.00659408
I0403 03:27:13.104516  4269 solver.cpp:244]     Train net output #0: loss = 0.00659417 (* 1 = 0.00659417 loss)
I0403 03:27:13.322183  4269 sgd_solver.cpp:106] Iteration 4242, lr = 0.005
I0403 03:27:28.456125  4269 solver.cpp:228] Iteration 4263, loss = 0.027223
I0403 03:27:28.461307  4269 solver.cpp:244]     Train net output #0: loss = 0.027223 (* 1 = 0.027223 loss)
I0403 03:27:28.692864  4269 sgd_solver.cpp:106] Iteration 4263, lr = 0.005
I0403 03:27:43.755523  4269 solver.cpp:228] Iteration 4284, loss = 0.000181081
I0403 03:27:43.763190  4269 solver.cpp:244]     Train net output #0: loss = 0.000181167 (* 1 = 0.000181167 loss)
I0403 03:27:43.992017  4269 sgd_solver.cpp:106] Iteration 4284, lr = 0.005
I0403 03:27:59.131381  4269 solver.cpp:228] Iteration 4305, loss = 0.0320691
I0403 03:27:59.138154  4269 solver.cpp:244]     Train net output #0: loss = 0.0320692 (* 1 = 0.0320692 loss)
I0403 03:27:59.314452  4269 sgd_solver.cpp:106] Iteration 4305, lr = 0.005
I0403 03:28:14.425611  4269 solver.cpp:228] Iteration 4326, loss = 0.000344149
I0403 03:28:14.431267  4269 solver.cpp:244]     Train net output #0: loss = 0.000344238 (* 1 = 0.000344238 loss)
I0403 03:28:14.599052  4269 sgd_solver.cpp:106] Iteration 4326, lr = 0.005
I0403 03:28:29.723696  4269 solver.cpp:228] Iteration 4347, loss = 0.00268871
I0403 03:28:29.730028  4269 solver.cpp:244]     Train net output #0: loss = 0.0026888 (* 1 = 0.0026888 loss)
I0403 03:28:29.893740  4269 sgd_solver.cpp:106] Iteration 4347, lr = 0.005
I0403 03:28:31.355581  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_4350.caffemodel
I0403 03:28:34.060467  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_4350.solverstate
I0403 03:28:35.891932  4269 solver.cpp:337] Iteration 4350, Testing net (#0)
I0403 03:28:59.952476  4269 solver.cpp:404]     Test net output #0: accuracy = 0.980841
I0403 03:28:59.958513  4269 solver.cpp:404]     Test net output #1: loss = 0.0732307 (* 1 = 0.0732307 loss)
I0403 03:29:13.544139  4269 solver.cpp:228] Iteration 4368, loss = 0.0262479
I0403 03:29:13.550881  4269 solver.cpp:244]     Train net output #0: loss = 0.026248 (* 1 = 0.026248 loss)
I0403 03:29:13.725744  4269 sgd_solver.cpp:106] Iteration 4368, lr = 0.0005
I0403 03:29:28.931035  4269 solver.cpp:228] Iteration 4389, loss = 0.00430846
I0403 03:29:28.937927  4269 solver.cpp:244]     Train net output #0: loss = 0.00430856 (* 1 = 0.00430856 loss)
I0403 03:29:29.091881  4269 sgd_solver.cpp:106] Iteration 4389, lr = 0.0005
I0403 03:29:44.399024  4269 solver.cpp:228] Iteration 4410, loss = 0.00483892
I0403 03:29:44.405156  4269 solver.cpp:244]     Train net output #0: loss = 0.00483901 (* 1 = 0.00483901 loss)
I0403 03:29:44.585584  4269 sgd_solver.cpp:106] Iteration 4410, lr = 0.0005
I0403 03:29:59.990211  4269 solver.cpp:228] Iteration 4431, loss = 0.0032947
I0403 03:29:59.996765  4269 solver.cpp:244]     Train net output #0: loss = 0.0032948 (* 1 = 0.0032948 loss)
I0403 03:30:00.170708  4269 sgd_solver.cpp:106] Iteration 4431, lr = 0.0005
I0403 03:30:15.270920  4269 solver.cpp:228] Iteration 4452, loss = 0.00153639
I0403 03:30:15.276732  4269 solver.cpp:244]     Train net output #0: loss = 0.00153648 (* 1 = 0.00153648 loss)
I0403 03:30:15.429242  4269 sgd_solver.cpp:106] Iteration 4452, lr = 0.0005
I0403 03:30:30.611807  4269 solver.cpp:228] Iteration 4473, loss = 0.000805099
I0403 03:30:30.617638  4269 solver.cpp:244]     Train net output #0: loss = 0.000805193 (* 1 = 0.000805193 loss)
I0403 03:30:30.793910  4269 sgd_solver.cpp:106] Iteration 4473, lr = 0.0005
I0403 03:30:45.786716  4269 solver.cpp:228] Iteration 4494, loss = 0.00138212
I0403 03:30:45.792568  4269 solver.cpp:244]     Train net output #0: loss = 0.00138222 (* 1 = 0.00138222 loss)
I0403 03:30:45.969297  4269 sgd_solver.cpp:106] Iteration 4494, lr = 0.0005
I0403 03:31:00.957937  4269 solver.cpp:228] Iteration 4515, loss = 0.00398859
I0403 03:31:00.964821  4269 solver.cpp:244]     Train net output #0: loss = 0.00398868 (* 1 = 0.00398868 loss)
I0403 03:31:01.155484  4269 sgd_solver.cpp:106] Iteration 4515, lr = 0.0005
I0403 03:31:16.194767  4269 solver.cpp:228] Iteration 4536, loss = 0.000996779
I0403 03:31:16.202733  4269 solver.cpp:244]     Train net output #0: loss = 0.000996871 (* 1 = 0.000996871 loss)
I0403 03:31:16.385520  4269 sgd_solver.cpp:106] Iteration 4536, lr = 0.0005
I0403 03:31:31.429477  4269 solver.cpp:228] Iteration 4557, loss = 0.000803841
I0403 03:31:31.436398  4269 solver.cpp:244]     Train net output #0: loss = 0.000803927 (* 1 = 0.000803927 loss)
I0403 03:31:31.631510  4269 sgd_solver.cpp:106] Iteration 4557, lr = 0.0005
I0403 03:31:46.807101  4269 solver.cpp:228] Iteration 4578, loss = 0.00362785
I0403 03:31:46.813261  4269 solver.cpp:244]     Train net output #0: loss = 0.00362794 (* 1 = 0.00362794 loss)
I0403 03:31:46.970249  4269 sgd_solver.cpp:106] Iteration 4578, lr = 0.0005
I0403 03:32:02.294600  4269 solver.cpp:228] Iteration 4599, loss = 0.000217311
I0403 03:32:02.301352  4269 solver.cpp:244]     Train net output #0: loss = 0.000217396 (* 1 = 0.000217396 loss)
I0403 03:32:02.497766  4269 sgd_solver.cpp:106] Iteration 4599, lr = 0.0005
I0403 03:32:17.605015  4269 solver.cpp:228] Iteration 4620, loss = 0.0105475
I0403 03:32:17.610766  4269 solver.cpp:244]     Train net output #0: loss = 0.0105476 (* 1 = 0.0105476 loss)
I0403 03:32:17.795526  4269 sgd_solver.cpp:106] Iteration 4620, lr = 0.0005
I0403 03:32:32.950201  4269 solver.cpp:228] Iteration 4641, loss = 0.0107569
I0403 03:32:32.956712  4269 solver.cpp:244]     Train net output #0: loss = 0.010757 (* 1 = 0.010757 loss)
I0403 03:32:33.121162  4269 sgd_solver.cpp:106] Iteration 4641, lr = 0.0005
I0403 03:32:48.537590  4269 solver.cpp:228] Iteration 4662, loss = 0.0120644
I0403 03:32:48.544270  4269 solver.cpp:244]     Train net output #0: loss = 0.0120645 (* 1 = 0.0120645 loss)
I0403 03:32:48.725116  4269 sgd_solver.cpp:106] Iteration 4662, lr = 0.0005
I0403 03:33:04.049064  4269 solver.cpp:228] Iteration 4683, loss = 0.0001928
I0403 03:33:04.055099  4269 solver.cpp:244]     Train net output #0: loss = 0.000192887 (* 1 = 0.000192887 loss)
I0403 03:33:04.237413  4269 sgd_solver.cpp:106] Iteration 4683, lr = 0.0005
I0403 03:33:19.493435  4269 solver.cpp:228] Iteration 4704, loss = 0.00028019
I0403 03:33:19.500162  4269 solver.cpp:244]     Train net output #0: loss = 0.000280277 (* 1 = 0.000280277 loss)
I0403 03:33:19.709359  4269 sgd_solver.cpp:106] Iteration 4704, lr = 0.0005
I0403 03:33:34.795889  4269 solver.cpp:228] Iteration 4725, loss = 0.00317389
I0403 03:33:34.802877  4269 solver.cpp:244]     Train net output #0: loss = 0.00317398 (* 1 = 0.00317398 loss)
I0403 03:33:35.011957  4269 sgd_solver.cpp:106] Iteration 4725, lr = 0.0005
I0403 03:33:50.198441  4269 solver.cpp:228] Iteration 4746, loss = 0.00107342
I0403 03:33:50.204044  4269 solver.cpp:244]     Train net output #0: loss = 0.00107351 (* 1 = 0.00107351 loss)
I0403 03:33:50.380523  4269 sgd_solver.cpp:106] Iteration 4746, lr = 0.0005
I0403 03:34:05.577857  4269 solver.cpp:228] Iteration 4767, loss = 0.000545401
I0403 03:34:05.583453  4269 solver.cpp:244]     Train net output #0: loss = 0.000545485 (* 1 = 0.000545485 loss)
I0403 03:34:05.772686  4269 sgd_solver.cpp:106] Iteration 4767, lr = 0.0005
I0403 03:34:18.185061  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_4785.caffemodel
I0403 03:34:20.954787  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_4785.solverstate
I0403 03:34:22.865723  4269 solver.cpp:337] Iteration 4785, Testing net (#0)
I0403 03:34:46.916839  4269 solver.cpp:404]     Test net output #0: accuracy = 0.987664
I0403 03:34:46.916942  4269 solver.cpp:404]     Test net output #1: loss = 0.0503176 (* 1 = 0.0503176 loss)
I0403 03:34:49.761785  4269 solver.cpp:228] Iteration 4788, loss = 0.001122
I0403 03:34:49.761872  4269 solver.cpp:244]     Train net output #0: loss = 0.00112208 (* 1 = 0.00112208 loss)
I0403 03:34:49.926602  4269 sgd_solver.cpp:106] Iteration 4788, lr = 0.0005
I0403 03:35:05.026289  4269 solver.cpp:228] Iteration 4809, loss = 0.000324411
I0403 03:35:05.026598  4269 solver.cpp:244]     Train net output #0: loss = 0.000324492 (* 1 = 0.000324492 loss)
I0403 03:35:05.203758  4269 sgd_solver.cpp:106] Iteration 4809, lr = 0.0005
I0403 03:35:20.305898  4269 solver.cpp:228] Iteration 4830, loss = 0.000325224
I0403 03:35:20.305995  4269 solver.cpp:244]     Train net output #0: loss = 0.000325306 (* 1 = 0.000325306 loss)
I0403 03:35:20.496799  4269 sgd_solver.cpp:106] Iteration 4830, lr = 0.0005
I0403 03:35:36.002926  4269 solver.cpp:228] Iteration 4851, loss = 2.93833e-05
I0403 03:35:36.003238  4269 solver.cpp:244]     Train net output #0: loss = 2.94653e-05 (* 1 = 2.94653e-05 loss)
I0403 03:35:36.197207  4269 sgd_solver.cpp:106] Iteration 4851, lr = 0.0005
I0403 03:35:51.315362  4269 solver.cpp:228] Iteration 4872, loss = 0.0322572
I0403 03:35:51.315453  4269 solver.cpp:244]     Train net output #0: loss = 0.0322573 (* 1 = 0.0322573 loss)
I0403 03:35:51.463917  4269 sgd_solver.cpp:106] Iteration 4872, lr = 0.0005
I0403 03:36:06.776754  4269 solver.cpp:228] Iteration 4893, loss = 0.000342228
I0403 03:36:06.777108  4269 solver.cpp:244]     Train net output #0: loss = 0.000342312 (* 1 = 0.000342312 loss)
I0403 03:36:06.957497  4269 sgd_solver.cpp:106] Iteration 4893, lr = 0.0005
I0403 03:36:21.992209  4269 solver.cpp:228] Iteration 4914, loss = 0.00263749
I0403 03:36:21.992312  4269 solver.cpp:244]     Train net output #0: loss = 0.00263757 (* 1 = 0.00263757 loss)
I0403 03:36:22.207298  4269 sgd_solver.cpp:106] Iteration 4914, lr = 0.0005
I0403 03:36:37.534536  4269 solver.cpp:228] Iteration 4935, loss = 0.026721
I0403 03:36:37.534857  4269 solver.cpp:244]     Train net output #0: loss = 0.0267211 (* 1 = 0.0267211 loss)
I0403 03:36:37.687574  4269 sgd_solver.cpp:106] Iteration 4935, lr = 0.0005
I0403 03:36:53.145058  4269 solver.cpp:228] Iteration 4956, loss = 0.00157045
I0403 03:36:53.145158  4269 solver.cpp:244]     Train net output #0: loss = 0.00157053 (* 1 = 0.00157053 loss)
I0403 03:36:53.361744  4269 sgd_solver.cpp:106] Iteration 4956, lr = 0.0005
I0403 03:37:08.893522  4269 solver.cpp:228] Iteration 4977, loss = 0.000251442
I0403 03:37:08.893822  4269 solver.cpp:244]     Train net output #0: loss = 0.000251526 (* 1 = 0.000251526 loss)
I0403 03:37:09.063359  4269 sgd_solver.cpp:106] Iteration 4977, lr = 0.0005
I0403 03:37:24.374312  4269 solver.cpp:228] Iteration 4998, loss = 0.0108243
I0403 03:37:24.374402  4269 solver.cpp:244]     Train net output #0: loss = 0.0108244 (* 1 = 0.0108244 loss)
I0403 03:37:24.555502  4269 sgd_solver.cpp:106] Iteration 4998, lr = 0.0005
I0403 03:37:39.761301  4269 solver.cpp:228] Iteration 5019, loss = 0.0275063
I0403 03:37:39.761627  4269 solver.cpp:244]     Train net output #0: loss = 0.0275063 (* 1 = 0.0275063 loss)
I0403 03:37:39.962043  4269 sgd_solver.cpp:106] Iteration 5019, lr = 0.0005
I0403 03:37:55.101933  4269 solver.cpp:228] Iteration 5040, loss = 0.00586796
I0403 03:37:55.102037  4269 solver.cpp:244]     Train net output #0: loss = 0.00586804 (* 1 = 0.00586804 loss)
I0403 03:37:55.312613  4269 sgd_solver.cpp:106] Iteration 5040, lr = 0.0005
I0403 03:38:10.687487  4269 solver.cpp:228] Iteration 5061, loss = 0.000995153
I0403 03:38:10.687808  4269 solver.cpp:244]     Train net output #0: loss = 0.000995234 (* 1 = 0.000995234 loss)
I0403 03:38:10.858356  4269 sgd_solver.cpp:106] Iteration 5061, lr = 0.0005
I0403 03:38:26.255717  4269 solver.cpp:228] Iteration 5082, loss = 0.00155739
I0403 03:38:26.255815  4269 solver.cpp:244]     Train net output #0: loss = 0.00155747 (* 1 = 0.00155747 loss)
I0403 03:38:26.476842  4269 sgd_solver.cpp:106] Iteration 5082, lr = 0.0005
I0403 03:38:41.633653  4269 solver.cpp:228] Iteration 5103, loss = 0.000502869
I0403 03:38:41.633983  4269 solver.cpp:244]     Train net output #0: loss = 0.000502948 (* 1 = 0.000502948 loss)
I0403 03:38:41.835032  4269 sgd_solver.cpp:106] Iteration 5103, lr = 0.0005
I0403 03:38:57.114389  4269 solver.cpp:228] Iteration 5124, loss = 0.000775179
I0403 03:38:57.114490  4269 solver.cpp:244]     Train net output #0: loss = 0.000775258 (* 1 = 0.000775258 loss)
I0403 03:38:57.332178  4269 sgd_solver.cpp:106] Iteration 5124, lr = 0.0005
I0403 03:39:12.734900  4269 solver.cpp:228] Iteration 5145, loss = 0.000869367
I0403 03:39:12.735224  4269 solver.cpp:244]     Train net output #0: loss = 0.000869446 (* 1 = 0.000869446 loss)
I0403 03:39:12.874490  4269 sgd_solver.cpp:106] Iteration 5145, lr = 0.0005
I0403 03:39:28.177647  4269 solver.cpp:228] Iteration 5166, loss = 0.000693533
I0403 03:39:28.177738  4269 solver.cpp:244]     Train net output #0: loss = 0.000693611 (* 1 = 0.000693611 loss)
I0403 03:39:28.437544  4269 sgd_solver.cpp:106] Iteration 5166, lr = 0.0005
I0403 03:39:43.771472  4269 solver.cpp:228] Iteration 5187, loss = 0.00714283
I0403 03:39:43.771787  4269 solver.cpp:244]     Train net output #0: loss = 0.00714291 (* 1 = 0.00714291 loss)
I0403 03:39:43.904386  4269 sgd_solver.cpp:106] Iteration 5187, lr = 0.0005
I0403 03:39:59.376111  4269 solver.cpp:228] Iteration 5208, loss = 0.000324958
I0403 03:39:59.376199  4269 solver.cpp:244]     Train net output #0: loss = 0.000325036 (* 1 = 0.000325036 loss)
I0403 03:39:59.557342  4269 sgd_solver.cpp:106] Iteration 5208, lr = 0.0005
I0403 03:40:07.558511  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_5220.caffemodel
I0403 03:40:10.351699  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_5220.solverstate
I0403 03:40:12.256150  4269 solver.cpp:337] Iteration 5220, Testing net (#0)
I0403 03:40:36.310719  4269 solver.cpp:404]     Test net output #0: accuracy = 0.98785
I0403 03:40:36.311029  4269 solver.cpp:404]     Test net output #1: loss = 0.047587 (* 1 = 0.047587 loss)
I0403 03:40:43.506309  4269 solver.cpp:228] Iteration 5229, loss = 0.00131954
I0403 03:40:43.506407  4269 solver.cpp:244]     Train net output #0: loss = 0.00131962 (* 1 = 0.00131962 loss)
I0403 03:40:43.703325  4269 sgd_solver.cpp:106] Iteration 5229, lr = 0.0005
I0403 03:40:58.888396  4269 solver.cpp:228] Iteration 5250, loss = 0.0175598
I0403 03:40:58.888481  4269 solver.cpp:244]     Train net output #0: loss = 0.0175599 (* 1 = 0.0175599 loss)
I0403 03:40:59.065569  4269 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0403 03:41:14.453373  4269 solver.cpp:228] Iteration 5271, loss = 0.00235028
I0403 03:41:14.453687  4269 solver.cpp:244]     Train net output #0: loss = 0.00235035 (* 1 = 0.00235035 loss)
I0403 03:41:14.625385  4269 sgd_solver.cpp:106] Iteration 5271, lr = 0.0005
I0403 03:41:29.867771  4269 solver.cpp:228] Iteration 5292, loss = 0.000288834
I0403 03:41:29.867856  4269 solver.cpp:244]     Train net output #0: loss = 0.000288909 (* 1 = 0.000288909 loss)
I0403 03:41:30.049799  4269 sgd_solver.cpp:106] Iteration 5292, lr = 0.0005
I0403 03:41:45.334642  4269 solver.cpp:228] Iteration 5313, loss = 0.00106842
I0403 03:41:45.334967  4269 solver.cpp:244]     Train net output #0: loss = 0.0010685 (* 1 = 0.0010685 loss)
I0403 03:41:45.529364  4269 sgd_solver.cpp:106] Iteration 5313, lr = 0.0005
I0403 03:42:00.857442  4269 solver.cpp:228] Iteration 5334, loss = 0.000413653
I0403 03:42:00.857529  4269 solver.cpp:244]     Train net output #0: loss = 0.000413727 (* 1 = 0.000413727 loss)
I0403 03:42:01.033149  4269 sgd_solver.cpp:106] Iteration 5334, lr = 0.0005
I0403 03:42:16.327356  4269 solver.cpp:228] Iteration 5355, loss = 0.000971122
I0403 03:42:16.327692  4269 solver.cpp:244]     Train net output #0: loss = 0.000971194 (* 1 = 0.000971194 loss)
I0403 03:42:16.525337  4269 sgd_solver.cpp:106] Iteration 5355, lr = 0.0005
I0403 03:42:31.568400  4269 solver.cpp:228] Iteration 5376, loss = 0.000150439
I0403 03:42:31.568490  4269 solver.cpp:244]     Train net output #0: loss = 0.000150512 (* 1 = 0.000150512 loss)
I0403 03:42:31.720247  4269 sgd_solver.cpp:106] Iteration 5376, lr = 0.0005
I0403 03:42:46.883744  4269 solver.cpp:228] Iteration 5397, loss = 0.0120969
I0403 03:42:46.884012  4269 solver.cpp:244]     Train net output #0: loss = 0.012097 (* 1 = 0.012097 loss)
I0403 03:42:47.109776  4269 sgd_solver.cpp:106] Iteration 5397, lr = 0.0005
I0403 03:43:02.255803  4269 solver.cpp:228] Iteration 5418, loss = 0.00386237
I0403 03:43:02.255897  4269 solver.cpp:244]     Train net output #0: loss = 0.00386245 (* 1 = 0.00386245 loss)
I0403 03:43:02.458441  4269 sgd_solver.cpp:106] Iteration 5418, lr = 0.0005
I0403 03:43:17.778869  4269 solver.cpp:228] Iteration 5439, loss = 0.000936739
I0403 03:43:17.789810  4269 solver.cpp:244]     Train net output #0: loss = 0.000936814 (* 1 = 0.000936814 loss)
I0403 03:43:17.963536  4269 sgd_solver.cpp:106] Iteration 5439, lr = 0.0005
I0403 03:43:33.275355  4269 solver.cpp:228] Iteration 5460, loss = 0.000230478
I0403 03:43:33.275450  4269 solver.cpp:244]     Train net output #0: loss = 0.000230553 (* 1 = 0.000230553 loss)
I0403 03:43:33.474195  4269 sgd_solver.cpp:106] Iteration 5460, lr = 0.0005
I0403 03:43:48.619652  4269 solver.cpp:228] Iteration 5481, loss = 9.51698e-05
I0403 03:43:48.619976  4269 solver.cpp:244]     Train net output #0: loss = 9.52462e-05 (* 1 = 9.52462e-05 loss)
I0403 03:43:48.805341  4269 sgd_solver.cpp:106] Iteration 5481, lr = 0.0005
I0403 03:44:04.019062  4269 solver.cpp:228] Iteration 5502, loss = 0.000803927
I0403 03:44:04.019157  4269 solver.cpp:244]     Train net output #0: loss = 0.000804004 (* 1 = 0.000804004 loss)
I0403 03:44:04.224000  4269 sgd_solver.cpp:106] Iteration 5502, lr = 0.0005
I0403 03:44:19.383405  4269 solver.cpp:228] Iteration 5523, loss = 0.00448796
I0403 03:44:19.383723  4269 solver.cpp:244]     Train net output #0: loss = 0.00448803 (* 1 = 0.00448803 loss)
I0403 03:44:19.565567  4269 sgd_solver.cpp:106] Iteration 5523, lr = 0.0005
I0403 03:44:34.843439  4269 solver.cpp:228] Iteration 5544, loss = 0.000957645
I0403 03:44:34.843526  4269 solver.cpp:244]     Train net output #0: loss = 0.000957721 (* 1 = 0.000957721 loss)
I0403 03:44:35.021255  4269 sgd_solver.cpp:106] Iteration 5544, lr = 0.0005
I0403 03:44:50.281302  4269 solver.cpp:228] Iteration 5565, loss = 0.000114196
I0403 03:44:50.281607  4269 solver.cpp:244]     Train net output #0: loss = 0.000114272 (* 1 = 0.000114272 loss)
I0403 03:44:50.424819  4269 sgd_solver.cpp:106] Iteration 5565, lr = 0.0005
I0403 03:45:05.771845  4269 solver.cpp:228] Iteration 5586, loss = 0.00275033
I0403 03:45:05.771939  4269 solver.cpp:244]     Train net output #0: loss = 0.00275041 (* 1 = 0.00275041 loss)
I0403 03:45:05.987669  4269 sgd_solver.cpp:106] Iteration 5586, lr = 0.0005
I0403 03:45:21.264183  4269 solver.cpp:228] Iteration 5607, loss = 0.00225005
I0403 03:45:21.264492  4269 solver.cpp:244]     Train net output #0: loss = 0.00225013 (* 1 = 0.00225013 loss)
I0403 03:45:21.456959  4269 sgd_solver.cpp:106] Iteration 5607, lr = 0.0005
I0403 03:45:36.795913  4269 solver.cpp:228] Iteration 5628, loss = 5.69063e-05
I0403 03:45:36.796010  4269 solver.cpp:244]     Train net output #0: loss = 5.69825e-05 (* 1 = 5.69825e-05 loss)
I0403 03:45:36.991462  4269 sgd_solver.cpp:106] Iteration 5628, lr = 0.0005
I0403 03:45:52.304277  4269 solver.cpp:228] Iteration 5649, loss = 0.00590829
I0403 03:45:52.304579  4269 solver.cpp:244]     Train net output #0: loss = 0.00590836 (* 1 = 0.00590836 loss)
I0403 03:45:52.499557  4269 sgd_solver.cpp:106] Iteration 5649, lr = 0.0005
I0403 03:45:56.174952  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_5655.caffemodel
I0403 03:45:58.929308  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_5655.solverstate
I0403 03:46:00.839663  4269 solver.cpp:337] Iteration 5655, Testing net (#0)
I0403 03:46:24.892647  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988037
I0403 03:46:24.892969  4269 solver.cpp:404]     Test net output #1: loss = 0.0458758 (* 1 = 0.0458758 loss)
I0403 03:46:36.378774  4269 solver.cpp:228] Iteration 5670, loss = 0.000463379
I0403 03:46:36.378861  4269 solver.cpp:244]     Train net output #0: loss = 0.000463454 (* 1 = 0.000463454 loss)
I0403 03:46:36.557457  4269 sgd_solver.cpp:106] Iteration 5670, lr = 0.0005
I0403 03:46:51.843912  4269 solver.cpp:228] Iteration 5691, loss = 5.5933e-05
I0403 03:46:51.843999  4269 solver.cpp:244]     Train net output #0: loss = 5.60073e-05 (* 1 = 5.60073e-05 loss)
I0403 03:46:52.024428  4269 sgd_solver.cpp:106] Iteration 5691, lr = 0.0005
I0403 03:47:07.225796  4269 solver.cpp:228] Iteration 5712, loss = 0.00123236
I0403 03:47:07.226115  4269 solver.cpp:244]     Train net output #0: loss = 0.00123244 (* 1 = 0.00123244 loss)
I0403 03:47:07.406417  4269 sgd_solver.cpp:106] Iteration 5712, lr = 0.0005
I0403 03:47:22.507915  4269 solver.cpp:228] Iteration 5733, loss = 0.000756428
I0403 03:47:22.508013  4269 solver.cpp:244]     Train net output #0: loss = 0.000756502 (* 1 = 0.000756502 loss)
I0403 03:47:22.691630  4269 sgd_solver.cpp:106] Iteration 5733, lr = 0.0005
I0403 03:47:37.780510  4269 solver.cpp:228] Iteration 5754, loss = 0.00194192
I0403 03:47:37.780804  4269 solver.cpp:244]     Train net output #0: loss = 0.00194199 (* 1 = 0.00194199 loss)
I0403 03:47:37.916412  4269 sgd_solver.cpp:106] Iteration 5754, lr = 0.0005
I0403 03:47:53.395679  4269 solver.cpp:228] Iteration 5775, loss = 0.001285
I0403 03:47:53.395779  4269 solver.cpp:244]     Train net output #0: loss = 0.00128507 (* 1 = 0.00128507 loss)
I0403 03:47:53.598031  4269 sgd_solver.cpp:106] Iteration 5775, lr = 0.0005
I0403 03:48:08.548230  4269 solver.cpp:228] Iteration 5796, loss = 0.000413835
I0403 03:48:08.548543  4269 solver.cpp:244]     Train net output #0: loss = 0.000413908 (* 1 = 0.000413908 loss)
I0403 03:48:08.725916  4269 sgd_solver.cpp:106] Iteration 5796, lr = 0.0005
I0403 03:48:23.898643  4269 solver.cpp:228] Iteration 5817, loss = 0.00689842
I0403 03:48:23.898749  4269 solver.cpp:244]     Train net output #0: loss = 0.0068985 (* 1 = 0.0068985 loss)
I0403 03:48:24.077272  4269 sgd_solver.cpp:106] Iteration 5817, lr = 0.0005
I0403 03:48:39.394366  4269 solver.cpp:228] Iteration 5838, loss = 0.000499031
I0403 03:48:39.394666  4269 solver.cpp:244]     Train net output #0: loss = 0.000499104 (* 1 = 0.000499104 loss)
I0403 03:48:39.560827  4269 sgd_solver.cpp:106] Iteration 5838, lr = 0.0005
I0403 03:48:54.766162  4269 solver.cpp:228] Iteration 5859, loss = 0.000671592
I0403 03:48:54.766261  4269 solver.cpp:244]     Train net output #0: loss = 0.000671664 (* 1 = 0.000671664 loss)
I0403 03:48:54.956684  4269 sgd_solver.cpp:106] Iteration 5859, lr = 0.0005
I0403 03:49:10.024281  4269 solver.cpp:228] Iteration 5880, loss = 0.000385121
I0403 03:49:10.024559  4269 solver.cpp:244]     Train net output #0: loss = 0.000385193 (* 1 = 0.000385193 loss)
I0403 03:49:10.196202  4269 sgd_solver.cpp:106] Iteration 5880, lr = 0.0005
I0403 03:49:25.297365  4269 solver.cpp:228] Iteration 5901, loss = 0.000912162
I0403 03:49:25.297453  4269 solver.cpp:244]     Train net output #0: loss = 0.000912235 (* 1 = 0.000912235 loss)
I0403 03:49:25.478473  4269 sgd_solver.cpp:106] Iteration 5901, lr = 0.0005
I0403 03:49:40.698361  4269 solver.cpp:228] Iteration 5922, loss = 0.000685976
I0403 03:49:40.698688  4269 solver.cpp:244]     Train net output #0: loss = 0.000686051 (* 1 = 0.000686051 loss)
I0403 03:49:40.883889  4269 sgd_solver.cpp:106] Iteration 5922, lr = 0.0005
I0403 03:49:56.140342  4269 solver.cpp:228] Iteration 5943, loss = 0.00018213
I0403 03:49:56.141139  4269 solver.cpp:244]     Train net output #0: loss = 0.000182206 (* 1 = 0.000182206 loss)
I0403 03:49:56.321873  4269 sgd_solver.cpp:106] Iteration 5943, lr = 0.0005
I0403 03:50:11.760462  4269 solver.cpp:228] Iteration 5964, loss = 0.000439042
I0403 03:50:11.760767  4269 solver.cpp:244]     Train net output #0: loss = 0.000439118 (* 1 = 0.000439118 loss)
I0403 03:50:11.978497  4269 sgd_solver.cpp:106] Iteration 5964, lr = 0.0005
I0403 03:50:27.344153  4269 solver.cpp:228] Iteration 5985, loss = 0.000170602
I0403 03:50:27.344243  4269 solver.cpp:244]     Train net output #0: loss = 0.000170679 (* 1 = 0.000170679 loss)
I0403 03:50:27.460597  4269 sgd_solver.cpp:106] Iteration 5985, lr = 0.0005
I0403 03:50:42.786834  4269 solver.cpp:228] Iteration 6006, loss = 0.00525599
I0403 03:50:42.787152  4269 solver.cpp:244]     Train net output #0: loss = 0.00525606 (* 1 = 0.00525606 loss)
I0403 03:50:42.967504  4269 sgd_solver.cpp:106] Iteration 6006, lr = 0.0005
I0403 03:50:58.130296  4269 solver.cpp:228] Iteration 6027, loss = 0.000260768
I0403 03:50:58.130389  4269 solver.cpp:244]     Train net output #0: loss = 0.000260845 (* 1 = 0.000260845 loss)
I0403 03:50:58.344403  4269 sgd_solver.cpp:106] Iteration 6027, lr = 0.0005
I0403 03:51:13.585237  4269 solver.cpp:228] Iteration 6048, loss = 0.000108163
I0403 03:51:13.585532  4269 solver.cpp:244]     Train net output #0: loss = 0.000108241 (* 1 = 0.000108241 loss)
I0403 03:51:13.745307  4269 sgd_solver.cpp:106] Iteration 6048, lr = 0.0005
I0403 03:51:28.890729  4269 solver.cpp:228] Iteration 6069, loss = 0.000441766
I0403 03:51:28.890817  4269 solver.cpp:244]     Train net output #0: loss = 0.000441844 (* 1 = 0.000441844 loss)
I0403 03:51:29.066532  4269 sgd_solver.cpp:106] Iteration 6069, lr = 0.0005
I0403 03:51:43.806406  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_6090.caffemodel
I0403 03:51:46.469420  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_6090.solverstate
I0403 03:51:48.246197  4269 solver.cpp:337] Iteration 6090, Testing net (#0)
I0403 03:52:12.296854  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988318
I0403 03:52:12.296947  4269 solver.cpp:404]     Test net output #1: loss = 0.0455885 (* 1 = 0.0455885 loss)
I0403 03:52:12.802741  4269 solver.cpp:228] Iteration 6090, loss = 0.000396893
I0403 03:52:12.802825  4269 solver.cpp:244]     Train net output #0: loss = 0.00039697 (* 1 = 0.00039697 loss)
I0403 03:52:12.982393  4269 sgd_solver.cpp:106] Iteration 6090, lr = 0.0005
I0403 03:52:28.269721  4269 solver.cpp:228] Iteration 6111, loss = 0.00190012
I0403 03:52:28.270040  4269 solver.cpp:244]     Train net output #0: loss = 0.00190019 (* 1 = 0.00190019 loss)
I0403 03:52:28.452304  4269 sgd_solver.cpp:106] Iteration 6111, lr = 0.0005
I0403 03:52:43.674317  4269 solver.cpp:228] Iteration 6132, loss = 0.000971875
I0403 03:52:43.674407  4269 solver.cpp:244]     Train net output #0: loss = 0.000971951 (* 1 = 0.000971951 loss)
I0403 03:52:43.846920  4269 sgd_solver.cpp:106] Iteration 6132, lr = 0.0005
I0403 03:52:59.170332  4269 solver.cpp:228] Iteration 6153, loss = 1.40838e-05
I0403 03:52:59.170622  4269 solver.cpp:244]     Train net output #0: loss = 1.41582e-05 (* 1 = 1.41582e-05 loss)
I0403 03:52:59.316862  4269 sgd_solver.cpp:106] Iteration 6153, lr = 0.0005
I0403 03:53:14.562449  4269 solver.cpp:228] Iteration 6174, loss = 0.00206027
I0403 03:53:14.562538  4269 solver.cpp:244]     Train net output #0: loss = 0.00206035 (* 1 = 0.00206035 loss)
I0403 03:53:14.725107  4269 sgd_solver.cpp:106] Iteration 6174, lr = 0.0005
I0403 03:53:29.986134  4269 solver.cpp:228] Iteration 6195, loss = 0.00117362
I0403 03:53:29.986431  4269 solver.cpp:244]     Train net output #0: loss = 0.0011737 (* 1 = 0.0011737 loss)
I0403 03:53:30.205260  4269 sgd_solver.cpp:106] Iteration 6195, lr = 0.0005
I0403 03:53:45.299315  4269 solver.cpp:228] Iteration 6216, loss = 0.00158148
I0403 03:53:45.299403  4269 solver.cpp:244]     Train net output #0: loss = 0.00158156 (* 1 = 0.00158156 loss)
I0403 03:53:45.480487  4269 sgd_solver.cpp:106] Iteration 6216, lr = 0.0005
I0403 03:54:00.508957  4269 solver.cpp:228] Iteration 6237, loss = 0.000376337
I0403 03:54:00.509301  4269 solver.cpp:244]     Train net output #0: loss = 0.000376413 (* 1 = 0.000376413 loss)
I0403 03:54:00.705133  4269 sgd_solver.cpp:106] Iteration 6237, lr = 0.0005
I0403 03:54:15.828171  4269 solver.cpp:228] Iteration 6258, loss = 0.000409363
I0403 03:54:15.828277  4269 solver.cpp:244]     Train net output #0: loss = 0.000409439 (* 1 = 0.000409439 loss)
I0403 03:54:16.019546  4269 sgd_solver.cpp:106] Iteration 6258, lr = 0.0005
I0403 03:54:31.240042  4269 solver.cpp:228] Iteration 6279, loss = 0.000500692
I0403 03:54:31.240342  4269 solver.cpp:244]     Train net output #0: loss = 0.00050077 (* 1 = 0.00050077 loss)
I0403 03:54:31.502727  4269 sgd_solver.cpp:106] Iteration 6279, lr = 0.0005
I0403 03:54:46.508968  4269 solver.cpp:228] Iteration 6300, loss = 0.000658555
I0403 03:54:46.509068  4269 solver.cpp:244]     Train net output #0: loss = 0.000658634 (* 1 = 0.000658634 loss)
I0403 03:54:46.713248  4269 sgd_solver.cpp:106] Iteration 6300, lr = 0.0005
I0403 03:55:01.807283  4269 solver.cpp:228] Iteration 6321, loss = 0.00150426
I0403 03:55:01.807595  4269 solver.cpp:244]     Train net output #0: loss = 0.00150434 (* 1 = 0.00150434 loss)
I0403 03:55:02.025641  4269 sgd_solver.cpp:106] Iteration 6321, lr = 0.0005
I0403 03:55:17.245455  4269 solver.cpp:228] Iteration 6342, loss = 0.00101161
I0403 03:55:17.250412  4269 solver.cpp:244]     Train net output #0: loss = 0.00101169 (* 1 = 0.00101169 loss)
I0403 03:55:17.426952  4269 sgd_solver.cpp:106] Iteration 6342, lr = 0.0005
I0403 03:55:32.845177  4269 solver.cpp:228] Iteration 6363, loss = 0.0038534
I0403 03:55:32.852637  4269 solver.cpp:244]     Train net output #0: loss = 0.00385348 (* 1 = 0.00385348 loss)
I0403 03:55:33.038324  4269 sgd_solver.cpp:106] Iteration 6363, lr = 0.0005
I0403 03:55:48.476006  4269 solver.cpp:228] Iteration 6384, loss = 0.000957471
I0403 03:55:48.476099  4269 solver.cpp:244]     Train net output #0: loss = 0.000957552 (* 1 = 0.000957552 loss)
I0403 03:55:48.666038  4269 sgd_solver.cpp:106] Iteration 6384, lr = 0.0005
I0403 03:56:03.817986  4269 solver.cpp:228] Iteration 6405, loss = 0.00246688
I0403 03:56:03.818295  4269 solver.cpp:244]     Train net output #0: loss = 0.00246696 (* 1 = 0.00246696 loss)
I0403 03:56:04.009529  4269 sgd_solver.cpp:106] Iteration 6405, lr = 0.0005
I0403 03:56:19.145369  4269 solver.cpp:228] Iteration 6426, loss = 0.000584301
I0403 03:56:19.145488  4269 solver.cpp:244]     Train net output #0: loss = 0.00058438 (* 1 = 0.00058438 loss)
I0403 03:56:19.337601  4269 sgd_solver.cpp:106] Iteration 6426, lr = 0.0005
I0403 03:56:34.488893  4269 solver.cpp:228] Iteration 6447, loss = 0.000263387
I0403 03:56:34.489214  4269 solver.cpp:244]     Train net output #0: loss = 0.000263466 (* 1 = 0.000263466 loss)
I0403 03:56:34.677685  4269 sgd_solver.cpp:106] Iteration 6447, lr = 0.0005
I0403 03:56:50.025568  4269 solver.cpp:228] Iteration 6468, loss = 0.000271057
I0403 03:56:50.029839  4269 solver.cpp:244]     Train net output #0: loss = 0.000271136 (* 1 = 0.000271136 loss)
I0403 03:56:50.208003  4269 sgd_solver.cpp:106] Iteration 6468, lr = 0.0005
I0403 03:57:05.649111  4269 solver.cpp:228] Iteration 6489, loss = 8.26397e-05
I0403 03:57:05.649436  4269 solver.cpp:244]     Train net output #0: loss = 8.27211e-05 (* 1 = 8.27211e-05 loss)
I0403 03:57:05.843216  4269 sgd_solver.cpp:106] Iteration 6489, lr = 0.0005
I0403 03:57:20.917397  4269 solver.cpp:228] Iteration 6510, loss = 0.000707405
I0403 03:57:20.917493  4269 solver.cpp:244]     Train net output #0: loss = 0.000707486 (* 1 = 0.000707486 loss)
I0403 03:57:21.172675  4269 sgd_solver.cpp:106] Iteration 6510, lr = 0.0005
I0403 03:57:31.269479  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_6525.caffemodel
I0403 03:57:34.052391  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_6525.solverstate
I0403 03:57:35.971818  4269 solver.cpp:337] Iteration 6525, Testing net (#0)
I0403 03:58:00.028596  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988131
I0403 03:58:00.028692  4269 solver.cpp:404]     Test net output #1: loss = 0.0459302 (* 1 = 0.0459302 loss)
I0403 03:58:04.915137  4269 solver.cpp:228] Iteration 6531, loss = 0.000465742
I0403 03:58:04.915236  4269 solver.cpp:244]     Train net output #0: loss = 0.000465823 (* 1 = 0.000465823 loss)
I0403 03:58:05.129230  4269 sgd_solver.cpp:106] Iteration 6531, lr = 0.0005
I0403 03:58:20.299527  4269 solver.cpp:228] Iteration 6552, loss = 0.000256582
I0403 03:58:20.299849  4269 solver.cpp:244]     Train net output #0: loss = 0.000256664 (* 1 = 0.000256664 loss)
I0403 03:58:20.489142  4269 sgd_solver.cpp:106] Iteration 6552, lr = 0.0005
I0403 03:58:35.480700  4269 solver.cpp:228] Iteration 6573, loss = 0.000692744
I0403 03:58:35.480787  4269 solver.cpp:244]     Train net output #0: loss = 0.000692825 (* 1 = 0.000692825 loss)
I0403 03:58:35.652204  4269 sgd_solver.cpp:106] Iteration 6573, lr = 0.0005
I0403 03:58:50.853942  4269 solver.cpp:228] Iteration 6594, loss = 0.000755275
I0403 03:58:50.854243  4269 solver.cpp:244]     Train net output #0: loss = 0.000755356 (* 1 = 0.000755356 loss)
I0403 03:58:51.036164  4269 sgd_solver.cpp:106] Iteration 6594, lr = 0.0005
I0403 03:59:06.230872  4269 solver.cpp:228] Iteration 6615, loss = 0.0016648
I0403 03:59:06.230973  4269 solver.cpp:244]     Train net output #0: loss = 0.00166488 (* 1 = 0.00166488 loss)
I0403 03:59:06.415860  4269 sgd_solver.cpp:106] Iteration 6615, lr = 0.0005
I0403 03:59:21.646570  4269 solver.cpp:228] Iteration 6636, loss = 0.000223026
I0403 03:59:21.646896  4269 solver.cpp:244]     Train net output #0: loss = 0.000223106 (* 1 = 0.000223106 loss)
I0403 03:59:21.859411  4269 sgd_solver.cpp:106] Iteration 6636, lr = 0.0005
I0403 03:59:37.066673  4269 solver.cpp:228] Iteration 6657, loss = 0.000873474
I0403 03:59:37.066771  4269 solver.cpp:244]     Train net output #0: loss = 0.000873554 (* 1 = 0.000873554 loss)
I0403 03:59:37.264747  4269 sgd_solver.cpp:106] Iteration 6657, lr = 0.0005
I0403 03:59:52.482202  4269 solver.cpp:228] Iteration 6678, loss = 0.00011885
I0403 03:59:52.482514  4269 solver.cpp:244]     Train net output #0: loss = 0.000118931 (* 1 = 0.000118931 loss)
I0403 03:59:52.663491  4269 sgd_solver.cpp:106] Iteration 6678, lr = 0.0005
I0403 04:00:07.945634  4269 solver.cpp:228] Iteration 6699, loss = 0.00178625
I0403 04:00:07.945734  4269 solver.cpp:244]     Train net output #0: loss = 0.00178633 (* 1 = 0.00178633 loss)
I0403 04:00:08.148582  4269 sgd_solver.cpp:106] Iteration 6699, lr = 0.0005
I0403 04:00:23.207023  4269 solver.cpp:228] Iteration 6720, loss = 0.00144655
I0403 04:00:23.207321  4269 solver.cpp:244]     Train net output #0: loss = 0.00144663 (* 1 = 0.00144663 loss)
I0403 04:00:23.405226  4269 sgd_solver.cpp:106] Iteration 6720, lr = 0.0005
I0403 04:00:38.677922  4269 solver.cpp:228] Iteration 6741, loss = 0.00493524
I0403 04:00:38.678028  4269 solver.cpp:244]     Train net output #0: loss = 0.00493531 (* 1 = 0.00493531 loss)
I0403 04:00:38.867223  4269 sgd_solver.cpp:106] Iteration 6741, lr = 0.0005
I0403 04:00:54.000408  4269 solver.cpp:228] Iteration 6762, loss = 0.034333
I0403 04:00:54.000650  4269 solver.cpp:244]     Train net output #0: loss = 0.034333 (* 1 = 0.034333 loss)
I0403 04:00:54.131466  4269 sgd_solver.cpp:106] Iteration 6762, lr = 0.0005
I0403 04:01:09.458343  4269 solver.cpp:228] Iteration 6783, loss = 0.00137898
I0403 04:01:09.458442  4269 solver.cpp:244]     Train net output #0: loss = 0.00137905 (* 1 = 0.00137905 loss)
I0403 04:01:09.666555  4269 sgd_solver.cpp:106] Iteration 6783, lr = 0.0005
I0403 04:01:24.945264  4269 solver.cpp:228] Iteration 6804, loss = 0.0134939
I0403 04:01:24.946441  4269 solver.cpp:244]     Train net output #0: loss = 0.013494 (* 1 = 0.013494 loss)
I0403 04:01:25.129688  4269 sgd_solver.cpp:106] Iteration 6804, lr = 0.0005
I0403 04:01:40.215390  4269 solver.cpp:228] Iteration 6825, loss = 0.000583754
I0403 04:01:40.215479  4269 solver.cpp:244]     Train net output #0: loss = 0.000583828 (* 1 = 0.000583828 loss)
I0403 04:01:40.396188  4269 sgd_solver.cpp:106] Iteration 6825, lr = 0.0005
I0403 04:01:55.466904  4269 solver.cpp:228] Iteration 6846, loss = 3.77748e-05
I0403 04:01:55.467238  4269 solver.cpp:244]     Train net output #0: loss = 3.78484e-05 (* 1 = 3.78484e-05 loss)
I0403 04:01:55.669556  4269 sgd_solver.cpp:106] Iteration 6846, lr = 0.0005
I0403 04:02:10.854097  4269 solver.cpp:228] Iteration 6867, loss = 0.0016585
I0403 04:02:10.854190  4269 solver.cpp:244]     Train net output #0: loss = 0.00165857 (* 1 = 0.00165857 loss)
I0403 04:02:11.025763  4269 sgd_solver.cpp:106] Iteration 6867, lr = 0.0005
I0403 04:02:26.115417  4269 solver.cpp:228] Iteration 6888, loss = 0.00115657
I0403 04:02:26.115732  4269 solver.cpp:244]     Train net output #0: loss = 0.00115664 (* 1 = 0.00115664 loss)
I0403 04:02:26.281087  4269 sgd_solver.cpp:106] Iteration 6888, lr = 0.0005
I0403 04:02:41.374418  4269 solver.cpp:228] Iteration 6909, loss = 0.00969229
I0403 04:02:41.374516  4269 solver.cpp:244]     Train net output #0: loss = 0.00969237 (* 1 = 0.00969237 loss)
I0403 04:02:41.588994  4269 sgd_solver.cpp:106] Iteration 6909, lr = 0.0005
I0403 04:02:56.765626  4269 solver.cpp:228] Iteration 6930, loss = 0.00312955
I0403 04:02:56.765945  4269 solver.cpp:244]     Train net output #0: loss = 0.00312963 (* 1 = 0.00312963 loss)
I0403 04:02:56.957283  4269 sgd_solver.cpp:106] Iteration 6930, lr = 0.0005
I0403 04:03:12.166411  4269 solver.cpp:228] Iteration 6951, loss = 0.00474882
I0403 04:03:12.166510  4269 solver.cpp:244]     Train net output #0: loss = 0.0047489 (* 1 = 0.0047489 loss)
I0403 04:03:12.356575  4269 sgd_solver.cpp:106] Iteration 6951, lr = 0.0005
I0403 04:03:18.253525  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_6960.caffemodel
I0403 04:03:21.027251  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_6960.solverstate
I0403 04:03:22.924343  4269 solver.cpp:337] Iteration 6960, Testing net (#0)
I0403 04:03:46.981613  4269 solver.cpp:404]     Test net output #0: accuracy = 0.987664
I0403 04:03:46.984261  4269 solver.cpp:404]     Test net output #1: loss = 0.0469588 (* 1 = 0.0469588 loss)
I0403 04:03:56.273612  4269 solver.cpp:228] Iteration 6972, loss = 0.000720159
I0403 04:03:56.273711  4269 solver.cpp:244]     Train net output #0: loss = 0.000720234 (* 1 = 0.000720234 loss)
I0403 04:03:56.482354  4269 sgd_solver.cpp:106] Iteration 6972, lr = 0.0005
I0403 04:04:11.870041  4269 solver.cpp:228] Iteration 6993, loss = 0.00188017
I0403 04:04:11.870126  4269 solver.cpp:244]     Train net output #0: loss = 0.00188024 (* 1 = 0.00188024 loss)
I0403 04:04:12.035563  4269 sgd_solver.cpp:106] Iteration 6993, lr = 0.0005
I0403 04:04:27.376256  4269 solver.cpp:228] Iteration 7014, loss = 0.00182174
I0403 04:04:27.376560  4269 solver.cpp:244]     Train net output #0: loss = 0.00182181 (* 1 = 0.00182181 loss)
I0403 04:04:27.554767  4269 sgd_solver.cpp:106] Iteration 7014, lr = 0.0005
I0403 04:04:42.843798  4269 solver.cpp:228] Iteration 7035, loss = 0.000213493
I0403 04:04:42.843899  4269 solver.cpp:244]     Train net output #0: loss = 0.000213567 (* 1 = 0.000213567 loss)
I0403 04:04:43.025892  4269 sgd_solver.cpp:106] Iteration 7035, lr = 0.0005
I0403 04:04:58.055541  4269 solver.cpp:228] Iteration 7056, loss = 0.000234386
I0403 04:04:58.055845  4269 solver.cpp:244]     Train net output #0: loss = 0.00023446 (* 1 = 0.00023446 loss)
I0403 04:04:58.238785  4269 sgd_solver.cpp:106] Iteration 7056, lr = 0.0005
I0403 04:05:13.497817  4269 solver.cpp:228] Iteration 7077, loss = 0.000744082
I0403 04:05:13.497905  4269 solver.cpp:244]     Train net output #0: loss = 0.000744156 (* 1 = 0.000744156 loss)
I0403 04:05:13.675767  4269 sgd_solver.cpp:106] Iteration 7077, lr = 0.0005
I0403 04:05:28.818002  4269 solver.cpp:228] Iteration 7098, loss = 0.000511526
I0403 04:05:28.819864  4269 solver.cpp:244]     Train net output #0: loss = 0.0005116 (* 1 = 0.0005116 loss)
I0403 04:05:29.042162  4269 sgd_solver.cpp:106] Iteration 7098, lr = 0.0005
I0403 04:05:44.312562  4269 solver.cpp:228] Iteration 7119, loss = 0.00119394
I0403 04:05:44.312660  4269 solver.cpp:244]     Train net output #0: loss = 0.00119402 (* 1 = 0.00119402 loss)
I0403 04:05:44.532932  4269 sgd_solver.cpp:106] Iteration 7119, lr = 0.0005
I0403 04:05:59.541035  4269 solver.cpp:228] Iteration 7140, loss = 8.80178e-05
I0403 04:05:59.541355  4269 solver.cpp:244]     Train net output #0: loss = 8.809e-05 (* 1 = 8.809e-05 loss)
I0403 04:05:59.746858  4269 sgd_solver.cpp:106] Iteration 7140, lr = 0.0005
I0403 04:06:14.785991  4269 solver.cpp:228] Iteration 7161, loss = 0.00113583
I0403 04:06:14.786090  4269 solver.cpp:244]     Train net output #0: loss = 0.00113591 (* 1 = 0.00113591 loss)
I0403 04:06:14.992667  4269 sgd_solver.cpp:106] Iteration 7161, lr = 0.0005
I0403 04:06:30.309310  4269 solver.cpp:228] Iteration 7182, loss = 0.00012176
I0403 04:06:30.309614  4269 solver.cpp:244]     Train net output #0: loss = 0.000121833 (* 1 = 0.000121833 loss)
I0403 04:06:30.493026  4269 sgd_solver.cpp:106] Iteration 7182, lr = 0.0005
I0403 04:06:45.827839  4269 solver.cpp:228] Iteration 7203, loss = 0.000968013
I0403 04:06:45.827929  4269 solver.cpp:244]     Train net output #0: loss = 0.000968085 (* 1 = 0.000968085 loss)
I0403 04:06:45.958385  4269 sgd_solver.cpp:106] Iteration 7203, lr = 0.0005
I0403 04:07:01.118399  4269 solver.cpp:228] Iteration 7224, loss = 0.0042355
I0403 04:07:01.118719  4269 solver.cpp:244]     Train net output #0: loss = 0.00423557 (* 1 = 0.00423557 loss)
I0403 04:07:01.325379  4269 sgd_solver.cpp:106] Iteration 7224, lr = 0.0005
I0403 04:07:16.464402  4269 solver.cpp:228] Iteration 7245, loss = 0.000237863
I0403 04:07:16.464503  4269 solver.cpp:244]     Train net output #0: loss = 0.000237935 (* 1 = 0.000237935 loss)
I0403 04:07:16.681315  4269 sgd_solver.cpp:106] Iteration 7245, lr = 0.0005
I0403 04:07:31.865236  4269 solver.cpp:228] Iteration 7266, loss = 0.00113504
I0403 04:07:31.865492  4269 solver.cpp:244]     Train net output #0: loss = 0.00113511 (* 1 = 0.00113511 loss)
I0403 04:07:32.082180  4269 sgd_solver.cpp:106] Iteration 7266, lr = 0.0005
I0403 04:07:47.204659  4269 solver.cpp:228] Iteration 7287, loss = 0.000225228
I0403 04:07:47.204756  4269 solver.cpp:244]     Train net output #0: loss = 0.0002253 (* 1 = 0.0002253 loss)
I0403 04:07:47.412508  4269 sgd_solver.cpp:106] Iteration 7287, lr = 0.0005
I0403 04:08:02.618873  4269 solver.cpp:228] Iteration 7308, loss = 0.000463216
I0403 04:08:02.619195  4269 solver.cpp:244]     Train net output #0: loss = 0.000463288 (* 1 = 0.000463288 loss)
I0403 04:08:02.803477  4269 sgd_solver.cpp:106] Iteration 7308, lr = 0.0005
I0403 04:08:18.002441  4269 solver.cpp:228] Iteration 7329, loss = 0.000403925
I0403 04:08:18.002531  4269 solver.cpp:244]     Train net output #0: loss = 0.000403997 (* 1 = 0.000403997 loss)
I0403 04:08:18.195364  4269 sgd_solver.cpp:106] Iteration 7329, lr = 0.0005
I0403 04:08:33.430809  4269 solver.cpp:228] Iteration 7350, loss = 0.000500183
I0403 04:08:33.431109  4269 solver.cpp:244]     Train net output #0: loss = 0.000500255 (* 1 = 0.000500255 loss)
I0403 04:08:33.605418  4269 sgd_solver.cpp:106] Iteration 7350, lr = 0.0005
I0403 04:08:48.716714  4269 solver.cpp:228] Iteration 7371, loss = 2.9995e-05
I0403 04:08:48.716822  4269 solver.cpp:244]     Train net output #0: loss = 3.00665e-05 (* 1 = 3.00665e-05 loss)
I0403 04:08:48.961710  4269 sgd_solver.cpp:106] Iteration 7371, lr = 0.0005
I0403 04:09:04.126385  4269 solver.cpp:228] Iteration 7392, loss = 0.000102168
I0403 04:09:04.126734  4269 solver.cpp:244]     Train net output #0: loss = 0.00010224 (* 1 = 0.00010224 loss)
I0403 04:09:04.325350  4269 sgd_solver.cpp:106] Iteration 7392, lr = 0.0005
I0403 04:09:05.785558  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_7395.caffemodel
I0403 04:09:08.488997  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_7395.solverstate
I0403 04:09:10.256695  4269 solver.cpp:337] Iteration 7395, Testing net (#0)
I0403 04:09:34.308266  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988037
I0403 04:09:34.308584  4269 solver.cpp:404]     Test net output #1: loss = 0.0473418 (* 1 = 0.0473418 loss)
I0403 04:09:48.088568  4269 solver.cpp:228] Iteration 7413, loss = 0.0136378
I0403 04:09:48.088666  4269 solver.cpp:244]     Train net output #0: loss = 0.0136378 (* 1 = 0.0136378 loss)
I0403 04:09:48.283567  4269 sgd_solver.cpp:106] Iteration 7413, lr = 0.0005
I0403 04:10:03.350805  4269 solver.cpp:228] Iteration 7434, loss = 0.000432597
I0403 04:10:03.350898  4269 solver.cpp:244]     Train net output #0: loss = 0.000432669 (* 1 = 0.000432669 loss)
I0403 04:10:03.545620  4269 sgd_solver.cpp:106] Iteration 7434, lr = 0.0005
I0403 04:10:18.624824  4269 solver.cpp:228] Iteration 7455, loss = 6.9489e-05
I0403 04:10:18.625128  4269 solver.cpp:244]     Train net output #0: loss = 6.95603e-05 (* 1 = 6.95603e-05 loss)
I0403 04:10:18.815201  4269 sgd_solver.cpp:106] Iteration 7455, lr = 0.0005
I0403 04:10:34.062990  4269 solver.cpp:228] Iteration 7476, loss = 0.000250761
I0403 04:10:34.063079  4269 solver.cpp:244]     Train net output #0: loss = 0.000250834 (* 1 = 0.000250834 loss)
I0403 04:10:34.231910  4269 sgd_solver.cpp:106] Iteration 7476, lr = 0.0005
I0403 04:10:49.782454  4269 solver.cpp:228] Iteration 7497, loss = 0.000308274
I0403 04:10:49.782774  4269 solver.cpp:244]     Train net output #0: loss = 0.000308346 (* 1 = 0.000308346 loss)
I0403 04:10:49.974874  4269 sgd_solver.cpp:106] Iteration 7497, lr = 0.0005
I0403 04:11:05.194149  4269 solver.cpp:228] Iteration 7518, loss = 0.0003931
I0403 04:11:05.194262  4269 solver.cpp:244]     Train net output #0: loss = 0.000393172 (* 1 = 0.000393172 loss)
I0403 04:11:05.440243  4269 sgd_solver.cpp:106] Iteration 7518, lr = 0.0005
I0403 04:11:20.952546  4269 solver.cpp:228] Iteration 7539, loss = 0.000302256
I0403 04:11:20.952859  4269 solver.cpp:244]     Train net output #0: loss = 0.00030233 (* 1 = 0.00030233 loss)
I0403 04:11:21.135164  4269 sgd_solver.cpp:106] Iteration 7539, lr = 0.0005
I0403 04:11:36.346323  4269 solver.cpp:228] Iteration 7560, loss = 9.49463e-05
I0403 04:11:36.346422  4269 solver.cpp:244]     Train net output #0: loss = 9.50199e-05 (* 1 = 9.50199e-05 loss)
I0403 04:11:36.539868  4269 sgd_solver.cpp:106] Iteration 7560, lr = 0.0005
I0403 04:11:51.804019  4269 solver.cpp:228] Iteration 7581, loss = 3.2127e-05
I0403 04:11:51.804335  4269 solver.cpp:244]     Train net output #0: loss = 3.22001e-05 (* 1 = 3.22001e-05 loss)
I0403 04:11:51.988987  4269 sgd_solver.cpp:106] Iteration 7581, lr = 0.0005
I0403 04:12:07.467473  4269 solver.cpp:228] Iteration 7602, loss = 0.0141387
I0403 04:12:07.467572  4269 solver.cpp:244]     Train net output #0: loss = 0.0141388 (* 1 = 0.0141388 loss)
I0403 04:12:07.672358  4269 sgd_solver.cpp:106] Iteration 7602, lr = 0.0005
I0403 04:12:22.957767  4269 solver.cpp:228] Iteration 7623, loss = 4.60191e-05
I0403 04:12:22.958082  4269 solver.cpp:244]     Train net output #0: loss = 4.60919e-05 (* 1 = 4.60919e-05 loss)
I0403 04:12:23.163868  4269 sgd_solver.cpp:106] Iteration 7623, lr = 0.0005
I0403 04:12:38.555557  4269 solver.cpp:228] Iteration 7644, loss = 0.0374173
I0403 04:12:38.555658  4269 solver.cpp:244]     Train net output #0: loss = 0.0374173 (* 1 = 0.0374173 loss)
I0403 04:12:38.742482  4269 sgd_solver.cpp:106] Iteration 7644, lr = 0.0005
I0403 04:12:53.884680  4269 solver.cpp:228] Iteration 7665, loss = 0.00195079
I0403 04:12:53.885833  4269 solver.cpp:244]     Train net output #0: loss = 0.00195086 (* 1 = 0.00195086 loss)
I0403 04:12:54.089262  4269 sgd_solver.cpp:106] Iteration 7665, lr = 0.0005
I0403 04:13:09.185812  4269 solver.cpp:228] Iteration 7686, loss = 0.000320998
I0403 04:13:09.185914  4269 solver.cpp:244]     Train net output #0: loss = 0.00032107 (* 1 = 0.00032107 loss)
I0403 04:13:09.402600  4269 sgd_solver.cpp:106] Iteration 7686, lr = 0.0005
I0403 04:13:24.606920  4269 solver.cpp:228] Iteration 7707, loss = 0.000219839
I0403 04:13:24.607244  4269 solver.cpp:244]     Train net output #0: loss = 0.000219912 (* 1 = 0.000219912 loss)
I0403 04:13:24.805908  4269 sgd_solver.cpp:106] Iteration 7707, lr = 0.0005
I0403 04:13:40.173514  4269 solver.cpp:228] Iteration 7728, loss = 0.00018435
I0403 04:13:40.173611  4269 solver.cpp:244]     Train net output #0: loss = 0.000184419 (* 1 = 0.000184419 loss)
I0403 04:13:40.393620  4269 sgd_solver.cpp:106] Iteration 7728, lr = 0.0005
I0403 04:13:55.834693  4269 solver.cpp:228] Iteration 7749, loss = 0.00130316
I0403 04:13:55.835006  4269 solver.cpp:244]     Train net output #0: loss = 0.00130323 (* 1 = 0.00130323 loss)
I0403 04:13:56.009769  4269 sgd_solver.cpp:106] Iteration 7749, lr = 0.0005
I0403 04:14:11.470468  4269 solver.cpp:228] Iteration 7770, loss = 0.00475931
I0403 04:14:11.470568  4269 solver.cpp:244]     Train net output #0: loss = 0.00475938 (* 1 = 0.00475938 loss)
I0403 04:14:11.666827  4269 sgd_solver.cpp:106] Iteration 7770, lr = 0.0005
I0403 04:14:26.817181  4269 solver.cpp:228] Iteration 7791, loss = 0.000493839
I0403 04:14:26.817490  4269 solver.cpp:244]     Train net output #0: loss = 0.000493906 (* 1 = 0.000493906 loss)
I0403 04:14:27.043169  4269 sgd_solver.cpp:106] Iteration 7791, lr = 0.0005
I0403 04:14:42.315547  4269 solver.cpp:228] Iteration 7812, loss = 0.00122781
I0403 04:14:42.315636  4269 solver.cpp:244]     Train net output #0: loss = 0.00122788 (* 1 = 0.00122788 loss)
I0403 04:14:42.486451  4269 sgd_solver.cpp:106] Iteration 7812, lr = 0.0005
I0403 04:14:54.885277  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_7830.caffemodel
I0403 04:14:57.661582  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_7830.solverstate
I0403 04:15:02.363452  4269 solver.cpp:337] Iteration 7830, Testing net (#0)
I0403 04:15:26.436367  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988411
I0403 04:15:26.436460  4269 solver.cpp:404]     Test net output #1: loss = 0.0475758 (* 1 = 0.0475758 loss)
I0403 04:15:29.314674  4269 solver.cpp:228] Iteration 7833, loss = 0.00346009
I0403 04:15:29.314986  4269 solver.cpp:244]     Train net output #0: loss = 0.00346016 (* 1 = 0.00346016 loss)
I0403 04:15:29.463196  4269 sgd_solver.cpp:106] Iteration 7833, lr = 0.0005
I0403 04:15:44.585780  4269 solver.cpp:228] Iteration 7854, loss = 0.00100893
I0403 04:15:44.585878  4269 solver.cpp:244]     Train net output #0: loss = 0.001009 (* 1 = 0.001009 loss)
I0403 04:15:44.789335  4269 sgd_solver.cpp:106] Iteration 7854, lr = 0.0005
I0403 04:16:00.080286  4269 solver.cpp:228] Iteration 7875, loss = 0.00017416
I0403 04:16:00.080615  4269 solver.cpp:244]     Train net output #0: loss = 0.000174228 (* 1 = 0.000174228 loss)
I0403 04:16:00.292511  4269 sgd_solver.cpp:106] Iteration 7875, lr = 0.0005
I0403 04:16:15.615751  4269 solver.cpp:228] Iteration 7896, loss = 0.00205734
I0403 04:16:15.615847  4269 solver.cpp:244]     Train net output #0: loss = 0.00205741 (* 1 = 0.00205741 loss)
I0403 04:16:15.815603  4269 sgd_solver.cpp:106] Iteration 7896, lr = 0.0005
I0403 04:16:31.229452  4269 solver.cpp:228] Iteration 7917, loss = 0.00148367
I0403 04:16:31.229784  4269 solver.cpp:244]     Train net output #0: loss = 0.00148373 (* 1 = 0.00148373 loss)
I0403 04:16:31.442138  4269 sgd_solver.cpp:106] Iteration 7917, lr = 0.0005
I0403 04:16:46.728770  4269 solver.cpp:228] Iteration 7938, loss = 0.000903854
I0403 04:16:46.729677  4269 solver.cpp:244]     Train net output #0: loss = 0.000903921 (* 1 = 0.000903921 loss)
I0403 04:16:46.904975  4269 sgd_solver.cpp:106] Iteration 7938, lr = 0.0005
I0403 04:17:02.164784  4269 solver.cpp:228] Iteration 7959, loss = 0.000258675
I0403 04:17:02.165102  4269 solver.cpp:244]     Train net output #0: loss = 0.000258742 (* 1 = 0.000258742 loss)
I0403 04:17:02.345871  4269 sgd_solver.cpp:106] Iteration 7959, lr = 0.0005
I0403 04:17:17.425238  4269 solver.cpp:228] Iteration 7980, loss = 0.00143959
I0403 04:17:17.425328  4269 solver.cpp:244]     Train net output #0: loss = 0.00143965 (* 1 = 0.00143965 loss)
I0403 04:17:17.594566  4269 sgd_solver.cpp:106] Iteration 7980, lr = 0.0005
I0403 04:17:32.984093  4269 solver.cpp:228] Iteration 8001, loss = 0.00197408
I0403 04:17:32.984402  4269 solver.cpp:244]     Train net output #0: loss = 0.00197415 (* 1 = 0.00197415 loss)
I0403 04:17:33.139050  4269 sgd_solver.cpp:106] Iteration 8001, lr = 0.0005
I0403 04:17:48.371183  4269 solver.cpp:228] Iteration 8022, loss = 0.000157643
I0403 04:17:48.371294  4269 solver.cpp:244]     Train net output #0: loss = 0.00015771 (* 1 = 0.00015771 loss)
I0403 04:17:48.582989  4269 sgd_solver.cpp:106] Iteration 8022, lr = 0.0005
I0403 04:18:03.744057  4269 solver.cpp:228] Iteration 8043, loss = 9.32341e-06
I0403 04:18:03.744382  4269 solver.cpp:244]     Train net output #0: loss = 9.391e-06 (* 1 = 9.391e-06 loss)
I0403 04:18:03.945518  4269 sgd_solver.cpp:106] Iteration 8043, lr = 0.0005
I0403 04:18:19.324030  4269 solver.cpp:228] Iteration 8064, loss = 0.000700375
I0403 04:18:19.324123  4269 solver.cpp:244]     Train net output #0: loss = 0.000700442 (* 1 = 0.000700442 loss)
I0403 04:18:19.502002  4269 sgd_solver.cpp:106] Iteration 8064, lr = 0.0005
I0403 04:18:34.457119  4269 solver.cpp:228] Iteration 8085, loss = 8.47435e-05
I0403 04:18:34.457432  4269 solver.cpp:244]     Train net output #0: loss = 8.48093e-05 (* 1 = 8.48093e-05 loss)
I0403 04:18:34.645339  4269 sgd_solver.cpp:106] Iteration 8085, lr = 0.0005
I0403 04:18:49.568228  4269 solver.cpp:228] Iteration 8106, loss = 0.00191069
I0403 04:18:49.568330  4269 solver.cpp:244]     Train net output #0: loss = 0.00191075 (* 1 = 0.00191075 loss)
I0403 04:18:49.797235  4269 sgd_solver.cpp:106] Iteration 8106, lr = 0.0005
I0403 04:19:04.723081  4269 solver.cpp:228] Iteration 8127, loss = 0.000124848
I0403 04:19:04.723407  4269 solver.cpp:244]     Train net output #0: loss = 0.000124912 (* 1 = 0.000124912 loss)
I0403 04:19:04.911012  4269 sgd_solver.cpp:106] Iteration 8127, lr = 0.0005
I0403 04:19:19.895050  4269 solver.cpp:228] Iteration 8148, loss = 0.000637362
I0403 04:19:19.895135  4269 solver.cpp:244]     Train net output #0: loss = 0.000637428 (* 1 = 0.000637428 loss)
I0403 04:19:20.049011  4269 sgd_solver.cpp:106] Iteration 8148, lr = 0.0005
I0403 04:19:35.116036  4269 solver.cpp:228] Iteration 8169, loss = 0.0015114
I0403 04:19:35.123282  4269 solver.cpp:244]     Train net output #0: loss = 0.00151146 (* 1 = 0.00151146 loss)
I0403 04:19:35.300309  4269 sgd_solver.cpp:106] Iteration 8169, lr = 0.0005
I0403 04:19:50.244765  4269 solver.cpp:228] Iteration 8190, loss = 0.000179429
I0403 04:19:50.244864  4269 solver.cpp:244]     Train net output #0: loss = 0.000179493 (* 1 = 0.000179493 loss)
I0403 04:19:50.429360  4269 sgd_solver.cpp:106] Iteration 8190, lr = 0.0005
I0403 04:20:05.523900  4269 solver.cpp:228] Iteration 8211, loss = 0.00259552
I0403 04:20:05.524209  4269 solver.cpp:244]     Train net output #0: loss = 0.00259559 (* 1 = 0.00259559 loss)
I0403 04:20:05.696507  4269 sgd_solver.cpp:106] Iteration 8211, lr = 0.0005
I0403 04:20:21.108090  4269 solver.cpp:228] Iteration 8232, loss = 6.31773e-05
I0403 04:20:21.108180  4269 solver.cpp:244]     Train net output #0: loss = 6.32432e-05 (* 1 = 6.32432e-05 loss)
I0403 04:20:21.263366  4269 sgd_solver.cpp:106] Iteration 8232, lr = 0.0005
I0403 04:20:36.733002  4269 solver.cpp:228] Iteration 8253, loss = 3.71046e-05
I0403 04:20:36.733345  4269 solver.cpp:244]     Train net output #0: loss = 3.71705e-05 (* 1 = 3.71705e-05 loss)
I0403 04:20:36.952754  4269 sgd_solver.cpp:106] Iteration 8253, lr = 0.0005
I0403 04:20:44.888970  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_8265.caffemodel
I0403 04:20:47.523928  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_8265.solverstate
I0403 04:20:49.333385  4269 solver.cpp:337] Iteration 8265, Testing net (#0)
I0403 04:21:13.399044  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988131
I0403 04:21:13.399365  4269 solver.cpp:404]     Test net output #1: loss = 0.0466835 (* 1 = 0.0466835 loss)
I0403 04:21:20.322593  4269 solver.cpp:228] Iteration 8274, loss = 0.00299407
I0403 04:21:20.322685  4269 solver.cpp:244]     Train net output #0: loss = 0.00299414 (* 1 = 0.00299414 loss)
I0403 04:21:20.500001  4269 sgd_solver.cpp:106] Iteration 8274, lr = 0.0005
I0403 04:21:35.474586  4269 solver.cpp:228] Iteration 8295, loss = 0.000817333
I0403 04:21:35.474684  4269 solver.cpp:244]     Train net output #0: loss = 0.000817398 (* 1 = 0.000817398 loss)
I0403 04:21:35.659287  4269 sgd_solver.cpp:106] Iteration 8295, lr = 0.0005
I0403 04:21:50.600700  4269 solver.cpp:228] Iteration 8316, loss = 0.000306261
I0403 04:21:50.601028  4269 solver.cpp:244]     Train net output #0: loss = 0.000306325 (* 1 = 0.000306325 loss)
I0403 04:21:50.790395  4269 sgd_solver.cpp:106] Iteration 8316, lr = 0.0005
I0403 04:22:05.757459  4269 solver.cpp:228] Iteration 8337, loss = 0.00306519
I0403 04:22:05.757555  4269 solver.cpp:244]     Train net output #0: loss = 0.00306525 (* 1 = 0.00306525 loss)
I0403 04:22:05.939522  4269 sgd_solver.cpp:106] Iteration 8337, lr = 0.0005
I0403 04:22:21.147908  4269 solver.cpp:228] Iteration 8358, loss = 0.00134936
I0403 04:22:21.148232  4269 solver.cpp:244]     Train net output #0: loss = 0.00134943 (* 1 = 0.00134943 loss)
I0403 04:22:21.333016  4269 sgd_solver.cpp:106] Iteration 8358, lr = 0.0005
I0403 04:22:36.467717  4269 solver.cpp:228] Iteration 8379, loss = 0.000391486
I0403 04:22:36.467815  4269 solver.cpp:244]     Train net output #0: loss = 0.000391551 (* 1 = 0.000391551 loss)
I0403 04:22:36.654733  4269 sgd_solver.cpp:106] Iteration 8379, lr = 0.0005
I0403 04:22:51.912960  4269 solver.cpp:228] Iteration 8400, loss = 0.00100697
I0403 04:22:51.913267  4269 solver.cpp:244]     Train net output #0: loss = 0.00100703 (* 1 = 0.00100703 loss)
I0403 04:22:52.071447  4269 sgd_solver.cpp:106] Iteration 8400, lr = 0.0005
I0403 04:23:07.458070  4269 solver.cpp:228] Iteration 8421, loss = 6.78981e-06
I0403 04:23:07.458168  4269 solver.cpp:244]     Train net output #0: loss = 6.85479e-06 (* 1 = 6.85479e-06 loss)
I0403 04:23:07.656769  4269 sgd_solver.cpp:106] Iteration 8421, lr = 0.0005
I0403 04:23:22.705735  4269 solver.cpp:228] Iteration 8442, loss = 0.00485063
I0403 04:23:22.706049  4269 solver.cpp:244]     Train net output #0: loss = 0.0048507 (* 1 = 0.0048507 loss)
I0403 04:23:22.887370  4269 sgd_solver.cpp:106] Iteration 8442, lr = 0.0005
I0403 04:23:38.003700  4269 solver.cpp:228] Iteration 8463, loss = 0.000742946
I0403 04:23:38.003790  4269 solver.cpp:244]     Train net output #0: loss = 0.000743011 (* 1 = 0.000743011 loss)
I0403 04:23:38.143440  4269 sgd_solver.cpp:106] Iteration 8463, lr = 0.0005
I0403 04:23:53.306092  4269 solver.cpp:228] Iteration 8484, loss = 0.00393544
I0403 04:23:53.306418  4269 solver.cpp:244]     Train net output #0: loss = 0.0039355 (* 1 = 0.0039355 loss)
I0403 04:23:53.463794  4269 sgd_solver.cpp:106] Iteration 8484, lr = 0.0005
I0403 04:24:08.660382  4269 solver.cpp:228] Iteration 8505, loss = 0.00899685
I0403 04:24:08.663290  4269 solver.cpp:244]     Train net output #0: loss = 0.00899691 (* 1 = 0.00899691 loss)
I0403 04:24:08.849308  4269 sgd_solver.cpp:106] Iteration 8505, lr = 0.0005
I0403 04:24:23.885385  4269 solver.cpp:228] Iteration 8526, loss = 0.00063631
I0403 04:24:23.885718  4269 solver.cpp:244]     Train net output #0: loss = 0.000636373 (* 1 = 0.000636373 loss)
I0403 04:24:24.105201  4269 sgd_solver.cpp:106] Iteration 8526, lr = 0.0005
I0403 04:24:39.354101  4269 solver.cpp:228] Iteration 8547, loss = 9.80513e-05
I0403 04:24:39.354203  4269 solver.cpp:244]     Train net output #0: loss = 9.8112e-05 (* 1 = 9.8112e-05 loss)
I0403 04:24:39.542814  4269 sgd_solver.cpp:106] Iteration 8547, lr = 0.0005
I0403 04:24:54.707579  4269 solver.cpp:228] Iteration 8568, loss = 0.000220708
I0403 04:24:54.707909  4269 solver.cpp:244]     Train net output #0: loss = 0.000220768 (* 1 = 0.000220768 loss)
I0403 04:24:54.906057  4269 sgd_solver.cpp:106] Iteration 8568, lr = 0.0005
I0403 04:25:10.036329  4269 solver.cpp:228] Iteration 8589, loss = 0.00167182
I0403 04:25:10.036417  4269 solver.cpp:244]     Train net output #0: loss = 0.00167189 (* 1 = 0.00167189 loss)
I0403 04:25:10.217125  4269 sgd_solver.cpp:106] Iteration 8589, lr = 0.0005
I0403 04:25:25.288452  4269 solver.cpp:228] Iteration 8610, loss = 0.000159723
I0403 04:25:25.288774  4269 solver.cpp:244]     Train net output #0: loss = 0.000159783 (* 1 = 0.000159783 loss)
I0403 04:25:25.533105  4269 sgd_solver.cpp:106] Iteration 8610, lr = 0.0005
I0403 04:25:40.807116  4269 solver.cpp:228] Iteration 8631, loss = 0.000116294
I0403 04:25:40.807214  4269 solver.cpp:244]     Train net output #0: loss = 0.000116354 (* 1 = 0.000116354 loss)
I0403 04:25:41.051851  4269 sgd_solver.cpp:106] Iteration 8631, lr = 0.0005
I0403 04:25:56.225369  4269 solver.cpp:228] Iteration 8652, loss = 0.0017745
I0403 04:25:56.225669  4269 solver.cpp:244]     Train net output #0: loss = 0.00177456 (* 1 = 0.00177456 loss)
I0403 04:25:56.406811  4269 sgd_solver.cpp:106] Iteration 8652, lr = 0.0005
I0403 04:26:11.581651  4269 solver.cpp:228] Iteration 8673, loss = 0.00901407
I0403 04:26:11.581745  4269 solver.cpp:244]     Train net output #0: loss = 0.00901413 (* 1 = 0.00901413 loss)
I0403 04:26:11.822581  4269 sgd_solver.cpp:106] Iteration 8673, lr = 0.0005
I0403 04:26:27.028090  4269 solver.cpp:228] Iteration 8694, loss = 0.00157612
I0403 04:26:27.028324  4269 solver.cpp:244]     Train net output #0: loss = 0.00157618 (* 1 = 0.00157618 loss)
I0403 04:26:27.214653  4269 sgd_solver.cpp:106] Iteration 8694, lr = 0.0005
I0403 04:26:30.852499  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_8700.caffemodel
I0403 04:26:33.494278  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_8700.solverstate
I0403 04:26:35.265404  4269 solver.cpp:337] Iteration 8700, Testing net (#0)
I0403 04:26:59.318248  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988972
I0403 04:26:59.323081  4269 solver.cpp:404]     Test net output #1: loss = 0.0454264 (* 1 = 0.0454264 loss)
I0403 04:27:10.844609  4269 solver.cpp:228] Iteration 8715, loss = 0.00761697
I0403 04:27:10.844697  4269 solver.cpp:244]     Train net output #0: loss = 0.00761703 (* 1 = 0.00761703 loss)
I0403 04:27:11.025043  4269 sgd_solver.cpp:106] Iteration 8715, lr = 5e-05
I0403 04:27:26.350003  4269 solver.cpp:228] Iteration 8736, loss = 0.000956454
I0403 04:27:26.355762  4269 solver.cpp:244]     Train net output #0: loss = 0.000956513 (* 1 = 0.000956513 loss)
I0403 04:27:26.538319  4269 sgd_solver.cpp:106] Iteration 8736, lr = 5e-05
I0403 04:27:41.945886  4269 solver.cpp:228] Iteration 8757, loss = 0.000110255
I0403 04:27:41.946192  4269 solver.cpp:244]     Train net output #0: loss = 0.000110313 (* 1 = 0.000110313 loss)
I0403 04:27:42.137431  4269 sgd_solver.cpp:106] Iteration 8757, lr = 5e-05
I0403 04:27:57.200897  4269 solver.cpp:228] Iteration 8778, loss = 0.00546409
I0403 04:27:57.200992  4269 solver.cpp:244]     Train net output #0: loss = 0.00546415 (* 1 = 0.00546415 loss)
I0403 04:27:57.408975  4269 sgd_solver.cpp:106] Iteration 8778, lr = 5e-05
I0403 04:28:12.625957  4269 solver.cpp:228] Iteration 8799, loss = 0.00102101
I0403 04:28:12.627203  4269 solver.cpp:244]     Train net output #0: loss = 0.00102107 (* 1 = 0.00102107 loss)
I0403 04:28:12.782950  4269 sgd_solver.cpp:106] Iteration 8799, lr = 5e-05
I0403 04:28:28.137306  4269 solver.cpp:228] Iteration 8820, loss = 0.000101906
I0403 04:28:28.137393  4269 solver.cpp:244]     Train net output #0: loss = 0.000101965 (* 1 = 0.000101965 loss)
I0403 04:28:28.287770  4269 sgd_solver.cpp:106] Iteration 8820, lr = 5e-05
I0403 04:28:43.684242  4269 solver.cpp:228] Iteration 8841, loss = 0.000159999
I0403 04:28:43.684552  4269 solver.cpp:244]     Train net output #0: loss = 0.000160058 (* 1 = 0.000160058 loss)
I0403 04:28:43.898756  4269 sgd_solver.cpp:106] Iteration 8841, lr = 5e-05
I0403 04:28:59.054108  4269 solver.cpp:228] Iteration 8862, loss = 0.000106644
I0403 04:28:59.054211  4269 solver.cpp:244]     Train net output #0: loss = 0.000106703 (* 1 = 0.000106703 loss)
I0403 04:28:59.282455  4269 sgd_solver.cpp:106] Iteration 8862, lr = 5e-05
I0403 04:29:14.394610  4269 solver.cpp:228] Iteration 8883, loss = 7.86504e-05
I0403 04:29:14.394930  4269 solver.cpp:244]     Train net output #0: loss = 7.87103e-05 (* 1 = 7.87103e-05 loss)
I0403 04:29:14.568228  4269 sgd_solver.cpp:106] Iteration 8883, lr = 5e-05
I0403 04:29:29.708403  4269 solver.cpp:228] Iteration 8904, loss = 0.000164167
I0403 04:29:29.708492  4269 solver.cpp:244]     Train net output #0: loss = 0.000164227 (* 1 = 0.000164227 loss)
I0403 04:29:29.889680  4269 sgd_solver.cpp:106] Iteration 8904, lr = 5e-05
I0403 04:29:45.152413  4269 solver.cpp:228] Iteration 8925, loss = 0.000112605
I0403 04:29:45.152736  4269 solver.cpp:244]     Train net output #0: loss = 0.000112665 (* 1 = 0.000112665 loss)
I0403 04:29:45.351794  4269 sgd_solver.cpp:106] Iteration 8925, lr = 5e-05
I0403 04:30:00.514389  4269 solver.cpp:228] Iteration 8946, loss = 0.000826592
I0403 04:30:00.514484  4269 solver.cpp:244]     Train net output #0: loss = 0.000826652 (* 1 = 0.000826652 loss)
I0403 04:30:00.697038  4269 sgd_solver.cpp:106] Iteration 8946, lr = 5e-05
I0403 04:30:15.896608  4269 solver.cpp:228] Iteration 8967, loss = 0.000886297
I0403 04:30:15.896914  4269 solver.cpp:244]     Train net output #0: loss = 0.000886357 (* 1 = 0.000886357 loss)
I0403 04:30:16.076652  4269 sgd_solver.cpp:106] Iteration 8967, lr = 5e-05
I0403 04:30:31.364156  4269 solver.cpp:228] Iteration 8988, loss = 0.00115376
I0403 04:30:31.364258  4269 solver.cpp:244]     Train net output #0: loss = 0.00115382 (* 1 = 0.00115382 loss)
I0403 04:30:31.566644  4269 sgd_solver.cpp:106] Iteration 8988, lr = 5e-05
I0403 04:30:46.600821  4269 solver.cpp:228] Iteration 9009, loss = 0.00133326
I0403 04:30:46.601132  4269 solver.cpp:244]     Train net output #0: loss = 0.00133332 (* 1 = 0.00133332 loss)
I0403 04:30:46.755388  4269 sgd_solver.cpp:106] Iteration 9009, lr = 5e-05
I0403 04:31:02.148010  4269 solver.cpp:228] Iteration 9030, loss = 0.000812998
I0403 04:31:02.148094  4269 solver.cpp:244]     Train net output #0: loss = 0.000813058 (* 1 = 0.000813058 loss)
I0403 04:31:02.320047  4269 sgd_solver.cpp:106] Iteration 9030, lr = 5e-05
I0403 04:31:17.458521  4269 solver.cpp:228] Iteration 9051, loss = 0.000216707
I0403 04:31:17.460727  4269 solver.cpp:244]     Train net output #0: loss = 0.000216767 (* 1 = 0.000216767 loss)
I0403 04:31:17.712087  4269 sgd_solver.cpp:106] Iteration 9051, lr = 5e-05
I0403 04:31:33.010056  4269 solver.cpp:228] Iteration 9072, loss = 0.00038002
I0403 04:31:33.010148  4269 solver.cpp:244]     Train net output #0: loss = 0.00038008 (* 1 = 0.00038008 loss)
I0403 04:31:33.237768  4269 sgd_solver.cpp:106] Iteration 9072, lr = 5e-05
I0403 04:31:48.497189  4269 solver.cpp:228] Iteration 9093, loss = 0.00165555
I0403 04:31:48.497517  4269 solver.cpp:244]     Train net output #0: loss = 0.00165561 (* 1 = 0.00165561 loss)
I0403 04:31:48.723767  4269 sgd_solver.cpp:106] Iteration 9093, lr = 5e-05
I0403 04:32:03.964037  4269 solver.cpp:228] Iteration 9114, loss = 2.3386e-05
I0403 04:32:03.964133  4269 solver.cpp:244]     Train net output #0: loss = 2.34444e-05 (* 1 = 2.34444e-05 loss)
I0403 04:32:04.162366  4269 sgd_solver.cpp:106] Iteration 9114, lr = 5e-05
I0403 04:32:18.676623  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_9135.caffemodel
I0403 04:32:21.512209  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_9135.solverstate
I0403 04:32:23.432521  4269 solver.cpp:337] Iteration 9135, Testing net (#0)
I0403 04:32:47.484230  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988692
I0403 04:32:47.484321  4269 solver.cpp:404]     Test net output #1: loss = 0.0461792 (* 1 = 0.0461792 loss)
I0403 04:32:48.001850  4269 solver.cpp:228] Iteration 9135, loss = 0.000701828
I0403 04:32:48.001925  4269 solver.cpp:244]     Train net output #0: loss = 0.000701886 (* 1 = 0.000701886 loss)
I0403 04:32:48.169860  4269 sgd_solver.cpp:106] Iteration 9135, lr = 5e-05
I0403 04:33:03.757568  4269 solver.cpp:228] Iteration 9156, loss = 8.38967e-05
I0403 04:33:03.761102  4269 solver.cpp:244]     Train net output #0: loss = 8.39551e-05 (* 1 = 8.39551e-05 loss)
I0403 04:33:03.880779  4269 sgd_solver.cpp:106] Iteration 9156, lr = 5e-05
I0403 04:33:19.062456  4269 solver.cpp:228] Iteration 9177, loss = 0.000191964
I0403 04:33:19.062549  4269 solver.cpp:244]     Train net output #0: loss = 0.000192023 (* 1 = 0.000192023 loss)
I0403 04:33:19.261203  4269 sgd_solver.cpp:106] Iteration 9177, lr = 5e-05
I0403 04:33:34.604241  4269 solver.cpp:228] Iteration 9198, loss = 0.00288548
I0403 04:33:34.604532  4269 solver.cpp:244]     Train net output #0: loss = 0.00288554 (* 1 = 0.00288554 loss)
I0403 04:33:34.785768  4269 sgd_solver.cpp:106] Iteration 9198, lr = 5e-05
I0403 04:33:50.169152  4269 solver.cpp:228] Iteration 9219, loss = 0.00112546
I0403 04:33:50.169246  4269 solver.cpp:244]     Train net output #0: loss = 0.00112552 (* 1 = 0.00112552 loss)
I0403 04:33:50.350013  4269 sgd_solver.cpp:106] Iteration 9219, lr = 5e-05
I0403 04:34:05.700170  4269 solver.cpp:228] Iteration 9240, loss = 0.000255765
I0403 04:34:05.700511  4269 solver.cpp:244]     Train net output #0: loss = 0.000255825 (* 1 = 0.000255825 loss)
I0403 04:34:05.894389  4269 sgd_solver.cpp:106] Iteration 9240, lr = 5e-05
I0403 04:34:20.996167  4269 solver.cpp:228] Iteration 9261, loss = 8.36332e-05
I0403 04:34:20.996269  4269 solver.cpp:244]     Train net output #0: loss = 8.36935e-05 (* 1 = 8.36935e-05 loss)
I0403 04:34:21.202980  4269 sgd_solver.cpp:106] Iteration 9261, lr = 5e-05
I0403 04:34:36.524024  4269 solver.cpp:228] Iteration 9282, loss = 0.000339047
I0403 04:34:36.524283  4269 solver.cpp:244]     Train net output #0: loss = 0.000339108 (* 1 = 0.000339108 loss)
I0403 04:34:36.705343  4269 sgd_solver.cpp:106] Iteration 9282, lr = 5e-05
I0403 04:34:52.009169  4269 solver.cpp:228] Iteration 9303, loss = 0.00538304
I0403 04:34:52.009273  4269 solver.cpp:244]     Train net output #0: loss = 0.0053831 (* 1 = 0.0053831 loss)
I0403 04:34:52.222386  4269 sgd_solver.cpp:106] Iteration 9303, lr = 5e-05
I0403 04:35:07.325640  4269 solver.cpp:228] Iteration 9324, loss = 0.00259479
I0403 04:35:07.325966  4269 solver.cpp:244]     Train net output #0: loss = 0.00259485 (* 1 = 0.00259485 loss)
I0403 04:35:07.534576  4269 sgd_solver.cpp:106] Iteration 9324, lr = 5e-05
I0403 04:35:22.656381  4269 solver.cpp:228] Iteration 9345, loss = 4.30746e-05
I0403 04:35:22.656484  4269 solver.cpp:244]     Train net output #0: loss = 4.3136e-05 (* 1 = 4.3136e-05 loss)
I0403 04:35:22.855130  4269 sgd_solver.cpp:106] Iteration 9345, lr = 5e-05
I0403 04:35:37.979151  4269 solver.cpp:228] Iteration 9366, loss = 0.000338317
I0403 04:35:37.979471  4269 solver.cpp:244]     Train net output #0: loss = 0.000338379 (* 1 = 0.000338379 loss)
I0403 04:35:38.171231  4269 sgd_solver.cpp:106] Iteration 9366, lr = 5e-05
I0403 04:35:53.240512  4269 solver.cpp:228] Iteration 9387, loss = 0.000150497
I0403 04:35:53.240607  4269 solver.cpp:244]     Train net output #0: loss = 0.000150559 (* 1 = 0.000150559 loss)
I0403 04:35:53.441550  4269 sgd_solver.cpp:106] Iteration 9387, lr = 5e-05
I0403 04:36:08.662284  4269 solver.cpp:228] Iteration 9408, loss = 0.00138243
I0403 04:36:08.666585  4269 solver.cpp:244]     Train net output #0: loss = 0.00138249 (* 1 = 0.00138249 loss)
I0403 04:36:08.852315  4269 sgd_solver.cpp:106] Iteration 9408, lr = 5e-05
I0403 04:36:23.995443  4269 solver.cpp:228] Iteration 9429, loss = 0.00143915
I0403 04:36:23.995556  4269 solver.cpp:244]     Train net output #0: loss = 0.00143921 (* 1 = 0.00143921 loss)
I0403 04:36:24.191437  4269 sgd_solver.cpp:106] Iteration 9429, lr = 5e-05
I0403 04:36:39.450500  4269 solver.cpp:228] Iteration 9450, loss = 0.000764716
I0403 04:36:39.450825  4269 solver.cpp:244]     Train net output #0: loss = 0.000764776 (* 1 = 0.000764776 loss)
I0403 04:36:39.634878  4269 sgd_solver.cpp:106] Iteration 9450, lr = 5e-05
I0403 04:36:54.575520  4269 solver.cpp:228] Iteration 9471, loss = 0.000331616
I0403 04:36:54.575616  4269 solver.cpp:244]     Train net output #0: loss = 0.000331676 (* 1 = 0.000331676 loss)
I0403 04:36:54.793716  4269 sgd_solver.cpp:106] Iteration 9471, lr = 5e-05
I0403 04:37:10.015223  4269 solver.cpp:228] Iteration 9492, loss = 0.000389249
I0403 04:37:10.015501  4269 solver.cpp:244]     Train net output #0: loss = 0.000389309 (* 1 = 0.000389309 loss)
I0403 04:37:10.196260  4269 sgd_solver.cpp:106] Iteration 9492, lr = 5e-05
I0403 04:37:25.234179  4269 solver.cpp:228] Iteration 9513, loss = 0.00013847
I0403 04:37:25.234278  4269 solver.cpp:244]     Train net output #0: loss = 0.00013853 (* 1 = 0.00013853 loss)
I0403 04:37:25.418578  4269 sgd_solver.cpp:106] Iteration 9513, lr = 5e-05
I0403 04:37:40.651098  4269 solver.cpp:228] Iteration 9534, loss = 0.000664501
I0403 04:37:40.667882  4269 solver.cpp:244]     Train net output #0: loss = 0.000664561 (* 1 = 0.000664561 loss)
I0403 04:37:40.879842  4269 sgd_solver.cpp:106] Iteration 9534, lr = 5e-05
I0403 04:37:56.312876  4269 solver.cpp:228] Iteration 9555, loss = 0.000208581
I0403 04:37:56.312976  4269 solver.cpp:244]     Train net output #0: loss = 0.000208641 (* 1 = 0.000208641 loss)
I0403 04:37:56.512253  4269 sgd_solver.cpp:106] Iteration 9555, lr = 5e-05
I0403 04:38:06.885169  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_9570.caffemodel
I0403 04:38:09.719887  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_9570.solverstate
I0403 04:38:11.630923  4269 solver.cpp:337] Iteration 9570, Testing net (#0)
I0403 04:38:35.676158  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988972
I0403 04:38:35.676254  4269 solver.cpp:404]     Test net output #1: loss = 0.0452488 (* 1 = 0.0452488 loss)
I0403 04:38:40.575237  4269 solver.cpp:228] Iteration 9576, loss = 0.000346472
I0403 04:38:40.575325  4269 solver.cpp:244]     Train net output #0: loss = 0.000346532 (* 1 = 0.000346532 loss)
I0403 04:38:40.752430  4269 sgd_solver.cpp:106] Iteration 9576, lr = 5e-05
I0403 04:38:55.985005  4269 solver.cpp:228] Iteration 9597, loss = 0.000274664
I0403 04:38:55.985294  4269 solver.cpp:244]     Train net output #0: loss = 0.000274723 (* 1 = 0.000274723 loss)
I0403 04:38:56.144091  4269 sgd_solver.cpp:106] Iteration 9597, lr = 5e-05
I0403 04:39:11.599045  4269 solver.cpp:228] Iteration 9618, loss = 0.000109131
I0403 04:39:11.599135  4269 solver.cpp:244]     Train net output #0: loss = 0.000109191 (* 1 = 0.000109191 loss)
I0403 04:39:11.751271  4269 sgd_solver.cpp:106] Iteration 9618, lr = 5e-05
I0403 04:39:26.971186  4269 solver.cpp:228] Iteration 9639, loss = 0.00013334
I0403 04:39:26.971503  4269 solver.cpp:244]     Train net output #0: loss = 0.0001334 (* 1 = 0.0001334 loss)
I0403 04:39:27.212759  4269 sgd_solver.cpp:106] Iteration 9639, lr = 5e-05
I0403 04:39:42.355871  4269 solver.cpp:228] Iteration 9660, loss = 0.00179941
I0403 04:39:42.355970  4269 solver.cpp:244]     Train net output #0: loss = 0.00179947 (* 1 = 0.00179947 loss)
I0403 04:39:42.558596  4269 sgd_solver.cpp:106] Iteration 9660, lr = 5e-05
I0403 04:39:57.632995  4269 solver.cpp:228] Iteration 9681, loss = 0.000129057
I0403 04:39:57.633352  4269 solver.cpp:244]     Train net output #0: loss = 0.000129115 (* 1 = 0.000129115 loss)
I0403 04:39:57.852370  4269 sgd_solver.cpp:106] Iteration 9681, lr = 5e-05
I0403 04:40:12.989686  4269 solver.cpp:228] Iteration 9702, loss = 0.000225974
I0403 04:40:12.989778  4269 solver.cpp:244]     Train net output #0: loss = 0.000226032 (* 1 = 0.000226032 loss)
I0403 04:40:13.160186  4269 sgd_solver.cpp:106] Iteration 9702, lr = 5e-05
I0403 04:40:28.336474  4269 solver.cpp:228] Iteration 9723, loss = 0.000281656
I0403 04:40:28.336762  4269 solver.cpp:244]     Train net output #0: loss = 0.000281715 (* 1 = 0.000281715 loss)
I0403 04:40:28.516046  4269 sgd_solver.cpp:106] Iteration 9723, lr = 5e-05
I0403 04:40:43.611980  4269 solver.cpp:228] Iteration 9744, loss = 0.000537981
I0403 04:40:43.612087  4269 solver.cpp:244]     Train net output #0: loss = 0.000538039 (* 1 = 0.000538039 loss)
I0403 04:40:43.832846  4269 sgd_solver.cpp:106] Iteration 9744, lr = 5e-05
I0403 04:40:59.208238  4269 solver.cpp:228] Iteration 9765, loss = 0.000133348
I0403 04:40:59.208560  4269 solver.cpp:244]     Train net output #0: loss = 0.000133406 (* 1 = 0.000133406 loss)
I0403 04:40:59.395994  4269 sgd_solver.cpp:106] Iteration 9765, lr = 5e-05
I0403 04:41:14.568056  4269 solver.cpp:228] Iteration 9786, loss = 0.00978018
I0403 04:41:14.568148  4269 solver.cpp:244]     Train net output #0: loss = 0.00978024 (* 1 = 0.00978024 loss)
I0403 04:41:14.731072  4269 sgd_solver.cpp:106] Iteration 9786, lr = 5e-05
I0403 04:41:30.118679  4269 solver.cpp:228] Iteration 9807, loss = 0.00447365
I0403 04:41:30.118985  4269 solver.cpp:244]     Train net output #0: loss = 0.0044737 (* 1 = 0.0044737 loss)
I0403 04:41:30.290969  4269 sgd_solver.cpp:106] Iteration 9807, lr = 5e-05
I0403 04:41:45.578089  4269 solver.cpp:228] Iteration 9828, loss = 0.00507602
I0403 04:41:45.578193  4269 solver.cpp:244]     Train net output #0: loss = 0.00507608 (* 1 = 0.00507608 loss)
I0403 04:41:45.785154  4269 sgd_solver.cpp:106] Iteration 9828, lr = 5e-05
I0403 04:42:01.016307  4269 solver.cpp:228] Iteration 9849, loss = 0.000212757
I0403 04:42:01.016603  4269 solver.cpp:244]     Train net output #0: loss = 0.000212815 (* 1 = 0.000212815 loss)
I0403 04:42:01.200877  4269 sgd_solver.cpp:106] Iteration 9849, lr = 5e-05
I0403 04:42:16.447253  4269 solver.cpp:228] Iteration 9870, loss = 2.58579e-05
I0403 04:42:16.447355  4269 solver.cpp:244]     Train net output #0: loss = 2.59157e-05 (* 1 = 2.59157e-05 loss)
I0403 04:42:16.644933  4269 sgd_solver.cpp:106] Iteration 9870, lr = 5e-05
I0403 04:42:32.180641  4269 solver.cpp:228] Iteration 9891, loss = 0.000117605
I0403 04:42:32.180939  4269 solver.cpp:244]     Train net output #0: loss = 0.000117663 (* 1 = 0.000117663 loss)
I0403 04:42:32.382333  4269 sgd_solver.cpp:106] Iteration 9891, lr = 5e-05
I0403 04:42:47.446414  4269 solver.cpp:228] Iteration 9912, loss = 0.00032042
I0403 04:42:47.446512  4269 solver.cpp:244]     Train net output #0: loss = 0.000320478 (* 1 = 0.000320478 loss)
I0403 04:42:47.652945  4269 sgd_solver.cpp:106] Iteration 9912, lr = 5e-05
I0403 04:43:03.175392  4269 solver.cpp:228] Iteration 9933, loss = 0.000428295
I0403 04:43:03.175694  4269 solver.cpp:244]     Train net output #0: loss = 0.000428353 (* 1 = 0.000428353 loss)
I0403 04:43:03.333580  4269 sgd_solver.cpp:106] Iteration 9933, lr = 5e-05
I0403 04:43:18.551774  4269 solver.cpp:228] Iteration 9954, loss = 0.000397705
I0403 04:43:18.551869  4269 solver.cpp:244]     Train net output #0: loss = 0.000397763 (* 1 = 0.000397763 loss)
I0403 04:43:18.737339  4269 sgd_solver.cpp:106] Iteration 9954, lr = 5e-05
I0403 04:43:33.921239  4269 solver.cpp:228] Iteration 9975, loss = 0.00107411
I0403 04:43:33.923135  4269 solver.cpp:244]     Train net output #0: loss = 0.00107417 (* 1 = 0.00107417 loss)
I0403 04:43:34.044256  4269 sgd_solver.cpp:106] Iteration 9975, lr = 5e-05
I0403 04:43:49.524513  4269 solver.cpp:228] Iteration 9996, loss = 0.00199748
I0403 04:43:49.524612  4269 solver.cpp:244]     Train net output #0: loss = 0.00199754 (* 1 = 0.00199754 loss)
I0403 04:43:49.727905  4269 sgd_solver.cpp:106] Iteration 9996, lr = 5e-05
I0403 04:43:55.572295  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_10005.caffemodel
I0403 04:43:58.317288  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_10005.solverstate
I0403 04:44:00.219287  4269 solver.cpp:337] Iteration 10005, Testing net (#0)
I0403 04:44:24.285856  4269 solver.cpp:404]     Test net output #0: accuracy = 0.989066
I0403 04:44:24.286198  4269 solver.cpp:404]     Test net output #1: loss = 0.045729 (* 1 = 0.045729 loss)
I0403 04:44:33.683449  4269 solver.cpp:228] Iteration 10017, loss = 4.63843e-05
I0403 04:44:33.683547  4269 solver.cpp:244]     Train net output #0: loss = 4.6442e-05 (* 1 = 4.6442e-05 loss)
I0403 04:44:33.872344  4269 sgd_solver.cpp:106] Iteration 10017, lr = 5e-05
I0403 04:44:49.399467  4269 solver.cpp:228] Iteration 10038, loss = 0.000491149
I0403 04:44:49.399567  4269 solver.cpp:244]     Train net output #0: loss = 0.000491208 (* 1 = 0.000491208 loss)
I0403 04:44:49.585078  4269 sgd_solver.cpp:106] Iteration 10038, lr = 5e-05
I0403 04:45:04.902297  4269 solver.cpp:228] Iteration 10059, loss = 0.000101068
I0403 04:45:04.902604  4269 solver.cpp:244]     Train net output #0: loss = 0.000101125 (* 1 = 0.000101125 loss)
I0403 04:45:05.054244  4269 sgd_solver.cpp:106] Iteration 10059, lr = 5e-05
I0403 04:45:20.357810  4269 solver.cpp:228] Iteration 10080, loss = 0.00027522
I0403 04:45:20.357913  4269 solver.cpp:244]     Train net output #0: loss = 0.000275278 (* 1 = 0.000275278 loss)
I0403 04:45:20.563170  4269 sgd_solver.cpp:106] Iteration 10080, lr = 5e-05
I0403 04:45:36.083060  4269 solver.cpp:228] Iteration 10101, loss = 0.000101765
I0403 04:45:36.083326  4269 solver.cpp:244]     Train net output #0: loss = 0.000101823 (* 1 = 0.000101823 loss)
I0403 04:45:36.271839  4269 sgd_solver.cpp:106] Iteration 10101, lr = 5e-05
I0403 04:45:51.443948  4269 solver.cpp:228] Iteration 10122, loss = 9.88039e-05
I0403 04:45:51.444036  4269 solver.cpp:244]     Train net output #0: loss = 9.88608e-05 (* 1 = 9.88608e-05 loss)
I0403 04:45:51.596884  4269 sgd_solver.cpp:106] Iteration 10122, lr = 5e-05
I0403 04:46:06.925354  4269 solver.cpp:228] Iteration 10143, loss = 0.000482086
I0403 04:46:06.925637  4269 solver.cpp:244]     Train net output #0: loss = 0.000482143 (* 1 = 0.000482143 loss)
I0403 04:46:07.104666  4269 sgd_solver.cpp:106] Iteration 10143, lr = 5e-05
I0403 04:46:22.392920  4269 solver.cpp:228] Iteration 10164, loss = 0.00289752
I0403 04:46:22.393021  4269 solver.cpp:244]     Train net output #0: loss = 0.00289758 (* 1 = 0.00289758 loss)
I0403 04:46:22.575850  4269 sgd_solver.cpp:106] Iteration 10164, lr = 5e-05
I0403 04:46:37.667623  4269 solver.cpp:228] Iteration 10185, loss = 0.000137683
I0403 04:46:37.667942  4269 solver.cpp:244]     Train net output #0: loss = 0.00013774 (* 1 = 0.00013774 loss)
I0403 04:46:37.875913  4269 sgd_solver.cpp:106] Iteration 10185, lr = 5e-05
I0403 04:46:53.019969  4269 solver.cpp:228] Iteration 10206, loss = 0.0017176
I0403 04:46:53.020068  4269 solver.cpp:244]     Train net output #0: loss = 0.00171766 (* 1 = 0.00171766 loss)
I0403 04:46:53.252321  4269 sgd_solver.cpp:106] Iteration 10206, lr = 5e-05
I0403 04:47:08.336673  4269 solver.cpp:228] Iteration 10227, loss = 0.00198621
I0403 04:47:08.336967  4269 solver.cpp:244]     Train net output #0: loss = 0.00198627 (* 1 = 0.00198627 loss)
I0403 04:47:08.535485  4269 sgd_solver.cpp:106] Iteration 10227, lr = 5e-05
I0403 04:47:23.578835  4269 solver.cpp:228] Iteration 10248, loss = 8.44205e-05
I0403 04:47:23.578925  4269 solver.cpp:244]     Train net output #0: loss = 8.44773e-05 (* 1 = 8.44773e-05 loss)
I0403 04:47:23.731304  4269 sgd_solver.cpp:106] Iteration 10248, lr = 5e-05
I0403 04:47:39.170672  4269 solver.cpp:228] Iteration 10269, loss = 0.000541693
I0403 04:47:39.174969  4269 solver.cpp:244]     Train net output #0: loss = 0.00054175 (* 1 = 0.00054175 loss)
I0403 04:47:39.332994  4269 sgd_solver.cpp:106] Iteration 10269, lr = 5e-05
I0403 04:47:54.460685  4269 solver.cpp:228] Iteration 10290, loss = 0.00077575
I0403 04:47:54.460783  4269 solver.cpp:244]     Train net output #0: loss = 0.000775807 (* 1 = 0.000775807 loss)
I0403 04:47:54.677685  4269 sgd_solver.cpp:106] Iteration 10290, lr = 5e-05
I0403 04:48:09.970739  4269 solver.cpp:228] Iteration 10311, loss = 6.95904e-05
I0403 04:48:09.971048  4269 solver.cpp:244]     Train net output #0: loss = 6.96471e-05 (* 1 = 6.96471e-05 loss)
I0403 04:48:10.172724  4269 sgd_solver.cpp:106] Iteration 10311, lr = 5e-05
I0403 04:48:25.369848  4269 solver.cpp:228] Iteration 10332, loss = 0.000204497
I0403 04:48:25.369941  4269 solver.cpp:244]     Train net output #0: loss = 0.000204556 (* 1 = 0.000204556 loss)
I0403 04:48:25.557782  4269 sgd_solver.cpp:106] Iteration 10332, lr = 5e-05
I0403 04:48:41.118502  4269 solver.cpp:228] Iteration 10353, loss = 0.00055362
I0403 04:48:41.118777  4269 solver.cpp:244]     Train net output #0: loss = 0.000553678 (* 1 = 0.000553678 loss)
I0403 04:48:41.345309  4269 sgd_solver.cpp:106] Iteration 10353, lr = 5e-05
I0403 04:48:56.684172  4269 solver.cpp:228] Iteration 10374, loss = 0.00769214
I0403 04:48:56.684262  4269 solver.cpp:244]     Train net output #0: loss = 0.00769219 (* 1 = 0.00769219 loss)
I0403 04:48:56.846884  4269 sgd_solver.cpp:106] Iteration 10374, lr = 5e-05
I0403 04:49:12.076876  4269 solver.cpp:228] Iteration 10395, loss = 7.96566e-05
I0403 04:49:12.077186  4269 solver.cpp:244]     Train net output #0: loss = 7.97146e-05 (* 1 = 7.97146e-05 loss)
I0403 04:49:12.265897  4269 sgd_solver.cpp:106] Iteration 10395, lr = 5e-05
I0403 04:49:27.431095  4269 solver.cpp:228] Iteration 10416, loss = 0.000113547
I0403 04:49:27.431187  4269 solver.cpp:244]     Train net output #0: loss = 0.000113605 (* 1 = 0.000113605 loss)
I0403 04:49:27.635587  4269 sgd_solver.cpp:106] Iteration 10416, lr = 5e-05
I0403 04:49:42.904636  4269 solver.cpp:228] Iteration 10437, loss = 9.63226e-06
I0403 04:49:42.904927  4269 solver.cpp:244]     Train net output #0: loss = 9.68997e-06 (* 1 = 9.68997e-06 loss)
I0403 04:49:43.085075  4269 sgd_solver.cpp:106] Iteration 10437, lr = 5e-05
I0403 04:49:44.604107  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_10440.caffemodel
I0403 04:49:47.227982  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_10440.solverstate
I0403 04:49:49.016003  4269 solver.cpp:337] Iteration 10440, Testing net (#0)
I0403 04:50:13.071913  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988692
I0403 04:50:13.074385  4269 solver.cpp:404]     Test net output #1: loss = 0.0462361 (* 1 = 0.0462361 loss)
I0403 04:50:26.703058  4269 solver.cpp:228] Iteration 10458, loss = 0.00299144
I0403 04:50:26.703156  4269 solver.cpp:244]     Train net output #0: loss = 0.00299149 (* 1 = 0.00299149 loss)
I0403 04:50:26.888381  4269 sgd_solver.cpp:106] Iteration 10458, lr = 5e-05
I0403 04:50:42.167945  4269 solver.cpp:228] Iteration 10479, loss = 8.86915e-05
I0403 04:50:42.168061  4269 solver.cpp:244]     Train net output #0: loss = 8.87492e-05 (* 1 = 8.87492e-05 loss)
I0403 04:50:42.384060  4269 sgd_solver.cpp:106] Iteration 10479, lr = 5e-05
I0403 04:50:57.641664  4269 solver.cpp:228] Iteration 10500, loss = 0.0051365
I0403 04:50:57.641980  4269 solver.cpp:244]     Train net output #0: loss = 0.00513656 (* 1 = 0.00513656 loss)
I0403 04:50:57.822780  4269 sgd_solver.cpp:106] Iteration 10500, lr = 5e-05
I0403 04:51:13.109040  4269 solver.cpp:228] Iteration 10521, loss = 0.00029925
I0403 04:51:13.109129  4269 solver.cpp:244]     Train net output #0: loss = 0.000299308 (* 1 = 0.000299308 loss)
I0403 04:51:13.284955  4269 sgd_solver.cpp:106] Iteration 10521, lr = 5e-05
I0403 04:51:28.494258  4269 solver.cpp:228] Iteration 10542, loss = 0.00670058
I0403 04:51:28.494607  4269 solver.cpp:244]     Train net output #0: loss = 0.00670064 (* 1 = 0.00670064 loss)
I0403 04:51:28.690908  4269 sgd_solver.cpp:106] Iteration 10542, lr = 5e-05
I0403 04:51:43.873734  4269 solver.cpp:228] Iteration 10563, loss = 0.000262218
I0403 04:51:43.873821  4269 solver.cpp:244]     Train net output #0: loss = 0.000262276 (* 1 = 0.000262276 loss)
I0403 04:51:44.046607  4269 sgd_solver.cpp:106] Iteration 10563, lr = 5e-05
I0403 04:51:59.542711  4269 solver.cpp:228] Iteration 10584, loss = 0.0002134
I0403 04:51:59.543025  4269 solver.cpp:244]     Train net output #0: loss = 0.000213458 (* 1 = 0.000213458 loss)
I0403 04:51:59.723426  4269 sgd_solver.cpp:106] Iteration 10584, lr = 5e-05
I0403 04:52:14.990854  4269 solver.cpp:228] Iteration 10605, loss = 0.00559399
I0403 04:52:14.990942  4269 solver.cpp:244]     Train net output #0: loss = 0.00559405 (* 1 = 0.00559405 loss)
I0403 04:52:15.127346  4269 sgd_solver.cpp:106] Iteration 10605, lr = 5e-05
I0403 04:52:30.395967  4269 solver.cpp:228] Iteration 10626, loss = 0.000344084
I0403 04:52:30.396278  4269 solver.cpp:244]     Train net output #0: loss = 0.000344141 (* 1 = 0.000344141 loss)
I0403 04:52:30.568727  4269 sgd_solver.cpp:106] Iteration 10626, lr = 5e-05
I0403 04:52:46.053928  4269 solver.cpp:228] Iteration 10647, loss = 0.000453794
I0403 04:52:46.054018  4269 solver.cpp:244]     Train net output #0: loss = 0.000453851 (* 1 = 0.000453851 loss)
I0403 04:52:46.229884  4269 sgd_solver.cpp:106] Iteration 10647, lr = 5e-05
I0403 04:53:01.656962  4269 solver.cpp:228] Iteration 10668, loss = 0.000630858
I0403 04:53:01.657279  4269 solver.cpp:244]     Train net output #0: loss = 0.000630915 (* 1 = 0.000630915 loss)
I0403 04:53:01.824151  4269 sgd_solver.cpp:106] Iteration 10668, lr = 5e-05
I0403 04:53:17.221045  4269 solver.cpp:228] Iteration 10689, loss = 0.000195092
I0403 04:53:17.221133  4269 solver.cpp:244]     Train net output #0: loss = 0.000195148 (* 1 = 0.000195148 loss)
I0403 04:53:17.327440  4269 sgd_solver.cpp:106] Iteration 10689, lr = 5e-05
I0403 04:53:32.811017  4269 solver.cpp:228] Iteration 10710, loss = 0.000223465
I0403 04:53:32.811331  4269 solver.cpp:244]     Train net output #0: loss = 0.000223521 (* 1 = 0.000223521 loss)
I0403 04:53:32.963027  4269 sgd_solver.cpp:106] Iteration 10710, lr = 5e-05
I0403 04:53:48.489392  4269 solver.cpp:228] Iteration 10731, loss = 0.0017594
I0403 04:53:48.489485  4269 solver.cpp:244]     Train net output #0: loss = 0.00175945 (* 1 = 0.00175945 loss)
I0403 04:53:48.677847  4269 sgd_solver.cpp:106] Iteration 10731, lr = 5e-05
I0403 04:54:03.757680  4269 solver.cpp:228] Iteration 10752, loss = 0.000570702
I0403 04:54:03.758008  4269 solver.cpp:244]     Train net output #0: loss = 0.000570757 (* 1 = 0.000570757 loss)
I0403 04:54:03.959476  4269 sgd_solver.cpp:106] Iteration 10752, lr = 5e-05
I0403 04:54:19.114583  4269 solver.cpp:228] Iteration 10773, loss = 0.000736132
I0403 04:54:19.114678  4269 solver.cpp:244]     Train net output #0: loss = 0.000736186 (* 1 = 0.000736186 loss)
I0403 04:54:19.302784  4269 sgd_solver.cpp:106] Iteration 10773, lr = 5e-05
I0403 04:54:34.501338  4269 solver.cpp:228] Iteration 10794, loss = 9.53507e-05
I0403 04:54:34.501616  4269 solver.cpp:244]     Train net output #0: loss = 9.54053e-05 (* 1 = 9.54053e-05 loss)
I0403 04:54:34.712504  4269 sgd_solver.cpp:106] Iteration 10794, lr = 5e-05
I0403 04:54:49.959859  4269 solver.cpp:228] Iteration 10815, loss = 0.00253888
I0403 04:54:49.959955  4269 solver.cpp:244]     Train net output #0: loss = 0.00253894 (* 1 = 0.00253894 loss)
I0403 04:54:50.175103  4269 sgd_solver.cpp:106] Iteration 10815, lr = 5e-05
I0403 04:55:05.285507  4269 solver.cpp:228] Iteration 10836, loss = 0.000419061
I0403 04:55:05.285861  4269 solver.cpp:244]     Train net output #0: loss = 0.000419116 (* 1 = 0.000419116 loss)
I0403 04:55:05.551746  4269 sgd_solver.cpp:106] Iteration 10836, lr = 5e-05
I0403 04:55:20.674809  4269 solver.cpp:228] Iteration 10857, loss = 0.000244305
I0403 04:55:20.674904  4269 solver.cpp:244]     Train net output #0: loss = 0.00024436 (* 1 = 0.00024436 loss)
I0403 04:55:20.875463  4269 sgd_solver.cpp:106] Iteration 10857, lr = 5e-05
I0403 04:55:33.535743  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_10875.caffemodel
I0403 04:55:36.141350  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_10875.solverstate
I0403 04:55:38.548511  4269 solver.cpp:337] Iteration 10875, Testing net (#0)
I0403 04:56:02.599989  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988692
I0403 04:56:02.600086  4269 solver.cpp:404]     Test net output #1: loss = 0.0461357 (* 1 = 0.0461357 loss)
I0403 04:56:05.360868  4269 solver.cpp:228] Iteration 10878, loss = 0.000684623
I0403 04:56:05.360954  4269 solver.cpp:244]     Train net output #0: loss = 0.000684678 (* 1 = 0.000684678 loss)
I0403 04:56:05.498560  4269 sgd_solver.cpp:106] Iteration 10878, lr = 5e-05
I0403 04:56:20.889776  4269 solver.cpp:228] Iteration 10899, loss = 0.000241385
I0403 04:56:20.890069  4269 solver.cpp:244]     Train net output #0: loss = 0.00024144 (* 1 = 0.00024144 loss)
I0403 04:56:21.071310  4269 sgd_solver.cpp:106] Iteration 10899, lr = 5e-05
I0403 04:56:36.521499  4269 solver.cpp:228] Iteration 10920, loss = 6.3915e-05
I0403 04:56:36.521590  4269 solver.cpp:244]     Train net output #0: loss = 6.39696e-05 (* 1 = 6.39696e-05 loss)
I0403 04:56:36.662983  4269 sgd_solver.cpp:106] Iteration 10920, lr = 5e-05
I0403 04:56:51.895095  4269 solver.cpp:228] Iteration 10941, loss = 1.98234e-05
I0403 04:56:51.895390  4269 solver.cpp:244]     Train net output #0: loss = 1.9878e-05 (* 1 = 1.9878e-05 loss)
I0403 04:56:52.076216  4269 sgd_solver.cpp:106] Iteration 10941, lr = 5e-05
I0403 04:57:07.274224  4269 solver.cpp:228] Iteration 10962, loss = 0.000500912
I0403 04:57:07.274330  4269 solver.cpp:244]     Train net output #0: loss = 0.000500966 (* 1 = 0.000500966 loss)
I0403 04:57:07.512616  4269 sgd_solver.cpp:106] Iteration 10962, lr = 5e-05
I0403 04:57:22.822011  4269 solver.cpp:228] Iteration 10983, loss = 0.00177326
I0403 04:57:22.822335  4269 solver.cpp:244]     Train net output #0: loss = 0.00177332 (* 1 = 0.00177332 loss)
I0403 04:57:23.024653  4269 sgd_solver.cpp:106] Iteration 10983, lr = 5e-05
I0403 04:57:38.328260  4269 solver.cpp:228] Iteration 11004, loss = 0.000106552
I0403 04:57:38.328356  4269 solver.cpp:244]     Train net output #0: loss = 0.000106609 (* 1 = 0.000106609 loss)
I0403 04:57:38.511370  4269 sgd_solver.cpp:106] Iteration 11004, lr = 5e-05
I0403 04:57:53.759138  4269 solver.cpp:228] Iteration 11025, loss = 5.65688e-05
I0403 04:57:53.763305  4269 solver.cpp:244]     Train net output #0: loss = 5.66254e-05 (* 1 = 5.66254e-05 loss)
I0403 04:57:53.984300  4269 sgd_solver.cpp:106] Iteration 11025, lr = 5e-05
I0403 04:58:09.066076  4269 solver.cpp:228] Iteration 11046, loss = 0.000265886
I0403 04:58:09.066174  4269 solver.cpp:244]     Train net output #0: loss = 0.000265944 (* 1 = 0.000265944 loss)
I0403 04:58:09.249848  4269 sgd_solver.cpp:106] Iteration 11046, lr = 5e-05
I0403 04:58:24.327886  4269 solver.cpp:228] Iteration 11067, loss = 0.000232661
I0403 04:58:24.328217  4269 solver.cpp:244]     Train net output #0: loss = 0.00023272 (* 1 = 0.00023272 loss)
I0403 04:58:24.553143  4269 sgd_solver.cpp:106] Iteration 11067, lr = 5e-05
I0403 04:58:39.802181  4269 solver.cpp:228] Iteration 11088, loss = 0.000332282
I0403 04:58:39.802285  4269 solver.cpp:244]     Train net output #0: loss = 0.000332341 (* 1 = 0.000332341 loss)
I0403 04:58:40.005798  4269 sgd_solver.cpp:106] Iteration 11088, lr = 5e-05
I0403 04:58:55.287899  4269 solver.cpp:228] Iteration 11109, loss = 0.00014727
I0403 04:58:55.290319  4269 solver.cpp:244]     Train net output #0: loss = 0.000147328 (* 1 = 0.000147328 loss)
I0403 04:58:55.466471  4269 sgd_solver.cpp:106] Iteration 11109, lr = 5e-05
I0403 04:59:10.523766  4269 solver.cpp:228] Iteration 11130, loss = 0.00486097
I0403 04:59:10.523852  4269 solver.cpp:244]     Train net output #0: loss = 0.00486103 (* 1 = 0.00486103 loss)
I0403 04:59:10.696244  4269 sgd_solver.cpp:106] Iteration 11130, lr = 5e-05
I0403 04:59:25.828934  4269 solver.cpp:228] Iteration 11151, loss = 8.83499e-05
I0403 04:59:25.829229  4269 solver.cpp:244]     Train net output #0: loss = 8.8409e-05 (* 1 = 8.8409e-05 loss)
I0403 04:59:26.010568  4269 sgd_solver.cpp:106] Iteration 11151, lr = 5e-05
I0403 04:59:41.146764  4269 solver.cpp:228] Iteration 11172, loss = 0.00465081
I0403 04:59:41.146862  4269 solver.cpp:244]     Train net output #0: loss = 0.00465087 (* 1 = 0.00465087 loss)
I0403 04:59:41.382964  4269 sgd_solver.cpp:106] Iteration 11172, lr = 5e-05
I0403 04:59:56.532380  4269 solver.cpp:228] Iteration 11193, loss = 0.00119085
I0403 04:59:56.532667  4269 solver.cpp:244]     Train net output #0: loss = 0.00119091 (* 1 = 0.00119091 loss)
I0403 04:59:56.709619  4269 sgd_solver.cpp:106] Iteration 11193, lr = 5e-05
I0403 05:00:11.874474  4269 solver.cpp:228] Iteration 11214, loss = 0.000158754
I0403 05:00:11.874572  4269 solver.cpp:244]     Train net output #0: loss = 0.000158809 (* 1 = 0.000158809 loss)
I0403 05:00:12.092290  4269 sgd_solver.cpp:106] Iteration 11214, lr = 5e-05
I0403 05:00:27.361870  4269 solver.cpp:228] Iteration 11235, loss = 0.000290738
I0403 05:00:27.362190  4269 solver.cpp:244]     Train net output #0: loss = 0.000290793 (* 1 = 0.000290793 loss)
I0403 05:00:27.575062  4269 sgd_solver.cpp:106] Iteration 11235, lr = 5e-05
I0403 05:00:42.821655  4269 solver.cpp:228] Iteration 11256, loss = 1.3636e-05
I0403 05:00:42.821759  4269 solver.cpp:244]     Train net output #0: loss = 1.36896e-05 (* 1 = 1.36896e-05 loss)
I0403 05:00:43.027899  4269 sgd_solver.cpp:106] Iteration 11256, lr = 5e-05
I0403 05:00:58.258826  4269 solver.cpp:228] Iteration 11277, loss = 0.000255596
I0403 05:00:58.259148  4269 solver.cpp:244]     Train net output #0: loss = 0.000255649 (* 1 = 0.000255649 loss)
I0403 05:00:58.440791  4269 sgd_solver.cpp:106] Iteration 11277, lr = 5e-05
I0403 05:01:13.569388  4269 solver.cpp:228] Iteration 11298, loss = 0.000341948
I0403 05:01:13.569485  4269 solver.cpp:244]     Train net output #0: loss = 0.000342001 (* 1 = 0.000342001 loss)
I0403 05:01:13.757675  4269 sgd_solver.cpp:106] Iteration 11298, lr = 5e-05
I0403 05:01:21.878110  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_11310.caffemodel
I0403 05:01:24.708879  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_11310.solverstate
I0403 05:01:26.611183  4269 solver.cpp:337] Iteration 11310, Testing net (#0)
I0403 05:01:50.663305  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988879
I0403 05:01:50.663619  4269 solver.cpp:404]     Test net output #1: loss = 0.0459243 (* 1 = 0.0459243 loss)
I0403 05:01:57.762048  4269 solver.cpp:228] Iteration 11319, loss = 0.000385968
I0403 05:01:57.762145  4269 solver.cpp:244]     Train net output #0: loss = 0.00038602 (* 1 = 0.00038602 loss)
I0403 05:01:57.968598  4269 sgd_solver.cpp:106] Iteration 11319, lr = 5e-05
I0403 05:02:13.158598  4269 solver.cpp:228] Iteration 11340, loss = 0.000392973
I0403 05:02:13.158692  4269 solver.cpp:244]     Train net output #0: loss = 0.000393026 (* 1 = 0.000393026 loss)
I0403 05:02:13.337265  4269 sgd_solver.cpp:106] Iteration 11340, lr = 5e-05
I0403 05:02:28.820489  4269 solver.cpp:228] Iteration 11361, loss = 0.0024598
I0403 05:02:28.820798  4269 solver.cpp:244]     Train net output #0: loss = 0.00245985 (* 1 = 0.00245985 loss)
I0403 05:02:29.022593  4269 sgd_solver.cpp:106] Iteration 11361, lr = 5e-05
I0403 05:02:44.326815  4269 solver.cpp:228] Iteration 11382, loss = 0.00452255
I0403 05:02:44.328040  4269 solver.cpp:244]     Train net output #0: loss = 0.00452261 (* 1 = 0.00452261 loss)
I0403 05:02:44.493867  4269 sgd_solver.cpp:106] Iteration 11382, lr = 5e-05
I0403 05:02:59.752213  4269 solver.cpp:228] Iteration 11403, loss = 0.000144746
I0403 05:02:59.752575  4269 solver.cpp:244]     Train net output #0: loss = 0.000144799 (* 1 = 0.000144799 loss)
I0403 05:02:59.948067  4269 sgd_solver.cpp:106] Iteration 11403, lr = 5e-05
I0403 05:03:15.107858  4269 solver.cpp:228] Iteration 11424, loss = 0.000978443
I0403 05:03:15.107956  4269 solver.cpp:244]     Train net output #0: loss = 0.000978496 (* 1 = 0.000978496 loss)
I0403 05:03:15.296175  4269 sgd_solver.cpp:106] Iteration 11424, lr = 5e-05
I0403 05:03:30.601897  4269 solver.cpp:228] Iteration 11445, loss = 0.000557497
I0403 05:03:30.602222  4269 solver.cpp:244]     Train net output #0: loss = 0.00055755 (* 1 = 0.00055755 loss)
I0403 05:03:30.815713  4269 sgd_solver.cpp:106] Iteration 11445, lr = 5e-05
I0403 05:03:45.953430  4269 solver.cpp:228] Iteration 11466, loss = 0.000838925
I0403 05:03:45.953523  4269 solver.cpp:244]     Train net output #0: loss = 0.000838978 (* 1 = 0.000838978 loss)
I0403 05:03:46.127704  4269 sgd_solver.cpp:106] Iteration 11466, lr = 5e-05
I0403 05:04:01.255995  4269 solver.cpp:228] Iteration 11487, loss = 0.00110297
I0403 05:04:01.256320  4269 solver.cpp:244]     Train net output #0: loss = 0.00110303 (* 1 = 0.00110303 loss)
I0403 05:04:01.472750  4269 sgd_solver.cpp:106] Iteration 11487, lr = 5e-05
I0403 05:04:16.480111  4269 solver.cpp:228] Iteration 11508, loss = 3.19407e-05
I0403 05:04:16.480201  4269 solver.cpp:244]     Train net output #0: loss = 3.19947e-05 (* 1 = 3.19947e-05 loss)
I0403 05:04:16.645632  4269 sgd_solver.cpp:106] Iteration 11508, lr = 5e-05
I0403 05:04:31.825637  4269 solver.cpp:228] Iteration 11529, loss = 0.000240043
I0403 05:04:31.825917  4269 solver.cpp:244]     Train net output #0: loss = 0.000240096 (* 1 = 0.000240096 loss)
I0403 05:04:32.032680  4269 sgd_solver.cpp:106] Iteration 11529, lr = 5e-05
I0403 05:04:47.153784  4269 solver.cpp:228] Iteration 11550, loss = 0.00314821
I0403 05:04:47.153887  4269 solver.cpp:244]     Train net output #0: loss = 0.00314826 (* 1 = 0.00314826 loss)
I0403 05:04:47.392853  4269 sgd_solver.cpp:106] Iteration 11550, lr = 5e-05
I0403 05:05:02.666147  4269 solver.cpp:228] Iteration 11571, loss = 0.000625892
I0403 05:05:02.666466  4269 solver.cpp:244]     Train net output #0: loss = 0.000625946 (* 1 = 0.000625946 loss)
I0403 05:05:02.909133  4269 sgd_solver.cpp:106] Iteration 11571, lr = 5e-05
I0403 05:05:18.205873  4269 solver.cpp:228] Iteration 11592, loss = 0.0005411
I0403 05:05:18.205973  4269 solver.cpp:244]     Train net output #0: loss = 0.000541154 (* 1 = 0.000541154 loss)
I0403 05:05:18.432535  4269 sgd_solver.cpp:106] Iteration 11592, lr = 5e-05
I0403 05:05:33.475782  4269 solver.cpp:228] Iteration 11613, loss = 0.00150053
I0403 05:05:33.476104  4269 solver.cpp:244]     Train net output #0: loss = 0.00150059 (* 1 = 0.00150059 loss)
I0403 05:05:33.664569  4269 sgd_solver.cpp:106] Iteration 11613, lr = 5e-05
I0403 05:05:48.930191  4269 solver.cpp:228] Iteration 11634, loss = 1.82979e-05
I0403 05:05:48.930294  4269 solver.cpp:244]     Train net output #0: loss = 1.83526e-05 (* 1 = 1.83526e-05 loss)
I0403 05:05:49.116853  4269 sgd_solver.cpp:106] Iteration 11634, lr = 5e-05
I0403 05:06:04.467628  4269 solver.cpp:228] Iteration 11655, loss = 0.00667999
I0403 05:06:04.467949  4269 solver.cpp:244]     Train net output #0: loss = 0.00668005 (* 1 = 0.00668005 loss)
I0403 05:06:04.655200  4269 sgd_solver.cpp:106] Iteration 11655, lr = 5e-05
I0403 05:06:19.716979  4269 solver.cpp:228] Iteration 11676, loss = 0.000588385
I0403 05:06:19.717077  4269 solver.cpp:244]     Train net output #0: loss = 0.00058844 (* 1 = 0.00058844 loss)
I0403 05:06:19.911739  4269 sgd_solver.cpp:106] Iteration 11676, lr = 5e-05
I0403 05:06:34.992949  4269 solver.cpp:228] Iteration 11697, loss = 0.0039182
I0403 05:06:34.993314  4269 solver.cpp:244]     Train net output #0: loss = 0.00391825 (* 1 = 0.00391825 loss)
I0403 05:06:35.192045  4269 sgd_solver.cpp:106] Iteration 11697, lr = 5e-05
I0403 05:06:50.452647  4269 solver.cpp:228] Iteration 11718, loss = 0.000633789
I0403 05:06:50.452746  4269 solver.cpp:244]     Train net output #0: loss = 0.000633844 (* 1 = 0.000633844 loss)
I0403 05:06:50.705335  4269 sgd_solver.cpp:106] Iteration 11718, lr = 5e-05
I0403 05:07:05.725801  4269 solver.cpp:228] Iteration 11739, loss = 9.69149e-05
I0403 05:07:05.726117  4269 solver.cpp:244]     Train net output #0: loss = 9.69691e-05 (* 1 = 9.69691e-05 loss)
I0403 05:07:05.933683  4269 sgd_solver.cpp:106] Iteration 11739, lr = 5e-05
I0403 05:07:09.537608  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_11745.caffemodel
I0403 05:07:12.167641  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_11745.solverstate
I0403 05:07:13.963198  4269 solver.cpp:337] Iteration 11745, Testing net (#0)
I0403 05:07:38.020866  4269 solver.cpp:404]     Test net output #0: accuracy = 0.988972
I0403 05:07:38.021183  4269 solver.cpp:404]     Test net output #1: loss = 0.0458325 (* 1 = 0.0458325 loss)
I0403 05:07:49.541508  4269 solver.cpp:228] Iteration 11760, loss = 0.000374732
I0403 05:07:49.541607  4269 solver.cpp:244]     Train net output #0: loss = 0.000374786 (* 1 = 0.000374786 loss)
I0403 05:07:49.781457  4269 sgd_solver.cpp:106] Iteration 11760, lr = 5e-05
I0403 05:08:04.857895  4269 solver.cpp:228] Iteration 11781, loss = 0.000248636
I0403 05:08:04.857991  4269 solver.cpp:244]     Train net output #0: loss = 0.00024869 (* 1 = 0.00024869 loss)
I0403 05:08:05.078773  4269 sgd_solver.cpp:106] Iteration 11781, lr = 5e-05
I0403 05:08:20.220722  4269 solver.cpp:228] Iteration 11802, loss = 0.00195385
I0403 05:08:20.221042  4269 solver.cpp:244]     Train net output #0: loss = 0.0019539 (* 1 = 0.0019539 loss)
I0403 05:08:20.422168  4269 sgd_solver.cpp:106] Iteration 11802, lr = 5e-05
I0403 05:08:35.765044  4269 solver.cpp:228] Iteration 11823, loss = 0.00111607
I0403 05:08:35.765142  4269 solver.cpp:244]     Train net output #0: loss = 0.00111613 (* 1 = 0.00111613 loss)
I0403 05:08:35.956231  4269 sgd_solver.cpp:106] Iteration 11823, lr = 5e-05
I0403 05:08:51.292443  4269 solver.cpp:228] Iteration 11844, loss = 0.00117754
I0403 05:08:51.292762  4269 solver.cpp:244]     Train net output #0: loss = 0.00117759 (* 1 = 0.00117759 loss)
I0403 05:08:51.445389  4269 sgd_solver.cpp:106] Iteration 11844, lr = 5e-05
I0403 05:09:06.957078  4269 solver.cpp:228] Iteration 11865, loss = 4.61635e-05
I0403 05:09:06.957167  4269 solver.cpp:244]     Train net output #0: loss = 4.62171e-05 (* 1 = 4.62171e-05 loss)
I0403 05:09:07.124493  4269 sgd_solver.cpp:106] Iteration 11865, lr = 5e-05
I0403 05:09:22.370388  4269 solver.cpp:228] Iteration 11886, loss = 0.000298975
I0403 05:09:22.370677  4269 solver.cpp:244]     Train net output #0: loss = 0.000299028 (* 1 = 0.000299028 loss)
I0403 05:09:22.497654  4269 sgd_solver.cpp:106] Iteration 11886, lr = 5e-05
I0403 05:09:37.919620  4269 solver.cpp:228] Iteration 11907, loss = 0.00121127
I0403 05:09:37.919719  4269 solver.cpp:244]     Train net output #0: loss = 0.00121132 (* 1 = 0.00121132 loss)
I0403 05:09:38.108423  4269 sgd_solver.cpp:106] Iteration 11907, lr = 5e-05
I0403 05:09:53.244058  4269 solver.cpp:228] Iteration 11928, loss = 0.000101763
I0403 05:09:53.244376  4269 solver.cpp:244]     Train net output #0: loss = 0.000101817 (* 1 = 0.000101817 loss)
I0403 05:09:53.472180  4269 sgd_solver.cpp:106] Iteration 11928, lr = 5e-05
I0403 05:10:08.774850  4269 solver.cpp:228] Iteration 11949, loss = 8.73018e-05
I0403 05:10:08.774950  4269 solver.cpp:244]     Train net output #0: loss = 8.73554e-05 (* 1 = 8.73554e-05 loss)
I0403 05:10:08.960783  4269 sgd_solver.cpp:106] Iteration 11949, lr = 5e-05
I0403 05:10:24.198146  4269 solver.cpp:228] Iteration 11970, loss = 0.000856484
I0403 05:10:24.198662  4269 solver.cpp:244]     Train net output #0: loss = 0.000856538 (* 1 = 0.000856538 loss)
I0403 05:10:24.413558  4269 sgd_solver.cpp:106] Iteration 11970, lr = 5e-05
I0403 05:10:39.599051  4269 solver.cpp:228] Iteration 11991, loss = 0.000576582
I0403 05:10:39.599148  4269 solver.cpp:244]     Train net output #0: loss = 0.000576635 (* 1 = 0.000576635 loss)
I0403 05:10:39.785807  4269 sgd_solver.cpp:106] Iteration 11991, lr = 5e-05
I0403 05:10:55.095991  4269 solver.cpp:228] Iteration 12012, loss = 0.000178493
I0403 05:10:55.096319  4269 solver.cpp:244]     Train net output #0: loss = 0.000178545 (* 1 = 0.000178545 loss)
I0403 05:10:55.353312  4269 sgd_solver.cpp:106] Iteration 12012, lr = 5e-05
I0403 05:11:10.603844  4269 solver.cpp:228] Iteration 12033, loss = 0.000547031
I0403 05:11:10.603941  4269 solver.cpp:244]     Train net output #0: loss = 0.000547083 (* 1 = 0.000547083 loss)
I0403 05:11:10.797060  4269 sgd_solver.cpp:106] Iteration 12033, lr = 5e-05
I0403 05:11:25.943915  4269 solver.cpp:228] Iteration 12054, loss = 0.000605946
I0403 05:11:25.944242  4269 solver.cpp:244]     Train net output #0: loss = 0.000605999 (* 1 = 0.000605999 loss)
I0403 05:11:26.193070  4269 sgd_solver.cpp:106] Iteration 12054, lr = 5e-05
I0403 05:11:41.401463  4269 solver.cpp:228] Iteration 12075, loss = 0.000384175
I0403 05:11:41.401562  4269 solver.cpp:244]     Train net output #0: loss = 0.000384227 (* 1 = 0.000384227 loss)
I0403 05:11:41.641607  4269 sgd_solver.cpp:106] Iteration 12075, lr = 5e-05
I0403 05:11:56.853585  4269 solver.cpp:228] Iteration 12096, loss = 7.83942e-05
I0403 05:11:56.853898  4269 solver.cpp:244]     Train net output #0: loss = 7.84468e-05 (* 1 = 7.84468e-05 loss)
I0403 05:11:57.024612  4269 sgd_solver.cpp:106] Iteration 12096, lr = 5e-05
I0403 05:12:12.393812  4269 solver.cpp:228] Iteration 12117, loss = 0.000157595
I0403 05:12:12.393913  4269 solver.cpp:244]     Train net output #0: loss = 0.000157649 (* 1 = 0.000157649 loss)
I0403 05:12:12.606770  4269 sgd_solver.cpp:106] Iteration 12117, lr = 5e-05
I0403 05:12:27.976359  4269 solver.cpp:228] Iteration 12138, loss = 0.00105624
I0403 05:12:27.976665  4269 solver.cpp:244]     Train net output #0: loss = 0.00105629 (* 1 = 0.00105629 loss)
I0403 05:12:28.185793  4269 sgd_solver.cpp:106] Iteration 12138, lr = 5e-05
I0403 05:12:43.259758  4269 solver.cpp:228] Iteration 12159, loss = 1.5066e-05
I0403 05:12:43.259858  4269 solver.cpp:244]     Train net output #0: loss = 1.51206e-05 (* 1 = 1.51206e-05 loss)
I0403 05:12:43.475970  4269 sgd_solver.cpp:106] Iteration 12159, lr = 5e-05
I0403 05:12:58.248427  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_12180.caffemodel
I0403 05:13:01.024767  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_12180.solverstate
I0403 05:13:02.943145  4269 solver.cpp:337] Iteration 12180, Testing net (#0)
I0403 05:13:26.998308  4269 solver.cpp:404]     Test net output #0: accuracy = 0.989066
I0403 05:13:26.998406  4269 solver.cpp:404]     Test net output #1: loss = 0.0454946 (* 1 = 0.0454946 loss)
I0403 05:13:27.530534  4269 solver.cpp:228] Iteration 12180, loss = 0.000107011
I0403 05:13:27.530617  4269 solver.cpp:244]     Train net output #0: loss = 0.000107066 (* 1 = 0.000107066 loss)
I0403 05:13:27.685500  4269 sgd_solver.cpp:106] Iteration 12180, lr = 5e-05
I0403 05:13:42.967783  4269 solver.cpp:228] Iteration 12201, loss = 0.000454033
I0403 05:13:42.968082  4269 solver.cpp:244]     Train net output #0: loss = 0.000454089 (* 1 = 0.000454089 loss)
I0403 05:13:43.158964  4269 sgd_solver.cpp:106] Iteration 12201, lr = 5e-05
I0403 05:13:58.237843  4269 solver.cpp:228] Iteration 12222, loss = 0.000601077
I0403 05:13:58.237938  4269 solver.cpp:244]     Train net output #0: loss = 0.000601133 (* 1 = 0.000601133 loss)
I0403 05:13:58.430826  4269 sgd_solver.cpp:106] Iteration 12222, lr = 5e-05
I0403 05:14:13.684959  4269 solver.cpp:228] Iteration 12243, loss = 0.00120104
I0403 05:14:13.686211  4269 solver.cpp:244]     Train net output #0: loss = 0.0012011 (* 1 = 0.0012011 loss)
I0403 05:14:13.950186  4269 sgd_solver.cpp:106] Iteration 12243, lr = 5e-05
I0403 05:14:29.187510  4269 solver.cpp:228] Iteration 12264, loss = 0.000745812
I0403 05:14:29.187608  4269 solver.cpp:244]     Train net output #0: loss = 0.000745869 (* 1 = 0.000745869 loss)
I0403 05:14:29.371284  4269 sgd_solver.cpp:106] Iteration 12264, lr = 5e-05
I0403 05:14:44.609133  4269 solver.cpp:228] Iteration 12285, loss = 0.000179424
I0403 05:14:44.609464  4269 solver.cpp:244]     Train net output #0: loss = 0.000179481 (* 1 = 0.000179481 loss)
I0403 05:14:44.800977  4269 sgd_solver.cpp:106] Iteration 12285, lr = 5e-05
I0403 05:14:59.976902  4269 solver.cpp:228] Iteration 12306, loss = 9.96165e-05
I0403 05:14:59.976990  4269 solver.cpp:244]     Train net output #0: loss = 9.96716e-05 (* 1 = 9.96716e-05 loss)
I0403 05:15:00.158269  4269 sgd_solver.cpp:106] Iteration 12306, lr = 5e-05
I0403 05:15:15.224033  4269 solver.cpp:228] Iteration 12327, loss = 0.000130913
I0403 05:15:15.224333  4269 solver.cpp:244]     Train net output #0: loss = 0.000130968 (* 1 = 0.000130968 loss)
I0403 05:15:15.397383  4269 sgd_solver.cpp:106] Iteration 12327, lr = 5e-05
I0403 05:15:30.593605  4269 solver.cpp:228] Iteration 12348, loss = 2.51897e-05
I0403 05:15:30.593698  4269 solver.cpp:244]     Train net output #0: loss = 2.52446e-05 (* 1 = 2.52446e-05 loss)
I0403 05:15:30.779320  4269 sgd_solver.cpp:106] Iteration 12348, lr = 5e-05
I0403 05:15:46.140314  4269 solver.cpp:228] Iteration 12369, loss = 0.000212524
I0403 05:15:46.140619  4269 solver.cpp:244]     Train net output #0: loss = 0.000212581 (* 1 = 0.000212581 loss)
I0403 05:15:46.342905  4269 sgd_solver.cpp:106] Iteration 12369, lr = 5e-05
I0403 05:16:01.702831  4269 solver.cpp:228] Iteration 12390, loss = 0.000392577
I0403 05:16:01.702919  4269 solver.cpp:244]     Train net output #0: loss = 0.000392634 (* 1 = 0.000392634 loss)
I0403 05:16:01.845473  4269 sgd_solver.cpp:106] Iteration 12390, lr = 5e-05
I0403 05:16:17.147900  4269 solver.cpp:228] Iteration 12411, loss = 0.000317612
I0403 05:16:17.148226  4269 solver.cpp:244]     Train net output #0: loss = 0.00031767 (* 1 = 0.00031767 loss)
I0403 05:16:17.339468  4269 sgd_solver.cpp:106] Iteration 12411, lr = 5e-05
I0403 05:16:32.386724  4269 solver.cpp:228] Iteration 12432, loss = 0.0240428
I0403 05:16:32.386821  4269 solver.cpp:244]     Train net output #0: loss = 0.0240428 (* 1 = 0.0240428 loss)
I0403 05:16:32.599627  4269 sgd_solver.cpp:106] Iteration 12432, lr = 5e-05
I0403 05:16:47.748688  4269 solver.cpp:228] Iteration 12453, loss = 0.000281513
I0403 05:16:47.748997  4269 solver.cpp:244]     Train net output #0: loss = 0.00028157 (* 1 = 0.00028157 loss)
I0403 05:16:47.982425  4269 sgd_solver.cpp:106] Iteration 12453, lr = 5e-05
I0403 05:17:03.123380  4269 solver.cpp:228] Iteration 12474, loss = 0.000399103
I0403 05:17:03.123468  4269 solver.cpp:244]     Train net output #0: loss = 0.000399161 (* 1 = 0.000399161 loss)
I0403 05:17:03.288888  4269 sgd_solver.cpp:106] Iteration 12474, lr = 5e-05
I0403 05:17:18.701481  4269 solver.cpp:228] Iteration 12495, loss = 0.000362865
I0403 05:17:18.701809  4269 solver.cpp:244]     Train net output #0: loss = 0.000362923 (* 1 = 0.000362923 loss)
I0403 05:17:18.927489  4269 sgd_solver.cpp:106] Iteration 12495, lr = 5e-05
I0403 05:17:34.152626  4269 solver.cpp:228] Iteration 12516, loss = 0.000134815
I0403 05:17:34.152722  4269 solver.cpp:244]     Train net output #0: loss = 0.000134872 (* 1 = 0.000134872 loss)
I0403 05:17:34.355514  4269 sgd_solver.cpp:106] Iteration 12516, lr = 5e-05
I0403 05:17:49.413765  4269 solver.cpp:228] Iteration 12537, loss = 0.00109034
I0403 05:17:49.414082  4269 solver.cpp:244]     Train net output #0: loss = 0.00109039 (* 1 = 0.00109039 loss)
I0403 05:17:49.570713  4269 sgd_solver.cpp:106] Iteration 12537, lr = 5e-05
I0403 05:18:04.857542  4269 solver.cpp:228] Iteration 12558, loss = 0.00739111
I0403 05:18:04.857642  4269 solver.cpp:244]     Train net output #0: loss = 0.00739117 (* 1 = 0.00739117 loss)
I0403 05:18:05.064950  4269 sgd_solver.cpp:106] Iteration 12558, lr = 5e-05
I0403 05:18:20.337384  4269 solver.cpp:228] Iteration 12579, loss = 0.00419956
I0403 05:18:20.337736  4269 solver.cpp:244]     Train net output #0: loss = 0.00419962 (* 1 = 0.00419962 loss)
I0403 05:18:20.508199  4269 sgd_solver.cpp:106] Iteration 12579, lr = 5e-05
I0403 05:18:35.844400  4269 solver.cpp:228] Iteration 12600, loss = 0.00289314
I0403 05:18:35.844488  4269 solver.cpp:244]     Train net output #0: loss = 0.0028932 (* 1 = 0.0028932 loss)
I0403 05:18:36.017963  4269 sgd_solver.cpp:106] Iteration 12600, lr = 5e-05
I0403 05:18:46.413650  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_12615.caffemodel
I0403 05:18:49.191534  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_12615.solverstate
I0403 05:18:51.113872  4269 solver.cpp:337] Iteration 12615, Testing net (#0)
I0403 05:19:15.164758  4269 solver.cpp:404]     Test net output #0: accuracy = 0.989159
I0403 05:19:15.164857  4269 solver.cpp:404]     Test net output #1: loss = 0.0456393 (* 1 = 0.0456393 loss)
I0403 05:19:20.027307  4269 solver.cpp:228] Iteration 12621, loss = 0.000424971
I0403 05:19:20.027395  4269 solver.cpp:244]     Train net output #0: loss = 0.00042503 (* 1 = 0.00042503 loss)
I0403 05:19:20.206710  4269 sgd_solver.cpp:106] Iteration 12621, lr = 5e-05
I0403 05:19:35.434645  4269 solver.cpp:228] Iteration 12642, loss = 0.0003077
I0403 05:19:35.434963  4269 solver.cpp:244]     Train net output #0: loss = 0.000307759 (* 1 = 0.000307759 loss)
I0403 05:19:35.616514  4269 sgd_solver.cpp:106] Iteration 12642, lr = 5e-05
I0403 05:19:50.839504  4269 solver.cpp:228] Iteration 12663, loss = 0.000196299
I0403 05:19:50.839592  4269 solver.cpp:244]     Train net output #0: loss = 0.000196356 (* 1 = 0.000196356 loss)
I0403 05:19:51.008559  4269 sgd_solver.cpp:106] Iteration 12663, lr = 5e-05
I0403 05:20:06.440683  4269 solver.cpp:228] Iteration 12684, loss = 0.000210499
I0403 05:20:06.440975  4269 solver.cpp:244]     Train net output #0: loss = 0.000210555 (* 1 = 0.000210555 loss)
I0403 05:20:06.618754  4269 sgd_solver.cpp:106] Iteration 12684, lr = 5e-05
I0403 05:20:21.878718  4269 solver.cpp:228] Iteration 12705, loss = 0.000652076
I0403 05:20:21.878815  4269 solver.cpp:244]     Train net output #0: loss = 0.000652132 (* 1 = 0.000652132 loss)
I0403 05:20:22.070006  4269 sgd_solver.cpp:106] Iteration 12705, lr = 5e-05
I0403 05:20:37.404044  4269 solver.cpp:228] Iteration 12726, loss = 5.73635e-05
I0403 05:20:37.404392  4269 solver.cpp:244]     Train net output #0: loss = 5.74204e-05 (* 1 = 5.74204e-05 loss)
I0403 05:20:37.596878  4269 sgd_solver.cpp:106] Iteration 12726, lr = 5e-05
I0403 05:20:52.724215  4269 solver.cpp:228] Iteration 12747, loss = 0.000957005
I0403 05:20:52.724318  4269 solver.cpp:244]     Train net output #0: loss = 0.000957062 (* 1 = 0.000957062 loss)
I0403 05:20:52.934285  4269 sgd_solver.cpp:106] Iteration 12747, lr = 5e-05
I0403 05:21:08.184607  4269 solver.cpp:228] Iteration 12768, loss = 0.000214139
I0403 05:21:08.184929  4269 solver.cpp:244]     Train net output #0: loss = 0.000214196 (* 1 = 0.000214196 loss)
I0403 05:21:08.403585  4269 sgd_solver.cpp:106] Iteration 12768, lr = 5e-05
I0403 05:21:23.473479  4269 solver.cpp:228] Iteration 12789, loss = 0.000353166
I0403 05:21:23.473578  4269 solver.cpp:244]     Train net output #0: loss = 0.000353224 (* 1 = 0.000353224 loss)
I0403 05:21:23.710937  4269 sgd_solver.cpp:106] Iteration 12789, lr = 5e-05
I0403 05:21:39.003382  4269 solver.cpp:228] Iteration 12810, loss = 0.000187586
I0403 05:21:39.003700  4269 solver.cpp:244]     Train net output #0: loss = 0.000187641 (* 1 = 0.000187641 loss)
I0403 05:21:39.193984  4269 sgd_solver.cpp:106] Iteration 12810, lr = 5e-05
I0403 05:21:54.369323  4269 solver.cpp:228] Iteration 12831, loss = 6.2129e-06
I0403 05:21:54.370499  4269 solver.cpp:244]     Train net output #0: loss = 6.26904e-06 (* 1 = 6.26904e-06 loss)
I0403 05:21:54.591569  4269 sgd_solver.cpp:106] Iteration 12831, lr = 5e-05
I0403 05:22:09.757232  4269 solver.cpp:228] Iteration 12852, loss = 0.00606237
I0403 05:22:09.757593  4269 solver.cpp:244]     Train net output #0: loss = 0.00606243 (* 1 = 0.00606243 loss)
I0403 05:22:09.962752  4269 sgd_solver.cpp:106] Iteration 12852, lr = 5e-05
I0403 05:22:25.185392  4269 solver.cpp:228] Iteration 12873, loss = 0.000295096
I0403 05:22:25.185485  4269 solver.cpp:244]     Train net output #0: loss = 0.000295152 (* 1 = 0.000295152 loss)
I0403 05:22:25.351140  4269 sgd_solver.cpp:106] Iteration 12873, lr = 5e-05
I0403 05:22:40.567276  4269 solver.cpp:228] Iteration 12894, loss = 0.00216026
I0403 05:22:40.567598  4269 solver.cpp:244]     Train net output #0: loss = 0.00216032 (* 1 = 0.00216032 loss)
I0403 05:22:40.751067  4269 sgd_solver.cpp:106] Iteration 12894, lr = 5e-05
I0403 05:22:55.878789  4269 solver.cpp:228] Iteration 12915, loss = 3.17142e-05
I0403 05:22:55.878888  4269 solver.cpp:244]     Train net output #0: loss = 3.17699e-05 (* 1 = 3.17699e-05 loss)
I0403 05:22:56.077193  4269 sgd_solver.cpp:106] Iteration 12915, lr = 5e-05
I0403 05:23:11.281384  4269 solver.cpp:228] Iteration 12936, loss = 8.12374e-05
I0403 05:23:11.281702  4269 solver.cpp:244]     Train net output #0: loss = 8.12934e-05 (* 1 = 8.12934e-05 loss)
I0403 05:23:11.478375  4269 sgd_solver.cpp:106] Iteration 12936, lr = 5e-05
I0403 05:23:26.939867  4269 solver.cpp:228] Iteration 12957, loss = 8.51356e-05
I0403 05:23:26.939967  4269 solver.cpp:244]     Train net output #0: loss = 8.51916e-05 (* 1 = 8.51916e-05 loss)
I0403 05:23:27.156597  4269 sgd_solver.cpp:106] Iteration 12957, lr = 5e-05
I0403 05:23:42.141892  4269 solver.cpp:228] Iteration 12978, loss = 0.000500363
I0403 05:23:42.142180  4269 solver.cpp:244]     Train net output #0: loss = 0.000500419 (* 1 = 0.000500419 loss)
I0403 05:23:42.344589  4269 sgd_solver.cpp:106] Iteration 12978, lr = 5e-05
I0403 05:23:57.539393  4269 solver.cpp:228] Iteration 12999, loss = 0.00968921
I0403 05:23:57.539489  4269 solver.cpp:244]     Train net output #0: loss = 0.00968926 (* 1 = 0.00968926 loss)
I0403 05:23:57.776470  4269 sgd_solver.cpp:106] Iteration 12999, lr = 5e-05
I0403 05:24:13.074643  4269 solver.cpp:228] Iteration 13020, loss = 0.00176689
I0403 05:24:13.074959  4269 solver.cpp:244]     Train net output #0: loss = 0.00176694 (* 1 = 0.00176694 loss)
I0403 05:24:13.230402  4269 sgd_solver.cpp:106] Iteration 13020, lr = 5e-05
I0403 05:24:28.500782  4269 solver.cpp:228] Iteration 13041, loss = 0.000781873
I0403 05:24:28.500875  4269 solver.cpp:244]     Train net output #0: loss = 0.000781929 (* 1 = 0.000781929 loss)
I0403 05:24:28.713416  4269 sgd_solver.cpp:106] Iteration 13041, lr = 5e-05
I0403 05:24:34.745962  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_13050.caffemodel
I0403 05:24:37.526175  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_13050.solverstate
I0403 05:24:39.438467  4269 solver.cpp:337] Iteration 13050, Testing net (#0)
I0403 05:25:03.503695  4269 solver.cpp:404]     Test net output #0: accuracy = 0.989159
I0403 05:25:03.504011  4269 solver.cpp:404]     Test net output #1: loss = 0.0447323 (* 1 = 0.0447323 loss)
I0403 05:25:08.715689  4269 solver.cpp:454] Snapshotting to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_13057.caffemodel
I0403 05:25:11.471386  4269 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /scratch/mohanty/AWS_FRESH_RUN/snapshots_final/alexnet_segmented-80-20_finetune/snapshots__iter_13057.solverstate
I0403 05:25:13.389194  4269 solver.cpp:322] Optimization Done.
I0403 05:25:13.469084  4269 caffe.cpp:222] Optimization Done.
